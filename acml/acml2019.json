[
    {
        "title": "$\\mathcal{X}$-Armed Bandits: Optimizing Quantiles, CVaR and Other Risks",
        "site": "https://proceedings.mlr.press/v101/torossian19a.html",
        "author": "L\u00e9onard Torossian; Aur\u00e9lien Garivier; Victor Picheny",
        "abstract": "We propose and analyze StoROO, an algorithm for risk optimization on stochastic black-box functions derived from StoOO. Motivated by risk-averse decision making fields like agriculture, medicine, biology or finance, we do not focus on the mean payoff but on generic functionals of the return distribution. We provide a generic regret analysis of StoROO and illustrate its applicability with two examples: the optimization of quantiles and CVaR. Inspired by the bandit literature and black-box mean optimizers, StoROO relies on the possibility to construct confidence intervals for the targeted functional based on random-size samples. We detail their construction in the case of quantiles, providing tight bounds based on Kullback-Leibler divergence. We finally present numerical experiments that show a dramatic impact of tight bounds for the optimization of quantiles and CVaR.",
        "bibtex": "@InProceedings{pmlr-v101-torossian19a,\n  title = \t {$\\mathcal{X}$-Armed Bandits: Optimizing Quantiles, CVaR and Other Risks},\n  author =       {Torossian, L\\'eonard and Garivier, Aur\\'elien and Picheny, Victor},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {252--267},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/torossian19a/torossian19a.pdf},\n  url = \t {https://proceedings.mlr.press/v101/torossian19a.html},\n  abstract = \t {We propose and analyze StoROO, an algorithm for risk optimization on stochastic black-box functions derived from StoOO. Motivated by risk-averse decision making fields like agriculture, medicine, biology or finance, we do not focus on the mean payoff but on generic functionals of the return distribution. We provide a generic regret analysis of StoROO and illustrate its applicability with two examples: the optimization of quantiles and CVaR. Inspired by the bandit literature and black-box mean optimizers, StoROO relies on the possibility to construct confidence intervals for the targeted functional based on random-size samples. We detail their construction in the case of quantiles, providing tight bounds based on Kullback-Leibler divergence. We finally present numerical experiments that show a dramatic impact of tight bounds for the optimization of quantiles and CVaR.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/torossian19a/torossian19a.pdf",
        "supp": "",
        "pdf_size": 1787775,
        "gs_citation": -1,
        "gs_cited_by_link": "",
        "gs_version_total": -1,
        "aff": "Universite de Toulouse, INRA, France+Institut de Mathematiques de Toulouse, France; Univ. Lyon, ENS de Lyon, France; PROWLER.io, 72 Hills Road, Cambridge, UK",
        "aff_domain": "inra.fr;ens-lyon.fr;prowler.io",
        "email": "inra.fr;ens-lyon.fr;prowler.io",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;2;3",
        "aff_unique_norm": "Universite de Toulouse;Institut de Mathematiques de Toulouse;Universit\u00e9 Lyon;PROWLER.io",
        "aff_unique_dep": "INRA;Mathematics;ENS de Lyon;",
        "aff_unique_url": "https://www.univ-toulouse.fr;https://www.imtoulouse.fr;https://www.ens-lyon.fr;https://www.prowler.io",
        "aff_unique_abbr": "UT;IMT;ENS de Lyon;",
        "aff_campus_unique_index": ";1",
        "aff_campus_unique": ";Cambridge",
        "aff_country_unique_index": "0+0;0;1",
        "aff_country_unique": "France;United Kingdom"
    },
    {
        "title": "A Continuous Actor-Critic Reinforcement Learning Approach to Flocking with Fixed-Wing UAVs",
        "site": "https://proceedings.mlr.press/v101/wang19a.html",
        "author": "Chang Wang; Chao Yan; Xiaojia Xiang; Han Zhou",
        "abstract": "Controlling a squad of fixed-wing UAVs is challenging due to the kinematics complexity and the environmental dynamics. In this paper, we develop a novel actor-critic reinforcement learning approach to solve the leader-follower flocking problem in continuous state and action spaces. Specifically, we propose a CACER algorithm that uses multilayer perceptron to represent both the actor and the critic, which has a deeper structure and provides a better function approximator than the original continuous actor-critic learning automation (CACLA) algorithm. Besides, we propose a double prioritized experience replay (DPER) mechanism to further improve the training efficiency. Specifically, the state transition samples are saved into two different experience replay buffers for updating the actor and the critic separately, based on the calculation of sample priority using the temporal difference errors. We have not only compared CACER with CACLA and a benchmark deep reinforcement learning algorithm DDPG in numerical simulation, but also demonstrated the performance of CACER in semi-physical simulation by transferring the learned policy in the numerical simulation without parameter tuning.",
        "bibtex": "@InProceedings{pmlr-v101-wang19a,\n  title = \t {A Continuous Actor-Critic Reinforcement Learning Approach to Flocking with Fixed-Wing UAVs},\n  author =       {Wang, Chang and Yan, Chao and Xiang, Xiaojia and Zhou, Han},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {64--79},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/wang19a/wang19a.pdf},\n  url = \t {https://proceedings.mlr.press/v101/wang19a.html},\n  abstract = \t {Controlling a squad of fixed-wing UAVs is challenging due to the kinematics complexity and the environmental dynamics. In this paper, we develop a novel actor-critic reinforcement learning approach to solve the leader-follower flocking problem in continuous state and action spaces. Specifically, we propose a CACER algorithm that uses multilayer perceptron to represent both the actor and the critic, which has a deeper structure and provides a better function approximator than the original continuous actor-critic learning automation (CACLA) algorithm. Besides, we propose a double prioritized experience replay (DPER) mechanism to further improve the training efficiency. Specifically, the state transition samples are saved into two different experience replay buffers for updating the actor and the critic separately, based on the calculation of sample priority using the temporal difference errors. We have not only compared CACER with CACLA and a benchmark deep reinforcement learning algorithm DDPG in numerical simulation, but also demonstrated the performance of CACER in semi-physical simulation by transferring the learned policy in the numerical simulation without parameter tuning.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/wang19a/wang19a.pdf",
        "supp": "",
        "pdf_size": 806266,
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2834045901020941729&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "National University of Defense Technology, Changsha, China; National University of Defense Technology, Changsha, China; National University of Defense Technology, Changsha, China; National University of Defense Technology, Changsha, China",
        "aff_domain": "nudt.edu.cn;nudt.edu.cn;nudt.edu.cn;nudt.edu.cn",
        "email": "nudt.edu.cn;nudt.edu.cn;nudt.edu.cn;nudt.edu.cn",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "National University of Defense Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "http://www.nudt.edu.cn",
        "aff_unique_abbr": "NUDT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Changsha",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "title": "A Generalization Bound for Online Variational Inference",
        "site": "https://proceedings.mlr.press/v101/cherief-abdellatif19a.html",
        "author": "Badr-Eddine Ch\u00e9rief-Abdellatif; Pierre Alquier; Mohammad Emtiyaz Khan",
        "abstract": "Bayesian inference provides an attractive online-learning framework to analyze sequential data, and offers generalization guarantees which hold even with model mismatch and adversaries. Unfortunately, exact Bayesian inference is rarely feasible in practice and approximation methods are usually employed, but do such methods preserve the generalization properties of Bayesian inference ? In this paper, we show that this is indeed the case for some variational inference (VI) algorithms. We consider a few existing online, tempered VI algorithms, as well as a new algorithm, and derive their generalization bounds. Our theoretical result relies on the convexity of the variational objective, but we argue that the result should hold more generally and present empirical evidence in support of this. Our work in this paper presents theoretical justifications in favor of online algorithms relying on approximate Bayesian methods.",
        "bibtex": "@InProceedings{pmlr-v101-cherief-abdellatif19a,\n  title = \t {A Generalization Bound for Online Variational Inference},\n  author =       {Ch\\'erief-Abdellatif, Badr-Eddine and Alquier, Pierre and Khan, Mohammad Emtiyaz},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {662--677},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/cherief-abdellatif19a/cherief-abdellatif19a.pdf},\n  url = \t {https://proceedings.mlr.press/v101/cherief-abdellatif19a.html},\n  abstract = \t {Bayesian inference provides an attractive online-learning framework to analyze sequential data, and offers generalization guarantees which hold even with model mismatch and adversaries. Unfortunately, exact Bayesian inference is rarely feasible in practice and approximation methods are usually employed, but do such methods preserve the generalization properties of Bayesian inference ? In this paper, we show that this is indeed the case for some variational inference (VI) algorithms. We consider a few existing online, tempered VI algorithms, as well as a new algorithm, and derive their generalization bounds. Our theoretical result relies on the convexity of the variational objective, but we argue that the result should hold more generally and present empirical evidence in support of this. Our work in this paper presents theoretical justifications in favor of online algorithms relying on approximate Bayesian methods.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/cherief-abdellatif19a/cherief-abdellatif19a.pdf",
        "supp": "",
        "pdf_size": 1229334,
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1392282111683319191&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "CREST, ENSAE, Institut Polytechnique de Paris; RIKEN Center for AI Project, Tokyo, Japan; RIKEN Center for AI Project, Tokyo, Japan",
        "aff_domain": "ensae.fr;riken.jp;riken.jp",
        "email": "ensae.fr;riken.jp;riken.jp",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Institut Polytechnique de Paris;RIKEN",
        "aff_unique_dep": ";Center for AI Project",
        "aff_unique_url": "https://www.ipparis.fr;https://www.riken.jp/en/",
        "aff_unique_abbr": "IP Paris;RIKEN",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Tokyo",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "France;Japan"
    },
    {
        "title": "A Model of Text-Enhanced Knowledge Graph Representation Learning with Collaborative Attention",
        "site": "https://proceedings.mlr.press/v101/wang19d.html",
        "author": "Yashen Wang; Huanhuan Zhang; Haiyong Xie",
        "abstract": "This paper proposes a novel collaborative attention mechanism, to fully utilize the mutually reinforcing relationship among the knowledge graph representation learning procedure (i.e., structure representation) and textual relation representation learning procedure (i.e., text representation). Based on this collaborative attention mechanism, a text-enhanced knowledge graph (KG) representation model is proposed, which could utilize textual information to enhance the knowledge representations and make the multi-direction signals to be fully integrated to learn more accurate textual representations for further improving structure representation and vice versa. Experimental results demonstrate the efficiency of the proposed model on both link prediction task and triple classification task.",
        "bibtex": "@InProceedings{pmlr-v101-wang19d,\n  title = \t {A Model of Text-Enhanced Knowledge Graph Representation Learning with Collaborative Attention},\n  author =       {Wang, Yashen and Zhang, Huanhuan and Xie, Haiyong},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {220--235},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/wang19d/wang19d.pdf},\n  url = \t {https://proceedings.mlr.press/v101/wang19d.html},\n  abstract = \t {This paper proposes a novel collaborative attention mechanism, to fully utilize the mutually reinforcing relationship among the knowledge graph representation learning procedure (i.e., structure representation) and textual relation representation learning procedure (i.e., text representation). Based on this collaborative attention mechanism, a text-enhanced knowledge graph (KG) representation model is proposed, which could utilize textual information to enhance the knowledge representations and make the multi-direction signals to be fully integrated to learn more accurate textual representations for further improving structure representation and vice versa. Experimental results demonstrate the efficiency of the proposed model on both link prediction task and triple classification task.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/wang19d/wang19d.pdf",
        "supp": "",
        "pdf_size": 526011,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9342567151878966754&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "China Academy of Electronics and Information Technology of CETC, Beijing, China; China Academy of Electronics and Information Technology of CETC, Beijing, China; China Academy of Electronics and Information Technology of CETC, Beijing, China+University of Science and Technology of China, Hefei, Anhui, China",
        "aff_domain": "126.com;139.com;ieee.org",
        "email": "126.com;139.com;ieee.org",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0+1",
        "aff_unique_norm": "China Academy of Electronics and Information Technology;University of Science and Technology of China",
        "aff_unique_dep": "Electronics and Information Technology;",
        "aff_unique_url": ";http://www.ustc.edu.cn",
        "aff_unique_abbr": "CAEIT;USTC",
        "aff_campus_unique_index": "0;0;0+1",
        "aff_campus_unique": "Beijing;Hefei",
        "aff_country_unique_index": "0;0;0+0",
        "aff_country_unique": "China"
    },
    {
        "title": "A New Multi-choice Reading Comprehension Dataset for Curriculum Learning",
        "site": "https://proceedings.mlr.press/v101/liang19a.html",
        "author": "Yichan Liang; Jianheng Li; Jian Yin",
        "abstract": "The past few years have witnessed the rapid development of machine reading comprehension (MRC), especially the challenging sub-task, multiple-choice reading comprehension (MCRC). And the release of large scale datasets promotes the research in this field. Yet previous methods have already achieved high accuracy of the MCRC datasets, \\textit{e.g.} RACE. It\u2019s necessary to propose a more difficult dataset which needs more reasoning and inference for evaluating the understanding capability of new methods. To respond to such demand, we present RACE-C, a new multi-choice reading comprehension dataset collected from college English examinations in China. And further we integrate it with RACE-M and RACE-H, collected by {{Lai et\u00a0al.}} ({2017}) from middle and high school exams respectively, to extend RACE to be RACE++. Based on RACE++, we propose a three-stage curriculum learning framework, which is able to use the best of the characteristic that the difficulty level within these three sub-datasets is in ascending order. Statistics show the higher difficulty level of our collected dataset, RACE-C, compared to RACE\u2019s two sub-datasets, \\textit{i.e.}, RACE-M and RACE-H. And experimental results demonstrate that our proposed three-stage curriculum learning approach improves the performance of the machine reading comprehension model to an extent.",
        "bibtex": "@InProceedings{pmlr-v101-liang19a,\n  title = \t {A New Multi-choice Reading Comprehension Dataset for Curriculum Learning},\n  author =       {Liang, Yichan and Li, Jianheng and Yin, Jian},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {742--757},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/liang19a/liang19a.pdf},\n  url = \t {https://proceedings.mlr.press/v101/liang19a.html},\n  abstract = \t {The past few years have witnessed the rapid development of machine reading comprehension (MRC), especially the challenging sub-task, multiple-choice reading comprehension (MCRC). And the release of large scale datasets promotes the research in this field. Yet previous methods have already achieved high accuracy of the MCRC datasets, \\textit{e.g.} RACE. It\u2019s necessary to propose a more difficult dataset which needs more reasoning and inference for evaluating the understanding capability of new methods. To respond to such demand, we present RACE-C, a new multi-choice reading comprehension dataset collected from college English examinations in China. And further we integrate it with RACE-M and RACE-H, collected by {{Lai et\u00a0al.}} ({2017}) from middle and high school exams respectively, to extend RACE to be RACE++. Based on RACE++, we propose a three-stage curriculum learning framework, which is able to use the best of the characteristic that the difficulty level within these three sub-datasets is in ascending order. Statistics show the higher difficulty level of our collected dataset, RACE-C, compared to RACE\u2019s two sub-datasets, \\textit{i.e.}, RACE-M and RACE-H. And experimental results demonstrate that our proposed three-stage curriculum learning approach improves the performance of the machine reading comprehension model to an extent.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/liang19a/liang19a.pdf",
        "supp": "",
        "pdf_size": 290514,
        "gs_citation": 40,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10685571629189236130&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "School of Data and Computer Science, Sun Yat-sen University, China + Guangdong Key Laboratory of Big Data Analysis and Processing, Guangzhou 510006, P.R.China; School of Data and Computer Science, Sun Yat-sen University, China + Guangdong Key Laboratory of Big Data Analysis and Processing, Guangzhou 510006, P.R.China; School of Data and Computer Science, Sun Yat-sen University, China + Guangdong Key Laboratory of Big Data Analysis and Processing, Guangzhou 510006, P.R.China",
        "aff_domain": "mail2.sysu.edu.cn;mail2.sysu.edu.cn;mail.sysu.edu.cn",
        "email": "mail2.sysu.edu.cn;mail2.sysu.edu.cn;mail.sysu.edu.cn",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;0+1;0+1",
        "aff_unique_norm": "Sun Yat-sen University;Guangdong Key Laboratory of Big Data Analysis and Processing",
        "aff_unique_dep": "School of Data and Computer Science;",
        "aff_unique_url": "http://www.sysu.edu.cn/;",
        "aff_unique_abbr": "SYSU;",
        "aff_campus_unique_index": "1;1;1",
        "aff_campus_unique": ";Guangzhou",
        "aff_country_unique_index": "0+0;0+0;0+0",
        "aff_country_unique": "China"
    },
    {
        "title": "Active Change-Point Detection",
        "site": "https://proceedings.mlr.press/v101/hayashi19a.html",
        "author": "Shogo Hayashi; Yoshinobu Kawahara; Hisashi Kashima",
        "abstract": "We introduce Active Change-Point Detection (ACPD), a novel active learning problem for efficient change-point detection in situations where the cost of data acquisition is expensive. At each round of ACPD, the task is to adaptively determine the next input, in order to detect the change-point in a black-box expensive-to-evaluate function, with as few evaluations as possible. We propose a novel framework that can be generalized for different types of data and change-points, by utilizing an existing change-point detection method to compute change scores and a Bayesian optimization method to determine the next input. We demonstrate the efficiency of our proposed framework in different settings of datasets and change-points, using synthetic data and real-world data, such as material science data and seafloor depth data.",
        "bibtex": "@InProceedings{pmlr-v101-hayashi19a,\n  title = \t {Active Change-Point Detection},\n  author =       {Hayashi, Shogo and Kawahara, Yoshinobu and Kashima, Hisashi},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {1017--1032},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/hayashi19a/hayashi19a.pdf},\n  url = \t {https://proceedings.mlr.press/v101/hayashi19a.html},\n  abstract = \t {We introduce Active Change-Point Detection (ACPD), a novel active learning problem for efficient change-point detection in situations where the cost of data acquisition is expensive. At each round of ACPD, the task is to adaptively determine the next input, in order to detect the change-point in a black-box expensive-to-evaluate function, with as few evaluations as possible. We propose a novel framework that can be generalized for different types of data and change-points, by utilizing an existing change-point detection method to compute change scores and a Bayesian optimization method to determine the next input. We demonstrate the efficiency of our proposed framework in different settings of datasets and change-points, using synthetic data and real-world data, such as material science data and seafloor depth data.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/hayashi19a/hayashi19a.pdf",
        "supp": "",
        "pdf_size": 1195923,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14443107387498909701&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "aff": "Graduate School of Informatics, Kyoto University; Institute of Mathematics for Industry, Kyushu University + RIKEN Center for AIP; Graduate School of Informatics, Kyoto University + RIKEN Center for AIP",
        "aff_domain": "ml.ist.i.kyoto-u.ac.jp;imi.kyushu-u.ac.jp;i.kyoto-u.ac.jp",
        "email": "ml.ist.i.kyoto-u.ac.jp;imi.kyushu-u.ac.jp;i.kyoto-u.ac.jp",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1+2;0+2",
        "aff_unique_norm": "Kyoto University;Kyushu University;RIKEN",
        "aff_unique_dep": "Graduate School of Informatics;Institute of Mathematics for Industry;Center for AIP",
        "aff_unique_url": "https://www.kyoto-u.ac.jp;https://www.kyushu-u.ac.jp;https://www.riken.jp",
        "aff_unique_abbr": "Kyoto U;Kyushu U;RIKEN",
        "aff_campus_unique_index": "0;;0",
        "aff_campus_unique": "Kyoto;",
        "aff_country_unique_index": "0;0+0;0+0",
        "aff_country_unique": "Japan"
    },
    {
        "title": "Adaptive truncated residual regression for fine-grained regression problems",
        "site": "https://proceedings.mlr.press/v101/hachiya19a.html",
        "author": "Hirotaka Hachiya; Yu Yamamoto; Kazuro Hirahara; Naonori Ueda",
        "abstract": "Recently, anchor-based regression methods have been applied to challenging regression problems, e.g., object detection and distance estimation, and greatly improved those performances. The key idea of anchor-based regression is to solve the regression of the residuals between selected anchors and original target variable, where the variance is expected to be smaller. However, similar to an ordinary regression method, the anchor-based regression could face difficulty on a fine-grained regression and ill-posed problems where the residual variables tend to be too small and complicated to accurately predict. To overcome these problems on the anchor-based regression, we propose to introduce an adaptive residual encoding in which the too small residual is magnified, and the too-large residual is truncated using adaptively tuned sigmoidal function. Our proposed method, called ATR-Nets (Adaptive Truncated Residual-Networks) with an end-to-end architecture could control the range of the target residual to be fitted based on the regression performance, Through experiments with toy-data and the system identification for earthquake asperity models, we show the effectiveness of our proposed method.",
        "bibtex": "@InProceedings{pmlr-v101-hachiya19a,\n  title = \t {Adaptive truncated residual regression for fine-grained regression problems},\n  author =       {Hachiya, Hirotaka and Yamamoto, Yu and Hirahara, Kazuro and Ueda, Naonori},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {868--882},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/hachiya19a/hachiya19a.pdf},\n  url = \t {https://proceedings.mlr.press/v101/hachiya19a.html},\n  abstract = \t {Recently, anchor-based regression methods have been applied to challenging regression problems, e.g., object detection and distance estimation, and greatly improved those performances. The key idea of anchor-based regression is to solve the regression of the residuals between selected anchors and original target variable, where the variance is expected to be smaller. However, similar to an ordinary regression method, the anchor-based regression could face difficulty on a fine-grained regression and ill-posed problems where the residual variables tend to be too small and complicated to accurately predict. To overcome these problems on the anchor-based regression, we propose to introduce an adaptive residual encoding in which the too small residual is magnified, and the too-large residual is truncated using adaptively tuned sigmoidal function. Our proposed method, called ATR-Nets (Adaptive Truncated Residual-Networks) with an end-to-end architecture could control the range of the target residual to be fitted based on the regression performance, Through experiments with toy-data and the system identification for earthquake asperity models, we show the effectiveness of our proposed method.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/hachiya19a/hachiya19a.pdf",
        "supp": "",
        "pdf_size": 6358981,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:Izwdf9SIPOUJ:scholar.google.com/&scioq=Adaptive+truncated+residual+regression+for+fine-grained+regression+problems&hl=en&as_sdt=0,33",
        "gs_version_total": 3,
        "aff": "Center for Advanced Intelligence Project, RIKEN, Tokyo, Japan+Graduate School of System Engineering, Wakayama University, Wakayama, Japan; Center for Advanced Intelligence Project, RIKEN, Tokyo, Japan+Graduate School of System Engineering, Wakayama University, Wakayama, Japan; Center for Advanced Intelligence Project, RIKEN, Tokyo, Japan; Center for Advanced Intelligence Project, RIKEN, Tokyo, Japan",
        "aff_domain": "riken.jp;riken.jp;riken.jp;riken.jp",
        "email": "riken.jp;riken.jp;riken.jp;riken.jp",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;0+1;0;0",
        "aff_unique_norm": "RIKEN;Wakayama University",
        "aff_unique_dep": "Center for Advanced Intelligence Project;Graduate School of System Engineering",
        "aff_unique_url": "https://www.riken.jp;https://www.wakayama-u.ac.jp",
        "aff_unique_abbr": "RIKEN;",
        "aff_campus_unique_index": "0+1;0+1;0;0",
        "aff_campus_unique": "Tokyo;Wakayama",
        "aff_country_unique_index": "0+0;0+0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "title": "An Anchor-Free Oriented Text Detector with Connectionist Text Proposal Network",
        "site": "https://proceedings.mlr.press/v101/huang19c.html",
        "author": "Chenhui Huang; Jinhua Xu",
        "abstract": "Deep learning approaches have made great progress for the scene text detection in recent years. However, there are still some difficulties such as the text orientation and varying aspect ratios. In this paper, we address these issues by treating a text instance as a sequence of fine-scale proposals. The vertical distances from a text pixel to the text borders are directly regressed without the commonly used anchor mechanism, and then the small local proposals are connected during the post-processing. A U-shape convolutional neural network (CNN) architecture is used to incorporate the context information and detect small text instances. In experiments, the proposed approach, referred to as Anchor-Free oriented text detector with Connectionist Text Proposal Network (AFCTPN), achieves better or comparable performance with less time consumption on benchmark datasets.",
        "bibtex": "@InProceedings{pmlr-v101-huang19c,\n  title = \t {An Anchor-Free Oriented Text Detector with Connectionist Text Proposal Network},\n  author =       {Huang, Chenhui and Xu, Jinhua},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {631--645},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/huang19c/huang19c.pdf},\n  url = \t {https://proceedings.mlr.press/v101/huang19c.html},\n  abstract = \t {Deep learning approaches have made great progress for the scene text detection in recent years. However, there are still some difficulties such as the text orientation and varying aspect ratios. In this paper, we address these issues by treating a text instance as a sequence of fine-scale proposals. The vertical distances from a text pixel to the text borders are directly regressed without the commonly used anchor mechanism, and then the small local proposals are connected during the post-processing. A U-shape convolutional neural network (CNN) architecture is used to incorporate the context information and detect small text instances. In experiments, the proposed approach, referred to as Anchor-Free oriented text detector with Connectionist Text Proposal Network (AFCTPN), achieves better or comparable performance with less time consumption on benchmark datasets.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/huang19c/huang19c.pdf",
        "supp": "",
        "pdf_size": 6511643,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8185220878683900344&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "School of Computer Science and Technology, East China Normal University, Shanghai 200062, China; School of Computer Science and Technology, East China Normal University, Shanghai 200062, China",
        "aff_domain": "gmail.com;cs.ecnu.edu.cn",
        "email": "gmail.com;cs.ecnu.edu.cn",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "East China Normal University",
        "aff_unique_dep": "School of Computer Science and Technology",
        "aff_unique_url": "http://www.ecnu.edu.cn",
        "aff_unique_abbr": "ECNU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Shanghai",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "title": "An Articulated Structure-aware Network for 3D Human Pose Estimation",
        "site": "https://proceedings.mlr.press/v101/tang19a.html",
        "author": "Zhenhua Tang; Xiaoyan Zhang; Junhui Hou",
        "abstract": "In this paper, we propose a new end-to-end articulated structure-aware network to regress 3D joint coordinates from the given 2D joint detections. The proposed method is capable of dealing with hard joints well that usually fail existing methods. Specifically, our framework cascades a refinement network with a basic network for two types of joints, and employs a attention module to simulate a camera projection model. In addition, we propose to use a random enhancement module to intensify the constraints between joints. Experimental results on the Human3.6M and HumanEva databases demonstrate the effectiveness and flexibility of the proposed network, and errors of hard joints and bone lengths are significantly reduced, compared with state-of-the-art approaches.",
        "bibtex": "@InProceedings{pmlr-v101-tang19a,\n  title = \t {An Articulated Structure-aware Network for 3D Human Pose Estimation},\n  author =       {Tang, Zhenhua and Zhang, Xiaoyan and Hou, Junhui},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {48--63},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/tang19a/tang19a.pdf},\n  url = \t {https://proceedings.mlr.press/v101/tang19a.html},\n  abstract = \t {In this paper, we propose a new end-to-end articulated structure-aware network to regress 3D joint coordinates from the given 2D joint detections. The proposed method is capable of dealing with hard joints well that usually fail existing methods. Specifically, our framework cascades a refinement network with a basic network for two types of joints, and employs a attention module to simulate a camera projection model. In addition, we propose to use a random enhancement module to intensify the constraints between joints. Experimental results on the Human3.6M and HumanEva databases demonstrate the effectiveness and flexibility of the proposed network, and errors of hard joints and bone lengths are significantly reduced, compared with state-of-the-art approaches.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/tang19a/tang19a.pdf",
        "supp": "",
        "pdf_size": 3019027,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17444992207993332722&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "College of Computer Science & Software Engineering, Shenzhen University, Shenzhen, China; College of Computer Science & Software Engineering, Shenzhen University, Shenzhen, China; Department of Computer Science, City University of Hong Kong, Hong Kong, China",
        "aff_domain": "gmail.com;szu.edu.cn;cityu.edu.hk",
        "email": "gmail.com;szu.edu.cn;cityu.edu.hk",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Shenzhen University;City University of Hong Kong",
        "aff_unique_dep": "College of Computer Science & Software Engineering;Department of Computer Science",
        "aff_unique_url": "https://www.szu.edu.cn;https://www.cityu.edu.hk",
        "aff_unique_abbr": "SZU;CityU",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Shenzhen;Hong Kong",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "title": "An Attentive Memory Network Integrated with Aspect Dependency for Document-Level Multi-Aspect Sentiment Classification",
        "site": "https://proceedings.mlr.press/v101/zhang19b.html",
        "author": "Qingxuan Zhang; Chongyang Shi",
        "abstract": "Document-level multi-aspect sentiment classification is one of the foundational tasks in natural language processing (NLP) and neural network methods have achieved great success in reviews sentiment classification. Most of recent works ignore the relation between different aspects and do not take into account the contexting dependent importance of sentences and aspect keywords. In this paper, we propose an attentive memory network for document-level multi-aspect sentiment classification. Unlike recent proposed models which average word embeddings of aspect keywords to represent aspect and utilize hierarchical architectures to encode review documents, we adopt attention-based memory networks to construct aspect and sentence memories. The recurrent attention operation is employed to capture long-distance dependency across sentences and obtain aspect-aware document representations over aspect and sentence memories. Then, incorporating the neighboring aspects related information into the final aspect rating predictions by using multi-hop attention memory networks. Experimental results on two real-world datasets TripAdvisor and BeerAdvocate show that our model achieves state-of-the-art performance.",
        "bibtex": "@InProceedings{pmlr-v101-zhang19b,\n  title = \t {An Attentive Memory Network Integrated with Aspect Dependency for Document-Level Multi-Aspect Sentiment Classification},\n  author =       {Zhang, Qingxuan and Shi, Chongyang},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {425--440},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/zhang19b/zhang19b.pdf},\n  url = \t {https://proceedings.mlr.press/v101/zhang19b.html},\n  abstract = \t {Document-level multi-aspect sentiment classification is one of the foundational tasks in natural language processing (NLP) and neural network methods have achieved great success in reviews sentiment classification. Most of recent works ignore the relation between different aspects and do not take into account the contexting dependent importance of sentences and aspect keywords. In this paper, we propose an attentive memory network for document-level multi-aspect sentiment classification. Unlike recent proposed models which average word embeddings of aspect keywords to represent aspect and utilize hierarchical architectures to encode review documents, we adopt attention-based memory networks to construct aspect and sentence memories. The recurrent attention operation is employed to capture long-distance dependency across sentences and obtain aspect-aware document representations over aspect and sentence memories. Then, incorporating the neighboring aspects related information into the final aspect rating predictions by using multi-hop attention memory networks. Experimental results on two real-world datasets TripAdvisor and BeerAdvocate show that our model achieves state-of-the-art performance.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/zhang19b/zhang19b.pdf",
        "supp": "",
        "pdf_size": 380260,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12864455930749246972&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "School of Computer, Beijing Institute of Technology, Beijing 100081, China; School of Computer, Beijing Institute of Technology, Beijing 100081, China",
        "aff_domain": "bit.edu.cn;bit.edu.cn",
        "email": "bit.edu.cn;bit.edu.cn",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Beijing Institute of Technology",
        "aff_unique_dep": "School of Computer",
        "aff_unique_url": "http://www.bit.edu.cn",
        "aff_unique_abbr": "BIT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "title": "An Encoding Adversarial Network for Anomaly Detection",
        "site": "https://proceedings.mlr.press/v101/gherbi19a.html",
        "author": "Elies Gherbi; Blaise Hanczar; Jean-Christophe Janodet; Witold Klaudel",
        "abstract": "Anomaly detection is a standard problem in Machine Learning with various applications such as health-care, predictive maintenance, and cyber-security. In such applications, the data is unbalanced: the rate of regular examples is much higher than the anomalous examples. The emergence of the Generative Adversarial Networks (GANs) has recently brought new algorithms for anomaly detection. Most of them use the generator as a proxy for the reconstruction loss. The idea is that the generator cannot reconstruct an anomaly. We develop an alternative approach for anomaly detection, based on an Encoding Adversarial Network (AnoEAN), which maps the data to a latent space (decision space), where the detection of anomalies is done directly by calculating a score. Our encoder is learned by adversarial learning, using two loss functions, the first constraining the encoder to project regular data into a Gaussian distribution and the second, to project anomalous data outside this distribution. We conduct a series of experiments on several standard bases and show that our approach outperforms the state of the art when using 10% anomalies during the learning stage, and detects unseen anomalies.",
        "bibtex": "@InProceedings{pmlr-v101-gherbi19a,\n  title = \t {An Encoding Adversarial Network for Anomaly Detection},\n  author =       {Gherbi, Elies and Hanczar, Blaise and Janodet, Jean-Christophe and Klaudel, Witold},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {188--203},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/gherbi19a/gherbi19a.pdf},\n  url = \t {https://proceedings.mlr.press/v101/gherbi19a.html},\n  abstract = \t {Anomaly detection is a standard problem in Machine Learning with various applications such as health-care, predictive maintenance, and cyber-security. In such applications, the data is unbalanced: the rate of regular examples is much higher than the anomalous examples. The emergence of the Generative Adversarial Networks (GANs) has recently brought new algorithms for anomaly detection. Most of them use the generator as a proxy for the reconstruction loss. The idea is that the generator cannot reconstruct an anomaly. We develop an alternative approach for anomaly detection, based on an Encoding Adversarial Network (AnoEAN), which maps the data to a latent space (decision space), where the detection of anomalies is done directly by calculating a score. Our encoder is learned by adversarial learning, using two loss functions, the first constraining the encoder to project regular data into a Gaussian distribution and the second, to project anomalous data outside this distribution. We conduct a series of experiments on several standard bases and show that our approach outperforms the state of the art when using 10% anomalies during the learning stage, and detects unseen anomalies.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/gherbi19a/gherbi19a.pdf",
        "supp": "",
        "pdf_size": 781361,
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3231653027693852751&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "title": "Asian Conference on Machine Learning: Preface",
        "site": "https://proceedings.mlr.press/v101/lee19a.html",
        "author": "Wee Sun Lee; Taiji Suzuki",
        "abstract": "Preface to ACML 2019.",
        "bibtex": "@InProceedings{pmlr-v101-lee19a,\n  title = \t {Asian Conference on Machine Learning: Preface},\n  author =       {Lee, Wee Sun and Suzuki, Taiji},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {i--xvi},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/lee19a/lee19a.pdf},\n  url = \t {https://proceedings.mlr.press/v101/lee19a.html},\n  abstract = \t {Preface to ACML 2019.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/lee19a/lee19a.pdf",
        "supp": "",
        "pdf_size": 132754,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:l6k7FqW5IuIJ:scholar.google.com/&scioq=Asian+Conference+on+Machine+Learning:+Preface&hl=en&as_sdt=0,5",
        "gs_version_total": 3,
        "aff": ";",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster"
    },
    {
        "title": "Canonical Soft Time Warping",
        "site": "https://proceedings.mlr.press/v101/kawano19a.html",
        "author": "Keisuke Kawano; Satoshi Koide; Takuro Kutsuna",
        "abstract": "Alignment of two given sequences (i.e., computing correspondence between frames considering local time shifting) is a fundamental operation for various applications such as computer vision and bioinformatics. To obtain an alignment between high-dimensional sequences, several methods have been proposed, including canonical time warping (CTW). However, the optimization problem for CTW, and its extensions, often fall into poor local minima when the initial solution is far from the global optima. In this paper, we propose \\emph{canonical soft time warping (CSTW)} in which an alignment is modeled as a probabilistic variable that follows the Gibbs distribution with temperature\u00a0$\\gamma$. We also propose the annealing CSTW\u00a0(ACTW), a variant of CSTW that gradually decreases $\\gamma$. ACTW is useful when underlying applications require hard alignments. Using synthetic and real-world data, we experimentally demonstrate that our proposed methods outperform previous methods, including CTW, in estimating alignments. In particular, our method does not suffer from poor local minima, as a consequence of the probabilistic treatment of alignments.",
        "bibtex": "@InProceedings{pmlr-v101-kawano19a,\n  title = \t {Canonical Soft Time Warping},\n  author =       {Kawano, Keisuke and Koide, Satoshi and Kutsuna, Takuro},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {551--566},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/kawano19a/kawano19a.pdf},\n  url = \t {https://proceedings.mlr.press/v101/kawano19a.html},\n  abstract = \t {Alignment of two given sequences (i.e., computing correspondence between frames considering local time shifting) is a fundamental operation for various applications such as computer vision and bioinformatics. To obtain an alignment between high-dimensional sequences, several methods have been proposed, including canonical time warping (CTW). However, the optimization problem for CTW, and its extensions, often fall into poor local minima when the initial solution is far from the global optima. In this paper, we propose \\emph{canonical soft time warping (CSTW)} in which an alignment is modeled as a probabilistic variable that follows the Gibbs distribution with temperature\u00a0$\\gamma$. We also propose the annealing CSTW\u00a0(ACTW), a variant of CSTW that gradually decreases $\\gamma$. ACTW is useful when underlying applications require hard alignments. Using synthetic and real-world data, we experimentally demonstrate that our proposed methods outperform previous methods, including CTW, in estimating alignments. In particular, our method does not suffer from poor local minima, as a consequence of the probabilistic treatment of alignments.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/kawano19a/kawano19a.pdf",
        "supp": "",
        "pdf_size": 651063,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=38364463591742011&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Toyota Central R&D Labs., 41-1 Yokomichi, Nagakute, Aichi, Japan; Toyota Central R&D Labs., 41-1 Yokomichi, Nagakute, Aichi, Japan; Toyota Central R&D Labs., 41-1 Yokomichi, Nagakute, Aichi, Japan",
        "aff_domain": "mosk.tytlabs.co.jp;mosk.tytlabs.co.jp;mosk.tytlabs.co.jp",
        "email": "mosk.tytlabs.co.jp;mosk.tytlabs.co.jp;mosk.tytlabs.co.jp",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Toyota Central R&D Labs",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.toyota-global.com",
        "aff_unique_abbr": "Toyota R&D",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "title": "Capsule Networks Need an Improved Routing Algorithm",
        "site": "https://proceedings.mlr.press/v101/paik19a.html",
        "author": "Inyoung Paik; Taeyeong Kwak; Injung Kim",
        "abstract": "In capsule networks, the routing algorithm connects capsules in consecutive layers, enabling the upper-level capsules to learn higher-level concepts by combining the concepts of the lower-level capsules. Capsule networks are known to have a few advantages over conventional neural networks, including robustness to 3D viewpoint changes and generalization capability. However, some studies have reported negative experimental results. Nevertheless, the reason for this phenomenon has not been analyzed yet. We empirically analyzed the effect of five different routing algorithms. The experimental results show that the routing algorithms do not behave as expected and often produce results that are worse than simple baseline algorithms that assign the connection strengths uniformly or randomly. We also show that, in most cases, the routing algorithms do not change the classification result but polarize the link strengths, and the polarization can be extreme when they continue to repeat without stopping. In order to realize the true potential of the capsule network, it is essential to develop an improved routing algorithm.",
        "bibtex": "@InProceedings{pmlr-v101-paik19a,\n  title = \t {Capsule Networks Need an Improved Routing Algorithm},\n  author =       {Paik, Inyoung and Kwak, Taeyeong and Kim, Injung},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {489--502},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/paik19a/paik19a.pdf},\n  url = \t {https://proceedings.mlr.press/v101/paik19a.html},\n  abstract = \t {In capsule networks, the routing algorithm connects capsules in consecutive layers, enabling the upper-level capsules to learn higher-level concepts by combining the concepts of the lower-level capsules. Capsule networks are known to have a few advantages over conventional neural networks, including robustness to 3D viewpoint changes and generalization capability. However, some studies have reported negative experimental results. Nevertheless, the reason for this phenomenon has not been analyzed yet. We empirically analyzed the effect of five different routing algorithms. The experimental results show that the routing algorithms do not behave as expected and often produce results that are worse than simple baseline algorithms that assign the connection strengths uniformly or randomly. We also show that, in most cases, the routing algorithms do not change the classification result but polarize the link strengths, and the polarization can be extreme when they continue to repeat without stopping. In order to realize the true potential of the capsule network, it is essential to develop an improved routing algorithm.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/paik19a/paik19a.pdf",
        "supp": "",
        "pdf_size": 631149,
        "gs_citation": 53,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1664620875875394696&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Deep Bio Inc., Seoul, Republic of Korea; Deep Bio Inc., Seoul, Republic of Korea; Handong Global University, Pohang, Republic of Korea",
        "aff_domain": "deepbio.com;deepbio.com;handong.edu",
        "email": "deepbio.com;deepbio.com;handong.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Deep Bio Inc.;Handong Global University",
        "aff_unique_dep": ";",
        "aff_unique_url": ";https://www.handong.ac.kr",
        "aff_unique_abbr": ";HGU",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Pohang",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "title": "Cascaded and Dual: Discrimination Oriented Network for Brain Tumor Classification",
        "site": "https://proceedings.mlr.press/v101/zhang19a.html",
        "author": "Wenxuan Zhang; Dong Zhang; Xinguang Xiang",
        "abstract": "Medical image classification is one of the fundamental research topics in the domain of computer-aided diagnosis. Although existing classification models of the natural image can produce promising results using deep convolutional neural networks in some cases, it is difficult to guarantee that these models can generate promising performance for medical images. To bridge such a gap, we propose a novel medical image classification method for brain tumors in this paper, termed as Discrimination Oriented Network (DONet). Inspired by the attention learning mechanism of the human brain, we first propose two categories of attention learning modules, i.e., the Cascaded Attention Learning (CAL) and the Dual Attention Learning (DAL), which can learn the discrimination information in both the spatial-wise and the channel-wise dimensions in a fine-grained manner. By the CAL and the DAL, the attention information of different dimensions is calculated in a series manner (for cascaded) and a parallel manner (for dual), respectively. To demonstrate the superiority of our proposed modules, we implement the CAL and the DAL on the Deep Residual Network (ResNet) for brain tumor classification. Compared with the ResNet, experimental results show that the DONet has a significant improvement in accuracy. Moreover, compared with state-of-the-art classification methods, the DONet can also achieve better performance.",
        "bibtex": "@InProceedings{pmlr-v101-zhang19a,\n  title = \t {Cascaded and Dual: Discrimination Oriented Network for Brain Tumor Classification},\n  author =       {Zhang, Wenxuan and Zhang, Dong and Xiang, Xinguang},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {363--378},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/zhang19a/zhang19a.pdf},\n  url = \t {https://proceedings.mlr.press/v101/zhang19a.html},\n  abstract = \t {Medical image classification is one of the fundamental research topics in the domain of computer-aided diagnosis. Although existing classification models of the natural image can produce promising results using deep convolutional neural networks in some cases, it is difficult to guarantee that these models can generate promising performance for medical images. To bridge such a gap, we propose a novel medical image classification method for brain tumors in this paper, termed as Discrimination Oriented Network (DONet). Inspired by the attention learning mechanism of the human brain, we first propose two categories of attention learning modules, i.e., the Cascaded Attention Learning (CAL) and the Dual Attention Learning (DAL), which can learn the discrimination information in both the spatial-wise and the channel-wise dimensions in a fine-grained manner. By the CAL and the DAL, the attention information of different dimensions is calculated in a series manner (for cascaded) and a parallel manner (for dual), respectively. To demonstrate the superiority of our proposed modules, we implement the CAL and the DAL on the Deep Residual Network (ResNet) for brain tumor classification. Compared with the ResNet, experimental results show that the DONet has a significant improvement in accuracy. Moreover, compared with state-of-the-art classification methods, the DONet can also achieve better performance.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/zhang19a/zhang19a.pdf",
        "supp": "",
        "pdf_size": 1050341,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5866853085802943263&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Nanjing University of Science and Technology; Nanjing University of Science and Technology; Nanjing University of Science and Technology",
        "aff_domain": "163.com;njust.edu.cn;njust.edu.cn",
        "email": "163.com;njust.edu.cn;njust.edu.cn",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Nanjing University of Science and Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "http://www.nust.edu.cn/",
        "aff_unique_abbr": "NUST",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "title": "Cell-aware Stacked LSTMs for Modeling Sentences",
        "site": "https://proceedings.mlr.press/v101/choi19a.html",
        "author": "Jihun Choi; Taeuk Kim; Sang-goo Lee",
        "abstract": "We propose a method of stacking multiple long short-term memory (LSTM) layers for modeling sentences. In contrast to the conventional stacked LSTMs where only hidden states are fed as input to the next layer, the suggested architecture accepts both hidden and memory cell states of the preceding layer and fuses information from the left and the lower context using the soft gating mechanism of LSTMs. Thus the architecture modulates the amount of information to be delivered not only in horizontal recurrence but also in vertical connections, from which useful features extracted from lower layers are effectively conveyed to upper layers. We dub this architecture Cell-aware Stacked LSTM (CAS-LSTM) and show from experiments that our models bring significant performance gain over the standard LSTMs on benchmark datasets for natural language inference, paraphrase detection, sentiment classification, and machine translation. We also conduct extensive qualitative analysis to understand the internal behavior of the suggested approach.",
        "bibtex": "@InProceedings{pmlr-v101-choi19a,\n  title = \t {Cell-aware Stacked LSTMs for Modeling Sentences},\n  author =       {Choi, Jihun and Kim, Taeuk and Lee, Sang-goo},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {1172--1187},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/choi19a/choi19a.pdf},\n  url = \t {https://proceedings.mlr.press/v101/choi19a.html},\n  abstract = \t {We propose a method of stacking multiple long short-term memory (LSTM) layers for modeling sentences. In contrast to the conventional stacked LSTMs where only hidden states are fed as input to the next layer, the suggested architecture accepts both hidden and memory cell states of the preceding layer and fuses information from the left and the lower context using the soft gating mechanism of LSTMs. Thus the architecture modulates the amount of information to be delivered not only in horizontal recurrence but also in vertical connections, from which useful features extracted from lower layers are effectively conveyed to upper layers. We dub this architecture Cell-aware Stacked LSTM (CAS-LSTM) and show from experiments that our models bring significant performance gain over the standard LSTMs on benchmark datasets for natural language inference, paraphrase detection, sentiment classification, and machine translation. We also conduct extensive qualitative analysis to understand the internal behavior of the suggested approach.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/choi19a/choi19a.pdf",
        "supp": "",
        "pdf_size": 388757,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17410412835794547623&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Department of Computer Science and Engineering, Seoul National University, Seoul, Korea; Department of Computer Science and Engineering, Seoul National University, Seoul, Korea; Department of Computer Science and Engineering, Seoul National University, Seoul, Korea",
        "aff_domain": "EUROPA.SNU.AC.KR;EUROPA.SNU.AC.KR;EUROPA.SNU.AC.KR",
        "email": "EUROPA.SNU.AC.KR;EUROPA.SNU.AC.KR;EUROPA.SNU.AC.KR",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Seoul National University",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.snu.ac.kr",
        "aff_unique_abbr": "SNU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "title": "Convolutional Neural Collaborative Filtering with Stacked Embeddings",
        "site": "https://proceedings.mlr.press/v101/han19a.html",
        "author": "Liu Han; Hailong Wu; Nan Hu; Binbin Qu",
        "abstract": "Recommender System plays an important role in keeping people engaged with online services, and collaborative filtering is a main technique for recommendation. With the immense influence of deep learning, there is a growing interest in applying it to collaborative filtering. Existing methods have applied different ways to learn the user-item interaction function, however, most of these methods have limitation in modeling user-item correlations because they ignore the original user-item information and the large size of embeddings. In this work we propose Stacked Embedding Convolutional Neural Collaborative Filtering (SECNCF), a novel neural collaborative filtering architecture. The idea is to create a pedrail by stacking embeddings which are composed of user embedding, item embedding and latent factors. We apply convolutional neural network (CNN) above the pedrail layer to capture the local features of dimension correlations. This method is good at extracting rich local dimension correlations of embeddings and is scalable for modeling user-item interactions. Extensive experiments on three public accessible datasets show that our method makes significant improvement over the state-of-the-art methods.",
        "bibtex": "@InProceedings{pmlr-v101-han19a,\n  title = \t {Convolutional Neural Collaborative Filtering with Stacked Embeddings },\n  author =       {Han, Liu and Wu, Hailong and Hu, Nan and Qu, Binbin},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {726--741},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/han19a/han19a.pdf},\n  url = \t {https://proceedings.mlr.press/v101/han19a.html},\n  abstract = \t {Recommender System plays an important role in keeping people engaged with online services, and collaborative filtering is a main technique for recommendation. With the immense influence of deep learning, there is a growing interest in applying it to collaborative filtering. Existing methods have applied different ways to learn the user-item interaction function, however, most of these methods have limitation in modeling user-item correlations because they ignore the original user-item information and the large size of embeddings. In this work we propose Stacked Embedding Convolutional Neural Collaborative Filtering (SECNCF), a novel neural collaborative filtering architecture. The idea is to create a pedrail by stacking embeddings which are composed of user embedding, item embedding and latent factors. We apply convolutional neural network (CNN) above the pedrail layer to capture the local features of dimension correlations. This method is good at extracting rich local dimension correlations of embeddings and is scalable for modeling user-item interactions. Extensive experiments on three public accessible datasets show that our method makes significant improvement over the state-of-the-art methods.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/han19a/han19a.pdf",
        "supp": "",
        "pdf_size": 457964,
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14993944464731581306&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Huazhong University of Science and Technology, Wuhan, China; Huazhong University of Science and Technology, Wuhan, China; Huazhong University of Science and Technology, Wuhan, China; Huazhong University of Science and Technology, Wuhan, China",
        "aff_domain": "hust.edu.cn;hust.edu.cn;hust.edu.cn;163.com",
        "email": "hust.edu.cn;hust.edu.cn;hust.edu.cn;163.com",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Huazhong University of Science and Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "http://www.hust.edu.cn",
        "aff_unique_abbr": "HUST",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Wuhan",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "title": "Deep Learning with a Rethinking Structure for Multi-label Classification",
        "site": "https://proceedings.mlr.press/v101/yang19b.html",
        "author": "Yao-Yuan Yang; Yi-An Lin; Hong-Min Chu; Hsuan-Tien Lin",
        "abstract": "Multi-label classification (MLC) is an important class of machine learning problems that come with a wide spectrum of applications, each demanding a possibly different evaluation criterion. When solving the MLC problems, we generally expect the learning algorithm to take the hidden correlation of the labels into account to improve the prediction performance. Extracting the hidden correlation is generally a challenging task. In this work, we propose a novel deep learning framework to better extract the hidden correlation with the help of the memory structure within recurrent neural networks. The memory stores the temporary guesses on the labels and effectively allows the framework to rethink about the goodness and correlation of the guesses before making the final prediction. Furthermore, the rethinking process makes it easy to adapt to different evaluation criteria to match real-world application needs. In particular, the framework can be trained in an end-to-end style with respect to any given MLC evaluation criteria. The end-to-end design can be seamlessly combined with other deep learning techniques to conquer challenging MLC problems like image tagging. Experimental results across many real-world data sets justify that the rethinking framework indeed improves MLC performance across different evaluation criteria and leads to superior performance over state-of-the-art MLC algorithms.",
        "bibtex": "@InProceedings{pmlr-v101-yang19b,\n  title = \t {Deep Learning with a Rethinking Structure for Multi-label Classification},\n  author =       {Yang, Yao-Yuan and Lin, Yi-An and Chu, Hong-Min and Lin, Hsuan-Tien},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {125--140},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/yang19b/yang19b.pdf},\n  url = \t {https://proceedings.mlr.press/v101/yang19b.html},\n  abstract = \t {Multi-label classification (MLC) is an important class of machine learning problems that come with a wide spectrum of applications, each demanding a possibly different evaluation criterion. When solving the MLC problems, we generally expect the learning algorithm to take the hidden correlation of the labels into account to improve the prediction performance. Extracting the hidden correlation is generally a challenging task. In this work, we propose a novel deep learning framework to better extract the hidden correlation with the help of the memory structure within recurrent neural networks. The memory stores the temporary guesses on the labels and effectively allows the framework to rethink about the goodness and correlation of the guesses before making the final prediction. Furthermore, the rethinking process makes it easy to adapt to different evaluation criteria to match real-world application needs. In particular, the framework can be trained in an end-to-end style with respect to any given MLC evaluation criteria. The end-to-end design can be seamlessly combined with other deep learning techniques to conquer challenging MLC problems like image tagging. Experimental results across many real-world data sets justify that the rethinking framework indeed improves MLC performance across different evaluation criteria and leads to superior performance over state-of-the-art MLC algorithms.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/yang19b/yang19b.pdf",
        "supp": "",
        "pdf_size": 608674,
        "gs_citation": 42,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7577675817034321822&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 8,
        "aff": "Department of Computer Science and Information Engineering, National Taiwan University; Department of Computer Science and Information Engineering, National Taiwan University; Department of Computer Science and Information Engineering, National Taiwan University; Department of Computer Science and Information Engineering, National Taiwan University",
        "aff_domain": "ntu.edu.tw;gmail.com;csie.ntu.edu.tw;csie.ntu.edu.tw",
        "email": "ntu.edu.tw;gmail.com;csie.ntu.edu.tw;csie.ntu.edu.tw",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "National Taiwan University",
        "aff_unique_dep": "Department of Computer Science and Information Engineering",
        "aff_unique_url": "https://www.ntu.edu.tw",
        "aff_unique_abbr": "NTU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Taiwan",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "title": "Differentially Private Community Detection in Attributed Social Networks",
        "site": "https://proceedings.mlr.press/v101/ji19a.html",
        "author": "Tianxi Ji; Changqing Luo; Yifan Guo; Jinlong Ji; Weixian Liao; Pan Li",
        "abstract": "Community detection is an effective approach to unveil social dynamics among individuals in social networks. In the literature, quite a few algorithms have been proposed to conduct community detection by exploiting the topology of social networks and the attributes of social actors. In practice, community detection is usually conducted by third parties like advertisement companies, hospitals, with access to social networks for different purposes, which can easily lead to privacy breaches. In this paper, we investigate community detection in social networks aiming to protect the privacy of both the network topologies and the users\u2019 attributes. In particular, we propose a new scheme called differentially private community detection (DPCD). DPCD detects communities in social networks via a probabilistic generative model, which can be decomposed into subproblems solved by individual users. The private social relationships and attributes of each user are protected by objective perturbation with differential privacy guarantees. Through both theoretical analysis and experimental validation using synthetic and real world social networks, we demonstrate that the proposed DPCD scheme detects social communities under modest privacy budget.",
        "bibtex": "@InProceedings{pmlr-v101-ji19a,\n  title = \t {Differentially Private Community Detection in Attributed Social Networks},\n  author =       {Ji, Tianxi and Luo, Changqing and Guo, Yifan and Ji, Jinlong and Liao, Weixian and Li, Pan},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {16--31},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/ji19a/ji19a.pdf},\n  url = \t {https://proceedings.mlr.press/v101/ji19a.html},\n  abstract = \t {Community detection is an effective approach to unveil social dynamics among individuals in social networks. In the literature, quite a few algorithms have been proposed to conduct community detection by exploiting the topology of social networks and the attributes of social actors. In practice, community detection is usually conducted by third parties like advertisement companies, hospitals, with access to social networks for different purposes, which can easily lead to privacy breaches. In this paper, we investigate community detection in social networks aiming to protect the privacy of both the network topologies and the users\u2019 attributes. In particular, we propose a new scheme called differentially private community detection (DPCD). DPCD detects communities in social networks via a probabilistic generative model, which can be decomposed into subproblems solved by individual users. The private social relationships and attributes of each user are protected by objective perturbation with differential privacy guarantees. Through both theoretical analysis and experimental validation using synthetic and real world social networks, we demonstrate that the proposed DPCD scheme detects social communities under modest privacy budget.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/ji19a/ji19a.pdf",
        "supp": "",
        "pdf_size": 382690,
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16459221958727600980&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Department of EECS, Case Western Reserve University; College of Engineering, Virginia Commonwealth University; Department of EECS, Case Western Reserve University; Department of EECS, Case Western Reserve University; Department of Computer and Information Sciences, Towson University; Department of EECS, Case Western Reserve University",
        "aff_domain": "case.edu;vcu.edu;case.edu;case.edu;towson.edu;case.edu",
        "email": "case.edu;vcu.edu;case.edu;case.edu;towson.edu;case.edu",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;0;2;0",
        "aff_unique_norm": "Case Western Reserve University;Virginia Commonwealth University;Towson University",
        "aff_unique_dep": "Department of EECS;College of Engineering;Department of Computer and Information Sciences",
        "aff_unique_url": "https://www.case.edu;https://www.vcu.edu;https://www.towson.edu",
        "aff_unique_abbr": "CWRU;VCU;Towson",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Effective Sentence Scoring Method Using BERT for Speech Recognition",
        "site": "https://proceedings.mlr.press/v101/shin19a.html",
        "author": "Joonbo Shin; Yoonhyung Lee; Kyomin Jung",
        "abstract": "In automatic speech recognition, language models (LMs) have been used in many ways to improve performance. Some of the studies have tried to use bidirectional LMs (biLMs) for rescoring the $n$-best hypothesis list decoded from the acoustic model. Despite their theoretical advantages over conventional unidirectional LMs (uniLMs), previous biLMs have not given notable improvements compared to the uniLMs in the experiments. This is due to the architectural limitation that the rightward and leftward representations are not fused in the biLMs. Recently, BERT addressed the same issue by proposing the masked language modeling and achieved state-of-the-art performances in many downstream tasks by fine-tuning the pre-trained BERT. In this paper, we propose an effective sentence scoring method by adjusting the BERT to the $n$-best list rescoring task, which has no fine-tuning step. The core idea of how we modify the BERT for the rescoring task is bridging the gap between training and testing environments by considering the only masked language modeling within a single sentence. Experimental results on the LibriSpeech corpus show that the proposed scoring method using our biLM outperforms uniLMs for the $n$-best list rescoring, consistently and significantly in all experimental conditions. Additionally, an analysis about where word errors occur in a sentence demonstrates that our biLM is more robust than the uniLM especially when a recognized sentence is short or a misrecognized word is at the beginning of the sentence. Consequently, we empirically prove that the left and right representations should be fused in biLMs for scoring a sentence.",
        "bibtex": "@InProceedings{pmlr-v101-shin19a,\n  title = \t {Effective Sentence Scoring Method Using BERT for Speech Recognition},\n  author =       {Shin, Joonbo and Lee, Yoonhyung and Jung, Kyomin},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {1081--1093},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/shin19a/shin19a.pdf},\n  url = \t {https://proceedings.mlr.press/v101/shin19a.html},\n  abstract = \t {In automatic speech recognition, language models (LMs) have been used in many ways to improve performance. Some of the studies have tried to use bidirectional LMs (biLMs) for rescoring the $n$-best hypothesis list decoded from the acoustic model. Despite their theoretical advantages over conventional unidirectional LMs (uniLMs), previous biLMs have not given notable improvements compared to the uniLMs in the experiments. This is due to the architectural limitation that the rightward and leftward representations are not fused in the biLMs. Recently, BERT addressed the same issue by proposing the masked language modeling and achieved state-of-the-art performances in many downstream tasks by fine-tuning the pre-trained BERT. In this paper, we propose an effective sentence scoring method by adjusting the BERT to the $n$-best list rescoring task, which has no fine-tuning step. The core idea of how we modify the BERT for the rescoring task is bridging the gap between training and testing environments by considering the only masked language modeling within a single sentence. Experimental results on the LibriSpeech corpus show that the proposed scoring method using our biLM outperforms uniLMs for the $n$-best list rescoring, consistently and significantly in all experimental conditions. Additionally, an analysis about where word errors occur in a sentence demonstrates that our biLM is more robust than the uniLM especially when a recognized sentence is short or a misrecognized word is at the beginning of the sentence. Consequently, we empirically prove that the left and right representations should be fused in biLMs for scoring a sentence.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/shin19a/shin19a.pdf",
        "supp": "",
        "pdf_size": 306247,
        "gs_citation": 131,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12895299241513349917&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Seoul National University; Seoul National University; Seoul National University",
        "aff_domain": "snu.ac.kr;snu.ac.kr;snu.ac.kr",
        "email": "snu.ac.kr;snu.ac.kr;snu.ac.kr",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Seoul National University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.snu.ac.kr",
        "aff_unique_abbr": "SNU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "title": "Efficient Diversified Mini-Batch Selection using Variable High-layer Features",
        "site": "https://proceedings.mlr.press/v101/huang19b.html",
        "author": "Wanming Huang; Richard Yi Da Xu; Ian Oppermann",
        "abstract": "Stochastic Gradient Descent (SGD) has been widely adopted in training Deep Neural networks of various structures. Instead of using a full dataset, a so-called {\\itshape mini-batch} is selected during each gradient descent iteration. This aims to speed up the learning when a large number of training data is present. Without the knowledge of its true underlying distribution, one often samples the data indices uniformly. Recently, researchers applied a diversified mini-batch selection scheme through the use of Determinantal Point Process (DPP), in order to avoid having highly correlated samples in one batch ({{Zhang et\u00a0al.}} ({2017})). Despite its success, the attempts were restrictive in the sense that they used fixed features to construct the Gram-matrix for DPP; using the raw or fixed higher-layer features limited the amount of potential improvement over the convergence rate. In this paper, we instead proposed to use variable higher-layer features which are updated at each iteration when the parameter changes. To avoid the high computation cost, several contributions have been made to speed up the computation of DPP sampling, including: (1) using hierarchical sampling to break down a single DPP sampling with large Gram-matrix into many DPP samplings of much smaller Gram-matrix and (2) using Markov k-DPP to encourage diversity across iterations. Empirical results show a much more diversified mini batch in each iteration in addition to a much improved convergence compared with the previous approach.",
        "bibtex": "@InProceedings{pmlr-v101-huang19b,\n  title = \t {Efficient Diversified Mini-Batch Selection using Variable High-layer Features},\n  author =       {Huang, Wanming and Xu, Richard Yi Da and Oppermann, Ian},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {300--315},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/huang19b/huang19b.pdf},\n  url = \t {https://proceedings.mlr.press/v101/huang19b.html},\n  abstract = \t {Stochastic Gradient Descent (SGD) has been widely adopted in training Deep Neural networks of various structures. Instead of using a full dataset, a so-called {\\itshape mini-batch} is selected during each gradient descent iteration. This aims to speed up the learning when a large number of training data is present. Without the knowledge of its true underlying distribution, one often samples the data indices uniformly. Recently, researchers applied a diversified mini-batch selection scheme through the use of Determinantal Point Process (DPP), in order to avoid having highly correlated samples in one batch ({{Zhang et\u00a0al.}} ({2017})). Despite its success, the attempts were restrictive in the sense that they used fixed features to construct the Gram-matrix for DPP; using the raw or fixed higher-layer features limited the amount of potential improvement over the convergence rate. In this paper, we instead proposed to use variable higher-layer features which are updated at each iteration when the parameter changes. To avoid the high computation cost, several contributions have been made to speed up the computation of DPP sampling, including: (1) using hierarchical sampling to break down a single DPP sampling with large Gram-matrix into many DPP samplings of much smaller Gram-matrix and (2) using Markov k-DPP to encourage diversity across iterations. Empirical results show a much more diversified mini batch in each iteration in addition to a much improved convergence compared with the previous approach.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/huang19b/huang19b.pdf",
        "supp": "",
        "pdf_size": 787884,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1614368598587906428&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Faculty of Engineering and IT, University of Technology Sydney; Faculty of Engineering and IT, University of Technology Sydney; NSW Data Analytics Centre",
        "aff_domain": "student.uts.edu.au;uts.edu.au;outlook.com",
        "email": "student.uts.edu.au;uts.edu.au;outlook.com",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "University of Technology Sydney;NSW Data Analytics Centre",
        "aff_unique_dep": "Faculty of Engineering and IT;",
        "aff_unique_url": "https://www.uts.edu.au;https://data.nsw.gov.au/",
        "aff_unique_abbr": "UTS;",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Sydney;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "title": "Efficient Learning of Restricted Boltzmann Machines Using Covariance Estimates",
        "site": "https://proceedings.mlr.press/v101/upadhya19a.html",
        "author": "Vidyadhar Upadhya; P S Sastry",
        "abstract": "Learning RBMs using standard algorithms such as CD(k) involves gradient descent on the negative log-likelihood. One of the terms in the gradient, which involves expectation w.r.t. the model distribution, is intractable and is obtained through an MCMC estimate. In this work we show that the Hessian of the log-likelihood can be written in terms of covariances of hidden and visible units and hence, all elements of the Hessian can also be estimated using the same MCMC samples with small extra computational costs. Since inverting the Hessian may be computationally expensive, we propose an algorithm that uses inverse of the diagonal approximation of the Hessian, instead. This essentially results in parameter-specific adaptive learning rates for the gradient descent process and improves the efficiency of learning RBMs compared to the standard methods. Specifically we show that using the inverse of diagonal approximation of Hessian in the stochastic DC (difference of convex functions) program approach results in very efficient learning of RBMs.",
        "bibtex": "@InProceedings{pmlr-v101-upadhya19a,\n  title = \t {Efficient Learning of Restricted Boltzmann Machines Using Covariance Estimates},\n  author =       {Upadhya, Vidyadhar and Sastry, P S},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {836--851},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/upadhya19a/upadhya19a.pdf},\n  url = \t {https://proceedings.mlr.press/v101/upadhya19a.html},\n  abstract = \t {Learning RBMs using standard algorithms such as CD(k) involves gradient descent on the negative log-likelihood. One of the terms in the gradient, which involves expectation w.r.t. the model distribution, is intractable and is obtained through an MCMC estimate. In this work we show that the Hessian of the log-likelihood can be written in terms of covariances of hidden and visible units and hence, all elements of the Hessian can also be estimated using the same MCMC samples with small extra computational costs. Since inverting the Hessian may be computationally expensive, we propose an algorithm that uses inverse of the diagonal approximation of the Hessian, instead. This essentially results in parameter-specific adaptive learning rates for the gradient descent process and improves the efficiency of learning RBMs compared to the standard methods. Specifically we show that using the inverse of diagonal approximation of Hessian in the stochastic DC (difference of convex functions) program approach results in very efficient learning of RBMs.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/upadhya19a/upadhya19a.pdf",
        "supp": "",
        "pdf_size": 687083,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6663028572531792380&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Indian Institute of Science Bangalore, India; Indian Institute of Science Bangalore, India",
        "aff_domain": "iisc.ac.in;iisc.ac.in",
        "email": "iisc.ac.in;iisc.ac.in",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Indian Institute of Science",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.iisc.ac.in",
        "aff_unique_abbr": "IISc",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Bangalore",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "India"
    },
    {
        "title": "Exemplar Based Mixture Models with Censored Data",
        "site": "https://proceedings.mlr.press/v101/kohjima19a.html",
        "author": "Masahiro Kohjima; Tatsushi Matsubayashi; Hiroyuki Toda",
        "abstract": "In this paper, we propose a method that can handle censored data, data collected under the condition that the exact value is recorded only when the value is within a certain range, abbreviated information is recorded otherwise. It is known that existing methods that use mixture models with censored data suffer from (i)\u00a0the existence of local optimum solutions and (ii)\u00a0the need to compute the statistics of truncated distributions for parameter estimation. Our proposal, exemplar based censored mixture model\u00a0(EBCM), overcomes these two difficulties at once by adopting the exemplar based model approach. The effectiveness of EBCM is confirmed by experiments on synthetic and real world dat sets.",
        "bibtex": "@InProceedings{pmlr-v101-kohjima19a,\n  title = \t {Exemplar Based Mixture Models with Censored Data},\n  author =       {Kohjima, Masahiro and Matsubayashi, Tatsushi and Toda, Hiroyuki},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {535--550},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/kohjima19a/kohjima19a.pdf},\n  url = \t {https://proceedings.mlr.press/v101/kohjima19a.html},\n  abstract = \t {In this paper, we propose a method that can handle censored data, data collected under the condition that the exact value is recorded only when the value is within a certain range, abbreviated information is recorded otherwise. It is known that existing methods that use mixture models with censored data suffer from (i)\u00a0the existence of local optimum solutions and (ii)\u00a0the need to compute the statistics of truncated distributions for parameter estimation. Our proposal, exemplar based censored mixture model\u00a0(EBCM), overcomes these two difficulties at once by adopting the exemplar based model approach. The effectiveness of EBCM is confirmed by experiments on synthetic and real world dat sets.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/kohjima19a/kohjima19a.pdf",
        "supp": "",
        "pdf_size": 1691234,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9543454836264272123&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "NTT Service Evolution Laboratories, NTT Corporation, Yokosuka, Japan; NTT Service Evolution Laboratories, NTT Corporation, Yokosuka, Japan; NTT Service Evolution Laboratories, NTT Corporation, Yokosuka, Japan",
        "aff_domain": "hco.ntt.co.jp;hco.ntt.co.jp;hco.ntt.co.jp",
        "email": "hco.ntt.co.jp;hco.ntt.co.jp;hco.ntt.co.jp",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "NTT Corporation",
        "aff_unique_dep": "Service Evolution Laboratories",
        "aff_unique_url": "https://www.ntt.co.jp",
        "aff_unique_abbr": "NTT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Yokosuka",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "title": "FEARS: a Feature and Representation Selection approach for Time Series Classification",
        "site": "https://proceedings.mlr.press/v101/bondu19a.html",
        "author": "Alexis Bondu; Dominique Gay; Vincent Lemaire; Marc Boull\u00e9; Eole Cervenka",
        "abstract": "This paper presents a method which extracts informative features while selecting simultaneously adequate representations for Time Series Classification. This method simultaneously (i) selects alternative representations, such as derivatives, cumulative integrals, power spectrum \u2026 (ii) and extracts informative features (via automatic variable construction) from the selected set of representations. The suggested approach is decomposed in three steps: (i) the original time series are transformed into several representations which are stored as relational data; (ii) then, a {regularized} propositionalisation method is applied in order to generate informative aggregate features; (iii) finally, a selective Naive Bayes classifier is learned from the outcoming feature-value data table. The previous steps are repeated by a forward backward selection algorithm in order to select the most informative subset of representations. The suggested approach proves to be highly competitive when compared with state-of-the-art methods while extracting interpretable features. Furthermore, the suggested approach is almost parameter free and only requires few hardware resources.",
        "bibtex": "@InProceedings{pmlr-v101-bondu19a,\n  title = \t {FEARS: a Feature and Representation Selection approach for Time Series Classification},\n  author =       {Bondu, Alexis and Gay, Dominique and Lemaire, Vincent and Boull\\'e, Marc and Cervenka, Eole},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {379--394},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/bondu19a/bondu19a.pdf},\n  url = \t {https://proceedings.mlr.press/v101/bondu19a.html},\n  abstract = \t {This paper presents a method which extracts informative features while selecting simultaneously adequate representations for Time Series Classification. This method simultaneously (i) selects alternative representations, such as derivatives, cumulative integrals, power spectrum \u2026 (ii) and extracts informative features (via automatic variable construction) from the selected set of representations. The suggested approach is decomposed in three steps: (i) the original time series are transformed into several representations which are stored as relational data; (ii) then, a {regularized} propositionalisation method is applied in order to generate informative aggregate features; (iii) finally, a selective Naive Bayes classifier is learned from the outcoming feature-value data table. The previous steps are repeated by a forward backward selection algorithm in order to select the most informative subset of representations. The suggested approach proves to be highly competitive when compared with state-of-the-art methods while extracting interpretable features. Furthermore, the suggested approach is almost parameter free and only requires few hardware resources.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/bondu19a/bondu19a.pdf",
        "supp": "",
        "pdf_size": 1125620,
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10929207088285917908&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": ";;;;",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster"
    },
    {
        "title": "Focused Anchors Loss: cost-sensitive learning of discriminative features for imbalanced classification",
        "site": "https://proceedings.mlr.press/v101/baloch19a.html",
        "author": "Bahram K. Baloch; Sateesh Kumar; Sanjay Haresh; Abeerah Rehman; Tahir Syed",
        "abstract": "Deep Neural Networks (DNNs) usually suffer performance penalties when there is a skewed label distribution. This phenomenon, class-imbalance, is most often mitigated peripheral to the classification algorithm itself, usually by modifying the amount of examples per class, for oversampling at the expense of computational efficiency, and for undersampling at the expense of statistical efficiency. In our solution, we combine discriminative feature learning with cost-sensitive learning to tackle the class imbalance problem by using a two step loss function, which we call the Focused Anchors loss (FAL). We evaluate FAL and its variant, Focused Anchor Mean Loss (FAML), on $6$ different datasets in comparison of traditional cross entropy loss and we observe a significant gain in balanced accuracy for all datasets. We also perform better than time-costly re-sampling and ensemble methods like SMOTE and Near Miss in $4$ out of $6$ datasets across F1-score, AUC-ROC and balanced accuracy. We also extend our evaluation to image domain and use long-tailed CIFAR$10$ to evaluate our loss function where we consistently report significant improvement in accuracy. We then go on to test our loss function under extreme imbalance on a propriety dataset and achieve a gain of $0.1$ AUC-ROC over the baseline.",
        "bibtex": "@InProceedings{pmlr-v101-baloch19a,\n  title = \t {Focused Anchors Loss: cost-sensitive learning of discriminative features for imbalanced classification},\n  author =       {Baloch, Bahram K. and Kumar, Sateesh and Haresh, Sanjay and Rehman, Abeerah and Syed, Tahir},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {822--835},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/baloch19a/baloch19a.pdf},\n  url = \t {https://proceedings.mlr.press/v101/baloch19a.html},\n  abstract = \t {Deep Neural Networks (DNNs) usually suffer performance penalties when there is a skewed label distribution. This phenomenon, class-imbalance, is most often mitigated peripheral to the classification algorithm itself, usually by modifying the amount of examples per class, for oversampling at the expense of computational efficiency, and for undersampling at the expense of statistical efficiency. In our solution, we combine discriminative feature learning with cost-sensitive learning to tackle the class imbalance problem by using a two step loss function, which we call the Focused Anchors loss (FAL). We evaluate FAL and its variant, Focused Anchor Mean Loss (FAML), on $6$ different datasets in comparison of traditional cross entropy loss and we observe a significant gain in balanced accuracy for all datasets. We also perform better than time-costly re-sampling and ensemble methods like SMOTE and Near Miss in $4$ out of $6$ datasets across F1-score, AUC-ROC and balanced accuracy. We also extend our evaluation to image domain and use long-tailed CIFAR$10$ to evaluate our loss function where we consistently report significant improvement in accuracy. We then go on to test our loss function under extreme imbalance on a propriety dataset and achieve a gain of $0.1$ AUC-ROC over the baseline.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/baloch19a/baloch19a.pdf",
        "supp": "",
        "pdf_size": 358888,
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3742755494450683725&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "aff": "National University of Computer and Emerging Sciences; National University of Computer and Emerging Sciences; National University of Computer and Emerging Sciences; National University of Computer and Emerging Sciences; National University of Computer and Emerging Sciences",
        "aff_domain": "nu.edu.pk;nu.edu.pk;nu.edu.pk;nu.edu.pk;nu.edu.pk",
        "email": "nu.edu.pk;nu.edu.pk;nu.edu.pk;nu.edu.pk;nu.edu.pk",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "National University of Computer and Emerging Sciences",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.nu.edu.pk",
        "aff_unique_abbr": "NUCES",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Pakistan"
    },
    {
        "title": "Forward and Backward Knowledge Transfer for Sentiment Classification",
        "site": "https://proceedings.mlr.press/v101/wang19f.html",
        "author": "Hao Wang; Bing Liu; Shuai Wang; Nianzu Ma; Yan Yang",
        "abstract": "This paper studies the problem of learning a sequence of sentiment classification tasks. The learned knowledge from each task is retained and later used to help future or subsequent task learning. This learning paradigm is called \\textit{lifelong learning}. However, existing lifelong learning methods either only transfer knowledge forward to help future learning and do not go back to improve the model of a previous task or require the training data of the previous task to retrain its model to exploit backward/reverse knowledge transfer. This paper studies reverse knowledge transfer of lifelong learning. It aims to improve the model of a previous task by leveraging future knowledge without retraining using its training data, which is challenging now. In this work, this is done by exploiting a key characteristic of the generative model of na\u00efve Bayes. That is, it is possible to improve the na\u00efve Bayesian classifier for a task by improving its model parameters directly using the retained knowledge from other tasks. Experimental results show that the proposed method markedly outperforms existing lifelong learning baselines.",
        "bibtex": "@InProceedings{pmlr-v101-wang19f,\n  title = \t {Forward and Backward Knowledge Transfer for Sentiment Classification},\n  author =       {Wang, Hao and Liu, Bing and Wang, Shuai and Ma, Nianzu and Yang, Yan},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {457--472},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/wang19f/wang19f.pdf},\n  url = \t {https://proceedings.mlr.press/v101/wang19f.html},\n  abstract = \t {This paper studies the problem of learning a sequence of sentiment classification tasks. The learned knowledge from each task is retained and later used to help future or subsequent task learning. This learning paradigm is called \\textit{lifelong learning}. However, existing lifelong learning methods either only transfer knowledge forward to help future learning and do not go back to improve the model of a previous task or require the training data of the previous task to retrain its model to exploit backward/reverse knowledge transfer. This paper studies reverse knowledge transfer of lifelong learning. It aims to improve the model of a previous task by leveraging future knowledge without retraining using its training data, which is challenging now. In this work, this is done by exploiting a key characteristic of the generative model of na\u00efve Bayes. That is, it is possible to improve the na\u00efve Bayesian classifier for a task by improving its model parameters directly using the retained knowledge from other tasks. Experimental results show that the proposed method markedly outperforms existing lifelong learning baselines.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/wang19f/wang19f.pdf",
        "supp": "",
        "pdf_size": 485832,
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6111961817933416146&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";;;;",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster"
    },
    {
        "title": "Forward-Backward Generative Adversarial Networks for Anomaly Detection",
        "site": "https://proceedings.mlr.press/v101/kim19b.html",
        "author": "Youngnam Kim; Seungjin Choi",
        "abstract": "Generative adversarial network (GAN) has established itself as a promising model for density estimation, with its wide applications to various problems. Of particular interest in this paper is the problem of {\\em anomaly detection} which involves identifying events that do not conform to expected patterns in data. Recent application of GANs to the task of anomaly detection, resort to their ability for learning probability distributions of normal examples, so that abnormal examples or outliers are detected when they reside in very low-probability regimes. Existing GAN methods often suffer from the bad {\\em cycle-consistency} problem, which yields the large reconstruction error so that the anomaly detection performance is degraded. In order to alleviate this, we present a model that consists of a forward GAN and backward GAN, each of which has an individual discriminator, that are coupled by enforcing feature matching in two discriminators. We show that our forward-backward GANs (FBGANs) better captures the data distribution so that the anomaly detection performance is improved over existing GAN-based methods. Experiments on MNIST an KDD99 datasets demonstrate that our method, FBGANs, outperforms existing state-of-the-art anomaly detection methods, in terms of the area under precision recall curve (AUPR) and $F_{1}$-score.",
        "bibtex": "@InProceedings{pmlr-v101-kim19b,\n  title = \t {Forward-Backward Generative Adversarial Networks for Anomaly Detection},\n  author =       {Kim, Youngnam and Choi, Seungjin},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {1142--1155},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/kim19b/kim19b.pdf},\n  url = \t {https://proceedings.mlr.press/v101/kim19b.html},\n  abstract = \t {Generative adversarial network (GAN) has established itself as a promising model for density estimation, with its wide applications to various problems. Of particular interest in this paper is the problem of {\\em anomaly detection} which involves identifying events that do not conform to expected patterns in data. Recent application of GANs to the task of anomaly detection, resort to their ability for learning probability distributions of normal examples, so that abnormal examples or outliers are detected when they reside in very low-probability regimes. Existing GAN methods often suffer from the bad {\\em cycle-consistency} problem, which yields the large reconstruction error so that the anomaly detection performance is degraded. In order to alleviate this, we present a model that consists of a forward GAN and backward GAN, each of which has an individual discriminator, that are coupled by enforcing feature matching in two discriminators. We show that our forward-backward GANs (FBGANs) better captures the data distribution so that the anomaly detection performance is improved over existing GAN-based methods. Experiments on MNIST an KDD99 datasets demonstrate that our method, FBGANs, outperforms existing state-of-the-art anomaly detection methods, in terms of the area under precision recall curve (AUPR) and $F_{1}$-score.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/kim19b/kim19b.pdf",
        "supp": "",
        "pdf_size": 1174573,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5051040213252924602&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Medi Whale Incorporated, Seoul, Republic of Korea; BARO, Korea",
        "aff_domain": "medi-whale.com;gmail.com",
        "email": "medi-whale.com;gmail.com",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Medi Whale Incorporated;BARO",
        "aff_unique_dep": ";",
        "aff_unique_url": ";",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "title": "From Implicit to Explicit Feedback: A deep neural network for modeling the sequential behavior of online users",
        "site": "https://proceedings.mlr.press/v101/phan-tuan19a.html",
        "author": "Anh Phan Tuan; Nhat Nguyen Trong; Duong Bui Trong; Linh Ngo Van; Khoat Than",
        "abstract": "We demonstrate the advantages of taking into account multiple types of behavior in recommendation systems. Intuitively, each user has to do some \\textbf{implicit} actions (e.g., click) before making an \\textbf{explicit} decision (e.g., purchase). Previous works showed that implicit and explicit feedback has distinct properties to make a useful recommendation. However, these works exploit implicit and explicit behavior separately and therefore ignore the semantic of interaction between users and items. In this paper, we propose a novel model namely \\textit{Implicit to Explicit (ITE)} which directly models the order of user actions. Furthermore, we present an extended version of ITE, namely \\textit{Implicit to Explicit with Side information (ITE-Si)}, which incorporates side information to enrich the representations of users and items. The experimental results show that both ITE and ITE-Si outperform existing recommendation systems and also demonstrate the effectiveness of side information in two large scale datasets.",
        "bibtex": "@InProceedings{pmlr-v101-phan-tuan19a,\n  title = \t {From Implicit to Explicit Feedback: A deep neural network for modeling the sequential behavior of online users},\n  author =       {Phan Tuan, Anh and Nguyen Trong, Nhat and Bui Trong, Duong and Ngo Van, Linh and Than, Khoat},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {1188--1203},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/phan-tuan19a/phan-tuan19a.pdf},\n  url = \t {https://proceedings.mlr.press/v101/phan-tuan19a.html},\n  abstract = \t {We demonstrate the advantages of taking into account multiple types of behavior in recommendation systems. Intuitively, each user has to do some \\textbf{implicit} actions (e.g., click) before making an \\textbf{explicit} decision (e.g., purchase). Previous works showed that implicit and explicit feedback has distinct properties to make a useful recommendation. However, these works exploit implicit and explicit behavior separately and therefore ignore the semantic of interaction between users and items. In this paper, we propose a novel model namely \\textit{Implicit to Explicit (ITE)} which directly models the order of user actions. Furthermore, we present an extended version of ITE, namely \\textit{Implicit to Explicit with Side information (ITE-Si)}, which incorporates side information to enrich the representations of users and items. The experimental results show that both ITE and ITE-Si outperform existing recommendation systems and also demonstrate the effectiveness of side information in two large scale datasets.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/phan-tuan19a/phan-tuan19a.pdf",
        "supp": "",
        "pdf_size": 551484,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13115456792114433095&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": ";;;;",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster"
    },
    {
        "title": "Functional Isolation Forest",
        "site": "https://proceedings.mlr.press/v101/staerman19a.html",
        "author": "Guillaume Staerman; Pavlo Mozharovskyi; Stephan Cl\u00e9men\u00e7on; Florence d\u2019Alch\u00e9-Buc",
        "abstract": "For the purpose of monitoring the behavior of complex infrastructures (\\textit{e.g.} aircrafts, transport or energy networks), high-rate sensors are deployed to capture multivariate data, generally unlabeled, in quasi continuous-time to detect quickly the occurrence of anomalies that may jeopardize the smooth operation of the system of interest. The statistical analysis of such massive data of functional nature raises many challenging methodological questions. The primary goal of this paper is to extend the popular {\\scshape Isolation Forest} (IF) approach to Anomaly Detection, originally dedicated to finite dimensional observations, to functional data. The major difficulty lies in the wide variety of topological structures that may equip a space of functions and the great variety of patterns that may characterize abnormal curves. We address the issue of (randomly) splitting the functional space in a flexible manner in order to isolate progressively any trajectory from the others, a key ingredient to the efficiency of the algorithm. Beyond a detailed description of the algorithm, computational complexity and stability issues are investigated at length. From the scoring function measuring the degree of abnormality of an observation provided by the proposed variant of the IF algorithm, a \\textit{Functional Statistical Depth} function is defined and discussed, as well as a multivariate functional extension. Numerical experiments provide strong empirical evidence of the accuracy of the extension proposed.",
        "bibtex": "@InProceedings{pmlr-v101-staerman19a,\n  title = \t {Functional Isolation Forest},\n  author =       {Staerman, Guillaume and Mozharovskyi, Pavlo and Cl\\'emen\\c{c}on, Stephan and d'Alch\\'e-Buc, Florence},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {332--347},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/staerman19a/staerman19a.pdf},\n  url = \t {https://proceedings.mlr.press/v101/staerman19a.html},\n  abstract = \t {For the purpose of monitoring the behavior of complex infrastructures (\\textit{e.g.} aircrafts, transport or energy networks), high-rate sensors are deployed to capture multivariate data, generally unlabeled, in quasi continuous-time to detect quickly the occurrence of anomalies that may jeopardize the smooth operation of the system of interest. The statistical analysis of such massive data of functional nature raises many challenging methodological questions. The primary goal of this paper is to extend the popular {\\scshape Isolation Forest} (IF) approach to Anomaly Detection, originally dedicated to finite dimensional observations, to functional data. The major difficulty lies in the wide variety of topological structures that may equip a space of functions and the great variety of patterns that may characterize abnormal curves. We address the issue of (randomly) splitting the functional space in a flexible manner in order to isolate progressively any trajectory from the others, a key ingredient to the efficiency of the algorithm. Beyond a detailed description of the algorithm, computational complexity and stability issues are investigated at length. From the scoring function measuring the degree of abnormality of an observation provided by the proposed variant of the IF algorithm, a \\textit{Functional Statistical Depth} function is defined and discussed, as well as a multivariate functional extension. Numerical experiments provide strong empirical evidence of the accuracy of the extension proposed.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/staerman19a/staerman19a.pdf",
        "supp": "",
        "pdf_size": 2499683,
        "gs_citation": 81,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1226673796342557027&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "LTCI, T\u00e9l\u00e9com Paris, Institut Polytechnique de Paris; LTCI, T\u00e9l\u00e9com Paris, Institut Polytechnique de Paris; LTCI, T\u00e9l\u00e9com Paris, Institut Polytechnique de Paris; LTCI, T\u00e9l\u00e9com Paris, Institut Polytechnique de Paris",
        "aff_domain": "telecom-paris.fr;telecom-paris.fr;telecom-paris.fr;telecom-paris.fr",
        "email": "telecom-paris.fr;telecom-paris.fr;telecom-paris.fr;telecom-paris.fr",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "T\u00e9l\u00e9com Paris",
        "aff_unique_dep": "LTCI",
        "aff_unique_url": "https://www.telecom-paris.fr",
        "aff_unique_abbr": "T\u00e9l\u00e9com Paris",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "title": "Fusing Recalibrated Features and Depthwise Separable Convolution for the Mangrove Bird Sound Classification",
        "site": "https://proceedings.mlr.press/v101/lei19a.html",
        "author": "Chongqin Lei; Weiguo Gong; Zixu Wang",
        "abstract": "The bird community in the mangrove areas is an important component of the mangrove wetlands ecosystem and an indicator species for the assessment of the environmental health status of mangrove wetlands. The classification of bird species by the sound of bird in the mangrove areas has the advantages of less interference to the environment and wide monitoring range. In this paper, we propose a novel method that combines the feature recalibration mechanism with depthwise separable convolution for the mangrove bird sound classification. In the proposed method, we introduce Xception network in which depthwise separable convolution with lower parameter number and computational cost than traditional convolution can be stacked in a residual manner, as the baseline network. And we fuse the feature recalibration mechanism into the depthwise separable convolution for actively learning the weights of the feature channels in the network layer, so that we can enhance the important features in bird sound signals to improve the performance of the classification. In the proposed method, firstly we extract three-channel log-mel features of the bird sound signals and we introduce the mixup method to augment the extracted features. Secondly, we construct the recalibrated feature maps including the different scales of information to get the classification results. To verify the effectiveness of the proposed method, we build a dataset with 9282 samples including 25 kinds of the mangrove birds such as Egretta alba, Parus major, Charadrius dubius, etc. habiting in the mangroves of Fangcheng Port of China, and execute the experiments on the built dataset. Furthermore, we also validate the adaptability of our proposed method on the dataset of TAU Urban Acoustic Scenes 2019, and achieve a better result.",
        "bibtex": "@InProceedings{pmlr-v101-lei19a,\n  title = \t {Fusing Recalibrated Features and Depthwise Separable Convolution for the Mangrove Bird Sound Classification},\n  author =       {Lei, Chongqin and Gong, Weiguo and Wang, Zixu},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {924--939},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/lei19a/lei19a.pdf},\n  url = \t {https://proceedings.mlr.press/v101/lei19a.html},\n  abstract = \t {The bird community in the mangrove areas is an important component of the mangrove wetlands ecosystem and an indicator species for the assessment of the environmental health status of mangrove wetlands. The classification of bird species by the sound of bird in the mangrove areas has the advantages of less interference to the environment and wide monitoring range. In this paper, we propose a novel method that combines the feature recalibration mechanism with depthwise separable convolution for the mangrove bird sound classification. In the proposed method, we introduce Xception network in which depthwise separable convolution with lower parameter number and computational cost than traditional convolution can be stacked in a residual manner, as the baseline network. And we fuse the feature recalibration mechanism into the depthwise separable convolution for actively learning the weights of the feature channels in the network layer, so that we can enhance the important features in bird sound signals to improve the performance of the classification. In the proposed method, firstly we extract three-channel log-mel features of the bird sound signals and we introduce the mixup method to augment the extracted features. Secondly, we construct the recalibrated feature maps including the different scales of information to get the classification results. To verify the effectiveness of the proposed method, we build a dataset with 9282 samples including 25 kinds of the mangrove birds such as Egretta alba, Parus major, Charadrius dubius, etc. habiting in the mangroves of Fangcheng Port of China, and execute the experiments on the built dataset. Furthermore, we also validate the adaptability of our proposed method on the dataset of TAU Urban Acoustic Scenes 2019, and achieve a better result.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/lei19a/lei19a.pdf",
        "supp": "",
        "pdf_size": 8069076,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12356141148740099474&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Key Lab of Optoelectronic Technology and Systems of Education Ministry, College of Optoelectronic Engineering, Chongqing University, Chongqing, China; Key Lab of Optoelectronic Technology and Systems of Education Ministry, College of Optoelectronic Engineering, Chongqing University, Chongqing, China; Key Lab of Optoelectronic Technology and Systems of Education Ministry, College of Optoelectronic Engineering, Chongqing University, Chongqing, China",
        "aff_domain": "cqu.edu.cn;cqu.edu.cn;cqu.edu.cn",
        "email": "cqu.edu.cn;cqu.edu.cn;cqu.edu.cn",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Chongqing University",
        "aff_unique_dep": "College of Optoelectronic Engineering",
        "aff_unique_url": "http://www.cqu.edu.cn/",
        "aff_unique_abbr": "CQU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Chongqing",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "title": "G-UAP: Generic Universal Adversarial Perturbation that Fools RPN-based Detectors",
        "site": "https://proceedings.mlr.press/v101/wu19a.html",
        "author": "Xing Wu; Lifeng Huang; Chengying Gao",
        "abstract": "Adversarial perturbation constructions have been demonstrated for object detection, but these are image-specific perturbations. Recent works have shown the existence of image-agnostic perturbations called universal adversarial perturbation (UAP) that can fool the classifiers over a set of natural images. In this paper, we extend this kind perturbation to attack deep proposal-based object detectors. We present a novel and effective approach called G-UAP to craft universal adversarial perturbations, which can explicitly degrade the detection accuracy of a detector on a wide range of image samples. Our method directly misleads the Region Proposal Network (RPN) of the detectors into mistaking foreground (objects) for background without specifying an adversarial label for each target (RPN\u2019s proposal), and even without considering that how many objects and object-like targets are in the image. The experimental results over three state-of-the-art detectors and two datasets demonstrate the effectiveness of the proposed method and transferability of the universal perturbations.",
        "bibtex": "@InProceedings{pmlr-v101-wu19a,\n  title = \t {G-UAP: Generic Universal Adversarial Perturbation that Fools RPN-based Detectors},\n  author =       {Wu, Xing and Huang, Lifeng and Gao, Chengying},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {1204--1217},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/wu19a/wu19a.pdf},\n  url = \t {https://proceedings.mlr.press/v101/wu19a.html},\n  abstract = \t {Adversarial perturbation constructions have been demonstrated for object detection, but these are image-specific perturbations. Recent works have shown the existence of image-agnostic perturbations called universal adversarial perturbation (UAP) that can fool the classifiers over a set of natural images. In this paper, we extend this kind perturbation to attack deep proposal-based object detectors. We present a novel and effective approach called G-UAP to craft universal adversarial perturbations, which can explicitly degrade the detection accuracy of a detector on a wide range of image samples. Our method directly misleads the Region Proposal Network (RPN) of the detectors into mistaking foreground (objects) for background without specifying an adversarial label for each target (RPN\u2019s proposal), and even without considering that how many objects and object-like targets are in the image. The experimental results over three state-of-the-art detectors and two datasets demonstrate the effectiveness of the proposed method and transferability of the universal perturbations.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/wu19a/wu19a.pdf",
        "supp": "",
        "pdf_size": 10225230,
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11828950618969391817&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "School of Data and Computer Science, Sun Yat-sen University, Guangzhou 510006, China; School of Data and Computer Science, Sun Yat-sen University, Guangzhou 510006, China; School of Data and Computer Science, Sun Yat-sen University, Guangzhou 510006, China",
        "aff_domain": "mail2.sysu.edu.cn;mail2.sysu.edu.cn;mail.sysu.edu.cn",
        "email": "mail2.sysu.edu.cn;mail2.sysu.edu.cn;mail.sysu.edu.cn",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Sun Yat-sen University",
        "aff_unique_dep": "School of Data and Computer Science",
        "aff_unique_url": "http://www.sysu.edu.cn",
        "aff_unique_abbr": "SYSU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Guangzhou",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "title": "Geometry-Aware Maximum Likelihood Estimation of Intrinsic Dimension",
        "site": "https://proceedings.mlr.press/v101/gomtsyan19a.html",
        "author": "Marina Gomtsyan; Nikita Mokrov; Maxim Panov; Yury Yanovich",
        "abstract": "The existing approaches to intrinsic dimension estimation usually are not reliable when the data are nonlinearly embedded in the high dimensional space. In this work, we show that the explicit accounting to geometric properties of unknown support leads to the polynomial correction to the standard maximum likelihood estimate of intrinsic dimension for flat manifolds. The proposed algorithm (GeoMLE) realizes the correction by regression of standard MLEs based on distances to nearest neighbors for different sizes of neighborhoods. Moreover, the proposed approach also efficiently handles the case of nonuniform sampling of the manifold. We perform a series of experiments on various synthetic and real-world datasets. The results show that our algorithm achieves state-of-the-art performance, while also being robust to noise in the data and competitive computationally.",
        "bibtex": "@InProceedings{pmlr-v101-gomtsyan19a,\n  title = \t {Geometry-Aware Maximum Likelihood Estimation of Intrinsic Dimension},\n  author =       {Gomtsyan, Marina and Mokrov, Nikita and Panov, Maxim and Yanovich, Yury},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {1126--1141},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/gomtsyan19a/gomtsyan19a.pdf},\n  url = \t {https://proceedings.mlr.press/v101/gomtsyan19a.html},\n  abstract = \t {The existing approaches to intrinsic dimension estimation usually are not reliable when the data are nonlinearly embedded in the high dimensional space. In this work, we show that the explicit accounting to geometric properties of unknown support leads to the polynomial correction to the standard maximum likelihood estimate of intrinsic dimension for flat manifolds. The proposed algorithm (GeoMLE) realizes the correction by regression of standard MLEs based on distances to nearest neighbors for different sizes of neighborhoods. Moreover, the proposed approach also efficiently handles the case of nonuniform sampling of the manifold. We perform a series of experiments on various synthetic and real-world datasets. The results show that our algorithm achieves state-of-the-art performance, while also being robust to noise in the data and competitive computationally.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/gomtsyan19a/gomtsyan19a.pdf",
        "supp": "",
        "pdf_size": 409075,
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4101727245801860002&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Skolkovo Institute of Science and Technology+Higher School of Economics; Skolkovo Institute of Science and Technology+Moscow Institute of Physics and Technology; Skolkovo Institute of Science and Technology; Skolkovo Institute of Science and Technology+Institute for Information Transmission Problems",
        "aff_domain": "skoltech.ru;skoltech.ru;skoltech.ru;skoltech.ru",
        "email": "skoltech.ru;skoltech.ru;skoltech.ru;skoltech.ru",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;0+2;0;0+3",
        "aff_unique_norm": "Skolkovo Institute of Science and Technology;Higher School of Economics;Moscow Institute of Physics and Technology;Institute for Information Transmission Problems",
        "aff_unique_dep": ";;;",
        "aff_unique_url": "https://www.skoltech.ru;https://www.hse.ru;https://www.mipt.ru/en;http://www.iitp.ru",
        "aff_unique_abbr": "Skoltech;HSE;MIPT;",
        "aff_campus_unique_index": ";;",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0+0;0+0;0;0+0",
        "aff_country_unique": "Russia"
    },
    {
        "title": "Gradient-based Training of Slow Feature Analysis by Differentiable Approximate Whitening",
        "site": "https://proceedings.mlr.press/v101/schuler19a.html",
        "author": "Merlin Sch\u00fcler; Hlynur Dav\u00ed\u00f0 Hlynsson; Laurenz Wiskott",
        "abstract": "We propose Power Slow Feature Analysis, a gradient-based method to extract temporally slow features from a high-dimensional input stream that varies on a faster time-scale, as a variant of Slow Feature Analysis (SFA) that allows end-to-end training of arbitrary differentiable architectures and thereby significantly extends the class of models that can effectively be used for slow feature extraction. We provide experimental evidence that PowerSFA is able to extract meaningful and informative low-dimensional features in the case of (a) synthetic low-dimensional data, (b) ego-visual data, and also for (c) a general dataset for which symmetric non-temporal similarities between points can be defined.",
        "bibtex": "@InProceedings{pmlr-v101-schuler19a,\n  title = \t {Gradient-based Training of Slow Feature Analysis by Differentiable Approximate Whitening},\n  author =       {Sch{\\\"u}ler, Merlin and Hlynsson, Hlynur Dav\\'i\\dh and Wiskott, Laurenz},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {316--331},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/schuler19a/schuler19a.pdf},\n  url = \t {https://proceedings.mlr.press/v101/schuler19a.html},\n  abstract = \t {We propose Power Slow Feature Analysis, a gradient-based method to extract temporally slow features from a high-dimensional input stream that varies on a faster time-scale, as a variant of Slow Feature Analysis (SFA) that allows end-to-end training of arbitrary differentiable architectures and thereby significantly extends the class of models that can effectively be used for slow feature extraction. We provide experimental evidence that PowerSFA is able to extract meaningful and informative low-dimensional features in the case of (a) synthetic low-dimensional data, (b) ego-visual data, and also for (c) a general dataset for which symmetric non-temporal similarities between points can be defined. }\n}",
        "pdf": "http://proceedings.mlr.press/v101/schuler19a/schuler19a.pdf",
        "supp": "",
        "pdf_size": 2429431,
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4116780982906632862&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Institute for Neural Computation, Ruhr-Universit\u00e4t Bochum, Germany; Institute for Neural Computation, Ruhr-Universit\u00e4t Bochum, Germany; Institute for Neural Computation, Ruhr-Universit\u00e4t Bochum, Germany",
        "aff_domain": "ini.rub.de;ini.rub.de;ini.rub.de",
        "email": "ini.rub.de;ini.rub.de;ini.rub.de",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Ruhr-Universit\u00e4t Bochum",
        "aff_unique_dep": "Institute for Neural Computation",
        "aff_unique_url": "https://www.ruhr-uni-bochum.de",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "title": "Hyperbolic Ordinal Embedding",
        "site": "https://proceedings.mlr.press/v101/suzuki19a.html",
        "author": "Atsushi Suzuki; Jing Wang; Feng Tian; Atsushi Nitanda; Kenji Yamanishi",
        "abstract": "Given ordinal relations such as the object $i$ is more similar to $j$ than $k$ is to $l$, ordinal embedding is to embed these objects into a low-dimensional space with all ordinal constraints preserved. Although existing approaches have preserved ordinal relations in Euclidean space, whether Euclidean space is compatible with true data structure is largely ignored, although it is essential to effective embedding. Since real data often exhibit hierarchical structure, it is hard for Euclidean space approaches to achieve effective embeddings in low dimensionality, which incurs high computational complexity or overfitting. In this paper we propose a novel hyperbolic ordinal embedding (HOE) method to embed objects in hyperbolic space. Due to the hierarchy-friendly property of hyperbolic space, HOE can effectively capture the hierarchy to achieve embeddings in an extremely low-dimensional space. We have not only theoretically proved the superiority of hyperbolic space and the limitations of Euclidean space for embedding hierarchical data, but also experimentally demonstrated that HOE significantly outperforms Euclidean-based methods.",
        "bibtex": "@InProceedings{pmlr-v101-suzuki19a,\n  title = \t {Hyperbolic Ordinal Embedding},\n  author =       {Suzuki, Atsushi and Wang, Jing and Tian, Feng and Nitanda, Atsushi and Yamanishi, Kenji},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {1065--1080},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/suzuki19a/suzuki19a.pdf},\n  url = \t {https://proceedings.mlr.press/v101/suzuki19a.html},\n  abstract = \t {Given ordinal relations such as the object $i$ is more similar to $j$ than $k$ is to $l$, ordinal embedding is to embed these objects into a low-dimensional space with all ordinal constraints preserved. Although existing approaches have preserved ordinal relations in Euclidean space, whether Euclidean space is compatible with true data structure is largely ignored, although it is essential to effective embedding. Since real data often exhibit hierarchical structure, it is hard for Euclidean space approaches to achieve effective embeddings in low dimensionality, which incurs high computational complexity or overfitting. In this paper we propose a novel hyperbolic ordinal embedding (HOE) method to embed objects in hyperbolic space. Due to the hierarchy-friendly property of hyperbolic space, HOE can effectively capture the hierarchy to achieve embeddings in an extremely low-dimensional space. We have not only theoretically proved the superiority of hyperbolic space and the limitations of Euclidean space for embedding hierarchical data, but also experimentally demonstrated that HOE significantly outperforms Euclidean-based methods.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/suzuki19a/suzuki19a.pdf",
        "supp": "",
        "pdf_size": 471538,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2441938827037518114&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "7-3-1, Hongo, Bunkyo-ku, Tokyo, Japan; 7-3-1, Hongo, Bunkyo-ku, Tokyo, Japan; Fern Barrow, Poole, BH12 5BB, the United Kingdom; 7-3-1, Hongo, Bunkyo-ku, Tokyo, Japan; 7-3-1, Hongo, Bunkyo-ku, Tokyo, Japan",
        "aff_domain": "gmail.com;mist.i.u-tokyo.ac.jp;bournemouth.ac.uk;mist.i.u-tokyo.ac.jp;mist.i.u-tokyo.ac.jp",
        "email": "gmail.com;mist.i.u-tokyo.ac.jp;bournemouth.ac.uk;mist.i.u-tokyo.ac.jp;mist.i.u-tokyo.ac.jp",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "University of Tokyo;Fern Barrow",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.u-tokyo.ac.jp;",
        "aff_unique_abbr": "UTokyo;",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Hongo;",
        "aff_country_unique_index": "0;0;1;0;0",
        "aff_country_unique": "Japan;United Kingdom"
    },
    {
        "title": "Improving Relation Classification by Entity Pair Graph",
        "site": "https://proceedings.mlr.press/v101/zhao19a.html",
        "author": "Yi Zhao; Huaiyu Wan; Jianwei Gao; Youfang Lin",
        "abstract": "Relation classification is one of the most important tasks in the field of information extraction, and also a key component of systems that require relational understanding of unstructured text. Existing relation classification approaches mainly rely on exploiting external resources and background knowledge to improve the performance and ignore the correlations between entity pairs which are helpful for relation classification. We present the concept of entity pair graph to represent the correlations between entity pairs and propose a novel entity pair graph based neural network (EPGNN) model, relying on graph convolutional network to capture the topological features of an entity pair graph. EPGNN combines sentence semantic features generated by pre-trained BERT model with graph topological features for relation classification. Our proposed model makes full use of a given corpus and forgoes the need of external resources and background knowledge. The experimental results on two widely used dataset: SemEval 2010 Task 8 and ACE 2005, show that our method outperforms the state-of-the-art approaches.",
        "bibtex": "@InProceedings{pmlr-v101-zhao19a,\n  title = \t {Improving Relation Classification by Entity Pair Graph},\n  author =       {Zhao, Yi and Wan, Huaiyu and Gao, Jianwei and Lin, Youfang},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {1156--1171},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/zhao19a/zhao19a.pdf},\n  url = \t {https://proceedings.mlr.press/v101/zhao19a.html},\n  abstract = \t {Relation classification is one of the most important tasks in the field of information extraction, and also a key component of systems that require relational understanding of unstructured text. Existing relation classification approaches mainly rely on exploiting external resources and background knowledge to improve the performance and ignore the correlations between entity pairs which are helpful for relation classification. We present the concept of entity pair graph to represent the correlations between entity pairs and propose a novel entity pair graph based neural network (EPGNN) model, relying on graph convolutional network to capture the topological features of an entity pair graph. EPGNN combines sentence semantic features generated by pre-trained BERT model with graph topological features for relation classification. Our proposed model makes full use of a given corpus and forgoes the need of external resources and background knowledge. The experimental results on two widely used dataset: SemEval 2010 Task 8 and ACE 2005, show that our method outperforms the state-of-the-art approaches.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/zhao19a/zhao19a.pdf",
        "supp": "",
        "pdf_size": 540293,
        "gs_citation": 49,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12301897539943045891&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "School of Computer and Information Technology, Beijing Jiaotong University, Beijing, China + Beijing Key Laboratory of Tra\ufb03c Data Analysis and Mining, Beijing, China; School of Computer and Information Technology, Beijing Jiaotong University, Beijing, China + Beijing Key Laboratory of Tra\ufb03c Data Analysis and Mining, Beijing, China; School of Computer and Information Technology, Beijing Jiaotong University, Beijing, China + Beijing Key Laboratory of Tra\ufb03c Data Analysis and Mining, Beijing, China; School of Computer and Information Technology, Beijing Jiaotong University, Beijing, China + Beijing Key Laboratory of Tra\ufb03c Data Analysis and Mining, Beijing, China",
        "aff_domain": "bjtu.edu.cn;bjtu.edu.cn;bjtu.edu.cn;bjtu.edu.cn",
        "email": "bjtu.edu.cn;bjtu.edu.cn;bjtu.edu.cn;bjtu.edu.cn",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;0+1;0+1;0+1",
        "aff_unique_norm": "Beijing Jiaotong University;Beijing Key Laboratory of Traffic Data Analysis and Mining",
        "aff_unique_dep": "School of Computer and Information Technology;Tra\ufb03c Data Analysis and Mining",
        "aff_unique_url": "http://www.bjtu.edu.cn;",
        "aff_unique_abbr": "BJTU;",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Beijing;",
        "aff_country_unique_index": "0+0;0+0;0+0;0+0",
        "aff_country_unique": "China"
    },
    {
        "title": "Improving Statute Prediction via Mining Correlations between Statutes",
        "site": "https://proceedings.mlr.press/v101/feng19a.html",
        "author": "Yi Feng; Chuanyi Li; Jidong Ge; Bin Luo",
        "abstract": "The task of statute prediction focuses on determining applicable statutes for legal cases with the inputs of fact descriptions, which is crucial for both legal experts and ordinary people without professional knowledge. Existing works just consider the correspondence from facts to individual statutes and ignore the correlations between statutes. Moreover, charges of cases have associations with statutes. To address these issues, we formulate statute prediction task as a sequence generation problem and propose a novel joint generative model to mine correlations between statutes. By integrating statute prediction task and charge prediction task, we also make model learn associations between statutes and charges. Experiments show our model outperforms several baselines significantly and correlative statutes are predicted accurately.",
        "bibtex": "@InProceedings{pmlr-v101-feng19a,\n  title = \t {Improving Statute Prediction via Mining Correlations between Statutes},\n  author =       {Feng, Yi and Li, Chuanyi and Ge, Jidong and Luo, Bin},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {710--725},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/feng19a/feng19a.pdf},\n  url = \t {https://proceedings.mlr.press/v101/feng19a.html},\n  abstract = \t {The task of statute prediction focuses on determining applicable statutes for legal cases with the inputs of fact descriptions, which is crucial for both legal experts and ordinary people without professional knowledge. Existing works just consider the correspondence from facts to individual statutes and ignore the correlations between statutes. Moreover, charges of cases have associations with statutes. To address these issues, we formulate statute prediction task as a sequence generation problem and propose a novel joint generative model to mine correlations between statutes. By integrating statute prediction task and charge prediction task, we also make model learn associations between statutes and charges. Experiments show our model outperforms several baselines significantly and correlative statutes are predicted accurately.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/feng19a/feng19a.pdf",
        "supp": "",
        "pdf_size": 760726,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=847876152440127334&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "State Key Laboratory for Novel Software Technology, Software Institute, Nanjing University, Nanjing 210093, China; State Key Laboratory for Novel Software Technology, Software Institute, Nanjing University, Nanjing 210093, China; State Key Laboratory for Novel Software Technology, Software Institute, Nanjing University, Nanjing 210093, China; State Key Laboratory for Novel Software Technology, Software Institute, Nanjing University, Nanjing 210093, China",
        "aff_domain": "smail.nju.edu.cn;nju.edu.cn;nju.edu.cn;nju.edu.cn",
        "email": "smail.nju.edu.cn;nju.edu.cn;nju.edu.cn;nju.edu.cn",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Nanjing University",
        "aff_unique_dep": "Software Institute",
        "aff_unique_url": "http://www.nju.edu.cn",
        "aff_unique_abbr": "Nanjing U",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Nanjing",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "title": "Investigating the effect of novel classes in semi-supervised learning",
        "site": "https://proceedings.mlr.press/v101/peng19a.html",
        "author": "Alex Yuxuan Peng; Yun Sing Koh; Patricia Riddle; Bernhard Pfahringer",
        "abstract": "Semi-supervised learning usually assumes the distribution of the unlabelled data to be the same as that of the labelled data. This assumption does not always hold in practice. We empirically show that unlabelled data containing novel examples and classes from outside the distribution of the labelled data can lead to a performance degradation for semi-supervised learning algorithms. We propose a 1-nearest-neighbour based method to assign a weight to each unlabelled example in order to reduce the negative effect of novel classes in unlabelled data. Experimental results on MNIST, Fashion-MNIST and CIFAR-10 datasets suggest that the negative effect of novel classes becomes statistically insignificant when the proposed method is applied. Using our proposed technique, models trained on unlabelled data with novel classes can achieve similar performance as ones trained on clean unlabelled data.",
        "bibtex": "@InProceedings{pmlr-v101-peng19a,\n  title = \t {Investigating the effect of novel classes in semi-supervised learning},\n  author =       {Peng, Alex Yuxuan and Koh, Yun Sing and Riddle, Patricia and Pfahringer, Bernhard},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {615--630},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/peng19a/peng19a.pdf},\n  url = \t {https://proceedings.mlr.press/v101/peng19a.html},\n  abstract = \t {Semi-supervised learning usually assumes the distribution of the unlabelled data to be the same as that of the labelled data. This assumption does not always hold in practice. We empirically show that unlabelled data containing novel examples and classes from outside the distribution of the labelled data can lead to a performance degradation for semi-supervised learning algorithms. We propose a 1-nearest-neighbour based method to assign a weight to each unlabelled example in order to reduce the negative effect of novel classes in unlabelled data. Experimental results on MNIST, Fashion-MNIST and CIFAR-10 datasets suggest that the negative effect of novel classes becomes statistically insignificant when the proposed method is applied. Using our proposed technique, models trained on unlabelled data with novel classes can achieve similar performance as ones trained on clean unlabelled data.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/peng19a/peng19a.pdf",
        "supp": "",
        "pdf_size": 359607,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9238056082101313845&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "University of Auckland; University of Auckland; University of Auckland; University of Waikato",
        "aff_domain": "aucklanduni.ac.nz;cs.auckland.ac.nz;cs.auckland.ac.nz;cs.waikato.ac.nz",
        "email": "aucklanduni.ac.nz;cs.auckland.ac.nz;cs.auckland.ac.nz;cs.waikato.ac.nz",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "University of Auckland;University of Waikato",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.auckland.ac.nz;https://www.waikato.ac.nz",
        "aff_unique_abbr": "UoA;UoW",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "New Zealand"
    },
    {
        "title": "Kernel Learning for Data-Driven Spectral Analysis of Koopman Operators",
        "site": "https://proceedings.mlr.press/v101/takeishi19a.html",
        "author": "Naoya Takeishi",
        "abstract": "Spectral analysis of the Koopman operators is a useful tool for studying nonlinear dynamical systems and has been utilized in various branches of science and engineering for purposes such as understanding complex phenomena and designing a controller. Several methods to compute the Koopman spectral analysis have been studied, among which data-driven methods are attracting attention. We focus on one of the popular data-driven methods, which is based on the Galerkin approximation of the operator using a basis estimated in a data-driven manner via the diffusion maps algorithm. The performance of this method with a finite amount of data depends on the choice of the kernel function used in diffusion maps, which creates a need for kernel selection. In this paper, we propose a method to learn the kernel function adaptively to obtain better performance in approximating spectra of the Koopman operator using the Galerkin approximation with diffusion maps. The proposed method depends on the multiple kernel learning scheme, and our objective function is based on the idea that a diffusion operator should commute with the Koopman operator. We also show the effectiveness of the proposed method empirically with numerical examples.",
        "bibtex": "@InProceedings{pmlr-v101-takeishi19a,\n  title = \t {Kernel Learning for Data-Driven Spectral Analysis of Koopman Operators},\n  author =       {Takeishi, Naoya},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {956--971},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/takeishi19a/takeishi19a.pdf},\n  url = \t {https://proceedings.mlr.press/v101/takeishi19a.html},\n  abstract = \t {Spectral analysis of the Koopman operators is a useful tool for studying nonlinear dynamical systems and has been utilized in various branches of science and engineering for purposes such as understanding complex phenomena and designing a controller. Several methods to compute the Koopman spectral analysis have been studied, among which data-driven methods are attracting attention. We focus on one of the popular data-driven methods, which is based on the Galerkin approximation of the operator using a basis estimated in a data-driven manner via the diffusion maps algorithm. The performance of this method with a finite amount of data depends on the choice of the kernel function used in diffusion maps, which creates a need for kernel selection. In this paper, we propose a method to learn the kernel function adaptively to obtain better performance in approximating spectra of the Koopman operator using the Galerkin approximation with diffusion maps. The proposed method depends on the multiple kernel learning scheme, and our objective function is based on the idea that a diffusion operator should commute with the Koopman operator. We also show the effectiveness of the proposed method empirically with numerical examples.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/takeishi19a/takeishi19a.pdf",
        "supp": "",
        "pdf_size": 702536,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2655977091090408213&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "RIKEN Center for Advanced Intelligence Project, Japan",
        "aff_domain": "riken.jp",
        "email": "riken.jp",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "RIKEN Center for Advanced Intelligence Project",
        "aff_unique_dep": "Center for Advanced Intelligence Project",
        "aff_unique_url": "https://www.riken.jp/en/c-aip/",
        "aff_unique_abbr": "RIKEN C-AIP",
        "aff_country_unique_index": "0",
        "aff_country_unique": "Japan"
    },
    {
        "title": "LADet: A Light-weight and Adaptive Network for Multi-scale Object Detection",
        "site": "https://proceedings.mlr.press/v101/zhou19a.html",
        "author": "Jiaming Zhou; Yuqiao Tian; Weicheng Li; Rui Wang; Zhongzhi Luan; Depei Qian",
        "abstract": "Scale variation is one of the most significant challenges for object detection task. In comparison with previous one-stage object detectors that simply make feature pyramid network deeper without consideration of speed, we propose a novel one-stage object detector called LADet, which consists of two parts, Adaptive Feature Pyramid Module(AFPM) and Light-weight Classification Function Module(LCFM). Adaptive Feature Pyramid Module generates complementary semantic information for each level feature map by jointly utilizing multi-level feature maps from backbone network, which is different from the top-down manner. Light-weight Classification Function Module is able to exploit more type of anchor boxes without a dramatic increase of parameters because of the utilization of interleaved group convolution. Extensive experiments on PASCAL VOC and MS COCO benchmark demonstrate that our model achieves a better trade-off between accuracy and efficiency over the comparable state-of-the-art detection methods.",
        "bibtex": "@InProceedings{pmlr-v101-zhou19a,\n  title = \t {LADet: A Light-weight and Adaptive Network for Multi-scale Object Detection},\n  author =       {Zhou, Jiaming and Tian, Yuqiao and Li, Weicheng and Wang, Rui and Luan, Zhongzhi and Qian, Depei},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {912--923},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/zhou19a/zhou19a.pdf},\n  url = \t {https://proceedings.mlr.press/v101/zhou19a.html},\n  abstract = \t {Scale variation is one of the most significant challenges for object detection task. In comparison with previous one-stage object detectors that simply make feature pyramid network deeper without consideration of speed, we propose a novel one-stage object detector called LADet, which consists of two parts, Adaptive Feature Pyramid Module(AFPM) and Light-weight Classification Function Module(LCFM). Adaptive Feature Pyramid Module generates complementary semantic information for each level feature map by jointly utilizing multi-level feature maps from backbone network, which is different from the top-down manner. Light-weight Classification Function Module is able to exploit more type of anchor boxes without a dramatic increase of parameters because of the utilization of interleaved group convolution. Extensive experiments on PASCAL VOC and MS COCO benchmark demonstrate that our model achieves a better trade-off between accuracy and efficiency over the comparable state-of-the-art detection methods.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/zhou19a/zhou19a.pdf",
        "supp": "",
        "pdf_size": 1636631,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6371896280480518278&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "School of Computer Science and Engineering, Beihang University, Beijing 100191, China; School of Computer Science and Engineering, Beihang University, Beijing 100191, China; School of Computer Science and Engineering, Beihang University, Beijing 100191, China; School of Computer Science and Engineering, Beihang University, Beijing 100191, China; School of Computer Science and Engineering, Beihang University, Beijing 100191, China; School of Computer Science and Engineering, Beihang University, Beijing 100191, China",
        "aff_domain": "BUAA.EDU.CN;BUAA.EDU.CN;163.COM;BUAA.EDU.CN;BUAA.EDU.CN;BUAA.EDU.CN",
        "email": "BUAA.EDU.CN;BUAA.EDU.CN;163.COM;BUAA.EDU.CN;BUAA.EDU.CN;BUAA.EDU.CN",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Beihang University",
        "aff_unique_dep": "School of Computer Science and Engineering",
        "aff_unique_url": "http://www.buaa.edu.cn",
        "aff_unique_abbr": "BUAA",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "title": "Latent Multi-view Semi-Supervised Classification",
        "site": "https://proceedings.mlr.press/v101/bo19a.html",
        "author": "Xiaofan Bo; Zhao Kang; Zhitong Zhao; Yuanzhang Su; Wenyu Chen",
        "abstract": "To explore underlying complementary information from multiple views, in this paper, we propose a novel Latent Multi-view Semi-Supervised Classification (LMSSC) method. Unlike most existing multi-view semi-supervised classification methods that learn the graph using original features, our method seeks an underlying latent representation and performs graph learning and label propagation based on the learned latent representation. With the complementarity of multiple views, the latent representation could depict the data more comprehensively than every single view individually, accordingly making the graph more accurate and robust as well. Finally, LMSSC integrates latent representation learning, graph construction, and label propagation into a unified framework, which makes each subtask optimized. Experimental results on real-world benchmark datasets validate the effectiveness of our proposed method.",
        "bibtex": "@InProceedings{pmlr-v101-bo19a,\n  title = \t {Latent Multi-view Semi-Supervised Classification},\n  author =       {Bo, Xiaofan and Kang, Zhao and Zhao, Zhitong and Su, Yuanzhang and Chen, Wenyu},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {348--362},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/bo19a/bo19a.pdf},\n  url = \t {https://proceedings.mlr.press/v101/bo19a.html},\n  abstract = \t {To explore underlying complementary information from multiple views, in this paper, we propose a novel Latent Multi-view Semi-Supervised Classification (LMSSC) method. Unlike most existing multi-view semi-supervised classification methods that learn the graph using original features, our method seeks an underlying latent representation and performs graph learning and label propagation based on the learned latent representation. With the complementarity of multiple views, the latent representation could depict the data more comprehensively than every single view individually, accordingly making the graph more accurate and robust as well. Finally, LMSSC integrates latent representation learning, graph construction, and label propagation into a unified framework, which makes each subtask optimized. Experimental results on real-world benchmark datasets validate the effectiveness of our proposed method.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/bo19a/bo19a.pdf",
        "supp": "",
        "pdf_size": 308259,
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2333225074230759926&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Glasgow college, University of Electronic Science and Technology of China; School of Computer Science and Engineering, University of Electronic Science and Technology of China; School of Computer Science and Engineering, University of Electronic Science and Technology of China; School of Foreign Languages, University of Electronic Science and Technology of China + School of Computer Science and Engineering, University of Electronic Science and Technology of China; School of Computer Science and Engineering, University of Electronic Science and Technology of China",
        "aff_domain": "uestc.edu.cn;uestc.edu.cn;uestc.edu.cn;uestc.edu.cn;uestc.edu.cn",
        "email": "uestc.edu.cn;uestc.edu.cn;uestc.edu.cn;uestc.edu.cn;uestc.edu.cn",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0+0;0",
        "aff_unique_norm": "University of Electronic Science and Technology of China",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.uestc.edu.cn",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;",
        "aff_campus_unique": "Glasgow;",
        "aff_country_unique_index": "0;0;0;0+0;0",
        "aff_country_unique": "China"
    },
    {
        "title": "Learning Weighted Top-$k$ Support Vector Machine",
        "site": "https://proceedings.mlr.press/v101/kato19a.html",
        "author": "Tsuyoshi Kato; Yoshihiro Hirohashi",
        "abstract": "Nowadays, the top-$k$ accuracy is a major performance criterion when benchmarking multi-class classifier using datasets with a large number of categories. Top-$k$ multiclass SVM has been designed with the aim to minimize the empirical risk based on the top-$k$ accuracy. There already exist two SDCA-based algorithms to learn the top-$k$ SVM, enjoying several preferable properties for optimization, although both the algorithms suffer from two disadvantages. A weak point is that, since the design of the algorithms are specialized only to the top-$k$ hinge, their applicability to other variants is limited. The other disadvantage is that both the two algorithms cannot attain the optimal solution in most cases due to their theoritical imperfections. In this study, a weighted extension of top-$k$ SVM is considered, and novel learning algorithms based on the Frank-Wolfe algorithm is devised. The new learning algorithms possess all the favorable properties of SDCA as well as the applicability not only to the original top-$k$ SVM but also to the weighted extension. Geometrical convergence is achieved by smoothing the loss functions. Numerical simulations demonstrate that only the proposed Frank-Wolfe algorithms can converge to the optimum, in contrast with the failure of the two existing SDCA-based algorithms. Finally, our analytical results for these two studies are presented to shed light on the meaning of the solutions produced from their algorithms.",
        "bibtex": "@InProceedings{pmlr-v101-kato19a,\n  title = \t {Learning Weighted Top-$k$ Support Vector Machine},\n  author =       {Kato, Tsuyoshi and Hirohashi, Yoshihiro},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {774--789},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/kato19a/kato19a.pdf},\n  url = \t {https://proceedings.mlr.press/v101/kato19a.html},\n  abstract = \t {Nowadays, the top-$k$ accuracy is a major performance criterion when benchmarking multi-class classifier using datasets with a large number of categories. Top-$k$ multiclass SVM has been designed with the aim to minimize the empirical risk based on the top-$k$ accuracy. There already exist two SDCA-based algorithms to learn the top-$k$ SVM, enjoying several preferable properties for optimization, although both the algorithms suffer from two disadvantages. A weak point is that, since the design of the algorithms are specialized only to the top-$k$ hinge, their applicability to other variants is limited. The other disadvantage is that both the two algorithms cannot attain the optimal solution in most cases due to their theoritical imperfections. In this study, a weighted extension of top-$k$ SVM is considered, and novel learning algorithms based on the Frank-Wolfe algorithm is devised. The new learning algorithms possess all the favorable properties of SDCA as well as the applicability not only to the original top-$k$ SVM but also to the weighted extension. Geometrical convergence is achieved by smoothing the loss functions. Numerical simulations demonstrate that only the proposed Frank-Wolfe algorithms can converge to the optimum, in contrast with the failure of the two existing SDCA-based algorithms. Finally, our analytical results for these two studies are presented to shed light on the meaning of the solutions produced from their algorithms. }\n}",
        "pdf": "http://proceedings.mlr.press/v101/kato19a/kato19a.pdf",
        "supp": "",
        "pdf_size": 451017,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11911792395700409668&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "aff": "Division of Electronics and Informatics, Faculty of Science and Technology, Gunma University; DENSO CORPORATION",
        "aff_domain": "cs.gunma-u.ac.jp;gmail.com",
        "email": "cs.gunma-u.ac.jp;gmail.com",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Gunma University;DENSO Corporation",
        "aff_unique_dep": "Division of Electronics and Informatics, Faculty of Science and Technology;",
        "aff_unique_url": "https://www.gunma-u.ac.jp;https://www.denso.com",
        "aff_unique_abbr": ";DENSO",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "title": "Learning to Aggregate: Tackling the Aggregation/Disaggregation Problem for OWA",
        "site": "https://proceedings.mlr.press/v101/melnikov19a.html",
        "author": "Vitalik Melnikov; Eyke H\u00fcllermeier",
        "abstract": "The problem of \u201clearning to aggregate\u201d (LTA) has recently been introduced as a novel machine learning setting, in which instances are represented in the form of a composition of a (variable) number on constituents. Such compositions are associated with an evaluation, which is the target of the prediction task, and which can presumably be modeled in the form of a suitable aggregation of the properties of its constituents. An especially interesting class of LTA problems arises when the evaluations of the constituents are not available at training time, and instead ought to be learned simultaneously with the aggregation function. This scenario is referred to as the \u201caggregation/disaggregation problem\u201d. In this paper, we tackle this problem for an interesting type of aggregation function, namely the Ordered Weighted Averaging (OWA) operator. In particular, we provide an algorithm for learning the OWA parameters together with local utility scores of the constituents, and evaluate this algorithm in a case study on predicting the performance of classifier ensembles.",
        "bibtex": "@InProceedings{pmlr-v101-melnikov19a,\n  title = \t {Learning to Aggregate: Tackling the Aggregation/Disaggregation Problem for OWA},\n  author =       {Melnikov, Vitalik and H{\\\"u}llermeier, Eyke},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {1110--1125},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/melnikov19a/melnikov19a.pdf},\n  url = \t {https://proceedings.mlr.press/v101/melnikov19a.html},\n  abstract = \t {The problem of \u201clearning to aggregate\u201d (LTA) has recently been introduced as a novel machine learning setting, in which instances are represented in the form of a composition of a (variable) number on constituents. Such compositions are associated with an evaluation, which is the target of the prediction task, and which can presumably be modeled in the form of a suitable aggregation of the properties of its constituents. An especially interesting class of LTA problems arises when the evaluations of the constituents are not available at training time, and instead ought to be learned simultaneously with the aggregation function. This scenario is referred to as the \u201caggregation/disaggregation problem\u201d. In this paper, we tackle this problem for an interesting type of aggregation function, namely the Ordered Weighted Averaging (OWA) operator. In particular, we provide an algorithm for learning the OWA parameters together with local utility scores of the constituents, and evaluate this algorithm in a case study on predicting the performance of classifier ensembles.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/melnikov19a/melnikov19a.pdf",
        "supp": "",
        "pdf_size": 2331320,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1967363262881963087&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "Paderborn University; Paderborn University",
        "aff_domain": "mail.upb.com;upb.com",
        "email": "mail.upb.com;upb.com",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Paderborn University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.upb.de/",
        "aff_unique_abbr": "UPB",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "title": "Learning to Augment with Feature Side-information",
        "site": "https://proceedings.mlr.press/v101/mollaysa19a.html",
        "author": "Amina Mollaysa; Alexandros Kalousis; Eric Bruno; Maurits Diephuis",
        "abstract": "Neural networks typically need huge amounts of data to train in order to get reasonable generalizable results. A common approach is to artificially generate samples by using prior knowledge of the data properties or other relevant domain knowledge. However, if the assumptions on the data properties are not accurate or the domain knowledge is irrelevant to the task at hand, one may end up degenerating learning performance by using such augmented data in comparison to simply training on the limited available dataset. We propose a critical data augmentation method using feature side-information, which is obtained from domain knowledge and provides detailed information about features' intrinsic properties. Most importantly, we introduce an instance wise quality checking procedure on the augmented data. It filters out irrelevant or harmful augmented data prior to entering the model. We validated this approach on both synthetic and real-world datasets, specifically in a scenario where the data augmentation is done based on a task independent, unreliable source of information. The experiments show that the introduced critical data augmentation scheme helps avoid performance degeneration resulting from incorporating wrong augmented data.",
        "bibtex": "@InProceedings{pmlr-v101-mollaysa19a,\n  title = \t {Learning to Augment with Feature Side-information},\n  author =       {Mollaysa, Amina and Kalousis, Alexandros and Bruno, Eric and Diephuis, Maurits},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {173--187},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/mollaysa19a/mollaysa19a.pdf},\n  url = \t {https://proceedings.mlr.press/v101/mollaysa19a.html},\n  abstract = \t {Neural networks typically need huge amounts of data to train in order to get reasonable generalizable results. A common approach is to artificially generate samples by using prior knowledge of the data properties or other relevant domain knowledge. However, if the assumptions on the data properties are not accurate or the domain knowledge is irrelevant to the task at hand, one may end up degenerating learning performance by using such augmented data in comparison to simply training on the limited available dataset. We propose a critical data augmentation method using feature side-information, which is obtained from domain knowledge and provides detailed information about features' intrinsic properties. Most importantly, we introduce an instance wise quality checking procedure on the augmented data. It filters out irrelevant or harmful augmented data prior to entering the model. We validated this approach on both synthetic and real-world datasets, specifically in a scenario where the data augmentation is done based on a task independent, unreliable source of information. The experiments show that the introduced critical data augmentation scheme helps avoid performance degeneration resulting from incorporating wrong augmented data.\n}\n}",
        "pdf": "http://proceedings.mlr.press/v101/mollaysa19a/mollaysa19a.pdf",
        "supp": "",
        "pdf_size": 376621,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15696637418890315123&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Geneva School of Business Administration, HES-SO University of Applied Sciences of Western Switzerland + University of Geneva, Switzerland; Geneva School of Business Administration, HES-SO University of Applied Sciences of Western Switzerland + University of Geneva, Switzerland; Expedia, Switzerland; University of Geneva, Switzerland",
        "aff_domain": "hesge.ch;hesge.ch;expedia.com;gmail.com",
        "email": "hesge.ch;hesge.ch;expedia.com;gmail.com",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;0+1;2;1",
        "aff_unique_norm": "HES-SO University of Applied Sciences of Western Switzerland;University of Geneva;Expedia",
        "aff_unique_dep": "School of Business Administration;;",
        "aff_unique_url": "https://www.hes-so.ch/en;https://www.unige.ch;https://www.expedia.com",
        "aff_unique_abbr": "HES-SO;UNIGE;",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Geneva;",
        "aff_country_unique_index": "0+0;0+0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "title": "Learning to Sample Hard Instances for Graph Algorithms",
        "site": "https://proceedings.mlr.press/v101/sato19a.html",
        "author": "Ryoma Sato; Makoto Yamada; Hisashi Kashima",
        "abstract": "\\textit{Hard instances}, which require a long time for a specific algorithm to solve, help (1) analyze the algorithm for accelerating it and (2) build a good benchmark for evaluating the performance of algorithms. There exist several efforts for automatic generation of hard instances. For example, evolutionary algorithms have been utilized to generate hard instances. However, they generate only finite number of hard instances. The merit of such methods is limited because it is difficult to extract meaningful patterns from small number of instances. We seek for a probabilistic generator of hard instances. Once the generative distribution of hard instances is obtained, we can sample a variety of hard instances to build a benchmark, and we can extract meaningful patterns of hard instances from sampled instances. The existing methods for modeling the hard instance distribution rely on parameters or rules that are found by domain experts; however, they are specific to the problem. Hence, it is challenging to model the distribution for general cases. In this paper, we focus on graph problems. We propose \\textsc{HiSampler}, the hard instance sampler, to model the hard instance distribution of graph algorithms. \\textsc{HiSampler} makes it possible to obtain the distribution of hard instances without hand-engineered features. To the best of our knowledge, this is the first method to learn the distribution of hard instances using machine learning. Through experiments, we demonstrate that our proposed method can generate instances that are a few to several orders of magnitude harder than the random-based approach in many settings. In particular, our method outperforms rule-based algorithms in the 3-coloring problem.",
        "bibtex": "@InProceedings{pmlr-v101-sato19a,\n  title = \t {Learning to Sample Hard Instances for Graph Algorithms},\n  author =       {Sato, Ryoma and Yamada, Makoto and Kashima, Hisashi},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {503--518},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/sato19a/sato19a.pdf},\n  url = \t {https://proceedings.mlr.press/v101/sato19a.html},\n  abstract = \t {\\textit{Hard instances}, which require a long time for a specific algorithm to solve, help (1) analyze the algorithm for accelerating it and (2) build a good benchmark for evaluating the performance of algorithms. There exist several efforts for automatic generation of hard instances. For example, evolutionary algorithms have been utilized to generate hard instances. However, they generate only finite number of hard instances. The merit of such methods is limited because it is difficult to extract meaningful patterns from small number of instances. We seek for a probabilistic generator of hard instances. Once the generative distribution of hard instances is obtained, we can sample a variety of hard instances to build a benchmark, and we can extract meaningful patterns of hard instances from sampled instances. The existing methods for modeling the hard instance distribution rely on parameters or rules that are found by domain experts; however, they are specific to the problem. Hence, it is challenging to model the distribution for general cases. In this paper, we focus on graph problems. We propose \\textsc{HiSampler}, the hard instance sampler, to model the hard instance distribution of graph algorithms. \\textsc{HiSampler} makes it possible to obtain the distribution of hard instances without hand-engineered features. To the best of our knowledge, this is the first method to learn the distribution of hard instances using machine learning. Through experiments, we demonstrate that our proposed method can generate instances that are a few to several orders of magnitude harder than the random-based approach in many settings. In particular, our method outperforms rule-based algorithms in the 3-coloring problem.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/sato19a/sato19a.pdf",
        "supp": "",
        "pdf_size": 403167,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12173133521089973111&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Kyoto University, Kyoto 606-8501, Japan; Kyoto University, Kyoto 606-8501, Japan; Kyoto University, Kyoto 606-8501, Japan + RIKEN Center for Advanced Intelligence Project, Tokyo 103-0027, Japan",
        "aff_domain": "ml.ist.i.kyoto-u.ac.jp;i.kyoto-u.ac.jp;i.kyoto-u.ac.jp",
        "email": "ml.ist.i.kyoto-u.ac.jp;i.kyoto-u.ac.jp;i.kyoto-u.ac.jp",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0+1",
        "aff_unique_norm": "Kyoto University;RIKEN Center for Advanced Intelligence Project",
        "aff_unique_dep": ";Center for Advanced Intelligence Project",
        "aff_unique_url": "https://www.kyoto-u.ac.jp;https://www.riken.jp/en/crai/",
        "aff_unique_abbr": "Kyoto U;RIKEN",
        "aff_campus_unique_index": "0;0;0+1",
        "aff_campus_unique": "Kyoto;Tokyo",
        "aff_country_unique_index": "0;0;0+0",
        "aff_country_unique": "Japan"
    },
    {
        "title": "Minimax Online Prediction of Varying Bernoulli Process under Variational Approximation",
        "site": "https://proceedings.mlr.press/v101/konagayoshi19a.html",
        "author": "Kenta Konagayoshi; Kazuho Watanabe",
        "abstract": "We consider the online prediction of a varying Bernoulli process (sequence of varying Bernoulli probabilities) from a single binary sequence. A real-valued online prediction method has been proposed as a prior work that incorporates the smoothness of the prediction sequence into the concept of the regret. Also, a Bayesian prediction method for the varying Bernoulli processes has been developed based on the variational inference. However, the former is not applicable to loss functions other than the  squared error function, and the latter has no guarantee on the regret as an online prediction method. We propose a new online prediction method of a varying Bernoulli process from a single binary sequence with a guarantee to minimize the maximum regret under variational approximation. Through numerical experiments, we compare the Bayesian prediction method with the proposed method by using the regret with/without approximation and the KL divergence from the true underlying process. We discuss the prediction accuracy and influences of the approximation of the proposed method.",
        "bibtex": "@InProceedings{pmlr-v101-konagayoshi19a,\n  title = \t {Minimax Online Prediction of Varying Bernoulli Process under Variational Approximation},\n  author =       {Konagayoshi, Kenta and Watanabe, Kazuho},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {141--156},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/konagayoshi19a/konagayoshi19a.pdf},\n  url = \t {https://proceedings.mlr.press/v101/konagayoshi19a.html},\n  abstract = \t {We consider the online prediction of a varying Bernoulli process (sequence of varying Bernoulli probabilities) from a single binary sequence. A real-valued online prediction method has been proposed as a prior work that incorporates the smoothness of the prediction sequence into the concept of the regret. Also, a Bayesian prediction method for the varying Bernoulli processes has been developed based on the variational inference. However, the former is not applicable to loss functions other than the  squared error function, and the latter has no guarantee on the regret as an online prediction method. We propose a new online prediction method of a varying Bernoulli process from a single binary sequence with a guarantee to minimize the maximum regret under variational approximation. Through numerical experiments, we compare the Bayesian prediction method with the proposed method by using the regret with/without approximation and the KL divergence from the true underlying process. We discuss the prediction accuracy and influences of the approximation of the proposed method.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/konagayoshi19a/konagayoshi19a.pdf",
        "supp": "",
        "pdf_size": 494985,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9574301262031071552&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Department of Informatics, Kyushu University, Fukuoka, 819-0395 Japan; Department of Computer Science and Engineering, Toyohashi University of Technology, Toyohashi, 441-8580 Japan",
        "aff_domain": "inf.kyushu-u.ac.jp;cs.tut.ac.jp",
        "email": "inf.kyushu-u.ac.jp;cs.tut.ac.jp",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Kyushu University;Toyohashi University of Technology",
        "aff_unique_dep": "Department of Informatics;Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.kyushu-u.ac.jp;https://www.tut.ac.jp",
        "aff_unique_abbr": "Kyushu U;TUT",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Fukuoka;Toyohashi",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "title": "Model-Based Reinforcement Learning Exploiting State-Action Equivalence",
        "site": "https://proceedings.mlr.press/v101/asadi19a.html",
        "author": "Mahsa Asadi; Mohammad Sadegh Talebi; Hippolyte Bourel; Odalric-Ambrym Maillard",
        "abstract": "Leveraging an equivalence property in the state-space of a Markov Decision Process (MDP) has been investigated in several studies. This paper studies equivalence structure in the reinforcement learning (RL) setup, where transition distributions are no longer assumed to be known. We present a notion of similarity between transition probabilities of various state-action pairs of an MDP, which naturally defines an equivalence structure in the state-action space. We present equivalence-aware confidence sets for the case where the learner knows the underlying structure in advance. These sets are provably smaller than their corresponding equivalence-oblivious counterparts. In the more challenging case of an unknown equivalence structure, we present an algorithm called ApproxEquivalence that seeks to find an (approximate) equivalence structure, and define confidence sets using the approximate equivalence. To illustrate the efficacy of the presented confidence sets, we present C-UCRL, as a natural modification of UCRL2 for RL in undiscounted MDPs. In the case of a known equivalence structure, we show that C-UCRL improves over UCRL2 in terms of \\emph{regret} by a factor of $\\sqrt{SA/C}$, in any communicating MDP with $S$ states, $A$ actions, and $C$ classes, which corresponds to a massive improvement when $C\\ll SA$. To the best of our knowledge, this is the first work providing regret bounds for RL when an equivalence structure in the MDP is efficiently exploited. In the case of an unknown equivalence structure, we show through numerical experiments that C-UCRL combined with ApproxEquivalence outperforms UCRL2 in ergodic MDPs.",
        "bibtex": "@InProceedings{pmlr-v101-asadi19a,\n  title = \t {Model-Based Reinforcement Learning Exploiting State-Action Equivalence},\n  author =       {Asadi, Mahsa and Talebi, Mohammad Sadegh and Bourel, Hippolyte and Maillard, Odalric-Ambrym},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {204--219},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/asadi19a/asadi19a.pdf},\n  url = \t {https://proceedings.mlr.press/v101/asadi19a.html},\n  abstract = \t {Leveraging an equivalence property in the state-space of a Markov Decision Process (MDP) has been investigated in several studies. This paper studies equivalence structure in the reinforcement learning (RL) setup, where transition distributions are no longer assumed to be known. We present a notion of similarity between transition probabilities of various state-action pairs of an MDP, which naturally defines an equivalence structure in the state-action space. We present equivalence-aware confidence sets for the case where the learner knows the underlying structure in advance. These sets are provably smaller than their corresponding equivalence-oblivious counterparts. In the more challenging case of an unknown equivalence structure, we present an algorithm called ApproxEquivalence that seeks to find an (approximate) equivalence structure, and define confidence sets using the approximate equivalence. To illustrate the efficacy of the presented confidence sets, we present C-UCRL, as a natural modification of UCRL2 for RL in undiscounted MDPs. In the case of a known equivalence structure, we show that C-UCRL improves over UCRL2 in terms of \\emph{regret} by a factor of $\\sqrt{SA/C}$, in any communicating MDP with $S$ states, $A$ actions, and $C$ classes, which corresponds to a massive improvement when $C\\ll SA$. To the best of our knowledge, this is the first work providing regret bounds for RL when an equivalence structure in the MDP is efficiently exploited. In the case of an unknown equivalence structure, we show through numerical experiments that C-UCRL combined with ApproxEquivalence outperforms UCRL2 in ergodic MDPs.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/asadi19a/asadi19a.pdf",
        "supp": "",
        "pdf_size": 745410,
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7325620981484540027&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 8,
        "aff": "Inria Lille \u2013 Nord Europe; Inria Lille \u2013 Nord Europe; Inria Lille \u2013 Nord Europe; Inria Lille \u2013 Nord Europe",
        "aff_domain": "inria.fr;inria.fr;ens-rennes.fr;inria.fr",
        "email": "inria.fr;inria.fr;ens-rennes.fr;inria.fr",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Inria",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.inria.fr",
        "aff_unique_abbr": "Inria",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Lille",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "title": "Multi-Label Learning with Regularization Enriched Label-Specific Features",
        "site": "https://proceedings.mlr.press/v101/chen19a.html",
        "author": "Ze-Sen Chen; Min-Ling Zhang",
        "abstract": "Multi-label learning learns from examples each associated with multiple class labels simultaneously, and the goal is to induce a predictive model which can assign a set of relevant labels for the unseen instance. Label-specific features serve as an effective strategy towards inducing multi-label predictive model, where the relevancy of each class label is determined by employing tailored features encoding inherent and distinct characteristics of the class label its own. In this paper, a regularization based approach named {\\textsc{Reel}} is proposed for label-specific features generation, which works by enriching label-specific feature representation for each class label via synergizing informative label-specific features from other class labels with sparse regularization. Specifically, full-order label correlations are considered by {\\textsc{Reel}} while the number of classifiers induced for multi-label prediction is linear to the number of class labels. Extensive experiments on fifteen benchmark multi-label data sets clearly show the favorable performance of {\\textsc{Reel}} against other state-of-the-art multi-label learning approaches with label-specific features.",
        "bibtex": "@InProceedings{pmlr-v101-chen19a,\n  title = \t {Multi-Label Learning with Regularization Enriched Label-Specific Features},\n  author =       {Chen, Ze-Sen and Zhang, Min-Ling},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {411--424},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/chen19a/chen19a.pdf},\n  url = \t {https://proceedings.mlr.press/v101/chen19a.html},\n  abstract = \t {Multi-label learning learns from examples each associated with multiple class labels simultaneously, and the goal is to induce a predictive model which can assign a set of relevant labels for the unseen instance. Label-specific features serve as an effective strategy towards inducing multi-label predictive model, where the relevancy of each class label is determined by employing tailored features encoding inherent and distinct characteristics of the class label its own. In this paper, a regularization based approach named {\\textsc{Reel}} is proposed for label-specific features generation, which works by enriching label-specific feature representation for each class label via synergizing informative label-specific features from other class labels with sparse regularization. Specifically, full-order label correlations are considered by {\\textsc{Reel}} while the number of classifiers induced for multi-label prediction is linear to the number of class labels. Extensive experiments on fifteen benchmark multi-label data sets clearly show the favorable performance of {\\textsc{Reel}} against other state-of-the-art multi-label learning approaches with label-specific features.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/chen19a/chen19a.pdf",
        "supp": "",
        "pdf_size": 285958,
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1711401940868019751&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "School of Computer Science and Engineering, Southeast University, Nanjing 210096, China + Key Laboratory of Computer Network and Information Integration (Southeast University), Ministry of Education, China; School of Computer Science and Engineering, Southeast University, Nanjing 210096, China + Key Laboratory of Computer Network and Information Integration (Southeast University), Ministry of Education, China",
        "aff_domain": "SEU.EDU.CN;SEU.EDU.CN",
        "email": "SEU.EDU.CN;SEU.EDU.CN",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+0;0+0",
        "aff_unique_norm": "Southeast University",
        "aff_unique_dep": "School of Computer Science and Engineering",
        "aff_unique_url": "https://www.seu.edu.cn/",
        "aff_unique_abbr": "SEU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Nanjing;",
        "aff_country_unique_index": "0+0;0+0",
        "aff_country_unique": "China"
    },
    {
        "title": "Multi-Scale Visual Semantics Aggregation with Self-Attention for End-to-End Image-Text Matching",
        "site": "https://proceedings.mlr.press/v101/zheng19a.html",
        "author": "Zhuobin Zheng; Youcheng Ben; Chun Yuan",
        "abstract": "The bird community in the mangrove areas is an important component of the mangrove wetlands ecosystem and an indicator species for the assessment of the environmental health status of mangrove wetlands. The classification of bird species by the sound of bird in the mangrove areas has the advantages of less interference to the environment and wide monitoring range. In this paper, we propose a novel method that combines the feature recalibration mechanism with depthwise separable convolution for the mangrove bird sound classification. In the proposed method, we introduce Xception network in which depthwise separable convolution with lower parameter number and computational cost than traditional convolution can be stacked in a residual manner, as the baseline network. And we fuse the feature recalibration mechanism into the depthwise separable convolution for actively learning the weights of the feature channels in the network layer, so that we can enhance the important features in bird sound signals to improve the performance of the classification. In the proposed method, firstly we extract three-channel log-mel features of the bird sound signals and we introduce the mixup method to augment the extracted features. Secondly, we construct the recalibrated feature maps including the different scales of information to get the classification results. To verify the effectiveness of the proposed method, we build a dataset with 9282 samples including 25 kinds of the mangrove birds such as Egretta alba, Parus major, Charadrius dubius, etc. habiting in the mangroves of Fangcheng Port of China, and execute the experiments on the built dataset. Furthermore, we also validate the adaptability of our proposed method on the dataset of TAU Urban Acoustic Scenes 2019, and achieve a better result.",
        "bibtex": "@InProceedings{pmlr-v101-zheng19a,\n  title = \t {Multi-Scale Visual Semantics Aggregation with Self-Attention for End-to-End Image-Text Matching},\n  author =       {Zheng, Zhuobin and Ben, Youcheng and Yuan, Chun},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {940--955},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/zheng19a/zheng19a.pdf},\n  url = \t {https://proceedings.mlr.press/v101/zheng19a.html},\n  abstract = \t {The bird community in the mangrove areas is an important component of the mangrove wetlands ecosystem and an indicator species for the assessment of the environmental health status of mangrove wetlands. The classification of bird species by the sound of bird in the mangrove areas has the advantages of less interference to the environment and wide monitoring range. In this paper, we propose a novel method that combines the feature recalibration mechanism with depthwise separable convolution for the mangrove bird sound classification. In the proposed method, we introduce Xception network in which depthwise separable convolution with lower parameter number and computational cost than traditional convolution can be stacked in a residual manner, as the baseline network. And we fuse the feature recalibration mechanism into the depthwise separable convolution for actively learning the weights of the feature channels in the network layer, so that we can enhance the important features in bird sound signals to improve the performance of the classification. In the proposed method, firstly we extract three-channel log-mel features of the bird sound signals and we introduce the mixup method to augment the extracted features. Secondly, we construct the recalibrated feature maps including the different scales of information to get the classification results. To verify the effectiveness of the proposed method, we build a dataset with 9282 samples including 25 kinds of the mangrove birds such as Egretta alba, Parus major, Charadrius dubius, etc. habiting in the mangroves of Fangcheng Port of China, and execute the experiments on the built dataset. Furthermore, we also validate the adaptability of our proposed method on the dataset of TAU Urban Acoustic Scenes 2019, and achieve a better result.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/zheng19a/zheng19a.pdf",
        "supp": "",
        "pdf_size": 3908537,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1434501763645525001&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "Department of Computer Science and Technologies, Tsinghua University, Beijing, China+Graduate School at Shenzhen, Tsinghua University, Shenzhen, China; Department of Computer Science and Technologies, Tsinghua University, Beijing, China+Graduate School at Shenzhen, Tsinghua University, Shenzhen, China; Graduate School at Shenzhen, Tsinghua University, Shenzhen, China+Peng Cheng Laboratory, Shenzhen, China",
        "aff_domain": "mails.tsinghua.edu.cn;mails.tsinghua.edu.cn;sz.tsinghua.edu.cn",
        "email": "mails.tsinghua.edu.cn;mails.tsinghua.edu.cn;sz.tsinghua.edu.cn",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+0;0+0;0+1",
        "aff_unique_norm": "Tsinghua University;Peng Cheng Laboratory",
        "aff_unique_dep": "Department of Computer Science and Technologies;",
        "aff_unique_url": "https://www.tsinghua.edu.cn;",
        "aff_unique_abbr": "THU;",
        "aff_campus_unique_index": "0+1;0+1;1+1",
        "aff_campus_unique": "Beijing;Shenzhen",
        "aff_country_unique_index": "0+0;0+0;0+0",
        "aff_country_unique": "China"
    },
    {
        "title": "Multi-branch Siamese Network for High Performance Online Visual Tracking",
        "site": "https://proceedings.mlr.press/v101/zhuang19a.html",
        "author": "Junfei Zhuang; Yuan Dong; Hongliang Bai; Gang Wang",
        "abstract": "Recently, Siamese networks have drawn great attention in the visual tracking community because of their balanced accuracy and speed. However, most existing Siamese frameworks describe the target appearance using a global pattern from the last layer, leading to high sensitivity to similar distractors, non-rigid appearance change, and partial occlusion. Addressing these issues, we propose a Multi-branch Siamese network (MSiam) for high-performance object tracking. The MSiam performs layer-wise feature aggregations and simultaneously considers the global-local patterns for more accurate target tracking. In particular, we propose a feature aggregation module (FAM) keeping the heterogeneity of the three types of features, further improving the discriminability of MSiam using both high-level semantic and low-level spatial information. To enhance the adaptability to non-rigid appearance change and partial occlusion, a multi-scale local pattern detection module (LPDM) is designed to identify discriminative regions of the target objects. By considering various combinations of the local structures, our tracker can form various types of structure patterns. Extensive evaluations on five benchmarks demonstrate that the proposed tracking algorithm performs favorably against state-of-the-art methods while running beyond real-time.",
        "bibtex": "@InProceedings{pmlr-v101-zhuang19a,\n  title = \t {Multi-branch Siamese Network for High Performance Online Visual Tracking},\n  author =       {Zhuang, Junfei and Dong, Yuan and Bai, Hongliang and Wang, Gang},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {519--534},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/zhuang19a/zhuang19a.pdf},\n  url = \t {https://proceedings.mlr.press/v101/zhuang19a.html},\n  abstract = \t {Recently, Siamese networks have drawn great attention in the visual tracking community because of their balanced accuracy and speed. However, most existing Siamese frameworks describe the target appearance using a global pattern from the last layer, leading to high sensitivity to similar distractors, non-rigid appearance change, and partial occlusion. Addressing these issues, we propose a Multi-branch Siamese network (MSiam) for high-performance object tracking. The MSiam performs layer-wise feature aggregations and simultaneously considers the global-local patterns for more accurate target tracking. In particular, we propose a feature aggregation module (FAM) keeping the heterogeneity of the three types of features, further improving the discriminability of MSiam using both high-level semantic and low-level spatial information. To enhance the adaptability to non-rigid appearance change and partial occlusion, a multi-scale local pattern detection module (LPDM) is designed to identify discriminative regions of the target objects. By considering various combinations of the local structures, our tracker can form various types of structure patterns. Extensive evaluations on five benchmarks demonstrate that the proposed tracking algorithm performs favorably against state-of-the-art methods while running beyond real-time.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/zhuang19a/zhuang19a.pdf",
        "supp": "",
        "pdf_size": 1091167,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3892568763029594333&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Beijing University of Posts and Telecommunications; Beijing University of Posts and Telecommunications; Beijing Faceall Technology Co.,Ltd; Ricoh software research center (Beijing) co. Ltd",
        "aff_domain": "bupt.edu.cn;bupt.edu.cn;faceall.cn;srcb.ricoh.com",
        "email": "bupt.edu.cn;bupt.edu.cn;faceall.cn;srcb.ricoh.com",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;2",
        "aff_unique_norm": "Beijing University of Posts and Telecommunications;Faceall Technology;Ricoh Software Research Center",
        "aff_unique_dep": ";;",
        "aff_unique_url": "http://www.bupt.edu.cn/;;https://www.ricoh.com",
        "aff_unique_abbr": "BUPT;;",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Beijing;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "title": "Multi-modal Representation Learning for Successive POI Recommendation",
        "site": "https://proceedings.mlr.press/v101/li19a.html",
        "author": "Lishan Li; Ying Liu; Jianping Wu; Lin He; Gang Ren",
        "abstract": "Successive POI recommendation is a fundamental problem for location-based social networks (LBSNs). POI recommendation takes a variety of POI context information (e.g. spatial location and textual comment) and user preference into consideration. Existing POI recommendation systems mainly focus on part of the POI context and user preference with a specific modeling, which loses valuable information from other aspects. In this paper, we propose to construct a multi-modal check-in graph, a heterogeneous graph that combines five check-in aspects in a unified way. We further propose a multi-modal representation learning model based on the graph to jointly learn POI and user representations. Finally, we employ an attentional recurrent neural network based on the representations for successive POI recommendation. Experiments on a public dataset studies the effects of modeling different aspects of check-in records and demonstrates the effectiveness of the method in improving POI recommendation performance.",
        "bibtex": "@InProceedings{pmlr-v101-li19a,\n  title = \t {Multi-modal Representation Learning for Successive POI Recommendation},\n  author =       {Li, Lishan and Liu, Ying and Wu, Jianping and He, Lin and Ren, Gang},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {441--456},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/li19a/li19a.pdf},\n  url = \t {https://proceedings.mlr.press/v101/li19a.html},\n  abstract = \t {Successive POI recommendation is a fundamental problem for location-based social networks (LBSNs). POI recommendation takes a variety of POI context information (e.g. spatial location and textual comment) and user preference into consideration. Existing POI recommendation systems mainly focus on part of the POI context and user preference with a specific modeling, which loses valuable information from other aspects. In this paper, we propose to construct a multi-modal check-in graph, a heterogeneous graph that combines five check-in aspects in a unified way. We further propose a multi-modal representation learning model based on the graph to jointly learn POI and user representations. Finally, we employ an attentional recurrent neural network based on the representations for successive POI recommendation. Experiments on a public dataset studies the effects of modeling different aspects of check-in records and demonstrates the effectiveness of the method in improving POI recommendation performance.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/li19a/li19a.pdf",
        "supp": "",
        "pdf_size": 429981,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8111415351053571501&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "Tsinghua University; Tsinghua University; Tsinghua University; Tsinghua University; Tsinghua University",
        "aff_domain": "mails.tsinghua.edu.cn;cernet.edu.cn;cernet.edu.cn;gmail.com;cernet.edu.cn",
        "email": "mails.tsinghua.edu.cn;cernet.edu.cn;cernet.edu.cn;gmail.com;cernet.edu.cn",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Tsinghua University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "THU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "title": "Multi-width Activation and Multiple Receptive Field Networks for Dynamic Scene Deblurring",
        "site": "https://proceedings.mlr.press/v101/cui19b.html",
        "author": "Jinkai Cui; Weihong Li; Wei Guo; Weiguo Gong",
        "abstract": "In this paper, we propose an end-to-end multi-width activation and multiple receptive field networks for the large-scale and complicated dynamic scene deblurring. Firstly, we design a multi-width activation feature extraction module, in which a multi-width activation residual block is proposed for making the activation function learn more the nonlinear information and extracting wider nonlinear features. Secondly, we design a multiple receptive field (RF) feature extraction module, in which a multiple RF residual block is proposed for enlarging the RF efficiently and capturing more nonlinear information from distant locations. And then, we design the multi-scale feature fusion module, where a learning fusion structure is designed to adaptively fuse the multi-scale features and complicated blur information from the different modules. Finally, we use a multi-component loss function to jointly optimize our networks. Extensive experimental results demonstrate that the proposed method outperforms the recent state-of-the-art deblurring methods, both quantitatively and qualitatively.",
        "bibtex": "@InProceedings{pmlr-v101-cui19b,\n  title = \t {Multi-width Activation and Multiple Receptive Field Networks for Dynamic Scene Deblurring},\n  author =       {Cui, Jinkai and Li, Weihong and Guo, Wei and Gong, Weiguo},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {852--867},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/cui19b/cui19b.pdf},\n  url = \t {https://proceedings.mlr.press/v101/cui19b.html},\n  abstract = \t {In this paper, we propose an end-to-end multi-width activation and multiple receptive field networks for the large-scale and complicated dynamic scene deblurring. Firstly, we design a multi-width activation feature extraction module, in which a multi-width activation residual block is proposed for making the activation function learn more the nonlinear information and extracting wider nonlinear features. Secondly, we design a multiple receptive field (RF) feature extraction module, in which a multiple RF residual block is proposed for enlarging the RF efficiently and capturing more nonlinear information from distant locations. And then, we design the multi-scale feature fusion module, where a learning fusion structure is designed to adaptively fuse the multi-scale features and complicated blur information from the different modules. Finally, we use a multi-component loss function to jointly optimize our networks. Extensive experimental results demonstrate that the proposed method outperforms the recent state-of-the-art deblurring methods, both quantitatively and qualitatively.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/cui19b/cui19b.pdf",
        "supp": "",
        "pdf_size": 9205196,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:4oGNZMXwNCYJ:scholar.google.com/&scioq=Multi-width+Activation+and+Multiple+Receptive+Field+Networks+for+Dynamic+Scene+Deblurring&hl=en&as_sdt=0,5",
        "gs_version_total": 3,
        "aff": "Key Lab of Optoelectronic Technology and Systems of Education Ministry, College of Optoelectronic Engineering, Chongqing University, Chongqing, China; Key Lab of Optoelectronic Technology and Systems of Education Ministry, College of Optoelectronic Engineering, Chongqing University, Chongqing, China; Key Lab of Optoelectronic Technology and Systems of Education Ministry, College of Optoelectronic Engineering, Chongqing University, Chongqing, China; Key Lab of Optoelectronic Technology and Systems of Education Ministry, College of Optoelectronic Engineering, Chongqing University, Chongqing, China",
        "aff_domain": "cqu.edu.cn;cqu.edu.cn;cqu.edu.cn;cqu.edu.cn",
        "email": "cqu.edu.cn;cqu.edu.cn;cqu.edu.cn;cqu.edu.cn",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Chongqing University",
        "aff_unique_dep": "College of Optoelectronic Engineering",
        "aff_unique_url": "http://www.cqu.edu.cn/",
        "aff_unique_abbr": "CQU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Chongqing",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "title": "Multiple Empirical Kernel Learning with Discriminant Locality Preservation",
        "site": "https://proceedings.mlr.press/v101/wang19b.html",
        "author": "Bolu Wang; Dongdong Li; Zhe Wang",
        "abstract": "Multiple Kernel Learning (MKL) algorithm effectively combines different kernels to improve the performance of classification. Most MKL algorithms implicitly map samples into feature space by the form of inner-product. In contrast, Multiple Empirical Kernel Learning (MEKL) can explicitly map the input spaces into feature spaces so that the mapped feature vectors are explicitly represented, which is easy to process and analyze the adaptability of kernels for input space. Meanwhile, in order to pay attention to the structure and discriminant information of samples in empirical feature space, inspired by discriminant locality preserving projections, we introduce the discriminant locality preservation regularization into MEKL framework to propose the Multiple Empirical Kernel Learning with Discriminant Locality Preservation (MEKL-DLP). Experiments conducted on real-world datasets validate the effectiveness of the proposed MEKL-DLP compared with the classical kernel-based algorithms and state-of-art MKL algorithms.",
        "bibtex": "@InProceedings{pmlr-v101-wang19b,\n  title = \t {Multiple Empirical Kernel Learning with Discriminant Locality Preservation},\n  author =       {Wang, Bolu and Li, Dongdong and Wang, Zhe},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {80--93},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/wang19b/wang19b.pdf},\n  url = \t {https://proceedings.mlr.press/v101/wang19b.html},\n  abstract = \t {Multiple Kernel Learning (MKL) algorithm effectively combines different kernels to improve the performance of classification. Most MKL algorithms implicitly map samples into feature space by the form of inner-product. In contrast, Multiple Empirical Kernel Learning (MEKL) can explicitly map the input spaces into feature spaces so that the mapped feature vectors are explicitly represented, which is easy to process and analyze the adaptability of kernels for input space. Meanwhile, in order to pay attention to the structure and discriminant information of samples in empirical feature space, inspired by discriminant locality preserving projections, we introduce the discriminant locality preservation regularization into MEKL framework to propose the Multiple Empirical Kernel Learning with Discriminant Locality Preservation (MEKL-DLP). Experiments conducted on real-world datasets validate the effectiveness of the proposed MEKL-DLP compared with the classical kernel-based algorithms and state-of-art MKL algorithms.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/wang19b/wang19b.pdf",
        "supp": "",
        "pdf_size": 293467,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:I5lKQFSy4UwJ:scholar.google.com/&scioq=Multiple+Empirical+Kernel+Learning+with+Discriminant+Locality+Preservation&hl=en&as_sdt=0,33",
        "gs_version_total": 3,
        "aff": "East China University of Science and Technology, China; East China University of Science and Technology, China; East China University of Science and Technology, China",
        "aff_domain": "foxmail.com;ecust.edu.cn;ecust.edu.cn",
        "email": "foxmail.com;ecust.edu.cn;ecust.edu.cn",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "East China University of Science and Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "http://www.ecust.edu.cn",
        "aff_unique_abbr": "ECUST",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "title": "Multivariate Time Series Prediction Based on Optimized Temporal Convolutional Networks with Stacked Auto-encoders",
        "site": "https://proceedings.mlr.press/v101/wang19c.html",
        "author": "Yunxiao Wang; Zheng Liu; Di Hu; Mian Zhang",
        "abstract": "Multivariate time series prediction has recently attracted extensive research attention due to its wide applications in the area of financial investment, energy consumption, environmental pollution and so on. Because of the temporal complexity and nonlinearity existing in multivariate time series, few existing models could provide satisfactory prediction results. In this paper, we proposed a novel prediction approach based on optimized temporal convolutional networks with stacked auto-encoders, which can achieve better prediction performance as demonstrated in the experiments. Stacked auto-encoders are employed to extract effective features from complex multivariate time series. A temporal convolutional network is then constructed serving as the prediction model, which has a flexible receptive field and enjoys faster training speed with parallel computing ability than recurrent neural networks. The optimal hyperparameters in these models are discovered by Bayesian optimization. We performed extensive experiments by comparing the proposed algorithms and other popular algorithms on three different datasets, where the proposed approach obtain the best prediction results in various prediction horizons. In addition, we carefully analyze the search process of Bayesian optimization and provide further insights into hyperparametric tuning processes combining the exploration strategy with the exploitation strategy.",
        "bibtex": "@InProceedings{pmlr-v101-wang19c,\n  title = \t {Multivariate Time Series Prediction Based on Optimized Temporal Convolutional Networks with Stacked Auto-encoders},\n  author =       {Wang, Yunxiao and Liu, Zheng and Hu, Di and Zhang, Mian},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {157--172},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/wang19c/wang19c.pdf},\n  url = \t {https://proceedings.mlr.press/v101/wang19c.html},\n  abstract = \t {Multivariate time series prediction has recently attracted extensive research attention due to its wide applications in the area of financial investment, energy consumption, environmental pollution and so on. Because of the temporal complexity and nonlinearity existing in multivariate time series, few existing models could provide satisfactory prediction results. In this paper, we proposed a novel prediction approach based on optimized temporal convolutional networks with stacked auto-encoders, which can achieve better prediction performance as demonstrated in the experiments. Stacked auto-encoders are employed to extract effective features from complex multivariate time series. A temporal convolutional network is then constructed serving as the prediction model, which has a flexible receptive field and enjoys faster training speed with parallel computing ability than recurrent neural networks. The optimal hyperparameters in these models are discovered by Bayesian optimization. We performed extensive experiments by comparing the proposed algorithms and other popular algorithms on three different datasets, where the proposed approach obtain the best prediction results in various prediction horizons. In addition, we carefully analyze the search process of Bayesian optimization and provide further insights into hyperparametric tuning processes combining the exploration strategy with the exploitation strategy.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/wang19c/wang19c.pdf",
        "supp": "",
        "pdf_size": 836007,
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10660513294041072150&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "Jiangsu Key Laboratory of Big Data Security and Intelligent Processing, School of Computer Science, Nanjing University of Posts and Telecommunications, China; Jiangsu Key Laboratory of Big Data Security and Intelligent Processing, School of Computer Science, Nanjing University of Posts and Telecommunications, China; Jiangsu Key Laboratory of Big Data Security and Intelligent Processing, School of Computer Science, Nanjing University of Posts and Telecommunications, China; Jiangsu Key Laboratory of Big Data Security and Intelligent Processing, School of Computer Science, Nanjing University of Posts and Telecommunications, China",
        "aff_domain": "qq.com;njupt.edu.cn;qq.com;gmail.com",
        "email": "qq.com;njupt.edu.cn;qq.com;gmail.com",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Nanjing University of Posts and Telecommunications",
        "aff_unique_dep": "School of Computer Science",
        "aff_unique_url": "http://www.njupt.edu.cn",
        "aff_unique_abbr": "NUPT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "title": "Nuclei segmentation by using convolutional network with distance map and contour information",
        "site": "https://proceedings.mlr.press/v101/liu19a.html",
        "author": "Xiaoming Liu; Zhengsheng Guo; Bo Li; Jun Cao",
        "abstract": "Accurate access to nuclear information on digital pathology images can assist physicians in diagnosis and subsequent treatment. The pathological images have a large number of nuclei and part of nuclei is touching, manual segmentation is time consuming and error prone. Therefore it is an important task to develop a accurate nuclei segmentation method. For traditional methods, it is hard to obtain a accurately nuclei segmentation result, because the nuclei have many different characterizations. In this paper, we propose a new nuclei segmentation method (MDC-Net), which is a deep fully convolutional network. The network contains multiple residual operations to reduce detail loss in image. In addition, dilated convolution which has different dilation ratio is used to increase receptive field. MDC-Net contains the distance map and contour image, enhancing information on individual nuclei to get accurate segmentation results. We improve the segmentation effect by using the post-processing operate. We demonstrate that MDC-Net can obtain state-of-the-art results on public dataset with multiple organ slices compared with other popular methods.",
        "bibtex": "@InProceedings{pmlr-v101-liu19a,\n  title = \t {Nuclei segmentation by using convolutional network with distance map and contour information},\n  author =       {Liu, Xiaoming and Guo, Zhengsheng and Li, Bo and Cao, Jun},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {972--986},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/liu19a/liu19a.pdf},\n  url = \t {https://proceedings.mlr.press/v101/liu19a.html},\n  abstract = \t {Accurate access to nuclear information on digital pathology images can assist physicians in diagnosis and subsequent treatment. The pathological images have a large number of nuclei and part of nuclei is touching, manual segmentation is time consuming and error prone. Therefore it is an important task to develop a accurate nuclei segmentation method. For traditional methods, it is hard to obtain a accurately nuclei segmentation result, because the nuclei have many different characterizations. In this paper, we propose a new nuclei segmentation method (MDC-Net), which is a deep fully convolutional network. The network contains multiple residual operations to reduce detail loss in image. In addition, dilated convolution which has different dilation ratio is used to increase receptive field. MDC-Net contains the distance map and contour image, enhancing information on individual nuclei to get accurate segmentation results. We improve the segmentation effect by using the post-processing operate. We demonstrate that MDC-Net can obtain state-of-the-art results on public dataset with multiple organ slices compared with other popular methods.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/liu19a/liu19a.pdf",
        "supp": "",
        "pdf_size": 1565947,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18070768476643448433&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "College of Computer Science and Technology, Wuhan University of Science and technology, Wuhan, 430065, China + Hubei Province Key Laboratory of Intelligent Information Processing and Real-time Industrial System, Wuhan, 430065, China; College of Computer Science and Technology, Wuhan University of Science and technology, Wuhan, 430065, China + Hubei Province Key Laboratory of Intelligent Information Processing and Real-time Industrial System, Wuhan, 430065, China; College of Computer Science and Technology, Wuhan University of Science and technology, Wuhan, 430065, China + Hubei Province Key Laboratory of Intelligent Information Processing and Real-time Industrial System, Wuhan, 430065, China; College of Computer Science and Technology, Wuhan University of Science and technology, Wuhan, 430065, China + Hubei Province Key Laboratory of Intelligent Information Processing and Real-time Industrial System, Wuhan, 430065, China",
        "aff_domain": "gmail.com;163.com;126.com;gmail.com",
        "email": "gmail.com;163.com;126.com;gmail.com",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;0+1;0+1;0+1",
        "aff_unique_norm": "Wuhan University of Science and Technology;Hubei Province Key Laboratory of Intelligent Information Processing and Real-time Industrial System",
        "aff_unique_dep": "College of Computer Science and Technology;Intelligent Information Processing and Real-time Industrial System",
        "aff_unique_url": "http://www.wust.edu.cn;",
        "aff_unique_abbr": "WUST;",
        "aff_campus_unique_index": "0+0;0+0;0+0;0+0",
        "aff_campus_unique": "Wuhan",
        "aff_country_unique_index": "0+0;0+0;0+0;0+0",
        "aff_country_unique": "China"
    },
    {
        "title": "Optimal PAC-Bayesian Posteriors for Stochastic Classifiers and their use for Choice of SVM Regularization Parameter",
        "site": "https://proceedings.mlr.press/v101/sahu19a.html",
        "author": "Puja Sahu; Nandyala Hemachandra",
        "abstract": "PAC-Bayesian set up involves a stochastic classifier characterized by a posterior distribution on a classifier set, offers a high probability bound on its averaged true risk and is robust to the training sample used. For a given posterior, this bound captures the trade off between averaged empirical risk and KL-divergence based model complexity term. Our goal is to identify an optimal posterior with the least PAC-Bayesian bound. We consider a finite classifier set and 5 distance functions: KL-divergence, its Pinsker\u2019s and a sixth degree polynomial approximations; linear and squared distances. Linear distance based model results in a convex optimization problem and we obtain a closed form expression for its optimal posterior. For uniform prior, this posterior has full support with weights negative-exponentially proportional to number of misclassifications. Squared distance and Pinsker\u2019s approximation bounds are possibly quasi-convex and are observed to have single local minimum. We derive fixed point equations (FPEs) using partial KKT system with strict positivity constraints. This obviates the combinatorial search for subset support of the optimal posterior. For uniform prior, exponential search on a full-dimensional simplex can be limited to an ordered subset of classifiers with increasing empirical risk values. These FPEs converge rapidly to a stationary point, even for a large classifier set when a solver fails. We apply these approaches to SVMs generated using a finite set of SVM regularization parameter values on 9 UCI datasets. The resulting optimal posteriors (on the set of regularization parameters) yield stochastic SVM classifiers with tight bounds. KL-divergence based bound is the tightest, but is computationally expensive due to its non-convex nature and multiple calls to a root finding algorithm. Optimal posteriors for all 5 distance functions have lowest 10% test error values on most datasets, with that of linear distance being the easiest to obtain.",
        "bibtex": "@InProceedings{pmlr-v101-sahu19a,\n  title = \t {Optimal PAC-Bayesian Posteriors for Stochastic Classifiers and their use for Choice of SVM Regularization Parameter},\n  author =       {Sahu, Puja and Hemachandra, Nandyala},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {268--283},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/sahu19a/sahu19a.pdf},\n  url = \t {https://proceedings.mlr.press/v101/sahu19a.html},\n  abstract = \t {PAC-Bayesian set up involves a stochastic classifier characterized by a posterior distribution on a classifier set, offers a high probability bound on its averaged true risk and is robust to the training sample used. For a given posterior, this bound captures the trade off between averaged empirical risk and KL-divergence based model complexity term. Our goal is to identify an optimal posterior with the least PAC-Bayesian bound. We consider a finite classifier set and 5 distance functions: KL-divergence, its Pinsker\u2019s and a sixth degree polynomial approximations; linear and squared distances. Linear distance based model results in a convex optimization problem and we obtain a closed form expression for its optimal posterior. For uniform prior, this posterior has full support with weights negative-exponentially proportional to number of misclassifications. Squared distance and Pinsker\u2019s approximation bounds are possibly quasi-convex and are observed to have single local minimum. We derive fixed point equations (FPEs) using partial KKT system with strict positivity constraints. This obviates the combinatorial search for subset support of the optimal posterior. For uniform prior, exponential search on a full-dimensional simplex can be limited to an ordered subset of classifiers with increasing empirical risk values. These FPEs converge rapidly to a stationary point, even for a large classifier set when a solver fails. We apply these approaches to SVMs generated using a finite set of SVM regularization parameter values on 9 UCI datasets. The resulting optimal posteriors (on the set of regularization parameters) yield stochastic SVM classifiers with tight bounds. KL-divergence based bound is the tightest, but is computationally expensive due to its non-convex nature and multiple calls to a root finding algorithm. Optimal posteriors for all 5 distance functions have lowest 10% test error values on most datasets, with that of linear distance being the easiest to obtain.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/sahu19a/sahu19a.pdf",
        "supp": "",
        "pdf_size": 483985,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16633409304224812470&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Indian Institute of Technology Bombay, Mumbai, India; Indian Institute of Technology Bombay, Mumbai, India",
        "aff_domain": "iitb.ac.in;iitb.ac.in",
        "email": "iitb.ac.in;iitb.ac.in",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Indian Institute of Technology Bombay",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.iitb.ac.in",
        "aff_unique_abbr": "IIT Bombay",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Mumbai",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "India"
    },
    {
        "title": "Prediction of Crowd Flow in City Complex with Missing Data",
        "site": "https://proceedings.mlr.press/v101/qiu19a.html",
        "author": "Shiyang Qiu; Peng Xu; Wei Zheng; Junjie Wang; Guo Yu; Mingyao Hou; Hengchang Liu",
        "abstract": "Crowd flow forecasting plays an important role in risk assessment and public safety. It is a difficult task due to complex spatial-temporal dependencies as well as missing values in data. A number of models are proposed to predict crowd flow on city-scale, yet the missing pattern in city complex environment is seldomly considered. We propose a crowd flow forecasting model, Imputed Spatial-Temporal Convolution network(ISTC) to accurately predict the crowd flow in large complex buildings. ISTC uses convolution layers, whose structures are configured by graphs, to model the spatial-temporal correlations. Meanwhile ISTC adds imputation layers to handle the missing data. We demonstrate our model on several real data sets collected from sensors in a large six-floor commercial complex building. The results show that ISTC outperforms the baseline methods and is capable of handling data with as much as 40% missing data.",
        "bibtex": "@InProceedings{pmlr-v101-qiu19a,\n  title = \t {Prediction of Crowd Flow in City Complex with Missing Data},\n  author =       {Qiu, Shiyang and Xu, Peng and Zheng, Wei and Wang, Junjie and Yu, Guo and Hou, Mingyao and Liu, Hengchang},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {758--773},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/qiu19a/qiu19a.pdf},\n  url = \t {https://proceedings.mlr.press/v101/qiu19a.html},\n  abstract = \t {Crowd flow forecasting plays an important role in risk assessment and public safety. It is a difficult task due to complex spatial-temporal dependencies as well as missing values in data. A number of models are proposed to predict crowd flow on city-scale, yet the missing pattern in city complex environment is seldomly considered. We propose a crowd flow forecasting model, Imputed Spatial-Temporal Convolution network(ISTC) to accurately predict the crowd flow in large complex buildings. ISTC uses convolution layers, whose structures are configured by graphs, to model the spatial-temporal correlations. Meanwhile ISTC adds imputation layers to handle the missing data. We demonstrate our model on several real data sets collected from sensors in a large six-floor commercial complex building. The results show that ISTC outperforms the baseline methods and is capable of handling data with as much as 40% missing data.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/qiu19a/qiu19a.pdf",
        "supp": "",
        "pdf_size": 1039535,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17285047768776788530&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "aff": "University of Science and Technology of China; University of Science and Technology of China; Kehang Technology and Information; University of Science and Technology of China; China People\u2019s Police University; Kehang Technology and Information; University of Science and Technology of China",
        "aff_domain": "mail.ustc.edu.cn;gmail.com;comprehend.com.cn;mail.ustc.edu.cn;qq.com;comprehend.com.cn;ustc.edu.cn",
        "email": "mail.ustc.edu.cn;gmail.com;comprehend.com.cn;mail.ustc.edu.cn;qq.com;comprehend.com.cn;ustc.edu.cn",
        "github": "",
        "project": "",
        "author_num": 7,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;0;2;1;0",
        "aff_unique_norm": "University of Science and Technology of China;Kehang Technology and Information;China People's Police University",
        "aff_unique_dep": ";;",
        "aff_unique_url": "http://www.ustc.edu.cn;;http://www.cppu.edu.cn",
        "aff_unique_abbr": "USTC;;CPPU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "title": "Random Projection in Neural Episodic Control",
        "site": "https://proceedings.mlr.press/v101/nishio19a.html",
        "author": "Daichi Nishio; Satoshi Yamane",
        "abstract": "End-to-end deep reinforcement learning has enabled agents to learn with little preprocessing by humans. However, it is still difficult to learn stably and efficiently because the learning method usually uses a nonlinear function approximation. Neural Episodic Control (NEC), which has been proposed in order to improve sample efficiency, is able to learn stably by estimating action values using a non-parametric method. In this paper, we propose an architecture that incorporates random projection into NEC to train with more stability. In addition, we verify the effectiveness of our architecture by Atari\u2019s five games. The main idea is to reduce the number of parameters that have to learn by replacing neural networks with random projection in order to reduce dimensions while keeping the learning end-to-end.",
        "bibtex": "@InProceedings{pmlr-v101-nishio19a,\n  title = \t {Random Projection in Neural Episodic Control},\n  author =       {Nishio, Daichi and Yamane, Satoshi},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {1--15},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/nishio19a/nishio19a.pdf},\n  url = \t {https://proceedings.mlr.press/v101/nishio19a.html},\n  abstract = \t {End-to-end deep reinforcement learning has enabled agents to learn with little preprocessing by humans. However, it is still difficult to learn stably and efficiently because the learning method usually uses a nonlinear function approximation. Neural Episodic Control (NEC), which has been proposed in order to improve sample efficiency, is able to learn stably by estimating action values using a non-parametric method. In this paper, we propose an architecture that incorporates random projection into NEC to train with more stability. In addition, we verify the effectiveness of our architecture by Atari\u2019s five games. The main idea is to reduce the number of parameters that have to learn by replacing neural networks with random projection in order to reduce dimensions while keeping the learning end-to-end.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/nishio19a/nishio19a.pdf",
        "supp": "",
        "pdf_size": 424826,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18441837390779385006&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Kanazawa University, Ishikawa, Japan; Kanazawa University, Ishikawa, Japan",
        "aff_domain": "csl.ec.t.kanazawa-u.ac.jp;is.t.kanazawa-u.ac.jp",
        "email": "csl.ec.t.kanazawa-u.ac.jp;is.t.kanazawa-u.ac.jp",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Kanazawa University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.kanazawa-u.ac.jp",
        "aff_unique_abbr": "KU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Ishikawa",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "title": "Real-time tree search with pessimistic scenarios: Winning the NeurIPS 2018 Pommerman Competition",
        "site": "https://proceedings.mlr.press/v101/osogami19a.html",
        "author": "Takayuki Osogami; Toshihiro Takahashi",
        "abstract": "Autonomous agents need to make decisions in a sequential manner, under partially observable environment, and in consideration of how other agents behave. In critical situations, such decisions need to be made in real time for example to avoid collisions and recover to safe conditions. We propose a technique of tree search where a deterministic and pessimistic scenario is used after a specified depth. Because there is no branching with the deterministic scenario, the proposed technique allows us to take into account the events that can occur far ahead in the future. The effectiveness of the proposed technique is demonstrated in Pommerman, a multi-agent environment used in a NeurIPS 2018 competition, where the agents that implement the proposed technique have won the first and third places.",
        "bibtex": "@InProceedings{pmlr-v101-osogami19a,\n  title = \t {Real-time tree search with pessimistic scenarios: Winning the NeurIPS 2018 Pommerman Competition},\n  author =       {Osogami, Takayuki and Takahashi, Toshihiro},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {583--598},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/osogami19a/osogami19a.pdf},\n  url = \t {https://proceedings.mlr.press/v101/osogami19a.html},\n  abstract = \t {Autonomous agents need to make decisions in a sequential manner, under partially observable environment, and in consideration of how other agents behave. In critical situations, such decisions need to be made in real time for example to avoid collisions and recover to safe conditions. We propose a technique of tree search where a deterministic and pessimistic scenario is used after a specified depth. Because there is no branching with the deterministic scenario, the proposed technique allows us to take into account the events that can occur far ahead in the future. The effectiveness of the proposed technique is demonstrated in Pommerman, a multi-agent environment used in a NeurIPS 2018 competition, where the agents that implement the proposed technique have won the first and third places.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/osogami19a/osogami19a.pdf",
        "supp": "",
        "pdf_size": 431697,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8540678773450183775&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "IBM Research - Tokyo; IBM Research - Tokyo",
        "aff_domain": "jp.ibm.com;jp.ibm.com",
        "email": "jp.ibm.com;jp.ibm.com",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "IBM Research",
        "aff_unique_dep": "Research",
        "aff_unique_url": "https://www.ibm.com/research",
        "aff_unique_abbr": "IBM",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "title": "Realistic Image Generation using Region-phrase Attention",
        "site": "https://proceedings.mlr.press/v101/huang19a.html",
        "author": "Wanming Huang; Richard Yi Da Xu; Ian Oppermann",
        "abstract": "The Generative Adversarial Network (GAN) has achieved remarkable progress in generating synthetic images from text, especially since the use of the attention mechanism. The current state-of-the-art algorithm applies attentions between individual regular-grid regions of an image and words of a sentence. These approaches are sufficient to generate images that contain a single object in its foreground. However, natural languages often involve complex foreground objects and the background may also constitute a variable portion of the generated image. In this case, the regular-grid region based image attention weights may not necessarily concentrate on the intended foreground region(s), which in turn, results in an unnatural looking image. Additionally, individual words such as \u201ca\u201d, \u201cblue\u201d and \u201cshirt\u201d do not necessarily provide a full visual context unless they are applied together. For this reason, in our paper, we proposed a novel method in which we introduced an additional set of natural attentions between object-grid regions and word phrases. The object-grid region is defined by a set of auxiliary bounding boxes. They serve as superior location indicators to where the alignment and attention should be drawn with the word phrases. We perform experiments on the Microsoft Common Objects in Context (MSCOCO) dataset and prove that our proposed approach is capable of generating more realistic images compared with the current state-of-the-art algorithms.",
        "bibtex": "@InProceedings{pmlr-v101-huang19a,\n  title = \t {Realistic Image Generation using Region-phrase Attention},\n  author =       {Huang, Wanming and Xu, Richard Yi Da and Oppermann, Ian},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {284--299},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/huang19a/huang19a.pdf},\n  url = \t {https://proceedings.mlr.press/v101/huang19a.html},\n  abstract = \t {The Generative Adversarial Network (GAN) has achieved remarkable progress in generating synthetic images from text, especially since the use of the attention mechanism. The current state-of-the-art algorithm applies attentions between individual regular-grid regions of an image and words of a sentence. These approaches are sufficient to generate images that contain a single object in its foreground. However, natural languages often involve complex foreground objects and the background may also constitute a variable portion of the generated image. In this case, the regular-grid region based image attention weights may not necessarily concentrate on the intended foreground region(s), which in turn, results in an unnatural looking image. Additionally, individual words such as \u201ca\u201d, \u201cblue\u201d and \u201cshirt\u201d do not necessarily provide a full visual context unless they are applied together. For this reason, in our paper, we proposed a novel method in which we introduced an additional set of natural attentions between object-grid regions and word phrases. The object-grid region is defined by a set of auxiliary bounding boxes. They serve as superior location indicators to where the alignment and attention should be drawn with the word phrases. We perform experiments on the Microsoft Common Objects in Context (MSCOCO) dataset and prove that our proposed approach is capable of generating more realistic images compared with the current state-of-the-art algorithms.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/huang19a/huang19a.pdf",
        "supp": "",
        "pdf_size": 6694349,
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1462882319803615941&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Faculty of Engineering and IT, University of Technology Sydney; Faculty of Engineering and IT, University of Technology Sydney; NSW Data Analytics Centre",
        "aff_domain": "student.uts.edu.au;uts.edu.au;outlook.com",
        "email": "student.uts.edu.au;uts.edu.au;outlook.com",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "University of Technology Sydney;NSW Data Analytics Centre",
        "aff_unique_dep": "Faculty of Engineering and IT;",
        "aff_unique_url": "https://www.uts.edu.au;https://data.nsw.gov.au/",
        "aff_unique_abbr": "UTS;",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Sydney;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "title": "Regularizing Neural Networks via Stochastic Branch Layers",
        "site": "https://proceedings.mlr.press/v101/park19a.html",
        "author": "Wonpyo Park; Paul Hongsuck Seo; Bohyung Han; Minsu Cho",
        "abstract": "We introduce a novel stochastic regularization technique for deep neural networks, which decomposes a layer into multiple branches with different parameters and merges stochastically sampled combinations of the outputs from the branches during training. Since the factorized branches can collapse into a single branch through a linear operation, inference requires no additional complexity compared to the ordinary layers. The proposed regularization method, referred to as StochasticBranch, is applicable to any linear layers such as fully-connected or convolution layers. The proposed regularizer allows the model to explore diverse regions of the model parameter space via multiple combinations of branches to find better local minima. An extensive set of experiments shows that our method effectively regularizes networks and further improves the generalization performance when used together with other existing regularization techniques.",
        "bibtex": "@InProceedings{pmlr-v101-park19a,\n  title = \t {Regularizing Neural Networks via Stochastic Branch Layers},\n  author =       {Park, Wonpyo and Seo, Paul Hongsuck and Han, Bohyung and Cho, Minsu},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {678--693},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/park19a/park19a.pdf},\n  url = \t {https://proceedings.mlr.press/v101/park19a.html},\n  abstract = \t {We introduce a novel stochastic regularization technique for deep neural networks, which decomposes a layer into multiple branches with different parameters and merges stochastically sampled combinations of the outputs from the branches during training. Since the factorized branches can collapse into a single branch through a linear operation, inference requires no additional complexity compared to the ordinary layers. The proposed regularization method, referred to as StochasticBranch, is applicable to any linear layers such as fully-connected or convolution layers. The proposed regularizer allows the model to explore diverse regions of the model parameter space via multiple combinations of branches to find better local minima. An extensive set of experiments shows that our method effectively regularizes networks and further improves the generalization performance when used together with other existing regularization techniques.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/park19a/park19a.pdf",
        "supp": "",
        "pdf_size": 803376,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:kmCaFlEfSiUJ:scholar.google.com/&scioq=Regularizing+Neural+Networks+via+Stochastic+Branch+Layers&hl=en&as_sdt=0,33",
        "gs_version_total": 5,
        "aff": "Computer Vision Lab, CSE, POSTECH + Kakao Corporation; Computer Vision Lab, CSE, POSTECH + Computer Vision Lab, ECE & ASRI, Seoul National University; Computer Vision Lab, ECE & ASRI, Seoul National University + The Neural Processing Research Center; Computer Vision Lab, CSE, POSTECH + The Neural Processing Research Center",
        "aff_domain": "postech.ac.kr;postech.ac.kr;snu.ac.kr;postech.ac.kr",
        "email": "postech.ac.kr;postech.ac.kr;snu.ac.kr;postech.ac.kr",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;0+2;2+3;0+3",
        "aff_unique_norm": "POSTECH;Kakao Corporation;Seoul National University;Neural Processing Research Center",
        "aff_unique_dep": "Computer Vision Lab, CSE;;Computer Vision Lab, ECE & ASRI;",
        "aff_unique_url": "https://www.postech.ac.kr;https://www.kakao.com;https://www.snu.ac.kr;",
        "aff_unique_abbr": "POSTECH;Kakao;SNU;",
        "aff_campus_unique_index": ";1;1;",
        "aff_campus_unique": ";Seoul",
        "aff_country_unique_index": "0+0;0+0;0+1;0+1",
        "aff_country_unique": "South Korea;United States"
    },
    {
        "title": "ResNet and Batch-normalization Improve Data Separability",
        "site": "https://proceedings.mlr.press/v101/furusho19a.html",
        "author": "Yasutaka Furusho; Kazushi Ikeda",
        "abstract": "The skip-connection and the batch-normalization (BN) in ResNet enable an extreme deep neural network to be trained with high performance. However, the reasons for its high performance are still unclear. To clear that, we study the effects of the skip-connection and the BN on the class-related signal propagation through hidden layers because a large ratio of the between-class distance to the within-class distance of feature vectors at the last hidden layer induces high performance. Our result shows that the between-class distance and the within-class distance change differently through layers: the deep multilayer perceptron with randomly initialized weights degrades the ratio of the between-class distance to the within-class distance and the skip-connection and the BN relax this degradation. Moreover, our analysis implies that the skip-connection and the BN encourage training to improve this distance ratio. These results imply that the skip-connection and the BN induce high performance.",
        "bibtex": "@InProceedings{pmlr-v101-furusho19a,\n  title = \t {ResNet and Batch-normalization Improve Data Separability},\n  author =       {Furusho, Yasutaka and Ikeda, Kazushi},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {94--108},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/furusho19a/furusho19a.pdf},\n  url = \t {https://proceedings.mlr.press/v101/furusho19a.html},\n  abstract = \t {The skip-connection and the batch-normalization (BN) in ResNet enable an extreme deep neural network to be trained with high performance. However, the reasons for its high performance are still unclear. To clear that, we study the effects of the skip-connection and the BN on the class-related signal propagation through hidden layers because a large ratio of the between-class distance to the within-class distance of feature vectors at the last hidden layer induces high performance. Our result shows that the between-class distance and the within-class distance change differently through layers: the deep multilayer perceptron with randomly initialized weights degrades the ratio of the between-class distance to the within-class distance and the skip-connection and the BN relax this degradation. Moreover, our analysis implies that the skip-connection and the BN encourage training to improve this distance ratio. These results imply that the skip-connection and the BN induce high performance.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/furusho19a/furusho19a.pdf",
        "supp": "",
        "pdf_size": 630370,
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5920838378608388144&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Nara Institute of Science and Technology, Nara 630-0192, Japan; Nara Institute of Science and Technology, Nara 630-0192, Japan",
        "aff_domain": "is.naist.jp;is.naist.jp",
        "email": "is.naist.jp;is.naist.jp",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Nara Institute of Science and Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.nist.go.jp",
        "aff_unique_abbr": "NIST",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Nara",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "title": "SDC-causing Error Detection Based on Lightweight Vulnerability Prediction",
        "site": "https://proceedings.mlr.press/v101/liu19c.html",
        "author": "Cheng Liu; Jingjing Gu; Zujia Yan; Fuzhen Zhuang; Yunyun Wang",
        "abstract": "Nowadays the system vulnerability caused by soft errors grows exponentially, of which Silent Data Corruption(SDC) is one of the most harmful issues due to introducing unnoticed changes to the original data and error outputs. Thus, the detection of SDC-causing errors is extremely significant to the system reliability. However, most of the current detecting techniques require sufficient data of fault injections for training, which are difficult to achieve in practice because of high resources consumption, such as expensive execution time and code size costs. To this end, we propose a lightweight model named Deep Forest Regression based Multi-granularity Redundancy(DFRMR) to improve the error detection rate and meanwhile decrease the resources consumption. Specifically, first, we employ the program analysis to extract instruction features which are highly related to SDCs. Second, we design the deep forest regression model to predict the SDC vulnerability of instructions. Third, we optimize the error detection procedure by duplicating the critical instructions with different granularity. Finally, we evaluate our DFRMR model on Mibench benchmarks with multiple testing programs. The results show that our method attains better detection accuracy compared to other state-of-the-art methods and keeps the low multi-granularity redundancy.",
        "bibtex": "@InProceedings{pmlr-v101-liu19c,\n  title = \t {SDC-causing Error Detection Based on Lightweight Vulnerability Prediction},\n  author =       {Liu, Cheng and Gu, Jingjing and Yan, Zujia and Zhuang, Fuzhen and Wang, Yunyun},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {1049--1064},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/liu19c/liu19c.pdf},\n  url = \t {https://proceedings.mlr.press/v101/liu19c.html},\n  abstract = \t {Nowadays the system vulnerability caused by soft errors grows exponentially, of which Silent Data Corruption(SDC) is one of the most harmful issues due to introducing unnoticed changes to the original data and error outputs. Thus, the detection of SDC-causing errors is extremely significant to the system reliability. However, most of the current detecting techniques require sufficient data of fault injections for training, which are difficult to achieve in practice because of high resources consumption, such as expensive execution time and code size costs. To this end, we propose a lightweight model named Deep Forest Regression based Multi-granularity Redundancy(DFRMR) to improve the error detection rate and meanwhile decrease the resources consumption. Specifically, first, we employ the program analysis to extract instruction features which are highly related to SDCs. Second, we design the deep forest regression model to predict the SDC vulnerability of instructions. Third, we optimize the error detection procedure by duplicating the critical instructions with different granularity. Finally, we evaluate our DFRMR model on Mibench benchmarks with multiple testing programs. The results show that our method attains better detection accuracy compared to other state-of-the-art methods and keeps the low multi-granularity redundancy.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/liu19c/liu19c.pdf",
        "supp": "",
        "pdf_size": 449763,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10017405120421977333&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "Nanjing University of Aeronautics and Astronautics, Nanjing, China; Nanjing University of Aeronautics and Astronautics, Nanjing, China; Nanjing University of Aeronautics and Astronautics, Nanjing, China; Key Lab of Intelligent Information Processing of Chinese Academy of Sciences (CAS), Institute of Computing Technology, CAS, Beijing 100190, China; Nanjing University of Posts and Telecommunications, Nanjing, China",
        "aff_domain": "nuaa.edu.cn;nuaa.edu.cn;nuaa.edu.cn;ict.ac.cn;njupt.edu.cn",
        "email": "nuaa.edu.cn;nuaa.edu.cn;nuaa.edu.cn;ict.ac.cn;njupt.edu.cn",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;1;2",
        "aff_unique_norm": "Nanjing University of Aeronautics and Astronautics;Chinese Academy of Sciences;Nanjing University of Posts and Telecommunications",
        "aff_unique_dep": ";Institute of Computing Technology;",
        "aff_unique_url": "http://www.nuaa.edu.cn;http://www.cas.ac.cn;http://www.njupt.edu.cn",
        "aff_unique_abbr": "NUAA;CAS;NJUPT",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Nanjing;Beijing",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "title": "SPCDet: Enhancing Object Detection with Combined Feature Fusing",
        "site": "https://proceedings.mlr.press/v101/wang19e.html",
        "author": "Haixin Wang; Lintao Wu; Qiongzhi Wu",
        "abstract": "Feature pyramid and feature fusing are widely used in object detection. Using feature pyramid can confront the challenge of scale variation across different objects. Feature fusing imports context information to improve detection performance. Although detecting with feature pyramid and feature fusing has achieved some encouraging results, there are still some limitations owing to the features\u2019 level variance among different layers. In this paper, we exploit that serial-parallel combined feature fusing can enhance object detection. Instead of detecting on the feature pyramid of backbone directly, we fuse different layers from backbone as base features. Then the base features are fed into a U-shape module to build local-global feature pyramid. At last, we use the pyramid to do the multi-scale detection with our combined feature fusing method. We call this one-stage detector SPCDet. It keeps real time speed and outperforms other detectors in trade-off between accuracy and speed.",
        "bibtex": "@InProceedings{pmlr-v101-wang19e,\n  title = \t {SPCDet: Enhancing Object Detection with Combined Feature Fusing},\n  author =       {Wang, Haixin and Wu, Lintao and Wu, Qiongzhi},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {236--251},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/wang19e/wang19e.pdf},\n  url = \t {https://proceedings.mlr.press/v101/wang19e.html},\n  abstract = \t {Feature pyramid and feature fusing are widely used in object detection. Using feature pyramid can confront the challenge of scale variation across different objects. Feature fusing imports context information to improve detection performance. Although detecting with feature pyramid and feature fusing has achieved some encouraging results, there are still some limitations owing to the features\u2019 level variance among different layers. In this paper, we exploit that serial-parallel combined feature fusing can enhance object detection. Instead of detecting on the feature pyramid of backbone directly, we fuse different layers from backbone as base features. Then the base features are fed into a U-shape module to build local-global feature pyramid. At last, we use the pyramid to do the multi-scale detection with our combined feature fusing method. We call this one-stage detector SPCDet. It keeps real time speed and outperforms other detectors in trade-off between accuracy and speed.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/wang19e/wang19e.pdf",
        "supp": "",
        "pdf_size": 1628129,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9619346745462579543&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "title": "SPoD-Net: Fast Recovery of Microscopic Images Using Learned ISTA",
        "site": "https://proceedings.mlr.press/v101/hara19a.html",
        "author": "Satoshi Hara; Weichih Chen; Takashi Washio; Tetsuichi Wazawa; Takeharu Nagai",
        "abstract": "Recovering high quality images from microscopic observations is an essential technology in biological imaging. Existing recovery methods require solving an optimization problem by using iterative algorithms, which are computationally expensive and time consuming. The focus of this study is to accelerate the image recovery by using deep neural networks (DNNs). In our approach, we first train a certain type of DNN by using some observations from microscopes, so that it can well approximate the image recovery process. The recovery of a new observation is then computed thorough a single forward propagation in the trained DNN. In this study, we specifically focus on observations obtained by SPoD (Super-resolution by Polarization Demodulation), a recently developed microscopic technique, and accelerate the image recovery for SPoD by using DNNs. To this end, we propose \\emph{SPoD-Net}, a specifically tailored DNN for fast recovery of SPoD images. Unlike general DNNs, SPoD-Net can be parameterized using a small number of parameters, which is helpful in two ways: (i) it can be stored in a small memory, and (ii) it can be trained efficiently. We also propose a method to stabilize the training of SPoD-Net. In the experiments with the real SPoD observations, we confirmed the effectiveness of SPoD-Net over existing recovery methods. Specifically, we observed that SPoD-Net could recover images with more than a hundred times faster than the existing method.",
        "bibtex": "@InProceedings{pmlr-v101-hara19a,\n  title = \t {SPoD-Net: Fast Recovery of Microscopic Images Using Learned ISTA},\n  author =       {Hara, Satoshi and Chen, Weichih and Washio, Takashi and Wazawa, Tetsuichi and Nagai, Takeharu},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {694--709},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/hara19a/hara19a.pdf},\n  url = \t {https://proceedings.mlr.press/v101/hara19a.html},\n  abstract = \t {Recovering high quality images from microscopic observations is an essential technology in biological imaging. Existing recovery methods require solving an optimization problem by using iterative algorithms, which are computationally expensive and time consuming. The focus of this study is to accelerate the image recovery by using deep neural networks (DNNs). In our approach, we first train a certain type of DNN by using some observations from microscopes, so that it can well approximate the image recovery process. The recovery of a new observation is then computed thorough a single forward propagation in the trained DNN. In this study, we specifically focus on observations obtained by SPoD (Super-resolution by Polarization Demodulation), a recently developed microscopic technique, and accelerate the image recovery for SPoD by using DNNs. To this end, we propose \\emph{SPoD-Net}, a specifically tailored DNN for fast recovery of SPoD images. Unlike general DNNs, SPoD-Net can be parameterized using a small number of parameters, which is helpful in two ways: (i) it can be stored in a small memory, and (ii) it can be trained efficiently. We also propose a method to stabilize the training of SPoD-Net. In the experiments with the real SPoD observations, we confirmed the effectiveness of SPoD-Net over existing recovery methods. Specifically, we observed that SPoD-Net could recover images with more than a hundred times faster than the existing method.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/hara19a/hara19a.pdf",
        "supp": "",
        "pdf_size": 2388482,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17383866225071881276&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 4,
        "aff": "Osaka University, Japan; National Taiwan University, Taiwan + Osaka University, Japan; Osaka University, Japan; Osaka University, Japan; Osaka University, Japan",
        "aff_domain": "ar.sanken.osaka-u.ac.jp;ntu.edu.tw;ar.sanken.osaka-u.ac.jp;sanken.osaka-u.ac.jp;sanken.osaka-u.ac.jp",
        "email": "ar.sanken.osaka-u.ac.jp;ntu.edu.tw;ar.sanken.osaka-u.ac.jp;sanken.osaka-u.ac.jp;sanken.osaka-u.ac.jp",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1+0;0;0;0",
        "aff_unique_norm": "Osaka University;National Taiwan University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.osaka-u.ac.jp;https://www.ntu.edu.tw",
        "aff_unique_abbr": "Osaka U;NTU",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Taiwan",
        "aff_country_unique_index": "0;1+0;0;0;0",
        "aff_country_unique": "Japan;China"
    },
    {
        "title": "Self-Paced Multi-Label Learning with Diversity",
        "site": "https://proceedings.mlr.press/v101/seyedi19a.html",
        "author": "Seyed Amjad Seyedi; S. Siamak Ghodsi; Fardin Akhlaghian; Mahdi Jalili; Parham Moradi",
        "abstract": "The major challenge of learning from multi-label data has arisen from the overwhelming size of label space which makes this problem NP-hard. This problem can be alleviated by gradually involving easy to hard tags into the learning process. Besides, the utilization of a diversity maintenance approach avoids overfitting on a subset of easy labels. In this paper, we propose a self-paced multi-label learning with diversity (SPMLD) which aims to cover diverse labels with respect to its learning pace. In addition, the proposed framework is applied to an efficient correlation-based multi-label method. The non-convex objective function is optimized by an extension of the block coordinate descent algorithm. Empirical evaluations on real-world datasets with different dimensions of features and labels imply the effectiveness of the proposed predictive model.",
        "bibtex": "@InProceedings{pmlr-v101-seyedi19a,\n  title = \t {Self-Paced Multi-Label Learning with Diversity},\n  author =       {Seyedi, Seyed Amjad and Ghodsi, S. Siamak and Akhlaghian, Fardin and Jalili, Mahdi and Moradi, Parham},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {790--805},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/seyedi19a/seyedi19a.pdf},\n  url = \t {https://proceedings.mlr.press/v101/seyedi19a.html},\n  abstract = \t {The major challenge of learning from multi-label data has arisen from the overwhelming size of label space which makes this problem NP-hard. This problem can be alleviated by gradually involving easy to hard tags into the learning process. Besides, the utilization of a diversity maintenance approach avoids overfitting on a subset of easy labels. In this paper, we propose a self-paced multi-label learning with diversity (SPMLD) which aims to cover diverse labels with respect to its learning pace. In addition, the proposed framework is applied to an efficient correlation-based multi-label method. The non-convex objective function is optimized by an extension of the block coordinate descent algorithm. Empirical evaluations on real-world datasets with different dimensions of features and labels imply the effectiveness of the proposed predictive model.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/seyedi19a/seyedi19a.pdf",
        "supp": "",
        "pdf_size": 429255,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2711105429574832337&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Computer Engineering, University of Kurdistan, Sanandaj, Iran; Department of Computer Engineering, University of Kurdistan, Sanandaj, Iran; Department of Computer Engineering, University of Kurdistan, Sanandaj, Iran; School of Engineering, RMIT University, Melbourne, Australia; Department of Computer Engineering, University of Kurdistan, Sanandaj, Iran",
        "aff_domain": "eng.uok.ac.ir;eng.uok.ac.ir;uok.ac.ir;rmit.edu.au;uok.ac.ir",
        "email": "eng.uok.ac.ir;eng.uok.ac.ir;uok.ac.ir;rmit.edu.au;uok.ac.ir",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "University of Kurdistan;RMIT University",
        "aff_unique_dep": "Department of Computer Engineering;School of Engineering",
        "aff_unique_url": ";https://www.rmit.edu.au",
        "aff_unique_abbr": ";RMIT",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Sanandaj;Melbourne",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "Iran;Australia"
    },
    {
        "title": "Self-Supervised Deep Multi-View Subspace Clustering",
        "site": "https://proceedings.mlr.press/v101/sun19a.html",
        "author": "Xiukun Sun; Miaomiao Cheng; Chen Min; Liping Jing",
        "abstract": "As a new occurring unsupervised method, multi-view clustering offers a good way to investigate the hidden structure from multi-view data and attracts extensive attention in the community of machine learning and data mining. One popular approach is to identify a common latent subspace for capturing the multi-view information. However, these methods are still limited due to the unsupervised learning process and suffer from considerable noisy information from different views. To address this issue, we present a novel multi-view subspace clustering method, named self-supervised deep multi-view subspace clustering (\\textbf{S2DMVSC}). It seamlessly integrates spectral clustering and affinity learning into a deep learning framework. \\textbf{S2DMVSC} has two main merits. One is that the clustering results can be sufficiently exploited to supervise the latent representation learning for each view (via a classification loss) and the common latent subspace learning (via a spectral clustering loss) for multiple views. The other is that the affinity matrix among data objects is automatically computed according to the high-level and cluster-driven representation. Experiments on two scenarios, including original features and multiple hand-crafted features, demonstrate the superiority of the proposed approach over the state-of-the-art baselines.",
        "bibtex": "@InProceedings{pmlr-v101-sun19a,\n  title = \t {Self-Supervised Deep Multi-View Subspace Clustering},\n  author =       {Sun, Xiukun and Cheng, Miaomiao and Min, Chen and Jing, Liping},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {1001--1016},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/sun19a/sun19a.pdf},\n  url = \t {https://proceedings.mlr.press/v101/sun19a.html},\n  abstract = \t {As a new occurring unsupervised method, multi-view clustering offers a good way to investigate the hidden structure from multi-view data and attracts extensive attention in the community of machine learning and data mining. One popular approach is to identify a common latent subspace for capturing the multi-view information. However, these methods are still limited due to the unsupervised learning process and suffer from considerable noisy information from different views. To address this issue, we present a novel multi-view subspace clustering method, named self-supervised deep multi-view subspace clustering (\\textbf{S2DMVSC}). It seamlessly integrates spectral clustering and affinity learning into a deep learning framework. \\textbf{S2DMVSC} has two main merits. One is that the clustering results can be sufficiently exploited to supervise the latent representation learning for each view (via a classification loss) and the common latent subspace learning (via a spectral clustering loss) for multiple views. The other is that the affinity matrix among data objects is automatically computed according to the high-level and cluster-driven representation. Experiments on two scenarios, including original features and multiple hand-crafted features, demonstrate the superiority of the proposed approach over the state-of-the-art baselines.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/sun19a/sun19a.pdf",
        "supp": "",
        "pdf_size": 1356935,
        "gs_citation": 59,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13910594586888515063&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Beijing Jiaotong University, Beijing, China; Beijing Jiaotong University, Beijing, China; Beijing Jiaotong University, Beijing, China; Beijing Jiaotong University, Beijing, China",
        "aff_domain": "bjtu.edu.cn;bjtu.edu.cn;bjtu.edu.cn;bjtu.edu.cn",
        "email": "bjtu.edu.cn;bjtu.edu.cn;bjtu.edu.cn;bjtu.edu.cn",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Beijing Jiaotong University",
        "aff_unique_dep": "",
        "aff_unique_url": "http://www.bjtu.edu.cn",
        "aff_unique_abbr": "BJTU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "title": "Self-Weighted Multi-View Clustering with Deep Matrix Factorization",
        "site": "https://proceedings.mlr.press/v101/cui19a.html",
        "author": "Beilei Cui; Hong Yu; Tiantian Zhang; Siwen Li",
        "abstract": "Due to the efficiency of exploring multiple views of the real-word data, Multi-View Clustering (MVC) has attracted extensive attention from the scholars and researches based on it have made significant progress. However, multi-view data with numerous complementary information is vulnerable to various factors (such as noise). So it is an important and challenging task to discover the intrinsic characteristics hidden deeply in the data. In this paper, we present a novel MVC algorithm based on deep matrix factorization, named Self-Weighted Multi-view Clustering with Deep Matrix Factorization (SMDMF). By performing the deep decomposition structure, SMDMF can eliminate interference and reveal semantic information of the multi-view data. To properly integrate the complementary information among views, it assigns an automatic weight for each view without introducing supernumerary parameters. We also analyze the convergence of the algorithm and discuss the hierarchical parameters. The experimental results on four datasets show our algorithm is superior to other comparisons in all aspects.",
        "bibtex": "@InProceedings{pmlr-v101-cui19a,\n  title = \t {Self-Weighted Multi-View Clustering with Deep Matrix Factorization},\n  author =       {Cui, Beilei and Yu, Hong and Zhang, Tiantian and Li, Siwen},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {567--582},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/cui19a/cui19a.pdf},\n  url = \t {https://proceedings.mlr.press/v101/cui19a.html},\n  abstract = \t {Due to the efficiency of exploring multiple views of the real-word data, Multi-View Clustering (MVC) has attracted extensive attention from the scholars and researches based on it have made significant progress. However, multi-view data with numerous complementary information is vulnerable to various factors (such as noise). So it is an important and challenging task to discover the intrinsic characteristics hidden deeply in the data. In this paper, we present a novel MVC algorithm based on deep matrix factorization, named Self-Weighted Multi-view Clustering with Deep Matrix Factorization (SMDMF). By performing the deep decomposition structure, SMDMF can eliminate interference and reveal semantic information of the multi-view data. To properly integrate the complementary information among views, it assigns an automatic weight for each view without introducing supernumerary parameters. We also analyze the convergence of the algorithm and discuss the hierarchical parameters. The experimental results on four datasets show our algorithm is superior to other comparisons in all aspects.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/cui19a/cui19a.pdf",
        "supp": "",
        "pdf_size": 525500,
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14869095325605671279&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "School of Software, Dalian University of Technology, Dalian, China; School of Software, Dalian University of Technology, Dalian, China; School of Software, Dalian University of Technology, Dalian, China; School of Software, Dalian University of Technology, Dalian, China",
        "aff_domain": "163.com;dlut.edu.cn;163.com;foxmail.com",
        "email": "163.com;dlut.edu.cn;163.com;foxmail.com",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Dalian University of Technology",
        "aff_unique_dep": "School of Software",
        "aff_unique_url": "http://www.dlut.edu.cn",
        "aff_unique_abbr": "DUT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Dalian",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "title": "Separate Loss for Basic and Compound Facial Expression Recognition in the Wild",
        "site": "https://proceedings.mlr.press/v101/li19b.html",
        "author": "Yingjian Li; Yao Lu; Jinxing Li; Guangming Lu",
        "abstract": "In the past few years, facial expression recognition has made great progress because of the development of convolutional neural networks. However, the features learned only using the softmax loss are not discriminative enough for highly accurate facial expression recognition in the wild, especially for the compound facial expression recognition. To enhance the discriminative power of the learned features, we propose the separate loss for both basic and compound facial expression recognition in the wild in this paper. Such loss maximizes intra-class similarity while minimizing the similarity between different classes. The qualitative and quantitative analysis shows that the features learned using such loss function are characterized by intra-class compactness and inter-class separation. Experiments are performed on two databases in the wild and the proposed method achieves state-of-the-art results on both basic and compound expressions. Furthermore, another two databases are used to perform cross database experiments to show the generalization ability of our method.",
        "bibtex": "@InProceedings{pmlr-v101-li19b,\n  title = \t {Separate Loss for Basic and Compound Facial Expression Recognition in the Wild},\n  author =       {Li, Yingjian and Lu, Yao and Li, Jinxing and Lu, Guangming},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {897--911},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/li19b/li19b.pdf},\n  url = \t {https://proceedings.mlr.press/v101/li19b.html},\n  abstract = \t {In the past few years, facial expression recognition has made great progress because of the development of convolutional neural networks. However, the features learned only using the softmax loss are not discriminative enough for highly accurate facial expression recognition in the wild, especially for the compound facial expression recognition. To enhance the discriminative power of the learned features, we propose the separate loss for both basic and compound facial expression recognition in the wild in this paper. Such loss maximizes intra-class similarity while minimizing the similarity between different classes. The qualitative and quantitative analysis shows that the features learned using such loss function are characterized by intra-class compactness and inter-class separation. Experiments are performed on two databases in the wild and the proposed method achieves state-of-the-art results on both basic and compound expressions. Furthermore, another two databases are used to perform cross database experiments to show the generalization ability of our method.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/li19b/li19b.pdf",
        "supp": "",
        "pdf_size": 1822930,
        "gs_citation": 86,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8027400427804534699&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "Harbin Institute of Technology Shenzhen, Shenzhen, China; Harbin Institute of Technology Shenzhen, Shenzhen, China; The Chinese University of Hong Kong Shenzhen, Shenzhen, China + University of Science and Technology of China, Hefei, China; Harbin Institute of Technology Shenzhen, Shenzhen, China",
        "aff_domain": "126.com;126.com;gmail.com;hit.edu.cn",
        "email": "126.com;126.com;gmail.com;hit.edu.cn",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1+2;0",
        "aff_unique_norm": "Harbin Institute of Technology;The Chinese University of Hong Kong Shenzhen;University of Science and Technology of China",
        "aff_unique_dep": ";;",
        "aff_unique_url": "http://en.hust.edu.cn/;https://www.cuhk.edu.cn;http://www.ustc.edu.cn",
        "aff_unique_abbr": "HIT;CUHK Shenzhen;USTC",
        "aff_campus_unique_index": "0;0;0+1;0",
        "aff_campus_unique": "Shenzhen;Hefei",
        "aff_country_unique_index": "0;0;0+0;0",
        "aff_country_unique": "China"
    },
    {
        "title": "Software Component Prediction for Bug Reports",
        "site": "https://proceedings.mlr.press/v101/zhang19c.html",
        "author": "Wei Zhang; Chris Challis",
        "abstract": "In a software life cycle, bugs could happen at any time. Assigning bugs to relevant components/developers is a crucial task for software development. It is also a tough and resource consuming job. First, there are many components in a complex system and it is hard to understand their interactions and identify the root cause. Second, the list of components keeps growing for actively developed products and it is not easy to catch all updates. This task also faces several challenges from the machine learning point of view: 1) the ground truth is mixed with multiple levels of labels; 2) the data are severely imbalanced. 3). concept drift as future bugs are unlikely to come from the same distribution as the historical data. In this paper, we present a machine learning based solution for the bug assignment problem. We build component classifiers using a multi-layer Neural Network, based on features that were learned from data directly. A hierarchical classification framework is proposed to address the mixed label problem and improve the prediction accuracy. We also introduce a recency based sampling procedure to alleviate the data imbalance and concept drift problem. Our solution can easily accommodate new data and handle continuous system development/update.",
        "bibtex": "@InProceedings{pmlr-v101-zhang19c,\n  title = \t {Software Component Prediction for Bug Reports},\n  author =       {Zhang, Wei and Challis, Chris},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {806--821},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/zhang19c/zhang19c.pdf},\n  url = \t {https://proceedings.mlr.press/v101/zhang19c.html},\n  abstract = \t {In a software life cycle, bugs could happen at any time. Assigning bugs to relevant components/developers is a crucial task for software development. It is also a tough and resource consuming job. First, there are many components in a complex system and it is hard to understand their interactions and identify the root cause. Second, the list of components keeps growing for actively developed products and it is not easy to catch all updates. This task also faces several challenges from the machine learning point of view: 1) the ground truth is mixed with multiple levels of labels; 2) the data are severely imbalanced. 3). concept drift as future bugs are unlikely to come from the same distribution as the historical data. In this paper, we present a machine learning based solution for the bug assignment problem. We build component classifiers using a multi-layer Neural Network, based on features that were learned from data directly. A hierarchical classification framework is proposed to address the mixed label problem and improve the prediction accuracy. We also introduce a recency based sampling procedure to alleviate the data imbalance and concept drift problem. Our solution can easily accommodate new data and handle continuous system development/update.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/zhang19c/zhang19c.pdf",
        "supp": "",
        "pdf_size": 590216,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9578356328717672495&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "Adobe Inc., Mclean, USA; Adobe Inc., Mclean, USA",
        "aff_domain": "adobe.com;adobe.com",
        "email": "adobe.com;adobe.com",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Adobe Inc.",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.adobe.com",
        "aff_unique_abbr": "Adobe",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Mclean",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Stochastic Gradient Trees",
        "site": "https://proceedings.mlr.press/v101/gouk19a.html",
        "author": "Henry Gouk; Bernhard Pfahringer; Eibe Frank",
        "abstract": "We present an algorithm for learning decision trees using stochastic gradient information as the source of supervision. In contrast to previous approaches to gradient-based tree learning, our method operates in the incremental learning setting rather than the batch learning setting, and does not make use of soft splits or require the construction of a new tree for every update. We demonstrate how one can apply these decision trees to different problems by changing only the loss function, using classification, regression, and multi-instance learning as example applications. In the experimental evaluation, our method performs similarly to standard incremental classification trees, outperforms state of the art incremental regression trees, and achieves comparable performance with batch multi-instance learning methods.",
        "bibtex": "@InProceedings{pmlr-v101-gouk19a,\n  title = \t {Stochastic Gradient Trees},\n  author =       {Gouk, Henry and Pfahringer, Bernhard and Frank, Eibe},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {1094--1109},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/gouk19a/gouk19a.pdf},\n  url = \t {https://proceedings.mlr.press/v101/gouk19a.html},\n  abstract = \t {We present an algorithm for learning decision trees using stochastic gradient information as the source of supervision. In contrast to previous approaches to gradient-based tree learning, our method operates in the incremental learning setting rather than the batch learning setting, and does not make use of soft splits or require the construction of a new tree for every update. We demonstrate how one can apply these decision trees to different problems by changing only the loss function, using classification, regression, and multi-instance learning as example applications. In the experimental evaluation, our method performs similarly to standard incremental classification trees, outperforms state of the art incremental regression trees, and achieves comparable performance with batch multi-instance learning methods.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/gouk19a/gouk19a.pdf",
        "supp": "",
        "pdf_size": 274350,
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18125706032076420380&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "School of Informatics, University of Edinburgh, Edinburgh, United Kingdom; Department of Computer Science, University of Waikato, Hamilton, New Zealand; Department of Computer Science, University of Waikato, Hamilton, New Zealand",
        "aff_domain": "inf.ed.ac.uk;waikato.ac.nz;waikato.ac.nz",
        "email": "inf.ed.ac.uk;waikato.ac.nz;waikato.ac.nz",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "University of Edinburgh;University of Waikato",
        "aff_unique_dep": "School of Informatics;Department of Computer Science",
        "aff_unique_url": "https://www.ed.ac.uk;https://www.waikato.ac.nz",
        "aff_unique_abbr": "Edinburgh;UoW",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Edinburgh;Hamilton",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "United Kingdom;New Zealand"
    },
    {
        "title": "Surface Reconstruction based on Self-Merging Octree with Deep Learning",
        "site": "https://proceedings.mlr.press/v101/lv19a.html",
        "author": "Jian Lv; Xie Han; Jiajie Zheng; Fengguang Xiong; Min Pang",
        "abstract": "A model segment method called Octree Subdivision has been presented for long years, which allows any three-dimensional point cloud object to be subdivided into infinitesimals so that it can be approximated by a particular surface function. In this paper, we proposed a new method named self-merging octree to reconstruct the surface of 3D Point Cloud which can be obtained by laser scanners or generated by some 3D modeling software. Different from any other surface reconstruction algorithms such as local property-based or specific type-based, a function pool-based was introduced in our research because it can express many different types of surfaces. We subdivide point cloud model by self-merging octree and categorize it by the neuro-network. In this idea, it is easy for us to find a proper surface function to present the subsurface of the model. What\u2018s more, while we extend the function pool, we can indicate far more style models. We have tried to reconstruct many point cloud models\u2018 surfaces in this way, and it works well and also shows its potential ability to build a bridge in the fields of model editing, model splicing, and model deformation.",
        "bibtex": "@InProceedings{pmlr-v101-lv19a,\n  title = \t {Surface Reconstruction based on Self-Merging Octree with Deep Learning},\n  author =       {Lv, Jian and Han, Xie and Zheng, Jiajie and Xiong, Fengguang and Pang, Min},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {883--896},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/lv19a/lv19a.pdf},\n  url = \t {https://proceedings.mlr.press/v101/lv19a.html},\n  abstract = \t {A model segment method called Octree Subdivision has been presented for long years, which allows any three-dimensional point cloud object to be subdivided into infinitesimals so that it can be approximated by a particular surface function. In this paper, we proposed a new method named self-merging octree to reconstruct the surface of 3D Point Cloud which can be obtained by laser scanners or generated by some 3D modeling software. Different from any other surface reconstruction algorithms such as local property-based or specific type-based, a function pool-based was introduced in our research because it can express many different types of surfaces. We subdivide point cloud model by self-merging octree and categorize it by the neuro-network. In this idea, it is easy for us to find a proper surface function to present the subsurface of the model. What\u2018s more, while we extend the function pool, we can indicate far more style models. We have tried to reconstruct many point cloud models\u2018 surfaces in this way, and it works well and also shows its potential ability to build a bridge in the fields of model editing, model splicing, and model deformation.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/lv19a/lv19a.pdf",
        "supp": "",
        "pdf_size": 5672261,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:oagi2KkHTR0J:scholar.google.com/&scioq=Surface+Reconstruction+based+on+Self-Merging+Octree+with+Deep+Learning&hl=en&as_sdt=0,5",
        "gs_version_total": 3,
        "aff": "School of Data Science and Technology, North University of China, Taiyuan, 030051, China; School of Data Science and Technology, North University of China, Taiyuan, 030051, China; School of Data Science and Technology, North University of China, Taiyuan, 030051, China; School of Data Science and Technology, North University of China, Taiyuan, 030051, China; School of Data Science and Technology, North University of China, Taiyuan, 030051, China",
        "aff_domain": "gmail.com;163.com;protonmail.com;nuc.edu.cn;nuc.edu.cn",
        "email": "gmail.com;163.com;protonmail.com;nuc.edu.cn;nuc.edu.cn",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "North University of China",
        "aff_unique_dep": "School of Data Science and Technology",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Taiyuan",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "title": "Text Length Adaptation in Sentiment Classification",
        "site": "https://proceedings.mlr.press/v101/amplayo19a.html",
        "author": "Reinald Kim Amplayo; Seonjae Lim; Seung-won Hwang",
        "abstract": "Can a text classifier generalize well for datasets where the text length is different? For example, when short reviews are sentiment-labeled, can these transfer to predict the sentiment of long reviews (i.e., short to long transfer), or vice versa? While unsupervised transfer learning has been well-studied for cross domain/lingual transfer tasks, \\textbf{Cross Length Transfer} (CLT) has not yet been explored. One reason is the assumption that length difference is trivially transferable in classification. We show that it is not, because short/long texts differ in context richness and word intensity. We devise new benchmark datasets from diverse domains and languages, and show that existing models from similar tasks cannot deal with the unique challenge of transferring across text lengths. We introduce a strong baseline model called \\textsc{BaggedCNN} that treats long texts as bags containing short texts. We propose a state-of-the-art CLT model called \\textbf{Le}ngth \\textbf{Tra}nsfer \\textbf{Net}work\\textbf{s} (\\textsc{LeTraNets}) that introduces a two-way encoding scheme for short and long texts using multiple training mechanisms. We test our models and find that existing models perform worse than the \\textsc{BaggedCNN} baseline, while \\textsc{LeTraNets} outperforms all models.",
        "bibtex": "@InProceedings{pmlr-v101-amplayo19a,\n  title = \t {Text Length Adaptation in Sentiment Classification},\n  author =       {Amplayo, Reinald Kim and Lim, Seonjae and Hwang, Seung-won},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {646--661},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/amplayo19a/amplayo19a.pdf},\n  url = \t {https://proceedings.mlr.press/v101/amplayo19a.html},\n  abstract = \t {Can a text classifier generalize well for datasets where the text length is different? For example, when short reviews are sentiment-labeled, can these transfer to predict the sentiment of long reviews (i.e., short to long transfer), or vice versa? While unsupervised transfer learning has been well-studied for cross domain/lingual transfer tasks, \\textbf{Cross Length Transfer} (CLT) has not yet been explored. One reason is the assumption that length difference is trivially transferable in classification. We show that it is not, because short/long texts differ in context richness and word intensity. We devise new benchmark datasets from diverse domains and languages, and show that existing models from similar tasks cannot deal with the unique challenge of transferring across text lengths. We introduce a strong baseline model called \\textsc{BaggedCNN} that treats long texts as bags containing short texts. We propose a state-of-the-art CLT model called \\textbf{Le}ngth \\textbf{Tra}nsfer \\textbf{Net}work\\textbf{s} (\\textsc{LeTraNets}) that introduces a two-way encoding scheme for short and long texts using multiple training mechanisms. We test our models and find that existing models perform worse than the \\textsc{BaggedCNN} baseline, while \\textsc{LeTraNets} outperforms all models.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/amplayo19a/amplayo19a.pdf",
        "supp": "",
        "pdf_size": 634000,
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15254030062527810040&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "University of Edinburgh, UK; Samsung Electronics, South Korea; Yonsei University, South Korea",
        "aff_domain": "ed.ac.uk;samsung.com;yonsei.ac.kr",
        "email": "ed.ac.uk;samsung.com;yonsei.ac.kr",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "University of Edinburgh;Samsung Electronics;Yonsei University",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.ed.ac.uk;https://www.samsung.com;https://www.yonsei.ac.kr",
        "aff_unique_abbr": "Edinburgh;Samsung;Yonsei",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "United Kingdom;South Korea"
    },
    {
        "title": "Towards Governing Agent\u2019s Efficacy: Action-Conditional $\u03b2$-VAE for Deep Transparent Reinforcement Learning",
        "site": "https://proceedings.mlr.press/v101/yang19a.html",
        "author": "John Yang; Gyuejeong Lee; Simyung Chang; Nojun Kwak",
        "abstract": "We tackle the blackbox issue of deep neural networks in the settings of reinforcement learning (RL) where neural agents learn towards maximizing reward gains in an uncontrollable way. Such learning approach is risky when the interacting environment includes an expanse of state space because it is then almost impossible to foresee all unwanted outcomes and penalize them with negative rewards beforehand. We propose Action-conditional $\\beta$-VAE (AC-$\\beta$-VAE) that allows succinct mappings of action-dependent factors in desirable dimensions of latent representations while disentangling environmental factors. Our proposed method tackles the blackbox issue by encouraging an RL policy network to learn interpretable latent features by distinguits influenshing ices from uncontrollable environmental factors, which closely resembles the way humans understand their scenes. Our experimental results show that the learned latent factors not only are interpretable, but also enable modeling the distribution of entire visited state-action space. We have experimented that this characteristic of the proposed structure can lead to ex post facto governance for desired behaviors of RL agents.",
        "bibtex": "@InProceedings{pmlr-v101-yang19a,\n  title = \t {Towards Governing Agent\u2019s Efficacy: Action-Conditional $\u03b2$-VAE for Deep Transparent Reinforcement Learning},\n  author =       {Yang, John and Lee, Gyuejeong and Chang, Simyung and Kwak, Nojun},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {32--47},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/yang19a/yang19a.pdf},\n  url = \t {https://proceedings.mlr.press/v101/yang19a.html},\n  abstract = \t {We tackle the blackbox issue of deep neural networks in the settings of reinforcement learning (RL) where neural agents learn towards maximizing reward gains in an uncontrollable way. Such learning approach is risky when the interacting environment includes an expanse of state space because it is then almost impossible to foresee all unwanted outcomes and penalize them with negative rewards beforehand. We propose Action-conditional $\\beta$-VAE (AC-$\\beta$-VAE) that allows succinct mappings of action-dependent factors in desirable dimensions of latent representations while disentangling environmental factors. Our proposed method tackles the blackbox issue by encouraging an RL policy network to learn interpretable latent features by distinguits influenshing ices from uncontrollable environmental factors, which closely resembles the way humans understand their scenes. Our experimental results show that the learned latent factors not only are interpretable, but also enable modeling the distribution of entire visited state-action space. We have experimented that this characteristic of the proposed structure can lead to ex post facto governance for desired behaviors of RL agents.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/yang19a/yang19a.pdf",
        "supp": "",
        "pdf_size": 3373406,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8576751490349576145&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Seoul National University, Seoul, Korea; Seoul National University, Seoul, Korea; Seoul National University, Seoul, Korea; Seoul National University, Seoul, Korea",
        "aff_domain": "snu.ac.kr;snu.ac.kr;snu.ac.kr;snu.ac.kr",
        "email": "snu.ac.kr;snu.ac.kr;snu.ac.kr;snu.ac.kr",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Seoul National University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.snu.ac.kr",
        "aff_unique_abbr": "SNU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "title": "Trust Region Sequential Variational Inference",
        "site": "https://proceedings.mlr.press/v101/kim19a.html",
        "author": "Geon-Hyeong Kim; Youngsoo Jang; Jongmin Lee; Wonseok Jeon; Hongseok Yang; Kee-Eung Kim",
        "abstract": "Stochastic variational inference has emerged as an effective method for performing inference on or learning complex models for data. Yet, one of the challenges in stochastic variational inference is handling high-dimensional data, such as sequential data, and models with non-differentiable densities caused by, for instance, the use of discrete latent variables. In such cases, it is challenging to control the variance of the gradient estimator used in stochastic variational inference, while low variance is often one of the key properties needed for successful inference. In this work, we present a new algorithm for stochastic variational inference of sequential models which trades off bias for variance to tackle this challenge effectively. Our algorithm is inspired by variance reduction techniques in reinforcement learning, yet it uniquely adopts their key ideas in the context of stochastic variational inference. We demonstrate the effectiveness of our approach through formal analysis and experiments on synthetic and real-world datasets.",
        "bibtex": "@InProceedings{pmlr-v101-kim19a,\n  title = \t {Trust Region Sequential Variational Inference},\n  author =       {Kim, Geon-Hyeong and Jang, Youngsoo and Lee, Jongmin and Jeon, Wonseok and Yang, Hongseok and Kim, Kee-Eung},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {1033--1048},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/kim19a/kim19a.pdf},\n  url = \t {https://proceedings.mlr.press/v101/kim19a.html},\n  abstract = \t {Stochastic variational inference has emerged as an effective method for performing inference on or learning complex models for data. Yet, one of the challenges in stochastic variational inference is handling high-dimensional data, such as sequential data, and models with non-differentiable densities caused by, for instance, the use of discrete latent variables. In such cases, it is challenging to control the variance of the gradient estimator used in stochastic variational inference, while low variance is often one of the key properties needed for successful inference. In this work, we present a new algorithm for stochastic variational inference of sequential models which trades off bias for variance to tackle this challenge effectively. Our algorithm is inspired by variance reduction techniques in reinforcement learning, yet it uniquely adopts their key ideas in the context of stochastic variational inference. We demonstrate the effectiveness of our approach through formal analysis and experiments on synthetic and real-world datasets.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/kim19a/kim19a.pdf",
        "supp": "",
        "pdf_size": 1857680,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11103663870832130931&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Graduate School of AI, KAIST, Daejeon, Republic of Korea + School of Computing, KAIST, Republic of Korea; School of Computing, KAIST, Republic of Korea; School of Computing, KAIST, Republic of Korea; MILA, McGill University, Canada; School of Computing, KAIST, Republic of Korea; Graduate School of AI, KAIST, Daejeon, Republic of Korea + School of Computing, KAIST, Republic of Korea",
        "aff_domain": "ai.kaist.ac.kr;ai.kaist.ac.kr;ai.kaist.ac.kr;mila.quebec;kaist.ac.kr;kaist.ac.kr",
        "email": "ai.kaist.ac.kr;ai.kaist.ac.kr;ai.kaist.ac.kr;mila.quebec;kaist.ac.kr;kaist.ac.kr",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+0;0;0;1;0;0+0",
        "aff_unique_norm": "KAIST;McGill University",
        "aff_unique_dep": "Graduate School of AI;MILA",
        "aff_unique_url": "https://www.kaist.edu;https://www.mcgill.ca",
        "aff_unique_abbr": "KAIST;McGill",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Daejeon;",
        "aff_country_unique_index": "0+0;0;0;1;0;0+0",
        "aff_country_unique": "South Korea;Canada"
    },
    {
        "title": "Unified Policy Optimization for Robust Reinforcement Learning",
        "site": "https://proceedings.mlr.press/v101/lin19a.html",
        "author": "Zichuan Lin; Li Zhao; Jiang Bian; Tao Qin; Guangwen Yang",
        "abstract": "Recent years have witnessed significant progress in solving challenging problems across various domains using deep reinforcement learning (RL). Despite the success, the weak robustness has risen as a big obstacle for applying existing RL algorithms into real problems. In this paper, we propose unified policy optimization (UPO), a sample-efficient shared policy framework that allows a policy to update itself by considering different gradients generated by different policy gradient (PG) methods. Specifically, we propose two algorithms called UPO-MAB and UPO-ES, to leverage these different gradients by adopting the idea of multi-arm bandit (MAB) and evolution strategies (ES), with the purpose of finding the gradient direction leading to more performance gain with less extra data cost. Extensive experiments show that our approach can lead to stronger robustness and better performance than baselines.",
        "bibtex": "@InProceedings{pmlr-v101-lin19a,\n  title = \t {Unified Policy Optimization for Robust Reinforcement Learning},\n  author =       {Lin, Zichuan and Zhao, Li and Bian, Jiang and Qin, Tao and Yang, Guangwen},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {395--410},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/lin19a/lin19a.pdf},\n  url = \t {https://proceedings.mlr.press/v101/lin19a.html},\n  abstract = \t {Recent years have witnessed significant progress in solving challenging problems across various domains using deep reinforcement learning (RL). Despite the success, the weak robustness has risen as a big obstacle for applying existing RL algorithms into real problems. In this paper, we propose unified policy optimization (UPO), a sample-efficient shared policy framework that allows a policy to update itself by considering different gradients generated by different policy gradient (PG) methods. Specifically, we propose two algorithms called UPO-MAB and UPO-ES, to leverage these different gradients by adopting the idea of multi-arm bandit (MAB) and evolution strategies (ES), with the purpose of finding the gradient direction leading to more performance gain with less extra data cost. Extensive experiments show that our approach can lead to stronger robustness and better performance than baselines.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/lin19a/lin19a.pdf",
        "supp": "",
        "pdf_size": 2395448,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:dQMlquAVJGIJ:scholar.google.com/&scioq=Unified+Policy+Optimization+for+Robust+Reinforcement+Learning&hl=en&as_sdt=0,33",
        "gs_version_total": 4,
        "aff": "Tsinghua University, Beijing; Microsoft Research, Beijing; Microsoft Research, Beijing; Microsoft Research, Beijing; Tsinghua University, Beijing",
        "aff_domain": "tsinghua.edu.cn;micros oft.com;micros oft.com;micros oft.com;tsinghua.edu.cn",
        "email": "tsinghua.edu.cn;micros oft.com;micros oft.com;micros oft.com;tsinghua.edu.cn",
        "github": "",
        "project": "https://sites.google.com/view/upopaper",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1;1;0",
        "aff_unique_norm": "Tsinghua University;Microsoft Research",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.tsinghua.edu.cn;https://www.microsoft.com/en-us/research/group/microsoft-research-asia",
        "aff_unique_abbr": "THU;MSR",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "title": "Unpaired Data based Cross-domain Synthesis and Segmentation Using Attention Neural Network",
        "site": "https://proceedings.mlr.press/v101/liu19b.html",
        "author": "Xiaoming Liu; Xiangkai Wei; Aihui Yu; Zhifang Pan",
        "abstract": "Medical images from different modalities (e.g. MRI, CT) or contrasts (e.g. T1, T2) are usually used to extract abundant information for medical image analysis. Some modalities or contrasts may be degraded or missing, caused by artifacts or strict timing during acquisition. Thus synthesizing realistic medical images in the required domain is meaningful and helpful for clinical application. Meanwhile, due to the time-consuming of manual annotation, automatic medical image segmentation has attracted much attention. In this paper, we propose an end-to-end cross-domain synthesis and segmentation framework SSA-Net. It is based on cycle generative adversarial network (CycleGAN) for unpaired data. We introduce a gradient consistent term to refine the boundaries in synthesized images. Besides, we design a special shape consistent term to constrain the anatomical structure in synthesized images and to guide segmentation without target domian labels. In order to make the synthesis subnet focusing on some hard-to-learn regions automatically, we also introduce the attention block into the generator. On two challenging validation datasets (CHAOS and iSeg-2017), the proposed method achieves superior synthesis performance and comparable segmentation performance.",
        "bibtex": "@InProceedings{pmlr-v101-liu19b,\n  title = \t {Unpaired Data based Cross-domain Synthesis and Segmentation Using Attention Neural Network},\n  author =       {Liu, Xiaoming and Wei, Xiangkai and Yu, Aihui and Pan, Zhifang},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {987--1000},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/liu19b/liu19b.pdf},\n  url = \t {https://proceedings.mlr.press/v101/liu19b.html},\n  abstract = \t {Medical images from different modalities (e.g. MRI, CT) or contrasts (e.g. T1, T2) are usually used to extract abundant information for medical image analysis. Some modalities or contrasts may be degraded or missing, caused by artifacts or strict timing during acquisition. Thus synthesizing realistic medical images in the required domain is meaningful and helpful for clinical application. Meanwhile, due to the time-consuming of manual annotation, automatic medical image segmentation has attracted much attention. In this paper, we propose an end-to-end cross-domain synthesis and segmentation framework SSA-Net. It is based on cycle generative adversarial network (CycleGAN) for unpaired data. We introduce a gradient consistent term to refine the boundaries in synthesized images. Besides, we design a special shape consistent term to constrain the anatomical structure in synthesized images and to guide segmentation without target domian labels. In order to make the synthesis subnet focusing on some hard-to-learn regions automatically, we also introduce the attention block into the generator. On two challenging validation datasets (CHAOS and iSeg-2017), the proposed method achieves superior synthesis performance and comparable segmentation performance.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/liu19b/liu19b.pdf",
        "supp": "",
        "pdf_size": 509878,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9184854448104934784&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "College of Computer Science and Technology, Wuhan University of Science and technology, Wuhan, 430065, China + Hubei Province Key Laboratory of Intelligent Information Processing and Real-time Industrial System, Wuhan, 430065, China; College of Computer Science and Technology, Wuhan University of Science and technology, Wuhan, 430065, China + Hubei Province Key Laboratory of Intelligent Information Processing and Real-time Industrial System, Wuhan, 430065, China; College of Computer Science and Technology, Wuhan University of Science and technology, Wuhan, 430065, China + Hubei Province Key Laboratory of Intelligent Information Processing and Real-time Industrial System, Wuhan, 430065, China; Information Technology Center, Wenzhou Medical University, 325035, China",
        "aff_domain": "gmail.com;foxmail.com;foxmail.com;wmu.edu.cn",
        "email": "gmail.com;foxmail.com;foxmail.com;wmu.edu.cn",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;0+1;0+1;2",
        "aff_unique_norm": "Wuhan University of Science and Technology;Hubei Province Key Laboratory of Intelligent Information Processing and Real-time Industrial System;Wenzhou Medical University",
        "aff_unique_dep": "College of Computer Science and Technology;Intelligent Information Processing and Real-time Industrial System;Information Technology Center",
        "aff_unique_url": "http://www.wust.edu.cn;;",
        "aff_unique_abbr": "WUST;;",
        "aff_campus_unique_index": "0+0;0+0;0+0",
        "aff_campus_unique": "Wuhan;",
        "aff_country_unique_index": "0+0;0+0;0+0;0",
        "aff_country_unique": "China"
    },
    {
        "title": "Variational Conditional GAN for Fine-grained Controllable Image Generation",
        "site": "https://proceedings.mlr.press/v101/hu19a.html",
        "author": "Mingqi Hu; Deyu Zhou; Yulan He",
        "abstract": "In this paper, we propose a novel variational generator framework for conditional GANs to catch semantic details for improving the generation quality and diversity. Traditional generators in conditional GANs simply concatenate the conditional vector with the noise as the input representation, which is directly employed for upsampling operations. However, the hidden condition information is not fully exploited, especially when the input is a class label. Therefore, we introduce a variational inference into the generator to infer the posterior of latent variable only from the conditional input, which helps achieve a variable augmented representation for image generation. Qualitative and quantitative experimental results show that the proposed method outperforms the state-of-the-art approaches and achieves the realistic controllable images.",
        "bibtex": "@InProceedings{pmlr-v101-hu19a,\n  title = \t {Variational Conditional GAN for Fine-grained Controllable Image Generation},\n  author =       {Hu, Mingqi and Zhou, Deyu and He, Yulan},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {109--124},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/hu19a/hu19a.pdf},\n  url = \t {https://proceedings.mlr.press/v101/hu19a.html},\n  abstract = \t {In this paper, we propose a novel variational generator framework for conditional GANs to catch semantic details for improving the generation quality and diversity. Traditional generators in conditional GANs simply concatenate the conditional vector with the noise as the input representation, which is directly employed for upsampling operations. However, the hidden condition information is not fully exploited, especially when the input is a class label. Therefore, we introduce a variational inference into the generator to infer the posterior of latent variable only from the conditional input, which helps achieve a variable augmented representation for image generation. Qualitative and quantitative experimental results show that the proposed method outperforms the state-of-the-art approaches and achieves the realistic controllable images.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/hu19a/hu19a.pdf",
        "supp": "",
        "pdf_size": 2971245,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17642020943809449597&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Southeast University, Nanjing 211189, China; Southeast University, Nanjing 211189, China; University of Warwick, Coventry CV4 7AL, UK",
        "aff_domain": "seu.edu.cn;seu.edu.cn;warwick.ac.uk",
        "email": "seu.edu.cn;seu.edu.cn;warwick.ac.uk",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Southeast University;University of Warwick",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.seu.edu.cn/;https://www.warwick.ac.uk",
        "aff_unique_abbr": "SEU;Warwick",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Nanjing;Coventry",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "China;United Kingdom"
    },
    {
        "title": "Variational Inference from Ranked Samples with Features",
        "site": "https://proceedings.mlr.press/v101/guo19a.html",
        "author": "Yuan Guo; Jennifer Dy; Deniz Erdo\u011fmu\u015f; Jayashree Kalpathy-Cramer; Susan Ostmo; J. Peter Campbell; Michael F. Chiang; Stratis Ioannidis",
        "abstract": "In many supervised learning settings, elicited labels comprise pairwise comparisons or rankings of samples. We propose a Bayesian inference model for ranking datasets, allowing us to take a probabilistic approach to ranking inference. Our probabilistic assumptions are motivated by, and consistent with, the so-called Plackett-Luce model. We propose a variational inference method to extract a closed-form Gaussian posterior distribution. We show experimentally that the resulting posterior yields more reliable ranking predictions compared to predictions via point estimates.",
        "bibtex": "@InProceedings{pmlr-v101-guo19a,\n  title = \t {Variational Inference from Ranked Samples with Features},\n  author =       {Guo, Yuan and Dy, Jennifer and Erdo\\u{g}mu\\c{s}, Deniz and Kalpathy-Cramer, Jayashree and Ostmo, Susan and Campbell, J. Peter and Chiang, Michael F. and Ioannidis, Stratis},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {599--614},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/guo19a/guo19a.pdf},\n  url = \t {https://proceedings.mlr.press/v101/guo19a.html},\n  abstract = \t {In many supervised learning settings, elicited labels comprise pairwise comparisons or rankings of samples. We propose a Bayesian inference model for ranking datasets, allowing us to take a probabilistic approach to ranking inference. Our probabilistic assumptions are motivated by, and consistent with, the so-called Plackett-Luce model. We propose a variational inference method to extract a closed-form Gaussian posterior distribution. We show experimentally that the resulting posterior yields more reliable ranking predictions compared to predictions via point estimates.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/guo19a/guo19a.pdf",
        "supp": "",
        "pdf_size": 544412,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13978631890915362615&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Department of Electrical and Computer Engineering, Northeastern University, MA, USA; Department of Electrical and Computer Engineering, Northeastern University, MA, USA; Department of Electrical and Computer Engineering, Northeastern University, MA, USA; Department of Radiology, Massachusetts General Hospital, MA, USA; Department of Ophthalmology, Casey Eye Institute, Oregon Health &Science University, OR, USA; Department of Ophthalmology, Casey Eye Institute, Oregon Health &Science University, OR, USA; Department of Ophthalmology, Casey Eye Institute, Oregon Health &Science University, OR, USA; Department of Electrical and Computer Engineering, Northeastern University, MA, USA",
        "aff_domain": "ece.neu.edu;ece.neu.edu;ece.neu.edu;nmr.mgh.harvard.edu;ohsu.edu;ohsu.edu;ohsu.edu;ece.neu.edu",
        "email": "ece.neu.edu;ece.neu.edu;ece.neu.edu;nmr.mgh.harvard.edu;ohsu.edu;ohsu.edu;ohsu.edu;ece.neu.edu",
        "github": "",
        "project": "",
        "author_num": 8,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;1;2;2;2;0",
        "aff_unique_norm": "Northeastern University;Massachusetts General Hospital;Oregon Health & Science University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Department of Radiology;Department of Ophthalmology",
        "aff_unique_url": "https://www.northeastern.edu;https://www.massgeneral.org;https://www.ohsu.edu",
        "aff_unique_abbr": "NU;MGH;OHSU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "MA;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "title": "Zero-shot Domain Adaptation Based on Attribute Information",
        "site": "https://proceedings.mlr.press/v101/ishii19a.html",
        "author": "Masato Ishii; Takashi Takenouchi; Masashi Sugiyama",
        "abstract": "In this paper, we propose a novel domain adaptation method that can be applied without target data. We consider the situation where domain shift is caused by a prior change of a specific factor and assume that we know how the prior changes between source and target domains. We call this factor an attribute, and reformulate the domain adaptation problem to utilize the attribute prior instead of target data. In our method, the source data are reweighted with the sample-wise weight estimated by the attribute prior and the data themselves so that they are useful in the target domain. We theoretically reveal that our method provides more precise estimation of sample-wise transferability than a straightforward attribute-based reweighting approach. Experimental results with both toy datasets and benchmark datasets show that our method can perform well, though it does not use any target data.",
        "bibtex": "@InProceedings{pmlr-v101-ishii19a,\n  title = \t {Zero-shot Domain Adaptation Based on Attribute Information},\n  author =       {Ishii, Masato and Takenouchi, Takashi and Sugiyama, Masashi},\n  booktitle = \t {Proceedings of The Eleventh Asian Conference on Machine Learning},\n  pages = \t {473--488},\n  year = \t {2019},\n  editor = \t {Lee, Wee Sun and Suzuki, Taiji},\n  volume = \t {101},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {17--19 Nov},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v101/ishii19a/ishii19a.pdf},\n  url = \t {https://proceedings.mlr.press/v101/ishii19a.html},\n  abstract = \t {In this paper, we propose a novel domain adaptation method that can be applied without target data. We consider the situation where domain shift is caused by a prior change of a specific factor and assume that we know how the prior changes between source and target domains. We call this factor an attribute, and reformulate the domain adaptation problem to utilize the attribute prior instead of target data. In our method, the source data are reweighted with the sample-wise weight estimated by the attribute prior and the data themselves so that they are useful in the target domain. We theoretically reveal that our method provides more precise estimation of sample-wise transferability than a straightforward attribute-based reweighting approach. Experimental results with both toy datasets and benchmark datasets show that our method can perform well, though it does not use any target data.}\n}",
        "pdf": "http://proceedings.mlr.press/v101/ishii19a/ishii19a.pdf",
        "supp": "",
        "pdf_size": 783502,
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=510446398641985974&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "The University of Tokyo + RIKEN Center for Advanced Intelligence Project + NEC Data Science Research Laboratories; Future University of Hakodate + RIKEN Center for Advanced Intelligence Project; RIKEN Center for Advanced Intelligence Project + The University of Tokyo",
        "aff_domain": "gmail.com;fun.ac.jp;k.u-tokyo.ac.jp",
        "email": "gmail.com;fun.ac.jp;k.u-tokyo.ac.jp",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1+2;3+1;1+0",
        "aff_unique_norm": "University of Tokyo;RIKEN;NEC;Future University of Hakodate",
        "aff_unique_dep": ";Center for Advanced Intelligence Project;Data Science Research Laboratories;",
        "aff_unique_url": "https://www.u-tokyo.ac.jp;https://www.riken.jp/en/;https://www.nec.com;http://www.fu-hakodate.ac.jp/",
        "aff_unique_abbr": "UTokyo;RIKEN;NEC;FUH",
        "aff_campus_unique_index": ";;",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0+0+0;0+0;0+0",
        "aff_country_unique": "Japan"
    }
]