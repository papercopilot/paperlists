[
    {
        "id": "06384",
        "title": "(Comet-) Atomic 2020: On Symbolic and Neural Commonsense Knowledge Graphs",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent years have brought about a renewed interest in commonsense representation and reasoning in the field of natural language understanding. The development of new commonsense knowledge graphs (CSKG) has been central to these advances as their diverse facts can be used and referenced by machine learning models for tackling new and challenging tasks. At the same time, there remain questions about the quality and coverage of these resources due to the massive scale required to comprehensively encompass general commonsense knowledge.  In this work, we posit that manually constructed CSKGs will never achieve the coverage necessary to be applicable in all situations encountered by NLP agents. Therefore, we propose a new evaluation framework for testing the utility of KGs based on how effectively implicit knowledge representations can be learned from them. \u00a0 With this new goal, we propose Atomic 2020, a new CSKG of general-purpose commonsense knowledge containing knowledge that is not readily available in pretrained language models. We evaluate its properties in comparison with other leading CSKGs, performing the first large-scale pairwise study of commonsense knowledge resources. Next, we show that Atomic 2020 is better suited for training knowledge models that can generate accurate, representative knowledge for new, unseen entities and events. Finally, through human evaluation, we show that the few-shot performance of GPT-3 (175B parameters), while impressive, remains ~12 absolute points lower than a BART-based knowledge model trained on Atomic 2020 despite using over 430x fewer parameters.",
        "primary_area": "Knowledge Representation and Reasoning",
        "author": "Jena D. Hwang; Chandra Bhagavatula; Ronan Le Bras; Jeff Da; Keisuke Sakaguchi; Antoine Bosselut; Yejin Choi",
        "authorids": "",
        "aff": "Allen Institute for AI; Allen Institute for AI; Allen Institute for AI; Allen Institute for AI; Allen Institute for AI; Stanford University Allen Institute for AI; University of Washington Allen Institute for AI",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16792/16792-13-20286-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06384-comet-atomic-2020-on-symbolic-and-neural-commonsense-knowledge-graphs/",
        "doi": "10.1609/aaai.v35i7.16792",
        "pdf_size": 216830
    },
    {
        "id": "09949",
        "title": "*-CFQ: Analyzing the Scalability of Machine Learning on a Compositional Task",
        "track": "main",
        "status": "Poster",
        "abstract": "We present *-CFQ (\"star-CFQ\"): a suite of large-scale datasets of varying scope based on the CFQ semantic parsing benchmark, designed for principled investigation of the scalability of machine learning systems in a realistic compositional task setting. Using this suite, we conduct a series of experiments investigating the ability of Transformers to benefit from increased training data size under conditions of fixed computational cost. We show that compositional generalization remains a challenge at all training sizes, and we show that increasing the scope of natural language leads to consistently higher error rates, which are only partially offset by increased training data. We further show that while additional training data from a related domain improves the accuracy in data-starved situations, this improvement is limited and diminishes as the distance from the related domain to the target domain increases.",
        "primary_area": "Machine Learning IV",
        "author": "Dmitry Tsarkov; Tibor Tihon; Nathan Scales; Nikola Momchev; Danila Sinopalnikov; Nathanael Sch\u00e4rli",
        "authorids": "",
        "aff": "Google; Google; Google; Google; Google; Google",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17195/17195-13-20689-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09949-cfq-analyzing-the-scalability-of-machine-learning-on-a-compositional-task/",
        "doi": "10.1609/aaai.v35i11.17195",
        "pdf_size": 355378
    },
    {
        "id": "09064",
        "title": "5* Knowledge Graph Embeddings with Projective Transformations",
        "track": "main",
        "status": "Poster",
        "abstract": "Performing link prediction using knowledge graph embedding models has become a popular approach for knowledge graph completion. Such models employ a transformation function that maps nodes via edges into a vector space in order to measure the likelihood of the links. While mapping the individual nodes, the structure of subgraphs is also transformed. Most of the embedding models designed in Euclidean geometry usually support a single transformation type -- often translation or rotation, which is suitable for learning on graphs with small differences in neighboring subgraphs. However, multi-relational knowledge graphs often include multiple subgraph structures in a neighborhood (e.g.~combinations of path and loop structures), which current embedding models do not capture well. To tackle this problem, we propose a novel KGE model 5*E in projective geometry, which supports multiple simultaneous transformations -- specifically inversion, reflection, translation, rotation, and homothety. The model has several favorable theoretical properties and subsumes the existing approaches. It outperforms them on most widely used link prediction benchmarks",
        "primary_area": "Machine Learning III",
        "author": "Mojtaba Nayyeri; Sahar Vahdati; Can Aykul; Jens Lehmann",
        "authorids": "",
        "aff": "Smart Data Analytics Group, University of Bonn, Germany Nature-Inspired Machine Intelligence-InfAI, Dresden, Germany; Nature-Inspired Machine Intelligence-InfAI, Dresden, Germany; Smart Data Analytics Group, University of Bonn, Germany; Smart Data Analytics Group, University of Bonn Fraunhofer IAIS, Dresden, German",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17095/17095-13-20589-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09064-5-knowledge-graph-embeddings-with-projective-transformations/",
        "doi": "10.1609/aaai.v35i10.17095",
        "pdf_size": 12732732
    },
    {
        "id": "08384",
        "title": "A Bayesian Approach for Subset Selection in Contextual Bandits",
        "track": "main",
        "status": "Poster",
        "abstract": "Subset selection in Contextual Bandits (CB) is an important task in various applications such as advertisement recommendation. In CB, arms are attached with contexts and thus correlated in the context space. Proper exploration for subset selection in CB should carefully consider the contexts. Previous works mainly concentrate on the best one arm identification in linear bandit problems, where the expected rewards are linearly dependent on the contexts. However, these methods highly rely on linearity, and cannot be easily extended to more general cases. We propose a novel Bayesian approach for subset selection in general CB where the reward functions can be nonlinear. Our method provides a principled way to employ contextual information and efficiently explore the arms. For cases with relatively smooth posteriors, we give theoretical results that are comparable to previous works. For general cases, we provide a calculable approximate variant. Empirical results show the effectiveness of our method on both linear bandits and general CB.",
        "primary_area": "Machine Learning II",
        "author": "Jialian Li; Chao Du; Jun Zhu",
        "authorids": "",
        "aff": "Tsinghua University; Alibaba Group; Tsinghua University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17019/17019-13-20513-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08384-a-bayesian-approach-for-subset-selection-in-contextual-bandits/",
        "doi": "10.1609/aaai.v35i9.17019",
        "pdf_size": 351084
    },
    {
        "id": "13889",
        "title": "A Bidirectional Multi-paragraph Reading Model for Zero-shot Entity Linking",
        "track": "main",
        "status": "Poster",
        "abstract": "Recently, a zero-shot entity linking task is introduced to challenge the generalization ability of entity linking models. In this task, mentions must be linked to unseen entities and only the textual information is available. In order to make full use of the documents, previous work has proposed a BERT-based model which can only take fixed length of text as input. However, the key information for entity linking may exist in nearly everywhere of the documents thus the proposed model cannot capture them all. To leverage more textual information and enhance text understanding capability, we propose a bidirectional multi-paragraph reading model for the zero-shot entity linking task. Firstly, the model treats the mention context as a query and matches it with multiple paragraphs of the entity description documents. Then, the mention-aware entity representation obtained from the first step is used as a query to match multiple paragraphs in the document containing the mention through an entity-mention attention mechanism. In particular, a new pre-training strategy is employed to strengthen the representative ability. Experimental results show that our bidirectional model can capture long-range context dependencies and outperform the baseline model by 3-4% in terms of accuracy.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Hongyin Tang; Xingwu Sun; Beihong Jin; Fuzheng Zhang",
        "authorids": "",
        "aff": "State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences University of Chinese Academy of Sciences, Beijing China; Meituan-Dianping Group, China; State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences University of Chinese Academy of Sciences, Beijing China; Meituan-Dianping Group, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17636/17636-13-21130-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13889-a-bidirectional-multi-paragraph-reading-model-for-zero-shot-entity-linking/",
        "doi": "10.1609/aaai.v35i15.17636",
        "pdf_size": 1055109
    },
    {
        "id": "06868",
        "title": "A Blind Block Term Decomposition of High Order Tensors",
        "track": "main",
        "status": "Poster",
        "abstract": "Tensor decompositions have found many applications in signal processing, data mining, machine learning, etc.  In particular, the block term decomposition (BTD), which is a generalization of CP decomposition and Tucker decomposition/HOSVD,  has been successfully used for the compression and acceleration of neural networks.  However, computing BTD is NP-hard, and optimization based methods usually suffer from slow convergence or even fail to converge, which limits the applications of BTD.  This paper considers a \u201cblind\u201d block term decomposition (BBTD) of high order tensors, in which the block diagonal structure of the core tensor is unknown.  Our contributions include:  1) We establish the necessary and sufficient conditions for the existence of BTD, characterize the condition when a BTD solves the BBTD problem, and show that the BBTD is unique under a \u201clow rank\u201d assumption.  2) We propose an algebraic method to compute the BBTD.  This method transforms the problem of determining the block diagonal structure of the core tensor into a clustering problem of complex numbers, in polynomial time.  And once the clustering problem is solved, the BBTD can be obtained via computing several matrix decompositions. Numerical results show that our method is able to compute the BBTD, even in the presence of noise to some extent,  whereas optimization based methods (e.g., MINF and NLS in TENSORLAB) may fail to converge.",
        "primary_area": "Machine Learning I",
        "author": "Yunfeng Cai; Ping Li",
        "authorids": "",
        "aff": "Baidu Research; Baidu Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16847/16847-13-20341-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06868-a-blind-block-term-decomposition-of-high-order-tensors/",
        "doi": "10.1609/aaai.v35i8.16847",
        "pdf_size": 331177
    },
    {
        "id": "00039",
        "title": "A Bottom-Up DAG Structure Extraction Model for Math Word Problems",
        "track": "main",
        "status": "Poster",
        "abstract": "Research on automatically solving mathematical word problems (MWP) has a long history. Most recent works adopt Seq2Seq approach to predict the result equations as a sequence of quantities and operators. Although result equations can be written as a sequence, it is essentially a structure. More precisely, it is a Direct Acyclic Graph (DAG) whose leaf nodes are the quantities, and internal and root nodes are arithmetic or comparison operators. In this paper, we propose a novel Seq2DAG approach to extract the equation set directly as a DAG structure. It is extracted in a bottom-up fashion by aggregating quantities and sub-expressions layer by layer iteratively. The advantages of our approach approach are three-fold: it is intrinsically suitable to solve multivariate problems, it always outputs valid structure, and its computation satisfies commutative law for +, x and =. Experimental results on Math23K and DRAW1K demonstrate that our model outperforms state-of-the-art deep learning methods. We also conduct detailed analysis on the results to show the strengths and limitations of our approach.",
        "primary_area": "Application Domains",
        "author": "Yixuan Cao; Feng Hong; Hongwei Li; Ping Luo",
        "authorids": "",
        "aff": "Institute of Computing Technology, Chinese Academy of Sciences University of Chinese Academy of Sciences; Institute of Computing Technology, Chinese Academy of Sciences University of Chinese Academy of Sciences; Institute of Computing Technology, Chinese Academy of Sciences University of Chinese Academy of Sciences; Institute of Computing Technology, Chinese Academy of Sciences University of Chinese Academy of Sciences Peng Cheng Laboratory, Shenzhen, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16075/16075-13-19569-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00039-a-bottom-up-dag-structure-extraction-model-for-math-word-problems/",
        "doi": "10.1609/aaai.v35i1.16075",
        "pdf_size": 1758003
    },
    {
        "id": "03181",
        "title": "A Case Study of the Shortcut Effects in Visual Commonsense Reasoning",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual reasoning and question-answering have gathered attention in recent years. Many datasets and evaluation protocols have been proposed; some have been shown to contain bias that allows models to ``cheat'' without performing true, generalizable reasoning. A well-known bias is dependence on language priors (frequency of answers) resulting in the model not looking at the image. We discover a new type of bias in the Visual Commonsense Reasoning (VCR) dataset. In particular we show that most state-of-the-art models exploit co-occurring text between input (question) and output (answer options), and rely on only a few pieces of information in the candidate options, to make a decision. Unfortunately, relying on such superficial evidence causes models to be very fragile. To measure fragility, we propose two ways to modify the validation data, in which a few words in the answer choices are modified without significant changes in meaning. We find such insignificant changes cause models' performance to degrade significantly. To resolve the issue, we propose a curriculum-based masking approach, as a mechanism to perform more robust training. Our method improves the baseline by requiring it to pay attention to the answers as a whole, and is more effective than prior masking strategies.",
        "primary_area": "Computer Vision III",
        "author": "Keren Ye; Adriana Kovashka",
        "authorids": "",
        "aff": "University of Pittsburgh; University of Pittsburgh",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16428/16428-13-19922-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03181-a-case-study-of-the-shortcut-effects-in-visual-commonsense-reasoning/",
        "doi": "10.1609/aaai.v35i4.16428",
        "pdf_size": 8638003
    },
    {
        "id": "11990",
        "title": "A Complexity-theoretic Analysis of Green Pickup-and-Delivery Problems",
        "track": "main",
        "status": "Poster",
        "abstract": "In a Green Pickup-and-Delivery problem (GPD), vehicles traveling in a transport network achieving pickup-and-delivery tasks are in particular subject to the two textit{green} constraints: limited vehicle fuel capacity thus short vehicle traveling range, and limited availability of refueling infrastructure for the vehicles. GPD adds additional but probably insignificant computational complexity to the classic and already NP-hard Pickup-and-Delivery problem and Vehicle Routing Problem. Nevertheless, we demonstrate in this paper an inherent intractability of these green components themselves. More precisely, we show that GPD problems whose total constraints are reduced to almost the green ones only, remain to be NP-complete in the strong sense. We figure out a specifically constrained variant of GPD that, however, is weakly NP-complete -- a practical pseudo-polynomial time algorithm solving the variant problem is identified. Insight obtained from this complexity-theoretic analysis would shed light for a deeper understanding of GPDs, and on better development of heuristics for solving these problems, leading to promisingly many real-world applications.",
        "primary_area": "Planning, Routing, and Scheduling",
        "author": "Xing Tan; Jimmy Xiangji Huang",
        "authorids": "",
        "aff": "York University, Toronto, ON, Canada; York University, Toronto, ON, Canada",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17424/17424-13-20918-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11990-a-complexity-theoretic-analysis-of-green-pickup-and-delivery-problems/",
        "doi": "10.1609/aaai.v35i13.17424",
        "pdf_size": 188344
    },
    {
        "id": "06030",
        "title": "A Continual Learning Framework for Uncertainty-Aware Interactive Image Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep learning models have achieved state-of-the-art performance in semantic image segmentation, but the results provided by fully automatic algorithms are not always guaranteed satisfactory to users. Interactive segmentation offers a solution by accepting user annotations on selective areas of the images to refine the segmentation results. However, most existing models only focus on correcting the current image's misclassified pixels, with no knowledge carried over to other images. In this work, we formulate interactive image segmentation as a continual learning problem and propose a framework to effectively learn from user annotations, aiming to improve the segmentation on both the current image and unseen images in future tasks while avoiding deteriorated performance on previously-seen images. It employs a probabilistic mask to control the neural network's kernel activation and extract the most suitable features for segmenting images in each task. We also apply a task-aware embedding to automatically infer the optimal kernel activation for initial segmentation and subsequent refinement. Interactions with users are guided through multi-source uncertainty estimation so that users can focus on the most important areas to minimize the overall manual annotation effort. Experiments are performed on both medical and natural image datasets to illustrate the proposed framework's effectiveness on basic segmentation performance, forward knowledge transfer, and backward knowledge transfer.",
        "primary_area": "Humans and AI",
        "author": "Ervine Zheng; Qi Yu; Rui Li; Pengcheng Shi; Anne Haake",
        "authorids": "",
        "aff": "Rochester Institute of Technology; Rochester Institute of Technology; Rochester Institute of Technology; Rochester Institute of Technology; Rochester Institute of Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16752/16752-13-20246-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06030-a-continual-learning-framework-for-uncertainty-aware-interactive-image-segmentation/",
        "doi": "10.1609/aaai.v35i7.16752",
        "pdf_size": 1506768
    },
    {
        "id": "14085",
        "title": "A Controllable Model of Grounded Response Generation",
        "track": "main",
        "status": "Poster",
        "abstract": "Current end-to-end neural conversation models inherently lack the flexibility to impose semantic control in the response generation process, often resulting in uninteresting responses. Attempts to boost informativeness alone come at the expense of factual accuracy, as attested by pretrained language models' propensity to \"hallucinate\" facts. While this may be mitigated by access to background knowledge, there is scant guarantee of relevance and informativeness in generated responses. We propose a framework that we call controllable grounded response generation (CGRG), in which lexical control phrases are either provided by a user or automatically extracted by a control phrase predictor from dialogue context and grounding knowledge. Quantitative and qualitative results show that, using this framework, a transformer based model with a novel inductive attention mechanism, trained on a conversation-like Reddit dataset, outperforms strong generation baselines.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Zeqiu Wu; Michel Galley; Chris Brockett; Yizhe Zhang; Xiang Gao; Chris Quirk; Rik Koncel-Kedziorski; Jianfeng Gao; Hannaneh Hajishirzi; Mari Ostendorf; Bill Dolan",
        "authorids": "",
        "aff": "University of Washington; Microsoft Research; Microsoft Research; Microsoft Research; Microsoft Research; Microsoft Research; University of Washington; Microsoft Research; University of Washington Allen Institute for AI; University of Washington; Microsoft Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17658/17658-13-21152-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14085-a-controllable-model-of-grounded-response-generation/",
        "doi": "10.1609/aaai.v35i16.17658",
        "pdf_size": 1007395
    },
    {
        "id": "06279",
        "title": "A Deep Reinforcement Learning Approach to First-Order Logic Theorem Proving",
        "track": "main",
        "status": "Poster",
        "abstract": "Automated theorem provers have traditionally relied on manually tuned heuristics to guide how they perform proof search. Deep reinforcement learning has been proposed as a way to obviate the need for such heuristics, however, its deployment in automated theorem proving remains a challenge. In this paper we introduce TRAIL, a system that applies deep reinforcement learning to saturation-based theorem proving. TRAIL leverages (a) a novel neural representation of the state of a theorem prover and (b) a novel characterization of the inference selection process in terms of an attention-based action policy. We show through systematic analysis that these mechanisms allow TRAIL to significantly outperform previous reinforcement-learning-based theorem provers on two benchmark datasets for first-order logic automated theorem proving (proving around 15% more theorems).",
        "primary_area": "Knowledge Representation and Reasoning",
        "author": "Maxwell Crouse; Ibrahim Abdelaziz; Bassem Makni; Spencer Whitehead; Cristina Cornelio; Pavan Kapanipathi; Kavitha Srinivas; Veronika Thost; Michael Witbrock; Achille Fokoue",
        "authorids": "",
        "aff": "Northwestern University; IBM Research; IBM Research; University of Illinois at Urbana-Champaign; IBM Research; IBM Research; IBM Research; MIT-IBM Watson AI Lab; The University of Auckland; IBM Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16780/16780-13-20274-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06279-a-deep-reinforcement-learning-approach-to-first-order-logic-theorem-proving/",
        "doi": "10.1609/aaai.v35i7.16780",
        "pdf_size": 541475
    },
    {
        "id": "09481",
        "title": "A Deeper Look at the Hessian Eigenspectrum of Deep Neural Networks and its Applications to Regularization",
        "track": "main",
        "status": "Poster",
        "abstract": "Loss landscape analysis is extremely useful for a deeper understanding of the generalization ability of deep neural network models. In this work, we propose a layerwise loss landscape analysis where the loss surface at every layer is studied independently and also on how each correlates to the overall loss surface. We study the layerwise loss landscape by studying the eigenspectra of the Hessian at each layer. In particular, our results show that the layerwise Hessian geometry is largely similar to the entire Hessian. We also report an interesting phenomenon where the Hessian eigenspectrum of middle layers of the deep neural network are observed to most similar to the overall Hessian eigenspectrum. We also show that the maximum eigenvalue and the trace of the Hessian (both full network and layerwise) reduce as training of the network progresses. We leverage on these observations to propose a new regularizer based on the trace of the layerwise Hessian. Penalizing the trace of the Hessian at every layer indirectly forces Stochastic Gradient Descent to converge to flatter minima, which are shown to have better generalization performance. In particular, we show that such a layerwise regularizer can be leveraged to penalize the middlemost layers alone, which yields promising results. Our empirical studies on well-known deep nets across datasets support the claims of this work.",
        "primary_area": "Machine Learning IV",
        "author": "Adepu Ravi Sankar; Yash Khasbage; Rahul  Vigneswaran; Vineeth N Balasubramanian",
        "authorids": "",
        "aff": "Indian Institute of Technology, Hyderabad; Indian Institute of Technology, Hyderabad; Indian Institute of Technology, Hyderabad; Indian Institute of Technology, Hyderabad",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17142/17142-13-20636-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09481-a-deeper-look-at-the-hessian-eigenspectrum-of-deep-neural-networks-and-its-applications-to-regularization/",
        "doi": "10.1609/aaai.v35i11.17142",
        "pdf_size": 3953882
    },
    {
        "id": "12217",
        "title": "A Fast Exact Algorithm for the Resource Constrained Shortest Path Problem",
        "track": "main",
        "status": "Poster",
        "abstract": "Resource constrained path finding is a well studied topic in AI, with real-world applications in different areas such as transportation and robotics. This paper introduces several heuristics in the resource constrained path finding context that significantly improve the algorithmic performance of the initialisation phase and the core search. We implement our heuristics on top of a bidirectional A* algorithm and evaluate them on a set of large instances. The experimental results show that, for the first time in the context of constrained path finding, our fast and enhanced algorithm can solve all of the benchmark instances to optimality, and compared to the state of the art algorithms, it can improve existing runtimes by up to four orders of magnitude on large-size network graphs.",
        "primary_area": "Search and Optimization",
        "author": "Saman Ahmadi; Guido Tack; Daniel D. Harabor; Philip Kilby",
        "authorids": "",
        "aff": "Monash University, Australia CSIRO Data61, Australia; Monash University, Australia; Monash University, Australia; CSIRO Data61, Australia",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17450/17450-13-20944-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12217-a-fast-exact-algorithm-for-the-resource-constrained-shortest-path-problem/",
        "doi": "10.1609/aaai.v35i14.17450",
        "pdf_size": 158664
    },
    {
        "id": "05078",
        "title": "A Few Queries Go a Long Way: Information-Distortion Tradeoffs in Matching",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider the one-sided matching problem, where n agents have preferences over n items, and these preferences are induced by underlying cardinal valuation functions. The goal is to match every agent to a single item so as to maximize the social welfare. Most of the related literature, however, assumes that the values of the agents are not a priori known, and only access to the ordinal preferences of the agents over the items is provided. Consequently, this incomplete information leads to loss of efficiency, which is measured by the notion of distortion. In this paper, we further assume that the agents can answer a small number of queries, allowing us partial access to their values. We study the interplay between elicited cardinal information (measured by the number of queries per agent) and distortion for one-sided matching, as well as a wide range of well-studied related problems. Qualitatively, our results show that with a limited number of queries, it is possible to obtain significant improvements over the classic setting, where only access to ordinal information is given.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Georgios Amanatidis; Georgios Birmpas; Aris Filos-Ratsikas; Alexandros A. Voudouris",
        "authorids": "",
        "aff": "Department of Mathematical Sciences, University of Essex ILLC, University of Amsterdam; Department of Computer, Control and Management Engineering, Sapienza University of Rome; Department of Computer Science, University of Liverpool; School of Computer Science and Electronic Engineering, University of Essex",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16642/16642-13-20136-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05078-a-few-queries-go-a-long-way-information-distortion-tradeoffs-in-matching/",
        "doi": "10.1609/aaai.v35i6.16642",
        "pdf_size": 169342
    },
    {
        "id": "08101",
        "title": "A Flexible Framework for Communication-Efficient Machine Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "With the increasing scale of machine learning tasks, it has become essential to reduce the communication between computing nodes. Early work on gradient compression focused on the bottleneck between CPUs and GPUs, but  communication-efficiency is now needed in a variety of  different system architectures, from high-performance clusters to energy-constrained IoT devices. In the current practice, compression levels are typically chosen before training and settings that work well for one task may be vastly suboptimal for another dataset on another architecture. In this paper, we propose a flexible framework which adapts the compression level to the true gradient at each iteration, maximizing the improvement in the objective function that is achieved per communicated bit. Our framework is easy to adapt from one technology to the next by modeling how the communication cost depends on the compression level for the specific technology. Theoretical results and practical experiments indicate that the automatic tuning strategies significantly increase communication efficiency on several state-of-the-art compression schemes.",
        "primary_area": "Machine Learning II",
        "author": "Sarit Khirirat; Sindri Magn\u00fasson; Arda Aytekin; Mikael Johansson",
        "authorids": "",
        "aff": "KTH Royal Institute of Technology; Stockholm University; Ericsson AB; KTH Royal Institute of Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16987/16987-13-20481-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08101-a-flexible-framework-for-communication-efficient-machine-learning/",
        "doi": "10.1609/aaai.v35i9.16987",
        "pdf_size": 536511
    },
    {
        "id": "08474",
        "title": "A Free Lunch for Unsupervised Domain Adaptive Object Detection without Source Data",
        "track": "main",
        "status": "Poster",
        "abstract": "Unsupervised domain adaptation (UDA) assumes that source and target domain data are freely available and usually trained together to reduce the domain gap. However, considering the data privacy and the inefficiency of data transmission, it is impractical in real scenarios. Hence, it draws our eyes to optimize the network in the target domain without accessing labeled source data. To explore this direction in object detection, for the first time, we propose a source data-free domain adaptive object detection (SFOD) framework via modeling it into a problem of learning with noisy labels. Generally, a straightforward method is to leverage the pre-trained network from the source domain to generate the pseudo labels for target domain optimization. However, it is difficult to evaluate the quality of pseudo labels since no labels are available in target domain. In this paper, self-entropy descent (SED) is a metric proposed to search an appropriate confidence threshold for reliable pseudo label generation without using any handcrafted labels. Nonetheless, completely clean labels are still unattainable. After a thorough experimental analysis, false negatives are found to dominate in the generated noisy labels. Undoubtedly, false negatives mining is helpful for performance improvement, and we ease it to false negatives simulation through data augmentation like Mosaic. Extensive experiments conducted in four representative adaptation tasks have demonstrated that the proposed framework can easily achieve state-of-the-art performance. From another view, it also reminds the UDA community that the labeled source data are not fully exploited in the existing methods.",
        "primary_area": "Machine Learning III",
        "author": "Xianfeng Li; Weijie Chen; Di Xie; Shicai Yang; Peng Yuan; Shiliang Pu; Yueting Zhuang",
        "authorids": "",
        "aff": "South China University of Technology; Zhejiang University Hikvision Research Institute; Hikvision Research Institute; Hikvision Research Institute; Hikvision Research Institute; Hikvision Research Institute; Zhejiang University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17029/17029-13-20523-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08474-a-free-lunch-for-unsupervised-domain-adaptive-object-detection-without-source-data/",
        "doi": "10.1609/aaai.v35i10.17029",
        "pdf_size": 3851647
    },
    {
        "id": "08992",
        "title": "A General Class of Transfer Learning Regression without Implementation Cost",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a novel framework that unifies and extends existing methods of transfer learning (TL) for regression. To bridge a pretrained source model to the model on a target task, we introduce a density-ratio reweighting function, which is estimated through the Bayesian framework with a specific prior distribution. By changing two intrinsic hyperparameters and the choice of the density-ratio model, the proposed method can integrate three popular methods of TL: TL based on cross-domain similarity regularization, a probabilistic TL using the density-ratio estimation, and fine-tuning of pretrained neural networks. Moreover, the proposed method can benefit from its simple implementation without any additional cost; the regression model can be fully trained using off-the-shelf libraries for supervised learning in which the original output variable is simply transformed to a new output variable. We demonstrate its simplicity, generality, and applicability using various real data applications.",
        "primary_area": "Machine Learning III",
        "author": "Shunya Minami; Song Liu; Stephen Wu; Kenji Fukumizu; Ryo Yoshida",
        "authorids": "",
        "aff": "The Graduate University for Advanced Studies; University of Bristol; The Institute of Statistical Mathematics The Graduate University for Advanced Studies; The Institute of Statistical Mathematics The Graduate University for Advanced Studies; The Institute of Statistical Mathematics The Graduate University for Advanced Studies National Institute for Materials Science",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17087/17087-13-20581-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08992-a-general-class-of-transfer-learning-regression-without-implementation-cost/",
        "doi": "10.1609/aaai.v35i10.17087",
        "pdf_size": 619157
    },
    {
        "id": "04512",
        "title": "A General Offline Reinforcement Learning Framework for Interactive Recommendation",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper studies the problem of learning interactive recommender systems from logged  feedbacks without any exploration in online environments. We address the problem by proposing a general offline reinforcement learning framework for recommendation, which enables maximizing cumulative user rewards without online exploration. Specifically, we first introduce a probabilistic generative model for  interactive recommendation, and then propose an effective inference algorithm for discrete and stochastic policy learning based on logged  feedbacks. In order to perform offline learning more effectively, we propose five approaches to minimize the distribution mismatch between the logging policy and recommendation policy: support constraints, supervised regularization, policy constraints, dual constraints and reward extrapolation. We conduct extensive  experiments on two public real-world datasets,  demonstrating that the proposed methods can achieve superior performance over existing supervised learning and reinforcement learning methods for  recommendation.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Teng Xiao; Donglin Wang",
        "authorids": "",
        "aff": "Machine Intelligence Lab (MiLAB), AI Division, School of Engineering, Westlake University; Machine Intelligence Lab (MiLAB), AI Division, School of Engineering, Westlake University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16579/16579-13-20073-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04512-a-general-offline-reinforcement-learning-framework-for-interactive-recommendation/",
        "doi": "10.1609/aaai.v35i5.16579",
        "pdf_size": 191359
    },
    {
        "id": "06185",
        "title": "A General Setting for Gradual Semantics Dealing with Similarity",
        "track": "main",
        "status": "Poster",
        "abstract": "The paper discusses theoretical foundations that  describe principles and processes involved in defining semantics that deal with similarity  between arguments.   Such semantics compute the strength of an argument on the basis of the strengths of its attackers, similarities between those attackers, and an initial weight ascribed to the argument.   We define a semantics by three functions: an adjustment function that updates the strengths of attackers on the basis of their similarities, an aggregation function that computes the strength of the group of attackers,   and an influence function that evaluates the impact of the group on the argument's initial weight.  We propose intuitive constraints for the three functions and key rationality principles for semantics, and show how the former lead to the satisfaction of the latter. Then, we propose a broad family of semantics whose instances satisfy the principles.  Finally, we analyse the existing adjustment functions and show that they violate some properties, then we propose novel ones and use them for generalizing h-Categorizer.",
        "primary_area": "Knowledge Representation and Reasoning",
        "author": "Leila Amgoud; Victor David",
        "authorids": "",
        "aff": "IRIT - CNRS - ANITI - Toulouse University; IRIT - CNRS - Toulouse University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16769/16769-13-20263-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06185-a-general-setting-for-gradual-semantics-dealing-with-similarity/",
        "doi": "10.1609/aaai.v35i7.16769",
        "pdf_size": 223608
    },
    {
        "id": "12104",
        "title": "A Generative Adversarial Framework for Bounding Confounded Causal Effects",
        "track": "main",
        "status": "Poster",
        "abstract": "Causal inference from observational data is receiving wide applications in many fields. However, unidentifiable situations, where causal effects cannot be uniquely computed from observational data, pose critical barriers to applying causal inference to complicated real applications. In this paper, we develop a bounding method for estimating the average causal effect (ACE) under unidentifiable situations due to hidden confounding based on Pearl's structural causal model. We propose to parameterize the unknown exogenous random variables and structural equations of a causal model using neural networks and implicit generative models. Then, using an adversarial learning framework, we search the parameter space to explicitly traverse causal models that agree with the given observational distribution, and find those that minimize or maximize the ACE to obtain its lower and upper bounds. The proposed method does not make assumption about the type of structural equations and variables. Experiments using both synthetic and real-world datasets are conducted.",
        "primary_area": "Reasoning under Uncertainty",
        "author": "Yaowei Hu; Yongkai Wu; Lu Zhang; Xintao Wu",
        "authorids": "",
        "aff": "University of Arkansas; Clemson University; University of Arkansas; University of Arkansas",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17437/17437-13-20931-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12104-a-generative-adversarial-framework-for-bounding-confounded-causal-effects/",
        "doi": "10.1609/aaai.v35i13.17437",
        "pdf_size": 563909
    },
    {
        "id": "02260",
        "title": "A Global Occlusion-Aware Approach to Self-Supervised Monocular Visual Odometry",
        "track": "main",
        "status": "Poster",
        "abstract": "Self-Supervised monocular visual odometry (VO) is often cast into a view synthesis problem based on depth and camera pose estimation. One of the key challenges is to accurately and robustly estimate depth with occlusions and moving objects in the scene. Existing methods simply detect and mask out regions of occlusions locally by several convolutional layers, and then perform only partial view synthesis in the rest of the image. However, occlusion and moving object detection is an unsolved problem itself which requires global layout information. Inaccurate detection inevitably results in incorrect depth as well as pose estimation. In this work, instead of locally detecting and masking out occlusions and moving objects, we propose to alleviate their negative effects on monocular VO implicitly but more effectively from two global perspectives. First, a multi-scale non-local attention module, consisting of both intra-stage augmented attention and cascaded across-stage attention, is proposed for robust depth estimation given occlusions, alleviating the impacts of occlusions via global attention modeling. Second, adversarial learning is introduced in view synthesis for monocular VO. Unlike existing methods that use pixel-level losses on the quality of synthesized views, we enforce the synthetic view to be indistinguishable from the real one at the scene-level. Such a global constraint again helps cope with occluded and moving regions. Extensive experiments on the KITTI dataset show that our approach achieves new state-of-the-art in both pose estimation and depth recovery.",
        "primary_area": "Computer Vision II",
        "author": "Yao Lu; Xiaoli Xu; Mingyu Ding; Zhiwu Lu; Tao Xiang",
        "authorids": "",
        "aff": "Renmin University of China Beijing Key Laboratory of Big Data Management and Analysis Methods; Renmin University of China Beijing Key Laboratory of Big Data Management and Analysis Methods; The University of Hong Kong; Renmin University of China Beijing Key Laboratory of Big Data Management and Analysis Methods; University of Surrey",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16325/16325-13-19819-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02260-a-global-occlusion-aware-approach-to-self-supervised-monocular-visual-odometry/",
        "doi": "10.1609/aaai.v35i3.16325",
        "pdf_size": 1132154
    },
    {
        "id": "13433",
        "title": "A Graph Reasoning Network for Multi-turn Response Selection via Customized Pre-training",
        "track": "main",
        "status": "Poster",
        "abstract": "We investigate response selection for multi-turn conversation in retrieval-based chatbots. Existing studies pay more attention to the matching between utterances and responses by calculating the matching score based on learned features, leading to insufficient model reasoning ability. In this paper, we propose a graph- reasoning network (GRN) to address the problem. GRN first conducts pre-training based on ALBERT using next utterance prediction and utterance order prediction tasks specifically devised for response selection. These two customized pre-training tasks can endow our model with the ability of capturing semantical and chronological dependency between utterances. We then fine-tune the model on an integrated network with sequence reasoning and graph reasoning structures. The sequence reasoning module conducts inference based on the highly summarized context vector of utterance-response pairs from the global perspective. The graph reasoning module conducts the reasoning on the utterance-level graph neural network from the local perspective. Experiments on two conversational reasoning datasets show that our model can dramatically outperform the strong baseline methods and can achieve performance which is close to human-level.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Yongkang Liu; Shi Feng; Daling Wang; Kaisong Song; Feiliang Ren; Yifei Zhang",
        "authorids": "",
        "aff": "Northeastern University; Northeastern University; Northeastern University; Alibaba Group; Northeastern University; Northeastern University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17585/17585-13-21079-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13433-a-graph-reasoning-network-for-multi-turn-response-selection-via-customized-pre-training/",
        "doi": "10.1609/aaai.v35i15.17585",
        "pdf_size": 385110
    },
    {
        "id": "04688",
        "title": "A Graph-based Relevance Matching Model for Ad-hoc Retrieval",
        "track": "main",
        "status": "Poster",
        "abstract": "To retrieve more relevant, appropriate and useful documents given a query, finding clues about that query through the text is crucial. Recent deep learning models regard the task as a term-level matching problem, which seeks exact or similar query patterns in the document. However, we argue that they are inherently based on local interactions and do not generalise to ubiquitous, non-consecutive contextual relationships. In this work, we propose a novel relevance matching model based on graph neural networks to leverage the document-level word relationships for ad-hoc retrieval. In addition to the local interactions, we explicitly incorporate all contexts of a term through the graph-of-word text format. Matching patterns can be revealed accordingly to provide a more accurate relevance score. Our approach significantly outperforms strong baselines on two ad-hoc benchmarks. We also experimentally compare our model with BERT and show our advantages on long documents.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Yufeng Zhang; Jinghao Zhang; Zeyu Cui; Shu Wu; Liang Wang",
        "authorids": "",
        "aff": "Institute of Automation, Chinese Academy of Sciences; Institute of Automation, Chinese Academy of Sciences University of Chinese Academy of Sciences; Institute of Automation, Chinese Academy of Sciences University of Chinese Academy of Sciences; Institute of Automation, Chinese Academy of Sciences University of Chinese Academy of Sciences Artificial Intelligence Research, Chinese Academy of Sciences; Institute of Automation, Chinese Academy of Sciences University of Chinese Academy of Sciences",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16599/16599-13-20093-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04688-a-graph-based-relevance-matching-model-for-ad-hoc-retrieval/",
        "doi": "10.1609/aaai.v35i5.16599",
        "pdf_size": 2743405
    },
    {
        "id": "00591",
        "title": "A Hierarchical Approach to Multi-Event Survival Analysis",
        "track": "main",
        "status": "Poster",
        "abstract": "In multi-event survival analysis, one aims to predict the probability of multiple different events occurring over some time horizon. One typically assumes that the timing of events is drawn from some distribution conditioned on an individual's covariates. However, during training, one does not have access to this distribution, and the natural variation in the observed event times makes the task of survival prediction challenging, on top of the potential interdependence among events. To address this issue, we introduce a novel approach for multi-event survival analysis that models the probability of event occurrence hierarchically at different time scales, using coarse predictions (e.g., monthly predictions) to iteratively guide predictions at finer and finer grained time scales (e.g., daily predictions). We evaluate the proposed approach across several publicly available datasets in terms of both intra-event, inter-individual (global) and intra-individual, inter-event (local) consistency. We show that the proposed method consistently outperforms well-accepted and commonly used approaches to multi-event survival analysis. When estimating survival curves for Alzheimer's disease and mortality, our approach achieves a C-index of 0.91 (95% CI 0.88-0.93) and a local consistency score of 0.97 (95% CI 0.94-0.98) compared to a C-index of 0.75 (95% CI 0.70-0.80) and a local consistency score of 0.94 (95% CI 0.91-0.97) when modeling each event separately. Overall, our approach improves the accuracy of survival predictions by iteratively reducing the original task to a set of nested, simpler subtasks.",
        "primary_area": "Application Domains",
        "author": "Donna Tjandra; Yifei He; Jenna Wiens",
        "authorids": "",
        "aff": "University of Michigan; University of Michigan; University of Michigan",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16138/16138-13-19632-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00591-a-hierarchical-approach-to-multi-event-survival-analysis/",
        "doi": "10.1609/aaai.v35i1.16138",
        "pdf_size": 381251
    },
    {
        "id": "01637",
        "title": "A Hybrid Attention Mechanism for Weakly-Supervised Temporal Action Localization",
        "track": "main",
        "status": "Poster",
        "abstract": "Weakly supervised temporal action localization is a challenging vision task due to the absence of ground-truth temporal locations of actions in the training videos. With only video-level supervision during training, most existing methods rely on a Multiple Instance Learning (MIL) framework to predict the start and end frame of each action category in a video. However, the existing MIL-based approach has a major limitation of only capturing the most discriminative frames of an action, ignoring the full extent of an activity. Moreover, these methods  cannot model background activity effectively, which plays an important role in localizing foreground activities. In this paper, we present a novel framework named HAM-Net with a hybrid attention mechanism which includes temporal soft, semi-soft and hard attentions to address these issues. Our temporal soft attention module, guided by an auxiliary background class in the classification module, models the background activity by introducing an ``action-ness'' score for each video snippet. Moreover, our temporal semi-soft and hard attention modules, calculating two attention scores for each video snippet, help to focus on the less discriminative frames of an action to capture the full action boundary. Our proposed approach outperforms recent state-of-the-art methods by at least 2.2% mAP at IoU threshold 0.5 on the THUMOS14 dataset, and by at least 1.3% mAP at IoU threshold 0.75 on the ActivityNet1.2 dataset.",
        "primary_area": "Computer Vision I",
        "author": "Ashraful Islam; Chengjiang Long; Richard Radke",
        "authorids": "",
        "aff": "Rensselaer Polytechnic Institute; JD Digits AI Lab; Rensselaer Polytechnic Institute",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16256/16256-13-19750-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01637-a-hybrid-attention-mechanism-for-weakly-supervised-temporal-action-localization/",
        "doi": "10.1609/aaai.v35i2.16256",
        "pdf_size": 1936239
    },
    {
        "id": "04036",
        "title": "A Hybrid Bandit Framework for Diversified Recommendation",
        "track": "main",
        "status": "Poster",
        "abstract": "The interactive recommender systems involve users in the recommendation procedure by receiving timely user feedback to update the recommendation policy. Therefore, they are widely used in real application scenarios. Previous interactive recommendation methods primarily focus on learning users' personalized preferences on the relevance properties of an item set. However, the investigation of users' personalized preferences on the diversity properties of an item set is usually ignored. To overcome this problem, we propose the Linear Modular Dispersion Bandit (LMDB) framework, which is an online learning setting for optimizing a combination of modular functions and dispersion functions. Specifically, LMDB employs modular functions to model the relevance properties of each item, and dispersion functions to describe the diversity properties of an item set. Moreover, we also develop a learning algorithm, called Linear Modular Dispersion Hybrid (LMDH) to solve the LMDB problem and derive a gap-free bound on its n-step regret. Extensive experiments on real datasets are performed to demonstrate the effectiveness of the proposed LMDB framework in balancing the recommendation accuracy and diversity.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Qinxu Ding; Yong Liu; Chunyan Miao; Fei Cheng; Haihong Tang",
        "authorids": "",
        "aff": "Alibaba-NTU Singapore Joint Research Institute; Alibaba-NTU Singapore Joint Research Institute Joint NTU-UBC Research Centre of Excellence in Active Living for the Elderly (LILY); School of Computer Science and Engineering, Nanyang Technological University; Alibaba Group; Alibaba Group",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16524/16524-13-20018-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04036-a-hybrid-bandit-framework-for-diversified-recommendation/",
        "doi": "10.1609/aaai.v35i5.16524",
        "pdf_size": 272109
    },
    {
        "id": "04366",
        "title": "A Hybrid Probabilistic Approach for Table Understanding",
        "track": "main",
        "status": "Poster",
        "abstract": "Tables of data are used to record vast amounts of socioeconomic, scientific, and governmental information. Although humans create tables using underlying organizational principles, unfortunately AI systems struggle to understand the contents of these tables. This paper introduces an end-to-end system for table understanding, the process of capturing the relational structure of data in tables. We introduce models that identify cell types, group these cells into blocks of data that serve a similar functional role, and predict the relationships between these blocks. We introduce a hybrid, neuro-symbolic approach, combining embedded representations learned from thousands of tables with probabilistic constraints that capture regularities in how humans organize tables. Our neuro-symbolic model is better able to capture positional invariants of headers and enforce homogeneity of data types. One limitation in this research area is the lack of rich datasets for evaluating end-to-end table understanding, so we introduce a new benchmark dataset comprised of 431 diverse tables from data.gov. The evaluation results show that our system achieves the state-of-the-art performance on cell type classification, block identification, and relationship prediction, improving over prior efforts by up to 7% of macro F1 score.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Kexuan Sun; Harsha Rayudu; Jay Pujara",
        "authorids": "",
        "aff": "University of Southern California; University of Southern California; University of Southern California",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16562/16562-13-20056-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04366-a-hybrid-probabilistic-approach-for-table-understanding/",
        "doi": "10.1609/aaai.v35i5.16562",
        "pdf_size": 630295
    },
    {
        "id": "10842",
        "title": "A Hybrid Stochastic Gradient Hamiltonian Monte Carlo Method",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent theoretical analyses reveal that existing Stochastic Gradient Markov Chain Monte Carlo (SG-MCMC) methods need large mini-batches  of samples (exponentially dependent on the dimension) to reduce the mean square error of gradient estimates and ensure non-asymptotic convergence guarantees when the target distribution has a nonconvex potential function.  In this paper, we propose a novel SG-MCMC algorithm, called Hybrid Stochastic Gradient Hamiltonian Monte Carlo (HSG-HMC) method, which needs merely one sample per iteration and possesses a simple structure with only one hyperparameter. Such improvement leverages a hybrid stochastic gradient estimator that exploits historical stochastic gradient information to control the mean square error. Theoretical analyses show that our method obtains the best-known overall sample complexity to achieve epsilon-accuracy in terms of the 2-Wasserstein distance for sampling from distributions with nonconvex potential functions. Empirical studies on both simulated and real-world datasets demonstrate the advantage of our method.",
        "primary_area": "Machine Learning V",
        "author": "Chao Zhang; Zhijian Li; Zebang Shen; Jiahao Xie; Hui Qian",
        "authorids": "",
        "aff": "Zhejiang University; Zhejiang University; University of Pennsylvania; Zhejiang University; Zhejiang University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17295/17295-13-20789-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10842-a-hybrid-stochastic-gradient-hamiltonian-monte-carlo-method/",
        "doi": "10.1609/aaai.v35i12.17295",
        "pdf_size": 1219075
    },
    {
        "id": "13543",
        "title": "A Joint Training Dual-MRC Framework for Aspect Based Sentiment Analysis",
        "track": "main",
        "status": "Poster",
        "abstract": "Aspect based sentiment analysis (ABSA) involves three fundamental subtasks: aspect term extraction, opinion term extraction, and aspect-level sentiment classification. Early works only focused on solving one of these subtasks individually. Some recent work focused on solving a combination of two subtasks, e.g., extracting aspect terms along with sentiment polarities or extracting the aspect and opinion terms pair-wisely. More recently, the triple extraction task has been proposed, i.e., extracting the (aspect term, opinion term, sentiment polarity) triples from a sentence. However, previous approaches fail to solve all subtasks in a unified end-to-end framework. In this paper, we propose a complete solution for ABSA. We construct two machine reading comprehension (MRC) problems, and solve all subtasks by joint training two BERT-MRC models with parameters sharing. We conduct experiments on these subtasks and results on several benchmark datasets demonstrate the effectiveness of our proposed framework, which significantly outperforms existing state-of-the-art methods.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Yue Mao; Yi Shen; Chao Yu; Longjun Cai",
        "authorids": "",
        "aff": "Alibaba Group; Alibaba Group; Alibaba Group; Alibaba Group",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17597/17597-13-21091-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13543-a-joint-training-dual-mrc-framework-for-aspect-based-sentiment-analysis/",
        "doi": "10.1609/aaai.v35i15.17597",
        "pdf_size": 1307726
    },
    {
        "id": "12657",
        "title": "A Lightweight Neural Model for Biomedical Entity Linking",
        "track": "main",
        "status": "Poster",
        "abstract": "Biomedical entity linking aims to map biomedical mentions, such as diseases and drugs, to standard entities in a given knowledge base. The specific challenge in this context is that the same biomedical entity can have a wide range of names, including synonyms, morphological variations, and names with different word orderings. Recently, BERT-based methods have advanced the state-of-the-art by allowing for rich representations of word sequences. However, they often have hundreds of millions of parameters and require heavy computing resources, which limits their applications in resource-limited scenarios. Here, we propose a lightweight neural method for biomedical entity linking, which needs just a fraction of the parameters of a BERT model and much less computing resources. Our method uses a simple alignment layer with attention mechanisms to capture the variations between mention and entity names. Yet, we show that our model is competitive with previous work on standard evaluation benchmarks.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Lihu Chen; Ga\u00ebl Varoquaux; Fabian M. Suchanek",
        "authorids": "",
        "aff": "LTCI T\u00e9l\u00e9com Paris Institut Polytechnique de Paris; Inria CEA Universit\u00e9 Paris-Saclay; LTCI T\u00e9l\u00e9com Paris Institut Polytechnique de Paris",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17499/17499-13-20993-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12657-a-lightweight-neural-model-for-biomedical-entity-linking/",
        "doi": "10.1609/aaai.v35i14.17499",
        "pdf_size": 1150267
    },
    {
        "id": "04776",
        "title": "A Market-Inspired Bidding Scheme for Peer Review Paper Assignment",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a market-inspired bidding scheme for the assignment of paper reviews in large academic conferences. We provide an analysis of the incentives of reviewers during the bidding phase, when reviewers have both private costs and some information about the demand for each paper; and their  goal is to obtain the best possible k papers for a predetermined k.   We show that by assigning `budgets' to reviewers and a `price' for every paper that is (roughly) proportional to its  demand, the best response of a reviewer is to bid sincerely, i.e., on her most favorite papers, and match the budget even when it is not enforced.  This game-theoretic analysis is based on a simple, prototypical assignment algorithm. We show via extensive simulations on bidding data from real conferences, that our  bidding scheme would substantially improve both the bid distribution and the resulting assignment.",
        "primary_area": "AI for Conference Organization and Delivery",
        "author": "Reshef Meir; J\u00e9r\u00f4me Lang; Julien Lesca; Nicholas Mattei; Natan Kaminsky",
        "authorids": "",
        "aff": "Technion, Israel; Universit\u00e9 Paris Dauphine, France; Universit\u00e9 Paris Dauphine, France; Tulane University, LA, USA; Technion, Israel",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16609/16609-13-20103-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04776-a-market-inspired-bidding-scheme-for-peer-review-paper-assignment/",
        "doi": "10.1609/aaai.v35i6.16609",
        "pdf_size": 552730
    },
    {
        "id": "05760",
        "title": "A Model of Winners Allocation",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a  model of winners allocation. In this model, we are given are two elections where the sets of candidates may intersect. The goal is to find two disjoint winning committees from respectively the two elections that are subjected to certain reasonable restrictions. For our model, we first propose several desirable properties. Then, we investigate the implication relationships among these properties. Finally, we study the complexity of computing winners allocations providing these properties. For hardness results, we also study some fixed-parameter algorithms.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Yongjie  Yang",
        "authorids": "",
        "aff": "Chair of Economic Theory, Saarland University, Saarbr\u00fccken, Germany",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16722/16722-13-20216-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05760-a-model-of-winners-allocation/",
        "doi": "10.1609/aaai.v35i6.16722",
        "pdf_size": 155861
    },
    {
        "id": "06948",
        "title": "A Multi-step-ahead Markov Conditional Forward Model with Cube Perturbations for Extreme Weather Forecasting",
        "track": "main",
        "status": "Poster",
        "abstract": "Predicting extreme weather events such as tropical and extratropical cyclones is of vital scientific and societal importance. Of late, machine learning methods have found their way to weather analysis and prediction, but mostly, these methods use machine learning merely as a complement to traditional numerical  weather  prediction models. Although some pure machine learning and data-driven approaches for weather prediction have been developed, they mainly formulate the problem similar to pattern recognition or follow the train of thought of traditional time-series models for extreme weather event forecasting; for the former, this usually yields only single-step ahead prediction, and for the latter, this lacks the flexibility to account for observed weather features as such methods concern only the patterns of the extreme weather occurrences. In this paper, we depart from the typical practice of pattern recognition and time-series approaches and focus on employing machine learning to estimate the probabilities of extreme weather occurrences in a multi-step-ahead (MSA) fashion given information on both weather features and the realized occurrences of extreme weather. Specifically, we propose a Markov conditional forward (MCF) model that adopts the Markov property between the occurrences of extreme weather  for MSA extreme weather forecasting. Moreover, for better long-term prediction, we propose three novel cube perturbation methods to address error accumulation in our model. Experimental results on a real-world extreme weather dataset show the superiority of the proposed MCF model in terms of prediction accuracy for both short-term and long-term forecasting; moreover, the three cube perturbation methods successfully increase the fault tolerance and generalization ability of the MCF model, yielding significant improvements for long-term prediction.",
        "primary_area": "Machine Learning I",
        "author": "Chia-Yuan Chang; Cheng-Wei Lu; Chuan-Ju Wang",
        "authorids": "",
        "aff": "Academia Sinica; Academia Sinica; Academia Sinica",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16856/16856-13-20350-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06948-a-multi-step-ahead-markov-conditional-forward-model-with-cube-perturbations-for-extreme-weather-forecasting/",
        "doi": "10.1609/aaai.v35i8.16856",
        "pdf_size": 1218750
    },
    {
        "id": "11755",
        "title": "A Multivariate Complexity Analysis of the Material Consumption Scheduling Problem",
        "track": "main",
        "status": "Poster",
        "abstract": "The NP-hard Material Consumption Scheduling Problem and closely related problems have been thoroughly studied since the 1980's. Roughly speaking, the problem deals with minimizing the makespan when scheduling jobs that consume non-renewable resources. We focus on the single-machine case without preemption: from time to time, the resources of the machine are (partially) replenished, thus allowing for meeting a necessary pre-condition for processing further jobs, each of which having individual resource demands. We initiate a systematic exploration of the parameterized computational complexity landscape of the problem, providing parameterized tractability as well as intractability results. Doing so, we mainly investigate how parameters related to the resource supplies influence the computational complexity. Thereby, we get a deepened understanding of this fundamental scheduling problem.",
        "primary_area": "Planning, Routing, and Scheduling",
        "author": "Matthias Bentert; Robert Bredereck; P\u00e9ter Gy\u00f6rgyi; Andrzej Kaczmarczyk; Rolf Niedermeier",
        "authorids": "",
        "aff": "Technische Universit\u00e4t Berlin; Technische Universit\u00e4t Berlin Humboldt-Universit\u00e4t zu Berlin; Institute for Computer Science and Control; Technische Universit\u00e4t Berlin; Technische Universit\u00e4t Berlin",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17397/17397-13-20891-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11755-a-multivariate-complexity-analysis-of-the-material-consumption-scheduling-problem/",
        "doi": "10.1609/aaai.v35i13.17397",
        "pdf_size": 161276
    },
    {
        "id": "14594",
        "title": "A Neural Group-wise Sentiment Analysis Model with Data Sparsity Awareness",
        "track": "main",
        "status": "Poster",
        "abstract": "Sentiment analysis on user-generated content has achieved notable progress by introducing user information to consider each individual\u2019s preference and language usage. However, most existing approaches ignore the data sparsity problem, where the content of some users is limited and the model fails to capture discriminative features of users. To address this issue, we hypothesize that users could be grouped together based on their rating biases as well as degree of rating consistency and the knowledge learned from groups could be employed to analyze the users with limited data. Therefore, in this paper, a neural group-wise sentiment analysis model with data sparsity awareness is proposed. The user-centred document representations are generated by incorporating a group-based user encoder. Furthermore, a multi-task learning framework is employed to jointly modelusers\u2019 rating biases and their degree of rating consistency. One task is vanilla populationlevel sentiment analysis and the other is groupwise sentiment analysis. Experimental results on three real-world datasets show that the proposed approach outperforms some state-of the-art methods. Moreover, model analysis and case study demonstrate its effectiveness of modeling user rating biases and variances.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Deyu Zhou; Meng Zhang; Linhai Zhang; Yulan He",
        "authorids": "",
        "aff": "Southeast University; Southeast University; Southeast University; University of Warwick",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17715/17715-13-21209-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14594-a-neural-group-wise-sentiment-analysis-model-with-data-sparsity-awareness/",
        "doi": "10.1609/aaai.v35i16.17715",
        "pdf_size": 975805
    },
    {
        "id": "12158",
        "title": "A New Bounding Scheme for Influence Diagrams",
        "track": "main",
        "status": "Poster",
        "abstract": "Influence diagrams provide a modeling and inference framework for sequential decision problems, representing the probabilistic knowledge by a Bayesian network and the preferences of an agent by utility functions over the random variables and decision variables. Computing the maximum expected utility (MEU) and the optimizing policy is exponential in the constrained induced width and therefore is notoriously difficult for larger models. In this paper, we develop a new bounding scheme for MEU that applies partitioning based approximations on top of the decomposition scheme called a multi-operator cluster DAG for influence diagrams that is more sensitive to the underlying structure of the model than the classical join-tree decomposition of influence diagrams. Our bounding scheme utilizes a cost-shifting mechanism to tighten the bound further. We demonstrate the effectiveness of the proposed scheme on various hard benchmarks.",
        "primary_area": "Reasoning under Uncertainty",
        "author": "Radu Marinescu; Junkyu Lee; Rina Dechter",
        "authorids": "",
        "aff": "IBM Research Europe; University of California Irvine; University of California Irvine",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17443/17443-13-20937-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12158-a-new-bounding-scheme-for-influence-diagrams/",
        "doi": "10.1609/aaai.v35i13.17443",
        "pdf_size": 575700
    },
    {
        "id": "03377",
        "title": "A Novel Visual Interpretability for Deep Neural Networks by Optimizing Activation Maps with Perturbation",
        "track": "main",
        "status": "Poster",
        "abstract": "Interpretability has been regarded as an essential component for deploying deep neural networks, in which the saliency-based method is one of the most prevailing interpretable approaches since it can generate individually intuitive heatmaps that highlight parts of the input image that are most important to the decision of the deep networks on a particular classification target. However, heatmaps generated by existing methods either contain little information to represent objects (perturbation-based methods) or cannot effectively locate multi-class objects (activation-based approaches). To address this issue, a two-stage framework for visualizing the interpretability of deep neural networks, called Activation Optimized with Perturbation (AOP), is designed to optimize activation maps generated by general activation-based methods with the help of perturbation-based methods. Finally, in order to obtain better explanations for different types of images, we further present an instance of the AOP framework, Smooth Integrated Gradient-based Class Activation Map (SIGCAM), which proposes a weighted GradCAM by applying the feature map as weight coefficients and employs I-GOS to optimize the base-mask generated by weighted GradCAM. Experimental results on common-used benchmarks, including deletion and insertion tests on ImageNet-1k, and pointing game tests on COCO2017, show that the proposed AOP and SIGCAM outperform the current state-of-the-art methods significantly by generating higher quality image-based saliency maps.",
        "primary_area": "Computer Vision III",
        "author": "Qinglong Zhang; Lu Rao; Yubin Yang",
        "authorids": "",
        "aff": "State Key Laboratory for Novel Software Technology, Nanjing University; State Key Laboratory for Novel Software Technology, Nanjing University; State Key Laboratory for Novel Software Technology, Nanjing University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16450/16450-13-19944-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03377-a-novel-visual-interpretability-for-deep-neural-networks-by-optimizing-activation-maps-with-perturbation/",
        "doi": "10.1609/aaai.v35i4.16450",
        "pdf_size": 6842240
    },
    {
        "id": "04785",
        "title": "A Novice-Reviewer Experiment to Address Scarcity of Qualified Reviewers in Large Conferences",
        "track": "main",
        "status": "Poster",
        "abstract": "Conference peer review constitutes a human-computation process whose importance cannot be overstated: not only it identifies the best submissions for acceptance, but, ultimately, it impacts the future of the whole research area by promoting some ideas and restraining others. A surge in the number of submissions received by leading AI conferences has challenged the sustainability of the review process by increasing the burden on the pool of qualified reviewers which is growing at a much slower rate. In this work, we consider the problem of reviewer recruiting with a focus on the scarcity of qualified reviewers in large conferences. Specifically, we design a procedure for (i) recruiting reviewers from the population not typically covered by major conferences and (ii) guiding them through the reviewing pipeline. In conjunction with the ICML 2020 --- a large, top-tier machine learning conference --- we recruit a small set of reviewers through our procedure and compare their performance with the general population of ICML reviewers. Our experiment reveals that a combination of the recruiting and guiding mechanisms allows for a principled enhancement of the reviewer pool and results in reviews of superior quality compared to the conventional pool of reviews as evaluated by senior members of the program committee (meta-reviewers).",
        "primary_area": "AI for Conference Organization and Delivery",
        "author": "Ivan Stelmakh; Nihar B. Shah; Aarti Singh; Hal Daum\u00e9 III",
        "authorids": "",
        "aff": "Carnegie Mellon University; Carnegie Mellon University; Carnegie Mellon University; University of Maryland, College Park Microsoft Research, New York",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16610/16610-13-20104-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04785-a-novice-reviewer-experiment-to-address-scarcity-of-qualified-reviewers-in-large-conferences/",
        "doi": "10.1609/aaai.v35i6.16610",
        "pdf_size": 2924796
    },
    {
        "id": "07254",
        "title": "A One-Size-Fits-All Solution to Conservative Bandit Problems",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we study a family of conservative bandit problems (CBPs) with sample-path reward constraints, i.e., the learner's reward performance must be at least as well as a given baseline at any time. We propose a One-Size-Fits-All solution to CBPs and present its applications to three encompassed problems, i.e. conservative multi-armed bandits (CMAB), conservative linear bandits (CLB) and conservative contextual combinatorial bandits (CCCB). Different from previous works which consider high probability constraints on the expected reward, we focus on a sample-path constraint on the actually received reward, and achieve better theoretical guarantees (T-independent additive regrets instead of T-dependent) and empirical performance. Furthermore, we extend the results and consider a novel  conservative mean-variance bandit problem (MV-CBP), which measures the learning performance with both the expected reward and variability. For this extended problem, we provide a novel algorithm with O(1/T) normalized additive regrets (T-independent in the cumulative form) and validate this result through empirical evaluation.",
        "primary_area": "Machine Learning I",
        "author": "Yihan Du; Siwei Wang; Longbo Huang",
        "authorids": "",
        "aff": "Tsinghua University; Tsinghua University; Tsinghua Univeristy",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16891/16891-13-20385-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07254-a-one-size-fits-all-solution-to-conservative-bandit-problems/",
        "doi": "10.1609/aaai.v35i8.16891",
        "pdf_size": 5681077
    },
    {
        "id": "05664",
        "title": "A Permutation-Equivariant Neural Network Architecture For Auction Design",
        "track": "main",
        "status": "Poster",
        "abstract": "Designing an incentive compatible auction that maximizes expected revenue is a central problem in Auction Design. Theoretical approaches to the problem have hit some limits in the past decades and analytical solutions are known for only a few simple settings. Computational approaches to the problem through the use of LPs  have their own set of limitations. Building on the success of deep learning, a new approach was recently proposed by  Duetting et al. (2019) in which the auction is modeled by a feed-forward neural network and the design problem is framed as a learning problem. The neural architectures used in that work are general purpose and do not take advantage of any of the symmetries the problem could present, such as permutation equivariance. In this work, we consider auction design problems that have permutation-equivariant symmetry and construct a neural architecture that is capable of perfectly recovering the permutation-equivariant optimal mechanism, which we show is not possible with the previous architecture. We demonstrate that permutation-equivariant architectures are not only capable of recovering previous results, they also have better generalization properties.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Jad Rahme; Samy Jelassi; Joan Bruna; S. Matthew Weinberg",
        "authorids": "",
        "aff": "Princeton University, USA; Princeton University, USA Courant Institute of Mathematical Sciences, New York University, USA; Courant Institute of Mathematical Sciences, New York University, USA Center for Data Science, New York University, USA; Princeton University, USA",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16711/16711-13-20205-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05664-a-permutation-equivariant-neural-network-architecture-for-auction-design/",
        "doi": "10.1609/aaai.v35i6.16711",
        "pdf_size": 994328
    },
    {
        "id": "11160",
        "title": "A Primal-Dual Online Algorithm for Online Matching Problem in Dynamic Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Recently, the online matching problem has attracted much attention due to its wide application on real-world decision-making scenarios. In stationary environments, by adopting the stochastic user arrival model, existing methods are proposed to learn dual optimal prices and are shown to achieve a fast regret bound. However, the stochastic model is no longer a proper assumption when the environment is changing, leading to an optimistic method that may suffer poor performance. In this paper, we study the online matching problem in dynamic environments in which the dual optimal prices are allowed to vary over time. We bound the dynamic regret of online matching problem by the sum of two quantities, including a regret of online max-min problem and a dynamic regret of online convex optimization (OCO) problem. Then we propose a novel online approach named Primal-Dual Online Algorithm (PDOA) to minimize both quantities. In particular, PDOA adopts the primal-dual framework by optimizing dual prices with the online gradient descent (OGD) algorithm to eliminate the online max-min problem's regret. Moreover, it maintains a set of OGD experts and combines them via an expert-tracking algorithm, which gives a sublinear dynamic regret bound for the OCO problem. We show that PDOA achieves an O(K sqrt{T(1+P_T)}) dynamic regret where K is the number of resources, T is the number of iterations and P_T is the path-length of any potential dual price sequence that reflects the dynamic environment. Finally, experiments on real applications exhibit the superiority of our approach.",
        "primary_area": "Machine Learning V",
        "author": "Yu-Hang Zhou; Peng Hu; Chen Liang; Huan Xu; Guangda Huzhang; Yinfu Feng; Qing Da; Xinshang Wang; An-Xiang Zeng",
        "authorids": "",
        "aff": "Alibaba Group; Alibaba Group; Alibaba Group; Alibaba Group; Alibaba Group; Alibaba Group; Alibaba Group; Alibaba Group; Alibaba Group",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17331/17331-13-20825-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11160-a-primal-dual-online-algorithm-for-online-matching-problem-in-dynamic-environments/",
        "doi": "10.1609/aaai.v35i12.17331",
        "pdf_size": 220244
    },
    {
        "id": "08074",
        "title": "A Recipe for Global Convergence Guarantee in Deep Neural Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Existing global convergence guarantees of (stochastic) gradient descent do not apply to practical deep networks in the practical regime of deep learning beyond the neural tangent kernel (NTK) regime. This paper proposes an algorithm, which is ensured to have global convergence guarantees in the practical regime beyond the NTK regime, under a verifiable condition called the expressivity condition. The expressivity condition is defined to be both data-dependent and architecture-dependent, which is the key property that makes our results applicable for practical settings beyond the NTK regime. On the one hand, the expressivity condition is theoretically proven to hold data-independently for fully-connected deep neural networks with narrow hidden layers and a single wide layer. On the other hand, the expressivity condition is numerically shown to hold data-dependently for deep (convolutional) ResNet with batch normalization with various standard image datasets. We also show that the the proposed algorithm has generalization performances comparable with those of the heuristic algorithm, with the same hyper-parameters and total number of iterations. Therefore, the proposed algorithm can be viewed as a step towards providing theoretical guarantees for deep learning in the practical regime.",
        "primary_area": "Machine Learning II",
        "author": "Kenji Kawaguchi; Qingyun Sun",
        "authorids": "",
        "aff": "Harvard University; Stanford University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16984/16984-13-20478-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08074-a-recipe-for-global-convergence-guarantee-in-deep-neural-networks/",
        "doi": "10.1609/aaai.v35i9.16984",
        "pdf_size": 345302
    },
    {
        "id": "03669",
        "title": "A SAT-based Resolution of Lam\u2019s Problem",
        "track": "main",
        "status": "Poster",
        "abstract": "In 1989, computer searches by Lam, Thiel, and Swiercz experimentally resolved Lam's problem from projective geometry\u2014the long-standing problem of determining if a projective plane of order ten exists.  Both the original search and an independent verification in 2011 discovered no such projective plane.  However, these searches were each performed using highly specialized custom-written code and did not produce nonexistence certificates.  In this paper, we resolve Lam's problem by translating the problem into Boolean logic and use satisfiability (SAT) solvers to produce nonexistence certificates that can be verified by a third party.  Our work uncovered consistency issues in both previous searches\u2014highlighting the difficulty of relying on special-purpose search code for nonexistence results.",
        "primary_area": "Constraint Satisfaction and Optimization",
        "author": "Curtis Bright; Kevin K. H. Cheung; Brett Stevens; Ilias Kotsireas; Vijay Ganesh",
        "authorids": "",
        "aff": "University of Windsor Carleton University; Carleton University; Carleton University; Wilfrid Laurier University; University of Waterloo",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16483/16483-13-19977-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03669-a-sat-based-resolution-of-lam-s-problem/",
        "doi": "10.1609/aaai.v35i5.16483",
        "pdf_size": 132406
    },
    {
        "id": "08030",
        "title": "A Sample-Efficient Algorithm for Episodic Finite-Horizon MDP with Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "Constrained Markov decision processes (CMDPs) formalize sequential decision-making problems whose objective is to minimize a cost function while satisfying constraints on various cost functions. In this paper, we consider the setting of episodic fixed-horizon CMDPs. We propose an online algorithm which leverages the linear programming formulation of repeated optimistic planning for finite-horizon CMDP to provide a probably approximately correctness (PAC) guarantee on the number of episodes needed to ensure a near optimal policy,  i.e., with resulting objective value close to that of the optimal value and satisfying the constraints within low tolerance, with high probability. The number of episodes needed is shown to have linear dependence on the sizes of the state and action spaces and quadratic dependence on the time horizon and an upper bound on the number of possible successor states for a state-action pair. Therefore, if the upper bound on the number of possible successor states is much smaller than the size of the state space, the number of needed episodes becomes linear in the sizes of the state and action spaces and quadratic in the time horizon.",
        "primary_area": "Machine Learning II",
        "author": "Krishna C. Kalagarla; Rahul Jain; Pierluigi Nuzzo",
        "authorids": "",
        "aff": "University of Southern California; University of Southern California; University of Southern California",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16979/16979-13-20473-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08030-a-sample-efficient-algorithm-for-episodic-finite-horizon-mdp-with-constraints/",
        "doi": "10.1609/aaai.v35i9.16979",
        "pdf_size": 164741
    },
    {
        "id": "04996",
        "title": "A Scalable Reasoning and Learning Approach for Neural-Symbolic Stream Fusion",
        "track": "main",
        "status": "Poster",
        "abstract": "Driven by deep neural networks (DNN), the recent development of computer vision makes vision sensors such as stereo cameras and  Lidars ubiquitous in autonomous cars, robotics and traffic monitoring. However,  a traditional DNN-based data fusion pipeline like object tracking has to hard-wire an engineered set of DNN models to a fixed processing logic, which makes it difficult to  infuse new models to that pipeline. To overcome this, we propose a novel neural-symbolic stream reasoning approach realised by semantic stream reasoning programs which specify DNN-based data fusion pipelines via logic rules with learnable probabilistic degrees as weights. The reasoning task over this program is governed by a novel incremental reasoning algorithm,  which lends itself also as a core building block for a scalable and parallel algorithm to learn the weights for such program. Extensive experiments  with our first prototype  on multi-object tracking benchmarks for autonomous driving and traffic monitoring show that our flexible approach can considerably improve both accuracy and processing throughput compared to the DNN-based counterparts.",
        "primary_area": "Neuro-Symbolic AI",
        "author": "Danh Le-Phuoc; Thomas Eiter; Anh Le-Tuan",
        "authorids": "",
        "aff": "Technical University Berlin; TU Wien; Technical University Berlin",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16633/16633-13-20127-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04996-a-scalable-reasoning-and-learning-approach-for-neural-symbolic-stream-fusion/",
        "doi": "10.1609/aaai.v35i6.16633",
        "pdf_size": 2179337
    },
    {
        "id": "03806",
        "title": "A Scalable Two Stage Approach to Computing Optimal Decision Sets",
        "track": "main",
        "status": "Poster",
        "abstract": "Machine learning (ML) is ubiquitous in modern life. Since it is being deployed in technologies that affect our privacy and safety, it is often crucial to understand the reasoning behind its decisions, warranting the need for explainable AI. Rule-based models, such as decision trees, decision lists, and decision sets, are conventionally deemed to be the most interpretable. Recent work uses propositional satisfiability (SAT) solving (and its optimization variants) to generate minimum-size decision sets. Motivated by limited practical scalability of these earlier methods, this paper proposes a novel approach to learn minimum-size decision sets by enumerating individual rules of the target decision set independently of each other, and then solving a set cover problem to select a subset of rules. The approach makes use of modern maximum satisfiability and integer linear programming technologies. Experiments on a wide range of publicly available datasets demonstrate the advantage of the new approach over the state of the art in SAT-based decision set learning.",
        "primary_area": "Constraint Satisfaction and Optimization",
        "author": "Alexey Ignatiev; Edward Lam; Peter J. Stuckey; Joao Marques-Silva",
        "authorids": "",
        "aff": "Monash University, Australia; Monash University, Australia CSIRO Data61, Australia; Monash University, Australia; ANITI, IRIT, CNRS, France",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16498/16498-13-19992-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03806-a-scalable-two-stage-approach-to-computing-optimal-decision-sets/",
        "doi": "10.1609/aaai.v35i5.16498",
        "pdf_size": 264824
    },
    {
        "id": "03697",
        "title": "A Sharp Leap from Quantified Boolean Formula to Stochastic Boolean Satisfiability Solving",
        "track": "main",
        "status": "Poster",
        "abstract": "Stochastic Boolean Satisfiability (SSAT) is a powerful representation for the concise encoding of quantified decision problems with uncertainty. While it shares commonalities with quantified Boolean formula (QBF) satisfiability and has the same PSPACE-complete complexity, SSAT solving tends to be more challenging as it involves expensive model counting, a.k.a. Sharp-SAT. To date, SSAT solvers, especially those imposing no restrictions on quantification levels, remain much lacking. In this paper, we present a new SSAT solver based on the framework of clause selection and cube distribution previously proposed for QBF solving. With model counting integrated and learning techniques strengthened, our solver is general and effective. Experimental results demonstrate the overall superiority of the proposed algorithm in both solving performance and memory usage compared to the state-of-the-art solvers on a number of benchmark formulas.",
        "primary_area": "Constraint Satisfaction and Optimization",
        "author": "Pei-Wei Chen; Yu-Ching Huang; Jie-Hong R. Jiang",
        "authorids": "",
        "aff": "Department of Electrical Engineering, National Taiwan University; Department of Electrical Engineering, National Taiwan University; Department of Electrical Engineering, National Taiwan University Graduate Institute of Electronics Engineering, National Taiwan University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16486/16486-13-19980-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03697-a-sharp-leap-from-quantified-boolean-formula-to-stochastic-boolean-satisfiability-solving/",
        "doi": "10.1609/aaai.v35i5.16486",
        "pdf_size": 182729
    },
    {
        "id": "06331",
        "title": "A Simple Framework for Cognitive Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a novel approach to cognitive planning, i.e., an agent's planning aimed at changing the cognitive attitudes of another agent including her beliefs and intentions. We encode the cognitive planning problem in an epistemic logic with a semantics exploiting belief bases. We study a NP-fragment of the logic whose satisfiability problem is reduced to SAT. We provide complexity results for the cognitive planning problem. Moreover, we illustrate its potential for applications in human-machine interaction in which an artificial agent is expected to interact with a human agent through dialogue and to persuade the human to behave in a certain way.",
        "primary_area": "Knowledge Representation and Reasoning",
        "author": "Jorge Luis Fernandez Davila; Dominique Longin; Emiliano Lorini; Fr\u00e9d\u00e9ric Maris",
        "authorids": "",
        "aff": "IRIT, Toulouse University, France; IRIT, CNRS, Toulouse University, France; IRIT, CNRS, Toulouse University, France; IRIT, Toulouse University, France",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16786/16786-13-20280-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06331-a-simple-framework-for-cognitive-planning/",
        "doi": "10.1609/aaai.v35i7.16786",
        "pdf_size": 185122
    },
    {
        "id": "13815",
        "title": "A Simple and Effective Self-Supervised Contrastive Learning Framework for Aspect Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Unsupervised aspect detection (UAD) aims at automatically extracting interpretable aspects and identifying aspect-specific segments (such as sentences) from online reviews. However, recent deep learning based topic models, specifically aspect-based autoencoder, suffer from several problems such as extracting noisy aspects and poorly mapping aspects discovered by models to the aspects of interest. To tackle these challenges, in this paper, we first propose a self-supervised contrastive learning framework and an attention-based model equipped with a novel smooth self-attention (SSA) module for the UAD task in order to learn better representations for aspects and review segments. Secondly, we introduce a high-resolution selective mapping (HRSMap) method to efficiently assign aspects discovered by the model to the aspects of interest. We also propose using a knowledge distillation technique to further improve the aspect detection performance. Our methods outperform several recent unsupervised and weakly supervised approaches on publicly available benchmark user review datasets. Aspect interpretation results show that extracted aspects are meaningful, have a good coverage, and can be easily mapped to aspects of interest. Ablation studies and attention weight visualization also demonstrate effectiveness of SSA and the knowledge distillation method.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Tian Shi; Liuqing Li; Ping Wang; Chandan K. Reddy",
        "authorids": "",
        "aff": "Virginia Tech; Verizon Media; Virginia Tech; Virginia Tech",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17628/17628-13-21122-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13815-a-simple-and-effective-self-supervised-contrastive-learning-framework-for-aspect-detection/",
        "doi": "10.1609/aaai.v35i15.17628",
        "pdf_size": 336636
    },
    {
        "id": "00733",
        "title": "A Spatial Regulated Patch-Wise Approach for Cervical Dysplasia Diagnosis",
        "track": "main",
        "status": "Poster",
        "abstract": "Cervical dysplasia diagnosis via visual investigation is a challenging problem. Recent approaches use deep learning techniques to extract features and require the downsampling of high-resolution cervical screening images to smaller sizes for training. Such a reduction may result in the loss of visual details that appear weakly and locally within a cervical image. To overcome this challenge, our work divides an image into patches and then represents it from patch features. We aggregate patch patterns into an image feature in a weighted manner by considering the patch--image label relation. The weights are visualized as a heatmap to explain where the diagnosis results come from. We further introduce a spatial regulator to guide the classifier to focus on the cervix region and to adjust the weight distribution, without requiring any manual annotations of the cervix region. A novel iterative algorithm is designed to refine the regulator, which is able to capture the variations in cervix center locations and shapes. Experiments on an 18-year real-world dataset indicate a minimal of 3.47%, 4.59%, 8.54% improvements over the state-of-the-art in accuracy, F1, and recall measures, respectively.",
        "primary_area": "Application Domains",
        "author": "Ying Zhang; Yifang Yin; Zhenguang Liu; Roger Zimmermann",
        "authorids": "",
        "aff": "National University of Singapore Northwestern Polytechnical University; National University of Singapore; Zhejiang Gongshang University; National University of Singapore",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16154/16154-13-19648-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00733-a-spatial-regulated-patch-wise-approach-for-cervical-dysplasia-diagnosis/",
        "doi": "10.1609/aaai.v35i1.16154",
        "pdf_size": 2010290
    },
    {
        "id": "13692",
        "title": "A Student-Teacher Architecture for Dialog Domain Adaptation Under the Meta-Learning Setting",
        "track": "main",
        "status": "Poster",
        "abstract": "Numerous new dialog domains are being created every day while collecting data for these domains is extremely costly since it involves human interactions. Therefore, it is essential to develop algorithms that can adapt to different domains efficiently when building data-driven dialog models. Most recent research on domain adaption focuses on giving the model a better initialization, rather than optimizing the adaptation process. We propose an efficient domain adaptive task-oriented dialog system model, which incorporates a meta-teacher model to emphasize the different impacts between generated tokens with respect to the context. We first train our base dialog model and meta-teacher model adversarially in a meta-learning setting on rich-resource domains. The meta-teacher learns to quantify the importance of tokens under different contexts across different domains. During adaptation, the meta-teacher guides the dialog model to focus on important tokens in order to achieve better adaptation efficiency. We evaluate our model on two multi-domain datasets, MultiWOZ and Google Schema-Guided Dialogue, and achieve state-of-the-art performance.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Kun Qian; Wei Wei; Zhou Yu",
        "authorids": "",
        "aff": "University of California, Davis; Google Inc.; University of California, Davis",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17614/17614-13-21108-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13692-a-student-teacher-architecture-for-dialog-domain-adaptation-under-the-meta-learning-setting/",
        "doi": "10.1609/aaai.v35i15.17614",
        "pdf_size": 467845
    },
    {
        "id": "14185",
        "title": "A Supervised Multi-Head Self-Attention Network for Nested Named Entity Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "In recent years, researchers have shown an increased interest in recognizing the overlapping entities that have nested structures. However, most existing models ignore the semantic correlation between words under different entity types. Considering words in sentence play different roles under different entity types, we argue that the correlation intensities of pairwise words in sentence for each entity type should be considered. In this paper, we treat named entity recognition as a multi-class classification of word pairs and design a simple neural model to handle this issue. Our model applies a supervised multi-head self-attention mechanism, where each head corresponds to one entity type, to construct the word-level correlations for each type. Our model can flexibly predict the span type by the correlation intensities of its head and tail under the corresponding type. In addition, we fuse entity boundary detection and entity classification by a multitask learning framework, which can capture the dependencies between these two tasks. To verify the performance of our model, we conduct extensive experiments on both nested and flat datasets. The experimental results show that our model can outperform the previous state-of-the-art methods on multiple tasks without any extra NLP tools or human annotations.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Yongxiu Xu; Heyan Huang; Chong Feng; Yue Hu",
        "authorids": "",
        "aff": "Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China; School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China; School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17669/17669-13-21163-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14185-a-supervised-multi-head-self-attention-network-for-nested-named-entity-recognition/",
        "doi": "10.1609/aaai.v35i16.17669",
        "pdf_size": 324966
    },
    {
        "id": "01379",
        "title": "A Systematic Evaluation of Object Detection Networks for Scientific Plots",
        "track": "main",
        "status": "Poster",
        "abstract": "Are existing object detection methods adequate for detecting text and visual elements in scientific plots which are arguably different than the objects found in natural images? To answer this question, we train and compare the accuracy of Fast/Faster R-CNN, SSD, YOLO and RetinaNet on the PlotQA dataset with over 220,000 scientific plots. At the standard IOU setting of 0.5, most networks perform well with mAP scores greater than 80% in detecting the relatively simple objects in plots. However, the performance drops drastically when evaluated at a stricter IOU of 0.9 with the best model giving a mAP of 35.70%. Note that such a stricter evaluation is essential when dealing with scientific plots where even minor localisation errors can lead to large errors in downstream numerical inferences. Given this poor performance, we propose minor modifications to existing models by combining ideas from different object detection networks. While this significantly improves the performance, there are still two main issues: (i) performance on text objects which are essential for reasoning is very poor, and (ii) inference time is unacceptably large considering the simplicity of plots. To solve this open problem, we make a series of contributions: (a) an efficient region proposal method based on Laplacian edge detectors, (b) a feature representation of region proposals that includes neighbouring information, (c) a linking component to join multiple region proposals for detecting longer textual objects, and (d) a custom loss function that combines a smooth L1-loss with an IOU-based loss. Combining these ideas, our final model is very accurate at extreme IOU values achieving a mAP of 93.44%@0.9 IOU. Simultaneously, our model is very efficient with an inference time 16x lesser than the current models, including one-stage detectors. Our model also achieves a high accuracy on an extrinsic plot-to-table conversion task with an F1 score of 0.77. With these contributions, we make a definitive progress in object detection for plots and enable further exploration on automated reasoning of plots.",
        "primary_area": "Computer Vision I",
        "author": "Pritha Ganguly; Nitesh S Methani; Mitesh M. Khapra; Pratyush Kumar",
        "authorids": "",
        "aff": "Indian Institute of Technology, Madras; Indian Institute of Technology, Madras; Indian Institute of Technology Madras; Indian Institute of Technology Madras",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16227/16227-13-19721-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01379-a-systematic-evaluation-of-object-detection-networks-for-scientific-plots/",
        "doi": "10.1609/aaai.v35i2.16227",
        "pdf_size": 1728658
    },
    {
        "id": "12848",
        "title": "A Theoretical Analysis of the Repetition Problem in Text Generation",
        "track": "main",
        "status": "Poster",
        "abstract": "Text generation tasks, including translation, summarization, language models, and etc. see rapid growth during recent years. Despite the remarkable achievements, the repetition problem has been observed in nearly all text generation models undermining the generation performance extensively. To solve the repetition problem, many methods have been proposed, but there is no existing theoretical analysis to show why this problem happens and how it is resolved. In this paper, we propose a new framework for theoretical analysis for the repetition problem. We first define the Average Repetition Probability (ARP) to characterize the repetition problem quantitatively. Then, we conduct an extensive analysis of the Markov generation model and derive several upper bounds of the average repetition probability with intuitive understanding. We show that most of the existing methods are essentially minimizing the upper bounds explicitly or implicitly. Grounded on our theory, we show that the repetition problem is, unfortunately, caused by the traits of our language itself. One major reason is attributed to the fact that there exist too many words predicting the same word as the subsequent word with high probability. Consequently, it is easy to go back to that word and form repetitions and we dub it as the high inflow problem. Furthermore, we extend our analysis to broader generation models by deriving a concentration bound of the average repetition probability for a general generation model. Finally,  based on the theoretical upper bounds, we propose a novel rebalanced encoding approach to alleviate the high inflow problem and thus reducing the upper bound.     The experimental results show that our theoretical framework is applicable in general generation models and our proposed rebalanced encoding approach alleviates the repetition problem significantly in both the translation task and the language modeling task. The source code of this paper can be obtained from https://github.com/fuzihaofzh/repetition-problem-nlg.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Zihao Fu; Wai Lam; Anthony Man-Cho So; Bei Shi",
        "authorids": "",
        "aff": "The Chinese University of Hong Kong; The Chinese University of Hong Kong; The Chinese University of Hong Kong; Tencent AI Lab",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17520/17520-13-21014-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12848-a-theoretical-analysis-of-the-repetition-problem-in-text-generation/",
        "doi": "10.1609/aaai.v35i14.17520",
        "pdf_size": 193469
    },
    {
        "id": "06741",
        "title": "A Theory of Independent Mechanisms for Extrapolation in Generative Models",
        "track": "main",
        "status": "Poster",
        "abstract": "Generative models can be trained to emulate complex empirical data, but are they useful to make predictions in the context of previously unobserved environments? An intuitive idea to promote such extrapolation capabilities is to have the architecture of such model reflect a causal graph of the true data generating process, such that one can intervene on each node independently of the others. However, the nodes of this graph are usually unobserved, leading to overparameterization and lack of identifiability of the causal structure. We develop a theoretical framework to address this challenging situation by defining a weaker form of identifiability, based on the principle of independence of mechanisms. We demonstrate on toy examples that classical stochastic gradient descent can hinder the model's extrapolation capabilities, suggesting independence of mechanisms should be enforced explicitly during training. Experiments on deep generative models trained on real world data support these insights and illustrate how the extrapolation capabilities of such models can be leveraged.",
        "primary_area": "Machine Learning I",
        "author": "Michel Besserve; Remy Sun; Dominik Janzing; Bernhard Sch\u00f6lkopf",
        "authorids": "",
        "aff": "Max Planck Institute for Intelligent Systems, T\u00fcbingen, Germany Max Planck Institute for Biological Cybernetics, T\u00fcbingen, Germany; ENS Rennes, France; Max Planck Institute for Intelligent Systems, T\u00fcbingen, Germany; Max Planck Institute for Intelligent Systems, T\u00fcbingen, Germany",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16833/16833-13-20327-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06741-a-theory-of-independent-mechanisms-for-extrapolation-in-generative-models/",
        "doi": "10.1609/aaai.v35i8.16833",
        "pdf_size": 2381355
    },
    {
        "id": "07519",
        "title": "A Trace-restricted Kronecker-Factored Approximation to Natural Gradient",
        "track": "main",
        "status": "Poster",
        "abstract": "Second-order optimization methods have the ability to accelerate convergence by modifying the gradient through the curvature matrix. There have been many attempts to use second-order optimization methods for training deep neural networks. In this work, inspired by diagonal approximations and factored approximations such as Kronecker-factored Approximate Curvature (KFAC), we propose a new approximation to the Fisher information matrix (FIM) called Trace-restricted Kronecker-factored Approximate Curvature (TKFAC), which can hold the certain trace relationship between the exact and the approximate FIM. In TKFAC, we decompose each block of the approximate FIM as a Kronecker product of two smaller matrices and scaled by a coefficient related to trace. We theoretically analyze TKFAC's approximation error and give an upper bound of it. We also propose a new damping technique for TKFAC on convolutional neural networks to maintain the superiority of second-order optimization methods during training. Experiments show that our method has better performance compared with several state-of-the-art algorithms on some deep network architectures.",
        "primary_area": "Machine Learning II",
        "author": "Kaixin Gao; Xiaolei Liu; Zhenghai Huang; Min Wang; Zidong Wang; Dachuan Xu; Fan Yu",
        "authorids": "",
        "aff": "Tianjin University; Tianjin University; Tianjin University; Huawei Technologies Co. Ltd; Huawei Technologies Co. Ltd; Beijing University of Technology; Huawei Technologies Co. Ltd",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16921/16921-13-20415-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07519-a-trace-restricted-kronecker-factored-approximation-to-natural-gradient/",
        "doi": "10.1609/aaai.v35i9.16921",
        "pdf_size": 2100531
    },
    {
        "id": "05016",
        "title": "A Unified Framework for Planning with Learned Neural Network Transition Models",
        "track": "main",
        "status": "Poster",
        "abstract": "Automated planning with neural network transition models is a two stage approach to solving planning problems with unknown transition models. The first stage of the approach learns the unknown transition model from data as a neural network model, and the second stage of the approach compiles the learned model to either a Mixed-Integer Linear Programming (MILP) model or a Recurrent Neural Network (RNN) model, and optimize it using an off-the-shelf solver. The previous studies have shown that both models have their advantages and disadvantages. Namely, the MILP model can be solved optimally using a branch-and-bound algorithm but has been experimentally shown not to scale well for neural networks with multiple hidden layers. In contrast, the RNN model can be solved effectively using a gradient descent algorithm but can only work under very restrictive assumptions. In this paper, we focus on improving the effectiveness of solving the second stage of the approach by introducing (i) a novel Lagrangian RNN architecture that can model the previously ignored components of the planning problem as Lagrangian functions, and (ii) a novel framework that unifies the MILP and the Lagrangian RNN models such that the weakness of one model is complemented by the strength of the other. Experimentally, we show that our unifying framework significantly outperforms the standalone MILP model by solving 80% more problem instances, and showcase the ability of our unifying framework to find high quality solutions to challenging automated planning problems with unknown transition models.",
        "primary_area": "Neuro-Symbolic AI",
        "author": "Buser Say",
        "authorids": "",
        "aff": "Monash University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16635/16635-13-20129-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05016-a-unified-framework-for-planning-with-learned-neural-network-transition-models/",
        "doi": "10.1609/aaai.v35i6.16635",
        "pdf_size": 797382
    },
    {
        "id": "01097",
        "title": "A Unified Multi-Scenario Attacking Network for Visual Object Tracking",
        "track": "main",
        "status": "Poster",
        "abstract": "Existing methods of adversarial attacks successfully generate adversarial examples to confuse Deep Neural Networks (DNNs) of image classification and object detection, resulting in wrong predictions. However, these methods are difficult to attack models of video object tracking, because the tracking algorithms could handle sequential information across video frames and the categories of targets tracked are normally unknown in advance. In this paper, we propose a Unified and Effective Network, named UEN, to attack visual object tracking models.  There are several appealing characteristics of UEN: (1) UEN could produce various invisible adversarial  perturbations according to different attack settings by using only one simple end-to-end network with three ingenious loss function; (2) UEN could generate general visible adversarial patch patterns to attack the advanced trackers in the real-world; (3) Extensive experiments show that UEN is able to attack many state-of-the-art trackers effectively (e.g. SiamRPN-based networks and DiMP) on popular tracking datasets including OTB100, UAV123, and GOT10K, making online real-time attacks possible. The attack results outperform the introduced baseline in terms of attacking ability and attacking efficiency.",
        "primary_area": "Computer Vision I",
        "author": "Xuesong Chen; Canmiao Fu; Feng Zheng; Yong Zhao; Hongsheng Li; Ping Luo; Guo-Jun Qi",
        "authorids": "",
        "aff": "The Chinese University of Hong Kong; Tencent; SUSTech; Peking University Shenzhen Graduate School; Chinese University of Hong Kong; The University of Hong Kong; Futurewei Technologies",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16195/16195-13-19689-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01097-a-unified-multi-scenario-attacking-network-for-visual-object-tracking/",
        "doi": "10.1609/aaai.v35i2.16195",
        "pdf_size": 3216057
    },
    {
        "id": "14524",
        "title": "A Unified Multi-Task Learning Framework for Joint Extraction of Entities and Relations",
        "track": "main",
        "status": "Poster",
        "abstract": "Joint extraction of entities and relations focuses on detecting entity pairs and their relations simultaneously with a unified model. Based on the extraction order, previous works mainly solve this task through relation-last, relation-first and relation-middle manner. However, these methods still suffer from the template-dependency, non-entity detection and non-predefined relation prediction problem. To overcome these challenges, in this paper, we propose a unified multi-task learning framework to divide the task into three interacted sub-tasks. Specifically, we first introduce the type-attentional method for subject extraction to provide prior type information explicitly. Then, the subject-aware relation prediction is presented to select useful relations based on the combination of global and local semantics. Third, we propose a question generation based QA method for object extraction to obtain diverse queries automatically. Notably, our method detects subjects or objects without relying on NER models and thus it is capable of dealing with the non-entity scenario. Finally, three sub-tasks are integrated into a unified model through parameter sharing. Extensive experiments demonstrate that the proposed framework outperforms all the baseline methods on two benchmark datasets, and further achieve excellent performance for non-predefined relations.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Tianyang Zhao; Zhao Yan; Yunbo Cao; Zhoujun Li",
        "authorids": "",
        "aff": "Beihang University; Tencent; Tencent; Beihang University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17707/17707-13-21201-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14524-a-unified-multi-task-learning-framework-for-joint-extraction-of-entities-and-relations/",
        "doi": "10.1609/aaai.v35i16.17707",
        "pdf_size": 901620
    },
    {
        "id": "04555",
        "title": "A Unified Pretraining Framework for Passage Ranking and Expansion",
        "track": "main",
        "status": "Poster",
        "abstract": "Pretrained language models have recently advanced a wide range of natural language processing tasks. Nowadays, the application of pretrained language models to IR tasks has also achieved impressive results. Typical methods either directly apply a pretrained model to improve the re-ranking stage, or use it to conduct passage expansion and term weighting for first-stage retrieval. We observe that the passage ranking and passage expansion tasks share certain inherent relations, and can benefit from each other. Therefore, in this paper, we propose a general pretraining framework to enhance both tasks with Unified Encoder-Decoder networks (UED). The overall ranking framework consists of two parts in a cascade manner: (1) passage expansion with a pretraining-based query generation method; (2) re-ranking of passage candidates from a traditional retrieval method with a pretrained transformer encoder. Both the two parts are based on the same pretrained UED model, where we jointly train the passage ranking and query generation tasks for further improving the full ranking pipeline. An extensive set of experiments have been conducted on two large-scale passage retrieval datasets to demonstrate the state-of-the-art results of the proposed framework in both the first-stage retrieval and the final re-ranking. In addition, we successfully deploy the framework to our online production system, which can stably serve industrial applications with a request volume of up to 100 QPS in less than 300ms.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Ming Yan; Chenliang Li; Bin Bi; Wei Wang; Songfang Huang",
        "authorids": "",
        "aff": "Alibaba Group; Alibaba Group; Alibaba Group; Alibaba Group; Alibaba Group",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16584/16584-13-20078-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04555-a-unified-pretraining-framework-for-passage-ranking-and-expansion/",
        "doi": "10.1609/aaai.v35i5.16584",
        "pdf_size": 496331
    },
    {
        "id": "11462",
        "title": "A Unified Taylor Framework for Revisiting Attribution Methods",
        "track": "main",
        "status": "Poster",
        "abstract": "Attribution methods have been developed to understand the decision making process of machine learning models, especially deep neural networks, by assigning importance scores to individual features. Existing attribution methods often built upon empirical intuitions and heuristics. There still lacks a general and theoretical framework that not only can unify these attribution methods, but also theoretically reveal their rationales, fidelity, and limitations. To bridge the gap, in this paper, we propose a Taylor attribution framework and reformulate seven mainstream attribution methods into the framework. Based on reformulations, we analyze the attribution methods in terms of rationale, fidelity, and limitation. Moreover, We establish three principles for a good attribution in the Taylor attribution framework, i.e., low approximation error, correct contribution assignment, and unbiased baseline selection. Finally, we empirically validate the Taylor reformulations, and reveal a positive correlation between the attribution performance and the number of principles followed by the attribution method via benchmarking on real-world datasets.",
        "primary_area": "Philosophy and Ethics of AI",
        "author": "Huiqi Deng; Na Zou; Mengnan Du; Weifu Chen; Guocan Feng; Xia Hu",
        "authorids": "",
        "aff": "Sun Yat-Sen University; Texas A&M University; Texas A&M University; Sun Yat-Sen University; Sun Yat-Sen University; Texas A&M University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17365/17365-13-20859-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11462-a-unified-taylor-framework-for-revisiting-attribution-methods/",
        "doi": "10.1609/aaai.v35i13.17365",
        "pdf_size": 971011
    },
    {
        "id": "03984",
        "title": "A User-Adaptive Layer Selection Framework for Very Deep Sequential Recommender Models",
        "track": "main",
        "status": "Poster",
        "abstract": "Sequential recommender systems (SRS) have become a research hotspot in recent studies. Because of the requirement in capturing user's dynamic interests, sequential neural network based recommender models often need to be stacked with more hidden layers (e.g., up to 100 layers) compared with standard collaborative filtering methods. However, the high network latency has become the main obstacle when deploying very deep recommender models into a production environment. In this paper, we argue that the typical prediction framework that treats all users equally during the inference phase is inefficient in running time, as well as sub-optimal in accuracy. To resolve such an issue, we present SkipRec, an adaptive inference framework by learning to skip inactive hidden layers on a per-user basis. Specifically, we devise a policy network to automatically determine which layers should be retained and which layers are allowed to be skipped, so as to achieve user-specific decisions. To derive the optimal skipping policy, we propose using gumbel softmax and reinforcement learning to solve the non-differentiable problem during backpropagation.  We perform extensive experiments on three real-world recommendation datasets, and demonstrate that SkipRec attains comparable or better accuracy with much less inference time.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Lei Chen; Fajie Yuan; Jiaxi Yang; Xiang Ao; Chengming Li; Min Yang",
        "authorids": "",
        "aff": "Shenzhen Key Laboratory for High Performance Data Mining, Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences University of Chinese Academy of Sciences; Tencent; Huazhong University of Science and Technology; Institute of Computing Technology, Chinese Academy of Sciences; Shenzhen Key Laboratory for High Performance Data Mining, Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences; Shenzhen Key Laboratory for High Performance Data Mining, Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16518/16518-13-20012-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03984-a-user-adaptive-layer-selection-framework-for-very-deep-sequential-recommender-models/",
        "doi": "10.1609/aaai.v35i5.16518",
        "pdf_size": 630657
    },
    {
        "id": "07857",
        "title": "ACMo: Angle-Calibrated Moment Methods for Stochastic Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "Stochastic gradient descent (SGD) is a widely used method for its outstanding generalization ability and simplicity. Adaptive gradient methods have been proposed to further accelerate the optimization process. In this paper, we revisit existing adaptive gradient optimization methods with a new interpretation. Such new perspective leads to a refreshed understanding of the roles of second moments in stochastic optimization. Based on this, we propose Angle-Calibration Moment method (ACMo), a novel stochastic optimization method. It enjoys the benefits of second moments with only first moment updates. Theoretical analysis shows that ACMo is able to achieve the same convergence rate as mainstream adaptive methods. Experiments on a variety of CV and NLP tasks demonstrate that ACMo has a comparable convergence to state-of-the-art Adam-type optimizers, and even a better generalization performance in most cases. The code is available at https://github.com/Xunpeng746/ACMo.",
        "primary_area": "Machine Learning II",
        "author": "Xunpeng Huang; Runxin Xu; Hao Zhou; Zhe Wang; Zhengyang Liu; Lei Li",
        "authorids": "",
        "aff": "ByteDance AI Lab; Peking University; ByteDance AI Lab; Ohio State University; Beijing Institute of Technology; ByteDance AI Lab",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16959/16959-13-20453-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07857-acmo-angle-calibrated-moment-methods-for-stochastic-optimization/",
        "doi": "10.1609/aaai.v35i9.16959",
        "pdf_size": 485498
    },
    {
        "id": "02233",
        "title": "ACSNet: Action-Context Separation Network for Weakly Supervised Temporal Action Localization",
        "track": "main",
        "status": "Poster",
        "abstract": "The object of Weakly-supervised Temporal Action Localization (WS-TAL) is to localize all action instances in an untrimmed video with only video-level supervision. Due to the lack of frame-level annotations during training, current WS-TAL methods rely on attention mechanisms to localize the foreground snippets or frames that contribute to the video-level classification task. This strategy frequently confuse context with the actual action, in the localization result. Separating action and context is a core problem for precise WS-TAL, but it is very challenging and has been largely ignored in the literature. In this paper, we introduce an Action-Context Separation Network (ACSNet) that explicitly takes into account context for accurate action localization. It consists of two branches (i.e., the Foreground-Background branch and the Action-Context branch). The Foreground-Background branch first distinguishes foreground from background within the entire video while the Action-Context branch further separates the foreground as action and context. We associate video snippets with two latent components (i.e., a positive component and a negative component), and their different combinations can effectively characterize foreground, action and context. Furthermore, we introduce extended labels with auxiliary context categories to facilitate the learning of action-context separation. Experiments on THUMOS14 and ActivityNet v1.2/v1.3 datasets demonstrate the ACSNet outperforms existing state-of-the-art WS-TAL methods by a large margin.",
        "primary_area": "Computer Vision II",
        "author": "Ziyi Liu; Le Wang; Qilin Zhang; Wei Tang; Junsong Yuan; Nanning Zheng; Gang Hua",
        "authorids": "",
        "aff": "Xi'an Jiaotong University; Xi'an Jiaotong University; HERE Technologies; University of Illinois at Chicago; The State University of New York at Buffalo; Xi'an Jiaotong University; Wormpex AI Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16322/16322-13-19816-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02233-acsnet-action-context-separation-network-for-weakly-supervised-temporal-action-localization/",
        "doi": "10.1609/aaai.v35i3.16322",
        "pdf_size": 512511
    },
    {
        "id": "13261",
        "title": "ACT: an Attentive Convolutional Transformer for Efficient Text Classification",
        "track": "main",
        "status": "Poster",
        "abstract": "Recently, Transformer has been demonstrating promising performance in many NLP tasks and showing a trend of replacing Recurrent Neural Network (RNN). Meanwhile, less attention is drawn to Convolutional Neural Network (CNN) due to its weak ability in capturing sequential and long-distance dependencies, although it has excellent local feature extraction capability. In this paper, we introduce an Attentive Convolutional Transformer (ACT) that takes the advantages of both Transformer and CNN for efficient text classification. Specifically, we propose a novel attentive convolution mechanism that utilizes the semantic meaning of convolutional filters attentively to transform text from complex word space to a more informative convolutional filter space where important n-grams are captured. ACT is able to capture both local and global dependencies effectively while preserving sequential information. Experiments on various text classification tasks and detailed analyses show that ACT is a lightweight, fast, and effective universal text classifier, outperforming CNNs, RNNs, and attentive models including Transformer.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Pengfei Li; Peixiang Zhong; Kezhi Mao; Dongzhe Wang; Xuefeng Yang; Yunfeng Liu; Jianxiong Yin; Simon See",
        "authorids": "",
        "aff": "Nanyang Technological University, Singapore; Nanyang Technological University, Singapore; Nanyang Technological University, Singapore; Zhuiyi Technology, Shenzhen, China; Zhuiyi Technology, Shenzhen, China; Zhuiyi Technology, Shenzhen, China; NVIDIA AI Tech Center; NVIDIA AI Tech Center",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17566/17566-13-21060-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13261-act-an-attentive-convolutional-transformer-for-efficient-text-classification/",
        "doi": "10.1609/aaai.v35i15.17566",
        "pdf_size": 619767
    },
    {
        "id": "10665",
        "title": "ADAHESSIAN: An Adaptive Second Order Optimizer for Machine Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Incorporating second-order curvature information into machine learning optimization algorithms can be subtle, and doing so na\u00efvely can lead to high per-iteration costs associated with forming the Hessian and performing the associated linear system solve. To address this, we introduce ADAHESSIAN, a new stochastic optimization algorithm. ADAHESSIAN directly incorporates approximate curvature information from the loss function, and it includes several novel performance-improving features, including: (i) a fast Hutchinson based method to approximate the curvature matrix with low computational overhead; (ii) a spatial averaging to reduce the variance of the second derivative; and (iii) a root-mean-square exponential moving average to smooth out variations of the second-derivative across different iterations. We perform extensive tests on NLP, CV, and recommendation system tasks, and ADAHESSIAN achieves state-of-the-art results. In particular, we find that ADAHESSIAN: (i) outperforms AdamW for transformers by0.13/0.33 BLEU score on IWSLT14/WMT14, 2.7/1.0 PPLon PTB/Wikitext-103; (ii) outperforms AdamW for Squeeze-Bert by 0.41 points on GLUE; (iii) achieves 1.45%/5.55%higher accuracy on ResNet32/ResNet18 on Cifar10/ImageNetas compared to Adam; and (iv) achieves 0.032% better score than Adagrad for DLRM on the Criteo Ad Kaggle dataset. The cost per iteration of ADAHESSIANis comparable to first-order methods, and ADAHESSIAN exhibits improved robustness towards variations in hyperparameter values. The code for ADAHESSIAN is open-sourced and publicly-available [1].",
        "primary_area": "Machine Learning V",
        "author": "Zhewei Yao; Amir Gholami; Sheng Shen; Mustafa Mustafa; Kurt Keutzer; Michael Mahoney",
        "authorids": "",
        "aff": "University of California, Berkeley; UC Berkeley; UC Berkeley; Lawrence Berkeley National Laboratory; EECS, UC Berkeley; \"University of California, Berkeley\"",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17275/17275-13-20769-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10665-adahessian-an-adaptive-second-order-optimizer-for-machine-learning/",
        "doi": "10.1609/aaai.v35i12.17275",
        "pdf_size": 792430
    },
    {
        "id": "05957",
        "title": "AI-Assisted Scientific Data Collection with Iterative Human Feedback",
        "track": "main",
        "status": "Poster",
        "abstract": "Although artificial intelligence has revolutionized data analysis, significantly less work has focused on using AI to improve scientific data collection. Past work in AI for data collection has typically assumed the objective function is well-defined by humans before starting an experiment; however, this is a poor fit for scientific domains where new discoveries and insights are made as data is being collected. In this paper we present a new framework to allow AI systems to work together with humans (e.g. scientists) to collect data more effectively in simple scientific domains. We present a novel algorithm, TESA, which seeks to achieve good performance by learning from past human behavior how to direct data to places that are likely to become scientifically interesting in the future. We analyze the problem theoretically, defining a novel notion of regret in this setting and showing that TESA is zero regret. Next, we show that TESA outperforms other related algorithms in simulations using real data drawn from three diverse domains (economics, mental health, and cognitive psychology). Finally, we run experiments with human subjects across these scientific domains to compare our iterative human-in-the-loop process to a (more standard) workflow in which information is communicated to the AI a priori.",
        "primary_area": "Humans and AI",
        "author": "Travis Mandel; James Boyd; Sebastian J. Carter; Randall H. Tanaka; Taishi Nammoto",
        "authorids": "",
        "aff": "University of Hawai'i at Hilo, Hilo, HI; University of Hawai'i at Hilo, Hilo, HI; University of Hawai'i at Hilo, Hilo, HI; University of Hawai'i at Hilo, Hilo, HI; University of Hawai'i at Hilo, Hilo, HI",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16744/16744-13-20238-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05957-ai-assisted-scientific-data-collection-with-iterative-human-feedback/",
        "doi": "10.1609/aaai.v35i7.16744",
        "pdf_size": 311982
    },
    {
        "id": "13657",
        "title": "ALP-KD: Attention-Based Layer Projection for Knowledge Distillation",
        "track": "main",
        "status": "Poster",
        "abstract": "Knowledge distillation is considered as a training and compression strategy in which two neural networks, namely a teacher and a student, are coupled together during training. The teacher network is supposed to be a trustworthy predictor and the student tries to mimic its predictions. Usually, a student with a lighter architecture is selected so we can achieve compression and yet deliver high-quality results. In such a setting, distillation only happens for final predictions whereas the student could also benefit from teacher\u2019s supervision for internal components.  Motivated by this, we studied the problem of distillation for intermediate layers. Since there might not be a one-to-one alignment between student and teacher layers, existing techniques skip some teacher layers and only distill from a subset of them. This shortcoming directly impacts quality, so we instead propose a combinatorial technique which relies on attention. Our model fuses teacher-side information and takes each layer\u2019s significance into consideration, then it performs distillation between combined teacher layers and those of the student. Using our technique, we distilled a 12-layer BERT (Devlin et al. 2019) into 6-, 4-, and 2-layer counterparts and evaluated them on GLUE tasks (Wang et al. 2018). Experimental results show that our combinatorial approach is able to outperform other existing techniques.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Peyman Passban; Yimeng Wu; Mehdi Rezagholizadeh; Qun Liu",
        "authorids": "",
        "aff": "Amazon; Huawei Noah\u2019s Ark Lab; Huawei Noah\u2019s Ark Lab; Huawei Noah's Ark Lab",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17610/17610-13-21104-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13657-alp-kd-attention-based-layer-projection-for-knowledge-distillation/",
        "doi": "10.1609/aaai.v35i15.17610",
        "pdf_size": 330100
    },
    {
        "id": "03625",
        "title": "ASHF-Net: Adaptive Sampling and Hierarchical Folding Network for Robust Point Cloud Completion",
        "track": "main",
        "status": "Poster",
        "abstract": "Estimating the complete 3D point cloud from an incomplete one lies at the core of many vision and robotics applications. Existing methods typically predict the complete point cloud based on the global shape representation extracted from the incomplete input. Although they could predict the overall shape of 3D objects, they are incapable of generating structure details of objects. Moreover, the partial input point sets obtained from range scans are often sparse, noisy and non-uniform, which largely hinder shape completion. In this paper, we propose an adaptive sampling and hierarchical folding network (ASHF-Net) for robust 3D point cloud completion. Our main contributions are two-fold. First, we propose a denoising auto-encoder with an adaptive sampling module, aiming at learning robust local region features that are insensitive to noise. Second, we propose a hierarchical folding decoder with the gated skip-attention and multi-resolution completion goal to effectively exploit the local structure details of partial inputs. We also design a KL regularization term to evenly distribute the generated points. Extensive experiments demonstrate that our method outperforms existing state-of-the-art methods on multiple 3D point cloud completion benchmarks.",
        "primary_area": "Computer Vision III",
        "author": "Daoming Zong; Shiliang Sun; Jing Zhao",
        "authorids": "",
        "aff": "East China Normal University; East China Normal University; East China Normal University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16478/16478-13-19972-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03625-ashf-net-adaptive-sampling-and-hierarchical-folding-network-for-robust-point-cloud-completion/",
        "doi": "10.1609/aaai.v35i4.16478",
        "pdf_size": 8832252
    },
    {
        "id": "12436",
        "title": "Accelerated Combinatorial Search for Outlier Detection with Provable Bound on Sub-Optimality",
        "track": "main",
        "status": "Poster",
        "abstract": "Outliers negatively affect the accuracy of data analysis. In this paper we are concerned with their influence on the accuracy of Principal Component Analysis (PCA). Algorithms that attempt to detect outliers and remove them from the data prior to applying PCA are sometimes called Robust PCA, or Robust Subspace Recovery algorithms. We propose a new algorithm for outlier detection that combines two ideas. The first is \"chunk recursive elimination\" that was used effectively to accelerate feature selection, and the second is combinatorial search, in a setting similar to  A*. Our main result is showing how to combine these two ideas. One variant of our algorithm is guaranteed to compute an optimal solution  according to some natural criteria,  but its running time makes it impractical for large datasets.  Other variants are much faster and come with provable bounds on sub-optimality. Experimental results show the effectiveness of the proposed approach.",
        "primary_area": "Search and Optimization",
        "author": "Guihong Wan; Haim Schweitzer",
        "authorids": "",
        "aff": "The University of Texas at Dallas; The University of Texas at Dallas",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17475/17475-13-20969-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12436-accelerated-combinatorial-search-for-outlier-detection-with-provable-bound-on-sub-optimality/",
        "doi": "10.1609/aaai.v35i14.17475",
        "pdf_size": 182244
    },
    {
        "id": "07832",
        "title": "Accelerating Continuous Normalizing Flow with Trajectory Polynomial Regularization",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose an approach to effectively accelerating the computation of continuous normalizing flow (CNF), which has been proven to be a powerful tool for the tasks such as variational inference and density estimation. The training time cost of CNF can be extremely high because the required number of function evaluations (NFE)  for solving corresponding ordinary differential equations (ODE) is very large. We think that the high NFE results from large truncation errors of solving ODEs. To address the problem, we propose to add a regularization. The regularization penalizes the difference between the trajectory of the ODE and its fitted polynomial regression. The trajectory of ODE will approximate a polynomial function, and thus the truncation error will be smaller. Furthermore, we provide two proofs and claim that the additional regularization does not harm training quality. Experimental results show that our proposed method can result in 42.3% to 71.3% reduction of NFE on the task of density estimation, and 19.3% to 32.1% reduction of NFE on  variational auto-encoder, while the testing losses are not affected.",
        "primary_area": "Machine Learning II",
        "author": "Han-Hsien Huang; Mi-Yen Yeh",
        "authorids": "",
        "aff": "Academia Sinica Texas A&M University; Academia Sinica",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16956/16956-13-20450-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07832-accelerating-continuous-normalizing-flow-with-trajectory-polynomial-regularization/",
        "doi": "10.1609/aaai.v35i9.16956",
        "pdf_size": 1150666
    },
    {
        "id": "14356",
        "title": "Accelerating Neural Machine Translation with Partial Word Embedding Compression",
        "track": "main",
        "status": "Poster",
        "abstract": "Large model size and high computational complexity prevent the neural machine translation (NMT) models from being deployed to low resource devices (e.g. mobile phones). Due to the large vocabulary, a large storage memory is required for the word embedding matrix in NMT models, in the meantime, high latency is introduced when constructing the word probability distribution. Based on reusing the word embedding matrix in the softmax layer, it is possible to handle the two problems brought by large vocabulary at the same time. In this paper, we propose Partial Vector Quantization (P-VQ) for NMT models, which can both compress the word embedding matrix and accelerate word probability prediction in the softmax layer. With P-VQ, the word embedding matrix is split into two low dimensional matrices, namely the shared part and the exclusive part. We compress the shared part by vector quantization and leave the exclusive part unchanged to maintain the uniqueness of each word. For acceleration, in the softmax layer, we replace most of the multiplication operations with the efficient looking-up operations based on our compression to reduce the computational complexity. Furthermore, we adopt curriculum learning and compact the word embedding matrix gradually to improve the compression quality. Experimental results on the Chinese-to-English translation task show that our method can reduce 74.35% of parameters of the word embedding and 74.42% of the FLOPs of the softmax layer. Meanwhile, the average BLEU score on the WMT test sets only drops 0.04.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Fan Zhang; Mei Tu; Jinyao Yan",
        "authorids": "",
        "aff": "Communication University of China Samsung Research China - Beijing; Samsung Research China - Beijing; Communication University of China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17688/17688-13-21182-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14356-accelerating-neural-machine-translation-with-partial-word-embedding-compression/",
        "doi": "10.1609/aaai.v35i16.17688",
        "pdf_size": 215063
    },
    {
        "id": "07891",
        "title": "Accurate and Robust Feature Importance Estimation under Distribution Shifts",
        "track": "main",
        "status": "Poster",
        "abstract": "With increasing reliance on the outcomes of black-box models in critical applications, post-hoc explainability tools that do not require access to the model internals are often used to enable humans understand and trust these models. In particular, we focus on the class of methods that can reveal the influence of  input features on the predicted outputs. Despite their wide-spread adoption, existing methods are known to suffer from one or more of the following challenges: computational complexities, large uncertainties and most importantly, inability to handle real-world domain shifts. In this paper, we propose PRoFILE (Producing Robust Feature Importances using Loss Estimates), a novel feature importance estimation method that addresses all these challenges. Through the use of a loss estimator jointly trained with the predictive model and a causal objective, PRoFILE can accurately estimate the feature importance scores even under complex distribution shifts, without any additional re-training. To this end, we also develop learning strategies for training the loss estimator, namely contrastive and dropout calibration, and find that it can effectively detect distribution shifts. Using empirical studies on several benchmark image and non-image data, we show significant improvements over state-of-the-art approaches, both in terms of fidelity and robustness.",
        "primary_area": "Machine Learning II",
        "author": "Jayaraman J. Thiagarajan; Vivek Narayanaswamy; Rushil Anirudh; Peer-Timo Bremer; Andreas Spanias",
        "authorids": "",
        "aff": "Lawrence Livermore National Laboratory; Arizona State University; Lawrence Livermore National Laboratory; Lawrence Livermore National Laboratory; Arizona State University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16963/16963-13-20457-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07891-accurate-and-robust-feature-importance-estimation-under-distribution-shifts/",
        "doi": "10.1609/aaai.v35i9.16963",
        "pdf_size": 4072522
    },
    {
        "id": "05102",
        "title": "Achieving Envy-freeness and Equitability with Monetary Transfers",
        "track": "main",
        "status": "Poster",
        "abstract": "When allocating indivisible resources or tasks, an envy-free allocation or equitable allocation may not exist. We present a sufficient condition and an algorithm to achieve envy-freeness and equitability when monetary transfers are allowed. The approach works for any agent valuation functions (positive or negative) as long as they satisfy superadditivity. For the case of additive utilities, we present a characterization of allocations that can simultaneously be made equitable and envy-free via payments. Our study shows that superadditive valuations constitute the largest class of valuations for which an envy-free and equitable outcome exists for all instances. We then present a distributed algorithm to compute an approximately envy-free outcome for any class of valuations.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Haris Aziz",
        "authorids": "",
        "aff": "UNSW Sydney",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16645/16645-13-20139-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05102-achieving-envy-freeness-and-equitability-with-monetary-transfers/",
        "doi": "10.1609/aaai.v35i6.16645",
        "pdf_size": 124293
    },
    {
        "id": "05143",
        "title": "Achieving Proportionality up to the Maximin Item with Indivisible Goods",
        "track": "main",
        "status": "Poster",
        "abstract": "We study the problem of fairly allocating indivisible goods and focus on the classic fairness notion of proportionality. The indivisibility of the goods is long known to pose highly non-trivial obstacles to achieving fairness, and a very vibrant line of research has aimed to circumvent them using appropriate notions of approximate fairness. Recent work has established that even approximate versions of proportionality (PROPx) may be impossible to achieve even for small instances, while the best known achievable approximations (PROP1) are much weaker. We introduce the notion of proportionality up to the maximin item (PROPm) and show how to reach an allocation satisfying this notion for any instance involving up to five agents with additive valuations. PROPm provides a well-motivated middle-ground between PROP1 and PROPx, while also capturing some elements of the well-studied maximin share (MMS) benchmark: another relaxation of proportionality that has attracted a lot of attention.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Artem Baklanov; Pranav Garimidi; Vasilis Gkatzelis; Daniel Schoepflin",
        "authorids": "",
        "aff": "HSE University, Russian Federation; Conestoga High School; Drexel University; Drexel University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16650/16650-13-20144-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05143-achieving-proportionality-up-to-the-maximin-item-with-indivisible-goods/",
        "doi": "10.1609/aaai.v35i6.16650",
        "pdf_size": 149384
    },
    {
        "id": "07979",
        "title": "Action Candidate Based Clipped Double Q-learning for Discrete and Continuous Action Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "Double Q-learning is a popular reinforcement learning algorithm in Markov decision process (MDP) problems. Clipped Double Q-learning, as an effective variant of Double Q-learning, employs the clipped double estimator to approximate the maximum expected action value. Due to the underestimation bias of the clipped double estimator, performance of clipped Double Q-learning may be degraded in some stochastic environments. In this paper, in order to reduce the underestimation bias, we propose an action candidate based clipped double estimator for Double Q-learning. Specifically, we first select a set of elite action candidates with the high action values from one set of estimators. Then, among these candidates, we choose the highest valued action from the other set of estimators. Finally, we use the maximum value in the second set of estimators to clip the action value of the chosen action in the first set of estimators and the clipped value is used for approximating the maximum expected action value.  Theoretically, the underestimation bias in our clipped Double Q-learning decays monotonically as the number of the action candidates decreases.  Moreover, the number of action candidates controls the trade-off between the overestimation and underestimation biases. In addition, we also extend our clipped Double Q-learning to continuous action tasks via approximating the elite continuous action candidates. We empirically verify that our algorithm can more accurately estimate the maximum expected action value on some toy environments and yield good performance on several benchmark problems.",
        "primary_area": "Machine Learning II",
        "author": "Haobo Jiang; Jin Xie; Jian Yang",
        "authorids": "",
        "aff": "Nanjing University of Science and Technology; Nanjing University of Science and Technology; Nanjing University of Science and Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16973/16973-13-20467-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07979-action-candidate-based-clipped-double-q-learning-for-discrete-and-continuous-action-tasks/",
        "doi": "10.1609/aaai.v35i9.16973",
        "pdf_size": 562233
    },
    {
        "id": "05931",
        "title": "ActionBert: Leveraging User Actions for Semantic Understanding of User Interfaces",
        "track": "main",
        "status": "Poster",
        "abstract": "As mobile devices are becoming ubiquitous, regularly interacting with a variety of user interfaces (UIs) is a common aspect of daily life for many people. To improve the accessibility of these devices and to enable their usage in a variety of settings, building models that can assist users and accomplish tasks through the UI is vitally important. However, there are several challenges to achieve this. First, UI components of similar appearance can have different functionalities, making understanding their function more important than just analyzing their appearance. Second, domain-specific features like Document Object Model (DOM) in web pages and View Hierarchy (VH) in mobile applications provide important signals about the semantics of UI elements, but these features are not in a natural language format. Third, owing to a large diversity in UIs and absence of standard DOM or VH representations, building a UI understanding model with high coverage requires large amounts of training data.   Inspired by the success of pre-training based approaches in NLP for tackling a variety of problems in a data-efficient way, we introduce a new pre-trained UI representation model called ActionBert. Our methodology is designed to leverage visual, linguistic and domain-specific features in user interaction traces to pre-train generic feature representations of UIs and their components. Our key intuition is that user actions, e.g., a sequence of clicks on different UI components, reveals important information about their functionality. We evaluate the proposed model on a wide variety of downstream tasks, ranging from icon classification to UI component retrieval based on its natural language description. Experiments show that the proposed ActionBert model outperforms multi-modal baselines across all downstream tasks by up to 15.5%.",
        "primary_area": "Humans and AI",
        "author": "Zecheng He; Srinivas Sunkara; Xiaoxue Zang; Ying Xu; Lijuan Liu; Nevan Wichers; Gabriel Schubiner; Ruby Lee; Jindong Chen",
        "authorids": "",
        "aff": "Princeton University; Google; Google; Google; Google; Google; Google; Princeton University; Google",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16741/16741-13-20235-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05931-actionbert-leveraging-user-actions-for-semantic-understanding-of-user-interfaces/",
        "doi": "10.1609/aaai.v35i7.16741",
        "pdf_size": 1721977
    },
    {
        "id": "07935",
        "title": "Active Bayesian Assessment of Black-Box Classifiers",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent advances in machine learning have led to increased deployment of black-box classifiers across a wide variety of applications. In many such situations there is a critical need to both reliably assess the performance of these pre-trained models and to perform this assessment in a label-efficient manner (given that labels may be scarce and costly to collect).  In this paper, we introduce an active Bayesian  approach for assessment of classifier performance  to satisfy the desiderata of both reliability and label-efficiency. We begin by developing inference strategies to quantify uncertainty for common assessment metrics such as accuracy, misclassification cost, and   calibration error. We then propose a general framework for active Bayesian assessment using inferred uncertainty to guide  efficient selection of instances for labeling, enabling better performance assessment with fewer labels. We demonstrate  significant gains from  our proposed active Bayesian approach   via a series of systematic empirical experiments assessing the performance of modern neural classifiers (e.g., ResNet and BERT) on several standard image and text classification datasets.",
        "primary_area": "Machine Learning II",
        "author": "Disi Ji; Robert L. Logan; Padhraic Smyth; Mark Steyvers",
        "authorids": "",
        "aff": "Department of Computer Science, University of California, Irvine; Department of Computer Science, University of California, Irvine; Department of Computer Science, University of California, Irvine; Department of Cognitive Sciences, University of California, Irvine",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16968/16968-13-20462-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07935-active-bayesian-assessment-of-black-box-classifiers/",
        "doi": "10.1609/aaai.v35i9.16968",
        "pdf_size": 368374
    },
    {
        "id": "09497",
        "title": "Active Feature Selection for the Mutual Information Criterion",
        "track": "main",
        "status": "Poster",
        "abstract": "We study active feature selection, a novel feature selection setting in which unlabeled data is available, but the budget for labels is limited, and the examples to label can be actively selected by the algorithm. We focus on feature selection using the classical mutual information criterion, which selects the k features with the largest mutual information with the label. In the active feature selection setting, the goal is to use significantly fewer labels than the data set size and still find k features whose mutual information with the label based on the entire data set is large.  We explain and experimentally study the choices that we make in the algorithm, and show that they lead to a successful algorithm, compared to other more naive approaches. Our design draws on insights which relate the problem of active feature selection to the study of pure-exploration multi-armed bandits settings. While we focus here on mutual information, our general methodology can be adapted to other feature-quality measures as well. The extended version of this paper, reporting all experiment results, is available at Schnapp and Sabato (2020). The code is available at the following url: https://github.com/ShacharSchnapp/ActiveFeatureSelection",
        "primary_area": "Machine Learning IV",
        "author": "Shachar Schnapp; Sivan Sabato",
        "authorids": "",
        "aff": "Ben-Gurion University of the Negev; Ben-Gurion University of the Negev",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17144/17144-13-20638-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09497-active-feature-selection-for-the-mutual-information-criterion/",
        "doi": "10.1609/aaai.v35i11.17144",
        "pdf_size": 493341
    },
    {
        "id": "02145",
        "title": "Activity Image-to-Video Retrieval by Disentangling Appearance and Motion",
        "track": "main",
        "status": "Poster",
        "abstract": "With the rapid emergence of video data, image-to-video retrieval has attracted much attention. There are two types of image-to-video retrieval: instance-based and activity-based. The former task aims to retrieve videos containing the same main objects as the query image, while the latter focuses on finding the similar activity. Since dynamic information plays a significant role in the video, we pay attention to the latter task to explore the motion relation between images and videos. In this paper, we propose a Motion-assisted Activity Proposal-based Image-to-Video Retrieval (MAP-IVR) approach to disentangle the video features into motion features and appearance features and obtain appearance features from the images. Then, we perform image-to-video translation to improve the disentanglement quality. The retrieval is performed in both appearance and video feature spaces. Extensive experiments demonstrate that our MAP-IVR approach remarkably outperforms the state-of-the-art approaches on two benchmark activity-based video datasets.",
        "primary_area": "Computer Vision II",
        "author": "Liu  Liu; Jiangtong Li; Li Niu; Ruicong Xu; Liqing Zhang",
        "authorids": "",
        "aff": "Shanghai Jiao Tong University; Shanghai Jiao Tong University; Shanghai Jiao Tong University; MEITUAN; Shanghai Jiao Tong University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16312/16312-13-19806-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02145-activity-image-to-video-retrieval-by-disentangling-appearance-and-motion/",
        "doi": "10.1609/aaai.v35i3.16312",
        "pdf_size": 7992171
    },
    {
        "id": "03333",
        "title": "Ada-Segment: Automated Multi-loss Adaptation for Panoptic Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "Panoptic segmentation that unifies instance segmentation and semantic segmentation has recently attracted increasing attention. While most existing methods focus on designing novel architectures, we steer toward a different perspective: performing automated multi-loss adaptation (named Ada-Segment) on the fly to flexibly adjust multiple training losses over the course of training using a controller trained to capture the learning dynamics. This offers a few advantages: it bypasses manual tuning of the sensitive loss combination, a decisive factor for panoptic segmentation; allows to explicitly model the learning dynamics, and reconcile the learning of multiple objectives (up to ten in our experiments); with an end-to-end architecture, it generalizes to different datasets without the need of re-tuning hyperparameters or re-adjusting the training process laboriously. Our Ada-Segment brings 2.7% panoptic quality (PQ) improvement on COCO val split from the vanilla baseline, achieving the state-of-the-art 48.5% PQ on COCO test-dev split and 32.9% PQ on ADE20K dataset. The extensive ablation studies reveal the ever-changing dynamics throughout the training process, necessitating the incorporation of an automated and adaptive learning strategy as presented in this paper.",
        "primary_area": "Computer Vision III",
        "author": "Gengwei Zhang; Yiming Gao; Hang Xu; Hao Zhang; Zhenguo Li; Xiaodan Liang",
        "authorids": "",
        "aff": "Sun Yat-sen University; Sun Yat-sen University; Huawei Noah's Ark Lab; Shanghai Jiao Tong University; Huawei Noah's Ark Lab; Sun Yat-sen University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16445/16445-13-19939-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03333-ada-segment-automated-multi-loss-adaptation-for-panoptic-segmentation/",
        "doi": "10.1609/aaai.v35i4.16445",
        "pdf_size": 522688
    },
    {
        "id": "10210",
        "title": "Adaptive Algorithms for Multi-armed Bandit with Composite and Anonymous Feedback",
        "track": "main",
        "status": "Poster",
        "abstract": "We study the multi-armed bandit (MAB) problem with composite and anonymous feedback. In this model, the reward of pulling an arm spreads over a period of time (we call this period as reward interval) and the player receives partial rewards of the action, convoluted with rewards from pulling other arms, successively. Existing results on this model require prior knowledge about the reward interval size as an input to their algorithms. In this paper, we propose adaptive algorithms for both the stochastic and the adversarial cases, without requiring any prior information about the reward interval. For the stochastic case, we prove that our algorithm guarantees a regret  that matches the lower bounds (in order). For the adversarial case, we propose the first algorithm to jointly handle non-oblivious adversary and unknown reward interval size. We also conduct simulations based on real-world dataset. The results show that  our algorithms outperform existing benchmarks.",
        "primary_area": "Machine Learning IV",
        "author": "Siwei Wang; Haoyun Wang; Longbo Huang",
        "authorids": "",
        "aff": "Tsinghua University; Georgia Institute of Technology; Tsinghua Univeristy",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17224/17224-13-20718-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10210-adaptive-algorithms-for-multi-armed-bandit-with-composite-and-anonymous-feedback/",
        "doi": "10.1609/aaai.v35i11.17224",
        "pdf_size": 645261
    },
    {
        "id": "13082",
        "title": "Adaptive Beam Search Decoding for Discrete Keyphrase Generation",
        "track": "main",
        "status": "Poster",
        "abstract": "Keyphrase Generation compresses a document into some highly-summative phrases, which is an important task in natural language processing. Most state-of-the-art adopt greedy search or beam search decoding methods. These two decoding methods generate a large number of duplicated keyphrases and are time-consuming. Moreover, beam search only predicts a fixed number of keyphrases for different documents. In this paper, we propose an adaptive generation model-AdaGM, which is mainly inspired by the importance of the first words in keyphrase generation. In AdaGM, a novel reset state training mechanism is proposed to maximize the difference in the predicted first words. To ensure the discreteness and get an appropriate number of keyphrases according to the content of the document adaptively, we equip beam search with a highly effective filter mechanism. Experiments on five public datasets demonstrate the proposed model can generate marginally less duplicated and more accurate keyphrases. The codes of AdaGM are available at: https://github.com/huangxiaolist/adaGM.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Xiaoli Huang; Tongge Xu; Lvan Jiao; Yueran Zu; Youmin Zhang",
        "authorids": "",
        "aff": "Beihang University; Beihang University; Beihang University; Beihang University; Beihang University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17546/17546-13-21040-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13082-adaptive-beam-search-decoding-for-discrete-keyphrase-generation/",
        "doi": "10.1609/aaai.v35i14.17546",
        "pdf_size": 7554724
    },
    {
        "id": "07314",
        "title": "Adaptive Gradient Methods for Constrained Convex Optimization and Variational Inequalities",
        "track": "main",
        "status": "Poster",
        "abstract": "We provide new adaptive first-order methods for constrained convex optimization. Our main algorithms AdaACSA and AdaAGD+ are accelerated methods, which are universal in the sense that they achieve nearly-optimal convergence rates for both smooth and non-smooth functions, even when they only have access to stochastic gradients. In addition, they do not require any prior knowledge on how the objective function is parametrized, since they automatically adjust their per-coordinate learning rate. These can be seen as truly accelerated Adagrad methods for constrained optimization. We complement them with a simpler algorithm AdaGrad+ which enjoys the same features, and achieves the standard non-accelerated convergence rate. We also present a set of new results involving adaptive methods for unconstrained optimization and variational inequalities arising from monotone operators.",
        "primary_area": "Machine Learning I",
        "author": "Alina Ene; Huy L. Nguyen; Adrian Vladu",
        "authorids": "",
        "aff": "Boston University; Northeastern University; CNRS IRIF",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16898/16898-13-20392-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07314-adaptive-gradient-methods-for-constrained-convex-optimization-and-variational-inequalities/",
        "doi": "10.1609/aaai.v35i8.16898",
        "pdf_size": 142582
    },
    {
        "id": "08810",
        "title": "Adaptive Knowledge Driven Regularization for Deep Neural Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "In many real-world applications, the amount of data available for training is often limited, and thus inductive bias and auxiliary knowledge are much needed for regularizing model training. One popular regularization method is to impose prior distribution assumptions on model parameters, and many recent works also attempt to regularize training by integrating external knowledge into specific neurons. However, existing regularization methods did not take account of the interaction between connected neuron pairs, which is invaluable internal knowledge for adaptive regularization for better representation learning as training progresses. In this paper, we explicitly take into account the interaction between connected neurons, and propose an adaptive internal knowledge driven regularization method, CORR-Reg. The key idea of CORR-Reg is to give a higher significance weight to connections of more correlated neuron pairs. The significance weights adaptively identify more important input neurons for each neuron. Instead of regularizing connection model parameters with a static strength such as weight decay, CORR-Reg imposes weaker regularization strength on more significant connections. As a consequence, neurons attend to more informative input features and thus learn more diversified and discriminative representation. We derive CORR-Reg with Bayesian inference framework and propose a novel optimization algorithm with Lagrange multiplier method and Stochastic Gradient Descent. Extensive evaluations on diverse benchmark datasets and neural network structures show that CORR-Reg achieves significant improvement over state-of-the-art regularization methods.",
        "primary_area": "Machine Learning III",
        "author": "Zhaojing Luo; Shaofeng Cai; Can Cui; Beng Chin Ooi; Yang Yang",
        "authorids": "",
        "aff": "National University of Singapore; National University of Singapore; National University of Singapore; National University of Singapore; University of Electronic Science and Technology of China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17067/17067-13-20561-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08810-adaptive-knowledge-driven-regularization-for-deep-neural-networks/",
        "doi": "10.1609/aaai.v35i10.17067",
        "pdf_size": 308527
    },
    {
        "id": "02154",
        "title": "Adaptive Pattern-Parameter Matching for Robust Pedestrian Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Pedestrians with challenging patterns, e.g. small scale or heavy occlusion, appear frequently in practical applications like autonomous driving, which remains tremendous obstacle to higher robustness of detectors. Although plenty of previous works have been dedicated to these problems, properly matching patterns of pedestrian and parameters of detector, i.e., constructing a detector with proper parameter sizes for certain pedestrian patterns of different complexity, has been seldom investigated intensively. Pedestrian instances are usually handled equally with the same amount of parameters, which in our opinion is inadequate for those with more difficult patterns and leads to unsatisfactory performance. Thus, we propose in this paper a novel detection approach via adaptive pattern-parameter matching. The input pedestrian patterns, especially the complex ones, are first disentangled into simpler patterns for detection head by Pattern Disentangling Module (PDM) with various receptive fields. Then, Gating Feature Filtering Module (GFFM) dynamically decides the spatial positions where the patterns are still not simple enough and need further disentanglement by the next-level PDM. Cooperating with these two key components, our approach can adaptively select the best matched parameter size for the input patterns according to their complexity. Moreover, to further explore the relationship between parameter sizes and their performance on the corresponding patterns, two parameter selection policies are designed: 1) extending parameter size to maximum, aiming at more difficult patterns for different occlusion types; 2) specializing parameter size by group division, aiming at complex patterns for scale variations. Extensive experiments on two popular benchmarks, Caltech and CityPersons, show that our proposed method achieves superior performance compared with other state-of-the-art methods on subsets of different scales and occlusion types.",
        "primary_area": "Computer Vision II",
        "author": "Mengyin Liu; Chao Zhu; Jun Wang; Xu-Cheng Yin",
        "authorids": "",
        "aff": "University of Science and Technology Beijing; University of Science and Technology Beijing; University of Science and Technology Beijing; University of Science and Technology Beijing",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16313/16313-13-19807-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02154-adaptive-pattern-parameter-matching-for-robust-pedestrian-detection/",
        "doi": "10.1609/aaai.v35i3.16313",
        "pdf_size": 1659023
    },
    {
        "id": "12701",
        "title": "Adaptive Prior-Dependent Correction Enhanced Reinforcement Learning for Natural Language Generation",
        "track": "main",
        "status": "Poster",
        "abstract": "Natural language generation (NLG) is an important task with various applications like neural machine translation (NMT) and image captioning. Since deep-learning-based methods have issues of exposure bias and loss inconsistency, reinforcement learning (RL) is widely adopted in NLG tasks recently. But most RL-based methods ignore the deviation ignorance issue, which means the model fails to understand the extent of token-level deviation well. It leads to semantic incorrectness and hampers the agent to perform well. To address the issue, we propose a technique called adaptive prior-dependent correction (APDC) to enhance RL. It leverages the distribution generated by computing the distances between the ground truth and all other words to correct the agent's stochastic policy. Additionally, some techniques on RL are explored to coordinate RL with APDC, which requires a reward estimation at every time step. We find that the RL-based NLG tasks are a special case in RL, where the state transition is deterministic and the afterstate value equals the Q-value at every time step. To utilize such prior knowledge, we estimate the advantage function with the difference of the Q-values which can be estimated by Monte Carlo rollouts. Experiments show that, on three tasks of NLG (NMT, image captioning, abstractive text summarization), our method consistently outperforms the state-of-the-art RL-based approaches on different frequently-used metrics.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Wei Cheng; Ziyan Luo; Qiyue Yin",
        "authorids": "",
        "aff": "Technology and Data Center, JD.com; University of California, San Diego; Institute of Automation, Chinese Academy of Sciences",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17504/17504-13-20998-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12701-adaptive-prior-dependent-correction-enhanced-reinforcement-learning-for-natural-language-generation/",
        "doi": "10.1609/aaai.v35i14.17504",
        "pdf_size": 366655
    },
    {
        "id": "05061",
        "title": "Adaptive Teaching of Temporal Logic Formulas to Preference-based Learners",
        "track": "main",
        "status": "Poster",
        "abstract": "Machine teaching is an algorithmic framework for teaching a target hypothesis via a sequence of examples or demonstrations. We investigate machine teaching for temporal logic formulas\u2014a novel and expressive hypothesis class amenable to time-related task specifications. In the context of teaching temporal logic formulas, an exhaustive search even for a myopic solution takes exponential time (with respect to the time span of the task). We propose an efficient approach for teaching parametric linear temporal logic formulas. Concretely, we derive a necessary condition for the minimal time length of a demonstration to eliminate a set of hypotheses. Utilizing this condition, we propose an efficient myopic teaching algorithm by solving a sequence of integer programming problems. We further show that, under two notions of teaching complexity, the proposed algorithm has near-optimal performance. We evaluate our algorithm extensively under different classes of learners (i.e., learners with different preferences over hypotheses) and interaction protocols (e.g., non-adaptive and adaptive). Our results demonstrate the effectiveness of the proposed algorithm in teaching temporal logic formulas; in particular, we show that there are significant gains of teaching efficacy when the teacher adapts to feedback of the learner, or adapts to a (non-myopic) oracle.",
        "primary_area": "Neuro-Symbolic AI",
        "author": "Zhe Xu; Yuxin Chen; Ufuk Topcu",
        "authorids": "",
        "aff": "Arizona State University; University of Chicago; University of Texas at Austin",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16640/16640-13-20134-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05061-adaptive-teaching-of-temporal-logic-formulas-to-preference-based-learners/",
        "doi": "10.1609/aaai.v35i6.16640",
        "pdf_size": 503222
    },
    {
        "id": "10201",
        "title": "Adaptive Verifiable Training Using Pairwise Class Similarity",
        "track": "main",
        "status": "Poster",
        "abstract": "Verifiable training has shown success in creating neural networks that are provably robust to a given amount of noise. However, despite only enforcing a single robustness criterion, its performance scales poorly with dataset complexity. On CIFAR10, a non-robust LeNet model has a 21.63% error rate, while a model created using verifiable training and a L-infinity robustness criterion of 8/255, has an error rate of 57.10%. Upon examination, we find that when labeling visually similar classes, the model's error rate is as high as 61.65%. Thus, we attribute the loss in performance to inter-class similarity. Classes that are similar (i.e., close in the feature space) increase the difficulty of learning a robust model. While it may be desirable to train a model to be robust for a large robustness region, pairwise class similarities limit the potential gains. Furthermore, consideration must be made regarding the relative cost of mistaking one class for another. In security or safety critical tasks, similar classes are likely to belong to the same group, and thus are equally sensitive.  In this work, we propose a new approach that utilizes inter-class similarity to improve the performance of verifiable training and create robust models with respect to multiple adversarial criteria. First, we cluster similar classes using agglomerate clustering and assign robustness criteria based on the degree of similarity between clusters.  Next, we propose two methods to apply our approach: (1) the Inter-Group Robustness Prioritization method, which uses a custom loss term to create a single model with multiple robustness guarantees and (2) the neural decision tree method, which trains multiple sub-classifiers with different robustness guarantees and combines them in a decision tree architecture. Our experiments on Fashion-MNIST and CIFAR10 demonstrate that by prioritizing the robustness between the most dissimilar groups, we improve clean performance by up to 9.63% and 30.89% respectively. Furthermore, on CIFAR100, our approach reduces the clean error rate by 26.32%.",
        "primary_area": "Machine Learning IV",
        "author": "Shiqi Wang; Kevin Eykholt; Taesung Lee; Jiyong Jang; Ian Molloy",
        "authorids": "",
        "aff": "Columbia University; IBM Research; IBM Research; IBM Research; IBM Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17223/17223-13-20717-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10201-adaptive-verifiable-training-using-pairwise-class-similarity/",
        "doi": "10.1609/aaai.v35i11.17223",
        "pdf_size": 303083
    },
    {
        "id": "07020",
        "title": "Addressing Action Oscillations through Learning Policy Inertia",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep reinforcement learning (DRL) algorithms have been demonstrated to be effective on a wide range of challenging decision making and control tasks. However, these methods typically suffer from severe action oscillations in particular in discrete action setting, which means that agents select different actions within consecutive steps even though states only slightly differ. This issue is often neglected since we usually evaluate the quality of a policy using cumulative rewards only. Action oscillation strongly affects the user experience and even causes serious potential security menace especially in real-world domains with the main concern of safety, such as autonomous driving. In this paper, we introduce Policy Inertia Controller (PIC) which serves as a generic plug-in framework to off-the-shelf DRL algorithms, to enable adaptive balance between the optimality and smoothness in a formal way. We propose Nested Policy Iteration as a general training algorithm for PIC-augmented policy which ensures monotonically non-decreasing updates.Further, we derive a practical DRL algorithm, namely Nested Soft Actor-Critic. Experiments on a collection of autonomous driving tasks and several Atari games suggest that our approach demonstrates substantial oscillation reduction than a range of commonly adopted baselines with almost no performance degradation.",
        "primary_area": "Machine Learning I",
        "author": "Chen Chen; Hongyao Tang; Jianye Hao; Wulong Liu; Zhaopeng Meng",
        "authorids": "",
        "aff": "Noah\u2019s Ark Lab, Huawei; College of Intelligence and Computing, Tianjin University Noah\u2019s Ark Lab, Huawei; Noah's Ark Lab, Huawei College of Intelligence and Computing, Tianjin University; Noah's Ark Lab, Huawei; College of Intelligence and Computing, Tianjin University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16864/16864-13-20358-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07020-addressing-action-oscillations-through-learning-policy-inertia/",
        "doi": "10.1609/aaai.v35i8.16864",
        "pdf_size": 6246080
    },
    {
        "id": "10165",
        "title": "Addressing Class Imbalance in Federated Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Federated learning (FL) is a promising approach for training decentralized data located on local client devices while improving efficiency and privacy. However, the distribution and quantity of the training data on the clients' side may lead to significant challenges such as class imbalance and non-IID (non-independent and identically distributed) data, which could greatly impact the performance of the common model. While much effort has been devoted to helping FL models converge when encountering non-IID data, the imbalance issue has not been sufficiently addressed. In particular, as FL training is executed by exchanging gradients in an encrypted form, the training data is not completely observable to either clients or server, and previous methods for class imbalance do not perform well for FL. Therefore, it is crucial to design new methods for detecting class imbalance in FL and mitigating its impact. In this work, we propose a monitoring scheme that can infer the composition of training data for each FL round, and design a new loss function -- Ratio Loss to mitigate the impact of the imbalance. Our experiments demonstrate the importance of acknowledging class imbalance and taking measures as early as possible in FL training, and the effectiveness of our method in mitigating the impact. Our method is shown to significantly outperform previous methods, while maintaining client privacy.",
        "primary_area": "Machine Learning IV",
        "author": "Lixu Wang; Shichao Xu; Xiao Wang; Qi Zhu",
        "authorids": "",
        "aff": "Northwestern University; Northwestern University; Northwestern University; Northwestern University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17219/17219-13-20713-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10165-addressing-class-imbalance-in-federated-learning/",
        "doi": "10.1609/aaai.v35i11.17219",
        "pdf_size": 1085245
    },
    {
        "id": "07528",
        "title": "Addressing Domain Gap via Content Invariant Representation for Semantic Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "The problem of unsupervised domain adaptation in semantic segmentation is a major challenge for numerous computer vision tasks because acquiring pixel-level labels is time-consuming with expensive human labor. A large gap exists among data distributions in different domains, which will cause severe performance loss when a model trained with synthetic data is generalized to real data. Hence, we propose a novel domain adaptation approach, called Content Invariant Representation Network, to narrow the domain gap between the source (S) and target (T) domains. The previous works developed a network to directly transfer the knowledge from the S to T. On the contrary, the proposed method aims to progressively reduce the gap between S and T on the basis of a Content Invariant Representation (CIR). CIR is an intermediate domain (I) sharing invariant content with S and having similar data distribution to T. Then, an Ancillary Classifier Module (ACM) is designed to focus on pixel-level details and generate attention-aware results. ACM adaptively assigns different weights to pixels according to their domain offsets, thereby reducing local domain gaps. The global domain gap between CIR and T is also narrowed by enforcing local alignments. Last, we perform self-supervised training in the pseudo-labeled target domain to further fit the distribution of the real data. Comprehensive experiments on two domain adaptation tasks, that is, GTAV \u2192 Cityscapes and SYNTHIA \u2192 Cityscapes, clearly demonstrate the superiority of our method compared with state-of-the-art methods.",
        "primary_area": "Machine Learning II",
        "author": "Li Gao; Lefei Zhang; Qian Zhang",
        "authorids": "",
        "aff": "Wuhan University; Wuhan University; Horizon Robotics",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16922/16922-13-20416-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07528-addressing-domain-gap-via-content-invariant-representation-for-semantic-segmentation/",
        "doi": "10.1609/aaai.v35i9.16922",
        "pdf_size": 6062399
    },
    {
        "id": "09489",
        "title": "AdvantageNAS: Efficient Neural Architecture Search with Credit Assignment",
        "track": "main",
        "status": "Poster",
        "abstract": "Neural architecture search (NAS) is an approach for automatically designing a neural network architecture without human effort or expert knowledge. However, the high computational cost of NAS limits its use in commercial applications. Two recent NAS paradigms, namely one-shot and sparse propagation, which reduce the time and space complexities, respectively, provide clues for solving this problem. In this paper, we propose a novel search strategy for one-shot and sparse propagation NAS, namely AdvantageNAS, which further reduces the time complexity of NAS by reducing the number of search iterations. AdvantageNAS is a gradient-based approach that improves the search efficiency by introducing credit assignment in gradient estimation for architecture updates. Experiments on the NAS-Bench-201 and PTB dataset show that AdvantageNAS discovers an architecture with higher performance under a limited time budget compared to existing sparse propagation NAS. To further reveal the reliabilities of AdvantageNAS, we investigate it theoretically and find that it monotonically improves the expected loss and thus converges.",
        "primary_area": "Machine Learning IV",
        "author": "Rei Sato; Jun Sakuma; Youhei Akimoto",
        "authorids": "",
        "aff": "University of Tsukuba RIKEN AIP; University of Tsukuba RIKEN AIP; University of Tsukuba RIKEN AIP",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17143/17143-13-20637-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09489-advantagenas-efficient-neural-architecture-search-with-credit-assignment/",
        "doi": "10.1609/aaai.v35i11.17143",
        "pdf_size": 193738
    },
    {
        "id": "07823",
        "title": "Adversarial Defence by Diversified Simultaneous Training of Deep Ensembles",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning-based classifiers are susceptible to adversarial examples. Existing defence methods are mostly devised on individual classifiers. Recent studies showed that it is viable to increase adversarial robustness by promoting diversity over an ensemble of models. In this paper, we propose adversarial defence by encouraging ensemble diversity on learning high-level feature representations and gradient dispersion in simultaneous training of deep ensemble networks. We perform extensive evaluations under white-box and black-box attacks including transferred examples and adaptive attacks. Our approach achieves a significant gain of up to 52% in adversarial robustness, compared with the baseline and the state-of-the-art method on image benchmarks with complex data scenes. The proposed approach complements the defence paradigm of adversarial training, and can further boost the performance. The source code is available at https://github.com/ALIS-Lab/AAAI2021-PDD.",
        "primary_area": "Machine Learning II",
        "author": "Bo Huang; Zhiwei Ke; Yi Wang; Wei Wang; Linlin Shen; Feng Liu",
        "authorids": "",
        "aff": "Dongguan University of Technology, Dongguan, China; Dongguan University of Technology, Dongguan, China Computer Vision Institute, Shenzhen University, Shenzhen, China; Dongguan University of Technology, Dongguan, China; The University of New South Wales, Sydney, Australia; Computer Vision Institute, Shenzhen University, Shenzhen, China Shenzhen Institute of Artificial Intelligence & Robotics for Society; Computer Vision Institute, Shenzhen University, Shenzhen, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16955/16955-13-20449-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07823-adversarial-defence-by-diversified-simultaneous-training-of-deep-ensembles/",
        "doi": "10.1609/aaai.v35i9.16955",
        "pdf_size": 299555
    },
    {
        "id": "04741",
        "title": "Adversarial Directed Graph Embedding",
        "track": "main",
        "status": "Poster",
        "abstract": "Node representation learning for directed graphs is critically important to facilitate many graph mining tasks. To capture the directed edges between nodes, existing methods mostly learn two embedding vectors for each node, source vector and target vector. However, these methods learn the source and target vectors separately. For the node with very low indegree or outdegree, the corresponding target vector or source vector cannot be effectively learned. In this paper, we propose a novel Directed Graph embedding framework based on Generative Adversarial Network, called DGGAN. The main idea is to use adversarial mechanisms to deploy a discriminator and two generators that jointly learn each node\u2019s source and target vectors. For a given node, the two generators are trained to generate its fake target and source neighbor nodes from the same underlying distribution, and the discriminator aims to distinguish whether a neighbor node is real or fake. The two generators are formulated into a unified framework and could mutually reinforce each other to learn more robust source and target vectors. Extensive experiments show that DGGAN consistently and significantly outperforms existing state-of-the-art methods across multiple graph mining tasks on directed graphs.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Shijie Zhu; Jianxin Li; Hao Peng; Senzhang Wang; Lifang He",
        "authorids": "",
        "aff": "Beijing Advanced Innovation Center for Big Data and Brain Computing, Beihang University, Beijing 100191, China State Key Laboratory of Software Development Environment, Beihang University, Beijing 100191, China; Beijing Advanced Innovation Center for Big Data and Brain Computing, Beihang University, Beijing 100191, China State Key Laboratory of Software Development Environment, Beihang University, Beijing 100191, China; Beijing Advanced Innovation Center for Big Data and Brain Computing, Beihang University, Beijing 100191, China State Key Laboratory of Software Development Environment, Beihang University, Beijing 100191, China; College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing 211106, China; Department of Computer Science and Engineering, Lehigh University, Bethlehem, PA, USA",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16605/16605-13-20099-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04741-adversarial-directed-graph-embedding/",
        "doi": "10.1609/aaai.v35i5.16605",
        "pdf_size": 2061172
    },
    {
        "id": "14248",
        "title": "Adversarial Language Games for Advanced Natural Language Intelligence",
        "track": "main",
        "status": "Poster",
        "abstract": "We study the problem of adversarial language games, in which multiple agents with conflicting goals compete with each other via natural language interactions. While adversarial language games are ubiquitous in human activities, little attention has been devoted to this field in natural language processing. In this work, we propose a challenging adversarial language game called Adversarial Taboo as an example, in which an attacker and a defender compete around a target word. The attacker is tasked with inducing the defender to utter the target word invisible to the defender, while the defender is tasked with detecting the target word before being induced by the attacker. In Adversarial Taboo, a successful attacker and defender need to hide or infer the intention, and induce or defend during conversations. This requires several advanced language abilities, such as adversarial pragmatic reasoning and goal-oriented language interactions in open domain, which will facilitate many downstream NLP tasks. To instantiate the game, we create a game environment and a competition platform. Comprehensive experiments on several baseline attack and defense strategies show promising and interesting results, based on which we discuss some directions for future research.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Yuan Yao; Haoxi Zhong; Zhengyan Zhang; Xu Han; Xiaozhi Wang; Kai Zhang; Chaojun Xiao; Guoyang Zeng; Zhiyuan Liu; Maosong Sun",
        "authorids": "",
        "aff": "Tsinghua University; Tsinghua University; Tsinghua University; Tsinghua University; Tsinghua University; Tsinghua University; Tsinghua University; Tsinghua University; Tsinghua University; Tsinghua University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17676/17676-13-21170-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14248-adversarial-language-games-for-advanced-natural-language-intelligence/",
        "doi": "10.1609/aaai.v35i16.17676",
        "pdf_size": 1816655
    },
    {
        "id": "10156",
        "title": "Adversarial Linear Contextual Bandits with Graph-Structured Side Observations",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper studies the adversarial graphical contextual bandits, a variant of adversarial multi-armed bandits that leverage two categories of the most common side information: contexts and side observations. In this setting, a learning agent repeatedly chooses from a set of K actions after being presented with a d-dimensional context vector. The agent not only incurs and observes the loss of the chosen action, but also observes the losses of its neighboring actions in the observation structures, which are encoded as a series of feedback graphs. This setting models a variety of applications in social networks, where both contexts and graph-structured side observations are available. Two efficient algorithms are developed based on EXP3. Under mild conditions, our analysis shows that for undirected feedback graphs the first algorithm, EXP3-LGC-U, achieves a sub-linear regret with respect to the time horizon and the average independence number of the feedback graphs. A slightly weaker result is presented for the directed graph setting as well. The second algorithm, EXP3-LGC-IX, is developed for a special class of problems, for which the regret is the same for both directed as well as undirected feedback graphs. Numerical tests corroborate the efficiency of proposed algorithms.",
        "primary_area": "Machine Learning IV",
        "author": "Lingda Wang; Bingcong Li; Huozhi Zhou; Georgios B. Giannakis; Lav R. Varshney; Zhizhen Zhao",
        "authorids": "",
        "aff": "University of Illinois at Urbana-Champaign; University of Minnesota - Twin Cities; University of Illinois at Urbana-Champaign; University of Minnesota - Twin Cities; University of Illinois at Urbana-Champaign; University of Illinois at Urbana-Champaign",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17218/17218-13-20712-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10156-adversarial-linear-contextual-bandits-with-graph-structured-side-observations/",
        "doi": "10.1609/aaai.v35i11.17218",
        "pdf_size": 286672
    },
    {
        "id": "14112",
        "title": "Adversarial Meta Sampling for Multilingual Low-Resource Speech Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "Low-resource automatic speech recognition (ASR) is challenging, as the low-resource target language data cannot well train an ASR model. To solve this issue, meta-learning formulates ASR for each source language into many small ASR tasks and meta-learns a model initialization on all tasks from different source languages to access fast adaptation on unseen target languages.  However,  for different source languages, the quantity and difficulty vary greatly because of their different data scales and diverse phonological systems, which leads to task-quantity and task-difficulty imbalance issues and thus a failure of multilingual meta-learning ASR (MML-ASR).   In this work, we solve this problem by developing a novel adversarial meta sampling (AMS) approach to improve MML-ASR. When sampling tasks in MML-ASR, AMS adaptively determines the task sampling probability for each source language. Specifically, for each source language, if the query loss is large, it means that its tasks are not well sampled to train ASR model in terms of its quantity and difficulty and thus should be sampled more frequently for extra learning.  Inspired by this fact, we feed the historical task query loss of all source language domain into a  network to learn a task sampling policy for adversarially increasing the current query loss of MML-ASR. Thus, the learnt task sampling policy can master the learning situation of each language and thus predicts good task sampling probability for each language for more effective learning.  Finally, experiment results on two multilingual datasets show significant performance improvement when applying our AMS on MML-ASR, and also demonstrate the applicability of AMS to other low-resource speech tasks and transfer learning ASR approaches.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Yubei Xiao; Ke Gong; Pan Zhou; Guolin Zheng; Xiaodan Liang; Liang Lin",
        "authorids": "",
        "aff": "Sun Yat-sen University, China; Dark Matter AI Research; Salesforce; Sun Yat-sen University, China; Sun Yat-sen University, China Dark Matter AI Research; Sun Yat-sen University, China Dark Matter AI Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17661/17661-13-21155-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14112-adversarial-meta-sampling-for-multilingual-low-resource-speech-recognition/",
        "doi": "10.1609/aaai.v35i16.17661",
        "pdf_size": 340315
    },
    {
        "id": "10568",
        "title": "Adversarial Partial Multi-Label Learning with Label Disambiguation",
        "track": "main",
        "status": "Poster",
        "abstract": "Partial multi-label learning (PML), which tackles the problem of learning multi-label prediction models from instances with overcomplete noisy annotations, has recently started gaining attention from the research community. In this paper, we propose a novel adversarial learning model, PML-GAN, under a generalized encoder-decoder framework for partial multi-label learning. The PML-GAN model uses a disambiguation network to identify irrelevant labels and uses a multi-label prediction network to map the training instances to their disambiguated label vectors, while deploying a generative adversarial network as an inverse mapping from label vectors to data samples in the input feature space. The learning of the overall model corresponds to a minimax adversarial game, which enhances the correspondence of input features with the output labels in a bi-directional mapping. Extensive experiments are conducted on both synthetic and real-world partial multi-label datasets, while the proposed model demonstrates the state-of-the-art performance.",
        "primary_area": "Machine Learning V",
        "author": "Yan Yan; Yuhong Guo",
        "authorids": "",
        "aff": "Northwestern Polytechnical University; Carleton University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17264/17264-13-20758-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10568-adversarial-partial-multi-label-learning-with-label-disambiguation/",
        "doi": "10.1609/aaai.v35i12.17264",
        "pdf_size": 470833
    },
    {
        "id": "09445",
        "title": "Adversarial Permutation Guided Node Representations for  Link Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "After observing a snapshot of a social network, a link prediction (LP) algorithm identifies node pairs between which new edges will likely materialize in future. Most LP algorithms estimate a score for currently non-neighboring node pairs, and rank them by this score.   Recent LP systems compute this score by comparing dense, low dimensional vector representations of nodes.  Graph neural networks (GNNs), in particular graph convolutional networks (GCNs), are popular examples.  For two nodes to be meaningfully compared, their embeddings should be indifferent to reordering of their neighbors.  GNNs typically use simple, symmetric set aggregators to ensure this property, but this design decision has been shown to produce representations with limited expressive power.  Sequence encoders are more expressive, but are permutation sensitive by design.  Recent efforts to overcome this dilemma turn out to be unsatisfactory for LP tasks. In response, we propose PermGNN, which aggregates neighbor features using a recurrent, order-sensitive aggregator and directly minimizes an LP loss while it is `attacked' by adversarial generator of neighbor permutations.  PermGNN has superior expressive power compared to earlier GNNs.  Next, we devise an optimization framework to map PermGNN's node embeddings to a suitable locality-sensitive hash, which speeds up reporting the top-K most likely edges for the LP task. Our experiments on diverse datasets show that PermGNN outperforms several state-of-the-art link predictors by a significant margin, and can predict the most likely edges fast.",
        "primary_area": "Machine Learning IV",
        "author": "Indradyumna Roy; Abir De; Soumen Chakrabarti",
        "authorids": "",
        "aff": "IIT Bombay; IIT Bombay; IIT Bombay",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17138/17138-13-20632-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09445-adversarial-permutation-guided-node-representations-for-link-prediction/",
        "doi": "10.1609/aaai.v35i11.17138",
        "pdf_size": 272757
    },
    {
        "id": "01940",
        "title": "Adversarial Pose Regression Network for Pose-Invariant Face Recognitions",
        "track": "main",
        "status": "Poster",
        "abstract": "Face recognition has achieved significant progress in recent years. However, the large pose variation between face images remains a challenge in face recognition. We observe that the pose variation in the hidden feature maps is one of the most critical factors to hinder the representations from being pose-invariant. Based on the observation, we propose an Adversarial Pose Regression Network (APRN) to extract pose-invariant identity representations by disentangling their pose variation in hidden feature maps. To model the pose discriminator in APRN as a regression task in its 3D space, we also propose an Adversarial Regression Loss Function and extend the adversarial learning from classification problems to regression problems in this paper. Our APRN is a plug-and-play structure that can be embedded in other state-of-the-art face recognition algorithms to improve their performance additionally. The experiments show that the proposed APRN consistently and significantly boosts the performance of baseline networks without extra computational costs in the inference phase. APRN achieves comparable or even superior to the state-of-the-art on CFP, Multi-PIE, IJB-A and MegaFace datasets. The code will be released, hoping to nourish our proposals to other computer vision fields",
        "primary_area": "Computer Vision II",
        "author": "Pengyu Li; Biao Wang; Lei Zhang",
        "authorids": "",
        "aff": "Alibaba Group; Alibaba Group; The Hong Kong Polytechnic University Alibaba Group",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16289/16289-13-19783-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01940-adversarial-pose-regression-network-for-pose-invariant-face-recognitions/",
        "doi": "10.1609/aaai.v35i3.16289",
        "pdf_size": 3171040
    },
    {
        "id": "03145",
        "title": "Adversarial Robustness through Disentangled Representations",
        "track": "main",
        "status": "Poster",
        "abstract": "Despite the remarkable empirical performance of deep learning models, their vulnerability to adversarial examples has been revealed in many studies. They are prone to make a susceptible prediction to the input with imperceptible adversarial perturbation. Although recent works have remarkably improved the model's robustness under the adversarial training strategy, an evident gap between the natural accuracy and adversarial robustness inevitably exists. In order to mitigate this problem, in this paper, we assume that the robust and non-robust representations are two basic ingredients entangled in the integral representation. For achieving adversarial robustness, the robust representations of natural and adversarial examples should be disentangled from the non-robust part and the alignment of the robust representations can bridge the gap between accuracy and robustness. Inspired by this motivation, we propose a novel defense method called Deep Robust Representation Disentanglement Network (DRRDN). Specifically, DRRDN employs a disentangler to extract and align the robust representations from both adversarial and natural examples. Theoretical analysis guarantees the mitigation of the trade-off between robustness and accuracy with good disentanglement and alignment performance. Experimental results on benchmark datasets finally demonstrate the empirical superiority of our method.",
        "primary_area": "Computer Vision III",
        "author": "Shuo Yang; Tianyu Guo; Yunhe Wang; Chang Xu",
        "authorids": "",
        "aff": "University of Sydney; Peking University; Huawei Noah's Ark Lab; University of Sydney",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16424/16424-13-19918-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03145-adversarial-robustness-through-disentangled-representations/",
        "doi": "10.1609/aaai.v35i4.16424",
        "pdf_size": 459095
    },
    {
        "id": "02674",
        "title": "Adversarial Training Reduces Information and Improves Transferability",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent results show that features of adversarially trained networks for classification, in addition to being robust, enable desirable properties such as invertibility.  The latter property may seem counter-intuitive as it is widely accepted by the community that classification models should only capture the minimal information (features) required for the task.  Motivated by this discrepancy, we investigate the dual relationship between Adversarial Training and Information Theory. We show that the Adversarial Training can improve linear transferability to new tasks, from which arises a new trade-off between transferability of representations and accuracy on the source task. We validate our results employing robust networks trained on CIFAR-10, CIFAR-100 and ImageNet on several datasets.  Moreover, we show that Adversarial Training reduces Fisher information of representations about the input and of the weights about the task, and we provide a theoretical argument which explains the invertibility of deterministic networks without violating the principle of minimality. Finally, we leverage our theoretical insights to remarkably improve the quality of reconstructed images through inversion.",
        "primary_area": "Computer Vision II",
        "author": "Matteo Terzi; Alessandro Achille; Marco Maggipinto; Gian Antonio Susto",
        "authorids": "",
        "aff": "University of Padova; AWS; University of Padova; University of Padova",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16371/16371-13-19865-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02674-adversarial-training-reduces-information-and-improves-transferability/",
        "doi": "10.1609/aaai.v35i3.16371",
        "pdf_size": 1489042
    },
    {
        "id": "07367",
        "title": "Adversarial Training and Provable Robustness: A Tale of Two Objectives",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a principled framework that combines adversarial training and provable robustness verification for training certifiably robust neural networks. We formulate the training problem as a joint optimization problem with both empirical and provable robustness objectives and develop a novel gradient-descent technique that can eliminate bias in stochastic multi-gradients. We perform both theoretical analysis on the convergence of the proposed technique and experimental comparison with state-of-the-arts. Results on MNIST and CIFAR-10 show that our method can consistently match or outperform prior approaches for provable l\u221e robustness. Notably, we achieve 6.60% verified test error on MNIST at \u03b5 = 0.3, and 66.57% on CIFAR-10 with \u03b5 = 8/255.",
        "primary_area": "Machine Learning I",
        "author": "Jiameng Fan; Wenchao Li",
        "authorids": "",
        "aff": "Boston University; Boston University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16904/16904-13-20398-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07367-adversarial-training-and-provable-robustness-a-tale-of-two-objectives/",
        "doi": "10.1609/aaai.v35i8.16904",
        "pdf_size": 1109220
    },
    {
        "id": "13997",
        "title": "Adversarial Training with Fast Gradient Projection Method against Synonym Substitution Based Text Attacks",
        "track": "main",
        "status": "Poster",
        "abstract": "Adversarial training is the most empirically successful approach in improving the robustness of deep neural networks for image classification. For text classification, however, existing synonym substitution based adversarial attacks are effective but not very efficient to be incorporated into practical text adversarial training. Gradient-based attacks, which are very efficient for images, are hard to be implemented for synonym substitution based text attacks due to the lexical, grammatical and semantic constraints and the discrete text input space. Thereby, we propose a fast text adversarial attack method called Fast Gradient Projection Method (FGPM) based on synonym substitution, which is about 20 times faster than existing text attack methods and could achieve similar attack performance. We then incorporate FGPM with adversarial training and propose a text defense method called Adversarial Training with FGPM enhanced by Logit pairing (ATFL). Experiments show that ATFL could significantly improve the model robustness and block the transferability of adversarial examples.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Xiaosen Wang; Yichen Yang; Yihe Deng; Kun He",
        "authorids": "",
        "aff": "Huazhong University of Science and Technology; Huazhong University of Science and Technology; University of California, Los Angeles; Huazhong University of Science and Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17648/17648-13-21142-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13997-adversarial-training-with-fast-gradient-projection-method-against-synonym-substitution-based-text-attacks/",
        "doi": "10.1609/aaai.v35i16.17648",
        "pdf_size": 226317
    },
    {
        "id": "02683",
        "title": "Adversarial Turing Patterns from Cellular Automata",
        "track": "main",
        "status": "Poster",
        "abstract": "State-of-the-art deep classifiers are intriguingly vulnerable to universal adversarial perturbations: single disturbances of small magnitude that lead to misclassification of most inputs. This phenomena may potentially result in a serious security problem. Despite the extensive research in this area, there is a lack of theoretical understanding of the structure of these perturbations. In image domain, there is a certain visual similarity between patterns, that represent these perturbations, and classical Turing patterns, which appear as a solution of non-linear partial differential equations and are underlying concept of many processes in nature. In this paper, we provide a theoretical bridge between these two different theories, by mapping a simplified algorithm for crafting universal perturbations to (inhomogeneous) cellular automata, the latter is known to generate Turing patterns. Furthermore, we propose to use Turing patterns, generated by cellular automata, as universal perturbations, and experimentally show that they significantly degrade the performance of deep learning models. We found this method to be a fast and efficient way to create a data-agnostic quasi-imperceptible perturbation in the black-box scenario. The source code is available at https://github.com/NurislamT/advTuring.",
        "primary_area": "Computer Vision II",
        "author": "Nurislam Tursynbek; Ilya Vilkoviskiy; Maria Sindeeva; Ivan Oseledets",
        "authorids": "",
        "aff": "Skolkovo Institute of Science and Technoogy; Skolkovo Institute of Science and Technology; Skolkovo Institute of Science and Technology; Skolkovo Institute of Science and Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16372/16372-13-19866-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02683-adversarial-turing-patterns-from-cellular-automata/",
        "doi": "10.1609/aaai.v35i3.16372",
        "pdf_size": 819956
    },
    {
        "id": "09073",
        "title": "Advice-Guided Reinforcement Learning in a non-Markovian Environment",
        "track": "main",
        "status": "Poster",
        "abstract": "We study a class of reinforcement learning tasks in which the agent receives its reward for complex, temporally-extended behaviors sparsely. For such tasks, the problem is how to augment the state-space so as to make the reward function Markovian in an efficient way. While some existing solutions assume that the reward function is explicitly provided to the learning algorithm (e.g., in the form of a reward machine), the others learn the reward function from the interactions with the environment, assuming no prior knowledge provided by the user. In this paper, we generalize both approaches and enable the user to give advice to the agent, representing the user\u2019s best knowledge about the reward function, potentially fragmented, partial, or even incorrect. We formalize advice as a set of DFAs and present a reinforcement learning algorithm that takes advantage of such advice, with optimal con- vergence guarantee. The experiments show that using well- chosen advice can reduce the number of training steps needed for convergence to optimal policy, and can decrease the computation time to learn the reward function by up to two orders of magnitude.",
        "primary_area": "Machine Learning III",
        "author": "Daniel Neider; Jean-Raphael Gaglione; Ivan Gavran; Ufuk Topcu; Bo Wu; Zhe Xu",
        "authorids": "",
        "aff": "Max Planck Institute for Software Systems; Ecole Polytechnique; Max Planck Institute for Software Systems; University of Texas at Austin; University of Texas at Austin; Arizona State University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17096/17096-13-20590-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09073-advice-guided-reinforcement-learning-in-a-non-markovian-environment/",
        "doi": "10.1609/aaai.v35i10.17096",
        "pdf_size": 3903476
    },
    {
        "id": "11487",
        "title": "Agent Incentives: A Causal Perspective",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a framework for analysing agent incentives using causal influence diagrams. We establish that a well-known criterion for value of information is complete. We propose a new graphical criterion for value of control, establishing its soundness and completeness. We also introduce two new concepts for incentive analysis: response incentives indicate which changes in the environment affect an optimal decision, while instrumental control incentives establish whether an agent can influence its utility via a variable X. For both new concepts, we provide sound and complete graphical criteria. We show by example how these results can help with evaluating the safety and fairness of an AI system",
        "primary_area": "Philosophy and Ethics of AI",
        "author": "Tom Everitt; Ryan Carey; Eric D. Langlois; Pedro A. Ortega; Shane Legg",
        "authorids": "",
        "aff": "DeepMind; University of Oxford; DeepMind; University of Toronto; Vector Institute; DeepMind; DeepMind",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17368/17368-13-20862-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11487-agent-incentives-a-causal-perspective/",
        "doi": "10.1609/aaai.v35i13.17368",
        "pdf_size": 166116
    },
    {
        "id": "02225",
        "title": "Aggregated Multi-GANs for Controlled 3D Human Motion Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "Human motion prediction from historical pose sequence is at the core of many applications in machine intelligence. However, in current state-of-the-art methods, the predicted future motion is confined within the same activity. One can neither generate predictions that differ from the current activity, nor manipulate the body parts to explore various future possibilities. Undoubtedly, this greatly limits the usefulness and applicability of motion prediction. In this paper, we propose a generalization of the human motion prediction task in which control parameters can be readily incorporated to adjust the forecasted motion. Our method is compelling in that it enables manipulable motion prediction across activity types and allows customization of the human movement in a variety of fine-grained ways. To this aim, a simple yet effective composite GAN structure, consisting of local GANs for different body parts and aggregated via a global GAN is presented. The local GANs game in lower dimensions, while the global GAN adjusts in high dimensional space to avoid mode collapse. Extensive experiments show that our method outperforms state-of-the-art. The codes are available at https://github.com/herolvkd/AM-GAN.",
        "primary_area": "Computer Vision II",
        "author": "Zhenguang Liu; Kedi Lyu; Shuang Wu; Haipeng Chen; Yanbin Hao; Shouling Ji",
        "authorids": "",
        "aff": "Zhejiang Gongshang University; Jilin University; Nanyang Technological University; Jilin University; University of Science and Technology of China; Zhejiang University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16321/16321-13-19815-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02225-aggregated-multi-gans-for-controlled-3d-human-motion-prediction/",
        "doi": "10.1609/aaai.v35i3.16321",
        "pdf_size": 903731
    },
    {
        "id": "05456",
        "title": "Aggregating Binary Judgments Ranked by Accuracy",
        "track": "main",
        "status": "Poster",
        "abstract": "We revisit the fundamental problem of predicting a binary ground truth based on independent binary judgments provided by experts. When the accuracy levels of the experts are known, the problem can be solved easily through maximum likelihood estimation. We consider, however, a setting in which we are given only a ranking of the experts by their accuracy. Motivated by the worst-case approach to handle the missing information, we consider three objective functions and design efficient algorithms for optimizing them. In particular, the recently popular distortion objective leads to an intuitive new rule. We show that our algorithms perform well empirically using real and synthetic data in collaborative filtering and political prediction domains.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Daniel Halpern; Gregory Kehne; Dominik Peters; Ariel D. Procaccia; Nisarg Shah; Piotr Skowron",
        "authorids": "",
        "aff": "Harvard University; Carnegie Mellon University; Harvard University; Harvard University; University of Toronto; University of Warsaw",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16687/16687-13-20181-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05456-aggregating-binary-judgments-ranked-by-accuracy/",
        "doi": "10.1609/aaai.v35i6.16687",
        "pdf_size": 158387
    },
    {
        "id": "07466",
        "title": "Agreement-Discrepancy-Selection: Active Learning with Progressive Distribution Alignment",
        "track": "main",
        "status": "Poster",
        "abstract": "In active learning, the ignorance of aligning unlabeled samples' distribution with that of labeled samples hinders the model trained upon labeled samples from selecting informative unlabeled samples. In this paper, we propose an agreement-discrepancy-selection (ADS) approach, and target at unifying distribution alignment with sample selection by introducing adversarial classifiers to the convolutional neural network (CNN). Minimizing classifiers' prediction discrepancy (maximizing prediction agreement) drives learning CNN features to reduce the distribution bias of labeled and unlabeled samples, while maximizing classifiers' discrepancy highlights informative samples. Iterative optimization of agreement and discrepancy loss calibrated with an entropy function drives aligning sample distributions in a progressive fashion for effective active learning. Experiments on image classification and object detection tasks demonstrate that ADS is task-agnostic, while significantly outperforms the previous methods when the labeled sets are small.",
        "primary_area": "Machine Learning I",
        "author": "Mengying Fu; Tianning Yuan; Fang Wan; Songcen Xu; Qixiang Ye",
        "authorids": "",
        "aff": "University of Chinese Academy of Sciences; University of Chinese Academy of Sciences; University of Chinese Academy of Sciences; Noah\u2019s Ark Lab, Huawei Technologies Co., Ltd.; University of Chinese Academy of Sciences, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16915/16915-13-20409-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07466-agreement-discrepancy-selection-active-learning-with-progressive-distribution-alignment/",
        "doi": "10.1609/aaai.v35i8.16915",
        "pdf_size": 2501345
    },
    {
        "id": "06235",
        "title": "Algebra of Modular Systems: Containment and Equivalence",
        "track": "main",
        "status": "Poster",
        "abstract": "The Algebra of Modular System is a KR formalism that allows for combinations of modules written in multiple languages. Informally, a module represents a piece of knowledge. It can be given by a knowledge base, be an agent, an ASP, ILP, CP program, etc. Formally, a module is a class of structures over the same vocabulary. Modules are combined declaratively, using, essentially, operations of Codd's relational algebra.  In this paper, we address the problem of checking modular system containment, which we relate to a homomorphism problem. We prove that, for a large class of modular systems, the containment problem (and thus equivalence) is in the complexity class NP, and therefore is solvable by, e.g.,  SAT solvers. We discuss  conditions under which  the problem is polynomial time solvable.",
        "primary_area": "Knowledge Representation and Reasoning",
        "author": "Andrei Bulatov; Eugenia Ternovska",
        "authorids": "",
        "aff": "Simon Fraser University; Simon Fraser University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16775/16775-13-20269-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06235-algebra-of-modular-systems-containment-and-equivalence/",
        "doi": "10.1609/aaai.v35i7.16775",
        "pdf_size": 155870
    },
    {
        "id": "04932",
        "title": "Aligning Artificial Neural Networks and Ontologies towards Explainable AI",
        "track": "main",
        "status": "Poster",
        "abstract": "Neural networks have been the key to solve a variety of different problems. However, neural network models are still regarded as black boxes, since they do not provide any human-interpretable evidence as to why they output a certain result. We address this issue by leveraging on ontologies and building small classifiers that map a neural network model's internal state to concepts from an ontology, enabling the generation of symbolic justifications for the output of neural network models. Using an image classification problem as testing ground, we discuss how to map the internal state of a neural network to the concepts of an ontology, examine whether the results obtained by the established mappings match our understanding of the mapped concepts, and analyze the justifications obtained through this method.",
        "primary_area": "Neuro-Symbolic AI",
        "author": "Manuel de Sousa Ribeiro; Jo\u00e3o Leite",
        "authorids": "",
        "aff": "NOVA University Lisbon; NOVA University Lisbon",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16626/16626-13-20120-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04932-aligning-artificial-neural-networks-and-ontologies-towards-explainable-ai/",
        "doi": "10.1609/aaai.v35i6.16626",
        "pdf_size": 553112
    },
    {
        "id": "05355",
        "title": "Almost Envy-freeness, Envy-rank, and Nash Social Welfare Matchings",
        "track": "main",
        "status": "Poster",
        "abstract": "Envy-freeness up to one good (EF1) and envy-freeness up to any good (EFX) are two well-known extensions of envy-freeness for the case of indivisible items. It is shown that EF1 can always be guaranteed for agents with subadditive valuations. In sharp contrast, it is unknown whether or not an EFX allocation always exists, even for four agents and additive valuations. In addition, the best approximation guarantee for EFX is (\u03c6 \u2212 1) \u2243 0.61 by Amanitidis et al.. In order to find a middle ground to bridge this gap, in this paper we suggest another fairness criterion, namely envy-freeness up to a random good or EFR, which is weaker than EFX, yet stronger than EF1. For this notion, we provide a polynomial-time 0.73-approximation allocation algorithm. For our algorithm we introduce Nash Social Welfare Matching which makes a connection between Nash Social Welfare and envy freeness.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Alireza Farhadi; MohammadTaghi Hajiaghayi; Mohamad Latifian; Masoud Seddighin; Hadi Yami",
        "authorids": "",
        "aff": "University of Maryland; University of Maryland; University of Toronto; Sharif University of Technology; Microsoft",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16675/16675-13-20169-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05355-almost-envy-freeness-envy-rank-and-nash-social-welfare-matchings/",
        "doi": "10.1609/aaai.v35i6.16675",
        "pdf_size": 163833
    },
    {
        "id": "07349",
        "title": "Almost Linear Time Density Level Set Estimation via DBSCAN",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work we focus on designing a fast algorithm for lambda-density level set estimation via DBSCAN clustering. Previous work (Jiang ICML\u201917, and Jang and Jiang ICML\u201919) shows that under some natural assumptions DBSCAN and its variant DBSCAN++ can be used to estimate the lambda-density level set with near-optimal Hausdorff distance, i.e., with rate O~(n^{-1/(2 * beta+D)}). However, to achieve this near-optimal rate, the current fastest DBSCAN algorithm needs near quadratic running time. This running time is not very practical for giant datasets. Usually when we are working with very large datasets we desire linear or almost linear time algorithms. With this motivation, in this work, we present a modified DBSCAN algorithm with near optimal Hausdorff distance for density level set estimation with O~(n) running time. In our empirical study, we show that our algorithm provides significant speedup over the previous algorithms, while achieving comparable solution quality.",
        "primary_area": "Machine Learning I",
        "author": "Hossein Esfandiari; Vahab Mirrokni; Peilin Zhong",
        "authorids": "",
        "aff": "Google Research; Google Research; Columbia University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16902/16902-13-20396-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07349-almost-linear-time-density-level-set-estimation-via-dbscan/",
        "doi": "10.1609/aaai.v35i8.16902",
        "pdf_size": 272105
    },
    {
        "id": "00634",
        "title": "Alternative Baselines for Low-Shot 3D Medical Image Segmentation\u2014An Atlas Perspective",
        "track": "main",
        "status": "Poster",
        "abstract": "Low-shot (one/few-shot) segmentation has attracted increasing attention as it works well with limited annotation. State-of-the-art low-shot segmentation methods on natural images usually focus on implicit representation learning for each novel class, such as learning prototypes, deriving guidance features via masked average pooling, and segmenting using cosine similarity in feature space. We argue that low-shot segmentation on medical images should step further to explicitly learn dense correspondences between images to utilize the anatomical similarity. The core ideas are inspired by the classical practice of multi-atlas segmentation, where the indispensable parts of atlas-based segmentation, i.e., registration, label propagation, and label fusion are unified into a single framework in our work. Specifically, we propose two alternative baselines, i.e., the Siamese-Baseline and Individual-Difference-Aware Baseline, where the former is targeted at anatomically stable structures (such as brain tissues), and the latter possesses a strong generalization ability to organs suffering large morphological variations (such as abdominal organs). In summary, this work sets up a benchmark for low-shot 3D medical image segmentation and sheds light on further understanding of atlas-based few-shot segmentation.",
        "primary_area": "Application Domains",
        "author": "Shuxin Wang; Shilei Cao; Dong Wei; Cong Xie; Kai Ma; Liansheng Wang; Deyu Meng; Yefeng Zheng",
        "authorids": "",
        "aff": "Department of Computer Science, Xiamen University, Xiamen, China Tencent Jarvis Lab, Shenzhen, China; Tencent Jarvis Lab, Shenzhen, China; Tencent Jarvis Lab, Shenzhen, China; Department of Computer Science, Xiamen University, Xiamen, China Tencent Jarvis Lab, Shenzhen, China; Tencent Jarvis Lab, Shenzhen, China; Department of Computer Science, Xiamen University, Xiamen, China Department of Digestive Diseases, School of Medicine, Xiamen University, Xiamen, China; School of Mathematics and Statistics, Xi\u2019an Jiaotong University, Xi\u2019an, China; Tencent Jarvis Lab, Shenzhen, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16143/16143-13-19637-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00634-alternative-baselines-for-low-shot-3d-medical-image-segmentation-an-atlas-perspective/",
        "doi": "10.1609/aaai.v35i1.16143",
        "pdf_size": 300877
    },
    {
        "id": "10691",
        "title": "Amata: An Annealing Mechanism for Adversarial Training Acceleration",
        "track": "main",
        "status": "Poster",
        "abstract": "Despite the empirical success in various domains, it has been revealed that deep neural networks are vulnerable to maliciously perturbed input data that much degrade their performance. This is known as adversarial attacks. To counter adversarial attacks, adversarial training formulated as a form of robust optimization has been demonstrated to be effective. However, conducting adversarial training brings much computational overhead compared with standard training. In order to reduce the computational cost, we propose an annealing mechanism, Amata, to reduce the overhead associated with adversarial training. The proposed Amata is provably convergent, well-motivated from the lens of optimal control theory and can be combined with existing acceleration methods to further enhance performance. It is demonstrated that on standard datasets, Amata can achieve similar or better robustness with around 1/3 to 1/2 the computational time compared with traditional methods. In addition, Amata can be incorporated into  other adversarial training acceleration algorithms (e.g. YOPO, Free, Fast, and ATTA), which leads to further reduction in computational time on large-scale problems.",
        "primary_area": "Machine Learning V",
        "author": "Nanyang Ye; Qianxiao Li; Xiao-Yun Zhou; Zhanxing Zhu",
        "authorids": "",
        "aff": "Shanghai Jiao Tong University; National University of Singapore; The Hamlyn Centre for Robotic Surgery, Imperial College London; Peking University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17278/17278-13-20772-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10691-amata-an-annealing-mechanism-for-adversarial-training-acceleration/",
        "doi": "10.1609/aaai.v35i12.17278",
        "pdf_size": 289991
    },
    {
        "id": "11516",
        "title": "Amnesiac Machine Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "The Right to be Forgotten is part of the recently enacted General Data Protection Regulation (GDPR) law that affects any data holder that has data on European Union residents. It gives EU residents the ability to request deletion of their personal data, including training records used to train machine learning models. Unfortunately, Deep Neural Network models are vulnerable to information leaking attacks such as model inversion attacks which extract class information from a trained model and membership inference attacks which determine the presence of an example in a model's training data. If a malicious party can mount an attack and learn private information that was meant to be removed, then it implies that the model owner has not properly protected their user's rights and their models may not be compliant with the GDPR law. In this paper, we present two efficient methods that address this question of how a model owner or data holder may delete personal data from models in such a way that they may not be vulnerable to model inversion and membership inference attacks while maintaining model efficacy. We start by presenting a real-world threat model that shows that simply removing training data is insufficient to protect users. We follow that up with two data removal methods, namely Unlearning and Amnesiac Unlearning, that enable model owners to protect themselves against such attacks while being compliant with regulations. We provide extensive empirical analysis that show that these methods are indeed efficient, safe to apply, effectively remove learned information about sensitive data from trained models while maintaining model efficacy.",
        "primary_area": "Philosophy and Ethics of AI",
        "author": "Laura Graves; Vineel Nagisetty; Vijay Ganesh",
        "authorids": "",
        "aff": "University of Waterloo; University of Waterloo; University of Waterloo",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17371/17371-13-20865-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11516-amnesiac-machine-learning/",
        "doi": "10.1609/aaai.v35i13.17371",
        "pdf_size": 1607990
    },
    {
        "id": "02995",
        "title": "Amodal Segmentation Based on Visible Region Segmentation and Shape Prior",
        "track": "main",
        "status": "Poster",
        "abstract": "Almost all existing amodal segmentation methods make the inferences of occluded regions by using features corresponding to the whole image. This is against the human's amodal perception, where human uses the visible part and the shape prior knowledge of the target to infer the occluded region. To mimic the behavior of human and solve the ambiguity in the learning, we propose a framework, it firstly estimates a coarse visible mask and a coarse amodal mask. Then based on the coarse prediction, our model infers the amodal mask by concentrating on the visible region and utilizing the shape prior in the memory. In this way, features corresponding to background and occlusion can be suppressed for amodal mask estimation. Consequently, the amodal mask would not be affected by what the occlusion is given the same visible regions. The leverage of shape prior makes the amodal mask estimation more robust and reasonable. Our proposed model is evaluated on three datasets. Experiments show that our proposed model outperforms existing state-of-the-art methods. The visualization of shape prior indicates that the category-specific feature in the codebook has certain interpretability. The code is available at https://github.com/YutingXiao/Amodal-Segmentation-Based-on-Visible-Region-Segmentation-and-Shape-Prior.",
        "primary_area": "Computer Vision III",
        "author": "Yuting Xiao; Yanyu Xu; Ziming Zhong; Weixin Luo; Jiawei Li; Shenghua Gao",
        "authorids": "",
        "aff": "ShanghaiTech University Shanghai Engineering Research Center of Intelligent Vision and Imaging; Institute of High Performance Computing, A*Star; ShanghaiTech University Shanghai Engineering Research Center of Intelligent Vision and Imaging; ShanghaiTech University Shanghai Engineering Research Center of Intelligent Vision and Imaging; Alibaba Group; ShanghaiTech University Shanghai Engineering Research Center of Intelligent Vision and Imaging",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16407/16407-13-19901-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02995-amodal-segmentation-based-on-visible-region-segmentation-and-shape-prior/",
        "doi": "10.1609/aaai.v35i4.16407",
        "pdf_size": 1310081
    },
    {
        "id": "14630",
        "title": "An Adaptive Hybrid Framework for Cross-domain Aspect-based Sentiment Analysis",
        "track": "main",
        "status": "Poster",
        "abstract": "Cross-domain aspect-based sentiment analysis aims to utilize the useful knowledge in a source domain to extract aspect terms and predict their sentiment polarities in a target domain. Recently, methods based on adversarial training have been applied to this task and achieved promising results. In such methods, both the source and target data are utilized to learn domain-invariant features through deceiving a domain discriminator. However, the task classifier is only trained on the source data, which causes the aspect and sentiment information lying in the target data can not be exploited by the task classifier. In this paper, we propose an Adaptive Hybrid Framework (AHF) for cross-domain aspect-based sentiment analysis. We integrate pseudo-label based semi-supervised learning and adversarial training in a unified network. Thus the target data can be used not only to align the features via the training of domain discriminator, but also to refine the task classifier. Furthermore, we design an adaptive mean teacher as the semi-supervised part of our network, which can mitigate the effects of noisy pseudo labels generated on the target data. We conduct experiments on four public datasets and the experimental results show that our framework significantly outperforms the state-of-the-art methods.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Yan Zhou; Fuqing Zhu; Pu Song; Jizhong Han; Tao Guo; Songlin Hu",
        "authorids": "",
        "aff": "Institute of Information Engineering, Chinese Academy of Sciences; Institute of Information Engineering, Chinese Academy of Sciences; Institute of Information Engineering, Chinese Academy of Sciences School of Cyber Security, University of Chinese Academy of Sciences; Institute of Information Engineering, Chinese Academy of Sciences; Institute of Information Engineering, Chinese Academy of Sciences; Institute of Information Engineering, Chinese Academy of Sciences School of Cyber Security, University of Chinese Academy of Sciences",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17719/17719-13-21213-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14630-an-adaptive-hybrid-framework-for-cross-domain-aspect-based-sentiment-analysis/",
        "doi": "10.1609/aaai.v35i16.17719",
        "pdf_size": 772149
    },
    {
        "id": "05448",
        "title": "An Analysis of Approval-Based Committee Rules for 2D-Euclidean Elections",
        "track": "main",
        "status": "Poster",
        "abstract": "We study approval-based committee elections for the case where the voters' preferences come from a 2D-Euclidean model. We consider two main issues: First, we ask for the complexity of computing election results. Second, we evaluate election outcomes experimentally, following the visualization technique of Elkind et al., (AAAI-2017).  Regarding the first issue, we find that many NP-hard rules remain intractable for 2D-Euclidean elections. For the second one, we observe that the behavior and nature of many rules strongly depends on the exact protocol for choosing the approved candidates.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Micha\u0142 T. Godziszewski; Pawe\u0142 Batko; Piotr Skowron; Piotr Faliszewski",
        "authorids": "",
        "aff": "University of Warsaw; AGH University of Science and Technology; University of Warsaw; AGH University of Science and Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16686/16686-13-20180-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05448-an-analysis-of-approval-based-committee-rules-for-2d-euclidean-elections/",
        "doi": "10.1609/aaai.v35i6.16686",
        "pdf_size": 2035597
    },
    {
        "id": "11193",
        "title": "An Efficient Algorithm for Deep Stochastic Contextual Bandits",
        "track": "main",
        "status": "Poster",
        "abstract": "In stochastic contextual bandit (SCB) problems, an agent selects an action based on certain observed context to maximize the cumulative reward over iterations. Recently there have been a few studies using a deep neural network (DNN) to predict the expected reward for an action, and the DNN is trained by a stochastic gradient based method. However, convergence analysis has been greatly ignored to examine whether and where these methods converge. In this work, we formulate the SCB that uses a DNN reward function as a non-convex stochastic optimization problem, and design a stage-wised stochastic gradient descent algorithm to optimize the problem and determine the action policy. We prove that with high probability, the action sequence chosen by our algorithm converges to a greedy action policy respecting a local optimal reward function. Extensive experiments have been performed to demonstrate the effectiveness and efficiency of the proposed algorithm on multiple real-world datasets.",
        "primary_area": "Machine Learning V",
        "author": "Tan Zhu; Guannan Liang; Chunjiang Zhu; Haining Li; Jinbo Bi",
        "authorids": "",
        "aff": "University of Connecticut; University of Connecticut; University of Connecticut; University of Connecticut; University of Connecticut",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17335/17335-13-20829-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11193-an-efficient-algorithm-for-deep-stochastic-contextual-bandits/",
        "doi": "10.1609/aaai.v35i12.17335",
        "pdf_size": 733960
    },
    {
        "id": "13315",
        "title": "An Efficient Transformer Decoder with Compressed Sub-layers",
        "track": "main",
        "status": "Poster",
        "abstract": "The large attention-based encoder-decoder network (Transformer) has become prevailing recently due to its effectiveness. But the high computation complexity of its decoder raises the inefficiency issue. By examining the mathematic formulation of the decoder, we show that under some mild conditions, the architecture could be simplified by compressing its sub-layers, the basic building block of Transformer, and achieves a higher parallelism. We thereby propose Compressed Attention Network, whose decoder layer consists of only one sub-layer instead of three. Extensive experiments on 14 WMT machine translation tasks show that our model is 1.42x faster with performance on par with a strong baseline. This strong baseline is already 2x faster than the widely used standard baseline without loss in performance.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Yanyang Li; Ye Lin; Tong Xiao; Jingbo Zhu",
        "authorids": "",
        "aff": "Northeastern University, China; Northeastern University, China; Northeastern University, China; Northeastern University, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17572/17572-13-21066-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13315-an-efficient-transformer-decoder-with-compressed-sub-layers/",
        "doi": "10.1609/aaai.v35i15.17572",
        "pdf_size": 238842
    },
    {
        "id": "06653",
        "title": "An Enhanced Advising Model in Teacher-Student Framework using State Categorization",
        "track": "main",
        "status": "Poster",
        "abstract": "The teacher-student framework aims to improve the sample efficiency of RL algorithms by deploying an advising mechanism in which a teacher helps a student by guiding its exploration. Prior work in this field has considered an advising mechanism where the teacher advises the student about the optimal action to take in a given state. However, real-world teachers can leverage domain expertise to provide more informative signals. Using this insight, we propose to extend the current advising framework wherein the teacher would provide not only the optimal action but also a qualitative assessment of the state. We introduce a novel architecture, namely Advice Replay Memory (ARM), to effectively reuse the advice provided by the teacher. We demonstrate the robustness of our approach by showcasing our experiments on multiple Atari 2600 games using a fixed set of hyper-parameters. Additionally, we show that a student taking help even from a sub-optimal teacher can achieve significant performance boosts and eventually outperform the teacher. Our approach outperforms the baselines even when provided with comparatively suboptimal teachers and an advising budget, which is smaller by orders of magnitude. The contributions of our paper are 4-fold (a) effectively leveraging a teacher's knowledge by richer advising (b) introduction of ARM to effectively reuse the advice throughout learning (c) ability to achieve significant performance boost even with a coarse state categorization (d) enabling the student to outperform the teacher.",
        "primary_area": "Machine Learning I",
        "author": "Daksh Anand; Vaibhav Gupta; Praveen Paruchuri; Balaraman Ravindran",
        "authorids": "",
        "aff": "International Institute of Information Technology, Hyderabad; International Institute of Information Technology, Hyderabad; International Institute of Information Technology, Hyderabad; Indian Institute of Technology, Madras",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16823/16823-13-20317-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06653-an-enhanced-advising-model-in-teacher-student-framework-using-state-categorization/",
        "doi": "10.1609/aaai.v35i8.16823",
        "pdf_size": 1038005
    },
    {
        "id": "03707",
        "title": "An Improved Upper Bound for SAT",
        "track": "main",
        "status": "Poster",
        "abstract": "We show that the CNF satisfiability problem can be solved O^*(1.2226^m) time, where m is the number of clauses in the formula, improving the known upper bounds O^*(1.234^m) given by Yamamoto 15 years ago and O^*(1.239^m) given by Hirsch 22 years ago. By using an amortized technique and careful case analysis, we successfully avoid the bottlenecks in previous algorithms and get the improvement.",
        "primary_area": "Constraint Satisfaction and Optimization",
        "author": "Huairui Chu; Mingyu Xiao; Zhe Zhang",
        "authorids": "",
        "aff": "University of Electronic Science and Technology of China; University of Electronic Science and Technology of China; University of Electronic Science and Technology of China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16487/16487-13-19981-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03707-an-improved-upper-bound-for-sat/",
        "doi": "10.1609/aaai.v35i5.16487",
        "pdf_size": 156466
    },
    {
        "id": "09126",
        "title": "An Information-Theoretic Framework for Unifying Active Learning Problems",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents an information-theoretic framework for unifying active learning problems: level set estimation (LSE), Bayesian optimization (BO), and their generalized variant. We first introduce a novel active learning criterion that subsumes an existing LSE algorithm and achieves state-of-the-art performance in LSE problems with a continuous input domain. Then, by exploiting the relationship between LSE and BO, we design a competitive information-theoretic acquisition function for BO that has interesting connections to upper confidence bound and max-value entropy search (MES). The latter connection reveals a drawback of MES which has important implications on not only MES but also on other MES-based acquisition functions. Finally, our unifying information-theoretic framework can be applied to solve a generalized problem of LSE and BO involving multiple level sets in a data-efficient manner. We empirically evaluate the performance of our proposed algorithms using synthetic benchmark functions, a real-world dataset, and in hyperparameter tuning of machine learning models.",
        "primary_area": "Machine Learning III",
        "author": "Quoc Phong Nguyen; Bryan Kian Hsiang Low; Patrick Jaillet",
        "authorids": "",
        "aff": "National University of Singapore; National University of Singapore; Massachusetts Institute of Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17102/17102-13-20596-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09126-an-information-theoretic-framework-for-unifying-active-learning-problems/",
        "doi": "10.1609/aaai.v35i10.17102",
        "pdf_size": 338366
    },
    {
        "id": "11939",
        "title": "An LP-Based Approach for Goal Recognition as Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Goal recognition aims to recognize the set of candidate goals that are compatible with the observed behavior of an agent. In this paper, we develop a method based on the operator-counting framework that efficiently computes solutions that satisfy the observations and uses the information generated to solve goal recognition tasks. Our method reasons explicitly about both partial and noisy observations: estimating uncertainty for the former, and satisfying observations given the unreliability of the sensor for the latter. We evaluate our approach empirically over a large data set, analyzing its components on how each can impact the quality of the solutions. In general, our approach is superior to previous methods in terms of agreement ratio, accuracy, and spread. Finally, our approach paves the way for new research on combinatorial optimization to solve goal recognition tasks.",
        "primary_area": "Planning, Routing, and Scheduling",
        "author": "Lu\u00edsa R. A. Santos; Felipe Meneguzzi; Ramon Fraga Pereira; Andr\u00e9 Grahl Pereira",
        "authorids": "",
        "aff": "Universidade Federal do Rio Grande do Sul; Pontifical Catholic University of Rio Grande do Sul; Sapienza Universit\u00e0 di Roma; Universidade Federal do Rio Grande do Sul",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17418/17418-13-20912-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11939-an-lp-based-approach-for-goal-recognition-as-planning/",
        "doi": "10.1609/aaai.v35i13.17418",
        "pdf_size": 200066
    },
    {
        "id": "13324",
        "title": "An Unsupervised Sampling Approach for Image-Sentence Matching Using Document-level Structural Information",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we focus on the problem of unsupervised image-sentence matching. Existing research explores to utilize document-level structural information to sample positive and negative instances for model training. Although the approach achieves positive results, it introduces a sampling bias and fails to distinguish instances with high semantic similarity. To alleviate the bias, we propose a new sampling strategy to select additional intra-document image-sentence pairs as positive or negative samples. Furthermore, to recognize the complex pattern in intra-document samples, we propose a Transformer based model to capture fine-grained features and implicitly construct a graph for each document, where concepts in a document are introduced to bridge the representation learning of images and sentences in the context of a document. Experimental results show the effectiveness of our approach to alleviate the bias and learn well-aligned multimodal representations.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Zejun Li; Zhongyu Wei; Zhihao Fan; Haijun Shan; Xuanjing Huang",
        "authorids": "",
        "aff": "School of Data Science, Fudan University, China; School of Data Science, Fudan University, China Research Institute of Intelligent and Complex Systems, Fudan University, China; School of Data Science, Fudan University, China; Zhejiang Lab, China; School of Computer Science, Fudan Universit",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17573/17573-13-21067-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13324-an-unsupervised-sampling-approach-for-image-sentence-matching-using-document-level-structural-information/",
        "doi": "10.1609/aaai.v35i15.17573",
        "pdf_size": 778024
    },
    {
        "id": "01433",
        "title": "Analogical Image Translation for Fog Generation",
        "track": "main",
        "status": "Poster",
        "abstract": "Image-to-image translation is to map images from a given style to another given style. While exceptionally successful, current methods assume the availability of training images in both source and target domains, which does not always hold in practice. Inspired by humans' reasoning capability of analogy, we propose analogical image translation (AIT)  that exploit the concept of gist, for the first time. Given images of two styles in the source domain: A and A', along with images B of the first style in the target domain, learn a model to translate B to B' in the target domain, such that A:A' :: B:B'.  AIT is especially useful for translation scenarios in which training data of one style is hard to obtain but training data of the same two styles in another domain is available. For instance, in the case from normal conditions to extreme, rare conditions, obtaining real training images for the latter case is challenging. However, obtaining synthetic data for both cases is relatively easy. In this work, we aim at adding adverse weather effects, more specifically fog, to images taken in clear weather. To circumvent the challenge of collecting real foggy images, AIT learns the gist of translating synthetic clear-weather to foggy images, followed by adding fog effects onto real clear-weather images, without ever seeing any real foggy image. AIT achieves zero-shot image translation capability, whose  effectiveness and benefit are demonstrated  by  the downstream task of semantic foggy scene understanding.",
        "primary_area": "Computer Vision I",
        "author": "Rui Gong; Dengxin Dai; Yuhua Chen; Wen Li; Danda Pani Paudel; Luc Van Gool",
        "authorids": "",
        "aff": "ETH Zurich; ETH Zurich; ETH Zurich; University of Electronic Science and Technology of China; ETH Zurich; ETH Zurich VISICS, KU Leuven",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16233/16233-13-19727-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01433-analogical-image-translation-for-fog-generation/",
        "doi": "10.1609/aaai.v35i2.16233",
        "pdf_size": 7729257
    },
    {
        "id": "12884",
        "title": "Analogy Training Multilingual Encoders",
        "track": "main",
        "status": "Poster",
        "abstract": "Language encoders encode words and phrases in ways that capture their local semantic relatedness, but are known to be globally inconsistent. Global inconsistency can seemingly be corrected for, in part, by leveraging signals from knowledge bases, but previous results are partial and limited to monolingual English encoders. We extract a large-scale multilingual, multi-word analogy dataset from Wikidata for diagnosing and correcting for global inconsistencies, and then implement a four-way Siamese BERT architecture for grounding multilingual BERT (mBERT) in Wikidata through analogy training. We show that analogy training not only improves the global consistency of mBERT, as well as the isomorphism of language-specific subspaces, but also leads to consistent gains on downstream tasks such as bilingual dictionary induction and sentence retrieval.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Nicolas Garneau; Mareike Hartmann; Anders Sandholm; Sebastian Ruder; Ivan Vuli\u0107; Anders S\u00f8gaard",
        "authorids": "",
        "aff": "Universit\u00e9 Laval; University of Copenhagen; Google Research; DeepMind; University of Cambridge; University of Copenhagen",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17524/17524-13-21018-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12884-analogy-training-multilingual-encoders/",
        "doi": "10.1609/aaai.v35i14.17524",
        "pdf_size": 286028
    },
    {
        "id": "07675",
        "title": "Analysing the Noise Model Error for Realistic Noisy Label Data",
        "track": "main",
        "status": "Poster",
        "abstract": "Distant and weak supervision allow to obtain large amounts of labeled training data quickly and cheaply, but these automatic annotations tend to contain a high amount of errors. A popular technique to overcome the negative effects of these noisy labels is noise modelling where the underlying noise process is modelled. In this work, we study the quality of these estimated noise models from the theoretical side by deriving the expected error of the noise model. Apart from evaluating the theoretical results on commonly used synthetic noise, we also publish NoisyNER, a new noisy label dataset from the NLP domain that was obtained through a realistic distant supervision technique. It provides seven sets of labels with differing noise patterns to evaluate different noise levels on the same instances. Parallel, clean labels are available making it possible to study scenarios where a small amount of gold-standard data can be leveraged. Our theoretical results and the corresponding experiments give insights into the factors that influence the noise model estimation like the noise distribution and the sampling technique.",
        "primary_area": "Machine Learning II",
        "author": "Michael A. Hedderich; Dawei Zhu; Dietrich Klakow",
        "authorids": "",
        "aff": "Saarland University, Saarland Informatics Campus, Germany; Saarland University, Saarland Informatics Campus, Germany; Saarland University, Saarland Informatics Campus, Germany",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16938/16938-13-20432-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07675-analysing-the-noise-model-error-for-realistic-noisy-label-data/",
        "doi": "10.1609/aaai.v35i9.16938",
        "pdf_size": 556112
    },
    {
        "id": "03092",
        "title": "AnchorFace: An Anchor-based Facial Landmark Detector Across Large Poses",
        "track": "main",
        "status": "Poster",
        "abstract": "Facial landmark localization aims to detect the predefined points of human faces, and the topic has been rapidly improved with the recent development of neural network based methods. However, it remains a challenging task when dealing with faces in unconstrained scenarios, especially with large pose variations. In this paper, we target the problem of facial landmark localization across large poses and address this task based on a split-and-aggregate strategy. To split the search space, we propose a set of anchor templates as references for regression, which well addresses the large variations of face poses. Based on the prediction of each anchor template, we propose to aggregate the results, which can reduce the landmark uncertainty due to the large poses. Overall, our proposed approach, named AnchorFace, obtains state-of-the-art results with extremely efficient inference speed on four challenging benchmarks, i.e. AFLW, 300W, Menpo, and WFLW dataset. Code will be available soon.",
        "primary_area": "Computer Vision III",
        "author": "Zixuan Xu; Banghuai Li; Ye Yuan; Miao Geng",
        "authorids": "",
        "aff": "School of Electronics Engineering and Computer Science, Peking University; Megvii Research; Megvii Research; Beihang University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16418/16418-13-19912-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03092-anchorface-an-anchor-based-facial-landmark-detector-across-large-poses/",
        "doi": "10.1609/aaai.v35i4.16418",
        "pdf_size": 2369663
    },
    {
        "id": "04131",
        "title": "Anomaly Attribution with Likelihood Compensation",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper addresses the task of explaining anomalous predictions of a black-box regression model. When using a black-box model, such as one to predict building energy consumption from many sensor measurements, we often have a situation where some observed samples may significantly deviate from their prediction. It may be due to a sub-optimal black-box model, or simply because those samples are outliers. In either case, one would ideally want to compute a responsibility score indicative of the extent to which an input variable is responsible for the anomalous output. In this work, we formalize this task as a statistical inverse problem: Given model deviation from the expected value, infer the responsibility score of each of the input variables. We propose a new method called likelihood compensation (LC), which is founded on the likelihood principle and computes a correction to each input variable. To the best of our knowledge, this is the first principled framework that computes a responsibility score for real valued anomalous model deviations. We apply our approach to a real-world building energy prediction task and confirm its utility based on expert feedback.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Tsuyoshi Id\u00e9; Amit Dhurandhar; Ji\u0159\u00ed Navr\u00e1til; Moninder Singh; Naoki Abe",
        "authorids": "",
        "aff": "IBM Research, T. J. Watson Research Center; IBM Research; IBM Research; IBM Research; IBM Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16535/16535-13-20029-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04131-anomaly-attribution-with-likelihood-compensation/",
        "doi": "10.1609/aaai.v35i5.16535",
        "pdf_size": 605589
    },
    {
        "id": "04968",
        "title": "Answering Complex Queries in Knowledge Graphs with Bidirectional Sequence Encoders",
        "track": "main",
        "status": "Poster",
        "abstract": "Representation learning for knowledge graphs (KGs) has focused on the problem of answering simple link prediction queries. In this work we address the more ambitious challenge of predicting the answers of conjunctive queries with multiple missing entities. We propose Bidirectional Query Embedding (BiQE), a method that embeds conjunctive queries with models based on bi-directional attention mechanisms. Contrary to prior work, bidirectional self-attention can capture interactions among all the elements of a query graph. We introduce two new challenging datasets for studying conjunctive query inference and conduct experiments on several benchmark datasets that demonstrate BiQE significantly outperforms state of the art baselines.",
        "primary_area": "Neuro-Symbolic AI",
        "author": "Bhushan Kotnis; Carolin Lawrence; Mathias Niepert",
        "authorids": "",
        "aff": "NEC Laboratories Europe; NEC Laboratories Europe; NEC Laboratories Europe",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16630/16630-13-20124-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04968-answering-complex-queries-in-knowledge-graphs-with-bidirectional-sequence-encoders/",
        "doi": "10.1609/aaai.v35i6.16630",
        "pdf_size": 318452
    },
    {
        "id": "06340",
        "title": "Answering Regular Path Queries Under Approximate Semantics in Lightweight Description Logics",
        "track": "main",
        "status": "Poster",
        "abstract": "Classical regular path queries (RPQs) can be too restrictive for some applications and answering such queries under approximate semantics to relax the query is desirable. While for answering regular path queries over graph databases under approximate semantics algorithms are available, such algorithms are scarce for the ontology-mediated setting. In this paper we extend an approach for answering RPQs over graph databases that uses weighted transducers to approximate paths from the query in two ways. The first extension is to answering approximate conjunctive 2-way regular path queries (C2RPQs) over graph databases and the second is to answering C2RPQs over ELH and DL-Lite_R ontologies. We provide results on the  computational complexity of the underlying reasoning problems and devise approximate query answering  algorithms.",
        "primary_area": "Knowledge Representation and Reasoning",
        "author": "Oliver Fern\u00e1ndez Gil; Anni-Yasmin Turhan",
        "authorids": "",
        "aff": "TU Dresden; TU Dresden",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16787/16787-13-20281-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06340-answering-regular-path-queries-under-approximate-semantics-in-lightweight-description-logics/",
        "doi": "10.1609/aaai.v35i7.16787",
        "pdf_size": 197533
    },
    {
        "id": "02952",
        "title": "Anticipating Future Relations via Graph Growing for Action Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "Predicting actions from partially observed videos is challenging as the partial videos containing incomplete action executions have insufficient discriminative information for classification. Recent progress has been made through enriching the features of the observed video part or generating the features for the unobserved video part, but without explicitly modeling the fine-grained evolution of visual object relations over both space and time. In this paper, we investigate how the interaction and correlation between visual objects evolve and propose a graph growing method to anticipate future object relations from limited video observations for reliable action prediction. There are two tasks in our method. First, we work with spatial-temporal graph neural networks to reason object relations in the observed video part. Then, we synthesize the spatial-temporal relation representation for the unobserved video part via graph node generation and aggregation. These two tasks are jointly learned to enable the anticipated future relation representation informative to action prediction. Experimental results on two action video datasets demonstrate the effectiveness of our method.",
        "primary_area": "Computer Vision III",
        "author": "Xinxiao Wu; Jianwei Zhao; Ruiqi Wang",
        "authorids": "",
        "aff": "Beijing Institute of Technology; Northeast Normal University; Beijing Institute of Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16402/16402-13-19896-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02952-anticipating-future-relations-via-graph-growing-for-action-prediction/",
        "doi": "10.1609/aaai.v35i4.16402",
        "pdf_size": 378407
    },
    {
        "id": "10763",
        "title": "Any-Precision Deep Neural Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "We present any-precision deep neural networks (DNNs), which are trained with a new method that allows the learned DNNs to be flexible in numerical precision during inference. The same model in runtime can be flexibly and directly set to different bit-widths, by truncating the least significant bits, to support dynamic speed and accuracy trade-off. When all layers are set to low-bits, we show that the model achieved accuracy comparable to dedicated models trained at the same precision. This nice property facilitates flexible deployment of deep learning models in real-world applications, where in practice trade-offs between model accuracy and runtime efficiency are often sought. Previous literature presents solutions to train models at each individual fixed efficiency/accuracy trade-off point. But how to produce a model flexible in runtime precision is largely unexplored. When the demand of efficiency/accuracy trade-off varies from time to time or even dynamically changes in runtime, it is infeasible to re-train models accordingly, and the storage budget may forbid keeping multiple models. Our proposed framework achieves this flexibility without performance degradation. More importantly, we demonstrate that this achievement is agnostic to model architectures and applicable to multiple vision tasks. Our code is released at https://github.com/SHI-Labs/Any-Precision-DNNs.",
        "primary_area": "Machine Learning V",
        "author": "Haichao Yu; Haoxiang Li; Humphrey Shi; Thomas S. Huang; Gang Hua",
        "authorids": "",
        "aff": "UIUC; Wormpex AI Research; University of Oregon UIUC; UIUC; Wormpex AI Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17286/17286-13-20780-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10763-any-precision-deep-neural-networks/",
        "doi": "10.1609/aaai.v35i12.17286",
        "pdf_size": 251459
    },
    {
        "id": "11317",
        "title": "Anytime Heuristic and Monte Carlo Methods for Large-Scale Simultaneous Coalition Structure Generation and Assignment",
        "track": "main",
        "status": "Poster",
        "abstract": "Optimal simultaneous coalition structure generation and assignment is computationally hard. The state-of-the-art can only compute solutions to problems with severely limited input sizes, and no effective approximation algorithms that are guaranteed to yield high-quality solutions are expected to exist. Real-world optimization problems, however, are often characterized by large-scale inputs and the need for generating feasible solutions of high quality in limited time. In light of this, and to make it possible to generate better feasible solutions for difficult large-scale problems efficiently, we present and benchmark several different anytime algorithms that use general-purpose heuristics and Monte Carlo techniques to guide search. We evaluate our methods using synthetic problem sets of varying distribution and complexity. Our results show that the presented algorithms are superior to previous methods at quickly generating near-optimal solutions for small-scale problems, and greatly superior for efficiently finding high-quality solutions for large-scale problems. For example, for problems with a thousand agents and values generated with a uniform distribution, our best approach generates solutions 99.5% of the expected optimal within seconds. For these problems, the state-of-the-art solvers fail to find any feasible solutions at all.",
        "primary_area": "Multiagent Systems",
        "author": "Fredrik Pr\u00e4ntare; Herman Appelgren; Fredrik Heintz",
        "authorids": "",
        "aff": "Link\u00f6ping University; Link\u00f6ping University; Link\u00f6ping University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17349/17349-13-20843-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11317-anytime-heuristic-and-monte-carlo-methods-for-large-scale-simultaneous-coalition-structure-generation-and-assignment/",
        "doi": "10.1609/aaai.v35i13.17349",
        "pdf_size": 228647
    },
    {
        "id": "09463",
        "title": "Anytime Inference with Distilled Hierarchical Neural Ensembles",
        "track": "main",
        "status": "Poster",
        "abstract": "Inference in deep neural networks can be  computationally expensive, and networks capable of anytime inference are  important in  scenarios where the amount of compute or input data varies over time. In such networks the inference process can interrupted to provide a result faster, or continued to obtain a more accurate result.  We propose Hierarchical Neural Ensembles (HNE), a novel framework to embed an ensemble of multiple networks in a hierarchical tree structure, sharing intermediate layers. In HNE we control the complexity of inference on-the-fly by evaluating more or less models in the ensemble. Our second contribution is a novel hierarchical distillation method to boost the predictions  of small ensembles. This approach leverages the nested structure of our ensembles, to optimally allocate accuracy and diversity across the individual models.  Our experiments show that, compared to previous anytime inference models, HNE provides state-of-the-art accuracy-computation trade-offs on the  CIFAR-10/100 and ImageNet datasets.",
        "primary_area": "Machine Learning IV",
        "author": "Adria Ruiz; Jakob Verbeek",
        "authorids": "",
        "aff": "CSIC-UPC; Facebook",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17140/17140-13-20634-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09463-anytime-inference-with-distilled-hierarchical-neural-ensembles/",
        "doi": "10.1609/aaai.v35i11.17140",
        "pdf_size": 3399411
    },
    {
        "id": "00792",
        "title": "Apparently Irrational Choice as Optimal Sequential Decision Making",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a normative approach to modeling apparently human irrational decision making (cognitive biases) that makes use of inherently rational computational mechanisms. We view preferential choice tasks as sequential decision making problems and formulate them as Partially Observable Markov Decision Processes (POMDPs). The resulting sequential decision model learns what information to gather about which options, whether to calculate option values or make comparisons between options and when to make a choice. We apply the model to choice problems where context is known to influence human choice, an effect that has been taken as evidence that human cognition is irrational. Our results show that the new model approximates a bounded optimal cognitive policy and makes quantitative predictions that correspond well to evidence about human choice. Furthermore, the model uses context to help infer which option has a maximum expected value while taking into account computational cost and cognitive limits. In addition, it predicts when, and explains why, people stop evidence accumulation and make a decision. We argue that the model provides evidence that apparent human irrationalities are emergent consequences of processes that prefer higher value (rational) policies.",
        "primary_area": "Cognitive Modeling and Cognitive Systems",
        "author": "Haiyang Chen; Hyung Jin Chang; Andrew Howes",
        "authorids": "",
        "aff": "University of Birmingham; University of Birmingham; University of Birmingham Aalto University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16161/16161-13-19655-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00792-apparently-irrational-choice-as-optimal-sequential-decision-making/",
        "doi": "10.1609/aaai.v35i1.16161",
        "pdf_size": 531732
    },
    {
        "id": "00938",
        "title": "Appearance-Motion Memory Consistency Network for Video Anomaly Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Abnormal event detection in the surveillance video is an essential but challenging task, and many methods have been proposed to deal with this problem. The previous methods either only consider the appearance information or directly integrate the results of appearance and motion information without considering their endogenous consistency semantics explicitly. Inspired by the rule humans identify the abnormal frames from multi-modality signals, we propose an Appearance-Motion Memory Consistency Network (AMMC-Net). Our method first makes full use of the prior knowledge of appearance and motion signals to explicitly capture the correspondence between them in the high-level feature space. Then, it combines the multi-view features to obtain a more essential and robust feature representation of regular events, which can significantly increase the gap between an abnormal and a regular event. In the anomaly detection phase, we further introduce a commit error in the latent space joint with the prediction error in pixel space to enhance the detection accuracy. Solid experimental results on various standard datasets validate the effectiveness of our approach.",
        "primary_area": "Computer Vision I",
        "author": "Ruichu Cai; Hao Zhang; Wen Liu; Shenghua Gao; Zhifeng Hao",
        "authorids": "",
        "aff": "Guangdong University of Technology; Guangdong University of Technology; ShanghaiTech University, Shanghai Institute of Microsystem and Information Technology, Chinese Academy of Sciences; Shanghaitech University; Guangdong University of Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16177/16177-13-19671-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00938-appearance-motion-memory-consistency-network-for-video-anomaly-detection/",
        "doi": "10.1609/aaai.v35i2.16177",
        "pdf_size": 1459688
    },
    {
        "id": "10058",
        "title": "Approximate Multiplication of Sparse Matrices with Limited Space",
        "track": "main",
        "status": "Poster",
        "abstract": "Approximate matrix multiplication with limited space has received ever-increasing attention due to the emergence of large-scale applications. Recently, based on a popular matrix sketching algorithm---frequent directions, previous work has introduced co-occuring directions (COD) to reduce the approximation error for this problem. Although it enjoys the space complexity of O((m_x+m_y)l) for two input matrices X\u2208\u211d^{m_x \u2573 n} and Y\u2208\u211d^{m_y \u2573 n} where l is the sketch size, its time complexity is O(n(m_x+m_y+l)l), which is still very high for large input matrices. In this paper, we propose to reduce the time complexity by exploiting the sparsity of the input matrices. The key idea is to employ an approximate singular value decomposition (SVD) method which can utilize the sparsity, to reduce the number of QR decompositions required by COD. In this way, we develop sparse co-occuring directions, which reduces the time complexity to \u00d5((nnz(X)+nnz(Y))l+nl^2) in expectation while keeps the same space complexity as O((m_x+m_y)l), where nnz(X) denotes the number of non-zero entries in X and the \u00d5 notation hides constant factors as well as polylogarithmic factors. Theoretical analysis reveals that the approximation error of our algorithm is almost the same as that of COD. Furthermore, we empirically verify the efficiency and effectiveness of our algorithm.",
        "primary_area": "Machine Learning IV",
        "author": "Yuanyu Wan; Lijun Zhang",
        "authorids": "",
        "aff": "Nanjing University; Nanjing University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17207/17207-13-20701-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10058-approximate-multiplication-of-sparse-matrices-with-limited-space/",
        "doi": "10.1609/aaai.v35i11.17207",
        "pdf_size": 411362
    },
    {
        "id": "01210",
        "title": "Arbitrary Video Style Transfer via Multi-Channel Correlation",
        "track": "main",
        "status": "Poster",
        "abstract": "Video style transfer is attracting increasing attention from the artificial intelligence community because of its numerous applications, such as augmented reality and animation production. Relative to traditional image style transfer, video style transfer presents new challenges, including how to effectively generate satisfactory stylized results for any specified style while maintaining temporal coherence across frames. Towards this end, we propose a Multi-Channel Correlation network (MCCNet), which can be trained to fuse exemplar style features and input content features for efficient style transfer while naturally maintaining the coherence of input videos to output videos. Specifically, MCCNet works directly on the feature space of style and content domain where it learns to rearrange and fuse style features on the basis of their similarity to content features. The outputs generated by MCC are features containing the desired style patterns that can further be decoded into images with vivid style textures.  Moreover, MCCNet is also designed to explicitly align the features to input and thereby ensure that the outputs maintain the content structures and the temporal continuity. To further improve the performance of MCCNet under complex light conditions, we also introduce illumination loss during training. Qualitative and quantitative evaluations demonstrate that MCCNet performs well in arbitrary video and image style transfer tasks. Code is available at https://github.com/diyiiyiii/MCCNet.",
        "primary_area": "Computer Vision I",
        "author": "Yingying Deng; Fan Tang; Weiming Dong; Haibin Huang; Chongyang Ma; Changsheng Xu",
        "authorids": "",
        "aff": "School of Artificial Intelligence, University of Chinese Academy of Sciences, NLPR, Institute of Automation, Chinese Academy of Sciences, CASIA-LLvision Joint Lab; School of Artificial Intelligence, Jilin University; School of Artificial Intelligence, University of Chinese Academy of Sciences, NLPR, Institute of Automation, Chinese Academy of Sciences, CASIA-LLvision Joint Lab; Kuaishou Technology; Kuaishou Technology; School of Artificial Intelligence, University of Chinese Academy of Sciences, NLPR, Institute of Automation, Chinese Academy of Sciences, CASIA-LLvision Joint Lab",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16208/16208-13-19702-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01210-arbitrary-video-style-transfer-via-multi-channel-correlation/",
        "doi": "10.1609/aaai.v35i2.16208",
        "pdf_size": 13496626
    },
    {
        "id": "10815",
        "title": "Are Adversarial Examples Created Equal? A Learnable Weighted Minimax Risk for Robustness under Non-uniform Attacks",
        "track": "main",
        "status": "Poster",
        "abstract": "Adversarial Training is proved to be an efficient method to defend against adversarial examples, being one of the few defenses that withstand strong attacks. However, traditional defense mechanisms assume a uniform attack over the examples according to the underlying data distribution, which is apparently unrealistic as the attacker could choose to focus on more vulnerable examples. We present a weighted minimax risk optimization that defends against non-uniform attacks, achieving robustness against adversarial examples under perturbed test data distributions. Our modified risk considers importance weights of different adversarial examples and focuses adaptively on harder examples that are wrongly classified or at higher risk of being classified incorrectly. The designed risk allows the training process to learn a strong defense through optimizing the importance weights. The experiments show that our model significantly improves state-of-the-art adversarial accuracy under non-uniform attacks without a significant drop under uniform attacks.",
        "primary_area": "Machine Learning V",
        "author": "Huimin Zeng; Chen Zhu; Tom Goldstein; Furong Huang",
        "authorids": "",
        "aff": "Technical University of Munich; University of Maryland, College Park; University of Maryland, College Park; University of Maryland, College Park",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17292/17292-13-20786-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10815-are-adversarial-examples-created-equal-a-learnable-weighted-minimax-risk-for-robustness-under-non-uniform-attacks/",
        "doi": "10.1609/aaai.v35i12.17292",
        "pdf_size": 339358
    },
    {
        "id": "04758",
        "title": "Argument Mining Driven Analysis of Peer-Reviews",
        "track": "main",
        "status": "Poster",
        "abstract": "Peer reviewing is a central process in modern research and essential for ensuring high quality and reliability of published work. At the same time, it is a time-consuming process and increasing interest in emerging fields often results in a high review workload, especially for senior researchers in this area. How to cope with this problem is an open question and it is vividly discussed across all major conferences. In this work, we propose an Argument Mining based approach for the assistance of editors, meta-reviewers, and reviewers.  We demonstrate that the decision process in the field of scientific publications is driven by arguments and automatic argument identification is helpful in various use-cases. One of our findings is that arguments used in the peer-review process differ from arguments in other domains making the transfer of pre-trained models difficult. Therefore, we provide the community with a new dataset of peer-reviews from different computer science conferences with annotated arguments.  In our extensive empirical evaluation, we show that Argument Mining can be used to efficiently extract the most relevant parts from reviews, which are paramount for the publication decision. Also, the process remains interpretable, since the extracted arguments can be highlighted in a review without detaching them from their context.",
        "primary_area": "AI for Conference Organization and Delivery",
        "author": "Michael Fromm; Evgeniy Faerman; Max Berrendorf; Siddharth Bhargava; Ruoxia Qi; Yao Zhang; Lukas Dennert; Sophia Selle; Yang Mao; Thomas Seidl",
        "authorids": "",
        "aff": "LMU Munich; LMU Munich; LMU Munich; LMU Munich; LMU Munich; LMU Munich; LMU Munich; LMU Munich; LMU Munich; LMU Munich",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16607/16607-13-20101-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04758-argument-mining-driven-analysis-of-peer-reviews/",
        "doi": "10.1609/aaai.v35i6.16607",
        "pdf_size": 163126
    },
    {
        "id": "06175",
        "title": "Argumentation Frameworks with Strong and Weak Constraints: Semantics and Complexity",
        "track": "main",
        "status": "Poster",
        "abstract": "Dung's abstract Argumentation Framework (AF) has emerged as a central formalism in formal argumentation. Key aspects of the success and popularity of Dung's framework include its simplicity and expressiveness. Integrity constraints help to express domain knowledge in a compact  and natural way, thus keeping easy the modeling task even for problems that otherwise would be hard to encode within an AF. In this paper, after providing an intuitive semantics  based on Lukasiewicz's logic for AFs with (strong) constraints, called Constrained AFs (CAFs), we propose Weak constrained AFs (WAFs)  that enhance CAFs with weak constraints.  Intuitively, these constraints can be used to find ``optimal''  solutions to problems defined through CAFs. We provide a detailed complexity analysis of CAFs and WAFs, showing that strong constraints do not increase the expressive  power of AFs in most cases,  while weak constraints systematically increase the expressive  power of CAFs under several well-known argumentation semantics.",
        "primary_area": "Knowledge Representation and Reasoning",
        "author": "Gianvincenzo Alfano; Sergio Greco; Francesco Parisi; Irina Trubitsyna",
        "authorids": "",
        "aff": "University of Calabria; University of Calabria; University of Calabria; University of Calabria",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16768/16768-13-20262-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06175-argumentation-frameworks-with-strong-and-weak-constraints-semantics-and-complexity/",
        "doi": "10.1609/aaai.v35i7.16768",
        "pdf_size": 168214
    },
    {
        "id": "02692",
        "title": "Artificial Dummies for Urban Dataset Augmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "Existing datasets for training pedestrian detectors in images suffer from limited appearance and pose variation. The most challenging scenarios are rarely included because they are too difficult to capture due to safety reasons, or they are very unlikely to happen. The strict safety requirements in assisted and autonomous driving applications call for an extra high detection accuracy also in these rare situations. Having the ability to generate people images in arbitrary poses, with arbitrary appearances and embedded in different background scenes with varying illumination and weather conditions, is a crucial component for the development and testing of such applications. The contributions of this paper are three-fold. First, we describe an augmentation method for the controlled synthesis of urban scenes containing people, thus producing rare or never-seen situations. This is achieved with a data generator (called DummyNet) with disentangled control of the pose, the appearance, and the target background scene. Second, the proposed generator relies on novel network architecture and associated loss that takes into account the segmentation of the foreground person and its composition into the background scene. Finally, we demonstrate that the data generated by our DummyNet improve the performance of several existing person detectors across various datasets as well as in challenging situations, such as night-time conditions, where only a limited amount of training data is available.  In the setup with only day-time data available, we improve the night-time detector by 17% log-average miss rate over the detector trained with the day-time data only.",
        "primary_area": "Computer Vision II",
        "author": "Anton\u00edn Vobeck\u00fd; David Hurych; Michal U\u0159i\u010d\u00e1\u0159; Patrick P\u00e9rez; Josef Sivic",
        "authorids": "",
        "aff": "Czech Institute of Informatics, Robotics and Cybernetics at the Czech Technical University in Prague; valeo.ai; no affiliation; valeo.ai; Czech Institute of Informatics, Robotics and Cybernetics at the Czech Technical University in Prague",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16373/16373-13-19867-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02692-artificial-dummies-for-urban-dataset-augmentation/",
        "doi": "10.1609/aaai.v35i3.16373",
        "pdf_size": 5252846
    },
    {
        "id": "12024",
        "title": "Asking the Right Questions: Learning Interpretable Action Models Through Query Answering",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper develops a new approach for estimating an interpretable, relational model of a black-box autonomous agent that can plan and act. Our main contributions are a new paradigm for estimating such models using a rudimentary query interface with the agent and a hierarchical querying algorithm that generates an interrogation policy for estimating the agent's internal model in a user-interpretable vocabulary. Empirical evaluation of our approach shows that despite the intractable search space of possible agent models, our approach allows correct and scalable estimation of interpretable agent models for a wide class of black-box autonomous agents. Our results also show that this approach can use predicate classifiers to learn interpretable models of planning agents that represent states as images.",
        "primary_area": "Planning, Routing, and Scheduling",
        "author": "Pulkit Verma; Shashank Rao Marpally; Siddharth Srivastava",
        "authorids": "",
        "aff": "Arizona State University; Arizona State University; Arizona State University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17428/17428-13-20922-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12024-asking-the-right-questions-learning-interpretable-action-models-through-query-answering/",
        "doi": "10.1609/aaai.v35i13.17428",
        "pdf_size": 821582
    },
    {
        "id": "12639",
        "title": "Aspect-Level Sentiment-Controllable Review Generation with Mutual Learning Framework",
        "track": "main",
        "status": "Poster",
        "abstract": "Review generation, aiming to automatically generate review text according to the given information, is proposed to assist in the unappealing review writing. However, most of existing methods only consider the overall sentiments of reviews and cannot achieve aspect-level sentiment control. Even though some previous studies attempt to generate aspect-level sentiment-controllable reviews, they usually require large-scale human annotations which are unavailable in the real world. To address this issue, we propose a mutual learning framework to take advantage of unlabeled data to assist the aspect-level sentiment-controllable review generation. The framework consists of a generator and a classifier which utilize confidence mechanism and reconstruction reward to enhance each other. Experimental results show our model can achieve aspect-sentiment control accuracy up to 88% without losing generation quality.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Huimin Chen; Yankai Lin; Fanchao Qi; Jinyi Hu; Peng Li; Jie Zhou; Maosong Sun",
        "authorids": "",
        "aff": "Tsinghua University; Wechat Tencent; Tsinghua University; Tsinghua University; Wechat Tencent; Wechat Tencent; Tsinghua University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17497/17497-13-20991-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12639-aspect-level-sentiment-controllable-review-generation-with-mutual-learning-framework/",
        "doi": "10.1609/aaai.v35i14.17497",
        "pdf_size": 2454003
    },
    {
        "id": "08209",
        "title": "Asynchronous Optimization Methods for Efficient Training of Deep Neural Networks with Guarantees",
        "track": "main",
        "status": "Poster",
        "abstract": "Asynchronous distributed algorithms are a popular way to reduce synchronization costs in large-scale optimization, and in particular for neural network training. However, for nonsmooth and nonconvex objectives, few convergence guarantees exist beyond cases where closed-form proximal operator solutions are available.  As training most popular deep neural networks corresponds to optimizing nonsmooth and nonconvex objectives, there is a pressing need for such convergence guarantees. In this paper, we analyze for the first time the convergence of stochastic asynchronous optimization for this general class of objectives. In particular, we focus on stochastic subgradient methods allowing for block variable partitioning, where the shared model is asynchronously updated by concurrent processes. To this end, we use a probabilistic model which captures key features of real asynchronous scheduling between concurrent processes. Under this model, we establish convergence with probability one to an invariant set for stochastic subgradient methods with momentum.  From a practical perspective, one issue with the family of algorithms that we consider is that they are not efficiently supported by machine learning frameworks, which mostly focus on distributed data-parallel strategies.  To address this, we propose a new implementation strategy for  shared-memory based training of deep neural networks for a partitioned but shared model in single- and multi-GPU settings.   Based on this implementation, we achieve on average1.2x speed-up in comparison to state-of-the-art training methods for popular image classification tasks, without compromising accuracy.",
        "primary_area": "Machine Learning II",
        "author": "Vyacheslav Kungurtsev; Malcolm Egan; Bapi Chatterjee; Dan Alistarh",
        "authorids": "",
        "aff": "Czech Technical University; INRIA; IST Austria; IST Austria",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16999/16999-13-20493-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08209-asynchronous-optimization-methods-for-efficient-training-of-deep-neural-networks-with-guarantees/",
        "doi": "10.1609/aaai.v35i9.16999",
        "pdf_size": 191750
    },
    {
        "id": "00328",
        "title": "Asynchronous Stochastic Gradient Descent for Extreme-Scale Recommender Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "Recommender systems are influential for many internet applications. As the size of the dataset provided for a recommendation model grows rapidly, how to utilize such amount of data effectively matters a lot. For a typical Click-Through-Rate(CTR) prediction model, the amount of daily samples can probably be up to hundreds of terabytes, which reaches dozens of petabytes at an extreme-scale when we take several days into consideration. Such data makes it essential to train the model parallelly and continuously. Traditional asynchronous stochastic gradient descent (ASGD) and its variants are proved efficient but often suffer from stale gradients. Hence, the model convergence tends to be worse as more workers are used. Moreover, the existing adaptive optimizers, which are friendly to sparse data, stagger in long-term training due to the significant imbalance between new and accumulated gradients.  To address the challenges posed by extreme-scale data, we propose: 1) Staleness normalization and data normalization to eliminate the turbulence of stale gradients when training asynchronously in hundreds and thousands of workers; 2) SWAP, a novel framework for adaptive optimizers to balance the new and historical gradients by taking sampling period into consideration. We implement these approaches in TensorFlow and apply them to CTR tasks in real-world e- commerce scenarios. Experiments show that the number of workers in asynchronous training can be extended to 3000 with guaranteed convergence, and the final AUC is improved by more than 5 percentage.",
        "primary_area": "Application Domains",
        "author": "Lewis Liu; Kun Zhao",
        "authorids": "",
        "aff": "University of Montreal, Quebec; Alibaba Group",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16108/16108-13-19602-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00328-asynchronous-stochastic-gradient-descent-for-extreme-scale-recommender-systems/",
        "doi": "10.1609/aaai.v35i1.16108",
        "pdf_size": 1438967
    },
    {
        "id": "01717",
        "title": "Asynchronous Teacher Guided Bit-wise Hard Mining for Online Hashing",
        "track": "main",
        "status": "Poster",
        "abstract": "Online hashing for streaming data has attracted increasing attention recently. However, most existing algorithms focus on batch inputs and instance-balanced optimization, which is limited in the single datum input case and does not match the dynamic training in online hashing. Furthermore, constantly updating the online model with new-coming samples will inevitably lead to the catastrophic forgetting problem. In this paper, we propose a novel online hashing method to handle the above-mentioned issues jointly, termed Asynchronus Teacher-Guided Bit-wise Hard Mining for Online Hashing. Firstly, to meet the needs of datum-wise online hashing, we design a novel binary codebook that is discriminative to separate different classes. Secondly, we propose a novel semantic loss (termed bit-wise attention loss) to dynamically focus on hard samples of each bit during training. Last but not least, we design a asynchronous knowledge distillation scheme to alleviate the catastrophic forgetting problem, where the teacher model is delaying updated to maintain the old knowledge, guiding the student model learning. Extensive experiments conducted on two public benchmarks demonstrate the favorable performance of our method over the state-of-the-arts.",
        "primary_area": "Computer Vision I",
        "author": "Sheng Jin; Qin Zhou; Hongxun Yao; Yao Liu; Xian-Sheng Hua",
        "authorids": "",
        "aff": "Harbin Institute of Technology; Alibaba Group; Harbin Institute of Technology; Alibaba Group; Alibaba Group",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16265/16265-13-19759-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01717-asynchronous-teacher-guided-bit-wise-hard-mining-for-online-hashing/",
        "doi": "10.1609/aaai.v35i2.16265",
        "pdf_size": 376679
    },
    {
        "id": "02567",
        "title": "AttaNet: Attention-Augmented Network for Fast and Accurate Scene Parsing",
        "track": "main",
        "status": "Poster",
        "abstract": "Two factors have proven to be very important to the performance of semantic segmentation models: global context and multi-level semantics. However, generating features that capture both factors always leads to high computational complexity, which is problematic in real-time scenarios. In this paper, we propose a new model, called Attention-Augmented Network (AttaNet), to capture both global context and multi-level semantics while keeping the efficiency high. AttaNet consists of two primary modules: Strip Attention Module (SAM) and Attention Fusion Module (AFM). Viewing that in challenging images with low segmentation accuracy, there are a significantly larger amount of vertical strip areas than horizontal ones, SAM utilizes a striping operation to reduce the complexity of encoding global context in the vertical direction drastically while keeping most of contextual information, compared to the non-local approaches. Moreover, AFM follows a cross-level aggregation strategy to limit the computation, and adopts an attention strategy to weight the importance of different levels of features at each pixel when fusing them, obtaining an efficient multi-level representation. We have conducted extensive experiments on two semantic segmentation benchmarks, and our network achieves different levels of speed/accuracy trade-offs on Cityscapes, e.g., 71 FPS/79.9% mIoU, 130 FPS/78.5% mIoU, and 180 FPS/70.1% mIoU, and leading performance on ADE20K as well.",
        "primary_area": "Computer Vision II",
        "author": "Qi Song; Kangfu Mei; Rui Huang",
        "authorids": "",
        "aff": "Shenzhen Institute of Artificial Intelligence and Robotics for Society Jilin University; The Chinese University of Hong Kong, Shenzhen Shenzhen Institute of Artificial Intelligence and Robotics for Society; The Chinese University of Hong Kong, Shenzhen Shenzhen Institute of Artificial Intelligence and Robotics for Society",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16359/16359-13-19853-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02567-attanet-attention-augmented-network-for-fast-and-accurate-scene-parsing/",
        "doi": "10.1609/aaai.v35i3.16359",
        "pdf_size": 1025956
    },
    {
        "id": "01009",
        "title": "Attention-based Multi-Level Fusion Network for Light Field Depth Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Depth estimation from Light Field (LF) images is a crucial basis for LF related applications. Since multiple views with abundant information are available, how to effectively fuse features of these views is a key point for accurate LF depth estimation. In this paper, we propose a novel attention-based multi-level fusion network. Combined with the four-branch structure, we design intra-branch fusion strategy and inter-branch fusion strategy to hierarchically fuse effective features from different views. By introducing the attention mechanism, features of views with less occlusions and richer textures are selected inside and between these branches to provide more effective information for depth estimation. The depth maps are finally estimated after further aggregation. Experimental results shows the proposed method achieves state-of-the-art performance in both quantitative and qualitative evaluation, which also ranks first in the commonly used HCI 4D Light Field Benchmark.",
        "primary_area": "Computer Vision I",
        "author": "Jiaxin Chen; Shuo Zhang; Youfang Lin",
        "authorids": "",
        "aff": "School of Computer and Information Technology, Beijing Jiaotong University, Beijing, China Beijing Key Laboratory of Traffic Data Analysis and Mining, Beijing, China; School of Computer and Information Technology, Beijing Jiaotong University, Beijing, China Beijing Key Laboratory of Traffic Data Analysis and Mining, Beijing, China CAAC Key Laboratory of Intelligent Passenger Service of Civil Aviation, Beijing, China; School of Computer and Information Technology, Beijing Jiaotong University, Beijing, China Beijing Key Laboratory of Traffic Data Analysis and Mining, Beijing, China CAAC Key Laboratory of Intelligent Passenger Service of Civil Aviation, Beijing, China Key Laboratory of Transport Industry of Big Data Appalication Technologies for Comprehensive Transport, Beijing, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16185/16185-13-19679-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01009-attention-based-multi-level-fusion-network-for-light-field-depth-estimation/",
        "doi": "10.1609/aaai.v35i2.16185",
        "pdf_size": 6949565
    },
    {
        "id": "07592",
        "title": "Attentive Neural Point Processes for Event Forecasting",
        "track": "main",
        "status": "Poster",
        "abstract": "Event sequence, where each event is associated with a marker and a timestamp, is increasingly ubiquitous in various applications. Accordingly, event forecasting emerges to be a crucial problem, which aims to predict the next event based on the historical sequence.  In this paper, we propose ANPP, an Attentive Neural Point Processes framework to solve this problem. In comparison with state-of-the-art methods like recurrent marked temporal point processes, ANPP leverages the time-aware self-attention mechanism to explicitly model the influence between every pair of historical events, resulting in more accurate predictions of events and better interpretation ability. Extensive experiments on one synthetic and four real-world datasets demonstrate that ANPP can achieve significant performance gains against state-of-the-art methods for predictions of both timings and markers. To facilitate future research, we release the codes and datasets at https://github.com/guyulongcs/AAAI2021_ANPP.",
        "primary_area": "Machine Learning II",
        "author": "Yulong Gu",
        "authorids": "",
        "aff": "Alibaba Group",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16929/16929-13-20423-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07592-attentive-neural-point-processes-for-event-forecasting/",
        "doi": "10.1609/aaai.v35i9.16929",
        "pdf_size": 673030
    },
    {
        "id": "04494",
        "title": "AttnMove: History Enhanced Trajectory Recovery via Attentional Network",
        "track": "main",
        "status": "Poster",
        "abstract": "A considerable amount of mobility data has been accumulated due to the proliferation of location-based service. Nevertheless, compared with mobility data from transportation systems like the GPS module in taxis, this kind of data is commonly sparse in terms of individual trajectories in the sense that users do not access mobile services and contribute their data all the time. Consequently, the sparsity inevitably weakens the practical value of the data even it has a high user penetration rate. To solve this problem, we propose a novel attentional neural network-based model, named AttnMove, to densify individual trajectories by recovering unobserved locations at a fine-grained spatial-temporal resolution. To tackle the challenges posed by sparsity, we design various intra- and inter- trajectory attention mechanisms to better model the mobility regularity of users and fully exploit the periodical pattern from long-term history. We evaluate our model on two real-world datasets, and extensive results demonstrate the performance gain compared with the state-of-the-art methods. This also shows that, by providing high-quality mobility data, our model can benefit a variety of mobility-oriented down-stream applications.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Tong Xia; Yunhan Qi; Jie Feng; Fengli Xu; Funing Sun; Diansheng Guo; Yong Li",
        "authorids": "",
        "aff": "Tsinghua University; Tsinghua University; Tsinghua University; Tsinghua University; Tencent Corporation; Tencent Corporation; Tsinghua University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16577/16577-13-20071-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04494-attnmove-history-enhanced-trajectory-recovery-via-attentional-network/",
        "doi": "10.1609/aaai.v35i5.16577",
        "pdf_size": 2860845
    },
    {
        "id": "07574",
        "title": "Attribute-Guided Adversarial Training for Robustness to Natural Perturbations",
        "track": "main",
        "status": "Poster",
        "abstract": "While existing work in robust deep learning has focused on small pixel-level norm-based perturbations, this may not account for perturbations encountered in several real world settings. In many such cases although test data might not be available, broad specifications about the types of perturbations (such as an unknown degree of rotation) may be known. We consider a setup where robustness is expected over an unseen test domain that is not i.i.d. but deviates from the training domain. While this deviation may not be exactly known, its broad characterization is specified a priori, in terms of attributes. We propose an adversarial training approach which learns to generate new samples so as to maximize exposure of the classifier to the attributes-space, without having access to the data from the test domain. Our adversarial training solves a min-max optimization problem, with the inner maximization generating adversarial perturbations, and the outer minimization finding model parameters by optimizing the loss on adversarial perturbations generated from the inner maximization. We demonstrate the applicability of our approach on three types of naturally occurring perturbations --- object-related shifts, geometric transformations, and common image corruptions. Our approach enables deep neural networks to be robust against a wide range of naturally occurring perturbations. We demonstrate the usefulness of the proposed approach by showing the robustness gains of deep neural networks trained using our adversarial training on MNIST, CIFAR-10, and a new variant of the CLEVR dataset.",
        "primary_area": "Machine Learning II",
        "author": "Tejas Gokhale; Rushil Anirudh; Bhavya Kailkhura; Jayaraman J. Thiagarajan; Chitta Baral; Yezhou Yang",
        "authorids": "",
        "aff": "Arizona State University; Lawrence Livermore National Laboratory; Lawrence Livermore National Laboratory; Lawrence Livermore National Laboratory; Arizona State University; Arizona State University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16927/16927-13-20421-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07574-attribute-guided-adversarial-training-for-robustness-to-natural-perturbations/",
        "doi": "10.1609/aaai.v35i9.16927",
        "pdf_size": 639589
    },
    {
        "id": "07840",
        "title": "Attributes-Guided and Pure-Visual Attention Alignment for Few-Shot Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "The purpose of few-shot recognition is to recognize novel categories with a limited number of labeled examples in each class. To encourage learning from a supplementary view, recent approaches have introduced auxiliary semantic modalities into effective metric-learning frameworks that aim to learn a feature similarity between training samples (support set) and test samples (query set). However, these approaches only augment the representations of samples with available semantics while ignoring the query set, which loses the potential for the improvement and may lead to a shift between the modalities combination and the pure-visual representation. In this paper, we devise an attributes-guided attention module (AGAM) to utilize human-annotated attributes and learn more discriminative features. This plug-and-play module enables visual contents and corresponding attributes to collectively focus on important channels and regions for the support set. And the feature selection is also achieved for query set with only visual information while the attributes are not available. Therefore, representations from both sets are improved in a fine-grained manner. Moreover, an attention alignment mechanism is proposed to distill knowledge from the guidance of attributes to the pure-visual branch for samples without attributes. Extensive experiments and analysis show that our proposed module can significantly improve simple metric-based approaches to achieve state-of-the-art performance on different datasets and settings.",
        "primary_area": "Machine Learning II",
        "author": "Siteng Huang; Min Zhang; Yachen Kang; Donglin Wang",
        "authorids": "",
        "aff": "Zhejiang University Machine Intelligence Lab (MiLAB), AI Division, School of Engineering, Westlake University; Machine Intelligence Lab (MiLAB), AI Division, School of Engineering, Westlake University; Machine Intelligence Lab (MiLAB), AI Division, School of Engineering, Westlake University; Machine Intelligence Lab (MiLAB), AI Division, School of Engineering, Westlake University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16957/16957-13-20451-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07840-attributes-guided-and-pure-visual-attention-alignment-for-few-shot-recognition/",
        "doi": "10.1609/aaai.v35i9.16957",
        "pdf_size": 380250
    },
    {
        "id": "13098",
        "title": "Audio-Oriented Multimodal Machine Comprehension via Dynamic Inter- and Intra-modality Attention",
        "track": "main",
        "status": "Poster",
        "abstract": "While Machine Comprehension (MC) has attracted extensive research interests in recent years, existing approaches mainly belong to the category of Machine Reading Comprehension task which mines textual inputs (paragraphs and questions) to predict the answers (choices or text spans). However, there are a lot of MC tasks that accept audio input in addition to the textual input, e.g. English listening comprehension test. In this paper, we target the problem of Audio-Oriented Multimodal Machine Comprehension, and its goal is to answer questions based on the given audio and textual information. To solve this problem, we propose a Dynamic Inter- and Intra-modality Attention (DIIA) model to effectively fuse the two modalities (audio and textual). DIIA can work as an independent component and thus be easily integrated into existing MC models. Moreover, we further develop a Multimodal Knowledge Distillation (MKD) module to enable our multimodal MC model to accurately predict the answers based only on either the text or the audio. As a result, the proposed approach can handle various tasks including: Audio-Oriented Multimodal Machine Comprehension, Machine Reading Comprehension and Machine Listening Comprehension, in a single model, making fair comparisons possible between our model and the existing unimodal MC models. Experimental results and analysis prove the effectiveness of the proposed approaches. First, the proposed DIIA boosts the baseline models by up to 21.08% in terms of accuracy; Second, under the unimodal scenarios, the MKD module allows our multimodal MC model to significantly outperform the unimodal models by up to 18.87%, which are trained and tested with only audio or textual data.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Zhiqi Huang; Fenglin Liu; Xian Wu; Shen Ge; Helin Wang; Wei Fan; Yuexian Zou",
        "authorids": "",
        "aff": "Peking University; Peking University; Tencent AI Lab; Tencent AI Lab; Peking University; Tencent AI Lab; Peking University Peng Cheng Laboratory, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17548/17548-13-21042-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13098-audio-oriented-multimodal-machine-comprehension-via-dynamic-inter-and-intra-modality-attention/",
        "doi": "10.1609/aaai.v35i14.17548",
        "pdf_size": 428343
    },
    {
        "id": "02523",
        "title": "Audio-Visual Localization by Synthetic Acoustic Image Generation",
        "track": "main",
        "status": "Poster",
        "abstract": "Acoustic images constitute an emergent data modality for multimodal scene understanding. Such images have the peculiarity to distinguish the spectral signature of sounds coming from different directions in space, thus providing richer information than the one derived from mono and binaural microphones. However, acoustic images are typically generated by cumbersome microphone arrays, which are not as widespread as ordinary microphones mounted on optical cameras. To exploit this empowered modality while using standard microphones and cameras we propose to leverage the generation of synthetic acoustic images from common audio-video data for the task of audio-visual localization. The generation of synthetic acoustic images is obtained by a novel deep architecture, based on Variational Autoencoder and U-Net models, which is trained to reconstruct the ground truth spatialized audio data collected by a microphone array, from the associated video and its corresponding monaural audio signal. Namely, the model learns how to mimic what an array of microphones can produce in the same conditions.  We assess the quality of the generated synthetic acoustic images on the task of unsupervised sound source localization in a qualitative and quantitative manner, while also considering standard generation metrics. Our model is evaluated by considering both multimodal datasets containing acoustic images, used for the training, and unseen datasets containing just monaural audio signals and RGB frames, showing to reach more accurate localization results as compared to the state of the art.",
        "primary_area": "Computer Vision II",
        "author": "Valentina Sanguineti; Pietro Morerio; Alessio Del Bue; Vittorio Murino",
        "authorids": "",
        "aff": "Pattern Analysis & Computer Vision, Istituto Italiano di Tecnologia, Genoa, Italy University of Genova, Genoa, Italy; Pattern Analysis & Computer Vision, Istituto Italiano di Tecnologia, Genoa, Italy; Visual Geometry and Modelling, Istituto Italiano di Tecnologia, Genoa, Italy; Pattern Analysis & Computer Vision, Istituto Italiano di Tecnologia, Genoa, Italy University of Verona, Verona, Italy Huawei Technologies Ltd., Ireland Research Center, Dublin, Ireland",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16354/16354-13-19848-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02523-audio-visual-localization-by-synthetic-acoustic-image-generation/",
        "doi": "10.1609/aaai.v35i3.16354",
        "pdf_size": 3839388
    },
    {
        "id": "04653",
        "title": "AugSplicing: Synchronized Behavior Detection in Streaming Tensors",
        "track": "main",
        "status": "Poster",
        "abstract": "How can we track synchronized behavior in a stream of time-stamped tuples, such as mobile devices installing and uninstalling applications in the lockstep, to boost their ranks in the app store?  We model such tuples as entries in a streaming tensor, which augments attribute sizes in its modes over time. Synchronized behavior tends to form dense blocks (i.e.~subtensors) in such a tensor, signaling anomalous behavior, or interesting communities. However, existing dense block detection methods are either based on a static tensor, or lack an efficient algorithm in a streaming setting. Therefore, we propose a fast streaming algorithm, AUGSPLICING, which can detect the top dense blocks by incrementally splicing the previous detection with the incoming ones in new tuples, avoiding re-runs over all the history data at every tracking time step. AUGSPLICING is based on a splicing condition that guides the algorithm (Section 4). Compared to the state-of-the-art methods, our method is (1) effective to detect fraudulent behavior in installing data of real-world apps and find a synchronized group of students with interesting features in campus Wi-Fi data; (2) robust with splicing theory for dense block detection; (3) streaming and faster than the existing streaming algorithm, with closely comparable accuracy.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Jiabao Zhang; Shenghua Liu; Wenting Hou; Siddharth Bhatia; Huawei Shen; Wenjian Yu; Xueqi Cheng",
        "authorids": "",
        "aff": "University of Chinese Academy of Sciences; Institute of Computing Technology; Institute of Computing Technology, CAS, China; Beijing InnovSharing Co.Ltd; National University of Singapore; Institute of Computing Technology, Chinese Academy of Sciences; Tsinghua University; Institute of Computing Technology, Chinese Academy of Sciences",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16595/16595-13-20089-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04653-augsplicing-synchronized-behavior-detection-in-streaming-tensors/",
        "doi": "10.1609/aaai.v35i5.16595",
        "pdf_size": 710947
    },
    {
        "id": "09251",
        "title": "Augmented Experiment in Material Engineering Using Machine Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "The synthesis of materials using the principle of thermogravimetric analysis to discover new anticorrosive paints requires several costly experiments. This paper presents an approach combining empirical data and domain analytical models to reduce the number of real experiments required to obtain the desired synthesis. The main idea is to predict the behavior of the synthesis of two materials with well-defined mass proportions as a function of temperature. As no exact equational model exists to predict the new material, we integrate a machine learning approach circumscribed by existing domain analytical models such as heating and kinetics equations in order to derive a generative model of augmented experiments. Extensive empirical evaluation shows that using machine learning approach guided by analytic models, it is possible to substantially reduce the number of needed physical experiments without losing the approximation quality.",
        "primary_area": "Machine Learning III",
        "author": "Aomar Osmani; Massinissa Hamidi; Salah Bouhouche",
        "authorids": "",
        "aff": "Laboratoire LIPN-UMR CNRS 7030, Univ. Sorbonne Paris Nord; Laboratoire LIPN-UMR CNRS 7030, Univ. Sorbonne Paris Nord; Industrial Technologies Research Center, CRTI-DTSI",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17116/17116-13-20610-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09251-augmented-experiment-in-material-engineering-using-machine-learning/",
        "doi": "10.1609/aaai.v35i10.17116",
        "pdf_size": 645272
    },
    {
        "id": "02047",
        "title": "Augmented Partial Mutual Learning with Frame Masking for Video Captioning",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent video captioning work improves greatly due to the invention of various elaborate model architectures. If multiple captioning models are combined into a unified framework not only by simple more ensemble, and each model can benefit from each other, the final captioning might be boosted further. Jointly training of multiple model have not been explored in previous works. In this paper, we propose a novel Augmented Partial Mutual Learning (APML) training method where multiple decoders are trained jointly with mimicry losses between different decoders and different input variations. Another problem of training captioning model is the \"one-to-many\" mapping problem which means that one identical video input is mapped to multiple caption annotations.  To address this problem, we propose an annotation-wise frame masking approach to convert the \"one-to-many\" mapping to \"one-to-one\" mapping. The experiments performed on MSR-VTT and MSVD datasets demonstrate our proposed algorithm achieves the state-of-the-art performance.",
        "primary_area": "Computer Vision II",
        "author": "Ke Lin; Zhuoxin Gan; Liwei Wang",
        "authorids": "",
        "aff": "Peking University Samsung Research China-Beijing (SRC-B); Samsung Research China-Beijing (SRC-B); Peking University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16301/16301-13-19795-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02047-augmented-partial-mutual-learning-with-frame-masking-for-video-captioning/",
        "doi": "10.1609/aaai.v35i3.16301",
        "pdf_size": 1419760
    },
    {
        "id": "11024",
        "title": "Augmenting Policy Learning with Routines Discovered from a Single Demonstration",
        "track": "main",
        "status": "Poster",
        "abstract": "Humans can abstract prior knowledge from very little data and use it to boost skill learning. In this paper, we propose routine-augmented policy learning (RAPL), which discovers routines composed of primitive actions from a single demonstration and uses discovered routines to augment policy learning. To discover routines from the demonstration, we first abstract routine candidates by identifying grammar over the demonstrated action trajectory. Then, the best routines measured by length and frequency are selected to form a routine library. We propose to learn policy simultaneously at primitive-level and routine-level with discovered routines, leveraging the temporal structure of routines. Our approach enables imitating expert behavior at multiple temporal scales for imitation learning and promotes reinforcement learning exploration. Extensive experiments on Atari games demonstrate that RAPL improves the state-of-the-art imitation learning method SQIL and reinforcement learning method A2C. Further, we show that discovered routines can generalize to unseen levels and difficulties on the CoinRun benchmark.",
        "primary_area": "Machine Learning V",
        "author": "Zelin Zhao; Chuang Gan; Jiajun Wu; Xiaoxiao Guo; Joshua B. Tenenbaum",
        "authorids": "",
        "aff": "Shanghai Jiao Tong University; MIT-IBM Watson AI Lab; Stanford University; MIT-IBM Watson AI Lab; Massachusetts Institute of Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17316/17316-13-20810-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11024-augmenting-policy-learning-with-routines-discovered-from-a-single-demonstration/",
        "doi": "10.1609/aaai.v35i12.17316",
        "pdf_size": 1251395
    },
    {
        "id": "08610",
        "title": "Auto-Encoding Transformations in Reparameterized Lie Groups for Unsupervised Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Unsupervised training of deep representations has demonstrated remarkable potentials in mitigating the prohibitive expenses on annotating labeled data recently. Among them is predicting transformations as a pretext task to self-train representations, which has shown great potentials for unsupervised learning. However, existing approaches in this category learn representations by either treating a discrete set of transformations as separate classes, or using the Euclidean distance as the metric to minimize the errors between transformations. None of them has been dedicated to revealing the vital role of the geometry of transformation groups in learning representations. Indeed, an image must continuously transform along the curved manifold of a transformation group rather than through a straight line in the forbidden ambient Euclidean space. This suggests the use of geodesic distance to minimize the errors between the estimated and groundtruth transformations. Particularly, we focus on homographies, a general group of planar transformations containing the Euclidean, similarity and affine transformations as its special cases. To avoid an explicit computing of intractable Riemannian logarithm, we project homographies onto an alternative group of rotation transformations SR(3) with a tractable form of geodesic distance. Experiments demonstrate the proposed approach to Auto-Encoding Transformations exhibits superior performances on a variety of recognition problems.",
        "primary_area": "Machine Learning III",
        "author": "Feng Lin; Haohang Xu; Houqiang Li; Hongkai Xiong; Guo-Jun Qi",
        "authorids": "",
        "aff": "CAS Key Laboratory of GIPAS, EEIS Department, University of Science and Technology of China; Department of Electronic Engineering, Shanghai Jiao Tong University; CAS Key Laboratory of GIPAS, EEIS Department, University of Science and Technology of China Institute of Artificial Intelligence, Hefei Comprehensive National Science Center; Department of Electronic Engineering, Shanghai Jiao Tong University; Laboratory for MAPLE, Futurewei Technologies",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17044/17044-13-20538-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08610-auto-encoding-transformations-in-reparameterized-lie-groups-for-unsupervised-learning/",
        "doi": "10.1609/aaai.v35i10.17044",
        "pdf_size": 953772
    },
    {
        "id": "09351",
        "title": "AutoDropout: Learning Dropout Patterns to Regularize Deep Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Neural networks are often over-parameterized and hence benefit from aggressive regularization. Conventional regularization methods, such as dropout or weight decay, do not leverage the structures of the network's inputs and hidden states. As a result, these conventional methods are less effective than methods that leverage the structures, such as SpatialDropout and DropBlock, which randomly drop the values at certain contiguous areas in the hidden states and setting them to zero. Although the locations of dropping areas random, the patterns of SpatialDropout and DropBlock are manually designed and fixed. Here we propose to learn the dropping patterns. In our method, a controller learns to generate a dropping pattern at every channel and layer of a target network, such as a ConvNet or a Transformer. The target network is then trained with the dropping pattern, and its resulting validation performance is used as a signal for the controller to learn from. We show that this method works well for both image recognition on CIFAR-10 and ImageNet, as well as language modeling on Penn Treebank and WikiText-2. The learned dropping patterns also transfers to different tasks and datasets, such as from language model on Penn Treebank to Engligh-French translation on WMT 2014. Our code will be available at: https://github.com/googleresearch/google-research/tree/master/auto_dropout.",
        "primary_area": "Machine Learning IV",
        "author": "Hieu Pham; Quoc Le",
        "authorids": "",
        "aff": "Google Brain; Google Brain",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17127/17127-13-20621-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09351-autodropout-learning-dropout-patterns-to-regularize-deep-networks/",
        "doi": "10.1609/aaai.v35i11.17127",
        "pdf_size": 638604
    },
    {
        "id": "02486",
        "title": "AutoLR: Layer-wise Pruning and Auto-tuning of Learning Rates in Fine-tuning of Deep Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Existing fine-tuning methods use a single learning rate over all layers. In this paper, first, we discuss that trends of layer-wise weight variations by fine-tuning using a single learning rate do not match the well-known notion that lower-level layers extract general features and higher-level layers extract specific features. Based on our discussion, we propose an algorithm that improves fine-tuning performance and reduces network complexity through layer-wise pruning and auto-tuning of layer-wise learning rates. The proposed algorithm has verified the effectiveness by achieving state-of-the-art performance on the image retrieval benchmark datasets (CUB-200, Cars-196, Stanford online product, and Inshop). Code is available at https://github.com/youngminPIL/AutoLR.",
        "primary_area": "Computer Vision II",
        "author": "Youngmin Ro; Jin Young Choi",
        "authorids": "",
        "aff": "Seoul National University Samsung SDS; Seoul National University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16350/16350-13-19844-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02486-autolr-layer-wise-pruning-and-auto-tuning-of-learning-rates-in-fine-tuning-of-deep-networks/",
        "doi": "10.1609/aaai.v35i3.16350",
        "pdf_size": 7709883
    },
    {
        "id": "06930",
        "title": "Automated Clustering of High-dimensional Data with a Feature Weighted Mean Shift Algorithm",
        "track": "main",
        "status": "Poster",
        "abstract": "Mean shift is a simple interactive procedure that gradually shifts data points towards the mode which denotes the highest density of data points in the region. Mean shift algorithms have been effectively used for data denoising, mode seeking, and finding the number of clusters in a dataset in an automated fashion. However, the merits of mean shift quickly fade away as the data dimensions increase and only a handful of features contain useful information about the cluster structure of the data. We propose a simple yet elegant feature-weighted variant of mean shift to efficiently learn the feature importance and thus, extending the merits of mean shift to high-dimensional data. The resulting algorithm not only outperforms the conventional mean shift clustering procedure but also preserves its computational simplicity. In addition, the proposed method comes with rigorous theoretical convergence guarantees and a convergence rate of at least a cubic order. The efficacy of our proposal is thoroughly assessed through experimental comparison against baseline and state-of-the-art clustering methods on synthetic as well as real-world datasets.",
        "primary_area": "Machine Learning I",
        "author": "Saptarshi Chakraborty; Debolina Paul; Swagatam Das",
        "authorids": "",
        "aff": "University of California, Berkeley; Indian Statistical Institute; Indian Statistical Institute",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16854/16854-13-20348-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06930-automated-clustering-of-high-dimensional-data-with-a-feature-weighted-mean-shift-algorithm/",
        "doi": "10.1609/aaai.v35i8.16854",
        "pdf_size": 353523
    },
    {
        "id": "13745",
        "title": "Automated Cross-prompt Scoring of Essay Traits",
        "track": "main",
        "status": "Poster",
        "abstract": "The majority of current research in Automated Essay Scoring (AES) focuses on prompt-specific scoring of either the overall quality of an essay or the quality with regards to certain traits. In real-world applications obtaining labelled data for a target essay prompt is often expensive or unfeasible, requiring the AES system to be able to perform well when predicting scores for essays from unseen prompts. As a result, some recent research has been dedicated to cross-prompt AES. However, this line of research has thus far only been concerned with holistic, overall scoring, with no exploration into the scoring of different traits. As users of AES systems often require feedback with regards to different aspects of their writing, trait scoring is a necessary component of an effective AES system. Therefore, to address this need, we introduce a new task named Automated Cross-prompt Scoring of Essay Traits, which requires the model to be trained solely on non-target-prompt essays and to predict the holistic, overall score as well as scores for a number of specific traits for target-prompt essays. This task challenges the model's ability to generalize in order to score essays from a novel domain as well as its ability to represent the quality of essays from multiple different aspects. In addition, we introduce a new, innovative approach which builds on top of a state-of-the-art method for cross-prompt AES. Our method utilizes a trait-attention mechanism and a multi-task architecture that leverages the relationships between each trait to simultaneously predict the overall score and the score of each individual trait. We conduct extensive experiments on the widely used ASAP and ASAP++ datasets and demonstrate that our approach is able to outperform leading prompt-specific trait scoring and cross-prompt AES methods.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Robert Ridley; Liang He; Xin-yu Dai; Shujian Huang; Jiajun Chen",
        "authorids": "",
        "aff": "Nanjing University; Nanjing University; Nanjing University; Nanjing University; Nanjing University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17620/17620-13-21114-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13745-automated-cross-prompt-scoring-of-essay-traits/",
        "doi": "10.1609/aaai.v35i15.17620",
        "pdf_size": 367461
    },
    {
        "id": "00160",
        "title": "Automated Lay Language Summarization of Biomedical Scientific Reviews",
        "track": "main",
        "status": "Poster",
        "abstract": "",
        "primary_area": "Application Domains",
        "author": "Yue Guo; Wei Qiu; Yizhong Wang; Trevor Cohen",
        "authorids": "",
        "aff": "",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16089/16089-13-19583-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00160-automated-lay-language-summarization-of-biomedical-scientific-reviews/",
        "doi": "",
        "pdf_size": 123452
    },
    {
        "id": "05789",
        "title": "Automated Mechanism Design for Classification with Partial Verification",
        "track": "main",
        "status": "Poster",
        "abstract": "We study the problem of automated mechanism design with partial verification, where each type can (mis)report only a restricted set of types (rather than any other type), induced by the principal's limited verification power. We prove hardness results when the revelation principle does not necessarily hold, as well as when types have even minimally different preferences. In light of these hardness results, we focus on truthful mechanisms in the setting where all types share the same preference over outcomes, which is motivated by applications in, e.g., strategic classification. We present a number of algorithmic and structural results, including an efficient algorithm for finding optimal deterministic truthful mechanisms, which also implies a faster algorithm for finding optimal randomized truthful mechanisms via a characterization based on the notion of convexity. We then consider a more general setting, where the principal's cost is a function of the combination of outcomes assigned to each type. In particular, we focus on the case where the cost function is submodular, and give generalizations of essentially all our results in the classical setting where the cost function is additive. Our results provide a relatively complete picture for automated mechanisms design with partial verification.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Hanrui Zhang; Yu Cheng; Vincent Conitzer",
        "authorids": "",
        "aff": "Duke University; University of Illinois at Chicago; Duke University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16725/16725-13-20219-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05789-automated-mechanism-design-for-classification-with-partial-verification/",
        "doi": "10.1609/aaai.v35i6.16725",
        "pdf_size": 394940
    },
    {
        "id": "04821",
        "title": "Automated Model Design and Benchmarking of Deep Learning Models for COVID-19 Detection with Chest CT Scans",
        "track": "main",
        "status": "Poster",
        "abstract": "The COVID-19 pandemic has spread globally for several months. Because its transmissibility and high pathogenicity seriously threaten people's lives, it is crucial to accurately and quickly detect COVID-19 infection. Many recent studies have shown that deep learning (DL) based solutions can help detect COVID-19 based on chest CT scans. However, most existing work focuses on 2D datasets, which may result in low quality models as the real CT scans are 3D images. Besides, the reported results span a broad spectrum on different datasets with a relatively unfair comparison. In this paper, we first use three state-of-the-art 3D models (ResNet3D101, DenseNet3D121, and MC3_18) to establish the baseline performance on three publicly available chest CT scan datasets. Then we propose a differentiable neural architecture search (DNAS) framework to automatically search the 3D DL models for 3D chest CT scans classification and use the Gumbel Softmax technique to improve the search efficiency. We further exploit the Class Activation Mapping (CAM) technique on our models to provide the interpretability of the results. The experimental results show that our searched models (CovidNet3D) outperform the baseline human-designed models on three datasets with tens of times smaller model size and higher accuracy. Furthermore, the results also verify that CAM can be well applied in CovidNet3D for COVID-19 datasets to provide interpretability for medical diagnosis. Code: https://github.com/HKBU-HPML/CovidNet3D.",
        "primary_area": "AI Responses to the COVID-19 Pandemic",
        "author": "Xin He; Shihao Wang; Xiaowen Chu; Shaohuai Shi; Jiangping Tang; Xin Liu; Chenggang Yan; Jiyong Zhang; Guiguang Ding",
        "authorids": "",
        "aff": "Hong Kong Baptist University; Hong Kong Baptist University; Hong Kong Baptist University; Hong Kong University of Science and Technology; Hangzhou Dianzi University; Hangzhou Dianzi University; Hangzhou Dianzi University; Hangzhou Dianzi University; Tsinghua University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16614/16614-13-20108-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04821-automated-model-design-and-benchmarking-of-deep-learning-models-for-covid-19-detection-with-chest-ct-scans/",
        "doi": "10.1609/aaai.v35i6.16614",
        "pdf_size": 1832997
    },
    {
        "id": "05859",
        "title": "Automated Storytelling via Causal, Commonsense Plot Ordering",
        "track": "main",
        "status": "Poster",
        "abstract": "Automated story plot generation is the task of generating a coherent sequence of plot events. Causal relations between plot events are believed to increase the perception of story and plot coherence. In this work, we introduce the concept of soft causal relations as causal relations inferred from commonsense reasoning. We demonstrate C2PO, an approach to narrative generation that operationalizes this concept through Causal, Commonsense Plot Ordering. Using human-participant protocols, we evaluate our system against baseline systems with different commonsense reasoning reasoning and inductive biases to determine the role of soft causal relations in perceived story quality. Through these studies we also probe the interplay of how changes in commonsense norms across storytelling genres affect perceptions of story quality.",
        "primary_area": "Humans and AI",
        "author": "Prithviraj Ammanabrolu; Wesley Cheung; William Broniec; Mark O. Riedl",
        "authorids": "",
        "aff": "Georgia Institute of Technology; Georgia Institute of Technology; Georgia Institute of Technology; Georgia Institute of Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16733/16733-13-20227-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05859-automated-storytelling-via-causal-commonsense-plot-ordering/",
        "doi": "10.1609/aaai.v35i7.16733",
        "pdf_size": 333920
    },
    {
        "id": "00660",
        "title": "Automated Symbolic Law Discovery: A Computer Vision Approach",
        "track": "main",
        "status": "Poster",
        "abstract": "One of the most exciting applications of modern artificial intelligence is to automatically discover scientific laws from experimental data. This is not a trivial problem as it involves searching for a complex mathematical relationship over a large set of explanatory variables and operators that can be combined in an infinite number of ways.  Inspired by the incredible success of deep learning in computer vision, we tackle this problem by adapting various successful network architectures into the symbolic law discovery pipeline. The novelty of our approach is in (1) encoding the input data as an image with super-resolution, (2) developing an appropriate deep network pipeline, and (3) predicting the importance of each mathematical operator from the relationship image. This allows us to prior the exponentially large search with the predicted importance of the symbolic operators, which can significantly accelerate the discovery process.  We apply our model to a variety of plausible relationships---both simulated and from physics and mathematics domains---involving different dimensions and constituents. We show that our model is able to identify the underlying operators from data, achieving a high accuracy and AUC (91% and 0.96 on average resp.) for systems with as many as ten independent variables. Our method significantly outperforms the current state of the art in terms of data fitting (R^2), discovery rate (recovering the true relationship), and succinctness (output formula complexity). The discovered equations can be seen as first drafts of scientific laws that can be helpful to the scientists for (1) hypothesis building, and (2) understanding the complex underlying structure of the studied phenomena. Our approach holds a real promise to help speed up the rate of scientific discovery.",
        "primary_area": "Application Domains",
        "author": "Hengrui Xing; Ansaf Salleb-Aouissi; Nakul Verma",
        "authorids": "",
        "aff": "Columbia University; Columbia University; Columbia University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16146/16146-13-19640-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00660-automated-symbolic-law-discovery-a-computer-vision-approach/",
        "doi": "10.1609/aaai.v35i1.16146",
        "pdf_size": 640952
    },
    {
        "id": "14540",
        "title": "Automatic Curriculum Learning With Over-repetition Penalty for Dialogue Policy Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Dialogue policy learning based on reinforcement learning is difficult to be applied to real users to train dialogue agents from scratch because of the high cost. User simulators, which choose random user goals for the dialogue agent to train on, have been considered as an affordable substitute for real users. However, this random sampling method ignores the law of human learning, making the learned dialogue policy inefficient and unstable. We propose a novel framework, Automatic Curriculum Learning-based Deep Q-Network (ACL-DQN), which replaces the traditional random sampling method with a teacher policy model to realize the dialogue policy for automatic curriculum learning. The teacher model arranges a meaningful ordered curriculum and automatically adjusts it by monitoring the learning progress of the dialogue agent and the over-repetition penalty without any requirement of prior knowledge. The learning progress of the dialogue agent reflects the relationship between the dialogue agent's ability and the sampled goals' difficulty for sample efficiency. The over-repetition penalty guarantees the sampled diversity. Experiments show that the ACL-DQN significantly improves the effectiveness and stability of dialogue tasks with a statistically significant margin. Furthermore, the framework can be further improved by equipping with different curriculum schedules, which demonstrates that the framework has strong generalizability.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Yangyang Zhao; Zhenyu Wang; Zhenhua Huang",
        "authorids": "",
        "aff": "South China University of Technology; South China University of Technology; South China University of Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17709/17709-13-21203-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14540-automatic-curriculum-learning-with-over-repetition-penalty-for-dialogue-policy-learning/",
        "doi": "10.1609/aaai.v35i16.17709",
        "pdf_size": 3555841
    },
    {
        "id": "06049",
        "title": "Automatic Generation of Flexible Plans via Diverse Temporal Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Robots operating in the real world must deal with uncertainty, be it due to working with humans who are unpredictable, or simply because they must operate in a dynamic environment. Ignoring the uncertainty is dangerous, while accounting for all possible outcomes is often computationally infeasible.  One approach, which lies between ignoring the uncertainty completely and addressing it completely is using flexible plans with choice, formulated as Temporal Planning Networks (TPNs). This method has been successfully demonstrated to work in human-robot teamwork using the Pike executive, an online executive that unifies intent recognition and plan adaptation.  However, one of the main challenges to using Pike is the need to manually specify the TPN. In this paper, we address this challenge by describing a technique for automatically synthesizing a TPN which covers multiple possible executions for a given temporal planning problem specified in PDDL 2.1. Our approach starts by using a diverse planner to generate multiple plans, and then merges them into a single TPN. As there were no available diverse planners for temporal planning, we first present a novel method for adapting an existing diverse planning method, based on top-k planning, to the temporal setting. We then describe how merging diverse plans into a single TPN is performed using constraint optimization. Finally, an empirical evaluation on a set of IPC benchmarks shows that our approach scales well, and generates TPNs which can generalize the set of plans they are generated from.",
        "primary_area": "Intelligent Robots",
        "author": "Yotam Amitai; Ayal Taitler; Erez Karpas",
        "authorids": "",
        "aff": "Technion; Technion; Technion",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16754/16754-13-20248-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06049-automatic-generation-of-flexible-plans-via-diverse-temporal-planning/",
        "doi": "10.1609/aaai.v35i7.16754",
        "pdf_size": 179314
    },
    {
        "id": "09967",
        "title": "Avoiding Kernel Fixed Points: Computing with ELU and GELU Infinite Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Analysing and computing with Gaussian processes arising from infinitely wide neural networks has recently seen a resurgence in popularity. Despite this, many explicit covariance functions of networks with activation functions used in modern networks remain unknown. Furthermore, while the kernels of deep networks can be computed iteratively, theoretical understanding of deep kernels is lacking, particularly with respect to fixed-point dynamics. Firstly, we derive the covariance functions of multi-layer perceptrons (MLPs) with exponential linear units (ELU) and Gaussian error linear units (GELU) and evaluate the performance of the limiting Gaussian processes on some benchmarks. Secondly, and more generally, we analyse the fixed-point dynamics of iterated kernels corresponding to a broad range of activation functions. We find that unlike some previously studied neural network kernels, these new kernels exhibit non-trivial fixed-point dynamics which are mirrored in finite-width neural networks. The fixed point behaviour present in some networks explains a mechanism for implicit regularisation in overparameterised deep models. Our results relate to both the static iid parameter conjugate kernel and the dynamic neural tangent kernel constructions",
        "primary_area": "Machine Learning IV",
        "author": "Russell Tsuchida; Tim Pearce; Chris van der Heide; Fred Roosta; Marcus Gallagher",
        "authorids": "",
        "aff": "Commonwealth Science & Industrial Research Organisation The University of Queensland; University of Cambridge; The University of Queensland; The University of Queensland International Computer Science Institute; The University of Queensland",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17197/17197-13-20691-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09967-avoiding-kernel-fixed-points-computing-with-elu-and-gelu-infinite-networks/",
        "doi": "10.1609/aaai.v35i11.17197",
        "pdf_size": 2131166
    },
    {
        "id": "10293",
        "title": "BANANAS: Bayesian Optimization with Neural Architectures for Neural Architecture Search",
        "track": "main",
        "status": "Poster",
        "abstract": "Over the past half-decade, many methods have been considered for neural architecture search (NAS). Bayesian optimization (BO), which has long had success in hyperparameter optimization, has recently emerged as a very promising strategy for NAS when it is coupled with a neural predictor. Recent work has proposed different instantiations of this framework, for example, using Bayesian neural networks or graph convolutional networks as the predictive model within BO. However, the analyses in these papers often focus on the full-fledged NAS algorithm, so it is difficult to tell which individual components of the framework lead to the best performance.  In this work, we give a thorough analysis of the \"BO + neural predictor framework\" by identifying five main components: the architecture encoding, neural predictor, uncertainty calibration method, acquisition function, and acquisition function optimization. We test several different methods for each component and also develop a novel path-based encoding scheme for neural architectures, which we show theoretically and empirically scales better than other encodings. Using all of our analyses, we develop a final algorithm called BANANAS, which achieves state-of-the-art performance on NAS search spaces. We adhere to the NAS research checklist (Lindauer and Hutter 2019) to facilitate best practices, and our code is available at https://github.com/naszilla/naszilla.",
        "primary_area": "Machine Learning V",
        "author": "Colin White; Willie Neiswanger; Yash Savani",
        "authorids": "",
        "aff": "Abacus.AI; Stanford University Petuum, Inc.; Abacus.AI",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17233/17233-13-20727-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10293-bananas-bayesian-optimization-with-neural-architectures-for-neural-architecture-search/",
        "doi": "10.1609/aaai.v35i12.17233",
        "pdf_size": 2904915
    },
    {
        "id": "12946",
        "title": "BERT & Family Eat Word Salad: Experiments with Text Understanding",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we study the response of large models from the BERT family to incoherent inputs that should confuse any model that claims to understand natural language. We define simple heuristics to construct such examples. Our experiments show that state-of-the-art models consistently fail to recognize them as ill-formed, and instead produce high confidence predictions on them. As a consequence of this phenomenon, models trained on sentences with randomly permuted word order perform close to state-of-the-art models. To alleviate these issues, we show that if models are explicitly trained to recognize invalid inputs, they can be robust to such attacks without a drop in performance.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Ashim Gupta; Giorgi Kvernadze; Vivek Srikumar",
        "authorids": "",
        "aff": "University of Utah; University of Utah; University of Utah",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17531/17531-13-21025-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12946-bert-family-eat-word-salad-experiments-with-text-understanding/",
        "doi": "10.1609/aaai.v35i14.17531",
        "pdf_size": 127202
    },
    {
        "id": "02602",
        "title": "BSN++: Complementary Boundary Regressor with Scale-Balanced Relation Modeling for Temporal Action Proposal Generation",
        "track": "main",
        "status": "Poster",
        "abstract": "Generating human action proposals in untrimmed videos is an important yet challenging task with wide applications. Current methods often suffer from the noisy boundary locations and the inferior quality of confidence scores used for proposal retrieving. In this paper, we present BSN++, a new framework which exploits complementary boundary regressor and relation modeling for temporal proposal generation. First, we propose a novel boundary regressor based on the complementary characteristics of both starting and ending boundary classifiers. Specifically, we utilize the U-shaped architecture with nested skip connections to capture rich contexts and introduce bi-directional boundary matching mechanism to improve boundary precision. Second, to account for the proposal-proposal relations ignored in previous methods, we devise a proposal relation block to which includes two self-attention modules from the aspects of position and channel. Furthermore, we find that there inevitably exists data imbalanced problems in the positive/negative proposals and temporal durations, which harm the model performance on tail distributions. To relieve this issue, we introduce the scale-balanced re-sampling strategy. Extensive experiments are conducted on two popular benchmarks: ActivityNet-1.3 and THUMOS14, which demonstrate that BSN++ achieves the state-of-the-art performance. Not surprisingly, the proposed BSN++ ranked 1st place in the CVPR19 - ActivityNet challenge leaderboard on temporal action localization task.",
        "primary_area": "Computer Vision II",
        "author": "Haisheng Su; Weihao Gan; Wei Wu; Yu Qiao; Junjie Yan",
        "authorids": "",
        "aff": "SenseTime Research; SenseTime Research; SenseTime Research; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences Shanghai AI Laboratory, Shanghai, China; SenseTime Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16363/16363-13-19857-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02602-bsn-complementary-boundary-regressor-with-scale-balanced-relation-modeling-for-temporal-action-proposal-generation/",
        "doi": "10.1609/aaai.v35i3.16363",
        "pdf_size": 941367
    },
    {
        "id": "06058",
        "title": "BT Expansion: a Sound and Complete Algorithm for Behavior Planning of Intelligent Robots with Behavior Trees",
        "track": "main",
        "status": "Poster",
        "abstract": "Behavior Trees (BTs) have attracted much attention in the robotics field in recent years, which generalize existing control architectures and bring unique advantages for building robot systems. Automated synthesis of BTs can reduce human workload and build behavior models for complex tasks beyond the ability of human design, but theoretical studies are almost missing in existing methods because it is difficult to conduct formal analysis with the classic BT representations. As a result, they may fail in tasks that are actually solvable. This paper proposes BT expansion, an automated planning approach to building intelligent robot behaviors with BTs, and proves the soundness and completeness through the state-space formulation of BTs. The advantages of blended reactive planning and acting are formally discussed through the region of attraction of BTs, by which robots with BT expansion are robust to any resolvable external disturbances. Experiments with a mobile manipulator and test sets are simulated to validate the effectiveness and efficiency, where the proposed algorithm surpasses the baseline by virtue of its soundness and completeness. To the best of our knowledge, it is the first time to leverage the state-space formulation to synthesize BTs with a complete theoretical basis.",
        "primary_area": "Intelligent Robots",
        "author": "Zhongxuan Cai; Minglong Li; Wanrong Huang; Wenjing Yang",
        "authorids": "",
        "aff": "Institute for Quantum Information & State Key Laboratory of High Performance Computing, College of Computer, National University of Defense Technology, China; Institute for Quantum Information & State Key Laboratory of High Performance Computing, College of Computer, National University of Defense Technology, China; Artifcial Intelligence Research Center, National Innovation Institute of Defense Technology, China; Institute for Quantum Information & State Key Laboratory of High Performance Computing, College of Computer, National University of Defense Technology, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16755/16755-13-20249-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06058-bt-expansion-a-sound-and-complete-algorithm-for-behavior-planning-of-intelligent-robots-with-behavior-trees/",
        "doi": "10.1609/aaai.v35i7.16755",
        "pdf_size": 1972391
    },
    {
        "id": "03832",
        "title": "Backdoor Decomposable Monotone Circuits and Propagation Complete Encodings",
        "track": "main",
        "status": "Poster",
        "abstract": "We describe a compilation language of backdoor decomposable monotone circuits (BDMCs) which generalizes several concepts appearing in the literature, e.g. DNNFs and backdoor trees. A C-BDMC sentence is a monotone circuit which satisfies decomposability property (such as in DNNF) in which the inputs (or leaves) are associated with CNF encodings from a given base class C. We consider the class of propagation complete (PC) encodings as a base class and we show that PC-BDMCs are polynomially equivalent to PC encodings. Additionally, we use this to determine the properties of PC-BDMCs and PC encodings with respect to the knowledge compilation map including the list of efficient operations on the languages.",
        "primary_area": "Constraint Satisfaction and Optimization",
        "author": "Petr Ku\u010dera; Petr Savick\u00fd",
        "authorids": "",
        "aff": "Charles University, Czech Republic; Institute of Computer Science of The Czech Academy of Sciences",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16501/16501-13-19995-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03832-backdoor-decomposable-monotone-circuits-and-propagation-complete-encodings/",
        "doi": "10.1609/aaai.v35i5.16501",
        "pdf_size": 149850
    },
    {
        "id": "03447",
        "title": "Bag of Tricks for Long-Tailed Visual Recognition with Deep Convolutional Neural Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "In recent years, visual recognition on challenging long-tailed distributions, where classes often exhibit extremely imbalanced frequencies, has made great progress mostly based on various complex paradigms (e.g., meta learning). Apart from these complex methods, simple refinements on training procedures also make contributions. These refinements, also called tricks, are minor but effective, such as adjustments in the data distribution or loss functions. However, different tricks might conflict with each other. If users apply these long-tail related tricks inappropriately, it could cause worse recognition accuracy than expected. Unfortunately, there has not been a scientific guideline of these tricks in the literature. In this paper, we first collect existing tricks in long-tailed visual recognition and then perform extensive and systematic experiments, in order to give a detailed experimental guideline and obtain an effective combination of these tricks. Furthermore, we also propose a novel data augmentation approach based on class activation maps for long-tailed recognition, which can be friendly combined with re-sampling methods and shows excellent results. By assembling these tricks scientifically, we can outperform state-of-the-art methods on four long-tailed benchmark datasets, including ImageNet-LT and iNaturalist 2018. Our code is open-source and available at https://github.com/zhangyongshun/BagofTricks-LT.",
        "primary_area": "Computer Vision III",
        "author": "Yongshun Zhang; Xiu-Shen Wei; Boyan Zhou; Jianxin Wu",
        "authorids": "",
        "aff": "Nanjing University; Nanjing University of Science and Technology Jiangsu Key Lab of Image and Video Understanding for Social Security; Megvii Research Nanjing; Nanjing University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16458/16458-13-19952-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03447-bag-of-tricks-for-long-tailed-visual-recognition-with-deep-convolutional-neural-networks/",
        "doi": "10.1609/aaai.v35i4.16458",
        "pdf_size": 2027735
    },
    {
        "id": "08013",
        "title": "Balanced Open Set Domain Adaptation via Centroid Alignment",
        "track": "main",
        "status": "Poster",
        "abstract": "Open Set Domain Adaptation (OSDA) is a challenging domain adaptation setting which allows the existence of unknown classes on the target domain. Although existing OSDA methods are good at classifying samples of known classes, they ignore the classification ability for the unknown samples, making them unbalanced OSDA methods. To alleviate this problem, we propose a balanced OSDA methods which could recognize the unknown samples while maintain high classification performance for the known samples. Specifically, to reduce the domain gaps, we first project the features to a hyperspherical latent space. In this space, we propose to bound the centroid deviation angles to not only increase the intra-class compactness but also enlarge the inter-class margins. With the bounded centroid deviation angles, we employ the statistical Extreme Value Theory to recognize the unknown samples that are misclassified into known classes. In addition, to learn better centroids, we propose an improved centroid update strategy based on sample reweighting and adaptive update rate to cooperate with centroid alignment. Experimental results on three OSDA benchmarks verify that our method can significantly outperform the compared methods and reduce the proportion of the unknown samples being misclassified into known classes.",
        "primary_area": "Machine Learning II",
        "author": "Mengmeng Jing; Jingjing Li; Lei Zhu; Zhengming Ding; Ke Lu; Yang Yang",
        "authorids": "",
        "aff": "University of Electronic Science and Technology of China; University of Electronic Science and Technology of China; Shandong Normal University; Department of Computer Science, Tulane University; University of Electronic Science and Technology of China; University of Electronic Science and Technology of China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16977/16977-13-20471-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08013-balanced-open-set-domain-adaptation-via-centroid-alignment/",
        "doi": "10.1609/aaai.v35i9.16977",
        "pdf_size": 494224
    },
    {
        "id": "05372",
        "title": "Bandit Linear Optimization for Sequential Decision Making and Extensive-Form Games",
        "track": "main",
        "status": "Poster",
        "abstract": "Tree-form sequential decision making (TFSDM) extends classical one-shot decision making by modeling tree-form interactions between an agent and a potentially adversarial environment. It captures the online decision-making problems that each player faces in an extensive-form game, as well as Markov decision processes and partially-observable Markov decision processes where the agent conditions on observed history. Over the past decade, there has been considerable effort into designing online optimization methods for TFSDM. Virtually all of that work has been in the full-feedback setting, where the agent has access to counterfactuals, that is, information on what would have happened had the agent chosen a different action at any decision node. Little is known about the bandit setting, where that assumption is reversed (no counterfactual information is available), despite this latter setting being well understood for almost 20 years in one-shot decision making. In this paper, we give the first algorithm for the bandit linear optimization problem for TFSDM that offers both (i) linear-time iterations (in the size of the decision tree) and (ii) O(sqrt(T)) cumulative regret in expectation compared to any fixed strategy, at all times T. This is made possible by new results that we derive, which may have independent uses as well: 1) geometry of the dilated entropy regularizer, 2) autocorrelation matrix of the natural sampling scheme for sequence-form strategies, 3) construction of an unbiased estimator for linear losses for sequence-form strategies, and 4) a refined regret analysis for mirror descent when using the dilated entropy regularizer.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Gabriele Farina; Robin Schmucker; Tuomas Sandholm",
        "authorids": "",
        "aff": "Carnegie Mellon University; Carnegie Mellon University; Carnegie Mellon University Strategy Robot, Inc. Optimized Markets, Inc. Strategic Machine, Inc.",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16677/16677-13-20171-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05372-bandit-linear-optimization-for-sequential-decision-making-and-extensive-form-games/",
        "doi": "10.1609/aaai.v35i6.16677",
        "pdf_size": 613756
    },
    {
        "id": "12418",
        "title": "Bayes DistNet \u2013 A Robust Neural Network for Algorithm Runtime Distribution Predictions",
        "track": "main",
        "status": "Poster",
        "abstract": "Randomized algorithms are used in many state-of-the-art solvers for constraint satisfaction problems (CSP) and Boolean satisfiability (SAT) problems. For many of these problems, there is no single solver which will dominate others. Having access to the underlying runtime distributions (RTD) of these solvers can allow for better use of algorithm selection, algorithm portfolios, and restart strategies. Previous state-of-the-art methods directly try to predict a fixed parametric distribution that the input instance follows. In this paper, we extend RTD prediction models into the Bayesian setting for the first time. This new model achieves robust predictive performance in the low observation setting, as well as handling censored observations. This technique also allows for richer representations which cannot be achieved by the classical models which restrict their output representations. Our model outperforms the previous state-of-the-art model in settings in which data is scarce, and can make use of censored data such as lower bound time estimates, where that type of data would otherwise be discarded. It can also quantify its uncertainty in its predictions, allowing for algorithm portfolio models to make better informed decisions about which algorithm to run on a particular instance.",
        "primary_area": "Search and Optimization",
        "author": "Jake Tuero; Michael Buro",
        "authorids": "",
        "aff": "University of Alberta; University of Alberta",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17473/17473-13-20967-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12418-bayes-distnet-a-robust-neural-network-for-algorithm-runtime-distribution-predictions/",
        "doi": "10.1609/aaai.v35i14.17473",
        "pdf_size": 3205181
    },
    {
        "id": "11423",
        "title": "Bayes-TrEx: a Bayesian Sampling Approach to Model Transparency by Example",
        "track": "main",
        "status": "Poster",
        "abstract": "Post-hoc explanation methods are gaining popularity for interpreting, understanding, and debugging neural networks. Most analyses using such methods explain decisions in response to inputs drawn from the test set. However, the test set may have few  examples that trigger some model behaviors, such as high-confidence failures or ambiguous classifications. To address these challenges, we introduce a flexible model inspection framework: Bayes-TrEx. Given a data distribution, Bayes-TrEx finds in-distribution examples which trigger a specified prediction confidence. We demonstrate several use cases of Bayes-TrEx, including revealing highly confident (mis)classifications, visualizing class boundaries via ambiguous examples, understanding novel-class extrapolation behavior, and exposing neural network overconfidence. We use Bayes-TrEx to study classifiers trained on CLEVR, MNIST, and Fashion-MNIST, and we show that this framework enables more flexible holistic model analysis than just inspecting the test set. Code and supplemental material are available at https://github.com/serenabooth/Bayes-TrEx.",
        "primary_area": "Philosophy and Ethics of AI",
        "author": "Serena Booth; Yilun Zhou; Ankit Shah; Julie Shah",
        "authorids": "",
        "aff": "Massachusetts Institute of Technology; Massachusetts Institute of Technology; Massachusetts Institute of Technology; Massachusetts Institute of Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17361/17361-13-20855-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11423-bayes-trex-a-bayesian-sampling-approach-to-model-transparency-by-example/",
        "doi": "10.1609/aaai.v35i13.17361",
        "pdf_size": 1258326
    },
    {
        "id": "08429",
        "title": "Bayesian Distributional Policy Gradients",
        "track": "main",
        "status": "Poster",
        "abstract": "Distributional Reinforcement Learning (RL) maintains the entire probability distribution of the reward-to-go, i.e. the return, providing more learning signals that account for the uncertainty associated with policy performance, which may be beneficial for trading off exploration and exploitation and policy learning in general. Previous works in distributional RL focused mainly on computing the state-action-return distributions, here we model the state-return distributions. This enables us to translate successful conventional RL algorithms that are based on state values into distributional RL. We formulate the distributional Bellman operation as an inference-based auto-encoding process that minimises Wasserstein metrics between target/model return distributions. The proposed algorithm, BDPG (Bayesian Distributional Policy Gradients), uses adversarial training in joint-contrastive learning to estimate a variational posterior from the returns. Moreover, we can now interpret the return prediction uncertainty as an information gain, which allows to obtain a new curiosity measure that helps BDPG steer exploration actively and efficiently. We demonstrate in a suite of Atari 2600 games and MuJoCo tasks, including well known hard-exploration challenges, how BDPG learns generally faster and with higher asymptotic performance than reference distributional RL algorithms.",
        "primary_area": "Machine Learning III",
        "author": "Luchen Li; A. Aldo Faisal",
        "authorids": "",
        "aff": "Imperial College London; Imperial College London",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17024/17024-13-20518-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08429-bayesian-distributional-policy-gradients/",
        "doi": "10.1609/aaai.v35i10.17024",
        "pdf_size": 1240915
    },
    {
        "id": "08083",
        "title": "Bayesian Dynamic Mode Decomposition with Variational Matrix Factorization",
        "track": "main",
        "status": "Poster",
        "abstract": "Dynamic mode decomposition (DMD) and its extensions are data-driven methods that have substantially contributed to our understanding of dynamical systems. However, because DMD and most of its extensions are deterministic, it is difficult to treat probabilistic representations of parameters and predictions. In this work, we propose a novel formulation of a Bayesian DMD model. Our Bayesian DMD model is consistent with the procedure of standard DMD, which is to first determine the subspace of observations, and then compute the modes on that subspace. Variational matrix factorization makes it possible to realize a fully-Bayesian scheme of DMD. Moreover, we derive a Bayesian DMD model for incomplete data, which demonstrates the advantage of probabilistic modeling. Finally, both of nonlinear simulated and real-world datasets are used to illustrate the potential of the proposed method.",
        "primary_area": "Machine Learning II",
        "author": "Takahiro Kawashima; Hayaru Shouno; Hideitsu Hino",
        "authorids": "",
        "aff": "The University of Electro-Communications; The University of Electro-Communications; The Institute of Statistical Mathematics",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16985/16985-13-20479-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08083-bayesian-dynamic-mode-decomposition-with-variational-matrix-factorization/",
        "doi": "10.1609/aaai.v35i9.16985",
        "pdf_size": 1105036
    },
    {
        "id": "11880",
        "title": "Bayesian Optimized Monte Carlo Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Online solvers for partially observable Markov decision processes have difficulty scaling to problems with large action spaces. Monte Carlo tree search with progressive widening attempts to improve scaling by sampling from the action space to construct a policy search tree. The performance of progressive widening search is dependent upon the action sampling policy, often requiring problem-specific samplers. In this work, we present a general method for efficient action sampling based on Bayesian optimization. The proposed method uses a Gaussian process to model a belief over the action-value function and selects the action that will maximize the expected improvement in the optimal action value. We implement the proposed approach in a new online tree search algorithm called Bayesian Optimized Monte Carlo Planning (BOMCP). Several experiments show that BOMCP is better able to scale to large action space POMDPs than existing state-of-the-art tree search solvers.",
        "primary_area": "Planning, Routing, and Scheduling",
        "author": "John Mern; Anil Yildiz; Zachary Sunberg; Tapan Mukerji; Mykel J. Kochenderfer",
        "authorids": "",
        "aff": "Stanford University; Stanford University; University of Colorado, Boulder, CO; Stanford University; Stanford University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17411/17411-13-20905-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11880-bayesian-optimized-monte-carlo-planning/",
        "doi": "10.1609/aaai.v35i13.17411",
        "pdf_size": 151966
    },
    {
        "id": "05127",
        "title": "Bayesian Persuasion under Ex Ante and Ex Post Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "Bayesian persuasion, as introduced by Kamenica and Gentzkow in 2011, is the study of information sharing policies among strategic agents. A prime example is signaling in online ad auctions: what information should a platform signal to an advertiser regarding a user when selling the opportunity to advertise to her? Practical considerations such as preventing discrimination, protecting privacy or acknowledging limited attention of the information receiver impose constraints on information sharing. We propose a simple way to mathematically model such constraints as restrictions on Receiver's admissible posterior beliefs. We consider two families of constraints - ex ante and ex post; the latter limits each instance of Sender-Receiver communication, while the former more general family can also pose restrictions in expectation. For the ex ante family, a result of Doval and Skreta (2018) establishes the existence of an optimal signaling scheme with a small number of signals - at most the number of constraints plus the number of states of nature - and we show this result is tight. For the ex post family, we tighten the previous bound of V\u00f8lund (2018), showing that the required number of signals is at most the number of states of nature, as in the original Kamenica-Gentzkow setting. As our main algorithmic result, we provide an additive bi-criteria FPTAS for an optimal constrained signaling scheme assuming a constant number of states of nature; we improve the approximation to single-criteria under a Slater-like regularity condition. The FPTAS holds under standard assumptions, and more relaxed assumptions yield a PTAS. We then establish a bound on the ratio between Sender's optimal utility under convex ex ante constraints and the corresponding ex post constraints. We demonstrate how this result can be applied to find an approximately welfare-maximizing constrained signaling scheme in ad auctions.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Yakov Babichenko; Inbal Talgam-Cohen; Konstantin Zabarnyi",
        "authorids": "",
        "aff": "Technion \u2013 Israel Institute of Technology; Technion \u2013 Israel Institute of Technology; Technion \u2013 Israel Institute of Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16648/16648-13-20142-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05127-bayesian-persuasion-under-ex-ante-and-ex-post-constraints/",
        "doi": "10.1609/aaai.v35i6.16648",
        "pdf_size": 149597
    },
    {
        "id": "02969",
        "title": "Beating Attackers At Their Own Games: Adversarial Example Detection Using Adversarial Gradient Directions",
        "track": "main",
        "status": "Poster",
        "abstract": "Adversarial examples are input examples that are specifically crafted to deceive machine learning classifiers. State-of-the-art adversarial example detection methods characterize an input example as adversarial either by quantifying the magnitude of feature variations under multiple perturbations or by measuring its distance from estimated benign example distribution. Instead of using such metrics, the proposed method is based on the observation that the directions of adversarial gradients when crafting (new) adversarial examples play a key role in characterizing the adversarial space. Compared to detection methods that use multiple perturbations, the proposed method is efficient as it only applies a single random perturbation on the input example. Experiments conducted on two different databases, CIFAR-10 and ImageNet, show that the proposed detection method achieves, respectively, 97.9% and 98.6% AUC-ROC (on average) on five different adversarial attacks, and outperforms multiple state-of-the-art detection methods. Results demonstrate the effectiveness of using adversarial gradient directions for adversarial example detection.",
        "primary_area": "Computer Vision III",
        "author": "Yuhang Wu; Sunpreet S Arora; Yanhong Wu; Hao Yang",
        "authorids": "",
        "aff": "Visa Research; Visa Research; Visa Research; Visa Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16404/16404-13-19898-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02969-beating-attackers-at-their-own-games-adversarial-example-detection-using-adversarial-gradient-directions/",
        "doi": "10.1609/aaai.v35i4.16404",
        "pdf_size": 2839533
    },
    {
        "id": "12574",
        "title": "Benchmarking Knowledge-Enhanced Commonsense Question Answering via Knowledge-to-Text Transformation",
        "track": "main",
        "status": "Poster",
        "abstract": "A fundamental ability of humans is to utilize commonsense knowledge in language understanding and question answering. In recent years, many knowledge-enhanced Commonsense Question Answering (CQA) approaches have been proposed. However, it remains unclear: (1) How far can we get by exploiting external knowledge for CQA? (2) How much potential of knowledge has been exploited in current CQA models? (3) Which are the most promising directions for future CQA? To answer these questions, we benchmark knowledge-enhanced CQA by conducting extensive experiments on multiple standard CQA datasets using a simple and effective knowledge-to-text transformation framework. Experiments show that: (1) Our knowledge-to-text framework is effective and achieves state-of-the-art performance on CommonsenseQA dataset, providing a simple and strong knowledge-enhanced baseline for CQA; (2) The potential of knowledge is still far from being fully exploited in CQA \u2014 there is a significant performance gap from current models to our models with golden knowledge; and (3) Context-sensitive knowledge selection, heterogeneous knowledge exploitation, and commonsense-rich language models are promising CQA directions.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Ning Bian; Xianpei Han; Bo Chen; Le Sun",
        "authorids": "",
        "aff": "Chinese Information Processing Laboratory, Institute of Software, Chinese Academy of Sciences University of Chinese Academy of Sciences; Chinese Information Processing Laboratory, Institute of Software, Chinese Academy of Sciences State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences; Chinese Information Processing Laboratory, Institute of Software, Chinese Academy of Sciences State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences; Chinese Information Processing Laboratory, Institute of Software, Chinese Academy of Sciences State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17490/17490-13-20984-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12574-benchmarking-knowledge-enhanced-commonsense-question-answering-via-knowledge-to-text-transformation/",
        "doi": "10.1609/aaai.v35i14.17490",
        "pdf_size": 315143
    },
    {
        "id": "12069",
        "title": "Better Bounds on the Adaptivity Gap of Influence Maximization under Full-adoption Feedback",
        "track": "main",
        "status": "Poster",
        "abstract": "In the influence maximization (IM) problem, we are given a social network and a budget k, and we look for a set of k nodes in the network, called seeds, that maximize the expected number of nodes that are reached by an influence cascade generated by the seeds, according to some stochastic model for influence diffusion. Extensive studies have been done on the IM problem, since his definition by Kempe, Kleinberg, and Tardos (2003). However, most of the work focuses on the non-adaptive version of the problem where all the k seed nodes must be selected before that the cascade starts. In this paper we study the adaptive IM, where the nodes are selected sequentially one by one, and the decision on the i-th seed can be based on the observed cascade produced by the first i-1 seeds. We focus on the full-adoption feedback in which we can observe the entire cascade of each previously selected seed and on the independent cascade model where each edge is associated with an independent probability of diffusing influence.  Previous works showed that there are constant upper bounds on the adaptivity gap, which compares the performance of an adaptive algorithm against a non-adaptive one, but the analyses used to prove these bounds only works for specific graph classes such as in-arborescences, out-arborescences, and one-directional bipartite graphs. Our main result is the first sub-linear upper bound that holds for any graph. Specifically, we show that the adaptivity gap is upper-bounded by \u221bn+1, where n is the number of nodes in the graph. Moreover we improve over the known upper bound for in-arborescences from 2e/(e-1)\u22483.16 to 2e\u00b2/(e\u00b2-1)\u22482.31. Finally, we study \u03b1-bounded graphs, a class of undirected graphs in which the sum of node degrees higher than two is at most \u03b1, and show that the adaptivity gap is upper-bounded by \u221a\u03b1+O(1). Moreover, we show that in 0-bounded graphs, i.e. undirected graphs in which each connected component is a path or a cycle, the adaptivity gap is at most 3e\u00b3/(e\u00b3-1)\u22483.16.  To prove our bounds, we introduce new techniques to relate adaptive policies with non-adaptive ones that might be of their own interest.",
        "primary_area": "Reasoning under Uncertainty",
        "author": "Gianlorenzo D'Angelo; Debashmita Poddar; Cosimo Vinci",
        "authorids": "",
        "aff": "Gran Sasso Science Institute, L'Aquila, Italy; Gran Sasso Science Institute, L'Aquila, Italy; Gran Sasso Science Institute, L'Aquila, Italy",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17433/17433-13-20927-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12069-better-bounds-on-the-adaptivity-gap-of-influence-maximization-under-full-adoption-feedback/",
        "doi": "10.1609/aaai.v35i13.17433",
        "pdf_size": 153308
    },
    {
        "id": "11442",
        "title": "Beyond Class-Conditional Assumption: A Primary Attempt to Combat Instance-Dependent Label Noise",
        "track": "main",
        "status": "Poster",
        "abstract": "Supervised learning under label noise has seen numerous advances recently, while existing theoretical findings and empirical results broadly build up on the class-conditional noise (CCN) assumption that the noise is independent of input features given the true label. In this work, we present a theoretical hypothesis testing and prove that noise in real-world dataset is unlikely to be CCN, which confirms that label noise should depend on the instance and justifies the urgent need to go beyond the CCN assumption.The theoretical results motivate us to study the more general and practical-relevant instance-dependent noise (IDN). To stimulate the development of theory and methodology on IDN, we formalize an algorithm to generate controllable IDN and present both theoretical and empirical evidence to show that IDN is semantically meaningful and challenging. As a primary attempt to combat IDN, we present a tiny algorithm termed self-evolution average label (SEAL), which not only stands out under IDN with various noise fractions, but also improves the generalization on real-world noise benchmark Clothing1M. Our code is released. Notably, our theoretical analysis in Section 2 provides rigorous motivations for studying IDN, which is an important topic that deserves more research attention in future.",
        "primary_area": "Philosophy and Ethics of AI",
        "author": "Pengfei Chen; Junjie Ye; Guangyong Chen; Jingwei Zhao; Pheng-Ann Heng",
        "authorids": "",
        "aff": "The Chinese University of Hong Kong; VIVO AI Lab; Shenzhen Key Laboratory of Virtual Reality and Human Interaction Technology, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences; VIVO AI Lab; The Chinese University of Hong Kong Shenzhen Key Laboratory of Virtual Reality and Human Interaction Technology, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17363/17363-13-20857-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11442-beyond-class-conditional-assumption-a-primary-attempt-to-combat-instance-dependent-label-noise/",
        "doi": "10.1609/aaai.v35i13.17363",
        "pdf_size": 1700547
    },
    {
        "id": "03950",
        "title": "Beyond Low-frequency Information in Graph Convolutional Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Graph neural networks (GNNs) have been proven to be effective in various network-related tasks. Most existing GNNs usually exploit the low-frequency signals of node features, which gives rise to one fundamental question: is the low-frequency information all we need in the real world applications? In this paper, we first present an experimental investigation assessing the roles of low-frequency and high-frequency signals, where the results clearly show that exploring low-frequency signal only is distant from learning an effective node representation in different scenarios. How can we adaptively learn more information beyond low-frequency information in GNNs? A well-informed answer can help GNNs enhance the adaptability. We tackle this challenge and propose a novel Frequency Adaptation Graph Convolutional Networks (FAGCN) with a self-gating mechanism, which can adaptively integrate different signals in the process of message passing. For a deeper understanding, we theoretically analyze the roles of low-frequency signals and high-frequency signals on learning node representations, which further explains why FAGCN can perform well on different types of networks. Extensive experiments on six real-world networks validate that FAGCN not only alleviates the over-smoothing problem, but also has advantages over the state-of-the-arts.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Deyu Bo; Xiao Wang; Chuan Shi; Huawei Shen",
        "authorids": "",
        "aff": "Beijing University of Posts and Telecommunications; Beijing University of Posts and Telecommunications; Beijing University of Posts and Telecommunications; Institute of Computing Technology, Chinese Academy of Sciences",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16514/16514-13-20008-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03950-beyond-low-frequency-information-in-graph-convolutional-networks/",
        "doi": "10.1609/aaai.v35i5.16514",
        "pdf_size": 555850
    },
    {
        "id": "08455",
        "title": "Bi-Classifier Determinacy Maximization for Unsupervised Domain Adaptation",
        "track": "main",
        "status": "Poster",
        "abstract": "Unsupervised domain adaptation challenges the problem of transferring knowledge from a well-labelled source domain to an unlabelled target domain. Recently, adversarial learning with bi-classifier has been proven effective in pushing cross-domain distributions close. Prior approaches typically leverage the disagreement between bi-classifier to learn transferable representations, however, they often neglect the classifier determinacy in the target domain, which could result in a lack of feature discriminability. In this paper, we present a simple yet effective method, namely Bi-Classifier Determinacy Maximization (BCDM), to tackle this problem. Motivated by the observation that target samples cannot always be separated distinctly by the decision boundary, here in the proposed BCDM, we design a novel classifier determinacy disparity (CDD) metric, which formulates classifier discrepancy as the class relevance of distinct target predictions and implicitly introduces constraint on the target feature discriminability. To this end, the BCDM can generate discriminative representations by encouraging target predictive outputs to be consistent and determined, meanwhile, preserve the diversity of predictions in an adversarial manner. Furthermore, the properties of CDD as well as the theoretical guarantees of BCDM's generalization bound are both elaborated. Extensive experiments show that BCDM compares favorably against the existing state-of-the-art domain adaptation methods.",
        "primary_area": "Machine Learning III",
        "author": "Shuang Li; Fangrui Lv; Binhui Xie; Chi Harold Liu; Jian Liang; Chen Qin",
        "authorids": "",
        "aff": "Beijing Institute of Technology; Beijing Institute of Technology; Beijing Institute of Technology; Beijing Institute of Technology; Alibaba Group; Institute for Digital Communications, School of Engineering, University of Edinburgh, Edinburgh, UK",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17027/17027-13-20521-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08455-bi-classifier-determinacy-maximization-for-unsupervised-domain-adaptation/",
        "doi": "10.1609/aaai.v35i10.17027",
        "pdf_size": 882526
    },
    {
        "id": "11177",
        "title": "Bias and Variance of Post-processing in Differential Privacy",
        "track": "main",
        "status": "Poster",
        "abstract": "Post-processing immunity is a fundamental property of differential privacy: it enables the application of arbitrary data-independent  transformations to the results of differentially private outputs  without affecting their privacy guarantees.  When query outputs must satisfy domain constraints, post-processing  can be used to project them back onto the feasibility region.  Moreover, when the feasible region is convex, a widely adopted class of post-processing steps is also guaranteed to improve accuracy. Post-processing has  been applied successfully in many applications including census  data, energy systems, and mobility. However, its effects on the  noise distribution is poorly understood: It is often argued that  post-processing may introduce bias and increase variance. This paper  takes a first step towards understanding the properties of  post-processing. It considers the release of census data and  examines, both empirically and theoretically, the behavior of a  widely adopted class of post-processing functions.",
        "primary_area": "Machine Learning V",
        "author": "Keyu Zhu; Pascal Van Hentenryck; Ferdinando Fioretto",
        "authorids": "",
        "aff": "Georgia Institute of Technology; Georgia Institute of Technology; Syracuse University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17333/17333-13-20827-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11177-bias-and-variance-of-post-processing-in-differential-privacy/",
        "doi": "10.1609/aaai.v35i12.17333",
        "pdf_size": 464545
    },
    {
        "id": "12666",
        "title": "Bidirectional Machine Reading Comprehension for Aspect Sentiment Triplet Extraction",
        "track": "main",
        "status": "Poster",
        "abstract": "Aspect sentiment triplet extraction (ASTE), which aims to identify aspects from review sentences along with their corresponding opinion expressions and sentiments, is an emerging task in fine-grained opinion mining. Since ASTE consists of multiple subtasks, including opinion entity extraction, relation detection, and sentiment classification, it is critical and challenging to appropriately capture and utilize the associations among them. In this paper, we transform ASTE task into a multi-turn machine reading comprehension (MTMRC) task and propose a bidirectional MRC (BMRC) framework to address this challenge. Specifically, we devise three types of queries, including non-restrictive extraction queries, restrictive extraction queries and sentiment classification queries, to build the associations among different subtasks. Furthermore, considering that an aspect sentiment triplet can derive from either an aspect or an opinion expression, we design a bidirectional MRC structure. One direction sequentially recognizes aspects, opinion expressions, and sentiments to obtain triplets, while the other direction identifies opinion expressions first, then aspects, and at last sentiments. By making the two directions complement each other, our framework can identify triplets more comprehensively. To verify the effectiveness of our approach, we conduct extensive experiments on four benchmark datasets. The experimental results demonstrate that BMRC achieves state-of-the-art performances.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Shaowei Chen; Yu Wang; Jie Liu; Yuelin Wang",
        "authorids": "",
        "aff": "College of Artificial Intelligence, Nankai University, Tianjin, China; College of Artificial Intelligence, Nankai University, Tianjin, China; College of Artificial Intelligence, Nankai University, Tianjin, China Cloopen Research, Beijing, China; College of Artificial Intelligence, Nankai University, Tianjin, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17500/17500-13-20994-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12666-bidirectional-machine-reading-comprehension-for-aspect-sentiment-triplet-extraction/",
        "doi": "10.1609/aaai.v35i14.17500",
        "pdf_size": 367231
    },
    {
        "id": "01808",
        "title": "Bidirectional RNN-based Few Shot Learning for 3D Medical Image Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "Segmentation of organs of interest in 3D medical images is necessary for accurate diagnosis and longitudinal studies. Though recent advances using deep learning have shown success for many segmentation tasks, large datasets are required for high performance and the annotation process is both time consuming and labor intensive. In this paper, we propose a 3D few shot segmentation framework for accurate organ segmentation using limited training samples of the target organ annotation. To achieve this, a U-Net like network is designed to predict segmentation by learning the relationship between 2D slices of support data and a query image, including a bidirectional gated recurrent unit (GRU) that learns consistency of encoded features between adjacent slices. Also, we introduce a transfer learning method to adapt the characteristics of the target image and organ by updating the model before testing with arbitrary support and query data sampled from the support data. We evaluate our proposed model using three 3D CT datasets with annotations of different organs. Our model yielded significantly improved performance over state-of-the-art few shot segmentation models and was comparable to a fully supervised model trained with more target training data.",
        "primary_area": "Computer Vision II",
        "author": "Soopil Kim; Sion An; Philip Chikontwe; Sang Hyun Park",
        "authorids": "",
        "aff": "DGIST; DGIST; DGIST; DGIST",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16275/16275-13-19769-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01808-bidirectional-rnn-based-few-shot-learning-for-3d-medical-image-segmentation/",
        "doi": "10.1609/aaai.v35i3.16275",
        "pdf_size": 784047
    },
    {
        "id": "00706",
        "title": "Bigram and Unigram Based Text Attack via Adaptive Monotonic Heuristic Search",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep neural networks (DNNs) are known to be vulnerable to adversarial images, while their robustness in text classification are rarely studied. Several lines of text attack methods have been proposed in the literature, such as character-level, word-level, and sentence-level attacks. However, it is still a challenge to minimize the number of word distortions necessary to induce misclassification, while simultaneously ensuring the lexical correctness, syntactic correctness, and semantic similarity. In this paper, we propose the Bigram and Unigram based Monotonic Heuristic Search (BU-MHS) method to examine the vulnerability of deep models. Our method has three major merits. Firstly, we propose to attack text documents not only at the unigram word level but also at the bigram level to avoid producing meaningless outputs. Secondly, we propose a hybrid method to replace the input words with both their synonyms and sememe candidates, which greatly enriches potential substitutions compared to only using synonyms. Lastly, we design a search algorithm, i.e., Monotonic Heuristic Search (MHS), to determine the priority of word replacements, aiming to reduce the modification cost in an adversarial attack. We evaluate the effectiveness of BU-MHS on IMDB, AG's News, and Yahoo! Answers text datasets by attacking four state-of-the-art DNNs models. Experimental results show that our BU-MHS achieves the highest attack success rate by changing the smallest number of words compared with other existing models.",
        "primary_area": "Application Domains",
        "author": "Xinghao Yang; Weifeng Liu; James Bailey; Dacheng Tao; Wei Liu",
        "authorids": "",
        "aff": "University of Technology Sydney; China University of Petroleum (East China); THE UNIVERSITY OF MELBOURNE; The University of Sydney; University of Technology Sydney",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16151/16151-13-19645-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00706-bigram-and-unigram-based-text-attack-via-adaptive-monotonic-heuristic-search/",
        "doi": "10.1609/aaai.v35i1.16151",
        "pdf_size": 274958
    },
    {
        "id": "11844",
        "title": "Bike-Repositioning Using Volunteers: Crowd Sourcing with Choice Restriction",
        "track": "main",
        "status": "Poster",
        "abstract": "Motivated by the Bike Angels Program in New York's Citi Bike and Boston's Blue Bikes, we study the use of (registered) volunteers to re-position empty bikes for riders in a bike sharing system. We propose a method that can be used to deploy the volunteers in the system, based on the real time distribution of the bikes in different stations. To account for (random) route demand in the network, we solve a related transshipment network design model and construct a sparse structure to restrict the re-balancing activities of the volunteers (concentrating re-balancing activities on essential routes). We also develop a comprehensive simulation model using a threshold-based policy to deploy the volunteers in real time,  to test the effect of choice restriction on volunteers (suitably deployed) to re-position bikes.  We use the Hubway system in Boston (with 60 stations) to demonstrate that using a sparse structure to concentrate the re-balancing activities of the volunteers, instead of allowing all admissible flows in the system (as in current practice),  can reduce the number of re-balancing moves by a huge amount, losing only a small proportion of demand satisfied.",
        "primary_area": "Planning, Routing, and Scheduling",
        "author": "Jinjia Huang; Mabel C. Chou; Chung-Piaw Teo",
        "authorids": "",
        "aff": "Institute of Operations Research and Analytics, National University of Singapore; Institute of Operations Research and Analytics, National University of Singapore; Institute of Operations Research and Analytics, National University of Singapore",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17407/17407-13-20901-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11844-bike-repositioning-using-volunteers-crowd-sourcing-with-choice-restriction/",
        "doi": "10.1609/aaai.v35i13.17407",
        "pdf_size": 646181
    },
    {
        "id": "03823",
        "title": "Binary Matrix Factorisation via Column Generation",
        "track": "main",
        "status": "Poster",
        "abstract": "Identifying discrete patterns in binary data is an important dimensionality reduction tool in machine learning and data mining. In this paper, we consider the problem of low-rank binary matrix factorisation (BMF) under Boolean arithmetic. Due to the hardness of this problem, most previous attempts rely on heuristic techniques. We formulate the problem as a mixed integer linear program and use a large scale optimisation technique of column generation to solve it without the need of heuristic pattern mining. Our approach focuses on accuracy and on the provision of optimality guarantees. Experimental results on real world datasets demonstrate that our proposed method is effective at producing highly accurate factorisations and improves on the previously available best known results for 15 out of 24 problem instances.",
        "primary_area": "Constraint Satisfaction and Optimization",
        "author": "Reka A. Kovacs; Oktay Gunluk; Raphael A. Hauser",
        "authorids": "",
        "aff": "University of Oxford, The Alan Turing Institute; Cornell University; University of Oxford, The Alan Turing Institute",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16500/16500-13-19994-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03823-binary-matrix-factorisation-via-column-generation/",
        "doi": "10.1609/aaai.v35i5.16500",
        "pdf_size": 302757
    },
    {
        "id": "02961",
        "title": "Binaural Audio-Visual Localization",
        "track": "main",
        "status": "Poster",
        "abstract": "Localizing sound sources in a visual scene has many important applications and quite a few traditional or learning-based methods have been proposed for this task. Humans have the ability to roughly localize sound sources within or beyond the range of the vision using their binaural system. However most existing methods use monaural audio, instead of  binaural audio, as a modality to help the localization. In addition, prior works usually localize sound sources in the form of object-level bounding boxes in images or videos and evaluate the localization accuracy by examining the overlap between the ground-truth and predicted bounding boxes. This is too rough since a real sound source is often only a part of an object. In this paper, we propose a deep learning method for pixel-level sound source localization by leveraging both binaural recordings and the corresponding videos. Specifically, we design a novel Binaural Audio-Visual Network (BAVNet), which concurrently extracts and integrates features from binaural recordings and videos. We also propose a point-annotation strategy to construct pixel-level ground truth for network training and performance evaluation. Experimental results on Fair-Play and YT-Music datasets demonstrate  the effectiveness of the proposed method and show that binaural audio can greatly improve the performance of localizing the sound sources, especially when the quality of the visual information is limited.",
        "primary_area": "Computer Vision III",
        "author": "Xinyi Wu; Zhenyao Wu; Lili Ju; Song Wang",
        "authorids": "",
        "aff": "University of South Carolina; University of South Carolina; University of South Carolina; University of South Carolina",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16403/16403-13-19897-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02961-binaural-audio-visual-localization/",
        "doi": "10.1609/aaai.v35i4.16403",
        "pdf_size": 9356349
    },
    {
        "id": "03403",
        "title": "BoW Pooling: A Plug-and-Play Unit for Feature Aggregation of Point Clouds",
        "track": "main",
        "status": "Poster",
        "abstract": "Point cloud provides a compact and flexible representation for 3D shapes and recently attracts more and more attention due to the increasing demands in practical applications. The major challenge of handling such irregular data is how to achieve the permutation invariance of points in the input. Most of existing methods extract local descriptors that encode the geometry of local structure, followed by a symmetric function to form a global representation. The max pooling usually serves as the symmetric function and shows slight superiority compared to the average pooling. We argue that some discrimination information is inevitably missing when applying the max pooling across all local descriptors. In this paper, we propose the BoW pooling, a plug-and-play unit to substitute the max pooling. Our BoW pooling analyzes the set of local descriptors statistically and generates a histogram that reflects how the primitives in the dictionary constitute the overall geometry. Extensive experiments demonstrate that the proposed Bow pooling is efficient to improve the performance in point cloud classification, shape retrieval and segmentation tasks and outperforms other existing symmetric functions.",
        "primary_area": "Computer Vision III",
        "author": "Xiang Zhang; Xiao Sun; Zhouhui Lian",
        "authorids": "",
        "aff": "Peking University; Peking University Meituan; Peking University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16453/16453-13-19947-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03403-bow-pooling-a-plug-and-play-unit-for-feature-aggregation-of-point-clouds/",
        "doi": "10.1609/aaai.v35i4.16453",
        "pdf_size": 4146322
    },
    {
        "id": "01273",
        "title": "Boosting Image-based Mutual Gaze Detection using Pseudo 3D Gaze",
        "track": "main",
        "status": "Poster",
        "abstract": "Mutual gaze detection, i.e., predicting whether or not two people are looking at each other, plays an important role in understanding human interactions. In this work, we focus on the task of image-based mutual gaze detection, and propose a simple and effective approach to boost the performance by using an auxiliary 3D gaze estimation task during the training phase. We achieve the performance boost without additional labeling cost by training the 3D gaze estimation branch using pseudo 3D gaze labels deduced from mutual gaze labels. By sharing the head image encoder between the 3D gaze estimation and the mutual gaze detection branches, we achieve better head features than learned by training the mutual gaze detection branch alone. Experimental results on three image datasets show that the proposed approach improves the detection performance significantly without additional annotations. This work also introduces a new image dataset that consists of 33.1K pairs of humans annotated with mutual gaze labels in 29.2K images.",
        "primary_area": "Computer Vision I",
        "author": "Bardia Doosti; Ching-Hui Chen; Raviteja Vemulapalli; Xuhui Jia; Yukun Zhu; Bradley Green",
        "authorids": "",
        "aff": "Luddy School of Informatics, Computing, and Engineering, Indiana University Bloomington; Google Research; Google Research; Google Research; Google Research; Google Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16215/16215-13-19709-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01273-boosting-image-based-mutual-gaze-detection-using-pseudo-3d-gaze/",
        "doi": "10.1609/aaai.v35i2.16215",
        "pdf_size": 3876769
    },
    {
        "id": "07771",
        "title": "Boosting Multi-task Learning Through Combination of Task Labels \u2013 with Applications in ECG Phenotyping",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-task learning has increased in importance due to its superior performance by learning multiple different tasks simultaneously and its ability to perform several different tasks using a single model. In medical phenotyping, task labels are costly to acquire and might contain a certain degree of label noise. This decreases the efficiency of using additional human labels as auxiliary tasks when applying multi-task learning to medical phenotyping. In this work, we proposed an effective multi-task learning framework, CO-TASK, to boost multi-task learning performance by generating auxiliary tasks through COmbination of TASK Labels. The proposed CO-TASK framework generates auxiliary tasks without additional labeling effort, is robust to a certain degree of label noise, and can be applied in parallel with various multi-task learning techniques.  We evaluated our performance using the CIFAR-MTL dataset and demonstrated its effectiveness in medical phenotyping using two large-scale ECG phenotyping datasets, an 18 diseases multi-label ECG-P18 dataset and an echocardiogram diagnostic from electrocardiogram dataset ECG-EchoLVH. On the CIFAR-MTL dataset, we doubled the average per-task performance gain of the multi-task learning model from 4.38% to 9.78%. With the proposed task-aware imbalance data sampler, the CO-TASK framework can effectively deal with the different imbalance ratios for the different tasks in electrocardiogram phenotyping datasets. The proposed framework combined with noisy annotations as minor tasks increased the sensitivity by 7.1% compared to the single-task model while maintaining the same specificity as the doctor annotations on the ECG-EchoLVH dataset.",
        "primary_area": "Machine Learning II",
        "author": "Ming-En Hsieh; Vincent Tseng",
        "authorids": "",
        "aff": "National Chiao Tung University; National Chiao Tung University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16949/16949-13-20443-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07771-boosting-multi-task-learning-through-combination-of-task-labels-with-applications-in-ecg-phenotyping/",
        "doi": "10.1609/aaai.v35i9.16949",
        "pdf_size": 1176479
    },
    {
        "id": "02986",
        "title": "Boundary Proposal Network for Two-stage Natural Language Video Localization",
        "track": "main",
        "status": "Poster",
        "abstract": "We aim to address the problem of Natural Language Video Localization (NLVL) \u2014 localizing the video segment corresponding to a natural language description in a long and untrimmed video. State-of-the-art NLVL methods are almost in one-stage fashion, which can be typically grouped into two categories: 1) anchor-based approach: it first pre-defines a series of video segment candidates (e.g., by sliding window), and then does classification for each candidate; 2) anchor-free approach: it directly predicts the probabilities for each video frame as a boundary or intermediate frame inside the positive segment. However, both kinds of one-stage approaches have inherent drawbacks: the anchor-based approach is susceptible to the heuristic rules, further limiting the capability of handling videos with variant length. While the anchor-free approach fails to exploit the segment-level interaction thus achieving inferior results. In this paper, we propose a novel Boundary Proposal Network (BPNet), a universal two-stage framework that gets rid of the issues mentioned above. Specifically, in the first stage, BPNet utilizes an anchor-free model to generate a group of high-quality candidate video segments with their boundaries. In the second stage, a visual-language fusion layer is proposed to jointly model the multi-modal interaction between the candidate and the language query, followed by a matching score rating layer that outputs the alignment score for each candidate. We evaluate our BPNet on three challenging NLVL benchmarks (i.e., Charades-STA, TACoS and ActivityNet-Captions). Extensive experiments and ablative studies on these datasets demonstrate that the BPNet outperforms the state-of-the-art methods.",
        "primary_area": "Computer Vision III",
        "author": "Shaoning Xiao; Long Chen; Songyang Zhang; Wei Ji; Jian Shao; Lu Ye; Jun Xiao",
        "authorids": "",
        "aff": "Zhejiang University; Tencent AI Lab; University of Rochester; National University of Singapore; Zhejiang University; Zhejiang University of Science and Technology; Zhejiang University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16406/16406-13-19900-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02986-boundary-proposal-network-for-two-stage-natural-language-video-localization/",
        "doi": "10.1609/aaai.v35i4.16406",
        "pdf_size": 2923342
    },
    {
        "id": "01424",
        "title": "Boundary-Aware Geometric Encoding for Semantic Segmentation of Point Clouds",
        "track": "main",
        "status": "Poster",
        "abstract": "Boundary information plays a significant role in 2D image segmentation, while usually being ignored in 3D point cloud segmentation where ambiguous features might be generated in feature extraction, leading to misclassification in the transition area between two objects. In this paper, firstly, we propose a Boundary Prediction Module (BPM) to predict boundary points. Based on the predicted boundary, a boundary-aware Geometric Encoding Module (GEM) is designed to encode geometric information and aggregate features with discrimination in a neighborhood, so that the local features belonging to different categories will not be polluted by each other. To provide extra geometric information for boundary-aware GEM, we also propose a light-weight Geometric Convolution Operation (GCO), making the extracted features more distinguishing. Built upon the boundary-aware GEM, we build our network and test it on benchmarks like ScanNet v2, S3DIS. Results show our methods can significantly improve the baseline and achieve state-of-the-art performance.",
        "primary_area": "Computer Vision I",
        "author": "Jingyu Gong; Jiachen Xu; Xin Tan; Jie Zhou; Yanyun Qu; Yuan Xie; Lizhuang Ma",
        "authorids": "",
        "aff": "Shanghai Jiao Tong University; Shanghai Jiao Tong University; Shanghai Jiao Tong University City University of Hong Kong; City University of Hong Kong; Xiamen University; East China Normal University; Shanghai Jiao Tong University East China Normal University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16232/16232-13-19726-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01424-boundary-aware-geometric-encoding-for-semantic-segmentation-of-point-clouds/",
        "doi": "10.1609/aaai.v35i2.16232",
        "pdf_size": 3986238
    },
    {
        "id": "06011",
        "title": "Bounded Risk-Sensitive Markov Games: Forward Policy Design and Inverse Reward Learning with Iterative Reasoning and Cumulative Prospect Theory",
        "track": "main",
        "status": "Poster",
        "abstract": "Classical game-theoretic approaches for multi-agent systems in both the forward policy design problem and the inverse reward learning problem often make strong rationality assumptions: agents perfectly maximize expected utilities under uncertainties. Such assumptions, however, substantially mismatch with observed human behaviors such as satisficing with sub-optimal, risk-seeking, and loss-aversion decisions. Drawing on iterative reasoning models and cumulative prospect theory, we propose a new game-theoretic framework, bounded risk-sensitive Markov Game (BRSMG), that captures two aspects of realistic human behaviors: bounded intelligence and risk-sensitivity. General solutions to both the forward policy design problem and the inverse reward learning problem are provided with theoretical analysis and simulation verification. We validate the proposed forward policy design algorithm and the inverse reward learning algorithm in a two-player navigation scenario. The results show that agents demonstrate bounded-intelligence, risk-averse and risk-seeking behaviors in our framework. Moreover, in the inverse reward learning task, the proposed bounded risk-sensitive inverse learning algorithm outperforms a baseline risk-neutral inverse learning algorithm by effectively learning not only more accurate reward values but also the intelligence levels and the risk-measure parameters of agents from demonstrations.",
        "primary_area": "Humans and AI",
        "author": "Ran Tian; Liting Sun; Masayoshi Tomizuka",
        "authorids": "",
        "aff": "University of California, Berkeley; University of California, Berkeley; University of California, Berkeley",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16750/16750-13-20244-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06011-bounded-risk-sensitive-markov-games-forward-policy-design-and-inverse-reward-learning-with-iterative-reasoning-and-cumulative-prospect-theory/",
        "doi": "10.1609/aaai.v35i7.16750",
        "pdf_size": 1029700
    },
    {
        "id": "12207",
        "title": "Bounding Causal Effects on Continuous Outcome",
        "track": "main",
        "status": "Poster",
        "abstract": "We investigate the problem of bounding causal effects from experimental studies in which treatment assignment is randomized but the subject compliance is imperfect. It is well known that under such conditions, the actual causal effects are not point-identifiable due to uncontrollable unobserved confounding. In their seminal work, Balke and Pearl (1994) derived the tightest bounds over the causal effects in this settings by employing an algebra program to derive analytic expressions. However, Pearl's approach assumes the primary outcome to be discrete and finite. Solving such a program could be intractable when high-dimensional context variables are present. In this paper, we present novel non-parametric methods to bound causal effects on the continuous outcome from studies with imperfect compliance. These bounds could be generalized to settings with a high-dimensional context.",
        "primary_area": "Reasoning under Uncertainty",
        "author": "Junzhe Zhang; Elias Bareinboim",
        "authorids": "",
        "aff": "Columbia University; Columbia University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17449/17449-13-20943-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12207-bounding-causal-effects-on-continuous-outcome/",
        "doi": "10.1609/aaai.v35i13.17449",
        "pdf_size": 327038
    },
    {
        "id": "12602",
        "title": "Brain Decoding Using fNIRS",
        "track": "main",
        "status": "Poster",
        "abstract": "Brain activation can reflect semantic information elicited by natural words and concepts. Increasing research has been conducted on decoding such neural activation patterns using representational semantic models. However, prior work decoding semantic meaning from neurophysiological responses has been largely limited to ECoG, fMRI, MEG, and EEG techniques, each having its own advantages and limitations. More recently, the functional near infrared spectroscopy (fNIRS) has emerged as an alternative hemodynamic-based approach and possesses a number of strengths. We investigate brain decoding tasks under the help of fNIRS and empirically compare fNIRS with fMRI. Primarily, we find that: 1) like fMRI scans, activation patterns recorded from fNIRS encode rich information for discriminating concepts, but show limits on the possibility of decoding fine-grained semantic clues; 2) fNIRS decoding shows robustness across different brain regions, semantic categories and even subjects; 3) fNIRS has higher accuracy being decoded based on multi-channel patterns as compared to single-channel ones, which is in line with our intuition of the working mechanism of human brain. Our findings prove that fNIRS has the potential to promote a deep integration of NLP and cognitive neuroscience from the perspective of language understanding. We release the largest fNIRS dataset by far to facilitate future research.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Lu Cao; Dandan Huang; Yue Zhang; Xiaowei Jiang; Yanan Chen",
        "authorids": "",
        "aff": "Singapore University of Technology and Design; School of Engineering, Westlake University, China Institute of Advanced Technology, Westlake Institute for Advanced Study, China; School of Engineering, Westlake University, China Institute of Advanced Technology, Westlake Institute for Advanced Study, China; Henan University; Henan University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17493/17493-13-20987-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12602-brain-decoding-using-fnirs/",
        "doi": "10.1609/aaai.v35i14.17493",
        "pdf_size": 1373378
    },
    {
        "id": "11853",
        "title": "Branch and Price for Bus Driver Scheduling with Complex Break Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a Branch and Price approach for a real-life Bus Driver Scheduling problem with a complex set of break constraints. The column generation uses a set partitioning model as master problem and a resource constrained shortest path problem as subproblem. Due to the complex constraints, the branch and price algorithm adopts several novel ideas to improve the column generation in the presence of a high-dimensional subproblem, including exponential arc throttling and a dedicated two-stage dominance algorithm. Evaluation on a publicly available set of benchmark instances shows that the approach provides the first provably optimal solutions for small instances, improving best-known solutions or proving them optimal for 48 out of 50 instances, and yielding an optimality gap of less than 1% for more than half the instances.",
        "primary_area": "Planning, Routing, and Scheduling",
        "author": "Lucas Kletzander; Nysret Musliu; Pascal Van Hentenryck",
        "authorids": "",
        "aff": "TU Wien; TU Wien; Georgia Institute of Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17408/17408-13-20902-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11853-branch-and-price-for-bus-driver-scheduling-with-complex-break-constraints/",
        "doi": "10.1609/aaai.v35i13.17408",
        "pdf_size": 162635
    },
    {
        "id": "13534",
        "title": "Bridging Towers of Multi-task Learning with a Gating Mechanism for Aspect-based Sentiment Analysis and Sequential Metaphor Identification",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-task learning (MTL) has been widely applied in Natural Language Processing. A major task and its associated auxiliary tasks share the same encoder; hence, an MTL encoder can learn the sharing abstract information between the major and auxiliary tasks. Task-specific towers are then employed upon the sharing encoder to learn task-specific information. Previous works demonstrated that exchanging information between task-specific towers yielded extra gains. This is known as soft-parameter sharing MTL. In this paper, we propose a novel gating mechanism for the bridging of MTL towers. Our method is evaluated based on aspect-based sentiment analysis and sequential metaphor identification tasks. The experiments demonstrate that our method can yield better performance than the baselines on both tasks. Based on the same Transformer backbone, we compare our gating mechanism with other information transformation mechanisms, e.g., cross-stitch, attention and vanilla gating. The experiments show that our method also surpasses these baselines.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Rui Mao; Xiao Li",
        "authorids": "",
        "aff": "Ruimao Tech, Shenzhen, China; Ruimao Tech, Shenzhen, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17596/17596-13-21090-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13534-bridging-towers-of-multi-task-learning-with-a-gating-mechanism-for-aspect-based-sentiment-analysis-and-sequential-metaphor-identification/",
        "doi": "10.1609/aaai.v35i15.17596",
        "pdf_size": 211696
    },
    {
        "id": "13970",
        "title": "Bridging the Domain Gap: Improve Informal Language Translation via Counterfactual Domain Adaptation",
        "track": "main",
        "status": "Poster",
        "abstract": "Despite the near-human performances already achieved on formal texts such as news articles, neural machine translation still has difficulty in dealing with \"user-generated\" texts that have diverse linguistic phenomena but lack large-scale high-quality parallel corpora. To address this problem, we propose a counterfactual domain adaptation method to better leverage both large-scale source-domain data (formal texts)  and small-scale target-domain data (informal texts). Specifically, by considering effective counterfactual conditions (the concatenations of source-domain texts and the target-domain tag), we construct the counterfactual representations to fill the sparse latent space of the target domain caused by a small amount of data, that is, bridging the gap between the source-domain data and the target-domain data. Experiments on English-to-Chinese and Chinese-to-English translation tasks show that our method outperforms the base model that is trained only on the informal corpus by a large margin, and consistently surpasses different baseline methods by +1.12 ~ 4.34 BLEU points on different datasets. Furthermore, we also show that our method achieves competitive performances on cross-domain language translation on four language pairs.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Ke Wang; Guandan Chen; Zhongqiang Huang; Xiaojun Wan; Fei Huang",
        "authorids": "",
        "aff": "Peking University; Alibaba Group; Alibaba Group; Peking University; Alibaba Group",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17645/17645-13-21139-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13970-bridging-the-domain-gap-improve-informal-language-translation-via-counterfactual-domain-adaptation/",
        "doi": "10.1609/aaai.v35i16.17645",
        "pdf_size": 321347
    },
    {
        "id": "00418",
        "title": "Bringing UMAP Closer to the Speed of Light with GPU Acceleration",
        "track": "main",
        "status": "Poster",
        "abstract": "",
        "primary_area": "Application Domains",
        "author": "Corey J. Nolet; Victor Lafargue; Edward Raff; Thejaswi Nanditale; Tim Oates; John Zedlewski; Joshua Patterson",
        "authorids": "",
        "aff": "",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16118/16118-13-19612-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00418-bringing-umap-closer-to-the-speed-of-light-with-gpu-acceleration/",
        "doi": "",
        "pdf_size": 182682
    },
    {
        "id": "05549",
        "title": "Budget Feasible Mechanisms Over Graphs",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper studies the budget-feasible mechanism design over graphs, where a buyer wishes to procure items from sellers, and all participants (the buyer and sellers) can only directly interact with their neighbors during the auction campaign. The problem for the buyer is to use the limited budget to incentivize sellers to propagate auction information to their neighbors, thereby more sellers will be informed of the auction and more item value will be procured. An impossibility result shows that the large-market assumption is necessary. We propose efficient budget-feasible diffusion mechanisms for large markets that simultaneously guarantee individual rationality, budget-feasibility, strong budget-balance, incentive-compatibility to report private costs and diffuse auction information. Moreover, the proposed mechanisms achieve logarithmic approximation that the total procured value is within a logarithmic factor of the optimal solution. Compared to most related budget-feasible mechanisms, which do not take the individual interactions among sellers into account, our mechanisms can incentivize sellers to further propagate auction information to other potential sellers. Meanwhile, existing related diffusion mechanisms only focus on seller-centric auctions and fail to satisfy the budget-feasibility of the buyer.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Xiang Liu; Weiwei Wu; Minming Li; Wanyuan Wang",
        "authorids": "",
        "aff": "Southeast University, Nanjing, P.R. China; Southeast University, Nanjing, P.R. China; City University of Hong Kong, Hongkong, P.R. China City University of Hong Kong Shenzhen Research Institute, Shenzhen, P.R. China; Southeast Univerity, Nanjing, P.R. China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16698/16698-13-20192-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05549-budget-feasible-mechanisms-over-graphs/",
        "doi": "10.1609/aaai.v35i6.16698",
        "pdf_size": 585696
    },
    {
        "id": "14328",
        "title": "Building Interpretable Interaction Trees for Deep NLP Models",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a method to disentangle and quantify interactions among words that are encoded inside a DNN for natural language processing. We construct a tree to encode salient interactions extracted by the DNN. Six metrics are proposed to analyze properties of interactions between constituents in a sentence. The interaction is defined based on Shapley values of words, which are considered as an unbiased estimation of word contributions to the network prediction. Our method is used to quantify word interactions encoded inside the BERT, ELMo, LSTM, CNN, and Transformer networks. Experimental results have provided a new perspective to understand these DNNs, and have demonstrated the effectiveness of our method.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Die Zhang; Hao Zhang; Huilin Zhou; Xiaoyi Bao; Da Huo; Ruizhao Chen; Xu Cheng; Mengyue Wu; Quanshi Zhang",
        "authorids": "",
        "aff": "Shanghai Jiao Tong University; Shanghai Jiao Tong University; Shanghai Jiao Tong University; Shanghai Jiao Tong University; Shanghai Jiao Tong University; Shanghai Jiao Tong University; Shanghai Jiao Tong University; Shanghai Jiao Tong University; Shanghai Jiao Tong University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17685/17685-13-21179-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14328-building-interpretable-interaction-trees-for-deep-nlp-models/",
        "doi": "10.1609/aaai.v35i16.17685",
        "pdf_size": 1653495
    },
    {
        "id": "04892",
        "title": "C-Watcher: A Framework for Early Detection of High-Risk Neighborhoods Ahead of COVID-19 Outbreak",
        "track": "main",
        "status": "Poster",
        "abstract": "The novel coronavirus disease (COVID-19) has crushed daily routines and is still rampaging through the world. Existing solution for nonpharmaceutical interventions usually needs to timely and precisely select a subset of residential urban areas for containment or even quarantine, where the spatial distribution of confirmed cases has been considered as a key criterion for the subset selection. While such containment measure has successfully stopped or slowed down the spread of COVID-19 in some countries, it is criticized for being inefficient or ineffective, as the statistics of confirmed cases are usually time-delayed and coarse-grained. To tackle the issues, we propose C-Watcher, a novel data-driven framework that aims at screening every neighborhood in a target city and predicting infection risks, prior to the spread of COVID-19 from epicenters to the city. In terms of design, C-Watcher collects large-scale long-term human mobility data from Baidu Maps, then characterizes every residential neighborhood in the city using a set of features based on urban mobility patterns. Furthermore, to transfer the firsthand knowledge (witted in epicenters) to the target city before local outbreaks, we adopt a novel adversarial encoder framework to learn \u201ccity-invariant\u201d representations from the mobility-related features for precise early detection of high-risk neighborhoods, even before any confirmed cases known, in the target city. We carried out extensive experiments on C-Watcher using the real-data records in the early stage of COVID-19 outbreaks, where the results demonstrate the efficiency and effectiveness of C-Watcher for early detection of high-risk neighborhoods from a large number of cities.",
        "primary_area": "AI Responses to the COVID-19 Pandemic",
        "author": "Congxi Xiao; Jingbo Zhou; Jizhou Huang; An Zhuo; Ji Liu; Haoyi Xiong; Dejing Dou",
        "authorids": "",
        "aff": "University of Science and Technology of China Baidu; Baidu; Baidu; Baidu; Baidu; Baidu; Baidu",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16622/16622-13-20116-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04892-c-watcher-a-framework-for-early-detection-of-high-risk-neighborhoods-ahead-of-covid-19-outbreak/",
        "doi": "10.1609/aaai.v35i6.16622",
        "pdf_size": 1321639
    },
    {
        "id": "13027",
        "title": "C2C-GenDA: Cluster-to-Cluster Generation for Data Augmentation of Slot Filling",
        "track": "main",
        "status": "Poster",
        "abstract": "Slot filling, a fundamental module of spoken language understanding, often suffers from insufficient quantity and diversity of training data. To remedy this, we propose a novel Cluster-to-Cluster generation framework for Data Augmentation (DA), named C2C-GenDA. It enlarges the training set by reconstructing existing utterances into alternative expressions while keeping semantic. Different from previous DA works that reconstruct utterances one by one independently, C2C-GenDA jointly encodes multiple existing utterances of the same semantics and simultaneously decodes multiple unseen expressions. Jointly generating multiple new utterances allows to consider the relations between generated instances and encourages diversity. Besides, encoding multiple existing utterances endows C2C with a wider view of existing expressions, helping to reduce generation that duplicates existing data. Experiments on ATIS and Snips datasets show that instances augmented by C2C-GenDA improve slot filling by 7.99 (11.9%\u2191) and 5.76 (13.6%\u2191) F-scores respectively, when there are only hundreds of training utterances. Code: https://github.com/Sanyuan-Chen/C2C-DA.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Yutai Hou; Sanyuan Chen; Wanxiang Che; Cheng Chen; Ting Liu",
        "authorids": "",
        "aff": "Harbin Institute of Technology; Harbin Institute of Technology; Research Center for Social Computing and Information Retrieval, Harbin Institute of Technology; Harbin Institute of Technology; Harbin Institute of Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17540/17540-13-21034-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13027-c2c-genda-cluster-to-cluster-generation-for-data-augmentation-of-slot-filling/",
        "doi": "10.1609/aaai.v35i14.17540",
        "pdf_size": 368581
    },
    {
        "id": "02852",
        "title": "C2F-FWN: Coarse-to-Fine Flow Warping Network for Spatial-Temporal Consistent Motion Transfer",
        "track": "main",
        "status": "Poster",
        "abstract": "Human video motion transfer (HVMT) aims to synthesize videos that one person imitates other persons' actions. Although existing GAN-based HVMT methods have achieved great success, they either fail to preserve appearance details due to the loss of spatial consistency between synthesized and exemplary images, or generate incoherent video results due to the lack of temporal consistency among video frames. In this paper, we propose Coarse-to-Fine Flow Warping Network (C2F-FWN) for spatial-temporal consistent HVMT. Particularly, C2F-FWN utilizes coarse-to-fine flow warping and Layout-Constrained Deformable Convolution (LC-DConv) to improve spatial consistency, and employs Flow Temporal Consistency (FTC) Loss to enhance temporal consistency. In addition, provided with multi-source appearance inputs, C2F-FWN can support appearance attribute editing with great flexibility and efficiency. Besides public datasets, we also collected a large-scale HVMT dataset named SoloDance for evaluation. Extensive experiments conducted on our SoloDance dataset and the iPER dataset show that our approach outperforms state-of-art HVMT methods in terms of both spatial and temporal consistency. Source code and the SoloDance dataset are available at https://github.com/wswdx/C2F-FWN.",
        "primary_area": "Computer Vision III",
        "author": "Dongxu Wei; Xiaowei Xu; Haibin Shen; Kejie Huang",
        "authorids": "",
        "aff": "Department of Information Science and Electronic Engineering, Zhejiang University; Guangdong Provincial People\u2019s Hospital, Guangdong Academy of Medical Sciences; Department of Information Science and Electronic Engineering, Zhejiang University; Department of Information Science and Electronic Engineering, Zhejiang University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16391/16391-13-19885-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02852-c2f-fwn-coarse-to-fine-flow-warping-network-for-spatial-temporal-consistent-motion-transfer/",
        "doi": "10.1609/aaai.v35i4.16391",
        "pdf_size": 1545610
    },
    {
        "id": "03225",
        "title": "CAKES: Channel-wise Automatic KErnel Shrinking for Efficient 3D Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "3D Convolution Neural Networks (CNNs) have been widely applied to 3D scene understanding, such as video analysis and volumetric image recognition. However, 3D networks can easily lead to over-parameterization which incurs expensive computation cost. In this paper, we propose Channel-wise Automatic KErnel Shrinking (CAKES), to enable efficient 3D learning by shrinking standard 3D convolutions into a set of economic operations (e.g., 1D, 2D convolutions). Unlike previous methods, CAKES performs channel-wise kernel shrinkage, which enjoys the following benefits: 1) enabling operations deployed in every layer to be heterogeneous, so that they can extract diverse and complementary information to benefit the learning process; and 2) allowing for an efficient and flexible replacement design, which can be generalized to both spatial-temporal and volumetric data. Further, we propose a new search space based on CAKES, so that the configuration can be determined automatically for simplifying 3D networks. CAKES shows superior performance to other methods with similar model size, and it also achieves comparable performance to state-of-the-art methods with much fewer parameters and computational costs on tasks including 3D medical imaging segmentation and video action recognition. Codes and models are available at https://github.com/yucornetto/CAKES",
        "primary_area": "Computer Vision III",
        "author": "Qihang Yu; Yingwei Li; Jieru Mei; Yuyin Zhou; Alan Yuille",
        "authorids": "",
        "aff": "Johns Hopkins University; Johns Hopkins University; Johns Hopkins University; Johns Hopkins University; Johns Hopkins University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16433/16433-13-19927-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03225-cakes-channel-wise-automatic-kernel-shrinking-for-efficient-3d-networks/",
        "doi": "10.1609/aaai.v35i4.16433",
        "pdf_size": 382581
    },
    {
        "id": "14577",
        "title": "CARE: Commonsense-Aware Emotional Response Generation with Latent Concepts",
        "track": "main",
        "status": "Poster",
        "abstract": "Rationality and emotion are two fundamental elements of humans. Endowing agents with rationality and emotion has been one of the major milestones in AI. However, in the field of conversational AI, most existing models only specialize in one aspect and neglect the other, which often leads to dull or unrelated responses. In this paper, we hypothesize that combining rationality and emotion into conversational agents can improve response quality. To test the hypothesis, we focus on one fundamental aspect of rationality, i.e., commonsense, and propose CARE, a novel model for commonsense-aware emotional response generation. Specifically, we first propose a framework to learn and construct commonsense-aware emotional latent concepts of the response given an input message and a desired emotion. We then propose three methods to collaboratively incorporate the latent concepts into response generation. Experimental results on two large-scale datasets support our hypothesis and show that our model can produce more accurate and commonsense-aware emotional responses and achieve better human ratings than state-of-the-art models that only specialize in one aspect.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Peixiang Zhong; Di Wang; Pengfei Li; Chen Zhang; Hao Wang; Chunyan Miao",
        "authorids": "",
        "aff": "Alibaba-NTU Singapore Joint Research Institute, Nanyang Technological University (NTU), Singapore Joint NTU-UBC Research Centre of Excellence in Active Living for the Elderly, NTU, Singapore; Joint NTU-UBC Research Centre of Excellence in Active Living for the Elderly, NTU, Singapore; School of Electrical and Electronic Engineering, NTU, Singapore; Alibaba Group, China; Alibaba Group, China; Alibaba-NTU Singapore Joint Research Institute, Nanyang Technological University (NTU), Singapore Joint NTU-UBC Research Centre of Excellence in Active Living for the Elderly, NTU, Singapore",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17713/17713-13-21207-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14577-care-commonsense-aware-emotional-response-generation-with-latent-concepts/",
        "doi": "10.1609/aaai.v35i16.17713",
        "pdf_size": 651893
    },
    {
        "id": "02346",
        "title": "CARPe Posterum: A Convolutional Approach for Real-Time Pedestrian Path Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "Pedestrian path prediction is an essential topic in computer vision and video understanding. Having insight into the movement of pedestrians is crucial for ensuring safe operation in a variety of applications including autonomous vehicles, social robots, and environmental monitoring. Current works in this area utilize complex generative or recurrent methods to capture many possible futures. However, despite the inherent real-time nature of predicting future paths, little work has been done to explore accurate and computationally efficient approaches for this task. To this end, we propose a convolutional approach for real-time pedestrian path prediction, CARPe. It utilizes a variation of Graph Isomorphism Networks in combination with an agile convolutional neural network design to form a fast and accurate path prediction approach. Notable results in both inference speed and prediction accuracy are achieved, improving FPS considerably in comparison to current state-of-the-art methods while delivering competitive accuracy on well-known path prediction datasets.",
        "primary_area": "Computer Vision II",
        "author": "Matias Mendieta; Hamed Tabkhi",
        "authorids": "",
        "aff": "University of North Carolina at Charlotte; University of North Carolina at Charlotte",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16335/16335-13-19829-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02346-carpe-posterum-a-convolutional-approach-for-real-time-pedestrian-path-prediction/",
        "doi": "10.1609/aaai.v35i3.16335",
        "pdf_size": 809210
    },
    {
        "id": "02423",
        "title": "CHEF: Cross-modal Hierarchical Embeddings for Food Domain Retrieval",
        "track": "main",
        "status": "Poster",
        "abstract": "Despite the abundance of multi-modal data, such as image-text pairs, there has been little effort in understanding the individual entities and their different roles in the construction of these data instances. In this work, we endeavour to discover the entities and their corresponding importance in cooking recipes automatically as a visual-linguistic association problem. More specifically, we introduce a novel cross-modal learning framework to jointly model the latent representations of images and text in the food image-recipe association and retrieval tasks. This model allows one to discover complex functional and hierarchical relationships between images and text, and among textual parts of a recipe including title, ingredients and cooking instructions. Our experiments show that by making use of efficient tree-structured Long Short-Term Memory as the text encoder in our computational cross-modal retrieval framework,  we are not only able to identify the main ingredients and cooking actions in the recipe descriptions without explicit supervision, but we can also learn more meaningful feature representations of food recipes, appropriate for challenging cross-modal retrieval and recipe adaption tasks.",
        "primary_area": "Computer Vision II",
        "author": "Hai X. Pham; Ricardo Guerrero; Vladimir Pavlovic; Jiatong Li",
        "authorids": "",
        "aff": "Samsung AI Center Cambridge; Samsung AI Center Cambridge; Samsung AI Center Cambridge Department of Computer Science, Rutgers University; Department of Computer Science, Rutgers University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16343/16343-13-19837-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02423-chef-cross-modal-hierarchical-embeddings-for-food-domain-retrieval/",
        "doi": "10.1609/aaai.v35i3.16343",
        "pdf_size": 496970
    },
    {
        "id": "03555",
        "title": "CIA-SSD: Confident IoU-Aware Single-Stage Object Detector From Point Cloud",
        "track": "main",
        "status": "Poster",
        "abstract": "Existing single-stage detectors for locating objects in point clouds often treat object localization and category classification as separate tasks, so the localization accuracy and classification confidence may not well align. To address this issue, we present a new single-stage detector named the Confident IoU-Aware Single-Stage object Detector (CIA-SSD). First, we design the lightweight Spatial-Semantic Feature Aggregation module to adaptively fuse high-level abstract semantic features and low-level spatial features for accurate predictions of bounding boxes and classification confidence. Also, the predicted confidence is further rectified with our designed IoU-aware confidence rectification module to make the confidence more consistent with the localization accuracy. Based on the rectified confidence, we further formulate the Distance-variant IoU-weighted NMS to obtain smoother regressions and avoid redundant predictions. We experiment CIA-SSD on 3D car detection in the KITTI test set and show that it attains top performance in terms of the official ranking metric (moderate AP 80.28%) and above 32 FPS inference speed, outperforming all prior single-stage detectors. The code is available at https://github.com/Vegeta2020/CIA-SSD.",
        "primary_area": "Computer Vision III",
        "author": "Wu Zheng; Weiliang Tang; Sijin Chen; Li Jiang; Chi-Wing Fu",
        "authorids": "",
        "aff": "The Chinese University of Hong Kong; The Chinese University of Hong Kong; The Chinese University of Hong Kong; The Chinese University of Hong Kong; The Chinese University of Hong Kong",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16470/16470-13-19964-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03555-cia-ssd-confident-iou-aware-single-stage-object-detector-from-point-cloud/",
        "doi": "10.1609/aaai.v35i4.16470",
        "pdf_size": 3390346
    },
    {
        "id": "06147",
        "title": "CMAX++ : Leveraging Experience in Planning and Execution using Inaccurate Models",
        "track": "main",
        "status": "Poster",
        "abstract": "Given access to accurate dynamical models, modern planning approaches are effective in computing feasible and optimal plans for repetitive robotic tasks. However, it is difficult to model the true dynamics of the real world before execution, especially for tasks requiring interactions with objects whose parameters are unknown. A recent planning approach, CMAX, tackles this problem by adapting the planner online during execution to bias the resulting plans away from inaccurately modeled regions. CMAX, while being provably guaranteed to reach the goal, requires strong assumptions on the accuracy of the model used for planning and fails to improve the quality of the solution over repetitions of the same task. In this paper we propose CMAX++, an approach that leverages real-world experience to improve the quality of resulting plans over successive repetitions of a robotic task. CMAX++ achieves this by integrating model-free learning using acquired experience with model-based planning using the potentially inaccurate model. We provide provable guarantees on the completeness and asymptotic convergence of CMAX++ to the optimal path cost as the number of repetitions increases. CMAX++ is also shown to outperform baselines in simulated robotic tasks including 3D mobile robot navigation where the track friction is incorrectly modeled, and a 7D pick-and-place task where the mass of the object is unknown leading to discrepancy between true and modeled dynamics.",
        "primary_area": "Intelligent Robots",
        "author": "Anirudh Vemula; J. Andrew Bagnell; Maxim Likhachev",
        "authorids": "",
        "aff": "Robotics Institute, Carnegie Mellon University; Aurora Innovation; Robotics Institute, Carnegie Mellon University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16765/16765-13-20259-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06147-cmax-leveraging-experience-in-planning-and-execution-using-inaccurate-models/",
        "doi": "10.1609/aaai.v35i7.16765",
        "pdf_size": 337337
    },
    {
        "id": "00991",
        "title": "CNN Profiler on Polar Coordinate Images for Tropical Cyclone Structure Analysis",
        "track": "main",
        "status": "Poster",
        "abstract": "Convolutional neural networks (CNN) have achieved great success in analyzing tropical cyclones (TC) with satellite images in several tasks, such as TC intensity estimation. In contrast, TC structure, which is conventionally described by a few parameters estimated subjectively by meteorology specialists, is still hard to be profiled objectively and routinely. This study applies CNN on satellite images to create the entire TC structure profiles, covering all the structural parameters. By utilizing the meteorological domain knowledge to construct TC wind profiles based on historical structure parameters, we provide valuable labels for training in our newly released benchmark dataset. With such a dataset, we hope to attract more attention to this crucial issue among data scientists. Meanwhile, a baseline is established based on a specialized convolutional model operating on polar-coordinates. We discovered that it is more feasible and physically reasonable to extract structural information on polar-coordinates, instead of Cartesian coordinates, according to a TC\u2019s rotational and spiral natures. Experimental results on the released benchmark dataset verified the robustness of the proposed model and demonstrated the potential for applying deep learning techniques for this barely developed yet important topic. For codes and implementation details, please visit https://github.com/BoyoChen/TCSA-CNN-profiler.",
        "primary_area": "Computer Vision I",
        "author": "Boyo Chen; Buo-Fu Chen; Chun Min Hsiao",
        "authorids": "",
        "aff": "National Taiwan University; National Taiwan University; National Taiwan University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16183/16183-13-19677-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00991-cnn-profiler-on-polar-coordinate-images-for-tropical-cyclone-structure-analysis/",
        "doi": "10.1609/aaai.v35i2.16183",
        "pdf_size": 2944007
    },
    {
        "id": "03154",
        "title": "CPCGAN: A Controllable 3D Point Cloud Generative Adversarial Network with Semantic Label Generating",
        "track": "main",
        "status": "Poster",
        "abstract": "Generative Adversarial Networks (GAN) are good at generating variant samples of complex data distributions. Generating a sample with certain properties is one of the major tasks in the real-world application of GANs. In this paper, we propose a novel generative adversarial network to generate 3D point clouds from random latent codes, named Controllable Point Cloud Generative Adversarial Network(CPCGAN). A two-stage GAN framework is utilized in CPCGAN and a sparse point cloud containing major structural information is extracted as the middle-level information between the two stages. With their help, CPCGAN has the ability to control the generated structure and generate 3D point clouds with semantic labels for points. Experimental results demonstrate that the proposed CPCGAN outperforms state-of-the-art point cloud GANs.",
        "primary_area": "Computer Vision III",
        "author": "Ximing Yang; Yuan Wu; Kaiyi Zhang; Cheng Jin",
        "authorids": "",
        "aff": "Fudan University; Fudan University Peng Cheng Laboratory; Fudan University; Fudan University Peng Cheng Laboratory",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16425/16425-13-19919-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03154-cpcgan-a-controllable-3d-point-cloud-generative-adversarial-network-with-semantic-label-generating/",
        "doi": "10.1609/aaai.v35i4.16425",
        "pdf_size": 8440703
    },
    {
        "id": "02764",
        "title": "Camera-Aware Proxies for Unsupervised Person Re-Identification",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper tackles the purely unsupervised person re-identification (Re-ID) problem that requires no annotations. Some previous methods adopt clustering techniques to generate pseudo labels and use the produced labels to train Re-ID models progressively. These methods are relatively simple but effective. However, most clustering-based methods take each cluster as a pseudo identity class, neglecting the large intra-ID variance caused mainly by the change of camera views. To address this issue, we propose to split each single cluster into multiple proxies and each proxy represents the instances coming from the same camera. These camera-aware proxies enable us to deal with large intra-ID variance and generate more reliable pseudo labels for learning. Based on the camera-aware proxies, we design both intra and inter-camera contrastive learning components for our Re-ID model to effectively learn the ID discrimination ability within and across cameras. Meanwhile, a proxy-balanced sampling strategy is also designed, which facilitates our learning further. Extensive experiments on three large-scale Re-ID datasets show that our proposed approach outperforms most unsupervised methods by a significant margin. Especially, on the challenging MSMT17 dataset, we gain 14.3 percent Rank-1 and 10.2 percent mAP improvements when compared to the second place. Code is available at: https://github.com/Terminator8758/CAP-master.",
        "primary_area": "Computer Vision III",
        "author": "Menglin Wang; Baisheng Lai; Jianqiang Huang; Xiaojin Gong; Xian-Sheng Hua",
        "authorids": "",
        "aff": "Zhejiang University; Alibaba Group; Alibaba Group; Zhejiang University; Alibaba Group",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16381/16381-13-19875-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02764-camera-aware-proxies-for-unsupervised-person-re-identification/",
        "doi": "10.1609/aaai.v35i4.16381",
        "pdf_size": 7551821
    },
    {
        "id": "04582",
        "title": "Capturing Delayed Feedback in Conversion Rate Prediction via Elapsed-Time Sampling",
        "track": "main",
        "status": "Poster",
        "abstract": "Conversion rate (CVR) prediction is one of the most critical tasks for digital display advertising. Commercial systems often require to update models in an online learning manner to catch up with the evolving data distribution. However, conversions usually do not happen immediately after user clicks. This may result in inaccurate labeling, which is called delayed feedback problem. In previous studies, delayed feedback problem is handled either by waiting positive label for a long period of time, or by consuming the negative sample on its arrival and then insert a positive duplicate when conversion happens later. Indeed, there is a trade-off between waiting for more accurate labels and utilizing fresh data, which is not considered in existing works. To strike a balance in this trade-off, we propose Elapsed-Time Sampling Delayed Feedback Model (ES-DFM), which models the relationship between the observed conversion distribution and the true conversion distribution. Then we optimize the expectation of true conversion distribution via importance sampling under the elapsed-time sampling distribution. We further estimate the importance weight for each instance, which is used as the weight of loss function in CVR prediction. To demonstrate the effectiveness of ES-DFM, we conduct extensive experiments on a public data and a private industrial dataset. Experimental results confirm that our method consistently outperforms the previous state-of-the-art results.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Jia-Qi Yang; Xiang Li; Shuguang Han; Tao Zhuang; De-Chuan Zhan; Xiaoyi Zeng; Bin Tong",
        "authorids": "",
        "aff": "Nanjing University; Alibaba Group; Alibaba Group; Alibaba Group; Nanjing University; Alibaba Group; Alibaba Group",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16587/16587-13-20081-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04582-capturing-delayed-feedback-in-conversion-rate-prediction-via-elapsed-time-sampling/",
        "doi": "10.1609/aaai.v35i5.16587",
        "pdf_size": 1633601
    },
    {
        "id": "00390",
        "title": "Capturing Uncertainty in Unsupervised GPS Trajectory Segmentation Using Bayesian Deep Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Intelligent transportation management requires not only statistical information on users' mobility patterns, but also knowledge of their corresponding transportation modes. While GPS trajectories can be readily obtained from GPS sensors found in modern smartphones and vehicles, these massive geospatial data are neither automatically annotated nor segmented by transportation mode, subsequently complicating transportation mode identification. In addition, predictive uncertainty caused by the learned model parameters or variable noise in GPS sensor readings typically remains unaccounted for. To jointly address the above issues, we propose a Bayesian deep learning framework for unsupervised GPS trajectory segmentation. After unlabeled GPS trajectories are preprocessed into sequences of motion features, they are used in unsupervised training of a channel-calibrated temporal convolutional neural network for timestep-level transportation mode identification. At test time, we approximate variational inference via Monte Carlo dropout sampling, leveraging the mean and variance of the predicted distributions to classify each input timestep and estimate its predictive uncertainty, respectively. The proposed approach outperforms both its non-Bayesian variant and established GPS trajectory segmentation baselines on Microsoft's Geolife dataset without using any labels.",
        "primary_area": "Application Domains",
        "author": "Christos Markos; James J. Q. Yu; Richard Yi Da Xu",
        "authorids": "",
        "aff": "Southern University of Science and Technology University of Technology Sydney; Southern University of Science and Technology; University of Technology, Sydney",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16115/16115-13-19609-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00390-capturing-uncertainty-in-unsupervised-gps-trajectory-segmentation-using-bayesian-deep-learning/",
        "doi": "10.1609/aaai.v35i1.16115",
        "pdf_size": 812214
    },
    {
        "id": "00488",
        "title": "CardioGAN: Attentive Generative Adversarial Network with Dual Discriminators for Synthesis of ECG from PPG",
        "track": "main",
        "status": "Poster",
        "abstract": "Electrocardiogram (ECG) is the electrical measurement of cardiac activity, whereas Photoplethysmogram (PPG) is the optical measurement of volumetric changes in blood circulation. While both signals are used for heart rate monitoring, from a medical perspective, ECG is more useful as it carries additional cardiac information. Despite many attempts toward incorporating ECG sensing in smartwatches or similar wearable devices for continuous and reliable cardiac monitoring, PPG sensors are the main feasible sensing solution available. In order to tackle this problem, we propose CardioGAN, an adversarial model which takes PPG as input and generates ECG as output. The proposed network utilizes an attention-based generator to learn local salient features, as well as dual discriminators to preserve the integrity of generated data in both time and frequency domains. Our experiments show that the ECG generated by CardioGAN provides more reliable heart rate measurements compared to the original input PPG, reducing the error from 9.74 beats per minute (measured from the PPG) to 2.89 (measured from the generated ECG).",
        "primary_area": "Application Domains",
        "author": "Pritam Sarkar; Ali Etemad",
        "authorids": "",
        "aff": "Queen's Univesity; Queen's University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16126/16126-13-19620-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00488-cardiogan-attentive-generative-adversarial-network-with-dual-discriminators-for-synthesis-of-ecg-from-ppg/",
        "doi": "10.1609/aaai.v35i1.16126",
        "pdf_size": 830737
    },
    {
        "id": "01123",
        "title": "Cascade Network with Guided Loss and Hybrid Attention for Finding Good Correspondences",
        "track": "main",
        "status": "Poster",
        "abstract": "Finding good correspondences is a critical prerequisite in many feature based tasks. Given a putative correspondence set of an image pair, we propose a neural network which finds correct correspondences by a binary-class classifier and estimates relative pose through classified correspondences. First, we analyze that due to the imbalance in the number of correct and wrong correspondences, the loss function has a great impact on the classification results. Thus, we propose a new Guided Loss that can directly use evaluation criterion (Fn-measure) as guidance to dynamically adjust the objective function during training. We theoretically prove that the perfect negative correlation between the Guided Loss and Fn-measure, so that the network is always trained towards the direction of increasing Fn-measure to maximize it. We then propose a hybrid attention block to extract feature, which integrates the Bayesian attentive context normalization (BACN) and channel-wise attention (CA). BACN can mine the prior information to better exploit global context and CA can capture complex channel context to enhance the channel awareness of the network. Finally, based on our Guided Loss and hybrid attention block, a cascade network is designed to gradually optimize the result for more superior performance. Experiments have shown that our network achieves the state-of-the-art performance on benchmark datasets. Our code will be available in https://github.com/wenbingtao/GLHA.",
        "primary_area": "Computer Vision I",
        "author": "Zhi Chen; Fan Yang; Wenbing Tao",
        "authorids": "",
        "aff": "Huazhong University of Science and Technology; Huazhong University of Science and Technology; Huazhong University of Science and Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16198/16198-13-19692-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01123-cascade-network-with-guided-loss-and-hybrid-attention-for-finding-good-correspondences/",
        "doi": "10.1609/aaai.v35i2.16198",
        "pdf_size": 374018
    },
    {
        "id": "06840",
        "title": "Cascade Size Distributions: Why They Matter and How to Compute Them Efficiently",
        "track": "main",
        "status": "Poster",
        "abstract": "Cascade models are central to understanding, predicting, and controlling epidemic spreading and information propagation. Related optimization, including influence maximization, model parameter inference, or the development of vaccination strategies, relies heavily on sampling from a model. This is either inefficient or inaccurate. As alternative, we present an efficient message passing algorithm that computes the probability distribution of the cascade size for the Independent Cascade Model on weighted directed networks and generalizations. Our approach is exact on trees but can be applied to any network topology. It approximates locally tree-like networks well, scales to large networks, and can lead to surprisingly good performance on more dense networks, as we also exemplify on real world data.",
        "primary_area": "Machine Learning I",
        "author": "Rebekka Burkholz; John Quackenbush",
        "authorids": "",
        "aff": "Harvard T.H. Chan School of Public Health, Boston, MA 02115; Harvard T.H. Chan School of Public Health, Boston, MA 02115 Harvard Medical School, Boston, MA 02115",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16844/16844-13-20338-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06840-cascade-size-distributions-why-they-matter-and-how-to-compute-them-efficiently/",
        "doi": "10.1609/aaai.v35i8.16844",
        "pdf_size": 2420743
    },
    {
        "id": "04794",
        "title": "Catch Me if I Can: Detecting Strategic Behaviour in Peer Assessment",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider the issue of strategic behaviour in various peer-assessment tasks, including peer grading of exams or homeworks and peer review in hiring or promotions. When a peer-assessment task is competitive (e.g., when students are graded on a curve), agents may be incentivized to misreport evaluations in order to improve their own final standing. Our focus is on designing methods  for detection of such manipulations. Specifically, we consider a setting in which agents evaluate a subset of their peers and output rankings that are later aggregated to form a final ordering. In this paper, we investigate a statistical framework for this problem and design a principled test for detecting strategic behaviour. We prove that our test has strong false alarm guarantees and evaluate its detection ability in practical settings. For this, we design and conduct an experiment that elicits strategic behaviour from subjects and release a dataset of patterns of strategic behaviour that may be of independent interest. We use this data to run a series of real and semi-synthetic evaluations that reveal a strong detection power of our test.",
        "primary_area": "AI for Conference Organization and Delivery",
        "author": "Ivan Stelmakh; Nihar B. Shah; Aarti Singh",
        "authorids": "",
        "aff": "Carnegie Mellon University; Carnegie Mellon University; Carnegie Mellon University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16611/16611-13-20105-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04794-catch-me-if-i-can-detecting-strategic-behaviour-in-peer-assessment/",
        "doi": "10.1609/aaai.v35i6.16611",
        "pdf_size": 1583163
    },
    {
        "id": "01949",
        "title": "Category Dictionary Guided Unsupervised Domain Adaptation for Object Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Unsupervised domain adaption (UDA) is a promising solution to enhance the generalization ability of a model from a source domain to a target domain without manually annotating labels for target data. Recent works in cross-domain object detection mostly resort to adversarial feature adaptation to match the marginal distributions of two domains. However, perfect feature alignment is hard to achieve and is likely to cause negative transfer due to the high complexity of object detection. In this paper, we propose a category dictionary guided (CDG) UDA model for cross-domain object detection, which learns category-specific dictionaries from the source domain to represent the candidate boxes in target domain. The representation residual can be used for not only pseudo label assignment but also quality (e.g., IoU) estimation of the candidate box. A residual weighted self-training paradigm is then developed to implicitly align source and target domains for detection model training. Compared with decision boundary based classifiers such as softmax, the proposed CDG scheme can select more informative and reliable pseudo-boxes. Experimental results on benchmark datasets show that the proposed CDG significantly exceeds the state-of-the-arts in cross-domain object detection.",
        "primary_area": "Computer Vision II",
        "author": "Shuai Li; Jianqiang Huang; Xian-Sheng Hua; Lei Zhang",
        "authorids": "",
        "aff": "The Hong Kong Polytechnic University, Hong Kong, China; Damo Academy, Alibaba Group; Damo Academy, Alibaba Group; The Hong Kong Polytechnic University, Hong Kong, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16290/16290-13-19784-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01949-category-dictionary-guided-unsupervised-domain-adaptation-for-object-detection/",
        "doi": "10.1609/aaai.v35i3.16290",
        "pdf_size": 7211324
    },
    {
        "id": "03768",
        "title": "Certifying Parity Reasoning Efficiently Using Pseudo-Boolean Proofs",
        "track": "main",
        "status": "Poster",
        "abstract": "The dramatic improvements in combinatorial optimization algorithms over the last decades have had a major impact in artificial intelligence, operations research, and beyond, but the output of current state-of-the-art solvers is often hard to verify and is sometimes wrong. For Boolean satisfiability (SAT) solvers proof logging has been introduced as a way to certify correctness, but the methods used seem hard to generalize to stronger paradigms. What is more, even for enhanced SAT techniques such as parity (XOR) reasoning, cardinality detection, and symmetry handling, it has remained beyond reach to design practically efficient proofs in the standard DRAT format. In this work, we show how to instead use pseudo-Boolean inequalities with extension variables to concisely justify XOR reasoning. Our experimental evaluation of a SAT solver integration shows a dramatic decrease in proof logging and verification time compared to existing DRAT methods. Since our method is a strict generalization of DRAT, and readily lends itself to expressing also 0-1 programming and even constraint programming problems, we hope this work points the way towards a unified approach for efficient machine-verifiable proofs for a rich class of combinatorial optimization paradigms.",
        "primary_area": "Constraint Satisfaction and Optimization",
        "author": "Stephan Gocht; Jakob Nordstr\u00f6m",
        "authorids": "",
        "aff": "Lund University, Lund, Sweden University of Copenhagen, Copenhagen, Denmark; University of Copenhagen, Copenhagen, Denmark Lund University, Lund, Sweden",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16494/16494-13-19988-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03768-certifying-parity-reasoning-efficiently-using-pseudo-boolean-proofs/",
        "doi": "10.1609/aaai.v35i5.16494",
        "pdf_size": 209895
    },
    {
        "id": "06244",
        "title": "Certifying Top-Down Decision-DNNF Compilers",
        "track": "main",
        "status": "Poster",
        "abstract": "Certifying the output of tools solving complex problems so as to ensure the correctness of the results they provide is of tremendous importance. Despite being widespread for SAT-solvers, this level of exigence has not yet percolated for tools solving more complex tasks, such as model counting or knowledge compilation. In this paper, the focus is laid on a general family of top-down Decision-DNNF compilers. We explain how those compilers can be tweaked so as to output certifiable Decision-DNNF circuits, which are mainly standard Decision-DNNF circuits decorated by annotations serving as certificates. We describe a polynomial-time checker for testing whether a given CNF\u00a0formula is equivalent or not to a given certifiable Decision-DNNF circuit. Finally, leveraging a modified version of the compiler d4 for generating certifiable Decision-DNNF circuits and an implementation of the checker, we present the results of an empirical evaluation that has been conducted for assessing how large are in practice certifiable Decision-DNNF circuits, and how much time is needed to compute and to check such circuits.",
        "primary_area": "Knowledge Representation and Reasoning",
        "author": "Florent Capelli; Jean-Marie Lagniez; Pierre Marquis",
        "authorids": "",
        "aff": "Universit\u00e9 de Lille CNRS Inria UMR 9189 - CRIStAL, F-59000 Lille; CRIL-CNRS Universit\u00e9 Artois; CRIL-CNRS Universit\u00e9 Artois Institut Universitaire de France",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16776/16776-13-20270-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06244-certifying-top-down-decision-dnnf-compilers/",
        "doi": "10.1609/aaai.v35i7.16776",
        "pdf_size": 211713
    },
    {
        "id": "09915",
        "title": "Characterizing Deep Gaussian Processes via Nonlinear Recurrence Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent advances in Deep Gaussian Processes (DGPs) show the potential to have more expressive representation than that of traditional Gaussian Processes (GPs). However, there exists a pathology of deep Gaussian processes that their learning capacities reduce significantly when the number of layers increases. In this paper, we present a new analysis in DGPs by studying its corresponding nonlinear dynamic systems to explain the issue. Existing work reports the pathology for the squared exponential kernel function. We extend our investigation to four types of common stationary kernel functions. The recurrence relations between layers are analytically derived, providing a tighter bound and the rate of convergence of the dynamic systems. We demonstrate our finding with a number of experimental results.",
        "primary_area": "Machine Learning IV",
        "author": "Anh Tong; Jaesik Choi",
        "authorids": "",
        "aff": "Ulsan National Institute of Science and Technology; Korea Advanced Institute of Science and Technology INEEJI",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17191/17191-13-20685-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09915-characterizing-deep-gaussian-processes-via-nonlinear-recurrence-systems/",
        "doi": "10.1609/aaai.v35i11.17191",
        "pdf_size": 4403236
    },
    {
        "id": "10647",
        "title": "Characterizing the Evasion Attackability of Multi-label Classifiers",
        "track": "main",
        "status": "Poster",
        "abstract": "Evasion attack in multi-label learning systems is an interesting, widely witnessed, yet rarely explored research topic. Characterizing the crucial factors determining the attackability of the multi-label adversarial threat is the key to interpret the origin of the adversarial vulnerability and to understand how to mitigate it. Our study is inspired by the theory of adversarial risk bound. We associate the attackability of a targeted multi-label classifier with the regularity of the classifier and the training data distribution. Beyond the theoretical attackability analysis, we further propose an efficient empirical attackability estimator via greedy label space exploration. It provides provably computational efficiency and approximation accuracy. Substantial experimental results on real-world datasets validate the unveiled attackability factors and the effectiveness of the proposed empirical attackability indicator.",
        "primary_area": "Machine Learning V",
        "author": "Zhuo Yang; Yufei Han; Xiangliang Zhang",
        "authorids": "",
        "aff": "King Abdullah University of Science and Technology, Thuwal, Saudi Arabia; Norton Research Group, Sophia Antipolis, France; King Abdullah University of Science and Technology, Thuwal, Saudi Arabia",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17273/17273-13-20767-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10647-characterizing-the-evasion-attackability-of-multi-label-classifiers/",
        "doi": "10.1609/aaai.v35i12.17273",
        "pdf_size": 3332697
    },
    {
        "id": "06768",
        "title": "Characterizing the Loss Landscape in Non-Negative Matrix Factorization",
        "track": "main",
        "status": "Poster",
        "abstract": "Non-negative matrix factorization (NMF) is a highly celebrated algorithm for matrix decomposition that guarantees non-negative factors. The underlying optimization problem is computationally intractable, yet in practice, gradient-descent-based methods often find good solutions. In this paper, we revisit the NMF optimization problem and analyze its loss landscape in non-worst-case settings. It has recently been observed that gradients in deep networks tend to point towards the final minimizer throughout the optimization procedure. We show that a similar property holds (with high probability) for NMF, provably in a non-worst case model with a planted solution, and empirically across an extensive suite of real-world NMF problems. Our analysis predicts that this property becomes more likely with growing number of parameters, and experiments suggest that a similar trend might also hold for deep neural networks---turning increasing dataset sizes and model sizes into a blessing from an optimization perspective.",
        "primary_area": "Machine Learning I",
        "author": "Johan Bjorck; Anmol Kabra; Kilian Q. Weinberger; Carla Gomes",
        "authorids": "",
        "aff": "Cornell University; Cornell University; Cornell University; Cornell University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16836/16836-13-20330-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06768-characterizing-the-loss-landscape-in-non-negative-matrix-factorization/",
        "doi": "10.1609/aaai.v35i8.16836",
        "pdf_size": 1049533
    },
    {
        "id": "12311",
        "title": "Choosing the Initial State for Online Replanning",
        "track": "main",
        "status": "Poster",
        "abstract": "The need to replan arises in many applications. However, in the context of planning as heuristic search, it raises an annoying problem: if the previous plan is still executing, what should the new plan search take as its initial state? If it were possible to accurately predict how long replanning would take, it would be easy to find the appropriate state at which control will transfer from the previous plan to the new one. But as planning problems can vary enormously in their difficulty, this prediction can be difficult. Many current systems merely use a manually chosen constant duration. In this paper, we show how such ad hoc solutions can be avoided by integrating the choice of the appropriate initial state into the search process itself. The search is initialized with multiple candidate initial states and a time-aware evaluation function is used to prefer plans whose total goal achievement time is minimal. Experimental results show that this approach yields better behavior than either guessing a constant or trying to predict replanning time in advance. By making replanning more effective and easier to implement, this work aids in creating planning systems that can better handle the inevitable exigencies of real-world execution.",
        "primary_area": "Search and Optimization",
        "author": "Maximilian Fickert; Ivan Gavran; Ivan Fedotov; J\u00f6rg Hoffmann; Rupak Majumdar; Wheeler Ruml",
        "authorids": "",
        "aff": "Saarland University; Max Planck Institute for Software Systems; Max Planck Institute for Software Systems; Saarland University; Max Planck Institute for Software Systems; University of New Hampshire",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17461/17461-13-20955-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12311-choosing-the-initial-state-for-online-replanning/",
        "doi": "10.1609/aaai.v35i14.17461",
        "pdf_size": 177613
    },
    {
        "id": "06471",
        "title": "ChronoR: Rotation Based Temporal Knowledge Graph Embedding",
        "track": "main",
        "status": "Poster",
        "abstract": "Despite the importance and abundance of temporal knowledge graphs, most of the current research has been focused on reasoning on static graphs. In this paper, we study the challenging problem of inference over temporal knowledge graphs. In particular, the task of temporal link prediction. In general, this is a difficult task due to data non-stationarity, data heterogeneity, and its complex temporal dependencies.  We propose Chronological Rotation embedding (ChronoR), a novel model for learning representations for entities, relations, and time. Learning dense representations is frequently used as an efficient and versatile method to perform reasoning on knowledge graphs. The proposed model learns a k-dimensional rotation transformation parametrized by relation and time, such that after each fact's head entity is transformed using the rotation, it falls near its corresponding tail entity. By using high dimensional rotation as its transformation operator, ChronoR captures rich interaction between the temporal and multi-relational characteristics of a Temporal Knowledge Graph. Experimentally, we show that ChronoR is able to outperform many of the state-of-the-art methods on the benchmark datasets for temporal knowledge graph link prediction.",
        "primary_area": "Knowledge Representation and Reasoning",
        "author": "Ali Sadeghian; Mohammadreza Armandpour; Anthony Colas; Daisy Zhe Wang",
        "authorids": "",
        "aff": "University of Florida; Texas A&M University; University of Florida; Univeresity of Florida",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16802/16802-13-20296-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06471-chronor-rotation-based-temporal-knowledge-graph-embedding/",
        "doi": "10.1609/aaai.v35i7.16802",
        "pdf_size": 1401462
    },
    {
        "id": "14472",
        "title": "Circles are like Ellipses, or Ellipses are like Circles? Measuring the Degree of Asymmetry of Static and Contextual Word Embeddings and the Implications to Representation Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Human judgments of word similarity have been a popular method of evaluating the quality of word embedding. But it fails to measure the geometry properties such as asymmetry. For example, it is more natural to say ``Ellipses are like Circles'' than ``Circles are like Ellipses''. Such asymmetry has been observed from the word evocation experiment, where one word is used to recall another. This association data have been understudied for measuring embedding quality. In this paper, we use three well-known evocation datasets for the purpose and study both static embedding as well as contextual embedding, such as BERT. To fight for the dynamic nature of BERT embedding, we probe BERT's conditional probabilities as a language model, using a large number of Wikipedia contexts to derive a theoretically justifiable Bayesian asymmetry score. The result shows that the asymmetry judgment and similarity judgments disagree, and asymmetry judgment aligns with its strong performance on ``extrinsic evaluations''. This is the first time we can show contextual embeddings's strength on intrinsic evaluation, and the asymmetry judgment provides a new perspective to evaluate contextual embedding and new insights for representation learning.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Wei Zhang; Murray Campbell; Yang Yu; Sadhana Kumaravel",
        "authorids": "",
        "aff": "IBM Research; IBM Research; Google; IBM Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17701/17701-13-21195-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14472-circles-are-like-ellipses-or-ellipses-are-like-circles-measuring-the-degree-of-asymmetry-of-static-and-contextual-word-embeddings-and-the-implications-to-representation-learning/",
        "doi": "10.1609/aaai.v35i16.17701",
        "pdf_size": 279159
    },
    {
        "id": "08601",
        "title": "Class-Attentive Diffusion Network for Semi-Supervised Classification",
        "track": "main",
        "status": "Poster",
        "abstract": "Recently, graph neural networks for semi-supervised classification have been widely studied. However, existing methods only use the information of limited neighbors and do not deal with the inter-class connections in graphs. In this paper, we propose Adaptive aggregation with Class-Attentive Diffusion (AdaCAD), a new aggregation scheme that adaptively aggregates nodes probably of the same class among K-hop neighbors. To this end, we first propose a novel stochastic process, called Class-Attentive Diffusion (CAD), that strengthens attention to intra-class nodes and attenuates attention to inter-class nodes. In contrast to the existing diffusion methods with a transition matrix determined solely by the graph structure, CAD considers both the node features and the graph structure with the design of our class-attentive transition matrix that utilizes a classifier. Then, we further propose an adaptive update scheme that leverages different reflection ratios of the diffusion result for each node depending on the local class-context. As the main advantage, AdaCAD alleviates the problem of undesired mixing of inter-class features caused by discrepancies between node labels and the graph topology. Built on AdaCAD, we construct a simple model called Class-Attentive Diffusion Network (CAD-Net). Extensive experiments on seven benchmark datasets consistently demonstrate the efficacy of the proposed method and our CAD-Net significantly outperforms the state-of-the-art methods. Code is available at https://github.com/ljin0429/CAD-Net.",
        "primary_area": "Machine Learning III",
        "author": "Jongin Lim; Daeho Um; Hyung Jin Chang; Dae Ung Jo; Jin Young Choi",
        "authorids": "",
        "aff": "Seoul National University; Seoul National University; University of Birmingham; Seoul National University; Seoul National University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17043/17043-13-20537-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08601-class-attentive-diffusion-network-for-semi-supervised-classification/",
        "doi": "10.1609/aaai.v35i10.17043",
        "pdf_size": 471905
    },
    {
        "id": "01478",
        "title": "Class-Incremental Instance Segmentation via Multi-Teacher Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Although deep neural networks have achieved amazing results on instance segmentation, they are still ill-equipped when they are required to learn new tasks incrementally. Concretely, they suffer from \u201ccatastrophic forgetting\u201d, an abrupt degradation of performance on old classes with the initial training data missing. Moreover, they are subjected to a negative transfer problem on new classes, which renders the model unable to update its knowledge while preserving the previous knowledge. To address these problems, we propose an incremental instance segmentation method that consists of three networks: Former Teacher Network (FTN), Current Student Network (CSN) and Current Teacher Network (CTN). Specifically, FTN supervises CSN to preserve the previous knowledge, and CTN supervises CSN to adapt to new classes. The supervision of two teacher networks is achieved by a distillation loss function for instances, bounding boxes, and classes. In addition, we adjust the supervision weights of different teacher networks to balance between the knowledge preservation for former classes and the adaption to new classes. Extensive experimental results on PASCAL 2012 SBD and COCO datasets show the effectiveness of the proposed method.",
        "primary_area": "Computer Vision I",
        "author": "Yanan Gu; Cheng Deng; Kun Wei",
        "authorids": "",
        "aff": "Xidian University; Xidian University; Xidian University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16238/16238-13-19732-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01478-class-incremental-instance-segmentation-via-multi-teacher-networks/",
        "doi": "10.1609/aaai.v35i2.16238",
        "pdf_size": 954109
    },
    {
        "id": "05905",
        "title": "Classification Under Human Assistance",
        "track": "main",
        "status": "Poster",
        "abstract": "Most supervised learning models are trained for full automation. However, their predictions are sometimes worse than those by human experts on some specific instances. Motivated by this empirical observation, our goal is to design classifiers that are optimized to operate under different automation levels. More specifically, we focus on convex margin-based classifiers and first show that the problem is NP-hard. Then, we further show that, for support vector machines, the corresponding objective function can be expressed as the difference of two functions f = g - c, where g is monotone, non-negative and gamma-weakly submodular, and c is non-negative and modular. This representation allows a recently introduced deterministic greedy algorithm, as well as a more efficient randomized variant of the algorithm, to enjoy approximation guarantees at solving the problem. Experiments on synthetic and real-world data from several applications in medical diagnosis illustrate our theoretical findings and demonstrate that, under human assistance, supervised learning models trained to operate under different automation levels can outperform those trained for full automation as well as humans operating alone.",
        "primary_area": "Humans and AI",
        "author": "Abir De; Nastaran Okati; Ali Zarezade; Manuel Gomez Rodriguez",
        "authorids": "",
        "aff": "IIT Bombay; MPI-SWS; MPI-SWS; MPI-SWS",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16738/16738-13-20232-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05905-classification-under-human-assistance/",
        "doi": "10.1609/aaai.v35i7.16738",
        "pdf_size": 566542
    },
    {
        "id": "05025",
        "title": "Classification by Attention: Scene Graph Classification with Prior Knowledge",
        "track": "main",
        "status": "Poster",
        "abstract": "A major challenge in scene graph classification is that the appearance of objects and relations can be significantly different from one image to another. Previous works have addressed this by relational reasoning over all objects in an image or incorporating prior knowledge into classification. Unlike previous works, we do not consider separate models for perception and prior knowledge. Instead, we take a multi-task learning approach by introducing schema representations and implementing the classification as an attention layer between image-based representations and the schemata. This allows for the prior knowledge to emerge and propagate within the perception model.\u00a0By enforcing the model also to represent the prior, we achieve a strong inductive bias. We show that our model can accurately generate commonsense knowledge and that the iterative injection of this knowledge to scene representations, as a top-down mechanism, leads to significantly higher classification performance. Additionally, our model can be fine-tuned on external knowledge given as triples. When combined with self-supervised learning and with 1% of annotated images only, this gives more than 3% improvement in object classification, 26% in scene graph classification, and 36% in predicate prediction accuracy.",
        "primary_area": "Neuro-Symbolic AI",
        "author": "Sahand Sharifzadeh; Sina Moayed Baharlou; Volker Tresp",
        "authorids": "",
        "aff": "Ludwig Maximilian University of Munich; Ludwig Maximilian University of Munich; Ludwig Maximilian University of Munich Siemens AG",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16636/16636-13-20130-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05025-classification-by-attention-scene-graph-classification-with-prior-knowledge/",
        "doi": "10.1609/aaai.v35i6.16636",
        "pdf_size": 2945700
    },
    {
        "id": "05805",
        "title": "Classification with Few Tests through Self-Selection",
        "track": "main",
        "status": "Poster",
        "abstract": "We study test-based binary classification, where a principal either accepts or rejects agents based on the outcomes they get in a set of tests.  The principal commits to a policy, which consists of all sets of outcomes that lead to acceptance.  Each agent is modeled by a distribution over the space of possible outcomes.  When an agent takes a test, he pays a cost and receives an independent sample from his distribution as the outcome.  Agents can always choose between taking another test and stopping.  They maximize their expected utility, which is the value of acceptance if the principal's policy accepts the set of outcomes they have and 0 otherwise, minus the total cost of tests taken.  We focus on the case where agents can be either \"good\" or \"bad\" (corresponding to their distribution over test outcomes), and the principal's goal is to accept good agents and reject bad ones.  We show, roughly speaking, that as long as the good and bad agents have different distributions (which can be arbitrarily close to each other), the principal can always achieve perfect accuracy, meaning good agents are accepted with probability 1, and bad ones are rejected with probability 1.  Moreover, there is a policy achieving perfect accuracy under which the maximum number of tests any agent needs to take is constant \u2014 in sharp contrast to the case where the principal directly observes samples from agents' distributions.  The key technique is to choose the policy so that agents self-select into taking tests.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Hanrui Zhang; Yu Cheng; Vincent Conitzer",
        "authorids": "",
        "aff": "Duke University; University of Illinois at Chicago; Duke University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16727/16727-13-20221-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05805-classification-with-few-tests-through-self-selection/",
        "doi": "10.1609/aaai.v35i6.16727",
        "pdf_size": 133876
    },
    {
        "id": "05514",
        "title": "Classification with Strategically Withheld Data",
        "track": "main",
        "status": "Poster",
        "abstract": "Machine learning techniques can be useful in applications such as credit approval and college admission. However, to be classified more favorably in such contexts, an agent may decide to strategically withhold some of her features, such as bad test scores.  This is a missing data problem with a twist: which data is missing depends on the chosen classifier, because the specific classifier is what may create the incentive to withhold certain feature values. We address the problem of training classifiers that are robust to this behavior.  We design three classification methods: MINCUT, Hill-Climbing (HC) and Incentive-Compatible Logistic Regression (IC-LR). We show that MINCUT is optimal when the true distribution of data is fully known. However, it can produce complex decision boundaries, and hence be prone to overfitting in some cases. Based on a characterization of truthful classifiers (i.e., those that give no incentive to strategically hide features), we devise a simpler alternative called HC which consists of a hierarchical ensemble of out-of-the-box classifiers, trained using a specialized hill-climbing procedure which we show to be convergent. For several reasons, MINCUT and HC are not effective in utilizing a large number of complementarily informative features. To this end, we present IC-LR, a modification of Logistic Regression that removes the incentive to strategically drop features. We also show that our algorithms perform well in experiments on real-world data sets, and present insights into their relative performance in different settings.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Anilesh K. Krishnaswamy; Haoming Li; David Rein; Hanrui Zhang; Vincent Conitzer",
        "authorids": "",
        "aff": "Duke University; University of Southern California; Duke University; Duke University; Duke University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16694/16694-13-20188-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05514-classification-with-strategically-withheld-data/",
        "doi": "10.1609/aaai.v35i6.16694",
        "pdf_size": 157620
    },
    {
        "id": "09386",
        "title": "Classifying Sequences of Extreme Length with Constant Memory Applied to Malware Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent works within machine learning have been tackling inputs of ever increasing size, with cyber security presenting sequence classification problems of particularly extreme lengths. In the case of Windows executable malware detection, an input executable could be >=100 MB, which would translate to a time series with T=100,000,000 steps. To date, the closest approach to handling such task is MalConv --- a convolutional neural network capable of processing T=2,000,000 steps. Because the memory used by CNNs is O(T), this has prevented many from processing all executables or further extending the MalConv approach. In this work, we develop a new approach to temporal max pooling that makes the required memory invariant to the sequence length T. This makes MalConv 116x more memory efficient, and up to 25.8x faster to train, while removing the input length restrictions to MalConv. We re-invest these gains into improving the MalConv architecture by developing a new Global Channel Gating design, giving us an attention mechanism capable of learning feature interactions across 100 million time steps in an efficient manner, a capability lacked by the original MalConv approach.",
        "primary_area": "Machine Learning IV",
        "author": "Edward Raff; William Fleshman; Richard Zak; Hyrum S. Anderson; Bobby Filar; Mark McLean",
        "authorids": "",
        "aff": "Booz Allen Hamilton Laboratory for Physical Sciences University of Maryland, Baltimore County; U.S. Military; Booz Allen Hamilton Laboratory for Physical Sciences University of Maryland, Baltimore County; Microsoft; Elastic; Laboratory for Physical Sciences",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17131/17131-13-20625-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09386-classifying-sequences-of-extreme-length-with-constant-memory-applied-to-malware-detection/",
        "doi": "10.1609/aaai.v35i11.17131",
        "pdf_size": 303107
    },
    {
        "id": "09081",
        "title": "Clinical Risk Prediction with Temporal Probabilistic Asymmetric Multi-Task Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Although recent multi-task learning methods have shown to be effective in improving the generalization of deep neural networks, they should be used with caution for safety-critical applications, such as clinical risk prediction. This is because even if they achieve improved task-average performance, they may still yield degraded performance on individual tasks, which may be critical (e.g., prediction of mortality risk). Existing asymmetric multi-task learning methods tackle this negative transfer problem by performing knowledge transfer from tasks with low loss to tasks with high loss. However, using loss as a measure of reliability is risky since low loss could result from overfitting. In the case of time-series prediction tasks, knowledge learned for one task (e.g., predicting the sepsis onset) at a specific timestep may be useful for learning another task (e.g., prediction of mortality) at a later timestep, but lack of loss at each timestep makes it difficult to measure the reliability at each timestep. To capture such dynamically changing asymmetric relationships between tasks in time-series data, we propose a novel temporal asymmetric multi-task learning model that performs knowledge transfer from certain tasks/timesteps to relevant uncertain tasks, based on the feature-level uncertainty. We validate our model on multiple clinical risk prediction tasks against various deep learning models for time-series prediction, which our model significantly outperforms without any sign of negative transfer. Further qualitative analysis of learned knowledge graphs by clinicians shows that they are helpful in analyzing the predictions of the model.",
        "primary_area": "Machine Learning III",
        "author": "A. Tuan Nguyen; Hyewon Jeong; Eunho Yang; Sung Ju Hwang",
        "authorids": "",
        "aff": "School of Computing, Korea Advanced Institute of Science and Technology, Department of Computer Science, University of Oxford; School of Computing, Korea Advanced Institute of Science and Technology; School of Computing, Korea Advanced Institute of Science and Technology, AI Graduate School, Korea Advanced Institute of Science and Technology, AITRICS; School of Computing, Korea Advanced Institute of Science and Technology, AI Graduate School, Korea Advanced Institute of Science and Technology, AITRICS",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17097/17097-13-20591-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09081-clinical-risk-prediction-with-temporal-probabilistic-asymmetric-multi-task-learning/",
        "doi": "10.1609/aaai.v35i10.17097",
        "pdf_size": 1129671
    },
    {
        "id": "14647",
        "title": "Clinical Temporal Relation Extraction with Probabilistic Soft Logic Regularization and Global Inference",
        "track": "main",
        "status": "Poster",
        "abstract": "There has been a steady need in the medical community to precisely extract the temporal relations between clinical events. In particular, temporal information can facilitate a variety of downstream applications such as case report retrieval and medical question answering. Existing methods either require expensive feature engineering or are incapable of modeling the global relational dependencies among the events. In this paper, we propose a novel method, Clinical Temporal ReLation Exaction with Probabilistic Soft Logic Regularization and Global Inference (CTRL-PG) to tackle the problem at the document level. Extensive experiments on two benchmark datasets, I2B2-2012 and TB-Dense, demonstrate that CTRL-PG significantly outperforms baseline methods for temporal relation extraction.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Yichao Zhou; Yu Yan; Rujun Han; J. Harry Caufield; Kai-Wei Chang; Yizhou Sun; Peipei Ping; Wei Wang",
        "authorids": "",
        "aff": "University of California, Los Angeles; University of California, Los Angeles; University of Southern California; University of California, Los Angeles; University of California, Los Angeles; University of California, Los Angeles; University of California, Los Angeles; University of California, Los Angeles",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17721/17721-13-21215-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14647-clinical-temporal-relation-extraction-with-probabilistic-soft-logic-regularization-and-global-inference/",
        "doi": "10.1609/aaai.v35i16.17721",
        "pdf_size": 388299
    },
    {
        "id": "10851",
        "title": "CloudLSTM: A Recurrent Neural Model for Spatiotemporal Point-cloud Stream Forecasting",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper introduces CloudLSTM, a new branch of recurrent neural models tailored to forecasting over data streams generated by geospatial point-cloud sources. We design a Dynamic Point-cloud Convolution (DConv) operator as the core component of CloudLSTMs, which performs convolution directly over point-clouds and extracts local spatial features from sets of neighboring points that surround different elements of the input. This operator maintains the permutation invariance of sequence-to-sequence learning frameworks, while representing neighboring correlations at each time step -- an important aspect in spatiotemporal predictive learning. The DConv operator resolves the grid-structural data requirements of existing spatiotemporal forecasting models and can be easily plugged into traditional LSTM architectures with sequence-to-sequence learning and attention mechanisms. We apply our proposed architecture to two representative, practical use cases that involve point-cloud streams, i.e. mobile service traffic forecasting and air quality indicator forecasting. Our results, obtained with real-world datasets collected in diverse scenarios for each use case, show that CloudLSTM delivers accurate long-term predictions, outperforming a variety of competitor neural network models.",
        "primary_area": "Machine Learning V",
        "author": "Chaoyun Zhang; Marco Fiore; Iain Murray; Paul Patras",
        "authorids": "",
        "aff": "Tencent Lightspeed & Quantum Studios; IMDEA Networks; University of Edinburgh; University of Edinburgh",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17296/17296-13-20790-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10851-cloudlstm-a-recurrent-neural-model-for-spatiotemporal-point-cloud-stream-forecasting/",
        "doi": "10.1609/aaai.v35i12.17296",
        "pdf_size": 683660
    },
    {
        "id": "07970",
        "title": "Clustering Ensemble Meets Low-rank Tensor Approximation",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper explores the problem of clustering ensemble, which aims to combine multiple base clusterings to produce better performance than that of the individual one. The existing clustering ensemble methods generally construct a co-association matrix, which indicates the pairwise similarity between samples, as the weighted linear combination of the connective matrices from different base clusterings, and the resulting co-association matrix is then adopted as the input of an off-the-shelf clustering algorithm, e.g., spectral clustering. However, the co-association matrix may be dominated by poor base clusterings, resulting in inferior performance. In this paper, we propose a novel low-rank tensor approximation based method to solve the problem from a global perspective. Specifically, by inspecting whether two samples are clustered to an identical cluster under different base clusterings, we derive a coherent-link matrix, which contains limited but highly reliable relationships between samples. We then stack the coherent-link matrix and the co-association matrix to form a three-dimensional tensor, the low-rankness property of which is further explored to propagate the information of the coherent-link matrix to the co-association matrix, producing a refined co-association matrix. We formulate the proposed method as a convex constrained optimization problem and solve it efficiently. Experimental results over 7 benchmark data sets show that the proposed model achieves a breakthrough in clustering performance, compared with 12 state-of-the-art methods. To the best of our knowledge, this is the first work to explore the potential of low-rank tensor on clustering ensemble, which is fundamentally different from previous approaches. Last but not least, our method only contains one parameter, which can be easily tuned.",
        "primary_area": "Machine Learning II",
        "author": "Yuheng Jia; Hui Liu; Junhui Hou; Qingfu Zhang",
        "authorids": "",
        "aff": "City University of Hong Kong Southeast University; City University of Hong Kong; City University of Hong Kong; City University of Hong Kong",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16972/16972-13-20466-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07970-clustering-ensemble-meets-low-rank-tensor-approximation/",
        "doi": "10.1609/aaai.v35i9.16972",
        "pdf_size": 435364
    },
    {
        "id": "13709",
        "title": "Co-GAT: A Co-Interactive Graph Attention Network for Joint Dialog Act Recognition and Sentiment Classification",
        "track": "main",
        "status": "Poster",
        "abstract": "In a dialog system, dialog act recognition and sentiment classification are two correlative tasks to capture speakers\u2019 intentions, where dialog act and sentiment can indicate the explicit and the implicit intentions separately. The dialog context information (contextual information) and the mutual interaction information are two key factors that contribute to the two related tasks. Unfortunately, none of the existing approaches consider the two important sources of information simultaneously. In this paper, we propose a Co-Interactive Graph Attention Network (Co-GAT) to jointly perform the two tasks. The core module is a proposed co-interactive graph interaction layer where a cross-utterances connection and a cross-tasks connection are constructed and iteratively updated with each other, achieving to consider the two types of information simultaneously. Experimental results on two public datasets show that our model successfully captures the two sources of information and achieve the state-of-the-art performance. In addition, we find that the contributions from the contextual and mutual interaction information do not fully overlap with contextualized word representations (BERT, Roberta, XLNet).",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Libo Qin; Zhouyang Li; Wanxiang Che; Minheng Ni; Ting Liu",
        "authorids": "",
        "aff": "Research Center for Social Computing and Information Retrieval, Harbin Institute of Technology; Research Center for Social Computing and Information Retrieval, Harbin Institute of Technology; Research Center for Social Computing and Information Retrieval, Harbin Institute of Technology; Research Center for Social Computing and Information Retrieval, Harbin Institute of Technology; Research Center for Social Computing and Information Retrieval, Harbin Institute of Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17616/17616-13-21110-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13709-co-gat-a-co-interactive-graph-attention-network-for-joint-dialog-act-recognition-and-sentiment-classification/",
        "doi": "10.1609/aaai.v35i15.17616",
        "pdf_size": 295222
    },
    {
        "id": "02800",
        "title": "Co-mining: Self-Supervised Learning for Sparsely Annotated Object Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Object detectors usually achieve promising results with the supervision of complete instance annotations. However, their performance is far from satisfactory with sparse instance annotations. Most existing methods for sparsely annotated object detection either re-weight the loss of hard negative samples or convert the unlabeled instances into ignored regions to reduce the interference of false negatives. We argue that these strategies are insufficient since they can at most alleviate the negative effect caused by missing annotations. In this  paper, we propose a simple but effective mechanism, called Co-mining, for sparsely annotated object detection. In our Co-mining, two branches of a siamese network predict the pseudo-label sets for each other. To enhance multi-view learning and better mine unlabeled instances, the original image and corresponding augmented image are used as the inputs of two branches of the siamese network, respectively. Co-mining can serve as a general training mechanism applied to most of modern object detectors. Experiments are performed on MS COCO dataset with three different sparsely annotated settings using two typical frameworks: anchor-based detector RetinaNet and anchor-free detector FCOS. Experimental results show that our Co-mining with RetinaNet achieves 1.4%\u223c2.1% improvements compared with different baselines and surpasses existing methods under the same sparsely annotated setting.",
        "primary_area": "Computer Vision III",
        "author": "Tiancai Wang; Tong Yang; Jiale Cao; Xiangyu Zhang",
        "authorids": "",
        "aff": "Megvii Technology; Megvii Technology; Tianjin University; Megvii Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16385/16385-13-19879-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02800-co-mining-self-supervised-learning-for-sparsely-annotated-object-detection/",
        "doi": "10.1609/aaai.v35i4.16385",
        "pdf_size": 1192556
    },
    {
        "id": "05603",
        "title": "Coalition Formation in Multi-defender Security Games",
        "track": "main",
        "status": "Poster",
        "abstract": "We study Stackelberg security game (SSG) with multiple defenders, where heterogeneous defenders need to allocate security resources to protect a set of targets against a strategic attacker.  In such games, coordination and cooperation between the defenders can increase their ability to protect their assets, but the heterogeneous preferences of the self-interested defenders often make such cooperation very difficult.  In this paper, we approach the problem from the perspective of cooperative game theory and study coalition formation among the defenders. Our main contribution is a number of algorithmic results for the computation problems that arise in this model. We provide a poly-time algorithm for computing a solution in the core of the game and show that all of the elements in the core are Pareto efficient. We show that the problem of computing the entire core is NP-hard and then delve into a special setting where the size of a coalition is limited up to some threshold.  We analyse the parameterized complexity of deciding if a coalition structure is in the core under this special setting, and provide a poly-time algorithm for computing successful deviation strategies for a given coalition.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Dolev Mutzari; Jiarui Gan; Sarit Kraus",
        "authorids": "",
        "aff": "Bar Ilan University; Max Planck Institute for Software Systems; Bar Ilan University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16704/16704-13-20198-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05603-coalition-formation-in-multi-defender-security-games/",
        "doi": "10.1609/aaai.v35i6.16704",
        "pdf_size": 157742
    },
    {
        "id": "14015",
        "title": "Code Completion by Modeling Flattened Abstract Syntax Trees as Graphs",
        "track": "main",
        "status": "Poster",
        "abstract": "Code completion has become an essential component of integrated development environments. Contemporary code completion methods rely on the abstract syntax tree (AST) to generate syntactically correct code. However, they cannot fully capture the sequential and repetitive patterns of writing code and the structural information of the AST. To alleviate these problems, we propose a new code completion approach named CCAG, which models the flattened sequence of a partial AST as an AST graph. CCAG uses our proposed AST Graph Attention Block to capture different dependencies in the AST graph for representation learning in code completion. The sub-tasks of code completion are optimized via multi-task learning in CCAG, and the task balance is automatically achieved using uncertainty without the need to tune task weights. The experimental results show that CCAG has superior performance than state-of-the-art approaches and it is able to provide intelligent code completion.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Yanlin Wang; Hui Li",
        "authorids": "",
        "aff": "Microsoft Research Asia; Xiamen University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17650/17650-13-21144-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14015-code-completion-by-modeling-flattened-abstract-syntax-trees-as-graphs/",
        "doi": "10.1609/aaai.v35i16.17650",
        "pdf_size": 303975
    },
    {
        "id": "04706",
        "title": "Cold-start Sequential Recommendation via Meta Learner",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper explores meta-learning in sequential recommendation to alleviate the item cold-start problem. Sequential recommendation aims to capture user's dynamic preferences based on historical behavior sequences and acts as a key component of most online recommendation scenarios. However, most previous methods have trouble recommending cold-start items, which are prevalent in those scenarios. As there is generally no side information in sequential recommendation task, previous cold-start methods could not be applied when only user-item interactions are available. Thus, we propose a Meta-learning-based Cold-Start Sequential Recommendation Framework, namely Mecos, to mitigate the item cold-start problem in sequential recommendation. This task is non-trivial as it targets at an important problem in a novel and challenging context. Mecos effectively extracts user preference from limited interactions and learns to match the target cold-start item with the potential user. Besides, our framework can be painlessly integrated with neural network-based models. Extensive experiments conducted on three real-world datasets verify the superiority of Mecos, with the average improvement up to 99%, 91%, and 70% in HR@10 over state-of-the-art baseline methods.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Yujia Zheng; Siyi Liu; Zekun Li; Shu Wu",
        "authorids": "",
        "aff": "University of Electronic Science and Technology of China; University of Electronic Science and Technology of China; Institute of Information Engineering, Chinese Academy of Sciences School of Cyber Security, University of Chinese Academy of Sciences , University of Chinese Academy of Sciences; Institute of Automation and Artificial Intelligence Research, Chinese Academy of Sciences School of Artificial Intelligence, University of Chinese Academy of Sciences",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16601/16601-13-20095-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04706-cold-start-sequential-recommendation-via-meta-learner/",
        "doi": "10.1609/aaai.v35i5.16601",
        "pdf_size": 1871906
    },
    {
        "id": "07431",
        "title": "Collaborative Group Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Collaborative learning has successfully applied knowledge transfer to guide a pool of small student networks towards robust local minima. However, previous approaches typically struggle with drastically aggravated student homogenization when the number of students rises. In this paper, we propose Collaborative Group Learning, an efficient framework that aims to diversify the feature representation and conduct an effective regularization. Intuitively, similar to the human group study mechanism, we induce students to learn and exchange different parts of course knowledge as collaborative groups. First, each student is established by randomly routing on a modular neural network, which facilitates flexible knowledge communication between students due to random levels of representation sharing and branching. Second, to resist the student homogenization, students first compose diverse feature sets by exploiting the inductive bias from sub-sets of training data, and then aggregate and distill different complementary knowledge by imitating a random sub-group of students at each time step. Overall, the above mechanisms are beneficial for maximizing the student population to further improve the model generalization without sacrificing computational efficiency. Empirical evaluations on both image and text tasks indicate that our method significantly outperforms various state-of-the-art collaborative approaches whilst enhancing computational efficiency.",
        "primary_area": "Machine Learning I",
        "author": "Shaoxiong Feng; Hongshen Chen; Xuancheng Ren; Zhuoye Ding; Kan Li; Xu Sun",
        "authorids": "",
        "aff": "School of Computer Science & Technology, Beijing Institute of Technology; JD.com; MOE Key Laboratory of Computational Linguistics, School of EECS, Peking University; JD.com; School of Computer Science & Technology, Beijing Institute of Technology; MOE Key Laboratory of Computational Linguistics, School of EECS, Peking University Center for Data Science, Peking University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16911/16911-13-20405-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07431-collaborative-group-learning/",
        "doi": "10.1609/aaai.v35i8.16911",
        "pdf_size": 2888918
    },
    {
        "id": "07262",
        "title": "Combinatorial Pure Exploration with Full-Bandit or Partial Linear Feedback",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we first study the problem of combinatorial pure exploration with full-bandit feedback (CPE-BL), where a learner is given a combinatorial action space X subseteq {0,1}^d, and in each round the learner pulls an action x in X and receives a random reward with expectation x^T theta, with theta in R^d a latent and unknown environment vector.  The objective is to identify the optimal action with the highest expected reward, using as few samples as possible. For CPE-BL, we design the first polynomial-time adaptive algorithm, whose sample complexity matches the lower bound (within a logarithmic factor) for a family of instances and has a light dependence of Delta_min (the smallest gap between the optimal action and sub-optimal actions). Furthermore, we propose a novel generalization of CPE-BL with  flexible feedback structures, called combinatorial pure exploration with partial linear feedback (CPE-PL), which encompasses several families of sub-problems including full-bandit feedback, semi-bandit feedback, partial feedback and nonlinear reward functions. In CPE-PL, each pull of action x reports a random feedback vector with expectation of M_x theta , where M_x in R^{m_x times d} is a transformation matrix for x, and gains a random (possibly nonlinear) reward related to x.  For CPE-PL, we develop the first polynomial-time algorithm, which simultaneously addresses limited feedback, general reward function and combinatorial action space (e.g., matroids, matchings and s-t paths), and provide its sample complexity analysis. Our empirical evaluation demonstrates that our algorithms run orders of magnitude faster than the existing ones, and our CPE-BL algorithm is robust across different Delta_min settings while our CPE-PL algorithm is the first one returning correct answers for nonlinear reward functions.",
        "primary_area": "Machine Learning I",
        "author": "Yihan Du; Yuko Kuroki; Wei Chen",
        "authorids": "",
        "aff": "IIIS, Tsinghua University; The University of Tokyo / RIKEN; Microsoft",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16892/16892-13-20386-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07262-combinatorial-pure-exploration-with-full-bandit-or-partial-linear-feedback/",
        "doi": "10.1609/aaai.v35i8.16892",
        "pdf_size": 359039
    },
    {
        "id": "12233",
        "title": "Combining Preference Elicitation with Local Search and Greedy Search for Matroid Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose two incremental preference elicitation methods for interactive preference-based optimization on weighted matroid structures. More precisely, for linear objective (utility) functions, we propose an interactive greedy algorithm interleaving preference queries with the incremental construction of an independent set to obtain an optimal or near-optimal base of a matroid. We also propose an interactive local search algorithm based on sequences of possibly improving exchanges for the same problem.  For both algorithms, we provide performance guarantees on the quality of the returned solutions and the number of queries.  Our algorithms are tested on the uniform, graphical and scheduling matroids to solve three different problems (committee election, spanning tree, and scheduling problems) and evaluated in terms of computation times, number of queries, and empirical error.",
        "primary_area": "Search and Optimization",
        "author": "Nawal Benabbou; Cassandre Leroy; Thibaut Lust; Patrice Perny",
        "authorids": "",
        "aff": "Sorbonne Universit\u00e9, LIP6, Paris; Sorbonne Universit\u00e9, LIP6, Paris; Sorbonne Universit\u00e9, LIP6, Paris; Sorbonne Universit\u00e9, LIP6, Paris",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17452/17452-13-20946-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12233-combining-preference-elicitation-with-local-search-and-greedy-search-for-matroid-optimization/",
        "doi": "10.1609/aaai.v35i14.17452",
        "pdf_size": 170023
    },
    {
        "id": "03677",
        "title": "Combining Reinforcement Learning and Constraint Programming for Combinatorial Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "Combinatorial optimization has found applications in numerous fields, from aerospace to transportation planning and economics. The goal is to find an optimal solution among a finite set of possibilities. The well-known challenge one faces with combinatorial optimization is the state-space explosion problem: the number of possibilities grows exponentially with the problem size, which makes solving intractable for large problems. In the last years, deep reinforcement learning (DRL) has shown its promise for designing good heuristics dedicated to solve NP-hard combinatorial optimization problems. However, current approaches have an important shortcoming:  they only provide an approximate solution with no systematic ways to improve it or to prove optimality. In another context, constraint programming (CP) is a generic tool to solve combinatorial optimization problems. Based on a complete search procedure, it will always find the optimal solution if we allow an execution time large enough. A critical design choice, that makes CP non-trivial to use in practice, is the branching decision, directing how the search space is explored. In this work, we propose a general and hybrid approach, based on DRL and CP, for solving combinatorial optimization problems. The core of our approach is based on a dynamic programming formulation, that acts as a bridge between both techniques. We experimentally show that our solver is efficient to solve three challenging problems: the traveling salesman problem with time windows, the 4-moments portfolio optimization problem, and the 0-1 knapsack problem. Results obtained show that the framework introduced outperforms the stand-alone RL and CP solutions, while being competitive with industrial solvers.",
        "primary_area": "Constraint Satisfaction and Optimization",
        "author": "Quentin Cappart; Thierry Moisan; Louis-Martin Rousseau; Isabeau Pr\u00e9mont-Schwarz; Andre A. Cire",
        "authorids": "",
        "aff": "Polytechnique Montr\u00e9al; Element AI; Polytechnique Montr\u00e9al; Element AI; University of Toronto",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16484/16484-13-19978-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03677-combining-reinforcement-learning-and-constraint-programming-for-combinatorial-optimization/",
        "doi": "10.1609/aaai.v35i5.16484",
        "pdf_size": 247027
    },
    {
        "id": "12445",
        "title": "Combining Reinforcement Learning with Lin-Kernighan-Helsgaun Algorithm for the Traveling Salesman Problem",
        "track": "main",
        "status": "Poster",
        "abstract": "We address the Traveling Salesman Problem (TSP), a famous NP-hard combinatorial optimization problem. And we propose a variable strategy reinforced approach, denoted as VSR-LKH, which combines three reinforcement learning methods (Q-learning, Sarsa and Monte Carlo) with the well-known TSP algorithm, called Lin-Kernighan-Helsgaun (LKH). VSR-LKH replaces the inflexible traversal operation in LKH, and lets the program learn to make choice at each search step by reinforcement learning. Experimental results on 111 TSP benchmarks from the TSPLIB with up to 85,900 cities demonstrate the excellent performance of the proposed method.",
        "primary_area": "Search and Optimization",
        "author": "Jiongzhi Zheng; Kun He; Jianrong Zhou; Yan Jin; Chu-Min Li",
        "authorids": "",
        "aff": "Huazhong University of Science and Technology; Huazhong University of Science and Technology; Huazhong University of Science and Technology; Huazhong University of Science and Technology; MIS, University of Picardie Jules Verne Huazhong University of Science and Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17476/17476-13-20970-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12445-combining-reinforcement-learning-with-lin-kernighan-helsgaun-algorithm-for-the-traveling-salesman-problem/",
        "doi": "10.1609/aaai.v35i14.17476",
        "pdf_size": 4223386
    },
    {
        "id": "00626",
        "title": "Commission Fee is not Enough: A Hierarchical Reinforced Framework for Portfolio Management",
        "track": "main",
        "status": "Poster",
        "abstract": "Portfolio management via reinforcement learning is at the forefront of fintech research, which explores how to optimally reallocate a fund into different financial assets over the long term by trial-and-error. Existing methods are impractical since they usually assume each reallocation can be finished immediately and thus ignoring the price slippage as part of the trading cost. To address these issues, we propose a hierarchical reinforced stock trading system for portfolio management (HRPM). Concretely, we decompose the trading process into a hierarchy of portfolio management over trade execution and train the corresponding policies. The high-level policy gives portfolio weights at a lower frequency to maximize the long-term profit and invokes the low-level policy to sell or buy the corresponding shares within a short time window at a higher frequency to minimize the trading cost. We train two levels of policies via a pre-training scheme and an iterative training scheme for data efficiency. Extensive experimental results in the U.S. market and the China market demonstrate that HRPM achieves significant improvement against many state-of-the-art approaches.",
        "primary_area": "Application Domains",
        "author": "Rundong Wang; Hongxin Wei; Bo An; Zhouyan Feng; Jun Yao",
        "authorids": "",
        "aff": "Nanyang Technological University; Nanyang Technological University; Nanyang Technological University; WeBank Co. Ltd.; WeBank Co. Ltd.",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16142/16142-13-19636-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00626-commission-fee-is-not-enough-a-hierarchical-reinforced-framework-for-portfolio-management/",
        "doi": "10.1609/aaai.v35i1.16142",
        "pdf_size": 3678851
    },
    {
        "id": "06393",
        "title": "Commonsense Knowledge Augmentation for Low-Resource Languages via Adversarial Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Commonsense reasoning is one of the ultimate goals of artificial intelligence research because it simulates the human thinking process. However, most commonsense reasoning studies have focused on English because available commonsense knowledge for low-resource languages is scarce due to high construction costs. Translation is one of the typical methods for augmenting data for low-resource languages; however, translation entails ambiguity problems, where one word can be translated into multiple words due to polysemes and homonyms. Previous studies have suggested methods to measure the validity of translated multiple triples by using additional metadata and manually labeled data. However, such handcrafted datasets are not available for many low-resource languages. In this paper, we propose a knowledge augmentation method using adversarial networks that does not require any labeled data. Our adversarial networks can transfer knowledge learned from a resource-rich language to low-resource languages and thus measure the validity score of translated triples even without labeled data. We designed experiments to demonstrate that high-scoring triples obtained by the proposed model can be considered augmented knowledge. The experimental results show that our proposed method for a low-resource language, Korean, achieved 93.7% precision@1 on a manually labeled benchmark. Furthermore, to verify our model for other low-resource languages, we introduced new test sets for knowledge validation in 16 different languages. Our adversarial model obtains strong results for all language test sets. We will release the augmented Korean knowledge and test sets for 16 languages.",
        "primary_area": "Knowledge Representation and Reasoning",
        "author": "Bosung Kim; Juae Kim; Youngjoong Ko; Jungyun Seo",
        "authorids": "",
        "aff": "Sungkyunkwan University; Sogang University Hyundai Motor Group; Sungkyunkwan University; Sogang University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16793/16793-13-20287-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06393-commonsense-knowledge-augmentation-for-low-resource-languages-via-adversarial-learning/",
        "doi": "10.1609/aaai.v35i7.16793",
        "pdf_size": 526777
    },
    {
        "id": "00999",
        "title": "Commonsense Knowledge Aware Concept Selection For Diverse and Informative Visual Storytelling",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual storytelling is a task of generating relevant and interesting stories for given image sequences. In this work we aim at increasing the diversity of the generated stories while preserving the informative content from the images. We propose to foster the diversity and informativeness of a generated story by using a concept selection module that suggests a set of concept candidates. Then, we utilize a large scale pre-trained model to convert concepts and images into full stories. To enrich the candidate concepts, a commonsense knowledge graph is created for each image sequence from which the concept candidates are proposed. To obtain appropriate concepts from the graph, we propose two novel modules that consider the correlation among candidate concepts and the image-concept correlation. Extensive automatic and human evaluation results demonstrate that our model can produce reasonable concepts. This enables our model to outperform the previous models by a large margin on the diversity and informativeness of the story, while retaining the relevance of the story to the image sequence.",
        "primary_area": "Computer Vision I",
        "author": "Hong Chen; Yifei Huang; Hiroya Takamura; Hideki Nakayama",
        "authorids": "",
        "aff": "The University of Tokyo, Japan National Institute of Advanced Industrial Science and Technology, Japan; The University of Tokyo, Japan; Tokyo Institute of Technology, Japan National Institute of Advanced Industrial Science and Technology, Japan; The University of Tokyo National Institute of Advanced Industrial Science and Technology, Japan",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16184/16184-13-19678-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00999-commonsense-knowledge-aware-concept-selection-for-diverse-and-informative-visual-storytelling/",
        "doi": "10.1609/aaai.v35i2.16184",
        "pdf_size": 2306751
    },
    {
        "id": "06786",
        "title": "Communication-Aware Collaborative Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Algorithms for noiseless collaborative PAC learning have been analyzed and optimized in recent years with respect to sample complexity. In this paper, we study collaborative PAC learning with the goal of reducing communication cost at essentially no penalty to the sample complexity. We develop communication efficient collaborative PAC learning algorithms using distributed boosting. We then consider the communication cost of collaborative learning in the presence of classification noise. As an intermediate step, we show how collaborative PAC learning algorithms can be adapted to handle classification noise. With this insight, we develop communication efficient algorithms for collaborative PAC learning robust to classification noise.",
        "primary_area": "Machine Learning I",
        "author": "Avrim Blum; Shelby Heinecke; Lev Reyzin",
        "authorids": "",
        "aff": "Toyota Technological Institute at Chicago; Salesforce Research; University of Illinois at Chicago",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16838/16838-13-20332-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06786-communication-aware-collaborative-learning/",
        "doi": "10.1609/aaai.v35i8.16838",
        "pdf_size": 135774
    },
    {
        "id": "10405",
        "title": "Communication-Efficient Frank-Wolfe Algorithm for Nonconvex Decentralized Distributed Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Recently decentralized optimization attracts much attention in machine learning because it is more communication-efficient than the centralized fashion. Quantization is a promising method to reduce the communication cost via cutting down the budget of each single communication using the gradient compression. To further improve the communication efficiency, more recently, some quantized decentralized algorithms have been studied. However, the quantized decentralized algorithm for nonconvex constrained machine learning problems is still limited. Frank-Wolfe (a.k.a., conditional gradient or projection-free) method is very efficient to solve many constrained optimization tasks, such as low-rank or sparsity-constrained models training. In this paper, to fill the gap of decentralized quantized constrained optimization, we propose a novel communication-efficient Decentralized Quantized Stochastic Frank-Wolfe (DQSFW) algorithm for non-convex constrained learning models. We first design a new counterexample to show that the vanilla decentralized quantized stochastic Frank-Wolfe algorithm usually diverges. Thus, we propose DQSFW algorithm with the gradient tracking technique to guarantee the method will converge to the stationary point of non-convex optimization safely. In our theoretical analysis, we prove that to achieve the stationary point our DQSFW algorithm achieves the same gradient complexity as the standard stochastic Frank-Wolfe and centralized Frank-Wolfe algorithms, but has much less communication cost. Experiments on matrix completion and model compression applications demonstrate the efficiency of our new algorithm.",
        "primary_area": "Machine Learning V",
        "author": "Wenhan Xian; Feihu Huang; Heng Huang",
        "authorids": "",
        "aff": "University of Pittsburgh; University of Pittsburgh; University of Pittsburgh JD Finance America Corporation",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17246/17246-13-20740-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10405-communication-efficient-frank-wolfe-algorithm-for-nonconvex-decentralized-distributed-learning/",
        "doi": "10.1609/aaai.v35i12.17246",
        "pdf_size": 350667
    },
    {
        "id": "04294",
        "title": "Communicative Message Passing for Inductive Relation Reasoning",
        "track": "main",
        "status": "Poster",
        "abstract": "Relation prediction for knowledge graphs aims at predicting missing relationships between entities. Despite the importance of inductive relation prediction, most previous works are limited to a transductive setting and cannot process previously unseen entities. The recent proposed subgraph-based relation reasoning models provided alternatives to predict links from the subgraph structure surrounding a candidate triplet inductively. However, we observe that these methods often neglect the directed nature of the extracted subgraph and weaken the role of relation information in the subgraph modeling. As a result, they fail to effectively handle the asymmetric/anti-symmetric triplets and produce insufficient embeddings for the target triplets. To this end, we introduce a Communicative Message Passing neural network for Inductive reLation rEasoning, CoMPILE, that reasons over local directed subgraph structures and has a vigorous inductive bias to process entity-independent semantic relations. In contrast to existing models, CoMPILE strengthens the message interactions between edges and entitles through a communicative kernel and enables a sufficient flow of relation information. Moreover, we demonstrate that CoMPILE can naturally handle asymmetric/anti-symmetric relations without the need for explosively increasing the number of model parameters by extracting the directed enclosing subgraphs. Extensive experiments show substantial performance gains in comparison to state-of-the-art methods on commonly used benchmark datasets with variant inductive settings.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Sijie Mai; Shuangjia Zheng; Yuedong Yang; Haifeng Hu",
        "authorids": "",
        "aff": "School of Electronic and Information Technology, Sun Yat-sen University; Sun Yat-sen University; Sun Yat-sen University; School of Electronics and Information Technology, Sun Yat-Sen University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16554/16554-13-20048-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04294-communicative-message-passing-for-inductive-relation-reasoning/",
        "doi": "10.1609/aaai.v35i5.16554",
        "pdf_size": 550953
    },
    {
        "id": "00320",
        "title": "Community-Aware Multi-Task Transportation Demand Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "Transportation demand prediction is of great importance to urban governance and has become an essential function in many online applications. While many efforts have been made for regional transportation demand prediction, predicting the diversified transportation demand for different communities (e.g., the aged, the juveniles) remains an unexplored problem. However, this task is challenging because of the joint influence of spatio-temporal correlation among regions and implicit correlation among different communities. To this end, in this paper, we propose the Multi-task Spatio-Temporal Network with Mutually-supervised Adaptive task grouping (Ada-MSTNet) for community-aware transportation demand prediction.  Specifically, we first construct a sequence of multi-view graphs from both spatial and community perspectives, and devise a spatio-temporal neural network to simultaneously capture the sophisticated correlations between regions and communities, respectively. Then, we propose an adaptively clustered multi-task learning module,  where the prediction of each region-community specific transportation demand is regarded as distinct task. Moreover, a mutually supervised adaptive task grouping strategy is introduced to softly cluster each task into different task groups, by leveraging the supervision signal from one another graph view. In such a way, Ada-MSTNet is not only able to share common knowledge among highly related communities and regions, but also shield the noise from unrelated tasks in an end-to-end fashion. Finally, extensive experiments on two real-world datasets demonstrate the effectiveness of our approach compared with seven baselines.",
        "primary_area": "Application Domains",
        "author": "Hao Liu; Qiyu Wu; Fuzhen Zhuang; Xinjiang Lu; Dejing Dou; Hui Xiong",
        "authorids": "",
        "aff": "Baidu Research, Beijing, China; Baidu Research, Beijing, China, Peking University, China; Key Lab of IIP of Chinese Academy of Sciences (CAS), ICT, CAS, Beijing 100190, China University of Chinese Academy of Sciences, Beijing 100049, China; Baidu Research, Beijing, China; Baidu Research, Beijing, China; Rutgers University, USA",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16107/16107-13-19601-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00320-community-aware-multi-task-transportation-demand-prediction/",
        "doi": "10.1609/aaai.v35i1.16107",
        "pdf_size": 8038106
    },
    {
        "id": "01361",
        "title": "CompFeat: Comprehensive Feature Aggregation for Video Instance Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "Video instance segmentation is a complex task in which we need to detect, segment, and track each object for any given video. Previous approaches only utilize single-frame features for the detection, segmentation, and tracking of objects and they suffer in the video scenario due to several distinct challenges such as motion blur and drastic appearance change. To eliminate ambiguities introduced by only using single-frame features, we propose a novel comprehensive feature aggregation approach (CompFeat) to refine features atboth frame-level and object-level with temporal and spatial context information. The aggregation process is carefully designed with a new attention mechanism which significantly increases the discriminative power of the learned features. We further improve the tracking capability of our model through a siamese design by incorporating both feature similarities and spatial similarities. Experiments conducted on the YouTube-VIS dataset validate the effectiveness of proposed CompFeat.",
        "primary_area": "Computer Vision I",
        "author": "Yang Fu; Linjie Yang; Ding Liu; Thomas S. Huang; Humphrey Shi",
        "authorids": "",
        "aff": "University of Illinois at Urbana-Champaign; ByteDance Inc.; Bytedance Inc.; University of Illinois at Urbana-Champaign; University of Illinois at Urbana-Champaign University of Oregon",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16225/16225-13-19719-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01361-compfeat-comprehensive-feature-aggregation-for-video-instance-segmentation/",
        "doi": "10.1609/aaai.v35i2.16225",
        "pdf_size": 11329670
    },
    {
        "id": "12034",
        "title": "Competitive Analysis for Two-Level Ski-Rental Problem",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we study a two-level ski-rental problem. There are multiple commodities, each one can be \u201crented\u201d (paying for on-demand usage) or \u201cpurchased\u201d (paying for life-time usage). There is also a combo purchase available so that all commodities can be purchased as a combo. Since the usages of the commodities in future are not known in advance, to minimize the overall cost, we design an online algorithm to decide if we rent a commodity, purchase a commodity, or make a combo purchase. We first propose a deterministic online algorithm. It can achieve 3 competitive ratio, which is optimal and tight. Next, we further propose a randomized online algorithm, leading to a e^\u03c3/(e^\u03c3-1) competitive ratio, where \u03c3 is the ratio between the price of a single commodity and the price of combo purchase. Finally, we apply simulation to verify the theoretical competitive ratios and evaluate the actual performance against benchmarks.",
        "primary_area": "Planning, Routing, and Scheduling",
        "author": "Binghan Wu; Wei Bao; Dong Yuan",
        "authorids": "",
        "aff": "The University of Sydney; The University of Sydney; The University of Sydney",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17429/17429-13-20923-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12034-competitive-analysis-for-two-level-ski-rental-problem/",
        "doi": "10.1609/aaai.v35i13.17429",
        "pdf_size": 3857030
    },
    {
        "id": "04098",
        "title": "Complete Closed Time Intervals-Related Patterns Mining",
        "track": "main",
        "status": "Poster",
        "abstract": "Using temporal abstraction, various forms of sampled multivariate temporal data can be transformed into a uniform representation of symbolic time intervals, from which Time Intervals Related Patterns (TIRPs) can be then discovered. Hence, mining TIRPs from symbolic time intervals offers a comprehensive framework for heterogeneous multivariate temporal data analysis. While the field of time intervals mining has gained a growing interest in recent decades, frequent closed TIRPs mining was not investigated in its full complexity. Mining frequent closed TIRPs is highly effective due to the discovery of a compact set of frequent TIRPs, which contains the complete information of all the frequent TIRPs. However, as we demonstrate in this paper, the recent advancements made in closed TIRPs discovery are incomplete, due to the discovery of only the first instances of the TIRPs within each STIs series in the database. In this paper we introduce the TIRPClo algorithm \u2013 for complete and efficient mining of frequent closed TIRPs. The algorithm utilizes a memory-efficient index and a novel method for data projection, due to which it is the first algorithm to guarantee a complete discovery of frequent closed TIRPs. In addition, a rigorous runtime comparison of TIRPClo to state-of-the-art methods is performed, demonstrating a significant speed-up on various real-world datasets.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Omer David Harel; Robert Moskovitch",
        "authorids": "",
        "aff": "Ben-Gurion University of the Negev; Ben-Gurion University of the Negev",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16531/16531-13-20025-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04098-complete-closed-time-intervals-related-patterns-mining/",
        "doi": "10.1609/aaai.v35i5.16531",
        "pdf_size": 2895168
    },
    {
        "id": "00223",
        "title": "Complex Coordinate-Based Meta-Analysis with Probabilistic Programming",
        "track": "main",
        "status": "Poster",
        "abstract": "With the growing number of published functional magnetic resonance imaging (fMRI) studies, meta-analysis databases and models have become an integral part of brain mapping research. Coordinate-based meta-analysis (CBMA) databases are built by extracting both coordinates of reported peak activations and term associations using natural language processing techniques from neuroimaging studies. Solving term-based queries on these databases makes it possible to obtain statistical maps of the brain related to specific cognitive processes. However, existing tools for analysing CBMA data are limited in their expressivity to propositional logic, restricting the variety of their queries. Moreover, with tools like Neurosynth, term-based queries on multiple terms often lead to power failure, because too few studies from the database contribute to the statistical estimations. We design a probabilistic domain-specific language (DSL) standing on Datalog and one of its probabilistic extensions, CP-Logic, for expressing and solving complex logic-based queries. We show how CBMA databases can be encoded as probabilistic programs. Using the joint distribution of their Bayesian network translation, we show that solutions of queries on these programs compute the right probability distributions of voxel activations. We explain how recent lifted query processing algorithms make it possible to scale to the size of large neuroimaging data, where knowledge compilation techniques fail to solve queries fast enough for practical applications. Finally, we introduce a method for relating studies to terms probabilistically, leading to better solutions for two-term conjunctive queries (CQs) on smaller databases. We demonstrate results for two-term CQs, both on simulated meta-analysis databases and on the widely used Neurosynth database.",
        "primary_area": "Application Domains",
        "author": "Valentin Iovene; Gaston E Zanitti; Demian Wassermann",
        "authorids": "",
        "aff": "Inria, CEA, Universit\u00e9 Paris-Saclay, Palaiseau, France; Inria, CEA, Universit\u00e9 Paris-Saclay, Palaiseau, France; Inria, CEA, Universit\u00e9 Paris-Saclay, Palaiseau, France",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16096/16096-13-19590-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00223-complex-coordinate-based-meta-analysis-with-probabilistic-programming/",
        "doi": "10.1609/aaai.v35i1.16096",
        "pdf_size": 191392
    },
    {
        "id": "05575",
        "title": "Complexity and Algorithms for Exploiting Quantal Opponents in Large Two-Player Games",
        "track": "main",
        "status": "Poster",
        "abstract": "Solution concepts of traditional game theory assume entirely rational players; therefore, their ability to exploit subrational opponents is limited. One type of subrationality that describes human behavior well is the quantal response. While there exist algorithms for computing solutions against quantal opponents, they either do not scale or may provide strategies that are even worse than the entirely-rational Nash strategies. This paper aims to analyze and propose scalable algorithms for computing effective and robust strategies against a quantal opponent in normal-form and extensive-form games. Our contributions are:  (1) we define two different solution concepts related to exploiting quantal opponents and analyze their properties;  (2) we prove that computing these solutions is computationally hard; (3) therefore, we evaluate several heuristic approximations based on scalable counterfactual regret minimization (CFR); and (4) we identify a CFR variant that exploits the bounded opponents better than the previously used variants while being less exploitable by the worst-case perfectly-rational opponent.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "David Milec; Jakub \u010cern\u00fd; Viliam Lis\u00fd; Bo An",
        "authorids": "",
        "aff": "Czech Technical University; Nanyang Technological University; Czech Technical University; Nanyang Technological University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16701/16701-13-20195-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05575-complexity-and-algorithms-for-exploiting-quantal-opponents-in-large-two-player-games/",
        "doi": "10.1609/aaai.v35i6.16701",
        "pdf_size": 516522
    },
    {
        "id": "08884",
        "title": "Composite Adversarial Attacks",
        "track": "main",
        "status": "Poster",
        "abstract": "Adversarial attack is a technique for deceiving Machine Learning (ML) models, which provides a way to evaluate the adversarial robustness. In practice, attack algorithms are artificially selected and tuned by human experts to break a ML system. However, manual selection of attackers tends to be sub-optimal, leading to a mistakenly assessment of model security. In this paper, a new procedure called Composite Adversarial Attack (CAA) is proposed for automatically searching the best combination of attack algorithms and their hyper-parameters from a candidate pool of 32 base attackers. We design a search space where attack policy is represented as an attacking sequence, i.e., the output of the previous attacker is used as the initialization input for successors. Multi-objective NSGA-II genetic algorithm is adopted for finding the strongest attack policy with minimum complexity. The experimental result shows CAA beats 10 top attackers on 11 diverse defenses with less elapsed time (6 \u00d7 faster than AutoAttack), and achieves the new state-of-the-art on linf, l2 and unrestricted adversarial attacks.",
        "primary_area": "Machine Learning III",
        "author": "Xiaofeng Mao; Yuefeng Chen; Shuhui Wang; Hang Su; Yuan He; Hui Xue",
        "authorids": "",
        "aff": "Alibaba Group; Alibaba Group; Inst. of Comput. Tech., CAS; Tsinghua Univiersity; Alibaba Group; Alibaba Group",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17075/17075-13-20569-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08884-composite-adversarial-attacks/",
        "doi": "10.1609/aaai.v35i10.17075",
        "pdf_size": 352222
    },
    {
        "id": "00178",
        "title": "Compound Word Transformer: Learning to Compose Full-Song Music over Dynamic Directed Hypergraphs",
        "track": "main",
        "status": "Poster",
        "abstract": "To apply neural sequence models such as the Transformers to music generation tasks, one has to represent a piece of music by a sequence of tokens drawn from a finite set of pre-defined vocabulary. Such a vocabulary usually involves tokens of various types. For example, to describe a musical note, one needs separate tokens to indicate the note\u2019s pitch, duration, velocity (dynamics), and placement (onset time) along the time grid. While different types of tokens may possess different properties, existing models usually treat them equally, in the same way as modeling words in natural languages. In this paper, we present a conceptually different approach that explicitly takes into account the type of the tokens, such as note types and metric types. And, we propose a new Transformer decoder architecture that uses different feed-forward heads to model tokens of different types. With an expansion-compression trick, we convert a piece of music to a sequence of compound words by grouping neighboring tokens, greatly reducing the length of the token sequences. We show that the resulting model can be viewed as a learner over dynamic directed hypergraphs. And, we employ it to learn to compose expressive Pop piano music of full-song length (involving up to 10K individual tokens per song), both conditionally and unconditionally. Our experiment shows that, compared to state-of-the-art models, the proposed model converges 5 to 10 times faster at training (i.e., within a day on a single GPU with 11 GB memory), and with comparable quality in the generated music",
        "primary_area": "Application Domains",
        "author": "Wen-Yi Hsiao; Jen-Yu Liu; Yin-Cheng Yeh; Yi-Hsuan Yang",
        "authorids": "",
        "aff": "Taiwan AI Labs; Taiwan AI Labs; Taiwan AI Labs; Academia Sinica",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16091/16091-13-19585-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00178-compound-word-transformer-learning-to-compose-full-song-music-over-dynamic-directed-hypergraphs/",
        "doi": "10.1609/aaai.v35i1.16091",
        "pdf_size": 412823
    },
    {
        "id": "11622",
        "title": "Comprehension and Knowledge",
        "track": "main",
        "status": "Poster",
        "abstract": "The ability of an agent to comprehend a sentence is tightly connected to the agent's prior experiences and background knowledge. The paper suggests to interpret comprehension as a modality and proposes a complete bimodal logical system that describes an interplay between comprehension and knowledge modalities.",
        "primary_area": "Philosophy and Ethics of AI",
        "author": "Pavel Naumov; Kevin Ros",
        "authorids": "",
        "aff": "King's College; University of Illinois at Urbana-Champaign",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17382/17382-13-20876-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11622-comprehension-and-knowledge/",
        "doi": "10.1609/aaai.v35i13.17382",
        "pdf_size": 196338
    },
    {
        "id": "08235",
        "title": "Compressing Deep Convolutional Neural Networks by Stacking Low-dimensional Binary Convolution Filters",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep Convolutional Neural Networks (CNN) have been successfully applied to many real-life problems. However, the huge memory cost of deep CNN models poses a great challenge of deploying them on memory-constrained devices (e.g., mobile phones). One popular way to reduce the memory cost of deep CNN model is to train binary CNN where the weights in convolution filters are either 1 or -1 and therefore each weight can be efficiently stored using a single bit. However, the compression ratio of existing binary CNN models is upper bounded by  \u223c 32. To address this limitation, we propose a novel method to compress deep CNN model by stacking low-dimensional binary convolution filters. Our proposed method approximates a standard convolution filter by selecting and stacking filters from a set of low-dimensional binary convolution filters. This set of low-dimensional binary convolution filters is shared across all filters for a given convolution layer. Therefore, our method will achieve much larger compression ratio than binary CNN models. In order to train our proposed model, we have theoretically shown that our proposed model is equivalent to select and stack intermediate feature maps generated by low-dimensional binary filters. Therefore,  our proposed model can be efficiently trained using the split-transform-merge strategy. We also provide detailed analysis of the memory and computation cost of our model in model inference. We compared the proposed method with other five popular model compression techniques on two benchmark datasets. Our experimental results have demonstrated that our proposed method achieves much higher compression ratio than existing methods while maintains comparable accuracy.",
        "primary_area": "Machine Learning II",
        "author": "Weichao Lan; Liang Lan",
        "authorids": "",
        "aff": "Hong Kong Baptist University; Hong Kong Baptist University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17002/17002-13-20496-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08235-compressing-deep-convolutional-neural-networks-by-stacking-low-dimensional-binary-convolution-filters/",
        "doi": "10.1609/aaai.v35i9.17002",
        "pdf_size": 430364
    },
    {
        "id": "05294",
        "title": "Computational Analyses of the Electoral College: Campaigning Is Hard But Approximately Manageable",
        "track": "main",
        "status": "Poster",
        "abstract": "In the classical discrete Colonel Blotto game\u2014introduced by Borel in 1921\u2014two colonels simultaneously distribute their troops across multiple battlefields. The winner of each battlefield is determined by a winner-take-all rule, independently of other battlefields. In the original formulation, each colonel\u2019s goal is to win as many battlefields as possible. The Blotto game and its extensions have been used in a wide range of applications from political campaign\u2014exemplified by the U.S presidential election\u2014to marketing campaign, from (innovative) technology competition to sports competition. Despite persistent efforts, efficient methods for finding the optimal strategies in Blotto games have been elusive for almost a century\u2014due to exponential explosion in the organic solution space\u2014until Ahmadinejad, Dehghani, Hajiaghayi, Lucier, Mahini, and Seddighin developed the first polynomial-time algorithm for this fundamental gametheoretical problem in 2016. However, that breakthrough polynomial-time solution has some structural limitation. It applies only to the case where troops are homogeneous with respect to battlegruounds, as in Borel\u2019s original formulation: For each battleground, the only factor that matters to the winner\u2019s payoff is how many troops as opposed to which sets of troops are opposing one another in that battleground.   In this paper, we consider a more general setting of the two-player-multi-battleground game, in which multifaceted resources (troops) may have different contributions to different battlegrounds. In the case of U.S presidential campaign, for example, one may interpret this as different types of resources\u2014human, financial, political\u2014that teams can invest in each state. We provide a complexity-theoretical evidence that, in contrast to Borel\u2019s homogeneous setting, finding optimal strategies in multifaceted Colonel Blotto games is intractable. We complement this complexity result with a polynomial-time algorithm that finds approximately optimal strategies with provable guarantees. We also study a further generalization when two competitors do not have zerosum/ constant-sum payoffs. We show that optimal strategies in these two-player-multi-battleground games are as hard to compute and approximate as Nash equilibria in general noncooperative  games and economic equilibria in exchange markets.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Sina Dehghani; Hamed Saleh; Saeed Seddighin; Shang-Hua Teng",
        "authorids": "",
        "aff": "Institute for Research in Fundamental Sciences; University of Maryland; Toyota Technological Institute; University of Southern California",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16668/16668-13-20162-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05294-computational-analyses-of-the-electoral-college-campaigning-is-hard-but-approximately-manageable/",
        "doi": "10.1609/aaai.v35i6.16668",
        "pdf_size": 318185
    },
    {
        "id": "07133",
        "title": "Computationally Tractable Riemannian Manifolds for Graph Embeddings",
        "track": "main",
        "status": "Poster",
        "abstract": "Representing graphs as sets of node embeddings in certain curved Riemannian manifolds has recently gained momentum in machine learning due to their desirable geometric inductive biases (e.g., hierarchical structures benefit from hyperbolic geometry). However, going beyond embedding spaces of constant sectional curvature, while potentially more representationally powerful, proves to be challenging as one can easily lose the appeal of computationally tractable tools such as geodesic distances or Riemannian gradients. Here, we explore two computationally efficient matrix manifolds, showcasing how to learn and optimize graph embeddings in these Riemannian spaces. Empirically, we demonstrate consistent improvements over Euclidean geometry while often outperforming hyperbolic and elliptical embeddings based on various metrics that capture different graph properties. Our results serve as new evidence for the benefits of non-Euclidean embeddings in machine learning pipelines.",
        "primary_area": "Machine Learning I",
        "author": "Calin Cruceru; Gary Becigneul; Octavian-Eugen Ganea",
        "authorids": "",
        "aff": "ETH Zurich; ETH Zurich MIT; ETH Zurich MIT",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16877/16877-13-20371-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07133-computationally-tractable-riemannian-manifolds-for-graph-embeddings/",
        "doi": "10.1609/aaai.v35i8.16877",
        "pdf_size": 15389963
    },
    {
        "id": "05813",
        "title": "Computing Ex Ante Coordinated Team-Maxmin Equilibria in Zero-Sum Multiplayer Extensive-Form Games",
        "track": "main",
        "status": "Poster",
        "abstract": "Computational game theory has many applications in the modern world in both adversarial situations and the optimization of social good. While there exist many algorithms for computing solutions in two-player interactions, finding optimal strategies in multiplayer interactions efficiently remains an open challenge. This paper focuses on computing the multiplayer Team-Maxmin Equilibrium with Coordination device (TMECor) in zero-sum extensive-form games. TMECor models  scenarios when a team of players coordinates ex ante against an adversary. Such situations can be found in card games (e.g., in Bridge and Poker), when a team works together to beat a target player but communication is prohibited; and also in real world, e.g., in forest-protection operations, when coordinated groups have limited contact during interdicting illegal loggers. The existing algorithms struggle to find a TMECor efficiently because of their high computational costs. To compute a TMECor in larger games, we make the following key contributions: (1) we propose a hybrid-form strategy representation for the team, which preserves the set of equilibria; (2) we introduce a column-generation algorithm with a guaranteed finite-time convergence in the infinite strategy space  based on a novel best-response oracle; (3) we develop an associated-representation technique for the exact representation of the multilinear terms in the best-response oracle; and (4) we experimentally show that our algorithm is several orders of magnitude faster than prior state-of-the-art algorithms in large games.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Youzhi Zhang; Bo An; Jakub \u010cern\u00fd",
        "authorids": "",
        "aff": "Nanyang Technological University; Nanyang Technological University; Nanyang Technological University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16728/16728-13-20222-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05813-computing-ex-ante-coordinated-team-maxmin-equilibria-in-zero-sum-multiplayer-extensive-form-games/",
        "doi": "10.1609/aaai.v35i6.16728",
        "pdf_size": 239783
    },
    {
        "id": "11709",
        "title": "Computing Plan-Length Bounds Using Lengths of Longest Paths",
        "track": "main",
        "status": "Poster",
        "abstract": "We devise a method to exactly compute the length of the longest simple path in factored state spaces, like state spaces encountered in classical planning. Although the complexity of this problem is NEXP-Hard, we show that our method can be used to compute practically useful upper-bounds on lengths of plans. We show that the computed upper-bounds are significantly better than bounds produced by state-of-the-art bounding techniques and that they can be used to improve the SAT-based planning.",
        "primary_area": "Planning, Routing, and Scheduling",
        "author": "Mohammad Abdulaziz,Dominik Berger",
        "authorids": "",
        "aff": "Technische Universit\u00e4t M\u00fcnchen,Technische Universit\u00e4t M\u00fcnchen",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17392/17392-13-20886-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11709-computing-plan-length-bounds-using-lengths-of-longest-paths/",
        "doi": "10.1609/aaai.v35i13.17392",
        "pdf_size": 731566
    },
    {
        "id": "05260",
        "title": "Computing Quantal Stackelberg Equilibrium in Extensive-Form Games",
        "track": "main",
        "status": "Poster",
        "abstract": "Deployments of game-theoretic solution concepts in the real world have highlighted the necessity to consider human opponents' boundedly rational behavior. If subrationality is not addressed, the system can face significant losses in terms of expected utility. While there exist algorithms for computing optimal strategies to commit to when facing subrational decision-makers in one-shot interactions, these algorithms cannot be generalized for solving sequential scenarios because of the inherent curse of strategy-space dimensionality in sequential games and because humans act subrationally in each decision point separately. We study optimal strategies to commit to against subrational opponents in sequential games for the first time and make the following key contributions: (1) we prove the problem is NP-hard in general; (2) to enable further analysis, we introduce a non-fractional reformulation of the direct non-concave representation of the equilibrium;  (3) we identify conditions under which the problem can be approximated in polynomial time in the size of the representation; (4) we show how an MILP can approximate the reformulation with a guaranteed bounded error, and (5) we experimentally demonstrate that our algorithm provides higher quality results several orders of magnitude faster than a baseline method for general non-linear optimization.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Jakub \u010cern\u00fd; Viliam Lis\u00fd; Branislav Bo\u0161ansk\u00fd; Bo An",
        "authorids": "",
        "aff": "Nanyang Technological University; Czech Technical University in Prague; Czech Technical University in Prague; Nanyang Technological University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16664/16664-13-20158-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05260-computing-quantal-stackelberg-equilibrium-in-extensive-form-games/",
        "doi": "10.1609/aaai.v35i6.16664",
        "pdf_size": 184727
    },
    {
        "id": "06636",
        "title": "Computing an Efficient Exploration Basis for Learning with Univariate Polynomial Features",
        "track": "main",
        "status": "Poster",
        "abstract": "Barycentric spanners have been used as an efficient exploration basis in online linear optimization problems in a bandit framework. We characterise the barycentric spanner for decision problems in which the cost (or reward) is a polynomial in a single decision variable. Our characterisation of the barycentric spanner is two-fold: we show that the barycentric spanner under a polynomial cost function is the unique solution to a set of nonlinear algebraic equations, as well as the solution to a convex optimization problem. We provide numerical results to show that our method computes the barycentric spanner for the polynomial case significantly faster than the only other known algorithm for the purpose. As an application, we consider a dynamic pricing problem in which the revenue is an unknown polynomial function of the price.  We then empirically show that the use of a barycentric spanner to initialise the prior distribution in a Thompson sampling setting leads to lower cumulative regret as compared to standard initialisations. We also illustrate the importance of barycentric spanners in adversarial settings by showing, both theoretically and empirically, that a barycentric spanner achieves the minimax value in a static adversarial linear regression problem where the learner selects the training points while an adversary selects the testing points and controls the variance of the noise corrupting the training samples",
        "primary_area": "Machine Learning I",
        "author": "Chaitanya Amballa; Manu K. Gupta; Sanjay P. Bhat",
        "authorids": "",
        "aff": "TCS Research, Hyderabad, India; Department of Management Studies, Indian Institute of Technology, Roorkee, India; TCS Research, Hyderabad, India",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16821/16821-13-20315-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06636-computing-an-efficient-exploration-basis-for-learning-with-univariate-polynomial-features/",
        "doi": "10.1609/aaai.v35i8.16821",
        "pdf_size": 465290
    },
    {
        "id": "05489",
        "title": "Computing the Proportional Veto Core",
        "track": "main",
        "status": "Poster",
        "abstract": "In social choice there often arises a conflict between the majority principle (the search for a candidate that is as good as possible for as many voters as possible), and the protection of minority rights (choosing a candidate that is not overly bad for particular individuals or groups). In a context where the latter is our main concern, veto-based rules -- giving individuals or groups the ability to strike off certain candidates from the list -- are a natural and effective way of ensuring that no minority is left with an outcome they find untenable. However, such rules often fail to be anonymous, or impose specific restrictions on the number of voters and candidates. These issues can be addressed by considering the proportional veto core -- the solution to a cooperative game where every coalition is given the power to veto a number of candidates proportional to its size. However, the naive algorithm for the veto core is exponential, and the only known rules for selecting from the veto core, with an arbitrary number of voters, violate either anonymity or neutrality. In this paper we present a polynomial time algorithm for computing the veto core and present a neutral and anonymous algorithm for selecting a candidate from it. We also show that a pessimist can manipulate the veto core in polynomial time.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Egor Ianovski; Aleksei Y. Kondratev",
        "authorids": "",
        "aff": "HSE University; HSE University Institute for Regional Economic Studies RAS",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16691/16691-13-20185-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05489-computing-the-proportional-veto-core/",
        "doi": "10.1609/aaai.v35i6.16691",
        "pdf_size": 136579
    },
    {
        "id": "13683",
        "title": "Conceptualized and Contextualized Gaussian Embedding",
        "track": "main",
        "status": "Poster",
        "abstract": "Word embedding can represent a word as a point vector or a Gaussian distribution in high-dimensional spaces. Gaussian distribution is innately more expressive than point vector owing to the ability to additionally capture semantic uncertainties of words, and thus can express asymmetric relations among words more naturally (e.g., animal entails cat but not the reverse. However, previous Gaussian embedders neglect inner-word conceptual knowledge and lack tailored Gaussian contextualizer, leading to inferior performance on both intrinsic (context-agnostic) and extrinsic (context-sensitive) tasks. In this paper, we first propose a novel Gaussian embedder which explicitly accounts for inner-word conceptual units (sememes) to represent word semantics more precisely; during learning, we propose Gaussian Distribution Attention over Gaussian representations to adaptively aggregate multiple sememe distributions into a word distribution, which guarantees the Gaussian linear combination property. Additionally, we propose a Gaussian contextualizer to utilize outer-word contexts in a sentence, producing contextualized Gaussian representations for context-sensitive tasks. Extensive experiments on intrinsic and extrinsic tasks demonstrate the effectiveness of the proposed approach, achieving state-of-the-art performance with near 5.00% relative improvement.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Chen Qian; Fuli Feng; Lijie Wen; Tat-Seng Chua",
        "authorids": "",
        "aff": "Tsinghua University; National University of Singapore; Tsinghua University; National university of Singapore",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17613/17613-13-21107-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13683-conceptualized-and-contextualized-gaussian-embedding/",
        "doi": "10.1609/aaai.v35i15.17613",
        "pdf_size": 225069
    },
    {
        "id": "06227",
        "title": "Conditional Inference under Disjunctive Rationality",
        "track": "main",
        "status": "Poster",
        "abstract": "The question of conditional inference, i.e., of which conditional sentences of the form ``if A then, normally, B'' should follow from a set KB of such sentences, has been one of the classic questions of AI, with several well-known solutions proposed. Perhaps the most notable is the rational closure construction of Lehmann and Magidor, under which the set of inferred conditionals forms a rational consequence relation, i.e., satisfies all the rules of preferential reasoning, *plus* Rational Monotonicity. However, this last named rule is not universally accepted, and other researchers have advocated working within the larger class of *disjunctive* consequence relations, which satisfy the weaker requirement of Disjunctive Rationality. While there are convincing arguments that the rational closure forms the ``simplest'' rational consequence relation extending a given set of conditionals, the question of what is the simplest *disjunctive* consequence relation has not been explored. In this paper, we propose a solution to this question and explore some of its properties.",
        "primary_area": "Knowledge Representation and Reasoning",
        "author": "Richard Booth; Ivan Varzinczak",
        "authorids": "",
        "aff": "Cardiff University, United Kingdom; CRIL, Univ. d\u2019Artois & CNRS, France CAIR, Computer Science Division, Stellenbosch University, South Africa ISTI-CNR, Italy",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16774/16774-13-20268-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06227-conditional-inference-under-disjunctive-rationality/",
        "doi": "10.1609/aaai.v35i7.16774",
        "pdf_size": 148846
    },
    {
        "id": "05407",
        "title": "Condorcet Relaxation In Spatial Voting",
        "track": "main",
        "status": "Poster",
        "abstract": "Consider a set of voters V, represented by a multiset in a metric space (X,d). The voters have to reach a decision - a point in X. A choice p\u2208 X is called a \u03b2-plurality point for V, if for any other choice q\u2208 X it holds that |{v\u2208 V \u2223\u00a0 \u03b2\u22c5 d(p,v)\u2264 d(q,v)}|\u00a0\u2265|V|/2 . In other words, at least half of the voters ``prefer'' over q, when an extra factor of \u03b2 is taken in favor of p.  For \u03b2=1, this is equivalent to Condorcet winner, which rarely exists. The concept of \u03b2-plurality was suggested by Aronov, de Berg, Gudmundsson, and Horton [SoCG 2020] as a relaxation of the Condorcet criterion.   Denote by \u03b2*(X,d) the value sup{ \u03b2 \u2223\u00a0 every finite multiset V in X admits a \u03b2-plurality point}}. The parameter \u03b2* determines the amount of relaxation required in order to reach a stable decision. Aronov et al. showed that for the Euclidean plane \u03b2*(\u211d2,|\u22c5|2)=\u221a3/2 , and more generally, for d-dimensional Euclidean space, 1/\u221ad \u2264 \u03b2*(\u211dd,|\u22c5|2)\u2264\u221a3/2 .  In this paper, we show that 0.557\u2264 \u03b2*(\u211dd,|\u22c5|2) for any dimension d (notice that 1/\u221ad",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Arnold Filtser; Omrit Filtser",
        "authorids": "",
        "aff": "Columbia University; Stony Brook University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16681/16681-13-20175-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05407-condorcet-relaxation-in-spatial-voting/",
        "doi": "10.1609/aaai.v35i6.16681",
        "pdf_size": 241917
    },
    {
        "id": "02835",
        "title": "Confidence-aware Non-repetitive Multimodal Transformers for TextCaps",
        "track": "main",
        "status": "Poster",
        "abstract": "When describing an image, reading text in the visual scene is crucial to understand the key information. Recent work explores the TextCaps task, i.e. image captioning with reading Optical Character Recognition (OCR) tokens, which requires models to read text and cover them in generated captions. Existing approaches fail to generate accurate descriptions because of their (1) poor reading ability; (2) inability to choose the crucial words among all extracted OCR tokens; (3) repetition of words in predicted captions. To this end, we propose a Confidence-aware Non-repetitive Multimodal Transformers (CNMT) to tackle the above challenges. Our CNMT consists of a reading, a reasoning and a generation modules, in which Reading Module employs better OCR systems to enhance text reading ability and a confidence embedding to select the most noteworthy tokens. To address the issue of word redundancy in captions, our Generation Module includes a repetition mask to avoid predicting repeated word in captions. Our model outperforms state-of-the-art models on TextCaps dataset, improving from 81.0 to 93.0 in CIDEr. Our source code is publicly available.",
        "primary_area": "Computer Vision III",
        "author": "Zhaokai Wang; Renda Bao; Qi Wu; Si Liu",
        "authorids": "",
        "aff": "Beihang University; Alibaba Group; University of Adelaide; Beihang University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16389/16389-13-19883-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02835-confidence-aware-non-repetitive-multimodal-transformers-for-textcaps/",
        "doi": "10.1609/aaai.v35i4.16389",
        "pdf_size": 2588882
    },
    {
        "id": "12738",
        "title": "Consecutive Decoding for Speech-to-text Translation",
        "track": "main",
        "status": "Poster",
        "abstract": "Speech-to-text translation (ST), which directly translates the source language speech to the target language text, has attracted intensive attention recently. However, the combination of speech recognition and machine translation in a single model poses a heavy burden on the direct cross-modal cross-lingual mapping. To reduce the learning difficulty, we propose COnSecutive Transcription and Translation (COSTT), an integral approach for speech-to-text translation. The key idea is to generate source transcript and target translation text with a single decoder. It benefits the model training so that additional large parallel text corpus can be fully exploited to enhance the speech translation training. Our method is verified on three mainstream datasets, including Augmented LibriSpeech English-French dataset, TED English-German dataset, and TED English-Chinese dataset. Experiments show that our proposed COSTT outperforms the previous state-of-the-art methods. The code is available at https://github.com/dqqcasia/st.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Qianqian Dong; Mingxuan Wang; Hao Zhou; Shuang Xu; Bo Xu; Lei Li",
        "authorids": "",
        "aff": "Institute of Automation, Chinese Academy of Sciences, China School of Artificial Intelligence, University of Chinese Academy of Sciences, China; ByteDance AI Lab, China; ByteDance AI Lab, China; Institute of Automation, Chinese Academy of Sciences, China; Institute of Automation, Chinese Academy of Sciences, China School of Artificial Intelligence, University of Chinese Academy of Sciences, China; ByteDance AI Lab, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17508/17508-13-21002-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12738-consecutive-decoding-for-speech-to-text-translation/",
        "doi": "10.1609/aaai.v35i14.17508",
        "pdf_size": 1186084
    },
    {
        "id": "03394",
        "title": "Consensus Graph Representation Learning for Better Grounded Image Captioning",
        "track": "main",
        "status": "Poster",
        "abstract": "The contemporary visual captioning models frequently hallucinate objects that are not actually in a scene, due to the visual misclassification or over-reliance on priors that resulting in the semantic inconsistency between the visual information and the target lexical words. The most common way is to encourage the captioning model to dynamically link generated object words or phrases to appropriate regions of the image, i.e., the grounded image captioning (GIC). However, GIC utilizes an auxiliary task (grounding objects) that has not solved the key issue of object hallucination, i.e., the semantic inconsistency. In this paper, we take a novel perspective on the issue above: exploiting the semantic coherency between the visual and language modalities. Specifically, we propose the Consensus Rraph Representation Learning framework (CGRL) for GIC that incorporates a consensus representation into the grounded captioning pipeline. The consensus is learned by aligning the visual graph (e.g., scene graph) to the language graph that   consider both the nodes and edges in a graph. With the aligned consensus, the captioning model can capture both the correct linguistic characteristics and visual relevance, and then grounding appropriate image regions further. We validate the effectiveness of our model, with a significant decline in object hallucination (-9% CHAIRi) on the Flickr30k Entities dataset. Besides, our CGRL also evaluated by several automatic metrics and human evaluation, the results indicate that the proposed approach can simultaneously improve the performance of image captioning (+2.9 Cider) and  grounding (+2.3 F1LOC}).",
        "primary_area": "Computer Vision III",
        "author": "Wenqiao Zhang; Haochen Shi; Siliang Tang; Jun Xiao; Qiang Yu; Yueting Zhuang",
        "authorids": "",
        "aff": "Zhejiang University; Zhejiang University; Zhejiang University; Zhejiang University; City Cloud Technology (China\uff09; Zhejiang University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16452/16452-13-19946-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03394-consensus-graph-representation-learning-for-better-grounded-image-captioning/",
        "doi": "10.1609/aaai.v35i4.16452",
        "pdf_size": 2988934
    },
    {
        "id": "10138",
        "title": "Consistency Regularization with High-dimensional Non-adversarial Source-guided Perturbation for Unsupervised Domain Adaptation in Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "Unsupervised domain adaptation for semantic segmentation has been intensively studied due to the low cost of the pixel-level annotation for synthetic data. The most common approaches try to generate images or features mimicking the distribution in the target domain while preserving the semantic contents in the source domain so that a model can be trained with annotations from the latter. However, such methods highly rely on an image translator or feature extractor trained in an elaborated mechanism including adversarial training, which brings in extra complexity and instability in the adaptation process. Furthermore, these methods mainly focus on taking advantage of the labeled source dataset, leaving the unlabeled target dataset not fully utilized. In this paper, we propose a bidirectional style-induced domain adaptation method, called BiSIDA, that employs consistency regularization to efficiently exploit information from the unlabeled target domain dataset, requiring only a simple neural style transfer model. BiSIDA aligns domains by not only transferring source images into the style of target images but also transferring target images into the style of source images to perform high-dimensional perturbation on the unlabeled target images, which is crucial to the success in applying consistency regularization in segmentation tasks. Extensive experiments show that our BiSIDA achieves new state-of-the-art on two commonly-used synthetic-to-real domain adaptation benchmarks: GTA5-to-CityScapes and SYNTHIA-to-CityScapes. Code and pretrained style transfer model are available at: https://github.com/wangkaihong/BiSIDA.",
        "primary_area": "Machine Learning IV",
        "author": "Kaihong Wang; Chenhongyi Yang; Margrit Betke",
        "authorids": "",
        "aff": "Boston University; Boston University; Boston University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17216/17216-13-20710-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10138-consistency-regularization-with-high-dimensional-non-adversarial-source-guided-perturbation-for-unsupervised-domain-adaptation-in-segmentation/",
        "doi": "10.1609/aaai.v35i11.17216",
        "pdf_size": 2074101
    },
    {
        "id": "08967",
        "title": "Consistency and Finite Sample Behavior of Binary Class Probability Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "We investigate to which extent one can recover class probabilities within the empirical risk minimization (ERM) paradigm. We extend existing results and emphasize the tight relations between empirical risk minimization and class probability estimation. Following previous literature on excess risk bounds and proper scoring rules, we derive a class probability estimator based on empirical risk minimization. We then derive conditions under which this estimator will converge with high probability to the true class probabilities with respect to the L1-norm. One of our core contributions is a novel way to derive finite sample L1-convergence rates of this estimator for different surrogate loss functions. We also study in detail which commonly used loss functions are suitable for this estimation problem and briefly address the setting of model-misspecification.",
        "primary_area": "Machine Learning III",
        "author": "Alexander Mey; Marco Loog",
        "authorids": "",
        "aff": "Delft University of Technology; Delft University of Technology University of Copenhagen",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17084/17084-13-20578-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08967-consistency-and-finite-sample-behavior-of-binary-class-probability-estimation/",
        "doi": "10.1609/aaai.v35i10.17084",
        "pdf_size": 228591
    },
    {
        "id": "06084",
        "title": "Consistent Right-Invariant Fixed-Lag Smoother with Application to Visual Inertial SLAM",
        "track": "main",
        "status": "Poster",
        "abstract": "State estimation problems without absolute position measurements routinely arise in navigation of unmanned aerial vehicles,  autonomous ground vehicles, etc., whose proper operation relies on  accurate state estimates and reliable covariances. Unaware of absolute positions, these problems have immanent unobservable directions. Traditional causal estimators, however, usually gain spurious information  on the unobservable directions, leading to over-confident covariance inconsistent with actual estimator errors. The consistency problem of fixed-lag smoothers (FLSs)  has only been attacked by the first estimate Jacobian (FEJ) technique because  of the complexity to analyze their observability property. But the FEJ has several drawbacks hampering its wide adoption. To ensure the consistency of a FLS, this paper introduces the right invariant error formulation into the FLS framework. To our knowledge,  we are the first to analyze the observability of a FLS with the right invariant error. Our main contributions are twofold. As the first novelty, to bypass the complexity of analysis with the classic  observability matrix, we show that observability analysis of FLSs can be done equivalently on the linearized system. Second, we prove that the inconsistency issue in the traditional FLS can be elegantly solved by the right invariant error formulation without artificially correcting Jacobians. By applying the proposed FLS to the monocular visual inertial simultaneous localization and mapping (SLAM) problem, we confirm that the method consistently estimates covariance similarly to a batch smoother in simulation and that our method achieved comparable accuracy as traditional FLSs on real data.",
        "primary_area": "Intelligent Robots",
        "author": "Jianzhu Huai; Yukai Lin; Yuan Zhuang; Min Shi",
        "authorids": "",
        "aff": "Wuhan University; ETH Zurich; Wuhan University; Florida Atlantic University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16758/16758-13-20252-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06084-consistent-right-invariant-fixed-lag-smoother-with-application-to-visual-inertial-slam/",
        "doi": "10.1609/aaai.v35i7.16758",
        "pdf_size": 1105346
    },
    {
        "id": "01531",
        "title": "Consistent-Separable Feature Representation for Semantic Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "Cross-entropy loss combined with softmax is one of the most commonly used supervision components in most existing segmentation methods. The softmax loss is typically good at optimizing the inter-class difference, but not good at reducing the intra-class variation, which can be suboptimal for semantic segmentation task. In this paper, we propose a Consistent-Separable Feature Representation Network to model the Consistent-Separable (C-S) features, which are intra-class consistent and inter-class separable, improving the discriminative power of the deep features. Specifically, we develop a Consistent-Separable Feature Learning Module to obtain C-S features through a new loss, called Class-Aware Consistency loss. This loss function is proposed to force the deep features to be consistent among the same class and apart between different classes. Moreover, we design an Adaptive feature Aggregation Module to fuse the C-S features and original features from backbone for the better semantic prediction. We show that compared with various baselines, the proposed method brings consistent performance improvement. Our proposed approach achieves state-of-the-art performance on Cityscapes (82.6% mIoU in test set), ADE20K (46.65% mIoU in validation set), COCO Stuff (41.3% mIoU in validation set) and PASCAL Context (55.9% mIoU in test set).",
        "primary_area": "Computer Vision I",
        "author": "Xingjian He; Jing Liu; Jun Fu; Xinxin Zhu; Jinqiao Wang; Hanqing Lu",
        "authorids": "",
        "aff": "School of Artificial Intelligence, University of Chinese Academy of Sciences National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences; School of Artificial Intelligence, University of Chinese Academy of Sciences National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences; School of Artificial Intelligence, University of Chinese Academy of Sciences National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16244/16244-13-19738-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01531-consistent-separable-feature-representation-for-semantic-segmentation/",
        "doi": "10.1609/aaai.v35i2.16244",
        "pdf_size": 605884
    },
    {
        "id": "11718",
        "title": "Constrained Risk-Averse Markov Decision Processes",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider the problem of designing policies for Markov decision processes (MDPs) with dynamic coherent risk objectives and constraints. We begin by formulating the problem in a Lagrangian framework. Under the assumption that the risk objectives and constraints can be represented by a Markov risk transition mapping, we propose an optimization-based method to synthesize Markovian policies that lower-bound the constrained risk-averse problem.  We demonstrate that the formulated optimization problems are in the form of difference convex programs (DCPs) and can be solved by the disciplined convex-concave programming (DCCP) framework. We show that these results generalize linear programs for constrained MDPs with total discounted expected costs and constraints. Finally, we illustrate the effectiveness of the proposed method with numerical experiments on a rover navigation problem involving conditional-value-at-risk (CVaR) and entropic-value-at-risk (EVaR) coherent risk measures.",
        "primary_area": "Planning, Routing, and Scheduling",
        "author": "Mohamadreza Ahmadi; Ugo Rosolia; Michel D. Ingham; Richard M. Murray; Aaron D. Ames",
        "authorids": "",
        "aff": "California Institute of Technology, 1200 E. California Blvd., Pasadena, CA 91125; California Institute of Technology, 1200 E. California Blvd., Pasadena, CA 91125; NASA Jet Propulsion Laboratory, 4800 Oak Grove Dr, Pasadena, CA 91109; California Institute of Technology, 1200 E. California Blvd., Pasadena, CA 91125; California Institute of Technology, 1200 E. California Blvd., Pasadena, CA 91125",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17393/17393-13-20887-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11718-constrained-risk-averse-markov-decision-processes/",
        "doi": "10.1609/aaai.v35i13.17393",
        "pdf_size": 1289516
    },
    {
        "id": "06358",
        "title": "Constraint Logic Programming for Real-World Test Laboratory Scheduling",
        "track": "main",
        "status": "Poster",
        "abstract": "The Test Laboratory Scheduling Problem (TLSP) and its subproblem TLSP-S are real-world industrial scheduling problems that are extensions of the Resource-Constrained Project Scheduling Problem (RCPSP). Besides several additional constraints, TLSP includes a grouping phase where the jobs to be scheduled have to be assembled from smaller tasks and derive their properties from this grouping. For TLSP-S such a grouping is already part of the input.  In this work, we show how TLSP-S can be solved by Answer-set Programming extended with ideas from other constraint solving paradigms. We propose a novel and efficient encoding and apply an answer-set solver for constraint logic programs called clingcon. Additionally, we utilize our encoding in a Very Large Neighborhood Search framework and compare our methods with the state of the art approaches. Our approach provides new upper bounds and optimality proofs for several existing benchmark instances in the literature.",
        "primary_area": "Knowledge Representation and Reasoning",
        "author": "Tobias Geibinger; Florian Mischek; Nysret Musliu",
        "authorids": "",
        "aff": "TU Wien; TU Wien; TU Wien",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16789/16789-13-20283-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06358-constraint-logic-programming-for-real-world-test-laboratory-scheduling/",
        "doi": "10.1609/aaai.v35i7.16789",
        "pdf_size": 164487
    },
    {
        "id": "07908",
        "title": "Constructing a Fair Classifier with Generated Fair Data",
        "track": "main",
        "status": "Poster",
        "abstract": "Fairness in machine learning is getting rising attention as it is directly related to real-world applications and social problems. Recent methods have been explored to alleviate the discrimination between certain demographic groups that are characterized by sensitive attributes (such as race, age, or gender). Some studies have found that the data itself is biased, so training directly on the data causes unfair decision making. Models directly trained on raw data can replicate or even exacerbate bias in the prediction between demographic groups. This leads to vastly different prediction performance in different demographic groups. In order to address this issue, we propose a new approach to improve machine learning fairness by generating fair data. We introduce a generative model to generate cross-domain samples w.r.t. multiple sensitive attributes. This ensures that we can generate infinite number of samples that are balanced wrt both target label and sensitive attributes to enhance fair prediction. By training the classifier solely with the synthetic data and then transfer the model to real data, we can overcome the under-representation problem which is non-trivial since collecting real data is extremely time and resource consuming. We provide empirical evidence to demonstrate the benefit of our model with respect to both fairness and accuracy.",
        "primary_area": "Machine Learning II",
        "author": "Taeuk Jang; Feng Zheng; Xiaoqian Wang",
        "authorids": "",
        "aff": "Purdue University; Southern University of Science and Technology; Purdue University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16965/16965-13-20459-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07908-constructing-a-fair-classifier-with-generated-fair-data/",
        "doi": "10.1609/aaai.v35i9.16965",
        "pdf_size": 730228
    },
    {
        "id": "06021",
        "title": "Content Learning with Structure-Aware Writing: A Graph-Infused Dual Conditional Variational Autoencoder for Automatic Storytelling",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent automatic storytelling methods mainly rely on keyword planning or plot skeleton generation to model long-range dependencies and create consistent narrative texts. However, these approaches generate story plans or plots sequentially, leaving the non-sequential conception and structural design processes of human writers unexplored. To mimic human writers and exploit the fine-grained, intrinsic structural information of each story, we decompose automatic story generation into sub-problems of graph construction, graph generation, and graph-infused sequence generation. Specifically, we propose a graph-infused dual conditional variational autoencoder model to capture multi-level intra-story structures (i.e., graph) by continuous variational latent variables and generate consistent stories through dual-infusion of story structure planning and content learning. Experimental results on the ROCStories dataset and the CMU Movie Summary corpus confirm that our proposed model outperforms strong baselines in both human judges and widely-used automatic metrics.",
        "primary_area": "Humans and AI",
        "author": "Meng-Hsuan Yu; Juntao Li; Zhangming Chan; Rui Yan; Dongyan Zhao",
        "authorids": "",
        "aff": "Peking University; Soochow University; Peking University; Peking University; Peking University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16751/16751-13-20245-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06021-content-learning-with-structure-aware-writing-a-graph-infused-dual-conditional-variational-autoencoder-for-automatic-storytelling/",
        "doi": "10.1609/aaai.v35i7.16751",
        "pdf_size": 1396900
    },
    {
        "id": "00505",
        "title": "Content Masked Loss: Human-Like Brush Stroke Planning in a Reinforcement Learning Painting Agent",
        "track": "main",
        "status": "Poster",
        "abstract": "The objective of most Reinforcement Learning painting agents is to minimize the loss between a target image and the paint canvas.  Human painter artistry emphasizes important features of the target image rather than simply reproducing it.  Using adversarial or L2 losses in the RL painting models, although its final output is generally a work of finesse, produces a stroke sequence that is vastly different from that which a human would produce since the model does not have knowledge about the abstract features in the target image.  In order to increase the human-like planning of the model without the use of expensive human data, we introduce a new loss function for use with the model's reward function: Content Masked Loss. In the context of robot painting, Content Masked Loss employs an object detection model to extract features which are used to assign higher weight to regions of the canvas that a human would find important for recognizing content. The results, based on 332 human evaluators, show that the digital paintings produced by our Content Masked model show detectable subject matter earlier in the stroke sequence than existing methods without compromising on the quality of the final painting. Our code is available at https://github.com/pschaldenbrand/ContentMaskedLoss.",
        "primary_area": "Application Domains",
        "author": "Peter Schaldenbrand; Jean Oh",
        "authorids": "",
        "aff": "Human-Computer Interaction Institute, Carnegie Mellon University; Robotics Institute, Carnegie Mellon University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16128/16128-13-19622-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00505-content-masked-loss-human-like-brush-stroke-planning-in-a-reinforcement-learning-painting-agent/",
        "doi": "10.1609/aaai.v35i1.16128",
        "pdf_size": 2587018
    },
    {
        "id": "04874",
        "title": "Context Matters: Graph-based Self-supervised Representation Learning for Medical Images",
        "track": "main",
        "status": "Poster",
        "abstract": "Supervised learning method requires a large volume of annotated datasets. Collecting such datasets is time-consuming and expensive. Until now, very few annotated COVID-19 imaging datasets are available. Although self-supervised learning enables us to bootstrap the training by exploiting  unlabeled data, the generic self-supervised methods for natural images do not sufficiently incorporate the context. For medical images, a desirable method should be sensitive enough to detect deviation from normal-appearing tissue of each anatomical region; here, anatomy is the context. We introduce a novel approach with two levels of self-supervised representation learning objectives: one on the regional anatomical level and another on the patient-level. We use graph neural networks to incorporate the relationship between different anatomical regions. The structure of the graph is informed by anatomical correspondences between each patient and an anatomical atlas. In addition, the graph representation has the advantage of handling any arbitrarily sized image in full resolution. Experiments on large-scale Computer Tomography (CT) datasets of lung images show that our approach compares favorably to baseline methods that do not account for the context. We use the learnt embedding to quantify the clinical progression of COVID-19 and show that our method generalizes well to COVID-19 patients from different hospitals. Qualitative results suggest that our model can identify clinically relevant regions in the images.",
        "primary_area": "AI Responses to the COVID-19 Pandemic",
        "author": "Li Sun; Ke Yu; Kayhan Batmanghelich",
        "authorids": "",
        "aff": "University of Pittsburgh; University of Pittsburgh; University of Pittsburgh",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16620/16620-13-20114-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04874-context-matters-graph-based-self-supervised-representation-learning-for-medical-images/",
        "doi": "10.1609/aaai.v35i6.16620",
        "pdf_size": 8424392
    },
    {
        "id": "01646",
        "title": "Context-Aware Graph Convolution Network for Target Re-identification",
        "track": "main",
        "status": "Poster",
        "abstract": "Most existing re-identification methods focus on learning robust and discriminative features with deep convolution networks. However, many of them consider content similarity separately and fail to utilize the context information of the query and gallery sets, e.g. probe-gallery and gallery-gallery relations, thus hard samples may not be well solved due to the limited or even misleading information. In this paper, we present a novel Context-Aware Graph Convolution Network (CAGCN), where the probe-gallery relations are encoded into the graph nodes and the graph edge connections are well controlled by the gallery-gallery relations. In this way, hard samples can be addressed with the context information flows among other easy samples during the graph reasoning. Specifically, we adopt an effective hard gallery sampler to obtain high recall for positive samples while keeping a reasonable graph size, which can also weaken the imbalanced problem in training process with low computation complexity. Experiments show that the proposed method achieves state-of-the-art performance on both person and vehicle re-identification datasets in a plug and play fashion with limited overhead.",
        "primary_area": "Computer Vision I",
        "author": "Deyi Ji; Haoran Wang; Hanzhe Hu; Weihao Gan; Wei Wu; Junjie Yan",
        "authorids": "",
        "aff": "SenseTime Research; Xidian University; Peking University; SenseTime Research; SenseTime Research; SenseTime Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16257/16257-13-19751-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01646-context-aware-graph-convolution-network-for-target-re-identification/",
        "doi": "10.1609/aaai.v35i2.16257",
        "pdf_size": 9581185
    },
    {
        "id": "03492",
        "title": "Context-Guided Adaptive Network for Efficient Human Pose Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Although recent work has achieved great progress in human pose estimation (HPE), most methods show limitations in either inference speed or accuracy. In this paper, we propose a fast and accurate end-to-end HPE method, which is specifically designed to overcome the commonly encountered jitter box, defective box and ambiguous box problems of box-based methods, e.g. Mask R-CNN. Concretely, 1) we propose the ROIGuider to aggregate box instance features from all feature levels under the guidance of global context instance information. Further, 2) the proposed Center Line Branch is equipped with a Dichotomy Extended Area algorithm to adaptively expand each instance box area, and Ambiguity Alleviation strategy to eliminate duplicated keypoints. Finally, 3) to achieve efficient multi-scale feature fusion and real-time inference, we design a novel Trapezoidal Network (TNet) backbone. Experimenting on the COCO dataset, our method achieves 68.1 AP at 25.4 fps, and outperforms Mask-RCNN by 8.9 AP at a similar speed. The competitive performance on the HPE and person instance segmentation tasks over the state-of-the-art models show the promise of the proposed method. The source code will be made available at https://github.com/zlcnup/CGANet.",
        "primary_area": "Computer Vision III",
        "author": "Lei Zhao; Jun Wen; Pengfei Wang; Nenggan Zheng",
        "authorids": "",
        "aff": "Qiushi Academy for Advanced Studies, Zhejiang University, Hangzhou, China College of Computer Science and Techology, Zhejiang University, Hangzhou, China; Qiushi Academy for Advanced Studies, Zhejiang University, Hangzhou, China College of Computer Science and Techology, Zhejiang University, Hangzhou, China; Qiushi Academy for Advanced Studies, Zhejiang University, Hangzhou, China College of Computer Science and Techology, Zhejiang University, Hangzhou, China; Qiushi Academy for Advanced Studies, Zhejiang University, Hangzhou, China College of Computer Science and Techology, Zhejiang University, Hangzhou, China Collaborative Innovation Center for Artificial Intelligence by MOE and Zhejiang Provincial Government (ZJU) Zhejiang Lab, Hangzhou, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16463/16463-13-19957-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03492-context-guided-adaptive-network-for-efficient-human-pose-estimation/",
        "doi": "10.1609/aaai.v35i4.16463",
        "pdf_size": 1900338
    },
    {
        "id": "14094",
        "title": "Context-Guided BERT for Targeted Aspect-Based Sentiment Analysis",
        "track": "main",
        "status": "Poster",
        "abstract": "Aspect-based sentiment analysis (ABSA) and Targeted ASBA (TABSA) allow finer-grained inferences about sentiment to be drawn from the same text, depending on context. For example, a given text can have different targets (e.g., neighborhoods) and different aspects (e.g., price or safety), with different sentiment associated with each target-aspect pair. In this paper, we investigate whether adding context to self-attention models improves performance on (T)ABSA. We propose two variants of Context-Guided BERT (CG-BERT) that learn to distribute attention under different contexts. We first adapt a context-aware Transformer to produce a CG-BERT that uses context-guided softmax-attention. Next, we propose an improved Quasi-Attention CG-BERT model that learns a compositional attention that supports subtractive attention. We train both models with pretrained BERT on two (T)ABSA datasets: SentiHood and SemEval-2014 (Task 4). Both models achieve new state-of-the-art results with our QACG-BERT model having the best performance. Furthermore, we provide analyses of the impact of context in the our proposed models. Our work provides more evidence for the utility of adding context-dependencies to pretrained self-attention-based language models for context-based natural language tasks.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Zhengxuan Wu; Desmond C. Ong",
        "authorids": "",
        "aff": "Symbolic Systems Program, Stanford University; Department of Information Systems and Analytics, National University of Singapore Institute of High Performance Computing, Agency for Science, Technology, and Research, Singapore",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17659/17659-13-21153-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14094-context-guided-bert-for-targeted-aspect-based-sentiment-analysis/",
        "doi": "10.1609/aaai.v35i16.17659",
        "pdf_size": 2346502
    },
    {
        "id": "00929",
        "title": "Context-aware Attentional Pooling (CAP) for Fine-grained Visual Classification",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep convolutional neural networks (CNNs) have shown a strong ability in mining discriminative object pose and parts information for image recognition. For fine-grained recognition, context-aware rich feature representation of object/scene plays a key role since it exhibits a significant variance in the same subcategory and subtle variance among different subcategories. Finding the subtle variance that fully characterizes the object/scene is not straightforward. To address this, we propose a novel context-aware attentional pooling (CAP) that effectively captures subtle changes via sub-pixel gradients, and learns to attend informative integral regions and their importance in discriminating different subcategories without requiring the bounding-box and/or distinguishable part annotations. We also introduce a novel feature encoding by considering the intrinsic consistency between the informativeness of the integral regions and their spatial structures to capture the semantic correlation among them. Our approach is simple yet extremely effective and can be easily applied on top of a standard classification backbone network. We evaluate our approach using six state-of-the-art (SotA) backbone networks and eight benchmark datasets. Our method significantly outperforms the SotA approaches on six datasets and is very competitive with the remaining two.",
        "primary_area": "Computer Vision I",
        "author": "Ardhendu Behera; Zachary Wharton; Pradeep R P G Hewage; Asish Bera",
        "authorids": "",
        "aff": "Edge Hill University; Edge Hill University; Edge Hill University; Edge Hill University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16176/16176-13-19670-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00929-context-aware-attentional-pooling-cap-for-fine-grained-visual-classification/",
        "doi": "10.1609/aaai.v35i2.16176",
        "pdf_size": 3990674
    },
    {
        "id": "06254",
        "title": "Contextual Conditional Reasoning",
        "track": "main",
        "status": "Poster",
        "abstract": "We extend the expressivity of classical conditional reasoning by introducing context as a new parameter. The enriched conditional logic generalises the defeasible setting in the style of Kraus, Lehmann and Magidor, and allows for a more refined representation of an agent\u2019s epistemic state, distinguishing, for example, between expectations and counterfactuals. In this paper we introduce the language for the enriched logic, and define an appropriate semantic framework for it. We analyse which properties generally associated with conditional reasoning are still satisfied by the new semantic framework, provide an appropriate representation result, and define an entailment relation based on Lehmann and Magidor\u2019s notion of Rational Closure.",
        "primary_area": "Knowledge Representation and Reasoning",
        "author": "Giovanni Casini; Thomas Meyer; Ivan Varzinczak",
        "authorids": "",
        "aff": "ISTI-CNR CAIR; University of Cape Town CAIR; Universit\u00e9 d\u2019Artois CAIR",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16777/16777-13-20271-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06254-contextual-conditional-reasoning/",
        "doi": "10.1609/aaai.v35i7.16777",
        "pdf_size": 180172
    },
    {
        "id": "12544",
        "title": "Contextualized Rewriting for Text Summarization",
        "track": "main",
        "status": "Poster",
        "abstract": "Extractive summarization suffers from irrelevance, redundancy and incoherence. Existing work shows that abstractive rewriting for extractive summaries can improve the conciseness and readability. These rewriting systems consider extracted summaries as the only input, which is relatively focused but can lose important background knowledge. In this paper, we investigate contextualized rewriting, which ingests the entire original document. We formalize contextualized rewriting as a seq2seq problem with group alignments, introducing group tag as a solution to model the alignments, identifying extracted summaries through content-based addressing. Results show that our approach significantly outperforms non-contextualized rewriting systems without requiring reinforcement learning, achieving strong improvements on ROUGE scores upon multiple extractive summarizers.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Guangsheng Bao; Yue Zhang",
        "authorids": "",
        "aff": "Westlake University; Westlake University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17487/17487-13-20981-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12544-contextualized-rewriting-for-text-summarization/",
        "doi": "10.1609/aaai.v35i14.17487",
        "pdf_size": 286594
    },
    {
        "id": "10006",
        "title": "Continual General Chunking Problem and SyncMap",
        "track": "main",
        "status": "Poster",
        "abstract": "Humans possess an inherent ability to chunk sequences into their constituent parts. In fact, this ability is thought to bootstrap language skills and learning of image patterns which might be a key to a more animal-like type of intelligence. Here, we propose a continual generalization of the chunking problem (an unsupervised problem), encompassing fixed and probabilistic chunks, discovery of temporal and causal structures and their continual variations. Additionally, we propose an algorithm called SyncMap that can learn and adapt to changes in the problem by creating a dynamic map which preserves the correlation between variables. Results of SyncMap  suggest that the proposed algorithm learn near optimal solutions, despite the presence of many types of structures and their continual variation. When compared to Word2vec, PARSER and MRIL, SyncMap surpasses or ties with the best algorithm on 66% of the scenarios while being the second best in the remaining 34%. SyncMap's model-free simple dynamics and the absence of loss functions reveal that, perhaps surprisingly, much can be done with self-organization alone.",
        "primary_area": "Machine Learning IV",
        "author": "Danilo Vasconcellos Vargas; Toshitake Asabuki",
        "authorids": "",
        "aff": "Kyushu University The University of Tokyo; Okinawa Institute of Science and Technology Graduate University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17201/17201-13-20695-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10006-continual-general-chunking-problem-and-syncmap/",
        "doi": "10.1609/aaai.v35i11.17201",
        "pdf_size": 789422
    },
    {
        "id": "07797",
        "title": "Continual Learning by Using Information of Each Class Holistically",
        "track": "main",
        "status": "Poster",
        "abstract": "Continual learning (CL) incrementally learns a sequence of tasks while solving  the catastrophic forgetting (CF) problem. Existing methods mainly try to deal with CF directly.  In this paper, we propose to avoid CF by considering the features of each class holistically rather than only the discriminative information for classifying the classes seen so far. This latter approach is prone to CF because the discriminative information for old classes may not be sufficiently discriminative for the new class to be learned. Consequently, in learning each new task, the network parameters for previous tasks have to be revised, which causes CF. With the holistic consideration, after adding new tasks, the system can still do well for previous tasks. The proposed technique is called Per-class Continual Learning (PCL).  PCL has two key novelties. (1) It proposes a one-class learning based technique for CL, which considers features of each class holistically and represents a new approach to solving the CL problem. (2) It proposes a method to extract discriminative information after training to further improve the accuracy. Empirical evaluation shows that PCL markedly outperforms the state-of-the-art baselines for one or more classes per task. More tasks also result in more gains.",
        "primary_area": "Machine Learning II",
        "author": "Wenpeng Hu; Qi Qin; Mengyu Wang; Jinwen Ma; Bing Liu",
        "authorids": "",
        "aff": "Peking University; Peking University; Peking University; Peking University; UIC",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16952/16952-13-20446-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07797-continual-learning-by-using-information-of-each-class-holistically/",
        "doi": "10.1609/aaai.v35i9.16952",
        "pdf_size": 222412
    },
    {
        "id": "13570",
        "title": "Continual Learning for Named Entity Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "Named Entity Recognition (NER) is a vital task in various NLP applications. However, in many real-world scenarios (e.g., voice-enabled assistants) new named entities are frequently introduced, entailing re-training NER models to support these new entities. Re-annotating the original training data for the new entities could be costly or even impossible when storage limitations or security concerns restrict access to that data, and annotating a new dataset for all of the entities becomes impractical and error-prone as the number of entities increases. To tackle this problem, we introduce a novel Continual Learning approach for NER, which requires new training material to be annotated only for the new entities. To preserve the existing knowledge previously learned by the model, we exploit the Knowledge Distillation (KD) framework, where the existing NER model acts as the teacher for a new NER model (i.e., the student), which learns the new entity by using the new training material and retains knowledge of old entities by imitating the teacher's outputs on this new training set. Our experiments show that this approach allows the student model to ``progressively'' learn to identify new entities without forgetting the previously learned ones. We also present a comparison with multiple strong baselines to demonstrate that our approach is superior for continually updating an NER model.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Natawut Monaikul; Giuseppe Castellucci; Simone Filice; Oleg Rokhlenko",
        "authorids": "",
        "aff": "University of Illinois at Chicago; Amazon; Amazon; Amazon",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17600/17600-13-21094-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13570-continual-learning-for-named-entity-recognition/",
        "doi": "10.1609/aaai.v35i15.17600",
        "pdf_size": 453799
    },
    {
        "id": "14393",
        "title": "Continuous Self-Attention Models with Neural ODE Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Stacked self-attention models receive widespread attention, due to its ability of capturing global dependency among words. However, the stacking of many layers and components generates huge parameters, leading to low parameter efficiency. In response to this issue, we propose a lightweight architecture named Continuous Self-Attention models with neural ODE networks (CSAODE). In CSAODE, continuous dynamical models (i.e., neural ODEs) are coupled with our proposed self-attention block to form a self-attention ODE solver. This solver  continuously calculates and optimizes the hidden states via only one layer of parameters to improve the  parameter efficiency. In addition, we design a novel accelerated continuous dynamical model to reduce computing costs, and integrate it in  CSAODE. Moreover, since the original self-attention ignores local information,  CSAODE makes use of N-gram convolution to encode local representations, and a fusion layer with only two trainable scalars are designed for generating sentence vectors. We perform a series of experiments on text classification, neural language inference (NLI) and text matching tasks. With fewer parameters, CSAODE outperforms state-of-the-art models on text classification tasks (e.g.,  1.3% accuracy improved on SUBJ task), and has competitive performances for NLI and text matching tasks as well.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Jing Zhang; Peng Zhang; Baiwen Kong; Junqiu Wei; Xin Jiang",
        "authorids": "",
        "aff": "Tianjin University; Tianjin University; Tianjin University; Huawei Noah\u2019s Ark Lab; Huawei Noah's Ark Lab",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17692/17692-13-21186-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14393-continuous-self-attention-models-with-neural-ode-networks/",
        "doi": "10.1609/aaai.v35i16.17692",
        "pdf_size": 1007882
    },
    {
        "id": "07116",
        "title": "Continuous-Time Attention for Sequential Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Attention mechanism is crucial for sequential learning where a wide range of applications have been successfully developed. This mechanism is basically trained to spotlight on the region of interest in hidden states of sequence data. Most of the attention methods compute the attention score through relating between a query and a sequence where the discrete-time state trajectory is represented. Such a discrete-time attention could not directly attend the continuous-time trajectory which is represented via neural differential equation (NDE) combined with recurrent neural network. This paper presents a new continuous-time attention method for sequential learning which is tightly integrated with NDE to construct an attentive continuous-time state machine. The continuous-time attention is performed at all times over the hidden states for different kinds of irregular time signals. The missing information in sequence data due to sampling loss, especially in presence of long sequence, can be seamlessly compensated and attended in learning representation. The experiments on irregular sequence samples from human activities, dialogue sentences and medical features show the merits of the proposed continuous-time attention for activity recognition, sentiment classification and mortality prediction, respectively.",
        "primary_area": "Machine Learning I",
        "author": "Jen-Tzung Chien; Yi-Hsiang Chen",
        "authorids": "",
        "aff": "National Chiao Tung University; National Chaio Tung University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16875/16875-13-20369-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07116-continuous-time-attention-for-sequential-learning/",
        "doi": "10.1609/aaai.v35i8.16875",
        "pdf_size": 689468
    },
    {
        "id": "11726",
        "title": "Contract Scheduling With Predictions",
        "track": "main",
        "status": "Poster",
        "abstract": "Contract scheduling is a general technique that allows to design a system with interruptible capabilities, given an algorithm that is not necessarily interruptible. Previous work on this topic has largely assumed that the interruption is a worst-case deadline that is unknown to the scheduler. In this work, we study the setting in which there is a potentially erroneous prediction concerning the interruption. Specifically, we consider the setting in which the prediction describes the time that the interruption occurs, as well as the setting in which the prediction is obtained as a response to a single or multiple binary queries. For both settings, we investigate tradeoffs between the robustness (i.e., the worst-case performance assuming adversarial prediction) and the consistency (i.e, the performance assuming that the prediction is error-free), both from the side of positive and negative results.",
        "primary_area": "Planning, Routing, and Scheduling",
        "author": "Spyros Angelopoulos; Shahin Kamali",
        "authorids": "",
        "aff": "Centre National de la Recherche Scientifique (CNRS) Sorbonne Universit\u00e9, Laboratoire d'informatique de Paris 6, LIP6, Paris, France; University of Manitoba, Winnipeg, Manitoba, Canada",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17394/17394-13-20888-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11726-contract-scheduling-with-predictions/",
        "doi": "10.1609/aaai.v35i13.17394",
        "pdf_size": 321514
    },
    {
        "id": "11361",
        "title": "Contract-based Inter-user Usage Coordination in Free-floating Car Sharing",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a novel distributed user-car matching method based on a contract between users to mitigate the imbalance problem between vehicle distribution and demand in free-floating car sharing. Previous regulation methods involved an incentive system based on the predictions of origin-destination (OD) demand obtained from past usage history. However, the difficulty these methods have in obtaining accurate data limits their applicability. To overcome this drawback, we introduce contract-based coordination among drop-off and pick-up users in which an auction is conducted for drop-off users' intended drop-off locations. We theoretically analyze the proposed method regarding the upper bound of its efficiency. We also compare it with a baseline method and non-regulation scenario on a free-floating car-sharing simulator. The experimental results show that the proposed method achieves a higher social surplus than the existing method.",
        "primary_area": "Multiagent Systems",
        "author": "Kentaro Takahira; Shigeo Matsubara",
        "authorids": "",
        "aff": "Kyoto University; Osaka University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17354/17354-13-20848-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11361-contract-based-inter-user-usage-coordination-in-free-floating-car-sharing/",
        "doi": "10.1609/aaai.v35i13.17354",
        "pdf_size": 131763
    },
    {
        "id": "05948",
        "title": "Contrastive Adversarial Learning for Person Independent Facial Emotion Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "Since most facial emotion recognition (FER) methods significantly rely on supervision information, they have a limit to analyzing emotions independently of persons. On the other hand, adversarial learning is a well-known approach for generalized representation learning because it never requires supervision information. This paper presents a new adversarial learning for FER. In detail, the proposed learning enables the FER network to better understand complex emotional elements inherent in strong emotions by adversarially learning weak emotion samples based on strong emotion samples. As a result, the proposed method can recognize the emotions independently of persons because it understands facial expressions more accurately. In addition, we propose a contrastive loss function for efficient adversarial learning. Finally, the proposed adversarial learning scheme was theoretically verified, and it was experimentally proven to show state of the art (SOTA) performance.",
        "primary_area": "Humans and AI",
        "author": "Daeha Kim; Byung Cheol Song",
        "authorids": "",
        "aff": "Inha University; Inha University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16743/16743-13-20237-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05948-contrastive-adversarial-learning-for-person-independent-facial-emotion-recognition/",
        "doi": "10.1609/aaai.v35i7.16743",
        "pdf_size": 2264578
    },
    {
        "id": "08547",
        "title": "Contrastive Clustering",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose an online clustering method called Contrastive Clustering (CC) which explicitly performs the instance- and cluster-level contrastive learning. To be specific, for a given dataset, the positive and negative instance pairs are constructed through data augmentations and then projected into a feature space. Therein, the instance- and cluster-level contrastive learning are respectively conducted in the row and column space by maximizing the similarities of positive pairs while minimizing those of negative ones. Our key observation is that the rows of the feature matrix could be regarded as soft labels of instances, and accordingly the columns could be further regarded as cluster representations. By simultaneously optimizing the instance- and cluster-level contrastive loss, the model jointly learns representations and cluster assignments in an end-to-end manner. Besides, the proposed method could timely compute the cluster assignment for each individual, even when the data is presented in streams. Extensive experimental results show that CC remarkably outperforms 17 competitive clustering methods on six challenging image benchmarks. In particular, CC achieves an NMI of 0.705 (0.431) on the CIFAR-10 (CIFAR-100) dataset, which is an up to 19% (39%) performance improvement compared with the best baseline. The code is available at https://github.com/XLearning-SCU/2021-AAAI-CC.",
        "primary_area": "Machine Learning III",
        "author": "Yunfan Li; Peng Hu; Zitao Liu; Dezhong Peng; Joey Tianyi Zhou; Xi Peng",
        "authorids": "",
        "aff": "College of Computer Science, Sichuan University, China; College of Computer Science, Sichuan University, China; TAL Education Group, China; College of Computer Science, Sichuan University, China Shenzhen Peng Cheng Laboratory, China College of Computer & Information Science, Southwest University, China; Institute of High Performance Computing, A*STAR, Singapore; College of Computer Science, Sichuan University, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17037/17037-13-20531-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08547-contrastive-clustering/",
        "doi": "10.1609/aaai.v35i10.17037",
        "pdf_size": 6451763
    },
    {
        "id": "10824",
        "title": "Contrastive Self-supervised Learning for Graph Classification",
        "track": "main",
        "status": "Poster",
        "abstract": "Graph classification is a widely studied problem and has broad applications. In many real-world problems, the number of labeled graphs available for training classification models is limited, which renders these models prone to overfitting. To address this problem, we propose two approaches based on contrastive self-supervised learning (CSSL) to alleviate overfitting. In the first approach, we use CSSL to pretrain graph encoders on widely-available unlabeled graphs without relying on human-provided labels, then finetune the pretrained encoders on labeled graphs. In the second approach, we develop a regularizer based on  CSSL, and solve the supervised classification task and the unsupervised CSSL task simultaneously. To perform CSSL on graphs, given a collection of original graphs, we perform data augmentation to create augmented graphs out of the original graphs. An augmented graph is created by consecutively applying a sequence of graph alteration operations. A contrastive loss is defined to learn graph encoders by judging whether two augmented graphs are from the same original graph. Experiments on various graph classification datasets demonstrate the effectiveness of our proposed methods. The code is available at https://github.com/UCSD-AI4H/GraphSSL.",
        "primary_area": "Machine Learning V",
        "author": "Jiaqi Zeng; Pengtao Xie",
        "authorids": "",
        "aff": "Shanghai Jiao Tong University; University of California San Diego",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17293/17293-13-20787-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10824-contrastive-self-supervised-learning-for-graph-classification/",
        "doi": "10.1609/aaai.v35i12.17293",
        "pdf_size": 393490
    },
    {
        "id": "10174",
        "title": "Contrastive Transformation for Self-supervised Correspondence Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we focus on the self-supervised learning of visual correspondence using unlabeled videos in the wild. Our method simultaneously considers intra- and inter-video representation associations for reliable correspondence estimation. The intra-video learning transforms the image contents across frames within a single video via the frame pair-wise affinity. To obtain the discriminative representation for instance-level separation, we go beyond the intra-video analysis and construct the inter-video affinity to facilitate the contrastive transformation across different videos. By forcing the transformation consistency between intra- and inter-video levels, the fine-grained correspondence associations are well preserved and the instance-level feature discrimination is effectively reinforced. Our simple framework outperforms the recent self-supervised correspondence methods on a range of visual tasks including video object tracking (VOT), video object segmentation (VOS), pose keypoint tracking, etc. It is worth mentioning that our method also surpasses the fully-supervised affinity representation (e.g., ResNet) and performs competitively against the recent fully-supervised algorithms designed for the specific tasks (e.g., VOT and VOS).",
        "primary_area": "Machine Learning IV",
        "author": "Ning Wang; Wengang Zhou; Houqiang Li",
        "authorids": "",
        "aff": "CAS Key Laboratory of GIPAS, EEIS Department, University of Science and Technology of China; CAS Key Laboratory of GIPAS, EEIS Department, University of Science and Technology of China Institute of Artificial Intelligence, Hefei Comprehensive National Science Center; CAS Key Laboratory of GIPAS, EEIS Department, University of Science and Technology of China Institute of Artificial Intelligence, Hefei Comprehensive National Science Center",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17220/17220-13-20714-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10174-contrastive-transformation-for-self-supervised-correspondence-learning/",
        "doi": "10.1609/aaai.v35i11.17220",
        "pdf_size": 5424660
    },
    {
        "id": "14257",
        "title": "Contrastive Triple Extraction with Generative Transformer",
        "track": "main",
        "status": "Poster",
        "abstract": "Triple extraction is an essential task in information extraction for natural language processing and knowledge graph construction. In this paper, we revisit the end-to-end triple extraction task for sequence generation. Since generative triple extraction may struggle to capture long-term dependencies and generate unfaithful triples, we introduce a novel model, contrastive triple extraction with a generative transformer. Specifically, we introduce a single shared transformer module for encoder-decoder-based generation. To generate faithful results, we propose a novel triplet contrastive training object.  Moreover, we introduce two mechanisms to further improve model performance (i.e., batch-wise dynamic attention-masking and triple-wise calibration).  Experimental results on three datasets (i.e., NYT, WebNLG, and MIE) show that our approach achieves better performance than that of baselines.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Hongbin Ye; Ningyu Zhang; Shumin Deng; Mosha Chen; Chuanqi Tan; Fei Huang; Huajun Chen",
        "authorids": "",
        "aff": "Zhejiang University AZFT Joint Lab for Knowledge Engine; Zhejiang University AZFT Joint Lab for Knowledge Engine; Zhejiang University AZFT Joint Lab for Knowledge Engine; Alibaba Group; Alibaba Group; Alibaba Group; Zhejiang University AZFT Joint Lab for Knowledge Engine",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17677/17677-13-21171-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14257-contrastive-triple-extraction-with-generative-transformer/",
        "doi": "10.1609/aaai.v35i16.17677",
        "pdf_size": 201028
    },
    {
        "id": "10049",
        "title": "Contrastive and Generative Graph Convolutional Networks for Graph-based Semi-Supervised Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Graph-based Semi-Supervised Learning (SSL) aims to transfer the labels of a handful of labeled data to the remaining massive unlabeled data via a graph. As one of the most popular graph-based SSL approaches, the recently proposed Graph Convolutional Networks (GCNs) have gained remarkable progress by combining the sound expressiveness of neural networks with graph structure. Nevertheless, the existing graph-based methods do not directly address the core problem of SSL, emph{i.e.}, the shortage of supervision, and thus their performances are still very limited. To accommodate this issue, this paper presents a novel GCN-based SSL algorithm which aims to enrich the supervision signals by utilizing both data similarities and graph structure. Firstly, by designing a semi-supervised contrastive loss, the improved node representations can be generated via maximizing the agreement between different views of the same data or the data from the same class. Therefore, the rich unlabeled data and the scarce yet valuable labeled data can jointly provide abundant supervision information for learning discriminative node representations, which helps improve the subsequent classification result. Secondly, the underlying determinative relationship between the input graph topology and data features is extracted as supplementary supervision signals for SSL via using a graph generative loss related to input features. Intensive experimental results on a variety of real-world datasets firmly verify the effectiveness of our algorithm when compared with other state-of-the-art methods.",
        "primary_area": "Machine Learning IV",
        "author": "Sheng Wan; Shirui Pan; Jian Yang; Chen Gong",
        "authorids": "",
        "aff": "PCA Lab, Key Lab of Intelligent Perception and Systems for High-Dimensional Information of Ministry of Education, and Jiangsu Key Lab of Image and Video Understanding for Social Security, School of Computer Science and Engineering, Nanjing University of Science and Technology; Faculty of IT, Monash University, Australia; PCA Lab, Key Lab of Intelligent Perception and Systems for High-Dimensional Information of Ministry of Education, and Jiangsu Key Lab of Image and Video Understanding for Social Security, School of Computer Science and Engineering, Nanjing University of Science and Technology; PCA Lab, Key Lab of Intelligent Perception and Systems for High-Dimensional Information of Ministry of Education, and Jiangsu Key Lab of Image and Video Understanding for Social Security, School of Computer Science and Engineering, Nanjing University of Science and Technology Department of Computing, Hong Kong Polytechnic University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17206/17206-13-20700-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10049-contrastive-and-generative-graph-convolutional-networks-for-graph-based-semi-supervised-learning/",
        "doi": "10.1609/aaai.v35i11.17206",
        "pdf_size": 478920
    },
    {
        "id": "07610",
        "title": "Controllable Guarantees for Fair Outcomes via Contrastive Information Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Controlling bias in training datasets is vital for ensuring equal treatment, or parity, between different groups in downstream applications. A naive solution is to transform the data so that it is statistically independent of group membership, but this may throw away too much information when a reasonable compromise between fairness and accuracy is desired. Another common approach is to limit the ability of a particular adversary who seeks to maximize parity. Unfortunately, representations produced by adversarial approaches may still retain biases as their efficacy is tied to the complexity of the adversary used during training. To this end, we theoretically establish that by limiting the mutual information between representations and protected attributes, we can assuredly control the parity of any downstream classifier. We demonstrate an effective method for controlling parity through mutual information based on contrastive information estimators and show that they outperform approaches that rely on variational bounds based on complex generative models. We test our approach on UCI Adult and Heritage Health datasets and demonstrate that our approach provides more informative representations across a range of desired parity thresholds while providing strong theoretical guarantees on the parity of any downstream algorithm.",
        "primary_area": "Machine Learning II",
        "author": "Umang Gupta; Aaron M Ferber; Bistra Dilkina; Greg Ver Steeg",
        "authorids": "",
        "aff": "Information Sciences Institute, University of Southern California; University of Southern California; University of Southern California; Information Sciences Institute, University of Southern California",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16931/16931-13-20425-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07610-controllable-guarantees-for-fair-outcomes-via-contrastive-information-estimation/",
        "doi": "10.1609/aaai.v35i9.16931",
        "pdf_size": 211615
    },
    {
        "id": "05399",
        "title": "Convergence Analysis of No-Regret Bidding Algorithms in Repeated Auctions",
        "track": "main",
        "status": "Poster",
        "abstract": "The connection between games and no-regret algorithms has been widely studied in the literature. A fundamental result is that when all players play no-regret strategies, this produces a sequence of actions whose time-average is a coarse-correlated equilibrium of the game. However, much less is known about equilibrium selection in the case that multiple equilibria exist. In this work, we study the convergence of no-regret bidding algorithms in auctions. Besides being of theoretical interest, bidding dynamics in auctions is an important question from a practical viewpoint as well. We study the repeated game between bidders in which a single item is sold at each time step and the bidder's value is drawn from an unknown distribution. We show that if the bidders use any mean-based learning rule then the bidders converge with high probability to the truthful pure Nash Equilibrium in a second price auction, in VCG auction in the multi-slot setting and to the Bayesian Nash equilibrium in a first price auction. We note mean-based algorithms cover a wide variety of known no-regret algorithms such as Exp3, UCB, epsilon-Greedy etc. Also, we analyze the convergence of the individual iterates produced by such learning algorithms, as opposed to the time-average of the sequence. Our experiments corroborate our theoretical findings and also find a similar convergence when we use other strategies such as Deep Q-Learning.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Zhe Feng; Guru Guruganesh; Christopher Liaw; Aranyak Mehta; Abhishek Sethi",
        "authorids": "",
        "aff": "Harvard University; Google Research; University of British Columbia; Google Research; Google Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16680/16680-13-20174-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05399-convergence-analysis-of-no-regret-bidding-algorithms-in-repeated-auctions/",
        "doi": "10.1609/aaai.v35i6.16680",
        "pdf_size": 277599
    },
    {
        "id": "04902",
        "title": "Conversational Neuro-Symbolic Commonsense Reasoning",
        "track": "main",
        "status": "Poster",
        "abstract": "In order for conversational AI systems to hold more natural and broad-ranging conversations, they will require much more commonsense, including the ability to identify unstated presumptions of their conversational partners. For example, in the command \"If it snows at night then wake me up early because I don't want to be late for work\" the speaker relies on commonsense reasoning of the listener to infer the implicit presumption that they wish to be woken only if it snows enough to cause traffic slowdowns.  We consider here the problem of understanding such imprecisely stated natural language commands given in the form of if-(state), then-(action), because-(goal) statements. More precisely, we consider the problem of identifying the unstated presumptions of the speaker that allow the requested action to achieve the desired goal from the given state (perhaps elaborated by making the implicit presumptions explicit). We release a benchmark data set for this task, collected from humans and annotated with commonsense presumptions. We present a neuro-symbolic theorem prover that extracts multi-hop reasoning chains, and apply it to this problem. Furthermore, to accommodate the reality that current AI commonsense systems lack full coverage, we also present an interactive conversational framework built on our neuro-symbolic system, that conversationally evokes commonsense knowledge from humans to complete its reasoning chains.",
        "primary_area": "Neuro-Symbolic AI",
        "author": "Forough Arabshahi; Jennifer Lee; Mikayla Gawarecki; Kathryn Mazaitis; Amos Azaria; Tom Mitchell",
        "authorids": "",
        "aff": "Facebook; Facebook; Carnegie Mellon University; Carnegie Mellon University; Ariel University; Carnegie Mellon University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16623/16623-13-20117-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04902-conversational-neuro-symbolic-commonsense-reasoning/",
        "doi": "10.1609/aaai.v35i6.16623",
        "pdf_size": 171595
    },
    {
        "id": "13380",
        "title": "Converse, Focus and Guess \u2013 Towards Multi-Document Driven Dialogue",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a novel task, Multi-Document Driven Dialogue (MD3), in which an agent can guess the target document that the user is interested in by leading a dialogue. To benchmark progress, we introduce a new dataset of GuessMovie, which contains 16,881 documents, each describing a movie, and associated 13,434 dialogues. Further, we propose the MD3 model. Keeping guessing the target document in mind, it converses with the user conditioned on both document engagement and user feedback. In order to incorporate large-scale external documents into the dialogue, it pretrains a document representation which is sensitive to attributes it talks about an object. Then it tracks dialogue state by detecting evolvement of document belief and attribute belief, and finally optimizes dialogue policy in principle of entropy decreasing and reward increasing, which is expected to successfully guess the user's target in a minimum number of turns. Experiments show that our method significantly outperforms several strong baseline methods and is very close to human's performance.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Han Liu; Caixia Yuan; Xiaojie Wang; Yushu Yang; Huixing Jiang; Zhongyuan Wang",
        "authorids": "",
        "aff": "Beijing University of Posts and Telecommunications, Beijing, China; Beijing University of Posts and Telecommunications, Beijing, China; Beijing University of Posts and Telecommunications, Beijing, China; Meituan, Beijing, China; Meituan, Beijing, China; Meituan, Beijing, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17579/17579-13-21073-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13380-converse-focus-and-guess-towards-multi-document-driven-dialogue/",
        "doi": "10.1609/aaai.v35i15.17579",
        "pdf_size": 476380
    },
    {
        "id": "11387",
        "title": "Coordination Between Individual Agents in Multi-Agent Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "The existing multi-agent reinforcement learning methods (MARL) for determining the coordination between agents focus on either global-level or neighborhood-level coordination between agents. However the problem of coordination between individual agents is remain to be solved. It is crucial for learning an optimal coordinated policy in unknown multi-agent environments to analyze the agent's roles and the correlation between individual agents. To this end, in this paper we propose an agent-level coordination based MARL method. Specifically, it includes two parts in our method. The first is correlation analysis between individual agents based on the Pearson, Spearman, and Kendall correlation coefficients; And the second is an agent-level coordinated training framework where the communication message between weakly correlated agents is dropped out, and a correlation based reward function is built. The proposed method is verified in four mixed cooperative-competitive environments. The experimental results show that the proposed method outperforms the state-of-the-art MARL methods and can measure the correlation between individual agents accurately.",
        "primary_area": "Multiagent Systems",
        "author": "Yang Zhang; Qingyu Yang; Dou An; Chengwei Zhang",
        "authorids": "",
        "aff": "Faculty of Electronics and Information, Xi\u2019an Jiaotong University, Xi\u2019an, China; Faculty of Electronics and Information, Xi\u2019an Jiaotong University, Xi\u2019an, China; State Key Laboratory for Manufacturing System Engineering (SKLMSE), Xi\u2019an Jiaotong University, Xi\u2019an, China; Ministry of Education (MOE) Key Laboratory for Intelligent Networks and Network Security, Xi\u2019an Jiaotong University, Xi\u2019an, China; Faculty of Electronics and Information, Xi\u2019an Jiaotong University, Xi\u2019an, China; State Key Laboratory for Manufacturing System Engineering (SKLMSE), Xi\u2019an Jiaotong University, Xi\u2019an, China; Ministry of Education (MOE) Key Laboratory for Intelligent Networks and Network Security, Xi\u2019an Jiaotong University, Xi\u2019an, China; Dalian Maritime University, Dalian, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17357/17357-13-20851-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11387-coordination-between-individual-agents-in-multi-agent-reinforcement-learning/",
        "doi": "10.1609/aaai.v35i13.17357",
        "pdf_size": 309099
    },
    {
        "id": "13622",
        "title": "Copy That! Editing Sequences by Copying Spans",
        "track": "main",
        "status": "Poster",
        "abstract": "Neural sequence-to-sequence models are finding increasing use in editing of documents, for example in correcting a text document or repairing source code. In this paper, we argue that common seq2seq models (with a facility to copy single tokens) are not a natural fit for such tasks, as they have to explicitly copy each unchanged token. We present an extension of seq2seq models capable of copying entire spans of the input to the output in one step, greatly reducing the number of decisions required during inference. This extension means that there are now many ways of generating the same output, which we handle by deriving a new objective for training and a variation of beam search for inference that explicitly handles this problem. In our experiments on a range of editing tasks of natural language and source code, we show that our new model consistently outperforms simpler baselines.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Sheena Panthaplackel; Miltiadis Allamanis; Marc Brockschmidt",
        "authorids": "",
        "aff": "The University of Texas at Austin; Microsoft Research; Microsoft Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17606/17606-13-21100-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13622-copy-that-editing-sequences-by-copying-spans/",
        "doi": "10.1609/aaai.v35i15.17606",
        "pdf_size": 225151
    },
    {
        "id": "12363",
        "title": "Correlation-Aware Heuristic Search for Intelligent Virtual Machine Provisioning in Cloud Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "The optimization of resource is crucial for the operation of public cloud systems such as Microsoft Azure, as well as servers dedicated to the workloads of large customers such as Microsoft 365. Those optimization tasks often need to take unknown parameters into consideration and can be formulated as Prediction+Optimization problems. This paper proposes a new Prediction+Optimization method named Correlation-Aware Heuristic Search (CAHS) that is capable of accounting for the uncertainty in unknown parameters and delivering effective solutions to difficult optimization problems. We apply this method to solving the predictive virtual machine (VM) provisioning (PreVMP) problem, where the VM provisioning plans are optimized based on the predicted demands of different VM types, to ensure rapid provisions upon customers' requests and to pursue high resource utilization. Unlike the current state-of-the-art PreVMP approaches that assume independence among the demands for different VM types, CAHS incorporates demand correlation when conducting prediction and optimization in a novel and effective way. Our experiments on two public benchmarks and one industrial benchmark demonstrate that CAHS can achieve better performance than its nine state-of-the-art competitors. CAHS has been successfully deployed in Microsoft Azure and significantly improved its performance. The main ideas of CAHS have also been leveraged to improve the efficiency and the reliability of the cloud services provided by Microsoft 365.",
        "primary_area": "Search and Optimization",
        "author": "Chuan Luo; Bo Qiao; Wenqian Xing; Xin Chen; Pu Zhao; Chao Du; Randolph Yao; Hongyu Zhang; Wei Wu; Shaowei Cai; Bing He; Saravanakumar Rajmohan; Qingwei Lin",
        "authorids": "",
        "aff": "Microsoft Research, China; Microsoft Research, China; Microsoft Research, China Microsoft 365, United States; Microsoft Research, China Microsoft 365, United States; Microsoft Research, China; Microsoft Research, China; Microsoft Azure, United States; The University of Newcastle, Australia; L3S Research Center, Leibniz University Hannover, Germany; State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences, China; Microsoft Research, China; Microsoft 365, United States; Microsoft Research, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17467/17467-13-20961-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12363-correlation-aware-heuristic-search-for-intelligent-virtual-machine-provisioning-in-cloud-systems/",
        "doi": "10.1609/aaai.v35i14.17467",
        "pdf_size": 1121111
    },
    {
        "id": "06714",
        "title": "Correlative Channel-Aware Fusion for Multi-View Time Series Classification",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-view time series classification (MVTSC) aims to improve the performance by fusing the distinctive temporal information from multiple views. Existing methods for MVTSC mainly aim to fuse multi-view information at an early stage, e.g., by extracting a common feature subspace among multiple views. However, these approaches may not fully explore the unique temporal patterns of each view in complicated time series. Additionally, the label correlations of multiple views, which are critical to boosting, are usually under-explored for the MVTSC problem. To address the aforementioned issues, we propose a Correlative Channel-Aware Fusion (C$^2$AF) network. First, C$^2$AF extracts comprehensive and robust temporal patterns by a two-stream structured encoder for each view, and derives the intra-view/inter-view label correlations with a concise correlation matrix. Second, a channel-aware learnable fusion mechanism is implemented through CNN to further explore the global correlative patterns. Our C$^2$AF is an end-to-end framework for MVTSC. Extensive experimental results on three real-world datasets demonstrate the superiority of our C$^2$AF over the state-of-the-art methods. A detailed ablation study is also provided to illustrate the indispensability of each model component.",
        "primary_area": "Machine Learning I",
        "author": "Yue Bai; Lichen Wang; Zhiqiang Tao; Sheng Li; Yun Fu",
        "authorids": "",
        "aff": "Northeastern University; Northeastern University; Santa Clara University; University of Georgia; Northeastern University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16830/16830-13-20324-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06714-correlative-channel-aware-fusion-for-multi-view-time-series-classification/",
        "doi": "10.1609/aaai.v35i8.16830",
        "pdf_size": 621815
    },
    {
        "id": "07142",
        "title": "Cost-aware Graph Generation: A Deep Bayesian Optimization Approach",
        "track": "main",
        "status": "Poster",
        "abstract": "Graph-structured data is ubiquitous throughout the natural and social sciences, ranging from complex drug molecules to artificial neural networks. Evaluating their functional properties, e.g., drug effectiveness and prediction accuracy, is usually costly in terms of time, money, energy, or environment, becoming a bottleneck for the graph generation task. In this work, from the perspective of saving cost, we propose a novel Cost-Aware Graph Generation (CAGG) framework to generate graphs with optimal properties at as low cost as possible. By introducing a robust Bayesian graph neural network as the surrogate model and a goal-oriented training scheme for the generation model, the CAGG can approach the real expensive evaluation function and generate search space close to the optimal property, to avoid unnecessary evaluations. Intensive experiments conducted on two challenging real-world applications, including molecular discovery and neural architecture search, demonstrate its effectiveness and applicability. The results show that it can generate the optimal graphs and reduce the evaluation costs significantly compared to the state-of-the-art.",
        "primary_area": "Machine Learning I",
        "author": "Jiaxu Cui; Bo Yang; Bingyi Sun; Jiming Liu",
        "authorids": "",
        "aff": "Jilin University; Jilin University; Jilin University National University of Defense Technology; Hong Kong Baptist University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16878/16878-13-20372-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07142-cost-aware-graph-generation-a-deep-bayesian-optimization-approach/",
        "doi": "10.1609/aaai.v35i8.16878",
        "pdf_size": 327186
    },
    {
        "id": "06903",
        "title": "Counterfactual Explanations for Oblique Decision Trees:Exact, Efficient Algorithms",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider counterfactual explanations, the problem of minimally adjusting features in a source input instance so that it is classified as a target class under a given classifier. This has become a topic of recent interest as a way to query a trained model and suggest possible actions to overturn its decision. Mathematically, the problem is formally equivalent to that of finding adversarial examples, which also has attracted significant attention recently. Most work on either counterfactual explanations or adversarial examples has focused on differentiable classifiers, such as neural nets. We focus on classification trees, both axis-aligned and oblique (having hyperplane splits). Although here the counterfactual optimization problem is nonconvex and nondifferentiable, we show that an exact solution can be computed very efficiently, even with high-dimensional feature vectors and with both continuous and categorical features, and demonstrate it in different datasets and settings. The results are particularly relevant for finance, medicine or legal applications, where interpretability and counterfactual explanations are particularly important.",
        "primary_area": "Machine Learning I",
        "author": "Miguel  \u00c1. Carreira-Perpi\u00f1\u00e1n; Suryabhan Singh Hada",
        "authorids": "",
        "aff": "UC Merced; UC Merced",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16851/16851-13-20345-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06903-counterfactual-explanations-for-oblique-decision-treesexact-efficient-algorithms/",
        "doi": "10.1609/aaai.v35i8.16851",
        "pdf_size": 246697
    },
    {
        "id": "08128",
        "title": "Counterfactual Fairness with Disentangled Causal Effect Variational Autoencoder",
        "track": "main",
        "status": "Poster",
        "abstract": "The problem of fair classification can be mollified if we develop a method to remove the embedded sensitive information from the classification features. This line of separating the sensitive information is developed through the causal inference, and the causal inference enables the counterfactual generations to contrast the what-if case of the opposite sensitive attribute. Along with this separation with the causality, a frequent assumption in the deep latent causal model defines a single latent variable to absorb the entire exogenous uncertainty of the causal graph. However, we claim that such structure cannot distinguish the 1) information caused by the intervention (i.e.,  sensitive variable) and 2) information correlated with the intervention from the data. Therefore, this paper proposes Disentangled Causal Effect Variational Autoencoder (DCEVAE) to resolve this limitation by disentangling the exogenous uncertainty into two latent variables: either 1) independent to interventions or 2) correlated to interventions without causality. Particularly, our disentangling approach preserves the latent variable correlated to interventions in generating counterfactual examples. We show that our method estimates the total effect and the counterfactual effect without a complete causal graph. By adding a fairness regularization, DCEVAE generates a counterfactual fair dataset while losing less original information. Also, DCEVAE generates natural counterfactual images by only flipping sensitive information. Additionally, we theoretically show the differences in the covariance structures of DCEVAE and prior works from the perspective of the latent disentanglement.",
        "primary_area": "Machine Learning II",
        "author": "Hyemi Kim; Seungjae Shin; JoonHo Jang; Kyungwoo Song; Weonyoung Joo; Wanmo Kang; Il-Chul Moon",
        "authorids": "",
        "aff": "Korea Advanced Institute of Science and Technology; Korea Advanced Institute of Science and Technology; Korea Advanced Institute of Science and Technology; University of Seoul; Korea Advanced Institute of Science and Technology; Korea Advanced Institute of Science and Technology; Korea Advanced Institute of Science and Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16990/16990-13-20484-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08128-counterfactual-fairness-with-disentangled-causal-effect-variational-autoencoder/",
        "doi": "10.1609/aaai.v35i9.16990",
        "pdf_size": 1045388
    },
    {
        "id": "03651",
        "title": "Counting Maximal Satisfiable Subsets",
        "track": "main",
        "status": "Poster",
        "abstract": "Given an unsatisfiable set of constraints F, a maximal satisfiable subset (MSS) is a maximal subset of constraints C \u2286 F such that C is satisfiable. Over the past two decades, the steady improvement in runtime performance of algorithms for finding MSS has led to an increased adoption of MSS-based techniques in wide variety of domains. Motivated by the progress in finding an MSS, the past decade has witnessed a surge of interest in design of algorithmic techniques to enumerate all the MSSes, which has subsequently led to discovery of new applications utilizing enumeration of MSSes. The development of techniques for finding and enumeration of MSSes mirrors a similar phenomenon of finding and enumeration of SAT solutions in the early 2000s, which subsequently motivated design of algorithmic techniques for model counting. In a similar spirit, we undertake study to investigate the feasibility of MSS counting techniques. In particular, the focus point of our investigation is to answer whether one can design efficient MSS counting techniques that do not rely on explicit MSS enumeration. The primary contribution of this work is an affirmative answer to the above question. Our tool, CountMSS, uses a novel architecture of a wrapper W and a remainder R such that the desired MSS count can be expressed as |W| \u2212 |R|. CountMSS relies on the advances in projected model counting to efficiently compute |W| and |R|. Our empirical evaluation demonstrates that CountMSS is able to scale to instances clearly beyond the reach of enumeration-based techniques.",
        "primary_area": "Constraint Satisfaction and Optimization",
        "author": "Jaroslav Bend\u00edk; Kuldeep S. Meel",
        "authorids": "",
        "aff": "Masaryk University; National University of Singapore",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16481/16481-13-19975-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03651-counting-maximal-satisfiable-subsets/",
        "doi": "10.1609/aaai.v35i5.16481",
        "pdf_size": 242304
    },
    {
        "id": "04617",
        "title": "Coupled Layer-wise Graph Convolution for Transportation Demand Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "Graph Convolutional Network (GCN) has been widely applied in transportation demand prediction due to its excellent ability to capture non-Euclidean spatial dependence among station-level or regional transportation demands. However, in most of the existing research, the graph convolution was implemented on a heuristically generated adjacency matrix, which could neither reflect the real spatial relationships of stations accurately, nor capture the multi-level spatial dependence of demands adaptively. To cope with the above problems, this paper provides a novel graph convolutional network for transportation demand prediction. Firstly, a novel graph convolution architecture is proposed, which has different adjacency matrices in different layers and all the adjacency matrices are self-learned during the training process. Secondly, a layer-wise coupling mechanism is provided, which associates the upper-level adjacency matrix with the lower-level one. It also reduces the scale of parameters in our model. Lastly, a unitary network is constructed to give the final prediction result by integrating the hidden spatial states with gated recurrent unit, which could capture the multi-level spatial dependence and temporal dynamics simultaneously. Experiments have been conducted on two real-world datasets, NYC Citi Bike and NYC Taxi, and the results demonstrate the superiority of our model over the state-of-the-art ones.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Junchen Ye; Leilei Sun; Bowen Du; Yanjie Fu; Hui Xiong",
        "authorids": "",
        "aff": "Beihang University; Beihang Univerisity; Beihang Univeristy; University of Central Florida; Rutgers University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16591/16591-13-20085-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04617-coupled-layer-wise-graph-convolution-for-transportation-demand-prediction/",
        "doi": "10.1609/aaai.v35i5.16591",
        "pdf_size": 1163741
    },
    {
        "id": "04418",
        "title": "Coupling Macro-Sector-Micro Financial Indicators for Learning Stock Representations with Less Uncertainty",
        "track": "main",
        "status": "Poster",
        "abstract": "While the stock movement prediction has been intensively studied, existing work suffers from weak generalization because of the uncertainty in both data and modeling. On one hand, training a stock representation on stochastic stock data in an end-to-end manner may lead to excessive modeling, which involves model uncertainty. On the other, the analysis of correlating stock data with its relevant factors involves data uncertainty. To simultaneously address such uncertainty both from data and modeling perspectives, a fundamental yet challenging task is to learn a better stock representation with less uncertainty by considering hierarchical couplings from the macro-level to the sector-and micro-level. Accordingly, we propose a copula-based contrastive predictive coding (Co-CPC) method. Co-CPC first models the dependence between a certain stock sector and relevant macroeconomic variables that are sequential and heterogeneous, e.g., macro-variables are associated with different time intervals, scales, and distributions.  Then, by involving a macro-sector context, stock representations are learned in a self-supervised way that can further be used for downstream tasks like stock movement prediction. Extensive experiments on two typical stock datasets verify the effectiveness of our Co-CPC method.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Guifeng Wang; Longbing Cao; Hongke Zhao; Qi Liu; Enhong Chen",
        "authorids": "",
        "aff": "Anhui Province Key Laboratory of Big Data Analysis and Application, School of Computer Science, University of Science and Technology of China; Advanced Analytics Institute, University of Technology Sydney; College of Management and Economics, Tianjin University; Anhui Province Key Laboratory of Big Data Analysis and Application, School of Computer Science, University of Science and Technology of China; Anhui Province Key Laboratory of Big Data Analysis and Application, School of Computer Science, University of Science and Technology of China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16568/16568-13-20062-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04418-coupling-macro-sector-micro-financial-indicators-for-learning-stock-representations-with-less-uncertainty/",
        "doi": "10.1609/aaai.v35i5.16568",
        "pdf_size": 879311
    },
    {
        "id": "05717",
        "title": "Coupon Design in Advertising Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "Online platforms sell advertisements via auctions (e.g., VCG and GSP auction) and revenue maximization is one of the most important tasks for them. Many revenue increment methods are proposed, like reserve pricing, boosting, coupons and so on. The novelty of coupons rests on the fact that coupons are optional for advertisers while the others are compulsory. Recent studies on coupons have limited applications in advertising systems because they only focus on second price auctions and do not consider the combination with other methods. In this work, we study the coupon design problem for revenue maximization in the widely used VCG auction. Firstly, we examine the bidder strategies in the VCG auction with coupons. Secondly, we cast the coupon design problem into a learning framework and propose corresponding algorithms using the properties of VCG auction. Then we further study how to combine coupons with reserve pricing in our framework. Finally, extensive experiments are conducted to demonstrate the effectiveness of our algorithms based on both synthetic data and industrial data.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Weiran Shen; Pingzhong Tang; Xun Wang; Yadong Xu; Xiwang Yang",
        "authorids": "",
        "aff": "Renmin University of China; Tsinghua University; Tsinghua University; Tsinghua University; Bytedance",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16717/16717-13-20211-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05717-coupon-design-in-advertising-systems/",
        "doi": "10.1609/aaai.v35i6.16717",
        "pdf_size": 608651
    },
    {
        "id": "01799",
        "title": "Cross-Domain Grouping and Alignment for Domain Adaptive Semantic Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "Existing techniques to adapt semantic segmentation networks across source and target domains within deep convolutional neural networks (CNNs) deal with all the samples from the two domains in a global or category-aware manner. They do not consider an inter-class variation within the target domain itself or estimated category, providing the limitation to encode the domains having a multi-modal data distribution. To overcome this limitation, we introduce a learnable clustering module, and a novel domain adaptation framework, called cross-domain grouping and alignment. To cluster the samples across domains with an aim to maximize the domain alignment without forgetting precise segmentation ability on the source domain, we present two loss functions, in particular, for encouraging semantic consistency and orthogonality among the clusters. We also present a loss so as to solve a class imbalance problem, which is the other limitation of the previous methods. Our experiments show that our method consistently boosts the adaptation performance in semantic segmentation, outperforming the state-of-the-arts on various domain adaptation settings.",
        "primary_area": "Computer Vision II",
        "author": "Minsu Kim; Sunghun Joung; Seungryong Kim; JungIn Park; Ig-Jae Kim; Kwanghoon Sohn",
        "authorids": "",
        "aff": "Yonsei University; Yonsei University; Korea University; Yonsei University; KIST; Yonsei University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16274/16274-13-19768-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01799-cross-domain-grouping-and-alignment-for-domain-adaptive-semantic-segmentation/",
        "doi": "10.1609/aaai.v35i3.16274",
        "pdf_size": 2752421
    },
    {
        "id": "07028",
        "title": "Cross-Layer Distillation with Semantic Calibration",
        "track": "main",
        "status": "Poster",
        "abstract": "Recently proposed knowledge distillation approaches based on feature-map transfer validate that intermediate layers of a teacher model can serve as effective targets for training a student model to obtain better generalization ability. Existing studies mainly focus on particular representation forms for knowledge transfer between manually specified pairs of teacher-student intermediate layers. However, semantics of intermediate layers may vary in different networks and manual association of layers might lead to negative regularization caused by semantic mismatch between certain teacher-student layer pairs. To address this problem, we propose Semantic Calibration for Cross-layer Knowledge Distillation (SemCKD), which automatically assigns proper target layers of the teacher model for each student layer with an attention mechanism. With a learned attention distribution, each student layer distills knowledge contained in multiple layers rather than a single fixed intermediate layer from the teacher model for appropriate cross-layer supervision in training. Consistent improvements over state-of-the-art approaches are observed in extensive experiments with various network architectures for teacher and student models, demonstrating the effectiveness and flexibility of the proposed attention based soft layer association mechanism for cross-layer distillation.",
        "primary_area": "Machine Learning I",
        "author": "Defang Chen; Jian-Ping Mei; Yuan Zhang; Can Wang; Zhe Wang; Yan Feng; Chun Chen",
        "authorids": "",
        "aff": "College of Computer Science, Zhejiang University, China. Zhejiang Provincial Key Laboratory of Service Robot. Zhejiang University-LianlianPay Joint Research Center.; College of Computer Science, Zhejiang University of Technology, China.; College of Computer Science, Zhejiang University, China. Zhejiang University-LianlianPay Joint Research Center.; College of Computer Science, Zhejiang University, China. Zhejiang Provincial Key Laboratory of Service Robot. Zhejiang University-LianlianPay Joint Research Center.; College of Computer Science, Zhejiang University, China. Zhejiang University-LianlianPay Joint Research Center.; College of Computer Science, Zhejiang University, China. Zhejiang University-LianlianPay Joint Research Center.; College of Computer Science, Zhejiang University, China. Zhejiang University-LianlianPay Joint Research Center.",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16865/16865-13-20359-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07028-cross-layer-distillation-with-semantic-calibration/",
        "doi": "10.1609/aaai.v35i8.16865",
        "pdf_size": 8527491
    },
    {
        "id": "04215",
        "title": "Cross-Oilfield Reservoir Classification via Multi-Scale Sensor Knowledge Transfer",
        "track": "main",
        "status": "Poster",
        "abstract": "Reservoir classification is an essential step for the exploration and production process in the oil and gas industry. An appropriate automatic reservoir classification will not only reduce the manual workloads of experts, but also help petroleum companies to make optimal decisions efficiently, which in turn will dramatically reduce the costs. Existing methods mainly focused on generating reservoir classification in a single geological block but failed to work well on a new oilfield block. Indeed, how to transfer the subsurface characteristics and make accurate reservoir classification across the geological oilfields is a very important but challenging problem. To that end, in this paper, we present a focused study on the cross-oilfield reservoir classification task. Specifically, we first propose a Multi-scale Sensor Extraction (MSE) to extract the multi-scale feature representations of geological characteristics from multivariate well logs. Furthermore, we design an encoder-decoder module, Specific Feature Learning (SFL), to take advantage of specific information of both oilfields. Then, we develop a Knowledge-Attentive Transfer (KAT) module to learn the feature-invariant representation and transfer the geological knowledge from a source oilfield to a target oilfield. Finally, we evaluate our approaches by conducting extensive experiments with real-world industrial datasets. The experimental results clearly demonstrate the effectiveness of our proposed approaches to transfer the geological knowledge and generate the cross-oilfield reservoir classifications.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Zhi Li; Zhefeng Wang; Zhicheng Wei; Xiangguang Zhou; Yijun Wang; Baoxing Huai; Qi Liu; Nicholas Jing Yuan; Renbin Gong; Enhong Chen",
        "authorids": "",
        "aff": "University of Science and Technology of China; Huawei Cloud & AI; Huawei Cloud & AI; Research Institute of Petroleum Exploration & Development, PetroChina; Huawei Cloud & AI; Huawei Cloud & AI; University of Science and Technology of China; Huawei Cloud & AI; Research Institute of Petroleum Exploration & Development, PetroChina; University of Science and Technology of China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16545/16545-13-20039-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04215-cross-oilfield-reservoir-classification-via-multi-scale-sensor-knowledge-transfer/",
        "doi": "10.1609/aaai.v35i5.16545",
        "pdf_size": 1378516
    },
    {
        "id": "13452",
        "title": "CrossNER: Evaluating Cross-Domain Named Entity Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "Cross-domain named entity recognition (NER) models are able to cope with the scarcity issue of NER samples in target domains. However, most of the existing NER benchmarks lack domain-specialized entity types or do not focus on a certain domain, leading to a less effective cross-domain evaluation. To address these obstacles, we introduce a cross-domain NER dataset (CrossNER), a fully-labeled collection of NER data spanning over five diverse domains with specialized entity categories for different domains. Additionally, we also provide a domain-related corpus since using it to continue pre-training language models (domain-adaptive pre-training) is effective for the domain adaptation. We then conduct comprehensive experiments to explore the effectiveness of leveraging different levels of the domain corpus and pre-training strategies to do domain-adaptive pre-training for the cross-domain task. Results show that focusing on the fractional corpus containing domain-specialized entities and utilizing a more challenging pre-training strategy in domain-adaptive pre-training are beneficial for the NER domain adaptation, and our proposed method can consistently outperform existing cross-domain NER baselines. Nevertheless, experiments also illustrate the challenge of this cross-domain NER task. We hope that our dataset and baselines will catalyze research in the NER domain adaptation area. The code and data are available at https://github.com/zliucr/CrossNER.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Zihan Liu; Yan Xu; Tiezheng Yu; Wenliang Dai; Ziwei Ji; Samuel Cahyawijaya; Andrea Madotto; Pascale Fung",
        "authorids": "",
        "aff": "The Hong Kong University of Science and Technology; Hong Kong University of Science and Technology; The Hong Kong University of Science and Technology; The Hong Kong University of Science and Technology; The Hong Kong University of Science and Technology; The Hong Kong University of Science and Technology; The Hong Kong University of Science and Technology; The Hong Kong University of Science and Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17587/17587-13-21081-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13452-crossner-evaluating-cross-domain-named-entity-recognition/",
        "doi": "10.1609/aaai.v35i15.17587",
        "pdf_size": 2979936
    },
    {
        "id": "06912",
        "title": "Curriculum Labeling: Revisiting Pseudo-Labeling for Semi-Supervised Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper we revisit the idea of pseudo-labeling in the context of semi-supervised learning where a learning algorithm has access to a small set of labeled samples and a large set of unlabeled samples. Pseudo-labeling works by applying pseudo-labels to samples in the unlabeled set by using a model trained on combination of the labeled samples and any previously pseudo-labeled samples, and iteratively repeating this process in a self-training cycle. Current methods seem to have abandoned this approach in favor of consistency regularization methods that train models under a combination of different styles of self-supervised losses on the unlabeled samples and standard supervised losses on the labeled samples. We empirically demonstrate that pseudo-labeling can in fact be competitive with the state-of-the-art, while being more resilient to out-of-distribution samples in the unlabeled set. We identify two key factors that allow pseudo-labeling to achieve such remarkable results (1) applying curriculum learning principles and (2) avoiding concept drift by restarting model parameters before each self-training cycle. We obtain 94.91% accuracy on CIFAR-10 using only 4,000 labeled samples, and 68.87% top-1 accuracy on Imagenet-ILSVRC using only 10% of the labeled samples.",
        "primary_area": "Machine Learning I",
        "author": "Paola Cascante-Bonilla; Fuwen Tan; Yanjun Qi; Vicente Ordonez",
        "authorids": "",
        "aff": "University of Virginia; University of Virginia; University of Virginia; University of Virginia",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16852/16852-13-20346-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06912-curriculum-labeling-revisiting-pseudo-labeling-for-semi-supervised-learning/",
        "doi": "10.1609/aaai.v35i8.16852",
        "pdf_size": 203336
    },
    {
        "id": "10363",
        "title": "Curriculum-Meta Learning for Order-Robust Continual Relation Extraction",
        "track": "main",
        "status": "Poster",
        "abstract": "Continual relation extraction is an important task that focuses on extracting new facts incrementally from unstructured text.  Given the sequential arrival order of the relations, this task is prone to two serious challenges, namely catastrophic forgetting and order-sensitivity. We propose a novel curriculum-meta learning method to tackle the above two challenges in continual relation extraction. We combine meta learning and curriculum learning to quickly adapt model parameters to a new task and to reduce interference of previously seen tasks on the current task.  We design a novel relation representation learning method through the distribution of domain and range types of relations.  Such representations are utilized to quantify the difficulty of tasks for the construction of curricula. Moreover, we also present novel difficulty-based metrics to quantitatively measure the extent of order-sensitivity of a given model, suggesting new ways to evaluate model robustness.  Our comprehensive experiments on three benchmark datasets show that our proposed method outperforms the state-of-the-art techniques.  The code is available at the anonymous GitHub repository: https://github.com/wutong8023/AAAI_CML.",
        "primary_area": "Machine Learning V",
        "author": "Tongtong Wu; Xuekai Li; Yuan-Fang Li; Gholamreza Haffari; Guilin Qi; Yujin Zhu; Guoqiang Xu",
        "authorids": "",
        "aff": "School of Computer Science and Engineering, Southeast University, Nanjing, China; School of Computer Science and Engineering, Southeast University, Nanjing, China; Faculty of Information Technology, Monash University, Melbourne, Australia; Faculty of Information Technology, Monash University, Melbourne, Australia; School of Computer Science and Engineering, Southeast University, Nanjing, China; Gamma Lab, Ping An OneConnect, Shanghai, China; Gamma Lab, Ping An OneConnect, Shanghai, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17241/17241-13-20735-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10363-curriculum-meta-learning-for-order-robust-continual-relation-extraction/",
        "doi": "10.1609/aaai.v35i12.17241",
        "pdf_size": 412565
    },
    {
        "id": "10807",
        "title": "Curse or Redemption? How Data Heterogeneity Affects the Robustness of Federated Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Data heterogeneity has been identified as one of the key features in federated learning but often overlooked in the lens of robustness to adversarial attacks. This paper focuses on characterizing and understanding its impact on backdooring attacks in federated learning through comprehensive experiments using synthetic and the LEAF benchmarks. The initial impression driven by our experimental results suggests that data heterogeneity is the dominant factor in the effectiveness of attacks and it may be a redemption for defending against backdooring as it makes the attack less efficient, more challenging to design effective attack strategies, and the attack result also becomes less predictable. However, with further investigations, we found data heterogeneity is more of a curse than a redemption as the attack effectiveness can be significantly boosted by simply adjusting the client-side backdooring timing. More importantly, data heterogeneity may result in overfitting at the local training of benign clients, which can be utilized by attackers to disguise themselves and fool skewed-feature based defenses. In addition, effective attack strategies can be made by adjusting attack data distribution. Finally, we discuss the potential directions of defending the curses brought by data heterogeneity. The results and lessons learned from our extensive experiments and analysis offer new insights for designing robust federated learning methods and systems.",
        "primary_area": "Machine Learning V",
        "author": "Syed Zawad; Ahsan Ali; Pin-Yu Chen; Ali Anwar; Yi Zhou; Nathalie Baracaldo; Yuan Tian; Feng Yan",
        "authorids": "",
        "aff": "University of Nervada, Reno; University of Nevada, Reno; IBM Research; IBM Research; IBM Research; IBM Research; University of Virginia; University of Nevada, Reno",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17291/17291-13-20785-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10807-curse-or-redemption-how-data-heterogeneity-affects-the-robustness-of-federated-learning/",
        "doi": "10.1609/aaai.v35i12.17291",
        "pdf_size": 1013447
    },
    {
        "id": "03750",
        "title": "Cutting to the Core of Pseudo-Boolean Optimization: Combining Core-Guided Search with Cutting Planes Reasoning",
        "track": "main",
        "status": "Poster",
        "abstract": "Core-guided techniques have revolutionized Boolean satisfiability approaches to optimization problems (MaxSAT), but the process at the heart of these methods, strengthening bounds on solutions by repeatedly adding cardinality constraints, remains a bottleneck. Cardinality constraints require significant work to be re-encoded to SAT, and SAT solvers are notoriously weak at cardinality reasoning.  In this work, we lift core-guided search to pseudo-Boolean (PB) solvers, which deal with more general PB optimization problems and operate natively with cardinality constraints. The cutting planes method used in such solvers allows us to derive stronger cardinality constraints, which yield better updates to solution bounds, and the increased efficiency of objective function reformulation also makes it feasible to switch repeatedly between lower-bounding and upper- bounding search. A thorough evaluation on applied and crafted benchmarks shows that our core-guided PB solver significantly improves on the state of the art in pseudo-Boolean optimization.",
        "primary_area": "Constraint Satisfaction and Optimization",
        "author": "Jo Devriendt; Stephan Gocht; Emir Demirovi\u0107; Jakob Nordstr\u00f6m; Peter J. Stuckey",
        "authorids": "",
        "aff": "Lund University University of Copenhagen KU Leuven; Lund University University of Copenhagen; Delft University of Technology; University of Copenhagen Lund University; Monash University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16492/16492-13-19986-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03750-cutting-to-the-core-of-pseudo-boolean-optimization-combining-core-guided-search-with-cutting-planes-reasoning/",
        "doi": "10.1609/aaai.v35i5.16492",
        "pdf_size": 1162051
    },
    {
        "id": "06557",
        "title": "DART: Adaptive Accept Reject Algorithm for Non-Linear Combinatorial Bandits",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider the bandit problem of selecting K out of N arms at each time step. The joint reward can be a non-linear function of the rewards of the selected individual arms. The direct use of a multi-armed bandit algorithm requires choosing among all possible combinations, making the action space large. To simplify the problem, existing works on combinatorial bandits typically assume feedback as a linear function of individual rewards. In this paper, we prove the lower bound for top-K subset selection with bandit feedback with possibly correlated rewards. We present a novel algorithm for the combinatorial setting without using individual arm feedback or requiring linearity of the reward function. Additionally, our algorithm works on correlated rewards of individual arms. Our algorithm, aDaptive Accept RejecT (DART), sequentially finds good arms and eliminates bad arms based on confidence bounds. DART is computationally efficient and uses storage linear in N. Further, DART  achieves a regret bound of \u00d5(K\u221aKNT) for a time horizon T, which matches the lower bound in bandit feedback up to a factor of \u221alog 2NT. When applied to the problem of cross-selling optimization and maximizing the mean of individual rewards, the performance of the proposed algorithm surpasses that of state-of-the-art algorithms. We also show that DART significantly outperforms existing methods for both linear and non-linear joint reward environments.",
        "primary_area": "Machine Learning I",
        "author": "Mridul Agarwal; Vaneet Aggarwal; Abhishek Kumar Umrawal; Chris Quinn",
        "authorids": "",
        "aff": "Purdue University; Purdue University; Purdue University; Iowa State University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16812/16812-13-20306-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06557-dart-adaptive-accept-reject-algorithm-for-non-linear-combinatorial-bandits/",
        "doi": "10.1609/aaai.v35i8.16812",
        "pdf_size": 319607
    },
    {
        "id": "10754",
        "title": "DAST: Unsupervised Domain Adaptation in Semantic Segmentation Based on Discriminator Attention and Self-Training",
        "track": "main",
        "status": "Poster",
        "abstract": "Unsupervised domain adaption has recently been used to reduce the domain shift, which would ultimately improve the performance of the semantic segmentation on unlabeled real-world data. In this paper, we follow the trend to propose a novel method to reduce the domain shift using strategies of discriminator attention and self-training. The discriminator attention strategy contains a two-stage adversarial learning process, which explicitly distinguishes the well-aligned (domain-invariant) and poorly-aligned (domain-specific) features, and then guides the model to focus on the latter. The self-training strategy adaptively improves the decision boundary of the model for the target domain, which implicitly facilitates the extraction of domain-invariant features. By combining the two strategies, we find a more effective way to reduce the domain shift. Extensive experiments demonstrate the effectiveness of the proposed method on numerous benchmark datasets.",
        "primary_area": "Machine Learning V",
        "author": "Fei Yu; Mo Zhang; Hexin Dong; Sheng Hu; Bin Dong; Li Zhang",
        "authorids": "",
        "aff": "Peking University; Peking University; Peking University; Peking University; Peking University Beijing International Center for Mathematical Research(BICMR); Peking University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17285/17285-13-20779-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10754-dast-unsupervised-domain-adaptation-in-semantic-segmentation-based-on-discriminator-attention-and-self-training/",
        "doi": "10.1609/aaai.v35i12.17285",
        "pdf_size": 860768
    },
    {
        "id": "01817",
        "title": "DASZL: Dynamic Action Signatures for Zero-shot Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "There are many realistic applications of activity recognition where the set of potential activity descriptions is combinatorially large. This makes end-to-end supervised training of a recognition system impractical as no training set is practically able to encompass the entire label set. In this paper, we present an approach to fine-grained recognition that models activities as compositions of dynamic action signatures.  This compositional approach allows us to reframe fine-grained recognition as zero-shot activity recognition,  where a detector is composed \"on the fly\" from simple first-principles state machines supported by deep-learned components.  We evaluate our method on the Olympic Sports and UCF101 datasets, where our model establishes a new state of the art under multiple experimental paradigms. We also extend this method to form a unique framework for zero-shot joint segmentation and classification of activities in video and demonstrate the first results in zero- shot decoding of complex action sequences on a widely-used surgical dataset. Lastly, we show that we can use  off-the-shelf object detectors to recognize activities in completely de-novo settings with no additional training.",
        "primary_area": "Computer Vision II",
        "author": "Tae Soo Kim; Jonathan Jones; Michael Peven; Zihao Xiao; Jin Bai; Yi Zhang; Weichao Qiu; Alan Yuille; Gregory D. Hager",
        "authorids": "",
        "aff": "Johns Hopkins University; Johns Hopkins University; Johns Hopkins University; Johns Hopkins University; Johns Hopkins University; Johns Hopkins University; Johns Hopkins University; Johns Hopkins University; Johns Hopkins University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16276/16276-13-19770-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01817-daszl-dynamic-action-signatures-for-zero-shot-learning/",
        "doi": "10.1609/aaai.v35i3.16276",
        "pdf_size": 1475640
    },
    {
        "id": "13125",
        "title": "DDRel: A New Dataset for Interpersonal Relation Classification in Dyadic Dialogues",
        "track": "main",
        "status": "Poster",
        "abstract": "Interpersonal language style shifting in dialogues is an interesting and almost instinctive ability of human. Understanding interpersonal relationship from language content is also a crucial step toward further understanding dialogues. Previous work mainly focuses on relation extraction between named entities in texts or within a single dialogue session.  In this paper, we propose the task of relation classification of interlocutors based on their dialogues. We crawled movie scripts from IMSDb, and annotated the relation label for each session according to 13 pre-defined relationships. The annotated dataset DDRel consists of 6,300 dyadic dialogue sessions between 694 pairs of speakers with 53,126 utterances in total. We also construct session-level and pair-level relation classification tasks with widely-accepted baselines. The experimental results show that both tasks are challenging for existing models and the dataset will be useful for future research.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Qi Jia; Hongru Huang; Kenny Q. Zhu",
        "authorids": "",
        "aff": "Shanghai Jiao Tong University; Shanghai Jiao Tong University; Shanghai Jiao Tong University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17551/17551-13-21045-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13125-ddrel-a-new-dataset-for-interpersonal-relation-classification-in-dyadic-dialogues/",
        "doi": "10.1609/aaai.v35i14.17551",
        "pdf_size": 536840
    },
    {
        "id": "00750",
        "title": "DEAR: Deep Reinforcement Learning for Online Advertising Impression in Recommender Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "With the recent prevalence of Reinforcement Learning (RL), there have been tremendous interests in utilizing RL for online advertising in recommendation platforms (e.g., e-commerce and news feed sites). However, most RL-based advertising algorithms focus on optimizing ads' revenue while ignoring the possible negative influence of ads on user experience of recommended items (products, articles and videos). Developing an optimal advertising algorithm in recommendations faces immense challenges because interpolating ads improperly or too frequently may decrease user experience, while interpolating fewer ads will reduce the advertising revenue. Thus, in this paper, we propose a novel advertising strategy for the rec/ads trade-off. To be specific, we develop an RL-based framework that can continuously update its advertising strategies and maximize reward in the long run. Given a recommendation list, we design a novel Deep Q-network architecture that can determine three internally related tasks jointly, i.e., (i) whether to interpolate an ad or not in the recommendation list, and if yes, (ii) the optimal ad and (iii) the optimal location to interpolate. The experimental results based on real-world data demonstrate the effectiveness of the proposed framework.",
        "primary_area": "Application Domains",
        "author": "Xiangyu Zhao; Changsheng Gu; Haoshenglun Zhang; Xiwang Yang; Xiaobing Liu; Jiliang Tang; Hui Liu",
        "authorids": "",
        "aff": "Michigan State University; Bytedance; Bytedance; Bytedance; Bytedance; Michigan State University; Michigan State University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16156/16156-13-19650-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00750-dear-deep-reinforcement-learning-for-online-advertising-impression-in-recommender-systems/",
        "doi": "10.1609/aaai.v35i1.16156",
        "pdf_size": 2693503
    },
    {
        "id": "09666",
        "title": "DIBS: Diversity Inducing Information Bottleneck in Model Ensembles",
        "track": "main",
        "status": "Poster",
        "abstract": "Although deep learning models have achieved state-of-the art performance on a number of vision tasks, generalization over high dimensional multi-modal data, and reliable predictive uncertainty estimation are still active areas of research.  Bayesian approaches including Bayesian Neural Nets (BNNs) do not scale well to modern computer vision tasks, as they are difficult to train, and have poor generalization under dataset-shift. This motivates the need for effective ensembles which can generalize and give reliable uncertainty estimates. In this paper, we target the problem of generating effective ensembles of neural networks by encouraging diversity in prediction. We explicitly optimize a diversity inducing adversarial loss for learning the stochastic latent variables and thereby obtain diversity in the output predictions necessary for modeling multi-modal data. We evaluate our method on benchmark datasets: MNIST, CIFAR100, TinyImageNet and MIT Places 2, and compared to the most competitive baselines show significant improvements in classification accuracy, under a shift in the data distribution and in out-of-distribution detection. over 10% relative improvement in classification accuracy, over 5% relative improvement in generalizing under dataset shift, and over 5% better predictive uncertainty estimation as inferred by efficient out-of-distribution (OOD) detection.",
        "primary_area": "Machine Learning IV",
        "author": "Samarth Sinha; Homanga Bharadhwaj; Anirudh Goyal; Hugo Larochelle; Animesh Garg; Florian Shkurti",
        "authorids": "",
        "aff": "University of Toronto Vector Institute; University of Toronto Vector Institute; University of Montreal; Google; University of Toronto Vector Institute; University of Toronto Vector Institute",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17163/17163-13-20657-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09666-dibs-diversity-inducing-information-bottleneck-in-model-ensembles/",
        "doi": "10.1609/aaai.v35i11.17163",
        "pdf_size": 366660
    },
    {
        "id": "01291",
        "title": "DIRV: Dense Interaction Region Voting for End-to-End Human-Object Interaction Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent years, human-object interaction (HOI) detection has achieved impressive advances. However, conventional two-stage methods are usually slow in inference. On the other hand, existing one-stage methods mainly focus on the union regions of interactions, which introduce unnecessary visual information as disturbances to HOI detection. To tackle the problems above, we propose a novel one-stage HOI detection approach DIRV in this paper, based on a new concept called interaction region for the HOI problem. Unlike previous methods, our approach concentrates on the densely sampled interaction regions across different scales for each human-object pair, so as to capture the subtle visual features that is most essential to the interaction. Moreover, in order to compensate for the detection flaws of a single interaction region, we introduce a novel voting strategy that makes full use of those overlapped interaction regions in place of conventional Non-Maximal Suppression (NMS). Extensive experiments on two popular benchmarks: V-COCO and HICO-DET show that our approach outperforms existing state-of-the-arts by a large margin with the highest inference speed and lightest network architecture. Our code  is publicly available at www.github.com/MVIG-SJTU/DIRV.",
        "primary_area": "Computer Vision I",
        "author": "Hao-Shu Fang; Yichen Xie; Dian Shao; Cewu Lu",
        "authorids": "",
        "aff": "Shanghai Jiao Tong University; Shanghai Jiao Tong University; The Chinese University of Hong Kong; Shanghai Jiao Tong University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16217/16217-13-19711-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01291-dirv-dense-interaction-region-voting-for-end-to-end-human-object-interaction-detection/",
        "doi": "10.1609/aaai.v35i2.16217",
        "pdf_size": 10848475
    },
    {
        "id": "02495",
        "title": "DPFPS: Dynamic and Progressive Filter Pruning for Compressing Convolutional Neural Networks from Scratch",
        "track": "main",
        "status": "Poster",
        "abstract": "Filter pruning is a commonly used method for compressing Convolutional Neural Networks (ConvNets), due to its friendly hardware supporting and flexibility. However, existing methods mostly need a cumbersome procedure, which brings many extra hyper-parameters and training epochs. This is because only using sparsity and pruning stages cannot obtain a satisfying performance. Besides, many works do not consider the difference of pruning ratio across different layers. To overcome these limitations, we propose a novel dynamic and progressive filter pruning (DPFPS) scheme that directly learns a structured sparsity network from Scratch. In particular, DPFPS imposes a new structured sparsity-inducing regularization specifically upon the expected pruning parameters in a dynamic sparsity manner. The dynamic sparsity scheme determines sparsity allocation ratios of different layers and a Taylor series based channel sensitivity criteria is presented to identify the expected pruning parameters. Moreover, we increase the structured sparsity-inducing penalty in a progressive manner. This helps the model to be sparse gradually instead of forcing the model to be sparse at the beginning. Our method solves the pruning ratio based optimization problem by an iterative soft-thresholding algorithm (ISTA) with dynamic sparsity. At the end of the training, we only need to remove the redundant parameters without other stages, such as fine-tuning. Extensive experimental results show that the proposed method is competitive with 11 state-of-the-art methods on both small-scale and large-scale datasets (i.e., CIFAR and ImageNet). Specifically, on ImageNet, we achieve a 44.97% pruning ratio of FLOPs by compressing ResNet-101, even with an increase of 0.12% Top-5 accuracy. Our pruned models and codes are released at https://github.com/taoxvzi/DPFPS.",
        "primary_area": "Computer Vision II",
        "author": "Xiaofeng Ruan; Yufan Liu; Bing Li; Chunfeng Yuan; Weiming Hu",
        "authorids": "",
        "aff": "National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences School of Artificial Intelligence, University of Chinese Academy of Sciences; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences School of Artificial Intelligence, University of Chinese Academy of Sciences; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences PeopleAI Inc.; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences School of Artificial Intelligence, University of Chinese Academy of Sciences CAS Center for Excellence in Brain Science and Intelligence Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16351/16351-13-19845-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02495-dpfps-dynamic-and-progressive-filter-pruning-for-compressing-convolutional-neural-networks-from-scratch/",
        "doi": "10.1609/aaai.v35i3.16351",
        "pdf_size": 668037
    },
    {
        "id": "08146",
        "title": "DPM: A Novel Training Method for Physics-Informed Neural Networks in Extrapolation",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a method for learning dynamics of complex physical processes described by time-dependent nonlinear partial differential equations (PDEs). Our particular interest lies in extrapolating solutions in time beyond the range of temporal domain used in training. Our choice for a baseline method is physics-informed neural network (PINN) because the method parameterizes not only the solutions, but also the equations that describe the dynamics of physical processes. We demonstrate that PINN performs poorly on extrapolation tasks in many benchmark problems. To address this, we propose a novel method for better training PINN and demonstrate that our newly enhanced PINNs can accurately extrapolate solutions in time. Our method shows up to 72% smaller errors than state-of-the-art methods in terms of the standard L2-norm metric.",
        "primary_area": "Machine Learning II",
        "author": "Jungeun Kim; Kookjin Lee; Dongeun Lee; Sheo Yon Jhin; Noseong Park",
        "authorids": "",
        "aff": "Yonsei University; Sandia National Lab; Texas A&M University-Commerce; Yonsei University; Yonsei University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16992/16992-13-20486-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08146-dpm-a-novel-training-method-for-physics-informed-neural-networks-in-extrapolation/",
        "doi": "10.1609/aaai.v35i9.16992",
        "pdf_size": 1221758
    },
    {
        "id": "13666",
        "title": "Data Augmentation for Abstractive Query-Focused Multi-Document Summarization",
        "track": "main",
        "status": "Poster",
        "abstract": "The progress in Query-focused Multi-Document Summarization (QMDS) has been limited by the lack of sufficient largescale high-quality training datasets. We present two QMDS training datasets, which we construct using two data augmentation methods: (1) transferring the commonly used single-document CNN/Daily Mail summarization dataset to create the QMDSCNN dataset, and (2) mining search-query logs to create the QMDSIR dataset. These two datasets have complementary properties, i.e., QMDSCNN has real summaries but queries are simulated, while QMDSIR has real queries but simulated summaries. To cover both these real summary and query aspects, we build abstractive end-to-end neural network models on the combined datasets that yield new state-of-the-art transfer results on DUC datasets. We also introduce new hierarchical encoders that enable a more efficient encoding of the query together with multiple documents. Empirical results demonstrate that our data augmentation and encoding methods outperform baseline models on automatic metrics, as well as on human evaluations along multiple attributes.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Ramakanth Pasunuru; Asli Celikyilmaz; Michel Galley; Chenyan Xiong; Yizhe Zhang; Mohit Bansal; Jianfeng Gao",
        "authorids": "",
        "aff": "University of North Carolina at Chapel Hill; Microsoft Research; Microsoft Research; Microsoft Research; Microsoft Research; University of North Carolina at Chapel Hill; Microsoft Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17611/17611-13-21105-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13666-data-augmentation-for-abstractive-query-focused-multi-document-summarization/",
        "doi": "10.1609/aaai.v35i15.17611",
        "pdf_size": 416347
    },
    {
        "id": "11015",
        "title": "Data Augmentation for Graph Neural Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Data augmentation has been widely used to improve generalizability of machine learning models.  However, comparatively little work studies data augmentation for graphs.  This is largely due to the complex, non-Euclidean structure of graphs, which limits possible manipulation operations. Augmentation operations commonly used in vision and language have no analogs for graphs.  Our work studies graph data augmentation for graph neural networks (GNNs) in the context of improving semi-supervised node-classification.  We discuss practical and theoretical motivations, considerations and strategies for graph data augmentation.  Our work shows that neural edge predictors can effectively encode class-homophilic structure to promote intra-class edges and demote inter-class edges in given graph structure, and our main contribution introduces the GAug graph data augmentation framework, which leverages these insights to improve performance in GNN-based node classification via edge prediction. Extensive experiments on multiple benchmarks show that augmentation via GAug improves performance across GNN architectures and datasets.",
        "primary_area": "Machine Learning V",
        "author": "Tong Zhao; Yozen Liu; Leonardo Neves; Oliver Woodford; Meng Jiang; Neil Shah",
        "authorids": "",
        "aff": "University of Notre Dame; Snap Inc; Snap Inc.; Snap Inc; University of Notre Dame; Snap Inc.",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17315/17315-13-20809-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11015-data-augmentation-for-graph-neural-networks/",
        "doi": "10.1609/aaai.v35i12.17315",
        "pdf_size": 3392665
    },
    {
        "id": "10245",
        "title": "Data-Free Knowledge Distillation with Soft Targeted Transfer Set Synthesis",
        "track": "main",
        "status": "Poster",
        "abstract": "Knowledge distillation (KD) has proved to be an effective approach for deep neural network compression, which learns a compact network (student) by transferring the knowledge from a pre-trained, over-parameterized network (teacher). In traditional KD, the transferred knowledge is usually obtained by feeding training samples to the teacher network to obtain the class probabilities. However, the original training dataset is not always available due to storage costs or privacy issues. In this study, we propose a novel data-free KD approach by modeling the intermediate feature space of the teacher with a multivariate normal distribution and leveraging the soft targeted labels generated by the distribution to synthesize pseudo samples as the transfer set. Several student networks trained with these synthesized transfer sets present competitive performance compared to the networks trained with the original training set and other data-free KD approaches.",
        "primary_area": "Machine Learning IV",
        "author": "Zi Wang",
        "authorids": "",
        "aff": "The University of Tennessee, Knoxville, TN",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17228/17228-13-20722-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10245-data-free-knowledge-distillation-with-soft-targeted-transfer-set-synthesis/",
        "doi": "10.1609/aaai.v35i11.17228",
        "pdf_size": 872879
    },
    {
        "id": "10833",
        "title": "Data-driven Competitive Algorithms for Online Knapsack and Set Cover",
        "track": "main",
        "status": "Poster",
        "abstract": "The design of online algorithms has tended to focus on algorithms with worst-case guarantees, e.g., bounds on the competitive ratio.  However, it is well-known that such algorithms are often overly pessimistic, performing sub-optimally on non-worst-case inputs.  In this paper, we develop an approach for data-driven design of online algorithms that maintain near-optimal worst-case guarantees while also performing learning in order to perform well for typical inputs. Our approach is to identify policy classes that admit global worst-case guarantees, and then perform learning using historical data within the policy classes. We demonstrate the approach in the context of two classical problems, online knapsack and online set cover, proving competitive bounds for rich policy classes in each case. Additionally, we illustrate the practical implications via a case study on electric vehicle charging.",
        "primary_area": "Machine Learning V",
        "author": "Ali Zeynali; Bo Sun; Mohammad Hajiesmaili; Adam Wierman",
        "authorids": "",
        "aff": "University of Massachusetts, Amherst; Hong Kong University of Science and Technology; University of Massachusetts, Amherst; California Institute of Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17294/17294-13-20788-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10833-data-driven-competitive-algorithms-for-online-knapsack-and-set-cover/",
        "doi": "10.1609/aaai.v35i12.17294",
        "pdf_size": 307344
    },
    {
        "id": "10585",
        "title": "DeHiB: Deep Hidden Backdoor Attack on Semi-supervised Learning via Adversarial Perturbation",
        "track": "main",
        "status": "Poster",
        "abstract": "The threat of data-poisoning backdoor attacks on learning algorithms typically comes from the labeled data. However, in deep semi-supervised learning (SSL), unknown threats mainly stem from the unlabeled data. In this paper, we propose a novel deep hidden backdoor (DeHiB) attack scheme for SSL-based systems. In contrast to the conventional attacking methods, the DeHiB can inject malicious unlabeled training data to the semi-supervised learner so as to enable the SSL model to output premeditated results. In particular, a robust adversarial perturbation generator regularized by a unified objective function is proposed to generate poisoned data. To alleviate the negative impact of the trigger patterns on model accuracy and improve the attack success rate, a novel contrastive data poisoning strategy is designed. Using the proposed data poisoning scheme, one can implant the backdoor into the SSL model using the raw data without hand-crafted labels. Extensive experiments based on CIFAR10 and CIFAR100 datasets demonstrated the effectiveness and crypticity of the proposed scheme.",
        "primary_area": "Machine Learning V",
        "author": "Zhicong Yan; Gaolei Li; Yuan TIan; Jun Wu; Shenghong Li; Mingzhe Chen; H. Vincent Poor",
        "authorids": "",
        "aff": "Shanghai Jiaotong University, Shanghai, China; Shanghai Jiaotong University, Shanghai, China; Shanghai Jiaotong University, Shanghai, China; Shanghai Jiaotong University, Shanghai, China; Shanghai Jiaotong University, Shanghai, China; Princeton University, Princeton, USA; Princeton University, Princeton, USA",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17266/17266-13-20760-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10585-dehib-deep-hidden-backdoor-attack-on-semi-supervised-learning-via-adversarial-perturbation/",
        "doi": "10.1609/aaai.v35i12.17266",
        "pdf_size": 872775
    },
    {
        "id": "10120",
        "title": "Debiasing Evaluations That Are Biased by Evaluations",
        "track": "main",
        "status": "Poster",
        "abstract": "It is common to evaluate a set of items by soliciting people to rate them. For example, universities ask students  to rate the teaching quality of their instructors, and conference organizers ask authors of submissions to evaluate the quality of the reviews. However, in these applications, students often give a higher rating to a course if they receive higher grades in a course, and authors often give a higher rating to the reviews if their papers are accepted to the conference. In this work, we call these external factors the \"outcome\" experienced by people, and consider the problem of mitigating these outcome-induced biases in the given ratings when some information about the outcome is available. We formulate the information about the outcome as a known partial ordering on the bias. We  propose a debiasing method by solving a regularized optimization problem under this ordering constraint, and also provide a carefully designed cross-validation method that adaptively chooses the appropriate amount of regularization. We provide theoretical guarantees on the performance of our algorithm, as well as experimental evaluations.",
        "primary_area": "Machine Learning IV",
        "author": "Jingyan Wang; Ivan Stelmakh; Yuting Wei; Nihar B. Shah",
        "authorids": "",
        "aff": "Carnegie Mellon University; Carnegie Mellon University; Carnegie Mellon University; Carnegie Mellon University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17214/17214-13-20708-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10120-debiasing-evaluations-that-are-biased-by-evaluations/",
        "doi": "10.1609/aaai.v35i11.17214",
        "pdf_size": 167494
    },
    {
        "id": "11282",
        "title": "Dec-SGTS: Decentralized Sub-Goal Tree Search for Multi-Agent Coordination",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-agent coordination tends to benefit from efficient communication, where cooperation often happens based on exchanging information about what the agents intend to do, i.e. intention sharing. It becomes a key problem to model the intention by some proper abstraction. Currently, it is either too coarse such as final goals or too fined as primitive steps, which is inefficient due to the lack of modularity and semantics. In this paper, we design a novel multi-agent coordination protocol based on subgoal intentions, defined as the probability distribution over feasible subgoal sequences. The subgoal intentions encode macro-action behaviors with modularity so as to facilitate joint decision making at higher abstraction. Built over the proposed protocol, we present Dec-SGTS (Decentralized Sub-Goal Tree Search) to solve decentralized online multi-agent planning hierarchically and efficiently. Each agent runs Dec-SGTS asynchronously by iteratively performing three phases including local sub-goal tree search, local subgoal intention update and global subgoal intention sharing. We conduct the experiments on courier dispatching problem, and the results show that Dec-SGTS achieves much better reward while enjoying a significant reduction of planning time and communication cost compared with Dec-MCTS (Decentralized Monte Carlo Tree Search).",
        "primary_area": "Multiagent Systems",
        "author": "Minglong Li; Zhongxuan Cai; Wenjing Yang; Lixia Wu; Yinghui Xu; Ji Wang",
        "authorids": "",
        "aff": "Institute for Quantum Information & State Key Laboratory of High Performance Computing, College of Computer, National University of Defense Technology, China; Institute for Quantum Information & State Key Laboratory of High Performance Computing, College of Computer, National University of Defense Technology, China; Institute for Quantum Information & State Key Laboratory of High Performance Computing, College of Computer, National University of Defense Technology, China; Artificial Intelligence Department, Zhejiang Cainiao Supply Chain Management Co., Ltd., China; Artificial Intelligence Department, Zhejiang Cainiao Supply Chain Management Co., Ltd., China; Institute for Quantum Information & State Key Laboratory of High Performance Computing, College of Computer, National University of Defense Technology, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17345/17345-13-20839-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11282-dec-sgts-decentralized-sub-goal-tree-search-for-multi-agent-coordination/",
        "doi": "10.1609/aaai.v35i13.17345",
        "pdf_size": 751765
    },
    {
        "id": "01300",
        "title": "DecAug: Augmenting HOI Detection via Decomposition",
        "track": "main",
        "status": "Poster",
        "abstract": "Human-object interaction (HOI) detection requires a large amount of annotated data. Current algorithms suffer from insufficient training samples and category imbalance within datasets. To increase data efficiency, in this paper, we propose an efficient and effective data augmentation method called DecAug for HOI detection. Based on our proposed object state similarity metric, object patterns across different HOIs are shared to augment local object appearance features without changing their states. Further, we shift spatial correlation between humans and objects to other feasible configurations with the aid of a pose-guided Gaussian Mixture Model while preserving their interactions. Experiments show that our method brings up to 3.3 mAP and 1.6 mAP improvements on V-COCO and HICO-DET dataset for two advanced models. Specifically, interactions with fewer samples enjoy more notable improvement. Our method can be easily integrated into various HOI detection models with negligible extra computational consumption.",
        "primary_area": "Computer Vision I",
        "author": "Hao-Shu Fang; Yichen Xie; Dian Shao; Yong-Lu Li; Cewu Lu",
        "authorids": "",
        "aff": "Shanghai Jiao Tong University; Shanghai Jiao Tong University; The Chinese University of Hong Kong; Shanghai Jiao Tong University; Shanghai Jiao Tong University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16218/16218-13-19712-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01300-decaug-augmenting-hoi-detection-via-decomposition/",
        "doi": "10.1609/aaai.v35i2.16218",
        "pdf_size": 1443028
    },
    {
        "id": "06705",
        "title": "DecAug: Out-of-Distribution Generalization via Decomposed Feature Representation and Semantic Augmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "While deep learning demonstrates its strong ability to handle independent and identically distributed (IID) data, it often suffers from out-of-distribution (OoD) generalization, where the test data come from another distribution (w.r.t. the training one). Designing a general OoD generalization framework for a wide range of applications is challenging, mainly due to different kinds of distribution shifts in the real world, such as the shift across domains or the extrapolation of correlation. Most of the previous approaches can only solve one specific distribution shift, leading to unsatisfactory performance when applied to various OoD benchmarks. In this work, we propose DecAug, a novel decomposed feature representation and semantic augmentation approach for OoD generalization. Specifically, DecAug disentangles the category-related and context-related features by orthogonalizing the two gradients (w.r.t. intermediate features) of losses for predicting category and context labels, where category-related features contain causal information of the target object, while context-related features cause distribution shifts between training and test data. Furthermore, we perform gradient-based augmentation on context-related features to improve the robustness of learned representations. Experimental results show that DecAug outperforms other state-of-the-art methods on various OoD datasets, which is among the very few methods that can deal with different types of OoD generalization challenges.",
        "primary_area": "Machine Learning I",
        "author": "Haoyue Bai; Rui Sun; Lanqing Hong; Fengwei Zhou; Nanyang Ye; Han-Jia Ye; S.-H. Gary Chan; Zhenguo Li",
        "authorids": "",
        "aff": "The Hong Kong University of Science and Technology; Huawei Noah's Ark Lab; Huawei Noah's Ark Lab; Huawei Noah's Ark Lab; Shanghai Jiao Tong University; Nanjing University; The Hong Kong University of Science and Technology; Huawei Noah's Ark Lab",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16829/16829-13-20323-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06705-decaug-out-of-distribution-generalization-via-decomposed-feature-representation-and-semantic-augmentation/",
        "doi": "10.1609/aaai.v35i8.16829",
        "pdf_size": 6980391
    },
    {
        "id": "02898",
        "title": "Decentralised Learning from Independent Multi-Domain Labels for Person Re-Identification",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep learning has been successful for many computer vision tasks due to the availability of shared and centralised large-scale training data. However, increasing awareness of privacy concerns poses new challenges to deep learning, especially for human subject related recognition such as person re-identification (Re-ID). In this work, we solve the Re-ID problem by decentralised learning from non-shared private training data distributed at multiple user sites of independent multi-domain label spaces. We propose a novel paradigm called Federated Person Re-Identification (FedReID) to construct a generalisable global model (a central server) by simultaneously learning with multiple privacy-preserved local models (local clients). Specifically, each local client receives global model updates from the server and trains a local model using its local data independent from all the other clients. Then, the central server aggregates transferrable local model updates to construct a generalisable global feature embedding model without accessing local data so to preserve local privacy. This client-server collaborative learning process is iteratively performed under privacy control, enabling FedReID to realise decentralised learning without sharing distributed data nor collecting any centralised data. Extensive experiments on ten Re-ID benchmarks show that FedReID achieves compelling generalisation performance beyond any locally trained models without using shared training data, whilst inherently protects the privacy of each local client. This is uniquely advantageous over contemporary Re-ID methods.",
        "primary_area": "Computer Vision III",
        "author": "Guile Wu; Shaogang Gong",
        "authorids": "",
        "aff": "Queen Mary University of London; Queen Mary University of London",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16396/16396-13-19890-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02898-decentralised-learning-from-independent-multi-domain-labels-for-person-re-identification/",
        "doi": "10.1609/aaai.v35i4.16396",
        "pdf_size": 629834
    },
    {
        "id": "06627",
        "title": "Decentralized Multi-Agent Linear Bandits with Safety Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "We study decentralized stochastic linear bandits, where a network of N agents acts cooperatively to efficiently solve a linear bandit-optimization problem over a d-dimensional space.  For this problem, we propose DLUCB: a fully decentralized algorithm that minimizes the cumulative regret over the entire network. At each round of the algorithm each agent chooses its actions following an upper confidence bound (UCB) strategy and agents share information with their immediate neighbors through a carefully designed consensus procedure that repeats over cycles. Our analysis adjusts the duration of these communication cycles ensuring near-optimal regret performance O(d log{NT}sqrt{NT}) at a communication rate of O(dN^2) per round. The structure of the network affects the regret performance via a small additive term \u2013 coined the regret of delay \u2013 that depends on the spectral gap of the underlying graph. Notably, our results apply to arbitrary network topologies without a requirement for a dedicated agent acting as a server. In consideration of situations with high communication cost, we propose RC-DLUCB: a modification of DLUCB with rare communication among agents. The new algorithm trades off regret performance for a significantly reduced total communication cost of O(d^3N^5/2) over all T rounds. Finally, we show that our ideas extend naturally to the emerging, albeit more challenging, setting of safe bandits. For the recently studied problem of linear bandits with unknown linear safety constraints, we propose the first safe decentralized algorithm. Our study contributes towards applying bandit techniques in safety-critical distributed systems that repeatedly deal with unknown stochastic environments. We present numerical simulations for various network topologies that corroborate our theoretical findings.",
        "primary_area": "Machine Learning I",
        "author": "Sanae Amani; Christos Thrampoulidis",
        "authorids": "",
        "aff": "University of California, Los Angeles; University of British Columbia, Vancouver",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16820/16820-13-20314-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06627-decentralized-multi-agent-linear-bandits-with-safety-constraints/",
        "doi": "10.1609/aaai.v35i8.16820",
        "pdf_size": 318536
    },
    {
        "id": "08767",
        "title": "Decentralized Policy Gradient Descent Ascent for Safe Multi-Agent Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper deals with distributed reinforcement learning problems with safety constraints. In particular, we consider that a team of agents cooperate in a shared environment, where each agent has its individual reward function and safety constraints that involve all agents' joint actions. As such, the agents aim to maximize the team-average long-term return, subject to all the safety constraints. More intriguingly, no central controller is assumed to coordinate the agents, and both the rewards and constraints are only known to each agent locally/privately. Instead, the agents are connected by a peer-to-peer communication network to share information with their neighbors. In this work, we first formulate this problem as a distributed constrained Markov decision process (D-CMDP) with networked agents. Then, we propose a decentralized policy gradient (PG) method, Safe Dec-PG, to perform policy optimization based on this D-CMDP model over a network. Convergence guarantees, together with numerical results, showcase the superiority of the proposed algorithm. To the best of our knowledge, this is the first decentralized PG algorithm that accounts for the coupled safety constraints with a quantifiable convergence rate in multi-agent reinforcement learning. Finally, we emphasize that our algorithm is also novel in solving a class of decentralized stochastic nonconvex-concave minimax optimization problems, where both the algorithm design and corresponding theoretical analysis are of independent interest.",
        "primary_area": "Machine Learning III",
        "author": "Songtao Lu; Kaiqing Zhang; Tianyi Chen; Tamer Ba\u015far; Lior Horesh",
        "authorids": "",
        "aff": "IBM Research; University of Illinois at Urbana-Champaign; Rensselaer Polytechnic Institute; University of Illinois at Urbana-Champaign; IBM Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17062/17062-13-20556-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08767-decentralized-policy-gradient-descent-ascent-for-safe-multi-agent-reinforcement-learning/",
        "doi": "10.1609/aaai.v35i10.17062",
        "pdf_size": 295681
    },
    {
        "id": "11699",
        "title": "Decision-Guided Weighted Automata Extraction from Recurrent Neural Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Recurrent Neural Networks (RNNs) have demonstrated their effectiveness in learning and processing sequential data (e.g., speech and natural language). However, due to the black-box nature of neural networks, understanding the decision logic of RNNs is quite challenging. Some recent progress has been made to approximate the behavior of an RNN by weighted automata. They provide better interpretability, but still suffer from poor scalability. In this paper, we propose a novel approach to extracting weighted automata with the guidance of a target RNN's decision and context information. In particular, we identify the patterns of RNN's step-wise predictive decisions to instruct the formation of automata states. Further, we propose a state composition method to enhance the context-awareness of the extracted model. Our in-depth evaluations on typical RNN tasks, including language model and classification, demonstrate the effectiveness and advantage of our method over the state-of-the-arts. The evaluation results show that our method can achieve accurate approximation of an RNN even on large-scale tasks.",
        "primary_area": "Philosophy and Ethics of AI",
        "author": "Xiyue Zhang; Xiaoning Du; Xiaofei Xie; Lei Ma; Yang Liu; Meng Sun",
        "authorids": "",
        "aff": "Peking University, China; Monash University, Australia; Nanyang Technological University, Singapore Hangzhou Xinzhou Network Technology Co., Ltd., China; Kyushu University, Japan; Nanyang Technology University, Singapore; Peking University, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17391/17391-13-20885-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11699-decision-guided-weighted-automata-extraction-from-recurrent-neural-networks/",
        "doi": "10.1609/aaai.v35i13.17391",
        "pdf_size": 568035
    },
    {
        "id": "01505",
        "title": "Decoupled and Memory-Reinforced Networks: Towards Effective Feature Learning for One-Step Person Search",
        "track": "main",
        "status": "Poster",
        "abstract": "The goal of person search is to localize and match query persons from scene images. For high efficiency, one-step methods have been developed to jointly handle the pedestrian detection and identification sub-tasks using a single network. There are two major challenges in the current one-step approaches. One is the mutual interference between the optimization objectives of multiple sub-tasks. The other is the sub-optimal identification feature learning caused by small batch size when end-to-end training. To overcome these problems, we propose a decoupled and memory-reinforced network (DMRNet). Specifically, to reconcile the conflicts of multiple objectives, we simplify the standard tightly coupled pipelines and establish a deeply decoupled multi-task learning framework. Further, we build a memory-reinforced mechanism to boost the identification feature learning. By queuing the identification features of recently accessed instances into a memory bank, the mechanism augments the similarity pair construction for pairwise metric learning. For better encoding consistency of the stored features, a slow-moving average of the network is applied for extracting these features. In this way, the dual networks reinforce each other and converge to robust solution states. Experimentally, the proposed method obtains 93.2% and 46.9% mAP on CUHK-SYSU and PRW datasets, which exceeds all the existing one-step methods.",
        "primary_area": "Computer Vision I",
        "author": "Chuchu Han; Zhedong Zheng; Changxin Gao; Nong Sang; Yi Yang",
        "authorids": "",
        "aff": "Huazhong University of Science and Technology; University of Technology Sydney Baidu Research; Huazhong University of Science and Technology; Huazhong University of Science and Technology; University of Technology Sydney",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16241/16241-13-19735-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01505-decoupled-and-memory-reinforced-networks-towards-effective-feature-learning-for-one-step-person-search/",
        "doi": "10.1609/aaai.v35i2.16241",
        "pdf_size": 1250649
    },
    {
        "id": "01089",
        "title": "Deductive Learning for Weakly-Supervised 3D Human Pose Estimation via Uncalibrated Cameras",
        "track": "main",
        "status": "Poster",
        "abstract": "Without prohibitive and laborious 3D annotations, weakly-supervised 3D human pose methods mainly employ the model regularization with geometric projection consistency or geometry estimation from multi-view images. Nevertheless, those approaches explicitly need known parameters of calibrated cameras, exhibiting a limited model generalization in various realistic scenarios. To mitigate this issue, in this paper, we propose a Deductive Weakly-Supervised Learning (DWSL) for 3D human pose machine. Our DWSL firstly learns latent representations on depth and camera pose for 3D pose reconstruction. Since weak supervision usually causes ill-conditioned learning or inferior estimation, our DWSL introduces deductive reasoning to make an inference for the human pose from a view to another and develops a reconstruction loss to demonstrate what the model learns and infers is reliable.  This learning by deduction strategy employs the view-transform demonstration and structural rules derived from depth, geometry and angle constraints, which improves the reliability of the model training with weak supervision. On three 3D human pose benchmarks, we conduct extensive experiments to evaluate our proposed method, which achieves superior performance in comparison with state-of-the-art weak-supervised methods. Particularly, our model shows an appealing potential for learning from 2D data captured in dynamic outdoor scenes, which demonstrates promising robustness and generalization in realistic scenarios. Our code is publicly available at https://github.com/Xipeng-Chen/DWSL-3D-pose.",
        "primary_area": "Computer Vision I",
        "author": "Xipeng Chen; Pengxu Wei; Liang Lin",
        "authorids": "",
        "aff": "Sun Yat-sen University; Sun Yat-sen University; Sun Yat-sen University DarkMatter AI Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16194/16194-13-19688-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01089-deductive-learning-for-weakly-supervised-3d-human-pose-estimation-via-uncalibrated-cameras/",
        "doi": "10.1609/aaai.v35i2.16194",
        "pdf_size": 1034606
    },
    {
        "id": "06600",
        "title": "Deep Bayesian Quadrature Policy Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "We study the problem of obtaining accurate policy gradient estimates using a finite number of samples. Monte-Carlo methods have been the default choice for policy gradient estimation, despite suffering from high variance in the gradient estimates. On the other hand, more sample efficient alternatives like Bayesian quadrature methods have received little attention due to their high computational complexity. In this work, we propose deep Bayesian quadrature policy gradient (DBQPG), a computationally efficient high-dimensional generalization of Bayesian quadrature, for policy gradient estimation. We show that DBQPG can substitute Monte-Carlo estimation in policy gradient methods, and demonstrate its effectiveness on a set of continuous control benchmarks. In comparison to Monte-Carlo estimation, DBQPG provides (i) more accurate gradient estimates with a significantly lower variance, (ii) a consistent improvement in the sample complexity and average return for several deep policy gradient algorithms, and, (iii) the uncertainty in gradient estimation that can be incorporated to further improve the performance.",
        "primary_area": "Machine Learning I",
        "author": "Ravi Tej Akella; Kamyar Azizzadenesheli; Mohammad Ghavamzadeh; Animashree Anandkumar; Yisong Yue",
        "authorids": "",
        "aff": "Purdue University; Purdue University; Google Research; Caltech; Caltech",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16817/16817-13-20311-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06600-deep-bayesian-quadrature-policy-optimization/",
        "doi": "10.1609/aaai.v35i8.16817",
        "pdf_size": 1835117
    },
    {
        "id": "00277",
        "title": "Deep Conservation: A Latent-Dynamics Model for Exact Satisfaction of Physical Conservation Laws",
        "track": "main",
        "status": "Poster",
        "abstract": "This work proposes an approach for latent-dynamics learning that exactly enforces physical conservation laws. The method comprises two steps. First, the method computes a low-dimensional embedding of the high-dimensional dynamical-system state using deep convolutional autoencoders. This defines a low-dimensional nonlinear manifold on which the state is subsequently enforced to evolve. Second, the method defines a latent-dynamics model that associates with the solution to a constrained optimization problem. Here, the objective function is defined as the sum of squares of conservation-law violations over control volumes within a finite-volume discretization of the problem; nonlinear equality constraints explicitly enforce conservation over prescribed subdomains of the problem. Under modest conditions, the resulting dynamics model guarantees that the time-evolution of the latent state exactly satisfies conservation laws over the prescribed subdomains.",
        "primary_area": "Application Domains",
        "author": "Kookjin Lee; Kevin T. Carlberg",
        "authorids": "",
        "aff": "Sandia National Laboratories; University of Washington",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16102/16102-13-19596-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00277-deep-conservation-a-latent-dynamics-model-for-exact-satisfaction-of-physical-conservation-laws/",
        "doi": "10.1609/aaai.v35i1.16102",
        "pdf_size": 1299582
    },
    {
        "id": "00249",
        "title": "Deep Contextual Clinical Prediction with Reverse Distillation",
        "track": "main",
        "status": "Poster",
        "abstract": "Healthcare providers are increasingly using machine learning to predict patient outcomes to make meaningful interventions. However, despite innovations in this area, deep learning models often struggle to match performance of shallow linear models in predicting these outcomes, making it difficult to leverage such techniques in practice. In this work, motivated by the task of clinical prediction from insurance claims, we present a new technique called reverse distillation which pretrains deep models by using high-performing linear models for initialization. We make use of the longitudinal structure of insurance claims datasets to develop Self Attention with Reverse Distillation, or SARD, an architecture that utilizes a combination of contextual embedding, temporal embedding and self-attention mechanisms and most critically is trained via reverse distillation. SARD outperforms state-of-the-art methods on multiple clinical prediction outcomes, with ablation studies revealing that reverse distillation is a primary driver of these improvements. Code is available at https://github.com/clinicalml/omop-learn.",
        "primary_area": "Application Domains",
        "author": "Rohan Kodialam; Rebecca Boiarsky; Justin Lim; Aditya Sai; Neil Dixit; David Sontag",
        "authorids": "",
        "aff": "MIT CSAIL & IMES; MIT CSAIL & IMES; MIT CSAIL & IMES; Independence Blue Cross; Independence Blue Cross; MIT CSAIL & IMES",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16099/16099-13-19593-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00249-deep-contextual-clinical-prediction-with-reverse-distillation/",
        "doi": "10.1609/aaai.v35i1.16099",
        "pdf_size": 448630
    },
    {
        "id": "00882",
        "title": "Deep Event Stereo Leveraged by Event-to-Image Translation",
        "track": "main",
        "status": "Poster",
        "abstract": "Depth estimation in real-world applications requires precise responses to fast motion and challenging lighting conditions. Event cameras use bio-inspired event-driven sensors that provide instantaneous and asynchronous information of pixel-level log intensity changes, which makes them suitable for depth estimation in such challenging conditions. However, as the event cameras primarily provide asynchronous and spatially sparse event data, it is hard to provide accurate dense disparity map in stereo event camera setups - especially in estimating disparities on local structures or edges. In this study, we develop a novel deep event stereo network that reconstructs spatial intensity image features from embedded event streams and leverages the event features using the reconstructed image features to compute dense disparity maps. To this end, we propose a novel event-to-image translation network with a cross-semantic attention mechanism that calculates the global semantic context of the event features for the intensity image reconstruction. In addition, a feature aggregation module is developed for accurate disparity estimation, which modulates the event features with the reconstructed image features by a stacked dilated spatially-adaptive denormalization mechanism. Experimental results reveal that our method can outperform the state-of-the-art methods by significant margins both in quantitative and qualitative measures.",
        "primary_area": "Computer Vision I",
        "author": "Soikat Hasan Ahmed; Hae Woong Jang; S M Nadim Uddin; Yong Ju Jung",
        "authorids": "",
        "aff": "Gachon University; Gachon University; Gachon University; Gachon University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16171/16171-13-19665-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00882-deep-event-stereo-leveraged-by-event-to-image-translation/",
        "doi": "10.1609/aaai.v35i2.16171",
        "pdf_size": 2526598
    },
    {
        "id": "01148",
        "title": "Deep Feature Space Trojan Attack of Neural Networks by Controlled Detoxification",
        "track": "main",
        "status": "Poster",
        "abstract": "Trojan (backdoor) attack is a form of adversarial attack on deep neural networks where the attacker provides victims with a model trained/retrained on malicious data. The backdoor can be activated when a normal input is stamped with a certain pattern called trigger, causing misclassification. Many existing trojan attacks have their triggers being input space patches/objects (e.g., a polygon with solid color) or simple input transformations such as Instagram filters. These simple triggers are susceptible to recent backdoor detection algorithms. We propose a novel deep feature space trojan attack with five characteristics: effectiveness, stealthiness, controllability, robustness and reliance on deep features. We conduct extensive experiments on 9 image classifiers on various datasets including ImageNet to demonstrate these properties and show that our attack can evade state-of-the-art defense.",
        "primary_area": "Computer Vision I",
        "author": "Siyuan Cheng; Yingqi Liu; Shiqing Ma; Xiangyu Zhang",
        "authorids": "",
        "aff": "Purdue University; Purdue University; Rutgers University; Purdue University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16201/16201-13-19695-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01148-deep-feature-space-trojan-attack-of-neural-networks-by-controlled-detoxification/",
        "doi": "10.1609/aaai.v35i2.16201",
        "pdf_size": 597843
    },
    {
        "id": "10541",
        "title": "Deep Frequency Principle Towards Understanding Why Deeper Learning Is Faster",
        "track": "main",
        "status": "Poster",
        "abstract": "Understanding the effect of depth in deep learning is a critical problem. In this work, we utilize the Fourier analysis to empirically provide a promising mechanism to understand why feedforward deeper learning is faster. To this end,  we separate a deep neural network, trained by normal stochastic gradient descent, into two parts during analysis, i.e., a  pre-condition component and  a learning component, in which the output of the pre-condition one is the input of the learning one. We use a filtering method to characterize the frequency distribution of a high-dimensional function.  Based on experiments of deep networks and real dataset, we propose a deep frequency principle, that is, the effective target function for a deeper hidden layer biases towards  lower  frequency during the training. Therefore, the learning component effectively learns a lower frequency function if the pre-condition component has more layers. Due to the well-studied frequency principle, i.e., deep neural networks learn lower frequency functions faster, the deep frequency principle provides a reasonable explanation to why deeper learning is faster. We believe these empirical studies would be valuable for future theoretical studies of the effect of depth in deep learning.",
        "primary_area": "Machine Learning V",
        "author": "Zhiqin John Xu; Hanxu Zhou",
        "authorids": "",
        "aff": "Shanghai Jiao Tong University; Shanghai Jiao Tong University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17261/17261-13-20755-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10541-deep-frequency-principle-towards-understanding-why-deeper-learning-is-faster/",
        "doi": "10.1609/aaai.v35i12.17261",
        "pdf_size": 2281731
    },
    {
        "id": "09978",
        "title": "Deep Fusion Clustering Network",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep clustering is a fundamental yet challenging task for data analysis. Recently we witness a strong tendency of combining autoencoder and graph neural networks to exploit structure information for clustering performance enhancement. However, we observe that existing literature 1) lacks a dynamic fusion mechanism to selectively integrate and refine the information of graph structure and node attributes for consensus representation learning; 2) fails to extract information from both sides for robust target distribution (i.e., \u201cgroundtruth\u201d soft labels) generation. To tackle the above issues, we propose a Deep Fusion Clustering Network (DFCN). Specifically, in our network, an interdependency learning-based Structure and Attribute Information Fusion (SAIF) module is proposed to explicitly merge the representations learned by an autoencoder and a graph autoencoder for consensus representation learning. Also, a reliable target distribution generation measure and a triplet self-supervision strategy, which facilitate cross-modality information exploitation, are designed for network training. Extensive experiments on six benchmark datasets have demonstrated that the proposed DFCN consistently outperforms the state-of-the-art deep clustering methods.",
        "primary_area": "Machine Learning IV",
        "author": "Wenxuan Tu; Sihang Zhou; Xinwang Liu; Xifeng Guo; Zhiping Cai; En Zhu; Jieren Cheng",
        "authorids": "",
        "aff": "National University of Defense Technology; National University of Defense Technology; National University of Defense Technology; National University of Defense Technology; National University of Defense Technology; National University of Defense Technology; Hainan university",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17198/17198-13-20692-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09978-deep-fusion-clustering-network/",
        "doi": "10.1609/aaai.v35i11.17198",
        "pdf_size": 6935490
    },
    {
        "id": "07358",
        "title": "Deep Graph Spectral Evolution Networks for Graph Topological Evolution",
        "track": "main",
        "status": "Poster",
        "abstract": "Characterizing the underlying mechanism of graph topological evolution from a source graph to a target graph has attracted fast increasing attention in the deep graph learning domain. However, it is very challenging to build expressive and efficient models that can handle global and local evolution patterns between source and target graphs. On the other hand, graph topological evolution has been investigated in the graph signal processing domain historically, but it involves intensive labors to manually determine suitable prescribed spectral models and prohibitive difficulty to fit their potential combinations and compositions. To address these challenges, this paper proposes the deep Graph Spectral Evolution Network (GSEN) for modeling the graph topology evolution problem by the composition of newly-developed generalized graph kernels. GSEN can effectively fit a wide range of existing graph kernels and their combinations and compositions with the theoretical guarantee and experimental verification. GSEN has outstanding efficiency in terms of time complexity (O(n)) and parameter complexity (O(1)), where n is the number of nodes of the graph. Extensive experiments on multiple synthetic and real-world datasets demonstrate outstanding performance.",
        "primary_area": "Machine Learning I",
        "author": "Negar Etemadyrad; Qingzhe Li; Liang Zhao",
        "authorids": "",
        "aff": "George Mason University; George Mason University; Emory University George Mason University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16903/16903-13-20397-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07358-deep-graph-spectral-evolution-networks-for-graph-topological-evolution/",
        "doi": "10.1609/aaai.v35i8.16903",
        "pdf_size": 1783430
    },
    {
        "id": "04626",
        "title": "Deep Graph-neighbor Coherence Preserving Network for Unsupervised Cross-modal Hashing",
        "track": "main",
        "status": "Poster",
        "abstract": "Unsupervised cross-modal hashing (UCMH) has become a hot topic recently. Current UCMH focuses on exploring data similarities. However, current UCMH methods calculate the similarity between two data, mainly relying on the two data's cross-modal features. These methods suffer from inaccurate similarity problems that result in a suboptimal retrieval Hamming space, because the cross-modal features between the data are not sufficient to describe the complex data relationships, such as situations where two data have different feature representations but share the inherent concepts. In this paper, we devise a deep graph-neighbor coherence preserving network (DGCPN). Specifically, DGCPN stems from graph models and explores graph-neighbor coherence by consolidating the information between data and their neighbors. DGCPN regulates comprehensive similarity preserving losses by exploiting three types of data similarities (i.e., the graph-neighbor coherence, the coexistent similarity, and the intra- and inter-modality consistency) and designs a half-real and half-binary optimization strategy to reduce the quantization errors during hashing. Essentially, DGCPN addresses the inaccurate similarity problem by exploring and exploiting the data's intrinsic relationships in a graph. We conduct extensive experiments on three public UCMH datasets. The experimental results demonstrate the superiority of DGCPN, e.g., by improving the mean average precision from 0.722 to 0.751 on MIRFlickr-25K using 64-bit hashing codes to retrieval texts from images. We will release the source code package and the trained model on https://github.com/Atmegal/DGCPN.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Jun Yu; Hao Zhou; Yibing Zhan; Dacheng Tao",
        "authorids": "",
        "aff": "Hangzhou Dianzi University; Hangzhou Dianzi University; Hangzhou Dianzi University; The University of Sydney",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16592/16592-13-20086-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04626-deep-graph-neighbor-coherence-preserving-network-for-unsupervised-cross-modal-hashing/",
        "doi": "10.1609/aaai.v35i5.16592",
        "pdf_size": 566626
    },
    {
        "id": "12391",
        "title": "Deep Innovation Protection: Confronting the Credit Assignment Problem in Training Heterogeneous Neural Architectures",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep reinforcement learning approaches have shown impressive results in a variety of different domains, however, more complex heterogeneous architectures such as world models require the different neural components to be trained separately instead of end-to-end. While a simple genetic algorithm recently showed end-to-end training is possible, it failed to solve a more complex 3D task. This paper presents a method called Deep Innovation Protection (DIP) that addresses the credit assignment problem in training complex heterogenous neural network models end-to-end for such  environments. The main idea behind the approach is to employ multiobjective optimization to temporally reduce the selection pressure on specific components in multi-component network, allowing other components to adapt. We investigate the emergent representations of these evolved networks, which learn to predict properties important for the survival of the agent, without the need for a specific forward-prediction loss.",
        "primary_area": "Search and Optimization",
        "author": "Sebastian Risi; Kenneth O. Stanley",
        "authorids": "",
        "aff": "IT University of Copenhagen; Uber AI",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17470/17470-13-20964-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12391-deep-innovation-protection-confronting-the-credit-assignment-problem-in-training-heterogeneous-neural-architectures/",
        "doi": "10.1609/aaai.v35i14.17470",
        "pdf_size": 2077325
    },
    {
        "id": "00427",
        "title": "Deep Just-In-Time Inconsistency Detection Between Comments and Source Code",
        "track": "main",
        "status": "Poster",
        "abstract": "Natural language comments convey key aspects of source code such as implementation, usage, and pre- and post-conditions. Failure to update comments accordingly when the corresponding code is modified introduces inconsistencies, which is known to lead to confusion and software bugs. In this paper, we aim to detect whether a comment becomes inconsistent as a result of changes to the corresponding body of code, in order to catch potential inconsistencies just-in-time, i.e., before they are committed to a code base. To achieve this, we develop a deep-learning approach that learns to correlate a comment with code changes. By evaluating on a large corpus of comment/code pairs spanning various comment types, we show that our model outperforms multiple baselines by significant margins. For extrinsic evaluation, we show the usefulness of our approach by combining it with a comment update model to build a more comprehensive automatic comment maintenance system which can both detect and resolve inconsistent comments based on code changes.",
        "primary_area": "Application Domains",
        "author": "Sheena Panthaplackel; Junyi Jessy Li; Milos Gligoric; Raymond J. Mooney",
        "authorids": "",
        "aff": "The University of Texas at Austin; The University of Texas at Austin; The University of Texas at Austin; The University of Texas at Austin",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16119/16119-13-19613-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00427-deep-just-in-time-inconsistency-detection-between-comments-and-source-code/",
        "doi": "10.1609/aaai.v35i1.16119",
        "pdf_size": 302645
    },
    {
        "id": "01725",
        "title": "Deep Low-Contrast Image Enhancement using Structure Tensor Representation",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a new deep learning framework for low-contrast image enhancement, which trains the network using the multi-exposure sequences rather than explicit ground-truth images. The purpose of our method is to enhance a low-contrast image so as to contain abundant details in various exposure levels. To realize this, we propose to design the loss function using the structure tensor representation, which has been widely used as high-dimensional image contrast. Our loss function penalizes the difference of the structure tensor between the network output and the multi-exposure images in a multi-scale manner. Eventually, the network trained by the loss function produces a high-quality image approximating the overall contrast of the sequence. We provide in-depth analysis on our method and comparison with conventional loss functions. Quantitative and qualitative evaluations demonstrate that the proposed method outperforms the existing state-of-the-art approaches in various benchmarks.",
        "primary_area": "Computer Vision I",
        "author": "Hyungjoo Jung; Hyunsung Jang; Namkoo Ha; Kwanghoon Sohn",
        "authorids": "",
        "aff": "Yonsei University Korea Institute of Science and Technology (KIST); Yonsei University LIG Nex1; LIG Nex1; Yonsei University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16266/16266-13-19760-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01725-deep-low-contrast-image-enhancement-using-structure-tensor-representation/",
        "doi": "10.1609/aaai.v35i2.16266",
        "pdf_size": 17551367
    },
    {
        "id": "00982",
        "title": "Deep Metric Learning with Graph Consistency",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep Metric Learning (DML) has been more attractive and widely applied in many computer vision tasks, in which a discriminative embedding is requested such that the image features belonging to the same class are gathered together and the ones belonging to different classes are pushed apart. Most existing works insist to learn this discriminative embedding by either devising powerful pair-based loss functions or hard-sample mining strategies. However, in this paper, we start from an another perspective and propose Deep Consistent Graph Metric Learning (CGML) framework to enhance the discrimination of the learned embedding. It is mainly achieved by rethinking the conventional distance constraints as a graph regularization and then introducing a Graph Consistency regularization term, which intends to optimize the feature distribution from a global graph perspective. Inspired by the characteristic of our defined \u2019Discriminative Graph\u2019, which regards DML from another novel perspective, the Graph Consistency regularization term encourages the sub-graphs randomly sampled from the training set to be consistent. We show that our CGML indeed serves as an efficient technique for learning towards discriminative embedding and is applicable to various popular metric objectives, e.g. Triplet, N-Pair and Binomial losses. This paper empirically and experimentally demonstrates the effectiveness of our graph regularization idea, achieving competitive results on the popular CUB, CARS, Stanford Online Products and In-Shop datasets.",
        "primary_area": "Computer Vision I",
        "author": "Binghui Chen; Pengyu Li; Zhaoyi Yan; Biao Wang; Lei Zhang",
        "authorids": "",
        "aff": "Artificial Intelligence Center, DAMO Academy, Alibaba Group; Artificial Intelligence Center, DAMO Academy, Alibaba Group; Artificial Intelligence Center, DAMO Academy, Alibaba Group Harbin Institute of Technology; Artificial Intelligence Center, DAMO Academy, Alibaba Group; Artificial Intelligence Center, DAMO Academy, Alibaba Group The Hong Kong Polytechnic University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16182/16182-13-19676-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00982-deep-metric-learning-with-graph-consistency/",
        "doi": "10.1609/aaai.v35i2.16182",
        "pdf_size": 1283880
    },
    {
        "id": "01370",
        "title": "Deep Metric Learning with Self-Supervised Ranking",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep metric learning aims to learn a deep embedding space, where similar objects are pushed towards together and different objects are repelled against. Existing approaches typically use inter-class characteristics, e.g. class-level information or instance-level similarity, to obtain semantic relevance of data points and get a large margin between different classes in the embedding space. However, the intra-class characteristics, e.g. local manifold structure or relative relationship within the same class, are usually overlooked in the learning process. Hence the data structure cannot be fully exploited and the output embeddings have limitation in retrieval. More importantly, retrieval results lack in a good ranking. This paper presents a novel self-supervised ranking auxiliary framework, which captures intra-class characteristics as well as inter-class characteristics for better metric learning. Our method defines specific transform functions to simulates the local structure change of intra-class in the initial image domain, and formulates a self-supervised learning procedure to fully exploit this property and preserve it in the embedding space. Extensive experiments on three standard benchmarks show that our method significantly improves and outperforms the state-of-the-art methods on the performances of both retrieval and ranking by 2%-4%.",
        "primary_area": "Computer Vision I",
        "author": "Zheren Fu; Yan Li; Zhendong Mao; Quan Wang; Yongdong Zhang",
        "authorids": "",
        "aff": "University of Science and Technology of China; Kuaishou Technology; University of Science and Technology of China; University of Science and Technology of China; University of Science and Technology of China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16226/16226-13-19720-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01370-deep-metric-learning-with-self-supervised-ranking/",
        "doi": "10.1609/aaai.v35i2.16226",
        "pdf_size": 2683483
    },
    {
        "id": "02826",
        "title": "Deep Multi-Task Learning for Diabetic Retinopathy Grading in Fundus Images",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent years have witnessed the growing interest in disease severity grading, especially for ocular diseases based on fundus images. The existing grading methods are usually trained with high resolution (HR) images. However, the grading performance decreases a lot given low resolution (LR) images, which are common in practice. In this paper, we mainly focus on diabetic retinopathy (DR) grading with LR fundus images. According to our analysis on the DR task, we find that: 1) image super-resolution (ISR) can boost the performance of DR grading and lesion segmentation; 2) the lesion segmentation regions of fundus images are highly consistent with pathological regions for DR grading. Thus, we propose a deep multi-task learning based DR grading (DeepMT-DR) method for LR fundus images, which simultaneously handles the auxiliary tasks of ISR and lesion segmentation. Specifically, based on our findings, we propose a hierarchical deep learning structure that simultaneously processes the low-level task of ISR, the mid-level task of lesion segmentation and the high-level task of DR grading. Moreover, a novel task-aware loss is developed to encourage ISR to focus on the pathological regions for its subsequent tasks: lesion segmentation and DR grading. Extensive experimental results show that our DeepMT-DR method significantly outperforms other state-of-the-art methods for DR grading over two public datasets. In addition, our method achieves comparable performance in two auxiliary tasks of ISR and lesion segmentation.",
        "primary_area": "Computer Vision III",
        "author": "Xiaofei Wang; Mai Xu; Jicong Zhang; Lai Jiang; Liu Li",
        "authorids": "",
        "aff": "Beihang University; Beihang University; Beihang University; Beihang University; Imperial College London",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16388/16388-13-19882-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02826-deep-multi-task-learning-for-diabetic-retinopathy-grading-in-fundus-images/",
        "doi": "10.1609/aaai.v35i4.16388",
        "pdf_size": 932090
    },
    {
        "id": "08893",
        "title": "Deep Mutual Information Maximin for Cross-Modal Clustering",
        "track": "main",
        "status": "Poster",
        "abstract": "Cross-modal clustering (CMC) aims to enhance the clustering performance by exploring complementary information from multiple modalities. However, the performances of existing CMC algorithms are still unsatisfactory due to the conflict of heterogeneous modalities and the high-dimensional non-linear property of individual modality. In this paper, a novel deep mutual information maximin (DMIM) method for cross-modal clustering is proposed to maximally preserve the shared information of multiple modalities while eliminating the superfluous information of individual modalities in an end-to-end manner. Specifically, a multi-modal shared encoder is firstly built to align the latent feature distributions by sharing parameters across modalities. Then, DMIM formulates the complementarity of multi-modalities representations as an mutual information maximin objective function, in which the shared information of multiple modalities and the superfluous information of individual modalities are identified by mutual information maximization and minimization respectively. To solve the DMIM objective function, we propose a variational optimization method to ensure it converge to a local optimal solution. Moreover, an auxiliary overclustering mechanism is employed to optimize the clustering structure by introducing more detailed clustering classes. Extensive experimental results demonstrate the superiority of DMIM method over the state-of-the-art cross-modal clustering methods on IAPR-TC12, ESP-Game, MIRFlickr and NUS-Wide datasets.",
        "primary_area": "Machine Learning III",
        "author": "Yiqiao Mao; Xiaoqiang Yan; Qiang Guo; Yangdong Ye",
        "authorids": "",
        "aff": "Zhengzhou University; Zhengzhou University; Zhengzhou University; Zhengzhou University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17076/17076-13-20570-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08893-deep-mutual-information-maximin-for-cross-modal-clustering/",
        "doi": "10.1609/aaai.v35i10.17076",
        "pdf_size": 580684
    },
    {
        "id": "14374",
        "title": "Deep Open Intent Classification with Adaptive Decision Boundary",
        "track": "main",
        "status": "Poster",
        "abstract": "Open intent classification is a challenging task in dialogue systems. On the one hand, it should ensure the quality of known intent identification. On the other hand, it needs to detect the open (unknown) intent without prior knowledge. Current models are limited in finding the appropriate decision boundary to balance the performances of both known intents and the open intent. In this paper, we propose a post-processing method to learn the adaptive decision boundary (ADB) for open intent classification. We first utilize the labeled known intent samples to pre-train the model. Then, we automatically learn the adaptive spherical decision boundary for each known class with the aid of well-trained features. Specifically, we propose a new loss function to balance both the empirical risk and the open space risk. Our method does not need open intent samples and is free from modifying the model architecture. Moreover, our approach is surprisingly insensitive with less labeled data and fewer known intents. Extensive experiments on three benchmark datasets show that our method yields significant improvements compared with the state-of-the-art methods.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Hanlei Zhang; Hua Xu; Ting-En Lin",
        "authorids": "",
        "aff": "State Key Laboratory of Intelligent Technology and Systems, Department of Computer Science and Technology, Tsinghua University, Beijing 100084, China, Beijing National Research Center for Information Science and Technology (BNRist), Beijing 100084, China; State Key Laboratory of Intelligent Technology and Systems, Department of Computer Science and Technology, Tsinghua University, Beijing 100084, China, Beijing National Research Center for Information Science and Technology (BNRist), Beijing 100084, China; State Key Laboratory of Intelligent Technology and Systems, Department of Computer Science and Technology, Tsinghua University, Beijing 100084, China, Beijing National Research Center for Information Science and Technology (BNRist), Beijing 100084, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17690/17690-13-21184-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14374-deep-open-intent-classification-with-adaptive-decision-boundary/",
        "doi": "10.1609/aaai.v35i16.17690",
        "pdf_size": 2105190
    },
    {
        "id": "00678",
        "title": "Deep Partial Rank Aggregation for Personalized Attributes",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we study the problem of how to aggregate pairwise personalized attributes (PA) annotations (e.g., Shoes A is more comfortable than B) from different annotators on the crowdsourcing platforms, which is an emerging topic gaining increasing attention in recent years. Given the crowdsourced annotations, the majority of the traditional literature assumes that all the pairs in the collected dataset are distinguishable. However, this assumption is incompatible with how humans perceive attributes since indistinguishable pairs are ubiquitous for the annotators due to the limitation of human perception. To attack this problem, we propose a novel deep prediction model that could simultaneously detect the indistinguishable pairs and aggregate ranking results for distinguishable pairs. First of all, we represent the pairwise annotations as a multi-graph. Based on such data structure, we propose an end-to-end partial ranking model which consists of a deep backbone architecture and a probabilistic model that captures the generative process of the partial rank annotations. Specifically, to recognize the indistinguishable pairs, the probabilistic model we proposed is equipped with an adaptive perception threshold, where indistinguishable pairs could be automatically detected when the absolute value of the score difference is below the learned threshold. In our empirical studies, we perform a series of experiments on three real-world datasets: LFW-10, Shoes, and Sun. The corresponding results consistently show the superiority of our proposed model.",
        "primary_area": "Application Domains",
        "author": "Qianqian Xu; Zhiyong Yang; Zuyao Chen; Yangbangyan Jiang; Xiaochun Cao; Yuan Yao; Qingming Huang",
        "authorids": "",
        "aff": "Institute of Computing Technology, CAS; Institute of Information Engineering, CAS University of Chinese Academy of Sciences; University of Chinese Academy of Sciences; Institute of Information Engineering, CAS University of Chinese Academy of Sciences; Institute of Information Engineering, CAS University of Chinese Academy of Sciences Peng Cheng Laboratory; Hong Kong University of Science and Technology; Institute of Computing Technology, CAS University of Chinese Academy of Sciences Chinese Academy of Sciences Peng Cheng Laboratory",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16148/16148-13-19642-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00678-deep-partial-rank-aggregation-for-personalized-attributes/",
        "doi": "10.1609/aaai.v35i1.16148",
        "pdf_size": 12278801
    },
    {
        "id": "00213",
        "title": "Deep Portfolio Optimization via Distributional Prediction of Residual Factors",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent developments in deep learning techniques have motivated intensive research in machine learning-aided stock trading strategies. However, since the financial market has a highly non-stationary nature hindering the application of typical data-hungry machine learning methods, leveraging financial inductive biases is important to ensure better sample efficiency and robustness. In this study, we propose a novel method of constructing a portfolio based on predicting the distribution of a financial quantity called residual factors, which is known to be generally useful for hedging the risk exposure to common market factors. The key technical ingredients are twofold. First, we introduce a computationally efficient extraction method for the residual information, which can be easily combined with various prediction algorithms. Second, we propose a novel neural network architecture that allows us to incorporate widely acknowledged financial inductive biases such as amplitude invariance and time-scale invariance. We demonstrate the efficacy of our method on U.S. and Japanese stock market data. Through ablation experiments, we also verify that each individual technique contributes to improving the performance of trading strategies. We anticipate our techniques may have wide applications in various financial problems.",
        "primary_area": "Application Domains",
        "author": "Kentaro Imajo; Kentaro Minami; Katsuya Ito; Kei Nakagawa",
        "authorids": "",
        "aff": "Preferred Networks, Inc.; Preferred Networks, Inc.; Preferred Networks, Inc.; Nomura Asset Management Co.,Ltd.",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16095/16095-13-19589-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00213-deep-portfolio-optimization-via-distributional-prediction-of-residual-factors/",
        "doi": "10.1609/aaai.v35i1.16095",
        "pdf_size": 1004184
    },
    {
        "id": "08055",
        "title": "Deep Probabilistic Canonical Correlation Analysis",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a deep generative framework for multi-view learning based on a probabilistic interpretation of canonical correlation analysis (CCA). The model combines a linear multi-view layer in the latent space with deep generative networks as observation models, to decompose the variability in multiple views into a shared latent representation that describes the common underlying sources of variation and a set of viewspecific components. To approximate the posterior distribution of the latent multi-view layer, an efficient variational inference procedure is developed based on the solution of probabilistic CCA. The model is then generalized to an arbitrary number of views. An empirical analysis confirms that the proposed deep multi-view model can discover subtle relationships between multiple views and recover rich representations.",
        "primary_area": "Machine Learning II",
        "author": "Mahdi Karami; Dale Schuurmans",
        "authorids": "",
        "aff": "University of Alberta; University of Alberta",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16982/16982-13-20476-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08055-deep-probabilistic-canonical-correlation-analysis/",
        "doi": "10.1609/aaai.v35i9.16982",
        "pdf_size": 3882706
    },
    {
        "id": "02628",
        "title": "Deep Probabilistic Imaging: Uncertainty Quantification and Multi-modal Solution Characterization for Computational Imaging",
        "track": "main",
        "status": "Poster",
        "abstract": "Computational image reconstruction algorithms generally produce a single image without any measure of uncertainty or confidence. Regularized Maximum Likelihood (RML) and feed-forward deep learning approaches for inverse problems typically focus on recovering a point estimate. This is a serious limitation when working with under-determined imaging systems, where it is conceivable that multiple image modes would be consistent with the measured data. Characterizing the space of probable images that explain the observational data is therefore crucial. In this paper, we propose a variational deep probabilistic imaging approach to quantify reconstruction uncertainty. Deep Probabilistic Imaging (DPI) employs an untrained deep generative model to estimate a posterior distribution of an unobserved image. This approach does not require any training data; instead, it optimizes the weights of a neural network to generate image samples that fit a particular measurement dataset. Once the network weights have been learned, the posterior distribution can be efficiently sampled. We demonstrate this approach in the context of interferometric radio imaging, which is used for black hole imaging with the Event Horizon Telescope, and compressed sensing Magnetic Resonance Imaging (MRI).",
        "primary_area": "Computer Vision II",
        "author": "He Sun; Katherine L. Bouman",
        "authorids": "",
        "aff": "California Institute of Technology, 1200 E California Blvd, Pasadena, California 91125; California Institute of Technology, 1200 E California Blvd, Pasadena, California 91125",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16366/16366-13-19860-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02628-deep-probabilistic-imaging-uncertainty-quantification-and-multi-modal-solution-characterization-for-computational-imaging/",
        "doi": "10.1609/aaai.v35i3.16366",
        "pdf_size": 9087173
    },
    {
        "id": "06696",
        "title": "Deep Radial-Basis Value Functions for Continuous Control",
        "track": "main",
        "status": "Poster",
        "abstract": "A core operation in reinforcement learning (RL) is finding an action that is optimal with respect to a learned value function. This operation is often challenging when the learned value function takes continuous actions as input. We introduce deep radial-basis value functions (RBVFs): value functions learned using a deep network with a radial-basis function (RBF) output layer. We show that the maximum action-value with respect to a deep RBVF can be approximated easily and accurately. Moreover, deep RBVFs can represent any true value function owing to their support for universal function approximation. We extend the standard DQN algorithm to continuous control by endowing the agent with a deep RBVF. We show that the resultant agent, called RBF-DQN, significantly outperforms value-function-only baselines, and is competitive with state-of-the-art actor-critic algorithms.",
        "primary_area": "Machine Learning I",
        "author": "Kavosh Asadi; Neev Parikh; Ronald E. Parr; George D. Konidaris; Michael L. Littman",
        "authorids": "",
        "aff": "Amazon Web Services, Brown University; Brown University; Duke University; Brown University; Brown University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16828/16828-13-20322-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06696-deep-radial-basis-value-functions-for-continuous-control/",
        "doi": "10.1609/aaai.v35i8.16828",
        "pdf_size": 1479841
    },
    {
        "id": "10236",
        "title": "Deep Recurrent Belief Propagation Network for POMDPs",
        "track": "main",
        "status": "Poster",
        "abstract": "In many real-world sequential decision-making tasks, especially in continuous control like robotic control, it is rare that the observations are perfect, that is, the sensory data could be incomplete, noisy or even dynamically polluted due to the unexpected malfunctions or intrinsic low quality of the sensors. Previous methods handle these issues in the framework of POMDPs and are either deterministic by feature memorization or stochastic by belief inference. In this paper, we present a new method that lies somewhere in the middle of the spectrum of research methodology identified above and combines the strength of both approaches. In particular, the proposed method, named Deep Recurrent Belief Propagation Network (DRBPN), takes a hybrid style belief updating procedure \u2212 an RNN-type feature extraction step followed by an analytical belief inference, significantly reducing the computational cost while faithfully capturing the complex dynamics and maintaining the necessary uncertainty for generalization. The effectiveness of the proposed method is verified on a collection of benchmark tasks, showing that our approach outperforms several state-of-the-art methods under various challenging scenarios.",
        "primary_area": "Machine Learning IV",
        "author": "Yuhui Wang; Xiaoyang Tan",
        "authorids": "",
        "aff": "College of Computer Science and Technology,Nanjing University of Aeronautics and Astronautics MIIT Key Laboratory of Pattern Analysis and Machine Intelligence; College of Computer Science and Technology,Nanjing University of Aeronautics and Astronautics MIIT Key Laboratory of Pattern Analysis and Machine Intelligence",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17227/17227-13-20721-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10236-deep-recurrent-belief-propagation-network-for-pomdps/",
        "doi": "10.1609/aaai.v35i11.17227",
        "pdf_size": 285236
    },
    {
        "id": "03572",
        "title": "Deep Semantic Dictionary Learning for Multi-label Image Classification",
        "track": "main",
        "status": "Poster",
        "abstract": "Compared with single-label image classification, multi-label image classification is more practical and challenging. Some recent studies attempted to leverage the semantic information of categories for improving multi-label image classification performance. However, these semantic-based methods only take semantic information as type of complements for visual representation without further exploitation. In this paper, we present an innovative path towards the solution of the multi-label image classification which considers it as a dictionary learning task. A novel end-to-end model named Deep Semantic Dictionary Learning (DSDL) is designed. In DSDL, an auto-encoder is applied to generate the semantic dictionary from class-level semantics and then such dictionary is utilized for representing the visual features extracted by Convolutional Neural Network (CNN) with label embeddings. The DSDL provides a simple but elegant way to exploit and reconcile the label, semantic and visual spaces simultaneously via conducting the dictionary learning among them. Moreover, inspired by iterative optimization of traditional dictionary learning, we further devise a novel training strategy named Alternately Parameters Update Strategy (APUS) for optimizing DSDL, which alternately optimizes the representation coefficients and the semantic dictionary in forward and backward propagation. Extensive experimental results on three popular benchmarks demonstrate that our method achieves promising performances in comparison with the state-of-the-arts. Our codes and models have been released.",
        "primary_area": "Computer Vision III",
        "author": "Fengtao Zhou; Sheng Huang; Yun Xing",
        "authorids": "",
        "aff": "School of Big data & Software Engineering, Chongqing University, Chongqing, China; School of Big data & Software Engineering, Chongqing University, Chongqing, China Ministry of Education Key Laboratory of Dependable Service Computing in Cyber Physical Society, Chongqing University, Chongqing, China; School of Big data & Software Engineering, Chongqing University, Chongqing, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16472/16472-13-19966-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03572-deep-semantic-dictionary-learning-for-multi-label-image-classification/",
        "doi": "10.1609/aaai.v35i4.16472",
        "pdf_size": 407293
    },
    {
        "id": "07073",
        "title": "Deep Spiking Neural Network with Neural Oscillation and Spike-Phase Information",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep spiking neural network (DSNN) is a promising computational model towards artificial intelligence. It benefits from both the DNNs and SNNs through a hierarchy structure to extract multiple levels of abstraction and the event-driven computational manner to provide ultra-low-power neuromorphic implementation, respectively. However, how to efficiently train the DSNNs remains an open question because of the non-differentiable spike function that prevents the traditional back-propagation (BP) learning algorithm directly applied to DSNNs. Here, inspired by the findings from the biological neural networks, we address the above-mentioned problem by introducing neural oscillation and spike-phase information to DSNNs. Specifically, we propose an Oscillation Postsynaptic Potential (Os-PSP) and phase-locking active function, and further put forward a new spiking neuron model, namely Resonate Spiking Neuron (RSN). Based on the RSN, we propose a Spike-Level-Dependent Back-Propagation (SLDBP) learning algorithm for DSNNs. Experimental results show that the proposed learning algorithm resolves the problems caused by the incompatibility between the BP learning algorithm and SNNs, and achieves state-of-the-art performance in single spike-based learning algorithms. This work investigates the contribution of introducing biologically inspired mechanisms, such as neural oscillation and spike-phase information to DSNNs and providing a new perspective to design future DSNNs.",
        "primary_area": "Machine Learning I",
        "author": "Yi Chen; Hong Qu; Malu Zhang; Yuchen Wang",
        "authorids": "",
        "aff": "University of Electronic Science and Technology of China; University of Electronic Science and Technology of China; University of Electronic Science and Technology of China National University of Singapore; University of Electronic Science and Technology of China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16870/16870-13-20364-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07073-deep-spiking-neural-network-with-neural-oscillation-and-spike-phase-information/",
        "doi": "10.1609/aaai.v35i8.16870",
        "pdf_size": 256896
    },
    {
        "id": "00353",
        "title": "Deep Style Transfer for Line Drawings",
        "track": "main",
        "status": "Poster",
        "abstract": "Line drawings are frequently used to illustrate ideas and concepts in digital documents and presentations. To compose a line drawing, it is common for users to retrieve multiple line drawings from the Internet and combine them as one image. However, different line drawings may have different line styles and are visually inconsistent when put together. In order that the line drawings can have consistent looks, in this paper, we make the first attempt to perform style transfer for line drawings. The key of our design lies in the fact that centerline plays a very important role in preserving line topology and extracting style features. With this finding, we propose to formulate the style transfer problem as a centerline stylization problem and solve it via a novel style-guided image-to-image translation network. Results and statistics show that our method significantly outperforms the existing methods both visually and quantitatively.",
        "primary_area": "Application Domains",
        "author": "Xueting Liu; Wenliang Wu; Huisi Wu; Zhenkun Wen",
        "authorids": "",
        "aff": "Shenzhen University; Shenzhen University; Shenzhen University; Shenzhen University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16111/16111-13-19605-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00353-deep-style-transfer-for-line-drawings/",
        "doi": "10.1609/aaai.v35i1.16111",
        "pdf_size": 3511017
    },
    {
        "id": "07394",
        "title": "Deep Switching Auto-Regressive Factorization: Application to Time Series Forecasting",
        "track": "main",
        "status": "Poster",
        "abstract": "We introduce deep switching auto-regressive factorization (DSARF), a deep generative model for spatio-temporal data with the capability to unravel recurring patterns in the data and perform robust short- and long-term predictions. Similar to other factor analysis methods, DSARF approximates high dimensional data by a product between time dependent weights and spatially dependent factors. These weights and factors are in turn represented in terms of lower dimensional latent variables that are inferred using stochastic variational inference. DSARF is different from the state-of-the-art techniques in that it parameterizes the weights in terms of a deep switching vector auto-regressive likelihood governed with a Markovian prior, which is able to capture the non-linear inter-dependencies among weights to characterize multimodal temporal dynamics. This results in a flexible hierarchical deep generative factor analysis model that can be extended to (i) provide a collection of potentially interpretable states abstracted from the process dynamics, and (ii) perform short- and long-term vector time series prediction in a complex multi-relational setting. Our extensive experiments, which include simulated data and real data from a wide range of applications such as climate change, weather forecasting, traffic, infectious disease spread and nonlinear physical systems attest the superior performance of DSARF in terms of long- and short-term prediction error, when compared with the state-of-the-art methods.",
        "primary_area": "Machine Learning I",
        "author": "Amirreza Farnoosh; Bahar Azari; Sarah Ostadabbas",
        "authorids": "",
        "aff": "Northeastern University; Northeastern University; Northeastern University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16907/16907-13-20401-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07394-deep-switching-auto-regressive-factorization-application-to-time-series-forecasting/",
        "doi": "10.1609/aaai.v35i8.16907",
        "pdf_size": 3864592
    },
    {
        "id": "04010",
        "title": "Deep Transfer Tensor Decomposition with Orthogonal Constraint for Recommender Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "Tensor decomposition is one of the most effective techniques for multi-criteria recommendations. However, it suffers from data sparsity when dealing with three-dimensional (3D) user-item-criterion ratings. To mitigate this issue, we consider effectively incorporating the side information and cross-domain knowledge in tensor decomposition. A deep transfer tensor decomposition (DTTD) method is proposed by integrating deep structure and Tucker decomposition, where an orthogonal constrained stacked denoising autoencoder (OC-SDAE) is proposed for alleviating the scale variation in learning effective latent representation, and the side information is incorporated as a compensation for tensor sparsity. Tucker decomposition generates private users and items' latent factors to connect with OC-SDAEs and creates a common core tensor to bridge different domains. A cross-domain alignment algorithm (CDAA) is proposed to solve the rotation issue between two core tensors in source and target domain. To the best of our knowledge, this is the first work in Tucker decomposition based recommendations to use deep structure to incorporate the side information and cross-domain knowledge. Experiments show that DTTD outperforms state-of-the-art related works.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Zhengyu Chen; Ziqing Xu; Donglin Wang",
        "authorids": "",
        "aff": "Zhejiang University Westlake University; University of Chicago; Westlake University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16521/16521-13-20015-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04010-deep-transfer-tensor-decomposition-with-orthogonal-constraint-for-recommender-systems/",
        "doi": "10.1609/aaai.v35i5.16521",
        "pdf_size": 6356427
    },
    {
        "id": "02002",
        "title": "Deep Unsupervised Image Hashing  by Maximizing Bit Entropy",
        "track": "main",
        "status": "Poster",
        "abstract": "Unsupervised hashing is important for indexing huge image or video collections without having expensive annotations available. Hashing aims to learn short binary codes for compact storage and efficient semantic retrieval. We propose an unsupervised deep hashing layer called Bi-Half Net that maximizes entropy of the binary codes. Entropy is maximal when both possible values of the bit are uniformly (half-half) distributed. To maximize bit entropy, we do not add a term to the loss function as this is difficult to optimize and tune. Instead, we design a new parameter-free network layer to explicitly force continuous image features to approximate the optimal half-half bit distribution. This layer is shown to minimize a penalized term of the Wasserstein distance between the learned continuous image features and the optimal half-half bit distribution. Experimental results on the image datasets FLICKR25K, NUS-WIDE, CIFAR-10, MS COCO, MNIST and the video datasets UCF-101 and HMDB-51 show that our approach leads to compact codes and compares favorably to the current state-of-the-art.",
        "primary_area": "Computer Vision II",
        "author": "Yunqiang Li; Jan van Gemert",
        "authorids": "",
        "aff": "Delft University of Technology; Delft University of Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16296/16296-13-19790-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02002-deep-unsupervised-image-hashing-by-maximizing-bit-entropy/",
        "doi": "10.1609/aaai.v35i3.16296",
        "pdf_size": 9085421
    },
    {
        "id": "07002",
        "title": "Deep Verifier Networks: Verification of Deep Discriminative Models with Deep Generative Models",
        "track": "main",
        "status": "Poster",
        "abstract": "AI Safety is a major concern in many deep learning applications such as autonomous driving. Given a trained deep learning model, an important natural problem is how to reliably verify the model's prediction. In this paper, we propose a novel framework --- deep verifier networks (DVN) to detect unreliable inputs or predictions of deep discriminative models, using separately trained deep generative models. Our proposed model is based on conditional variational auto-encoders with disentanglement constraints to separate the label information from the latent representation. We give both intuitive and theoretical justifications for the model. Our verifier network is trained independently with the prediction model, which eliminates the need of retraining the verifier network for a new model. We test the verifier network on both out-of-distribution detection and adversarial example detection problems, as well as anomaly detection problems in structured prediction tasks such as image caption generation. We achieve state-of-the-art results in all of these problems.",
        "primary_area": "Machine Learning I",
        "author": "Tong Che; Xiaofeng Liu; Site Li; Yubin Ge; Ruixiang Zhang; Caiming Xiong; Yoshua Bengio",
        "authorids": "",
        "aff": "Mila, Universit de Montral; Harvard Medical School, Harvard University; Carnegie Mellon University; University of Illinois at Urbana-Champaign; Mila, Universit de Montral; Salesforce Research; Mila, Universit de Montral",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16862/16862-13-20356-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07002-deep-verifier-networks-verification-of-deep-discriminative-models-with-deep-generative-models/",
        "doi": "10.1609/aaai.v35i8.16862",
        "pdf_size": 731914
    },
    {
        "id": "10914",
        "title": "Deep Wasserstein Graph Discriminant Learning for Graph Classification",
        "track": "main",
        "status": "Poster",
        "abstract": "Graph topological structures are crucial to distinguish different-class graphs. In this work, we propose a deep Wasserstein graph discriminant learning (WGDL) framework to learn discriminative embeddings of graphs in Wasserstein-metric (W-metric) matching space. In order to bypass the calculation of W-metric class centers in discriminant analysis, as well as better support batch process learning, we introduce a reference set of graphs (aka graph dictionary) to express those representative graph samples (aka dictionary keys). On the bridge of graph dictionary, every input graph can be projected into the latent dictionary space through our proposed Wasserstein graph transformation (WGT). In WGT, we formulate inter-graph distance in W-metric space by virtue of the optimal transport (OT) principle, which effectively expresses the correlations of cross-graph structures. To make WGDL better representation ability, we dynamically update graph dictionary during training by maximizing the ratio of inter-class versus intra-class Wasserstein distance. To evaluate our WGDL method, comprehensive experiments are conducted on six graph classification datasets. Experimental results demonstrate the effectiveness of our WGDL, and state-of-the-art performance.",
        "primary_area": "Machine Learning V",
        "author": "Tong Zhang; Yun Wang; Zhen Cui; Chuanwei Zhou; Baoliang Cui; Haikuan Huang; Jian Yang",
        "authorids": "",
        "aff": "Nanjing University of Science and Technology; Nanjing University of Science and Technology; Nanjing University of Science and Technology; Nanjing University of Science and Technology; Alibaba Group; Alibaba Group; Nanjing University of Science and Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17303/17303-13-20797-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10914-deep-wasserstein-graph-discriminant-learning-for-graph-classification/",
        "doi": "10.1609/aaai.v35i12.17303",
        "pdf_size": 658460
    },
    {
        "id": "01175",
        "title": "DeepCollaboration: Collaborative Generative and Discriminative Models for Class Incremental Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "An important challenge for neural networks is to learn incrementally, i.e., learn new classes without catastrophic forgetting. To overcome this problem, generative replay technique has been suggested, which can generate samples belonging to learned classes while learning new ones. However, such generative models usually suffer from increased distribution mismatch between the generated and original samples along the learning process. In this work, we propose DeepCollaboration (D-Collab), a collaborative framework of deep generative and discriminative models to solve this problem effectively. We develop a discriminative learning model to incrementally update the latent feature space for continual classification. At the same time, a generative model is introduced to achieve conditional generation using the latent feature distribution produced by the discriminative model. Importantly, the generative and discriminative models are connected through bidirectional training to enforce cycle-consistency of mappings between feature and image domains. Furthermore, a domain alignment module is used to eliminate the divergence between the feature distributions of generated images and real ones. This module together with the discriminative model can perform effective sample mining to facilitate incremental learning. Extensive experiments on several visual recognition datasets show that our system can achieve state-of-the-art performance.",
        "primary_area": "Computer Vision I",
        "author": "Bo Cui; Guyue Hu; Shan Yu",
        "authorids": "",
        "aff": "Brainnetome Center and National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences School of Artificial Intelligence, University of Chinese Academy of Sciences; Brainnetome Center and National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences School of Artificial Intelligence, University of Chinese Academy of Sciences; Brainnetome Center and NLPR;University of Chinese Academy of Sciences CAS Center for Excellence in Brain Science and Intelligence Technology, Chinese Academy of Sciences School of Future Technology, University of Chinese Academy of Sciences",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16204/16204-13-19698-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01175-deepcollaboration-collaborative-generative-and-discriminative-models-for-class-incremental-learning/",
        "doi": "10.1609/aaai.v35i2.16204",
        "pdf_size": 5042021
    },
    {
        "id": "02277",
        "title": "DeepDT: Learning Geometry From Delaunay Triangulation for Surface Reconstruction",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, a novel learning-based network, named DeepDT, is proposed to reconstruct the surface from Delaunay triangulation of point cloud. DeepDT learns to predict inside/outside labels of Delaunay tetrahedrons directly from a point cloud and corresponding Delaunay triangulation. The local geometry features are first extracted from the input point cloud and aggregated into a graph deriving from the Delaunay triangulation. Then a graph filtering is applied on the aggregated features in order to add structural regularization to the label prediction of tetrahedrons. Due to the complicated spatial relations between tetrahedrons and the triangles, it is impossible to directly generate ground truth labels of tetrahedrons from ground truth surface. Therefore, we propose a multi-label supervision strategy which votes for the label of a tetrahedron with labels of sampling locations inside it. The proposed DeepDT can maintain abundant geometry details without generating overly complex surfaces, especially for inner surfaces of open scenes. Meanwhile, the generalization ability and time consumption of the proposed method is acceptable and competitive compared with the state-of-the-art methods. Experiments demonstrate the superior performance of the proposed DeepDT.",
        "primary_area": "Computer Vision II",
        "author": "Yiming Luo; Zhenxing Mi; Wenbing Tao",
        "authorids": "",
        "aff": "Huazhong University of Science and Technology; Huazhong University of Science and Technology; Huazhong University of Science and Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16327/16327-13-19821-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02277-deepdt-learning-geometry-from-delaunay-triangulation-for-surface-reconstruction/",
        "doi": "10.1609/aaai.v35i3.16327",
        "pdf_size": 4223414
    },
    {
        "id": "00479",
        "title": "DeepPseudo: Pseudo Value Based Deep Learning Models for Competing Risk Analysis",
        "track": "main",
        "status": "Poster",
        "abstract": "Competing Risk Analysis (CRA) aims at the correct estimation of the marginal probability of occurrence of an event in the presence of competing events. Many of the statistical approaches developed for CRA are limited by strong assumptions about the underlying stochastic processes. To overcome these issues and to handle censoring, machine learning approaches for CRA have designed specialized cost functions. However, these approaches are not generalizable, and are computationally expensive. This paper formulates CRA as a cause-specific regression problem and proposes DeepPseudo models, which use simple and effective feed-forward deep neural networks, to predict the cumulative incidence function (CIF) using Aalen-Johansen estimator-based pseudo values. DeepPseudo models capture the time-varying covariate effect on CIF while handling the censored observations. We show how DeepPseudo models can address co-variate dependent censoring by using modified pseudo values. Experiments on real and synthetic datasets demonstrate that our proposed models obtain promising and statistically significant results compared to the state-of-the-art CRA approaches. Furthermore, we show that explainable methods such as Layer-wise Relevance Propagation can be used to interpret the predictions of our DeepPseudo models.",
        "primary_area": "Application Domains",
        "author": "Md Mahmudur Rahman; Koji Matsuo; Shinya Matsuzaki; Sanjay Purushotham",
        "authorids": "",
        "aff": "University of Maryland Baltimore County; University of Southern California; Osaka University; University of Maryland, Baltimore County",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16125/16125-13-19619-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00479-deeppseudo-pseudo-value-based-deep-learning-models-for-competing-risk-analysis/",
        "doi": "10.1609/aaai.v35i1.16125",
        "pdf_size": 281711
    },
    {
        "id": "07647",
        "title": "DeepSynth: Automata Synthesis for Automatic Task Segmentation in Deep Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes DeepSynth, a method for effective training of deep Reinforcement Learning (RL) agents when the reward is sparse and non-Markovian, but at the same time progress towards the reward requires achieving an unknown sequence of high-level objectives. Our method employs a novel algorithm for synthesis of compact automata to uncover this sequential structure automatically. We synthesise a human-interpretable automaton from trace data collected by exploring the environment. The state space of the environment is then enriched with the synthesised automaton so that the generation of a control policy by deep RL is guided by the discovered structure encoded in the automaton. The proposed approach is able to cope  with both high-dimensional, low-level features and unknown sparse non-Markovian rewards. We have evaluated DeepSynth's performance in a set of experiments that includes the Atari game Montezuma's Revenge. Compared to existing approaches, we obtain a reduction of two orders of magnitude in the number of iterations required for policy synthesis, and also a significant improvement in scalability.",
        "primary_area": "Machine Learning II",
        "author": "Mohammadhosein Hasanbeig; Natasha Yogananda Jeppu; Alessandro Abate; Tom Melham; Daniel Kroening",
        "authorids": "",
        "aff": "University of Oxford; University of Oxford; University of Oxford; University of Oxford; University of Oxford",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16935/16935-13-20429-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07647-deepsynth-automata-synthesis-for-automatic-task-segmentation-in-deep-reinforcement-learning/",
        "doi": "10.1609/aaai.v35i9.16935",
        "pdf_size": 736540
    },
    {
        "id": "00643",
        "title": "DeepTrader: A Deep Reinforcement Learning Approach for Risk-Return Balanced Portfolio Management with Market Conditions Embedding",
        "track": "main",
        "status": "Poster",
        "abstract": "Most existing reinforcement learning (RL)-based portfolio management models do not take into account the market conditions, which limits their performance in risk-return balancing. In this paper, we propose DeepTrader, a deep RL method to optimize the investment policy. In particular, to tackle the risk-return balancing problem, our model embeds macro market conditions as an indicator to dynamically adjust the proportion between long and short funds, to lower the risk of market fluctuations, with the negative maximum drawdown as the reward function. Additionally, the model involves a unit to evaluate individual assets, which learns dynamic patterns from historical data with the price rising rate as the reward function. Both temporal and spatial dependencies between assets are captured hierarchically by a specific type of graph structure. Particularly, we find that the estimated causal structure best captures the interrelationships between assets, compared to industry classification and correlation. The two units are complementary and integrated to generate a suitable portfolio which fits the market trend well and strikes a balance between return and risk effectively. Experiments on three well-known stock indexes demonstrate the superiority of DeepTrader in terms of risk-gain criteria.",
        "primary_area": "Application Domains",
        "author": "Zhicheng Wang; Biwei Huang; Shikui Tu; Kun Zhang; Lei Xu",
        "authorids": "",
        "aff": "Shanghai JiaoTong University; Carnegie Mellon University; Shanghai Jiao Tong University; Carnegie Mellon University; Shanghai Jiao Tong University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16144/16144-13-19638-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00643-deeptrader-a-deep-reinforcement-learning-approach-for-risk-return-balanced-portfolio-management-with-market-conditions-embedding/",
        "doi": "10.1609/aaai.v35i1.16144",
        "pdf_size": 423307
    },
    {
        "id": "00600",
        "title": "DeepWriteSYN: On-Line Handwriting Synthesis via Deep Short-Term Representations",
        "track": "main",
        "status": "Poster",
        "abstract": "This study proposes DeepWriteSYN, a novel on-line handwriting synthesis approach via deep short-term representations. It comprises two modules: i) an optional and interchangeable temporal segmentation, which divides the handwriting into short-time segments consisting of individual or multiple concatenated strokes; and ii) the on-line synthesis of those short-time handwriting segments, which is based on a sequence-to-sequence Variational Autoencoder (VAE). The main advantages of the proposed approach are that the synthesis is carried out in short-time segments (that can run from a character fraction to full characters) and that the VAE can be trained on a configurable handwriting dataset. These two properties give a lot of flexibility to our synthesiser, e.g., as shown in our experiments, DeepWriteSYN can generate realistic handwriting variations of a given handwritten structure corresponding to the natural variation within a given population or a given subject. These two cases are developed experimentally for individual digits and handwriting signatures, respectively, achieving in both cases remarkable results.  Also, we provide experimental results for the task of on-line signature verification showing the high potential of DeepWriteSYN to improve significantly one-shot learning scenarios. To the best of our knowledge, this is the first synthesis approach capable of generating realistic on-line handwriting in the short term (including handwritten signatures) via deep learning. This can be very useful as a module toward long-term realistic handwriting generation either completely synthetic or as natural variation of given handwriting samples.",
        "primary_area": "Application Domains",
        "author": "Ruben Tolosana; Paula Delgado-Santos; Andres Perez-Uribe; Ruben Vera-Rodriguez; Julian Fierrez; Aythami Morales",
        "authorids": "",
        "aff": "Universidad Autonoma de Madrid; Universidad Autonoma de Madrid; University of Applied Sciences Western Switzerland; Universidad Autonoma de Madrid; Universidad Autonoma de Madrid; Universidad Autonoma de Madrid",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16139/16139-13-19633-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00600-deepwritesyn-on-line-handwriting-synthesis-via-deep-short-term-representations/",
        "doi": "10.1609/aaai.v35i1.16139",
        "pdf_size": 3539028
    },
    {
        "id": "09268",
        "title": "Defending against Backdoors in Federated Learning with Robust Learning Rate",
        "track": "main",
        "status": "Poster",
        "abstract": "Federated learning (FL) allows a set of agents to collaboratively train a model without sharing their potentially sensitive data. This makes FL suitable for privacy-preserving applications. At the same time, FL is susceptible to adversarial attacks due to decentralized and unvetted data. One important line of attacks against FL is the backdoor attacks. In a backdoor attack, an adversary tries to embed a backdoor functionality to the model during training that can later be activated to cause a desired misclassification. To prevent backdoor attacks, we propose a lightweight defense that requires minimal change to the FL protocol. At a high level, our defense is based on carefully adjusting the aggregation server's learning rate, per dimension and per round, based on the sign information of agents' updates. We first conjecture the necessary steps to carry a successful backdoor attack in FL setting, and then, explicitly formulate the defense based on our conjecture. Through experiments, we provide empirical evidence that supports our conjecture, and we test our defense against backdoor attacks under different settings. We observe that either backdoor is completely eliminated, or its accuracy is significantly reduced. Overall, our experiments suggest that our defense significantly outperforms some of the recently proposed defenses in the literature. We achieve this by having minimal influence over the accuracy of the trained models. In addition, we also provide convergence rate analysis for our proposed scheme.",
        "primary_area": "Machine Learning III",
        "author": "Mustafa Safa Ozdayi; Murat Kantarcioglu; Yulia R. Gel",
        "authorids": "",
        "aff": "The University of Texas at Dallas; The University of Texas at Dallas; The University of Texas at Dallas",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17118/17118-13-20612-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09268-defending-against-backdoors-in-federated-learning-with-robust-learning-rate/",
        "doi": "10.1609/aaai.v35i10.17118",
        "pdf_size": 375343
    },
    {
        "id": "05135",
        "title": "Defending against Contagious Attacks on a Network with Resource Reallocation",
        "track": "main",
        "status": "Poster",
        "abstract": "In classic network security games, the defender distributes defending resources to the nodes of the network, and the attacker attacks a node, with the objective to maximize the damage caused. Existing models assume that the attack at node u causes damage only at u. However, in many real-world security scenarios, the attack at a node u spreads to the neighbors of u and can cause damage at multiple nodes, e.g., for the outbreak of a virus. In this paper, we consider the network defending problem against contagious attacks. Existing works that study shared resources assume that the resource allocated to a node can be shared or duplicated between neighboring nodes. However, in real world, sharing resource naturally leads to a decrease in defending power of the source node, especially when defending against contagious attacks. To this end, we study the model in which resources allocated to a node can only be transferred to its neighboring nodes, which we refer to as a reallocation process. We show that this more general model is difficult in two aspects: (1) even for a fixed allocation of resources, we show that computing the optimal reallocation is NP-hard; (2) for the case when reallocation is not allowed, we show that computing the optimal allocation (against contagious attack) is also NP-hard. For positive results, we give a mixed integer linear program formulation for the problem and a bi-criteria approximation algorithm. Our experimental results demonstrate that the allocation and reallocation strategies our algorithm computes perform well in terms of minimizing the damage due to contagious attacks.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Rufan Bai; Haoxing Lin; Xinyu Yang; Xiaowei Wu; Minming Li; Weijia Jia",
        "authorids": "",
        "aff": "IoTSC, University of Macau, yb97439@um.edu.mo; IoTSC, University of Macau, starklin@um.edu.mo; IoTSC, University of Macau, mb95466@um.edu.mo; IoTSC, University of Macau, xiaoweiwu@um.edu.mo; City University of Hong Kong, minming.li@cityu.edu.hk; BNU(Zhuhai) & UIC, jiawj@sjtu.edu.cn",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16649/16649-13-20143-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05135-defending-against-contagious-attacks-on-a-network-with-resource-reallocation/",
        "doi": "10.1609/aaai.v35i6.16649",
        "pdf_size": 199511
    },
    {
        "id": "02216",
        "title": "Delving into Variance Transmission and Normalization: Shift of Average Gradient Makes the Network Collapse",
        "track": "main",
        "status": "Poster",
        "abstract": "Normalization operations are essential for state-of-the-art neural networks and enable us to train a network from scratch with a large learning rate (LR). We attempt to explain the real effect of Batch Normalization (BN) from the perspective of variance transmission by investigating the relationship between BN and Weights Normalization (WN). In this work, we demonstrate that the problem of the shift of the average gradient will amplify the variance of every convolutional (conv) layer. We propose Parametric Weights Standardization (PWS), a fast and robust to mini-batch size module used for conv filters, to solve the shift of the average gradient. PWS can provide the speed-up of BN. Besides, it has less computation and does not change the output of a conv layer. PWS enables the network to converge fast without normalizing the outputs. This result enhances the persuasiveness of the shift of the average gradient and explains why BN works from the perspective of variance transmission. The code and appendix will be made available on https://github.com/lyxzzz/PWSConv.",
        "primary_area": "Computer Vision II",
        "author": "Yuxiang Liu; Jidong Ge; Chuanyi Li; Jie Gui",
        "authorids": "",
        "aff": "Nanjing University; Nanjing University; Nanjing University; Southeast University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16320/16320-13-19814-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02216-delving-into-variance-transmission-and-normalization-shift-of-average-gradient-makes-the-network-collapse/",
        "doi": "10.1609/aaai.v35i3.16320",
        "pdf_size": 8984418
    },
    {
        "id": "03278",
        "title": "Demodalizing Face Recognition with Synthetic Samples",
        "track": "main",
        "status": "Poster",
        "abstract": "Using data generated by generative adversarial networks or three-dimensional (3D) technology for face recognition training is a theoretically reasonable solution to the problems of unbalanced data distributions and data scarcity. However, due to the modal difference between synthetic data and real data, the direct use of data for training often leads to a decrease in the recognition performance, and the effect of synthetic data on recognition remains ambiguous. In this paper, after observing in experiments that modality information has a fixed form, we propose a demodalizing face recognition training architecture for the first time and provide a feasible method for recognition training using synthetic samples. Specifically, three different demodalizing training methods, from implicit to explicit, are proposed. These methods gradually reveal a generated modality that is difficult to quantify or describe. By removing the modalities of the synthetic data, the performance degradation is greatly alleviated. We validate the effectiveness of our approach on various benchmarks of large-scale face recognition and outperform the previous methods, especially in the low FAR range.",
        "primary_area": "Computer Vision III",
        "author": "Zhonghua Zhai; Pengju Yang; Xiaofeng Zhang; Maji Huang; Haijing Cheng; Xuejun Yan; Chunmao Wang; Shiliang Pu",
        "authorids": "",
        "aff": "Hikvision Research Institute Zhejiang University; Hikvision Research Institute; Hikvision Research Institute; Hikvision Research Institute; Hikvision Research Institute; Hikvision Research Institue; Hikvision Research Institute; Hikvision Research Institute",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16439/16439-13-19933-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03278-demodalizing-face-recognition-with-synthetic-samples/",
        "doi": "10.1609/aaai.v35i4.16439",
        "pdf_size": 473873
    },
    {
        "id": "14481",
        "title": "Denoising Distantly Supervised Named Entity Recognition via a Hypergeometric Probabilistic Model",
        "track": "main",
        "status": "Poster",
        "abstract": "Denoising is the essential step for distant supervision based named entity recognition. Previous denoising methods are mostly based on instance-level confidence statistics, which ignore the variety of the underlying noise distribution on different datasets and entity types. This makes them difficult to be adapted to high noise rate settings. In this paper, we propose Hypergeometric Learning (HGL), a denoising algorithm for distantly supervised NER that takes both noise distribution and instance-level confidence into consideration. Specifically, during neural network training, we naturally model the noise samples in each batch following a hypergeometric distribution parameterized by the noise-rate. Then each instance in the batch is regarded as either correct or noisy one according to its label confidence derived from previous training step, as well as the noise distribution in this sampled batch. Experiments show that HGL can effectively denoise the weakly-labeled data retrieved from distant supervision, and therefore results in significant improvements on the trained models.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Wenkai Zhang; Hongyu Lin; Xianpei Han; Le Sun; Huidan Liu; Zhicheng Wei; Nicholas Yuan",
        "authorids": "",
        "aff": "Chinese Information Processing Laboratory, Institute of Software, Chinese Academy of Sciences University of Chinese Academy of Sciences; Chinese Information Processing Laboratory, Institute of Software, Chinese Academy of Sciences; Chinese Information Processing Laboratory, Institute of Software, Chinese Academy of Sciences State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences; Chinese Information Processing Laboratory, Institute of Software, Chinese Academy of Sciences State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences; Chinese Information Processing Laboratory, Institute of Software, Chinese Academy of Sciences; Huawei Cloud&AI; Huawei Cloud&AI",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17702/17702-13-21196-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14481-denoising-distantly-supervised-named-entity-recognition-via-a-hypergeometric-probabilistic-model/",
        "doi": "10.1609/aaai.v35i16.17702",
        "pdf_size": 197661
    },
    {
        "id": "00920",
        "title": "Dense Events Grounding in Video",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper explores a novel setting of temporal sentence grounding for the first time, dubbed as dense events grounding. Given an untrimmed video and a paragraph description, dense events grounding aims to jointly localize temporal moments of multiple events described in the paragraph. Our main motivating fact is that multiple events to be grounded in a video are often semantically related and temporally coordinated according to their order appearing in the paragraph. This fact sheds light on devising more accurate visual grounding model. In this work, we propose Dense Events Propagation Network (DepNet) for this novel task. DepNet first adaptively aggregates temporal and semantic information of dense events into a compact set through a second-order attention pooling, then selectively propagates the aggregated information to each single event with soft attention. Based on such aggregation-and-propagation mechanism, DepNet can effectively exploit both the temporal order and semantic relations of dense events. We conduct comprehensive experiments on large-scale datasets ActivityNet Captions and TACoS. For fair comparisons, our evaluations include both state-of-art single-event grounding methods and their natural extensions to the dense-events grounding setting implemented by us. All experiments clearly shows the performance superiority of the proposed DepNet by significant margins.",
        "primary_area": "Computer Vision I",
        "author": "Peijun Bao; Qian Zheng; Yadong Mu",
        "authorids": "",
        "aff": "Peking University, China; Nanyang Technological University, Singapore; Peking University, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16175/16175-13-19669-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00920-dense-events-grounding-in-video/",
        "doi": "10.1609/aaai.v35i2.16175",
        "pdf_size": 756333
    },
    {
        "id": "06101",
        "title": "DenserNet: Weakly Supervised Visual Localization Using Multi-Scale Feature Aggregation",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work,   we introduce a   Denser   Feature   Network(DenserNet) for visual localization. Our work provides three principal contributions.  First,  we develop a  convolutional neural network (CNN) architecture which aggregates feature maps at different semantic levels for image representations. Using denser feature maps,  our method can produce more key point features and increase image retrieval accuracy. Second, our model is trained end-to-end without pixel-level an-notation other than positive and negative GPS-tagged image pairs.  We use a  weakly supervised triplet ranking loss to learn discriminative features and encourage keypoint feature repeatability for image representation.  Finally,  our method is computationally efficient as our architecture has shared features and parameters during forwarding propagation. Our method is flexible and can be crafted on a  light-weighted backbone architecture to achieve appealing efficiency with a small penalty on accuracy. Extensive experiment results indicate that our method sets a  new state-of-the-art on four challenging large-scale localization benchmarks and three image retrieval benchmarks with the same level of supervision. The code is available at https://github.com/goodproj13/DenserNet",
        "primary_area": "Intelligent Robots",
        "author": "Dongfang Liu; Yiming Cui; Liqi Yan; Christos Mousas; Baijian Yang; Yingjie Chen",
        "authorids": "",
        "aff": "Purdue University; University of Florida; Fudan University; Purdue University; Purdue University; Purdue University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16760/16760-13-20254-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06101-densernet-weakly-supervised-visual-localization-using-multi-scale-feature-aggregation/",
        "doi": "10.1609/aaai.v35i7.16760",
        "pdf_size": 10573683
    },
    {
        "id": "03877",
        "title": "Dependency Stochastic Boolean Satisfiability: A Logical Formalism for NEXPTIME Decision Problems with Uncertainty",
        "track": "main",
        "status": "Poster",
        "abstract": "Stochastic Boolean Satisfiability (SSAT) is a logical formalism to model decision problems with uncertainty, such as Partially Observable Markov Decision Process (POMDP) for verification of probabilistic systems. SSAT, however, is limited by its descriptive power within the PSPACE complexity class. More complex problems, such as the NEXPTIME-complete Decentralized POMDP (Dec-POMDP), cannot be succinctly encoded with SSAT. To provide a logical formalism of such problems, we generalize the Dependency Quantified Boolean Formula (DQBF), a representative problem in the NEXPTIME-complete class, to its stochastic variant, named Dependency SSAT (DSSAT), and show that DSSAT is also NEXPTIME-complete. We demonstrate the potential applications of DSSAT to circuit synthesis of probabilistic and approximate design. Furthermore, to study the descriptive power of DSSAT, we establish a polynomial-time reduction from Dec-POMDP to DSSAT. With the theoretical foundations paved in this work, we hope to encourage the development of DSSAT solvers for potential broad applications.",
        "primary_area": "Constraint Satisfaction and Optimization",
        "author": "Nian-Ze Lee; Jie-Hong R. Jiang",
        "authorids": "",
        "aff": "Graduate Institute of Electronics Engineering, National Taiwan University; Department of Electrical Engineering, National Taiwan University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16506/16506-13-20000-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03877-dependency-stochastic-boolean-satisfiability-a-logical-formalism-for-nexptime-decision-problems-with-uncertainty/",
        "doi": "10.1609/aaai.v35i5.16506",
        "pdf_size": 212452
    },
    {
        "id": "03456",
        "title": "Depth Privileged Object Detection in Indoor Scenes via Deformation Hallucination",
        "track": "main",
        "status": "Poster",
        "abstract": "RGB-D object detection has achieved significant advance, because depth provides complementary geometric information to RGB images. Considering depth images are unavailable in some scenarios, we focus on depth privileged object detection in indoor scenes, where the depth images are only available in the training phase. Under this setting, one prevalent research line is modality hallucination, in which depth image and depth feature are the common choices for hallucinating. In contrast, we choose to hallucinate depth deformation, which is explicit geometric information and efficient to hallucinate. Specifically, we employ the deformable convolution layer with augmented offsets as our deformation module and regard the offsets as geometric deformation, because the offsets enable flexibly sampling over the object and transforming to a canonical shape for ease of detection. In addition, we design a quality-based mechanism to avoid negative transfer of depth deformation. Experimental results and analyses on NYUDv2 and SUN RGB-D demonstrate the effectiveness of our method against the state-of-the-art methods for depth privileged object detection.",
        "primary_area": "Computer Vision III",
        "author": "Zhijie Zhang; Yan Liu; Junjie Chen; Li Niu; Liqing Zhang",
        "authorids": "",
        "aff": "Shanghai Jiao Tong University; Shanghai Jiao Tong University; Shanghai Jiao Tong University; Shanghai Jiao Tong University; Shanghai Jiao Tong University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16459/16459-13-19953-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03456-depth-privileged-object-detection-in-indoor-scenes-via-deformation-hallucination/",
        "doi": "10.1609/aaai.v35i4.16459",
        "pdf_size": 5029503
    },
    {
        "id": "09877",
        "title": "Detecting Adversarial Examples from Sensitivity Inconsistency of Spatial-Transform Domain",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep neural networks (DNNs) have been shown to be vulnerable against adversarial examples (AEs), which are maliciously designed to cause dramatic model output errors. In this work, we reveal that normal examples (NEs) are insensitive to the fluctuations occurring at the highly-curved region of the decision boundary, while AEs typically designed over one single domain (mostly spatial domain) exhibit exorbitant sensitivity on such fluctuations. This phenomenon motivates us to design another classifier (called dual classifier) with transformed decision boundary, which can be collaboratively used with the original classifier (called primal classifier) to detect AEs, by virtue of the sensitivity inconsistency. When comparing with the state-of-the-art algorithms based on Local Intrinsic Dimensionality (LID), Mahalanobis Distance (MD), and Feature Squeezing (FS), our proposed\u00a0Sensitivity Inconsistency Detector (SID) achieves improved AE\u00a0 detection performance and superior generalization capabilities, especially in the challenging cases where the adversarial perturbation levels are small. Intensive experimental results on ResNet and VGG validate the superiority of the proposed SID.",
        "primary_area": "Machine Learning IV",
        "author": "Jinyu Tian; Jiantao Zhou; Yuanman Li; Jia Duan",
        "authorids": "",
        "aff": "University of Macau; University of Macau; Shenzhen University; University of Macau",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17187/17187-13-20681-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09877-detecting-adversarial-examples-from-sensitivity-inconsistency-of-spatial-transform-domain/",
        "doi": "10.1609/aaai.v35i11.17187",
        "pdf_size": 862980
    },
    {
        "id": "04357",
        "title": "Detecting Beneficial Feature Interactions for Recommender Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "Feature interactions are essential for achieving high accuracy in recommender systems. Many studies take into account the interaction between every pair of features. However, this is suboptimal because some feature interactions may not be that relevant to the recommendation result and taking them into account may introduce noise and decrease recommendation accuracy. To make the best out of feature interactions, we propose a graph neural network approach to effectively model them, together with a novel technique to automatically detect those feature interactions that are beneficial in terms of recommendation accuracy. The automatic feature interaction detection is achieved via edge prediction with an L0 activation regularization. Our proposed model is proved to be effective through the information bottleneck principle and statistical interaction theory. Experimental results show that our model (i) outperforms existing baselines in terms of accuracy, and (ii) automatically identifies beneficial feature interactions.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Yixin Su; Rui Zhang; Sarah Erfani; Zhenghua Xu",
        "authorids": "",
        "aff": "University of Melbourne; Tsinghua University; University of Melbourne; Hebei University of Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16561/16561-13-20055-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04357-detecting-beneficial-feature-interactions-for-recommender-systems/",
        "doi": "10.1609/aaai.v35i5.16561",
        "pdf_size": 479301
    },
    {
        "id": "06723",
        "title": "Deterministic Mini-batch Sequencing for Training Deep Neural Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent advancements in the field of deep learning have dramatically improved the performance of machine learning models in a variety of applications, including computer vision, text mining, speech processing and fraud detection among others. Mini-batch gradient descent is the standard algorithm to train deep models, where mini-batches of a fixed size are sampled randomly from the training data and passed through the network sequentially. In this paper, we present a novel algorithm to generate a deterministic sequence of mini-batches to train a deep neural network (rather than a random sequence). Our rationale is to select a mini-batch by minimizing the Maximum Mean Discrepancy (MMD) between the already selected mini-batches and the unselected training samples. We pose the mini-batch selection as a constrained optimization problem and derive a linear programming relaxation to determine the sequence of mini-batches. To the best of our knowledge, this is the first research effort that uses the MMD criterion to determine a sequence of mini-batches to train a deep neural network. The proposed mini-batch sequencing strategy is deterministic and independent of the underlying network architecture and prediction task. Our extensive empirical analyses on three challenging datasets corroborate the merit of our framework over competing baselines. We further study the performance of our framework on two other applications besides classification (regression and semantic segmentation) to validate its generalizability.",
        "primary_area": "Machine Learning I",
        "author": "Subhankar Banerjee; Shayok Chakraborty",
        "authorids": "",
        "aff": "Florida State University; Florida State University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16831/16831-13-20325-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06723-deterministic-mini-batch-sequencing-for-training-deep-neural-networks/",
        "doi": "10.1609/aaai.v35i8.16831",
        "pdf_size": 196254
    },
    {
        "id": "00047",
        "title": "Diagnose Like A Pathologist: Weakly-Supervised Pathologist-Tree Network for Slide-Level Immunohistochemical Scoring",
        "track": "main",
        "status": "Poster",
        "abstract": "The immunohistochemistry (IHC) test of biopsy tissue is crucial to develop targeted treatment and evaluate prognosis for cancer patients. The IHC staining slide is usually digitized into the whole-slide image (WSI) with gigapixels for quantitative image analysis. To perform a whole image prediction (e.g., IHC scoring, survival prediction, and cancer grading) from this kind of high-dimensional image, algorithms are often developed based on multi-instance learning (MIL) framework. However, the multi-scale information of WSI and the associations among instances are not well explored in existing MIL based studies. Inspired by the fact that pathologists jointly analyze visual fields at multiple powers of objective for diagnostic predictions, we propose a Pathologist-Tree Network (PTree-Net) to sparsely model the WSI efficiently in multi-scale manner. Specifically, we propose a Focal-Aware Module (FAM) that can approximately estimate diagnosis-related regions with an extractor trained using the thumbnail of WSI. With the initial diagnosis-related regions, we hierarchically model the multi-scale patches in a tree structure, where both the global and local information can be captured. To explore this tree structure in an end-to-end network, we propose a patch Relevance-enhanced Graph Convolutional Network (RGCN) to explicitly model the correlations of adjacent parent-child nodes, accompanied by patch relevance to exploit the implicit contextual information among distant nodes. In addition, tree-based self-supervision is devised to improve representation learning and suppress irrelevant instances adaptively. Extensive experiments are performed on a large-scale IHC HER2 dataset. The ablation study confirms the effectiveness of our design, and our approach outperforms state-of-the-art by a large margin.",
        "primary_area": "Application Domains",
        "author": "Zhen Chen; Jun Zhang; Shuanlong Che; Junzhou Huang; Xiao Han; Yixuan Yuan",
        "authorids": "",
        "aff": "City University of Hong Kong; Tencent AI Lab; KingMed Diagnostics; Tencent AI Lab; Tencent AI Lab; City University of Hong Kong",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16076/16076-13-19570-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00047-diagnose-like-a-pathologist-weakly-supervised-pathologist-tree-network-for-slide-level-immunohistochemical-scoring/",
        "doi": "10.1609/aaai.v35i1.16076",
        "pdf_size": 9063375
    },
    {
        "id": "13604",
        "title": "Dialog Policy Learning for Joint Clarification and Active Learning Queries",
        "track": "main",
        "status": "Poster",
        "abstract": "Intelligent systems need to be able to recover from mistakes, resolve uncertainty, and adapt to novel concepts not seen during training. Dialog interaction can enable this by the use of clarifications for correction and resolving uncertainty, and active learning queries to learn new concepts encountered during operation. Prior work on dialog systems has either focused on exclusively learning how to perform clarification/ information seeking, or to perform active learning. In this work, we train a hierarchical dialog policy to jointly perform {it both} clarification and active learning in the context of an interactive language-based image retrieval task motivated by an online shopping application, and demonstrate that jointly learning dialog policies for clarification and active learning is more effective than the use of static dialog policies for one or both of these functions.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Aishwarya Padmakumar; Raymond J. Mooney",
        "authorids": "",
        "aff": "Amazon Alexa AI; University of Texas at Austin",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17604/17604-13-21098-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13604-dialog-policy-learning-for-joint-clarification-and-active-learning-queries/",
        "doi": "10.1609/aaai.v35i15.17604",
        "pdf_size": 360682
    },
    {
        "id": "12911",
        "title": "DialogBERT: Discourse-Aware Response Generation via Learning to Recover and Rank Utterances",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent advances in pre-trained language models have significantly improved neural response generation. However, existing methods usually view the dialogue context as a linear sequence of tokens and learn to generate the next word through token-level self-attention. Such token-level encoding hinders the exploration of discourse-level coherence among utterances. This paper presents DialogBERT, a novel conversational response generation model that enhances previous PLM-based dialogue models. DialogBERT employs a hierarchical Transformer architecture. To efficiently capture the discourse-level coherence among utterances, we propose two training objectives, including masked utterance regression and distributed utterance order ranking in analogy to the original BERT training. Experiments on three multi-turn conversation datasets show that our approach remarkably outperforms three baselines, such as BART and DialoGPT, in terms of quantitative evaluation. The human evaluation suggests that DialogBERT generates more coherent, informative, and human-like responses than the baselines with significant margins.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Xiaodong Gu; Kang Min Yoo; Jung-Woo Ha",
        "authorids": "",
        "aff": "School of Software, Shanghai Jiao Tong University, China; NAVER AI Lab, Korea; NAVER AI Lab, Korea",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17527/17527-13-21021-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12911-dialogbert-discourse-aware-response-generation-via-learning-to-recover-and-rank-utterances/",
        "doi": "10.1609/aaai.v35i14.17527",
        "pdf_size": 257010
    },
    {
        "id": "13789",
        "title": "DialogXL: All-in-One XLNet for Multi-Party Conversation Emotion Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents our pioneering effort for emotion recognition in conversation (ERC) with pre-trained language models. Unlike regular documents, conversational utterances appear alternately from different parties and are usually organized as hierarchical structures in previous work. Such structures are not conducive to the application of pre-trained language models such as XLNet. To address this issue, we propose an all-in-one XLNet model, namely DialogXL, with enhanced memory to store longer historical context and dialog-aware self-attention to deal with the multi-party structures. Specifically, we first modify the recurrence mechanism of XLNet from segment-level to utterance-level in order to better model the conversational data. Second, we introduce dialog-aware self-attention in replacement of the vanilla self-attention in XLNet to capture useful intra- and inter-speaker dependencies. Extensive experiments are conducted on four ERC benchmarks with mainstream models presented for comparison. The experimental results show that the proposed model outperforms the baselines on all the datasets. Several other experiments such as ablation study and error analysis are also conducted and the results confirm the role of the critical modules of DialogXL.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Weizhou Shen; Junqing Chen; Xiaojun Quan; Zhixian Xie",
        "authorids": "",
        "aff": "Sun Yat-sen university; Sun Yat-sen University; Sun Yat-sen University; Sun Yat-sen University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17625/17625-13-21119-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13789-dialogxl-all-in-one-xlnet-for-multi-party-conversation-emotion-recognition/",
        "doi": "10.1609/aaai.v35i15.17625",
        "pdf_size": 1234037
    },
    {
        "id": "06138",
        "title": "Differentiable Fluids with Solid Coupling for Learning and Control",
        "track": "main",
        "status": "Poster",
        "abstract": "We introduce an efficient differentiable fluid simulator that can be integrated with deep neural networks as a part of layers for learning dynamics and solving control problems. It offers the capability to handle one-way coupling of fluids with rigid objects using a variational principle that naturally enforces necessary boundary conditions at the fluid-solid interface with sub-grid details. This simulator utilizes the adjoint method to efficiently compute the gradient for multiple time steps of fluid simulation with user defined objective functions. We demonstrate the effectiveness of our method for solving inverse and control problems on fluids with one-way coupled solids. Our method outperforms the previous gradient computations, state-of-the-art derivative-free optimization, and model-free reinforcement learning techniques by at least one order of magnitude.",
        "primary_area": "Intelligent Robots",
        "author": "Tetsuya Takahashi; Junbang Liang; Yi-Ling Qiao; Ming C. Lin",
        "authorids": "",
        "aff": "Adobe University of Maryland at College Park; University of Maryland at College Park; University of Maryland at College Park; University of Maryland at College Park",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16764/16764-13-20258-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06138-differentiable-fluids-with-solid-coupling-for-learning-and-control/",
        "doi": "10.1609/aaai.v35i7.16764",
        "pdf_size": 5746272
    },
    {
        "id": "05034",
        "title": "Differentiable Inductive Logic Programming for Structured Examples",
        "track": "main",
        "status": "Poster",
        "abstract": "The differentiable implementation of logic yields a seamless combination of symbolic reasoning and deep neural networks. Recent research, which has developed a differentiable framework to learn logic programs from examples, can even acquire reasonable solutions from noisy datasets. However, this framework severely limits expressions for solutions, e.g., no function symbols are allowed, and the shapes of clauses are fixed. As a result, the framework cannot deal with structured examples. Therefore we propose a new framework to learn logic programs from noisy and structured examples, including the following contributions. First, we propose an adaptive clause search method by looking through structured space, which is defined by the generality of the clauses, to yield an efficient search space for differentiable solvers. Second, we propose for ground atoms an enumeration algorithm, which determines a necessary and sufficient set of ground atoms to perform differentiable inference functions. Finally, we propose a new method to compose logic programs softly, enabling the system to deal with complex programs consisting of several clauses. Our experiments show that our new framework can learn logic programs from noisy and structured examples, such as sequences or trees. Our framework can be scaled to deal with complex programs that consist of several clauses with function symbols.",
        "primary_area": "Neuro-Symbolic AI",
        "author": "Hikaru Shindo; Masaaki Nishino; Akihiro Yamamoto",
        "authorids": "",
        "aff": "Kyoto University; NTT Communication Science Laboratories, NTT Corporation; Kyoto University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16637/16637-13-20131-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05034-differentiable-inductive-logic-programming-for-structured-examples/",
        "doi": "10.1609/aaai.v35i6.16637",
        "pdf_size": 400730
    },
    {
        "id": "09675",
        "title": "Differential Spectral Normalization (DSN) for PDE Discovery",
        "track": "main",
        "status": "Poster",
        "abstract": "Partial differential equations (PDEs) play a prominent role in many disciplines for describing the governing systems of interest. Traditionally, PDEs are derived based on first principles. In the era of big data, the needs of uncovering PDEs from massive data-set are emerging and become essential. One of the latest advance in PDE discovery models is PDE-Net, which has shown promising predictive power with its moment-constrained convolutional filters, but may suffer from noisy data and numerical instability intrinsic in numerical differentiation. We propose a novel and robust regularization method tailored for moment-constrained convolutional filters, namely, Differential Spectral Normalization (DSN), to allow accurate estimation of coefficient functions and stable prediction of dynamics in a long time horizon. We investigated the effectiveness of DSN against batch normalization, dropout, spectral normalization, weight decay, weight normalization, jacobian regularization and orthonormal regularization and supported with empirical evidence that DSN owns the highest effectiveness by learning the convolutional filters in a robust manner. Numerical experiments further reveal that with DSN there is a substantial potential to uncover the hidden PDEs in a scarce data setting and predict the dynamical behavior for a long time horizon, even in a noisy environment where all data samples are contaminated with noise.",
        "primary_area": "Machine Learning IV",
        "author": "Chi Chiu So; Tsz On Li; Chufang Wu; Siu Pang Yung",
        "authorids": "",
        "aff": "The University of Hong Kong; The University of Hong Kong; The University of Hong Kong; The University of Hong Kong",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17164/17164-13-20658-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09675-differential-spectral-normalization-dsn-for-pde-discovery/",
        "doi": "10.1609/aaai.v35i11.17164",
        "pdf_size": 269468
    },
    {
        "id": "11555",
        "title": "Differentially Private Clustering via Maximum Coverage",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper studies the problem of clustering in metric spaces while preserving the privacy of individual data. Specifically, we examine differentially private variants of the k-medians and Euclidean k-means problems. We  present polynomial algorithms with constant multiplicative error and lower additive error than the previous state-of-the-art for each problem. Additionally, our algorithms use a clustering algorithm without differential privacy as a black-box. This allows  practitioners to control the trade-off between runtime and approximation factor by choosing a suitable clustering algorithm to use.",
        "primary_area": "Philosophy and Ethics of AI",
        "author": "Matthew Jones; Huy L. Nguyen; Thy D Nguyen",
        "authorids": "",
        "aff": "Northeastern University; Northeastern University; Northeastern University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17375/17375-13-20869-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11555-differentially-private-clustering-via-maximum-coverage/",
        "doi": "10.1609/aaai.v35i13.17375",
        "pdf_size": 158011
    },
    {
        "id": "06984",
        "title": "Differentially Private Decomposable Submodular Maximization",
        "track": "main",
        "status": "Poster",
        "abstract": "We study the problem of differentially private constrained maximization of decomposable submodular functions. A submodular function is decomposable if it takes the form of a sum of submodular functions. The special case of maximizing a monotone, decomposable submodular function under cardinality constraints is known as the Combinatorial Public Projects (CPP) problem (Papadimitriou, Schapira, and Singer 2008). Previous work by Gupta et al. (2010) gave a differentially private algorithm for the CPP problem.  We extend this work by designing differentially private algorithms for both monotone and non-monotone decomposable submodular maximization under general matroid constraints, with competitive utility guarantees. We complement our theoretical bounds with experiments demonstrating improved empirical performance.",
        "primary_area": "Machine Learning I",
        "author": "Anamay Chaturvedi; Huy L\u00ea Nguy\u1ec5n; Lydia Zakynthinou",
        "authorids": "",
        "aff": "Northeastern University; Northeastern University; Northeastern University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16860/16860-13-20354-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06984-differentially-private-decomposable-submodular-maximization/",
        "doi": "10.1609/aaai.v35i8.16860",
        "pdf_size": 212647
    },
    {
        "id": "00063",
        "title": "Differentially Private Link Prediction with Protected Connections",
        "track": "main",
        "status": "Poster",
        "abstract": "Link prediction (LP) algorithms propose to each node a ranked list of nodes that are currently non-neighbors, as the most likely candidates for future linkage. Owing to increasing concerns about privacy, users (nodes) may prefer to keep some of their connections protected or private. Motivated by this observation, our goal is to design a differentially private LP  algorithm, which trades off between privacy of the protected node-pairs and the link prediction accuracy. More specifically, we first propose a form of differential privacy on graphs, which models the privacy loss only of those node-pairs which are marked as protected. Next, we develop DPLP, a learning to rank algorithm, which applies a monotone transform to base scores from a non-private LP system, and then adds noise.  DPLP is trained with a privacy induced ranking loss, which optimizes the ranking utility for a given maximum allowed level of privacy leakage of the protected node-pairs. Under a recently introduced latent node embedding model, we present a formal trade-off between privacy and LP utility. Extensive experiments with several real-life graphs and several LP heuristics show that DPLP can trade off between privacy and predictive performance more effectively than several alternatives.",
        "primary_area": "Application Domains",
        "author": "Abir De; Soumen Chakrabarti",
        "authorids": "",
        "aff": "IIT Bombay; IIT Bombay",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16078/16078-13-19572-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00063-differentially-private-link-prediction-with-protected-connections/",
        "doi": "10.1609/aaai.v35i1.16078",
        "pdf_size": 975735
    },
    {
        "id": "07176",
        "title": "Differentially Private Stochastic Coordinate Descent",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper we tackle the challenge of making the stochastic coordinate descent algorithm differentially private.  Compared to the classical gradient descent algorithm where updates operate on a single model vector and controlled noise addition to this vector suffices to hide critical information about individuals, stochastic coordinate descent crucially relies on keeping auxiliary information in memory during training.  This auxiliary information provides an additional privacy leak and poses the major challenge addressed in this work.  Driven by the insight that under independent noise addition, the consistency of the auxiliary information holds in expectation, we present DP-SCD, the first differentially private stochastic coordinate descent algorithm. We analyze our new method theoretically and argue that decoupling and parallelizing coordinate updates is essential for its utility. On the empirical side we demonstrate competitive performance against the popular stochastic gradient descent alternative (DP-SGD) while requiring significantly less tuning.",
        "primary_area": "Machine Learning I",
        "author": "Georgios Damaskinos; Celestine Mendler-D\u00fcnner; Rachid Guerraoui; Nikolaos Papandreou; Thomas Parnell",
        "authorids": "",
        "aff": "\u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL); University of California, Berkeley; \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL); IBM Research Zurich; IBM Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16882/16882-13-20376-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07176-differentially-private-stochastic-coordinate-descent/",
        "doi": "10.1609/aaai.v35i8.16882",
        "pdf_size": 3646943
    },
    {
        "id": "07219",
        "title": "Differentially Private and Communication Efficient Collaborative Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Collaborative learning has received huge interests due to its capability of exploiting the collective computing power of the wireless edge devices. However, during the learning process, model updates using local private samples and large-scale parameter exchanges among agents impose severe privacy concerns and communication bottleneck. In this paper, to address these problems, we propose two differentially private (DP) and communication efficient algorithms, called Q-DPSGD-1 and Q-DPSGD-2. In Q-DPSGD-1, each agent first performs local model updates by a DP gradient descent method to provide the DP guarantee and then quantizes the local model before transmitting it to neighbors to improve communication efficiency. In Q-DPSGD-2, each agent injects discrete Gaussian noise to enforce DP guarantee after first quantizing the local model. Moreover, we track the privacy loss of both approaches under the Renyi DP and provide convergence analysis for both convex and non-convex loss functions.  The proposed methods are evaluated in extensive experiments on real-world datasets and the empirical results validate our theoretical findings.",
        "primary_area": "Machine Learning I",
        "author": "Jiahao Ding; Guannan Liang; Jinbo Bi; Miao Pan",
        "authorids": "",
        "aff": "University of Houston; University of Connecticut; University of Connecticut; University of Houston",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16887/16887-13-20381-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07219-differentially-private-and-communication-efficient-collaborative-learning/",
        "doi": "10.1609/aaai.v35i8.16887",
        "pdf_size": 330296
    },
    {
        "id": "09932",
        "title": "Differentially Private and Fair Deep Learning: A Lagrangian Dual Approach",
        "track": "main",
        "status": "Poster",
        "abstract": "A critical concern in data-driven decision making is to build models whose outcomes do not discriminate against some demographic groups, including gender, ethnicity, or age. To ensure non-discrimination in learning tasks, knowledge of the sensitive attributes is essential, while, in practice, these attributes may not be available due to legal and ethical requirements. To address this challenge, this paper studies a model that protects the privacy of the individuals\u2019 sensitive information while also allowing it to learn non-discriminatory predictors. The method relies on the notion of differential privacy and the use of Lagrangian duality to design neural networks that can accommodate fairness constraints while guaranteeing the privacy of sensitive attributes. The paper analyses the tension between accuracy, privacy, and fairness and the experimental evaluation illustrates the benefits of the proposed model on several prediction tasks.",
        "primary_area": "Machine Learning IV",
        "author": "Cuong Tran; Ferdinando Fioretto; Pascal Van Hentenryck",
        "authorids": "",
        "aff": "Syracuse University; Syracuse University; Georgia Institute of Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17193/17193-13-20687-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09932-differentially-private-and-fair-deep-learning-a-lagrangian-dual-approach/",
        "doi": "10.1609/aaai.v35i11.17193",
        "pdf_size": 2735442
    },
    {
        "id": "09101",
        "title": "Differentially Private k-Means via Exponential Mechanism and Max Cover",
        "track": "main",
        "status": "Poster",
        "abstract": "We introduce a new (\u03f5\u209a, \u03b4\u209a)-differentially private algorithm for the k-means clustering problem. Given a dataset in Euclidean space, the k-means clustering problem requires one to find k points in that space such that the sum of squares of Euclidean distances between each data point and its closest respective point among the k returned is minimised. Although there exist privacy-preserving methods with good theoretical guarantees to solve this problem, in practice it is seen that it is the additive error which dictates the practical performance of these methods. By reducing the problem to a sequence of instances of maximum coverage on a grid, we are able to derive a new method that achieves lower additive error than previous works. For input datasets with cardinality n and diameter \u0394, our algorithm has an O(\u0394\u00b2 (k log\u00b2 n  log(1/\u03b4\u209a)/\u03f5\u209a + k \u221a(d log(1/\u03b4\u209a))/\u03f5\u209a)) additive error whilst maintaining constant multiplicative error. We conclude with some experiments and find an improvement over previously implemented work for this problem.",
        "primary_area": "Machine Learning III",
        "author": "Huy L. Nguyen; Anamay Chaturvedi; Eric Z Xu",
        "authorids": "",
        "aff": "Northeastern University; Northeastern University; Northeastern University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17099/17099-13-20593-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09101-differentially-private-k-means-via-exponential-mechanism-and-max-cover/",
        "doi": "10.1609/aaai.v35i10.17099",
        "pdf_size": 187796
    },
    {
        "id": "07493",
        "title": "Diffusion Network Inference from Partial Observations",
        "track": "main",
        "status": "Poster",
        "abstract": "To infer the structure of a diffusion network from observed diffusion results, existing approaches customarily assume that observed data are complete and contain the final infection status of each node, as well as precise timestamps of node infections. Due to high cost and uncertainties in the monitoring of node infections, exact timestamps are often unavailable in practice, and even the final infection statuses of nodes are sometimes missing. In this work, we study how to carry out diffusion network inference without infection timestamps, using only partial observations of the final infection statuses of nodes. To this end, we iteratively infer the structure of the target diffusion network with observed data and imputed values for missing data, and learn the most likely infection transmission probabilities between nodes w.r.t. current inferred structure, which then help us update the imputation of missing data in turn. Extensive experimental results on both synthetic and real-world networks show that our approach can properly handle missing data and accurately uncover diffusion network structures.",
        "primary_area": "Machine Learning II",
        "author": "Ting Gan; Keqi Han; Hao Huang; Shi Ying; Yunjun Gao; Zongpeng Li",
        "authorids": "",
        "aff": "Wuhan University; Wuhuan University; Wuhan University; Wuhan University; Zhejiang University; Wuhan University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16918/16918-13-20412-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07493-diffusion-network-inference-from-partial-observations/",
        "doi": "10.1609/aaai.v35i9.16918",
        "pdf_size": 211323
    },
    {
        "id": "12719",
        "title": "DirectQE: Direct Pretraining for Machine Translation Quality Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Machine Translation Quality Estimation (QE) is a task of predicting the quality of machine translations without relying on any reference. Recently, the predictor-estimator framework trains the predictor as a feature extractor, which leverages the extra parallel corpora without QE labels, achieving promising QE performance. However, we argue that there are gaps between the predictor and the estimator in both data quality and training objectives, which preclude QE models from benefiting from a large number of parallel corpora more directly. We propose a novel framework called DirectQE that provides a direct pretraining for QE tasks. In DirectQE, a generator is trained to produce pseudo data that is closer to the real QE data, and a detector is pretrained on these data with novel objectives that are akin to the QE task. Experiments on widely used benchmarks show that DirectQE outperforms existing methods, without using any pretraining models such as BERT. We also give extensive analyses showing how fixing the two gaps contributes to our improvements.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Qu Cui; Shujian Huang; Jiahuan Li; Xiang Geng; Zaixiang Zheng; Guoping Huang; Jiajun Chen",
        "authorids": "",
        "aff": "National Key Laboratory for Novel Software Technology, Nanjing University; National Key Laboratory for Novel Software Technology, Nanjing University; National Key Laboratory for Novel Software Technology, Nanjing University; National Key Laboratory for Novel Software Technology, Nanjing University; National Key Laboratory for Novel Software Technology, Nanjing University; Tencent AI Lab; National Key Laboratory for Novel Software Technology, Nanjing University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17506/17506-13-21000-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12719-directqe-direct-pretraining-for-machine-translation-quality-estimation/",
        "doi": "10.1609/aaai.v35i14.17506",
        "pdf_size": 1652897
    },
    {
        "id": "08975",
        "title": "Discovering Fully Oriented Causal Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "We study the problem of inferring causal graphs from observational data. We are particularly interested in discovering graphs where all edges are oriented, as opposed to the partially directed graph that the state of the art discover. To this end, we base our approach on the algorithmic Markov condition. Unlike the statistical Markov condition, it uniquely identifies the true causal network as the one that provides the simplest\u2014 as measured in Kolmogorov complexity\u2014factorization of the joint distribution. Although Kolmogorov complexity is not computable, we can approximate it from above via the Minimum Description Length principle, which allows us to define a consistent and computable score based on non-parametric multivariate regression. To efficiently discover causal networks in practice, we introduce the GLOBE algorithm, which greedily adds, removes, and orients edges such that it minimizes the overall cost. Through an extensive set of experiments, we show GLOBE performs very well in practice, beating the state of the art by a margin.",
        "primary_area": "Machine Learning III",
        "author": "Osman A Mian; Alexander Marx; Jilles Vreeken",
        "authorids": "",
        "aff": "CISPA Helmholtz Center for Information Security; CISPA Helmholtz Center for Information Security; CISPA Helmholtz Center for Information Security",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17085/17085-13-20579-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08975-discovering-fully-oriented-causal-networks/",
        "doi": "10.1609/aaai.v35i10.17085",
        "pdf_size": 194896
    },
    {
        "id": "14365",
        "title": "Discovering New Intents with Deep Aligned Clustering",
        "track": "main",
        "status": "Poster",
        "abstract": "Discovering new intents is a crucial task in dialogue systems. Most existing methods are limited in transferring the prior knowledge from known intents to new intents. These methods also have difficulties in providing high-quality supervised signals to learn clustering-friendly features for grouping unlabeled intents. In this work, we propose an effective method (Deep Aligned Clustering) to discover new intents with the aid of limited known intent data. Firstly, we leverage a few labeled known intent samples as prior knowledge to pre-train the model. Then, we perform k-means to produce cluster assignments as pseudo-labels. Moreover, we propose an alignment strategy to tackle the label inconsistency problem during clustering assignments. Finally, we learn the intent representations under the supervision of the aligned pseudo-labels. With an unknown number of new intents, we predict the number of intent categories by eliminating low-confidence intent-wise clusters. Extensive experiments on two benchmark datasets show that our method is more robust and achieves substantial improvements over the state-of-the-art methods.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Hanlei Zhang; Hua Xu; Ting-En Lin; Rui Lyu",
        "authorids": "",
        "aff": "State Key Laboratory of Intelligent Technology and Systems, Department of Computer Science and Technology, Tsinghua University Beijing National Research Center for Information Science and Technology (BNRist); State Key Laboratory of Intelligent Technology and Systems, Department of Computer Science and Technology, Tsinghua University Beijing National Research Center for Information Science and Technology (BNRist); State Key Laboratory of Intelligent Technology and Systems, Department of Computer Science and Technology, Tsinghua University Beijing National Research Center for Information Science and Technology (BNRist); State Key Laboratory of Intelligent Technology and Systems, Department of Computer Science and Technology, Tsinghua University Beijing University of Posts and Telecommunications University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17689/17689-13-21183-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14365-discovering-new-intents-with-deep-aligned-clustering/",
        "doi": "10.1609/aaai.v35i16.17689",
        "pdf_size": 1721613
    },
    {
        "id": "01754",
        "title": "Discriminative Region Suppression for Weakly-Supervised Semantic Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "Weakly-supervised semantic segmentation (WSSS) using image-level labels has recently attracted much attention for reducing annotation costs. Existing WSSS methods utilize localization maps from the classification network to generate pseudo segmentation labels. However, since localization maps obtained from the classifier focus only on sparse discriminative object regions, it is difficult to generate high-quality segmentation labels. To address this issue, we introduce discriminative region suppression (DRS) module that is a simple yet effective method to expand object activation regions. DRS suppresses the attention on discriminative regions and spreads it to adjacent non-discriminative regions, generating dense localization maps. DRS requires few or no additional parameters and can be plugged into any network. Furthermore, we introduce an additional learning strategy to give a self-enhancement of localization maps, named localization map refinement learning. Benefiting from this refinement learning, localization maps are refined and enhanced by recovering some missing parts or removing noise itself. Due to its simplicity and effectiveness, our approach achieves mIoU 71.4% on the PASCAL VOC 2012 segmentation benchmark using only image-level labels. Extensive experiments demonstrate the effectiveness of our approach.",
        "primary_area": "Computer Vision I",
        "author": "Beomyoung Kim; Sangeun Han; Junmo Kim",
        "authorids": "",
        "aff": "KAIST (Korea Advanced Institute of Science and Technology); KAIST (Korea Advanced Institute of Science and Technology); KAIST (Korea Advanced Institute of Science and Technology)",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16269/16269-13-19763-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01754-discriminative-region-suppression-for-weakly-supervised-semantic-segmentation/",
        "doi": "10.1609/aaai.v35i2.16269",
        "pdf_size": 5955368
    },
    {
        "id": "09285",
        "title": "Disentangled Information Bottleneck",
        "track": "main",
        "status": "Poster",
        "abstract": "The information bottleneck (IB) method is a technique for extracting information that is relevant for predicting the target random variable from the source random variable, which is typically implemented by optimizing the IB Lagrangian that balances the compression and prediction terms. However, the IB Lagrangian is hard to optimize, and multiple trials for tuning values of Lagrangian multiplier are required. Moreover, we show that the prediction performance strictly decreases as the compression gets stronger during optimizing the IB Lagrangian. In this paper, we implement the IB method from the perspective of supervised disentangling. Specifically, we introduce Disentangled Information Bottleneck (DisenIB) that is consistent on compressing source maximally without target prediction performance loss (maximum compression). Theoretical and experimental results demonstrate that our method is consistent on maximum compression, and performs well in terms of generalization, robustness to adversarial attack, out-of-distribution detection, and supervised disentangling.",
        "primary_area": "Machine Learning III",
        "author": "Ziqi Pan; Li Niu; Jianfu Zhang; Liqing Zhang",
        "authorids": "",
        "aff": "Shanghai Jiao Tong University; Shanghai Jiao Tong University; RIKEN AIP;Shanghai Jiao Tong University; Shanghai Jiao Tong University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17120/17120-13-20614-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09285-disentangled-information-bottleneck/",
        "doi": "10.1609/aaai.v35i10.17120",
        "pdf_size": 1010408
    },
    {
        "id": "13587",
        "title": "Disentangled Motif-aware Graph Learning for Phrase Grounding",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a novel graph learning framework for phrase grounding in the image. Developing from the sequential to the dense graph model, existing works capture coarse-grained context but fail to distinguish the diversity of context among phrases and image regions. In contrast, we pay special attention to different motifs implied in the context of the scene graph and devise the disentangled graph network to integrate the motif-aware contextual information into representations. Besides, we adopt interventional strategies at the feature and the structure levels to consolidate and generalize representations. Finally, the cross-modal attention network is utilized to fuse intra-modal features, where each phrase can be computed similarity with regions to select the best-grounded one. We validate the efficiency of disentangled and interventional graph network (DIGN) through a series of ablation studies, and our model achieves state-of-the-art performance on Flickr30K Entities and ReferIt Game benchmarks.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Zongshen Mu; Siliang Tang; Jie Tan; Qiang Yu; Yueting Zhuang",
        "authorids": "",
        "aff": "Zhejiang University; Zhejiang University; Zhejiang University; City Cloud Technology (China); Zhejiang University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17602/17602-13-21096-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13587-disentangled-motif-aware-graph-learning-for-phrase-grounding/",
        "doi": "10.1609/aaai.v35i15.17602",
        "pdf_size": 1045987
    },
    {
        "id": "00911",
        "title": "Disentangled Multi-Relational Graph Convolutional Network for Pedestrian Trajectory Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "Pedestrian trajectory prediction is one of the important tasks required for autonomous navigation and social robots in human environments. Previous studies focused on estimating social forces among individual pedestrians. However, they did not consider the social forces of groups on pedestrians, which results in over-collision avoidance problems. To address this problem, we present a Disentangled Multi-Relational Graph Convolutional Network (DMRGCN) for socially entangled pedestrian trajectory prediction. We first introduce a novel disentangled multi-scale aggregation to better represent social interactions, among pedestrians on a weighted graph. For the aggregation, we construct the multi-relational weighted graphs based on distances and relative displacements among pedestrians. In the prediction step, we propose a global temporal aggregation to alleviate accumulated errors for pedestrians changing their directions. Finally, we apply DropEdge into our DMRGCN to avoid the over-fitting issue on relatively small pedestrian trajectory datasets. Through the effective incorporation of the three parts within an end-to-end framework, DMRGCN achieves state-of-the-art performances on a variety of challenging trajectory prediction benchmarks.",
        "primary_area": "Computer Vision I",
        "author": "Inhwan Bae; Hae-Gon Jeon",
        "authorids": "",
        "aff": "Gwangju Institute of Science and Technology; Gwangju Institute of Science and Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16174/16174-13-19668-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00911-disentangled-multi-relational-graph-convolutional-network-for-pedestrian-trajectory-prediction/",
        "doi": "10.1609/aaai.v35i2.16174",
        "pdf_size": 6417504
    },
    {
        "id": "07754",
        "title": "Disentangled Representation Learning in Heterogeneous Information Network for Large-scale Android Malware Detection in the COVID-19 Era and Beyond",
        "track": "main",
        "status": "Poster",
        "abstract": "In the fight against the COVID-19 pandemic, many social activities have moved online; society's overwhelming reliance on the complex cyberspace makes its security more important than ever. In this paper, we propose and develop an intelligent system named Dr.HIN to protect users against the evolving Android malware attacks in the COVID-19 era and beyond. In Dr.HIN, besides app content, we propose to consider higher-level semantics and social relations among apps, developers and mobile devices to comprehensively depict Android apps; and then we introduce a structured heterogeneous information network (HIN) to model the complex relations and exploit meta-path guided strategy to learn node (i.e., app) representations from HIN. As the representations of malware could be highly entangled with benign apps in the complex ecosystem of development, it poses a new challenge of learning the latent explanatory factors hidden in the HIN embeddings to detect the evolving malware. To address this challenge, we propose to integrate domain priors generated from different views (i.e., app content, app authorship, app installation) to devise an adversarial disentangler to separate the distinct, informative factors of variations hidden in the HIN embeddings for large-scale Android malware detection. This is the first attempt of disentangled representation learning in HIN data. Promising experimental results based on the large-scale and real sample collections from security industry demonstrate the performance of Dr.HIN in evolving Android malware detection, by comparison with baselines and popular mobile security products.",
        "primary_area": "Machine Learning II",
        "author": "Shifu Hou; Yujie Fan; Mingxuan Ju; Yanfang Ye; Wenqiang Wan; Kui Wang; Yinming Mei; Qi Xiong; Fudong Shao",
        "authorids": "",
        "aff": "Case Western Reserve University; Case Western Reserve University; Case Western Reserve University; Case Western Reserve University; Tencent Security Lab; Tencent Security Lab; Tencent Security Lab; Tencent Security Lab; Tencent Security Lab",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16947/16947-13-20441-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07754-disentangled-representation-learning-in-heterogeneous-information-network-for-large-scale-android-malware-detection-in-the-covid-19-era-and-beyond/",
        "doi": "10.1609/aaai.v35i9.16947",
        "pdf_size": 7615524
    },
    {
        "id": "03724",
        "title": "Disjunctive Temporal Problems under Structural Restrictions",
        "track": "main",
        "status": "Poster",
        "abstract": "The disjunctive temporal problem (DTP) is an expressive temporal formalism that extends Dechter et al.'s simple temporal problem.  The DTP is well studied in the literature and has many important applications. It is known that deciding satisfiability of DTPs is NP-hard and that, in many cases, single-exponential algorithms (running in O(c^n) time) do not exist under the Exponential-Time Hypothesis. The computational hardness makes it worthwhile to identify restricted problems that are efficiently solvable.  One way of doing this is to restrict the interactions of variables and constraints. We show that instances of DTP of any arity with integers bounded by poly(n) can be solved in n^{f(w)} time, where n denotes the problem size, w is the treewidth of the incidence graph and f is a computable function; in other words, this problem is in the complexity class XP  and it can be solved in polynomial time whenever w is fixed. We complement this result by showing that binary DTPs that only involve the integers 0 and 1 are not fixed-parameter tractable with respect to treewidth,  i.e. they do not admit a f(w)poly(n)$ time algorithm for any computable function f, under standard complexity assumptions. For instances with unbounded integers,  we show that even binary DTPs parameterized by treewidth  cannot be in XP, unless P = NP.",
        "primary_area": "Constraint Satisfaction and Optimization",
        "author": "Konrad K Dabrowski; Peter Jonsson; Sebastian Ordyniak; George Osipov",
        "authorids": "",
        "aff": "Durham University; Link\u00f6ping University; University of Leeds; Link\u00f6ping University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16489/16489-13-19983-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03724-disjunctive-temporal-problems-under-structural-restrictions/",
        "doi": "10.1609/aaai.v35i5.16489",
        "pdf_size": 173167
    },
    {
        "id": "04172",
        "title": "Disposable Linear Bandits for Online Recommendations",
        "track": "main",
        "status": "Poster",
        "abstract": "We study the classic stochastic linear bandit problem under the restriction that each arm may be selected for limited number of times. This simple constraint, which we call disposability, captures a common restriction that occurs in recommendation problems from a diverse array of applications ranging from personalized styling services to dating platforms. We show that the regret for this problem is characterized by a previously-unstudied function of the reward distribution among optimal arms. Algorithmically, our upper bound relies on an optimism-based policy which, while computationally intractable, lends itself to approximation via a fast alternating heuristic initialized with a classic similarity score. Experiments show that our policy dominates a set of benchmarks which includes algorithms known to be optimal for the linear bandit without disposability, along with natural modifications to these algorithms for the disposable setting.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Melda Korkut; Andrew Li",
        "authorids": "",
        "aff": "Carnegie Mellon University; Carnegie Mellon University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16540/16540-13-20034-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04172-disposable-linear-bandits-for-online-recommendations/",
        "doi": "10.1609/aaai.v35i5.16540",
        "pdf_size": 299490
    },
    {
        "id": "10422",
        "title": "Distant Transfer Learning via Deep Random Walk",
        "track": "main",
        "status": "Poster",
        "abstract": "Transfer learning, which is to improve the learning performance in the target domain by leveraging useful knowledge from the source domain, often requires that those two domains are very close, which limits its application scope. Recently, distant transfer learning has been studied to transfer knowledge between two distant or even totally unrelated domains via unlabeled auxiliary domains that act as a bridge in the spirit of human transitive inference that two completely unrelated concepts can be connected through gradual knowledge transfer. In this paper, we study distant transfer learning by proposing a DeEp Random Walk basEd distaNt Transfer (DERWENT) method. Different from existing distant transfer learning models that  implicitly identify the path of knowledge transfer between the source and target instances through auxiliary instances, the proposed DERWENT model can explicitly learn such paths via the deep random walk technique. Specifically, based on sequences identified by the random walk technique on a data graph where source and target data have no direct connection, the proposed DERWENT model enforces adjacent data points in a sequence to be similar, makes the ending data point be represented by other data points in the same sequence, and considers weighted classification losses of source data. Empirical studies on several benchmark datasets demonstrate that the proposed DERWENT algorithm yields the state-of-the-art performance.",
        "primary_area": "Machine Learning V",
        "author": "Qiao Xiao; Yu Zhang",
        "authorids": "",
        "aff": "Department of Computer Science and Engineering, Southern University of Science and Technology; Department of Computer Science and Engineering, Southern University of Science and Technology Peng Cheng Laboratory",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17248/17248-13-20742-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10422-distant-transfer-learning-via-deep-random-walk/",
        "doi": "10.1609/aaai.v35i12.17248",
        "pdf_size": 2286476
    },
    {
        "id": "10990",
        "title": "Distilling Localization for Self-Supervised Representation Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent  progress  in  contrastive  learning  has  revolutionized unsupervised  representation  learning.  Concretely,  multiple views (augmentations) from the same image are encouraged to map to close embeddings, while views from different images are pulled apart.In this paper, through visualizing and diagnosing classification errors, we observe that current contrastive models are ineffective at localizing the foreground object, limiting their ability to extract discriminative high-level features. This is due to the fact that view generation process considers pixels in an image uniformly.To address this problem, we propose a data-driven approach for learning invariance to backgrounds. It first estimates foreground  saliency  in  images  and  then  creates  augmentations by copy-and-pasting the foreground onto a variety of back-grounds. The learning still follows an instance discrimination approach,  so  that  the  representation  is  trained  to  disregard background content and focus on the foreground. We study a variety of saliency estimation methods, and find that most methods lead to improvements for contrastive learning. With this  approach,  significant  performance  is  achieved  for  self-supervised learning on ImageNet classification, and also for object detection on PASCAL VOC and MSCOCO.",
        "primary_area": "Machine Learning V",
        "author": "Nanxuan Zhao; Zhirong Wu; Rynson W.H. Lau; Stephen Lin",
        "authorids": "",
        "aff": "City University of Hong Kong; Microsoft Research; City University of Hong Kong; Microsoft Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17312/17312-13-20806-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10990-distilling-localization-for-self-supervised-representation-learning/",
        "doi": "10.1609/aaai.v35i12.17312",
        "pdf_size": 3745077
    },
    {
        "id": "07037",
        "title": "Distributed Ranking with Communications: Approximation Analysis and Applications",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning theory of distributed algorithms has recently attracted enormous attention in the machine learning community. However, most of existing works focus on learning problem with pointwise loss and does not consider the communication among local processors. In this paper, we propose a new distributed pairwise ranking  with communication (called DLSRank-C) based on the Newton-Raphson iteration, and establish its learning rate analysis in probability. Theoretical and empirical assessments demonstrate the effectiveness of DLSRank-C under mild conditions.",
        "primary_area": "Machine Learning I",
        "author": "Hong Chen; Yingjie Wang; Yulong Wang; Feng Zheng",
        "authorids": "",
        "aff": "Huazhong Agricultural University, China; Huazhong Agricultural University, China; Huazhong Agricultural University, China; Southern University of Science and Technology, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16866/16866-13-20360-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07037-distributed-ranking-with-communications-approximation-analysis-and-applications/",
        "doi": "10.1609/aaai.v35i8.16866",
        "pdf_size": 209494
    },
    {
        "id": "03483",
        "title": "Distribution Adaptive INT8 Quantization for Training CNNs",
        "track": "main",
        "status": "Poster",
        "abstract": "Researches have demonstrated that low bit-width (e.g., INT8) quantization can be employed to accelerate the inference process. It makes the gradient quantization very promising since the backward propagation requires approximately twice more computation than forward one. Due to the variability and uncertainty of gradient distribution, a lot of methods have been proposed to attain training stability. However, most of them ignore the channel-wise gradient distributions and the impact of gradients with different magnitudes, resulting in the degradation of final accuracy. In this paper, we propose a novel INT8 quantization training framework for convolutional neural network to address the above issues. Specifically, we adopt Gradient Vectorized Quantization to quantize the gradient, based on the observation that layer-wise gradients contain multiple distributions along the channel dimension. Then, Magnitude-aware Clipping Strategy is introduced by taking the magnitudes of gradients into consideration when minimizing the quantization error, and we present a theoretical derivation to solve the quantization parameters of different distributions. Experimental results on broad range of computer vision tasks, such as image classification, object detection and video classification, demonstrate that the proposed Distribution Adaptive INT8 Quantization training method has achieved almost lossless training accuracy for different backbones, including ResNet, MobileNetV2, InceptionV3, VGG and AlexNet, which is superior to the state-of-the-art techniques. Moreover, we further implement the INT8 kernel that can accelerate the training iteration more than 200% under the latest Turing architecture, i.e., our method excels on both training accuracy and speed.",
        "primary_area": "Computer Vision III",
        "author": "Kang Zhao; Sida Huang; Pan Pan; Yinghan Li; Yingya Zhang; Zhenyu Gu; Yinghui Xu",
        "authorids": "",
        "aff": "Alibaba; Alibaba; Alibaba; Alibaba; Alibaba; Alibaba; Alibaba",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16462/16462-13-19956-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03483-distribution-adaptive-int8-quantization-for-training-cnns/",
        "doi": "10.1609/aaai.v35i4.16462",
        "pdf_size": 2016427
    },
    {
        "id": "13090",
        "title": "Distribution Matching for Rationalization",
        "track": "main",
        "status": "Poster",
        "abstract": "The task of rationalization aims to extract pieces of input text as rationales to justify neural network predictions on text classification tasks. By definition, rationales represent key text pieces used for prediction and thus should have similar classification feature distribution compared to the original input text. However, previous methods mainly focused on maximizing the mutual information between rationales and labels while neglecting the relationship between rationales and input text. To address this issue, we propose a novel rationalization method that matches the distributions of rationales and input text in both the feature space and output space. Empirically, the proposed distribution matching approach consistently outperforms previous methods by a large margin. Our data and code are available.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Yongfeng Huang; Yujun Chen; Yulun Du; Zhilin Yang",
        "authorids": "",
        "aff": "Tsinghua University, Beijing; Recurrent AI; Recurrent AI; Recurrent AI",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17547/17547-13-21041-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13090-distribution-matching-for-rationalization/",
        "doi": "10.1609/aaai.v35i14.17547",
        "pdf_size": 204657
    },
    {
        "id": "09144",
        "title": "Distributional Reinforcement Learning via Moment Matching",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider the problem of learning a set of probability distributions from the empirical Bellman dynamics in distributional reinforcement learning (RL), a class of state-of-the-art methods that estimate the distribution, as opposed to only the expectation, of the total return. We formulate a method that learns a finite set of statistics from each return distribution via neural networks, as in the distributional RL literature. Existing distributional RL methods however constrain the learned statistics to predefined functional forms of the return distribution which is both restrictive in representation and difficult in maintaining the predefined statistics. Instead, we learn unrestricted statistics, i.e., deterministic (pseudo-)samples, of the return distribution by leveraging a technique from hypothesis testing known as maximum mean discrepancy (MMD), which leads to a simpler objective amenable to backpropagation.  Our method can be interpreted as implicitly matching all orders of moments between a return distribution and its Bellman target. We establish sufficient conditions for the contraction of the distributional Bellman operator and provide finite-sample analysis for the deterministic samples in distribution approximation. Experiments on the suite of Atari games show that our method outperforms the standard distributional RL baselines and sets a new record in the Atari games for non-distributed agents.",
        "primary_area": "Machine Learning III",
        "author": "Thanh Nguyen-Tang; Sunil Gupta; Svetha Venkatesh",
        "authorids": "",
        "aff": "Deakin University; Deakin University; Deakin University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17104/17104-13-20598-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09144-distributional-reinforcement-learning-via-moment-matching/",
        "doi": "10.1609/aaai.v35i10.17104",
        "pdf_size": 1548635
    },
    {
        "id": "05464",
        "title": "District-Fair Participatory Budgeting",
        "track": "main",
        "status": "Poster",
        "abstract": "Participatory budgeting is a method used by city governments to select public projects to fund based on residents' votes. Many cities use participatory budgeting at a district level. Typically, a budget is divided among districts proportionally to their population, and each district holds an election over local projects and then uses its budget to fund the projects most preferred by its voters. However, district-level participatory budgeting can yield poor social welfare because it does not necessarily fund projects supported across multiple districts. On the other hand, decision making that only takes global social welfare into account can be unfair to districts: A social-welfare-maximizing solution might not fund any of the projects preferred by a district, despite the fact that its constituents pay taxes to the city. Thus, we study how to fairly maximize social welfare in a participatory budgeting setting with a single city-wide election. We propose a notion of fairness that guarantees each district at least as much welfare as it would have received in a district-level election. We show that, although optimizing social welfare subject to this notion of fairness is NP-hard, we can efficiently construct a lottery over welfare-optimal outcomes that is fair in expectation. Moreover, we show that, when we are allowed to slightly relax fairness, we can efficiently compute a fair solution that is welfare-maximizing, but which may overspend the budget.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "D Ellis Hershkowitz; Anson Kahng; Dominik Peters; Ariel D. Procaccia",
        "authorids": "",
        "aff": "Carnegie Mellon University; Carnegie Mellon University; Harvard University; Harvard University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16688/16688-13-20182-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05464-district-fair-participatory-budgeting/",
        "doi": "10.1609/aaai.v35i6.16688",
        "pdf_size": 153709
    },
    {
        "id": "03412",
        "title": "Diverse Knowledge Distillation for End-to-End Person Search",
        "track": "main",
        "status": "Poster",
        "abstract": "Person search aims to localize and identify a specific person from a gallery of images. Recent methods can be categorized into two groups, i.e., two-step and end-to-end approaches. The former views person search as two independent tasks and achieves dominant results using separately trained person detection and re-identification (Re-ID) models. The latter performs person search in an end-to-end fashion. Although the end-to-end approaches yield higher inference efficiency, they largely lag behind those two-step counterparts in terms of accuracy. In this paper, we argue that the gap between the two kinds of methods is mainly caused by the Re-ID sub-networks of end-to-end methods. To this end, we propose a simple yet strong end-to-end network with diverse knowledge distillation to break the bottleneck. We also design a spatial-invariant augmentation to assist model to be invariant to inaccurate detection results. Experimental results on the CUHK-SYSU and PRW datasets demonstrate the superiority of our method against existing approaches -- it achieves on par accuracy with state-of-the-art two-step methods while maintaining high efficiency due to the single joint model. Code is available at: https://git.io/DKD-PersonSearch.",
        "primary_area": "Computer Vision III",
        "author": "Xinyu Zhang; Xinlong Wang; Jia-Wang Bian; Chunhua Shen; Mingyu You",
        "authorids": "",
        "aff": "Tongji University, China The University of Adelaide, Australia; The University of Adelaide, Australia; The University of Adelaide, Australia; The University of Adelaide, Australia Monash University, Australia; Tongji University, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16454/16454-13-19948-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03412-diverse-knowledge-distillation-for-end-to-end-person-search/",
        "doi": "10.1609/aaai.v35i4.16454",
        "pdf_size": 2112203
    },
    {
        "id": "05159",
        "title": "Dividing a Graphical Cake",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider the classical cake-cutting problem where we wish to fairly divide a heterogeneous resource, often modeled as a cake, among interested agents. Work on the subject typically assumes that the cake is represented by an interval. In this paper, we introduce a generalized setting where the cake can be in the form of the set of edges of an undirected graph, allowing us to model the division of road networks. Unlike in the canonical setting, common fairness criteria such as proportionality cannot always be satisfied in our setting if each agent must receive a connected subgraph. We determine the optimal approximation of proportionality that can be obtained for any number of agents with arbitrary valuations, and exhibit a tight guarantee for each graph in the case of two agents. In addition, when more than one connected piece per agent is allowed, we establish the best egalitarian welfare guarantee for each total number of connected pieces. We also study a number of variants and extensions, including when approximate equitability is considered, or when the item to be divided is undesirable (also known as chore division).",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Xiaohui Bei; Warut Suksompong",
        "authorids": "",
        "aff": "Nanyang Technological University; National University of Singapore",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16652/16652-13-20146-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05159-dividing-a-graphical-cake/",
        "doi": "10.1609/aaai.v35i6.16652",
        "pdf_size": 136408
    },
    {
        "id": "14041",
        "title": "Do Response Selection Models Really Know What\u2019s Next? Utterance Manipulation Strategies for Multi-turn Response Selection",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we study the task of selecting the optimal response given a user and system utterance history in retrieval-based multi-turn dialog systems. Recently, pre-trained language models (e.g., BERT, RoBERTa, and ELECTRA) showed significant improvements in various natural language processing tasks. This and similar response selection tasks can also be solved using such language models by formulating the tasks as dialog--response binary classification tasks. Although existing works using this approach successfully obtained state-of-the-art results, we observe that language models trained in this manner tend to make predictions based on the relatedness of history and candidates, ignoring the sequential nature of multi-turn dialog systems. This suggests that the response selection task alone is insufficient for learning temporal dependencies between utterances. To this end, we propose utterance manipulation strategies (UMS) to address this problem. Specifically, UMS consist of several strategies (i.e., insertion, deletion, and search), which aid the response selection model towards maintaining dialog coherence. Further, UMS are self-supervised methods that do not require additional annotation and thus can be easily incorporated into existing approaches. Extensive evaluation across multiple languages and models shows that UMS are highly effective in teaching dialog consistency, which leads to models pushing the state-of-the-art with significant margins on multiple public benchmark datasets.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Taesun Whang; Dongyub Lee; Dongsuk Oh; Chanhee Lee; Kijong Han; Dong-hun Lee; Saebyeok Lee",
        "authorids": "",
        "aff": "Wisenut Inc.; Kakao Corp.; Korea University; Korea University; Kakao Enterprise Corp.; Kakao Enterprise Corp.; Wisenut Inc. Korea University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17653/17653-13-21147-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14041-do-response-selection-models-really-know-whats-next-utterance-manipulation-strategies-for-multi-turn-response-selection/",
        "doi": "10.1609/aaai.v35i16.17653",
        "pdf_size": 2462260
    },
    {
        "id": "04328",
        "title": "DocParser: Hierarchical Document Structure Parsing from Renderings",
        "track": "main",
        "status": "Poster",
        "abstract": "Translating renderings (e. g. PDFs, scans) into hierarchical document structures is extensively demanded in the daily routines of many real-world applications. However, a holistic, principled approach to inferring the complete hierarchical structure in documents is missing. As a remedy, we developed \u201cDocParser\u201d: an end-to-end system for parsing complete document structure \u2013 including all text elements, nested figures, tables, and table cell structures. Our second contribution is to provide a dataset for evaluating hierarchical document structure parsing. Our third contribution is to propose a scalable learning framework for settings where domain-specific data are scarce, which we address by a novel approach to weak supervision that significantly improves the document structure parsing performance. Our experiments confirm the effectiveness of our proposed weak supervision: Compared to the baseline without weak supervision, it improves the mean average precision for detecting document entities by 39.1% and improves the F1 score of classifying hierarchical relations by 35.8%.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Johannes Rausch; Octavio Martinez; Fabian Bissig; Ce Zhang; Stefan Feuerriegel",
        "authorids": "",
        "aff": "Department of Computer Science, ETH Zurich; Department of Computer Science, ETH Zurich; Department of Computer Science, ETH Zurich; Department of Computer Science, ETH Zurich; Department of Management, Technology, and Economics, ETH Zurich",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16558/16558-13-20052-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04328-docparser-hierarchical-document-structure-parsing-from-renderings/",
        "doi": "10.1609/aaai.v35i5.16558",
        "pdf_size": 1828393
    },
    {
        "id": "14612",
        "title": "Document-Level Relation Extraction with Adaptive Thresholding and Localized Context Pooling",
        "track": "main",
        "status": "Poster",
        "abstract": "Document-level relation extraction (RE) poses new challenges compared to its sentence-level counterpart. One document commonly contains multiple entity pairs, and one entity pair occurs multiple times in the document associated with multiple possible relations. In this paper, we propose two novel techniques, adaptive thresholding and localized context pooling, to solve the multi-label and multi-entity problems. The adaptive thresholding replaces the global threshold for multi-label classification in the prior work with a learnable entities-dependent threshold. The localized context pooling directly transfers attention from pre-trained language models to locate relevant context that is useful to decide the relation. We experiment on three document-level RE benchmark datasets: DocRED, a recently released large-scale RE dataset, and two datasets CDRand GDA in the biomedical domain. Our ATLOP (Adaptive Thresholding and Localized cOntext Pooling) model achieves an F1 score of 63.4, and also significantly outperforms existing models on both CDR and GDA. We have released our code at https://github.com/wzhouad/ATLOP.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Wenxuan Zhou; Kevin Huang; Tengyu Ma; Jing Huang",
        "authorids": "",
        "aff": "University of Southern California; JD AI Research; Stanford; JD AI Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17717/17717-13-21211-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14612-document-level-relation-extraction-with-adaptive-thresholding-and-localized-context-pooling/",
        "doi": "10.1609/aaai.v35i16.17717",
        "pdf_size": 1050123
    },
    {
        "id": "14167",
        "title": "Document-Level Relation Extraction with Reconstruction",
        "track": "main",
        "status": "Poster",
        "abstract": "In document-level relation extraction (DocRE), graph structure is generally used to encode relation information in the input document to classify the relation category between each entity pair, and has greatly advanced the DocRE task over the past several years. However, the learned graph representation universally models relation information between all entity pairs regardless of whether there are relationships between these entity pairs. Thus, those entity pairs without relationships disperse the attention of the encoder-classifier DocRE for ones with relationships, which may further hind the improvement of DocRE. To alleviate this issue, we propose a novel encoder-classifier-reconstructor model for DocRE. The reconstructor manages to reconstruct the ground-truth path dependencies from the graph representation, to ensure that the proposed DocRE model pays more attention to encode entity pairs with relationships in the training. Furthermore, the reconstructor is regarded as a relationship indicator to assist relation classification in the inference, which can further improve the performance of DocRE model. Experimental results on a large-scale DocRE dataset show that the proposed model can significantly improve the accuracy of relation extraction on a strong heterogeneous graph-based baseline. The code is publicly available at https://github.com/xwjim/DocRE-Rec.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Wang Xu; Kehai Chen; Tiejun Zhao",
        "authorids": "",
        "aff": "Harbin Institute of Technology, Harbin, China; National Institute of Information and Communications Technology, Kyoto, Japan; Harbin Institute of Technology, Harbin, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17667/17667-13-21161-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14167-document-level-relation-extraction-with-reconstruction/",
        "doi": "10.1609/aaai.v35i16.17667",
        "pdf_size": 264689
    },
    {
        "id": "06618",
        "title": "Does Explainable Artificial Intelligence Improve Human Decision-Making?",
        "track": "main",
        "status": "Poster",
        "abstract": "Explainable AI provides insights to users into the why for model predictions, offering potential for users to better understand and trust a model, and to recognize and correct AI predictions that are incorrect. Prior research on human and explainable AI interactions has focused on measures such as interpretability, trust, and usability of the explanation. There are mixed findings whether explainable AI can improve actual human decision-making and the ability to identify the problems with the underlying model. Using real datasets, we compare objective human decision accuracy without AI (control), with an AI prediction (no explanation), and AI prediction with explanation. We find providing any kind of AI prediction tends to improve user decision accuracy, but no conclusive evidence that explainable AI has a meaningful impact. Moreover, we observed the strongest predictor for human decision accuracy was AI accuracy and that users were somewhat able to detect when the AI was correct vs. incorrect, but this was not significantly affected by including an explanation. Our results indicate that, at least in some situations, the why information provided in explainable AI may not enhance user decision-making, and further research may be needed to understand how to integrate explainable AI into real systems.",
        "primary_area": "Machine Learning I",
        "author": "Yasmeen Alufaisan; Laura R. Marusich; Jonathan Z. Bakdash; Yan Zhou; Murat Kantarcioglu",
        "authorids": "",
        "aff": "Saudi Aramco; U.S. Army Research Laboratory; U.S. Army Research Laboratory; University of Texas at Dallas; University of Texas at Dallas",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16819/16819-13-20313-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06618-does-explainable-artificial-intelligence-improve-human-decision-making/",
        "doi": "10.1609/aaai.v35i8.16819",
        "pdf_size": 361784
    },
    {
        "id": "14103",
        "title": "Does Head Label Help for Long-Tailed Multi-Label Text Classification",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-label text classification (MLTC) aims to annotate documents with the most relevant labels from a number of candidate labels. In real applications, the distribution of label frequency often exhibits a long tail, i.e., a few labels are associated with a large number of  documents (a.k.a. head labels), while a large fraction of labels are associated with a  small number of documents (a.k.a. tail labels). To address the challenge of insufficient training data on tail label classification, we propose a Head-to-Tail Network (HTTN) to transfer the meta-knowledge from the data-rich head labels to data-poor tail labels. The meta-knowledge is the mapping from few-shot network parameters to many-shot network parameters, which aims to promote the generalizability of tail classifiers. Extensive experimental results on three benchmark datasets demonstrate that HTTN consistently outperforms the state-of-the-art methods. The code and hyper-parameter settings are released for reproducibility.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Lin Xiao; Xiangliang Zhang; Liping Jing; Chi Huang; Mingyang Song",
        "authorids": "",
        "aff": "Beijing Jiaotong University; King Abdullah University of Science and Technology, Saudi Arabia; Beijing Jiaotong University; Beijing Jiaotong University; Beijing Jiaotong University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17660/17660-13-21154-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14103-does-head-label-help-for-long-tailed-multi-label-text-classification/",
        "doi": "10.1609/aaai.v35i16.17660",
        "pdf_size": 609826
    },
    {
        "id": "10452",
        "title": "Domain Adaptation In Reinforcement Learning Via Latent Unified State Representation",
        "track": "main",
        "status": "Poster",
        "abstract": "Despite the recent success of deep reinforcement learning (RL), domain adaptation remains an open problem. Although the generalization ability of RL agents is critical for the real-world applicability of Deep RL, zero-shot policy transfer is still a challenging problem since even minor visual changes could make the trained agent completely fail in the new task. To address this issue, we propose a two-stage RL agent that first learns a latent unified state representation (LUSR) which is consistent across multiple domains in the first stage, and then do RL training in one source domain based on LUSR in the second stage. The cross-domain consistency of LUSR allows the policy acquired from the source domain to generalize to other target domains without extra training. We first demonstrate our approach in variants of CarRacing games with customized manipulations, and then verify it in CARLA, an autonomous driving simulator with more complex and realistic visual observations. Our results show that this approach can achieve state-of-the-art domain adaptation performance in related RL tasks and outperforms prior approaches based on latent-representation based RL and image-to-image translation.",
        "primary_area": "Machine Learning V",
        "author": "Jinwei Xing; Takashi Nagata; Kexin Chen; Xinyun Zou; Emre Neftci; Jeffrey L. Krichmar",
        "authorids": "",
        "aff": "University of California, Irvine; University of California, Irvine; University of California, Irvine; University of California, Irvine; University of California, Irvine; University of California, Irvine",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17251/17251-13-20745-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10452-domain-adaptation-in-reinforcement-learning-via-latent-unified-state-representation/",
        "doi": "10.1609/aaai.v35i12.17251",
        "pdf_size": 12008881
    },
    {
        "id": "02638",
        "title": "Domain General Face Forgery Detection by Learning to Weight",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a domain-general model, termed learning-to-weight (LTW), that guarantees face detection performance across multiple domains, particularly the target domains that are never seen before. However, various face forgery methods cause complex and biased data distributions, making it challenging to detect fake faces in unseen domains. We argue that different faces contribute differently to a detection model trained on multiple domains, making the model likely to fit domain-specific biases. As such, we propose the LTW approach based on the meta-weight learning algorithm, which configures different weights for face images from different domains. The LTW network can balance the model's generalizability across multiple domains. Then, the meta-optimization calibrates the source domain's gradient enabling more discriminative features to be learned. The detection ability of the network is further improved by introducing an intra-class compact loss. Extensive experiments on several commonly used deepfake datasets to demonstrate the effectiveness of our method in detecting synthetic faces. Code and supplemental material are available at https://github.com/skJack/LTW.",
        "primary_area": "Computer Vision II",
        "author": "Ke Sun; Hong Liu; Qixiang Ye; Yue Gao; Jianzhuang Liu; Ling Shao; Rongrong Ji",
        "authorids": "",
        "aff": "Media Analytics and Computing Lab, Department of Artificial Intelligence, School of Informatics, Xiamen University, 361005, China; National Institute of Informatics, Japan; University of Chinese Academy of Sciences, China; Tsinghua University, China; Noah's Ark Lab, Huawei Technologies, China; Inception Institute of Artificial Intelligence, Abu Dhabi, UAE; Media Analytics and Computing Lab, Department of Artificial Intelligence, School of Informatics, Xiamen University, 361005, China Institute of Artificial Intelligence, Xiamen University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16367/16367-13-19861-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02638-domain-general-face-forgery-detection-by-learning-to-weight/",
        "doi": "10.1609/aaai.v35i3.16367",
        "pdf_size": 4027613
    },
    {
        "id": "05070",
        "title": "Double Oracle Algorithm for Computing Equilibria in Continuous Games",
        "track": "main",
        "status": "Poster",
        "abstract": "Many efficient algorithms have been designed to recover Nash equilibria of various classes of finite games. Special classes of continuous games with infinite strategy spaces, such as polynomial games, can be solved by semidefinite programming. In general, however, continuous games are not directly amenable to computational procedures. In this contribution, we develop an iterative strategy generation technique for finding a Nash equilibrium in a whole class of continuous two-person zero-sum games with compact strategy sets. The procedure, which is called the double oracle algorithm, has been successfully applied to large finite games in the past. We prove the convergence of the double oracle algorithm to a Nash equilibrium. Moreover, the algorithm is guaranteed to recover an approximate equilibrium in finitely-many steps. Our numerical experiments show that it outperforms fictitious play on several examples of games appearing in the literature. In particular, we provide a detailed analysis of experiments with a version of the continuous Colonel Blotto game.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Luk\u00e1\u0161 Adam; Rostislav Hor\u010d\u00edk; Tom\u00e1\u0161 Kasl; Tom\u00e1\u0161 Kroupa",
        "authorids": "",
        "aff": "Faculty of Electrical Engineering, Czech Technical University in Prague; Faculty of Electrical Engineering, Czech Technical University in Prague; Faculty of Electrical Engineering, Czech Technical University in Prague; Faculty of Electrical Engineering, Czech Technical University in Prague",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16641/16641-13-20135-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05070-double-oracle-algorithm-for-computing-equilibria-in-continuous-games/",
        "doi": "10.1609/aaai.v35i6.16641",
        "pdf_size": 404116
    },
    {
        "id": "08574",
        "title": "Doubly Residual Neural Decoder: Towards Low-Complexity High-Performance Channel Decoding",
        "track": "main",
        "status": "Poster",
        "abstract": "Recently deep neural networks have been successfully applied in channel coding to improve the decoding performance. However, the state-of-the-art neural channel decoders cannot achieve high decoding performance and low complexity simultaneously. To overcome this challenge, in this paper we propose doubly residual neural (DRN) decoder. By integrating both the residual input and residual learning to the design of neural channel decoder, DRN enables significant decoding performance improvement while maintaining low complexity. Extensive experiment results show that on different types of channel codes, our DRN decoder consistently outperform the state-of-the-art decoders in terms of decoding performance, model sizes and computational cost.",
        "primary_area": "Machine Learning III",
        "author": "Siyu Liao; Chunhua Deng; Miao Yin; Bo Yuan",
        "authorids": "",
        "aff": "Rutgers University; Rutgers University; Rutgers University; Rutgers university",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17040/17040-13-20534-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08574-doubly-residual-neural-decoder-towards-low-complexity-high-performance-channel-decoding/",
        "doi": "10.1609/aaai.v35i10.17040",
        "pdf_size": 2227977
    },
    {
        "id": "01166",
        "title": "DramaQA: Character-Centered Video Story Understanding with Hierarchical QA",
        "track": "main",
        "status": "Poster",
        "abstract": "Despite recent progress on computer vision and natural language processing, developing a machine that can understand video story is still hard to achieve due to the intrinsic difficulty of video story. Moreover, researches on how to evaluate the degree of video understanding based on human cognitive process have not progressed as yet. In this paper, we propose a novel video question answering (Video QA) task, DramaQA, for a comprehensive understanding of the video story. The DramaQA focuses on two perspectives: 1) Hierarchical QAs as an evaluation metric based on the cognitive developmental stages of human intelligence. 2) Character-centered video annotations to model local coherence of the story. Our dataset is built upon the TV drama \"Another Miss Oh\" and it contains 17,983 QA pairs from 23,928 various length video clips, with each QA pair belonging to one of four difficulty levels. We provide 217,308 annotated images with rich character-centered annotations, including visual bounding boxes, behaviors and emotions of main characters, and coreference resolved scripts. Additionally, we suggest Multi-level Context Matching model which hierarchically understands character-centered representations of video to answer questions. We release our dataset and model publicly for research purposes, and we expect our work to provide a new perspective on video story understanding research.",
        "primary_area": "Computer Vision I",
        "author": "Seongho Choi; Kyoung-Woon On; Yu-Jung Heo; Ahjeong Seo; Youwon Jang; Minsu Lee; Byoung-Tak Zhang",
        "authorids": "",
        "aff": "Seoul National University; Seoul National University; Seoul National University; Seoul National University; Seoul National University; Seoul National University; Seoul National University AI Institute (AIIS)",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16203/16203-13-19697-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01166-dramaqa-character-centered-video-story-understanding-with-hierarchical-qa/",
        "doi": "10.1609/aaai.v35i2.16203",
        "pdf_size": 4774024
    },
    {
        "id": "01549",
        "title": "DropLoss for Long-Tail Instance Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "Long-tailed class distributions are prevalent among the practical applications of object detection and instance segmentation. Prior work in long-tail instance segmentation addresses the imbalance of losses between rare and frequent categories by reducing the penalty for a model incorrectly predicting a rare class label. We demonstrate that the rare categories are heavily suppressed by correct background predictions, which reduces the probability for all foreground categories with equal weight. Due to the relative infrequency of rare categories, this leads to an imbalance that biases towards predicting more frequent categories. Based on this insight, we develop DropLoss -- a novel adaptive loss to compensate for this imbalance without a trade-off between rare and frequent categories. With this loss, we show state-of-the-art mAP across rare, common, and frequent categories on the LVIS dataset. Codes are available at https://github.com/timy90022/DropLoss.",
        "primary_area": "Computer Vision I",
        "author": "Ting-I Hsieh; Esther Robb; Hwann-Tzong Chen; Jia-Bin Huang",
        "authorids": "",
        "aff": "National Tsing Hua University; Virginia Tech; National Tsing Hua University Aeolus Robotics; Virginia Tech",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16246/16246-13-19740-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01549-droploss-for-long-tail-instance-segmentation/",
        "doi": "10.1609/aaai.v35i2.16246",
        "pdf_size": 1914100
    },
    {
        "id": "02440",
        "title": "Dual Adversarial Graph Neural Networks for Multi-label Cross-modal Retrieval",
        "track": "main",
        "status": "Poster",
        "abstract": "Cross-modal retrieval has become an active study field with the expanding scale of multimodal data. To date, most existing methods transform multimodal data into a common representation space where semantic similarities between items can be directly measured across different modalities. However, these methods typically suffer from following limitations: 1) They usually attempt to bridge the modality gap by designing losses in the common representation space which may not be sufficient to eliminate potential heterogeneity of different modalities in the common space. 2) They typically treat labels as independent individuals and ignore label relationships which are important for constructing semantic links between multimodal data. In this work, we propose a novel Dual Adversarial Graph Neural Networks (DAGNN) composed of the dual generative adversarial networks and the multi-hop graph neural networks, which learn modality-invariant and discriminative common representations for cross-modal retrieval. Firstly, we construct the dual generative adversarial networks to project multimodal data into a common representation space. Secondly, we leverage the multi-hop graph neural networks, in which a layer aggregation mechanism is proposed to exploit multi-hop propagation information, to capture the label correlation dependency and learn inter-dependent classifiers. Comprehensive experiments conducted on two cross-modal retrieval benchmark datasets, NUS-WIDE and MIRFlickr, indicate the superiority of DAGNN.",
        "primary_area": "Computer Vision II",
        "author": "Shengsheng Qian; Dizhan Xue; Huaiwen Zhang; Quan Fang; Changsheng Xu",
        "authorids": "",
        "aff": "National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences University of Chinese Academy of Sciences; University of Chinese Academy of Sciences; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences University of Chinese Academy of Sciences; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences University of Chinese Academy of Sciences; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences University of Chinese Academy of Sciences Peng Cheng Laboratory",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16345/16345-13-19839-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02440-dual-adversarial-graph-neural-networks-for-multi-label-cross-modal-retrieval/",
        "doi": "10.1609/aaai.v35i3.16345",
        "pdf_size": 1096177
    },
    {
        "id": "01771",
        "title": "Dual Compositional Learning in Interactive Image Retrieval",
        "track": "main",
        "status": "Poster",
        "abstract": "We present an approach named Dual Composition Network (DCNet) for interactive image retrieval that searches for the best target image for a natural language query and a reference image. To accomplish this task, existing methods have focused on learning a composite representation of the reference image and the text query to be as close to the embedding of the target image as possible. We refer this approach as Composition Network. In this work, we propose to close the loop with Correction Network that models the difference between the reference and target image in the embedding space and matches it with the embedding of the text query. That is, we consider two cyclic directional mappings for triplets of (reference image, text query, target image) by using both Composition Network and Correction Network. We also propose a joint training loss that can further improve the robustness of multimodal representation learning. We evaluate the proposed model on three benchmark datasets for multimodal retrieval: Fashion-IQ, Shoes, and Fashion200K. Our experiments show that our DCNet achieves new state-of-the-art performance on all three datasets, and the addition of Correction Network consistently improves multiple existing methods that are solely based on Composition Network. Moreover, an ensemble of our model won the first place in Fashion-IQ 2020 challenge held in a CVPR 2020 workshop.",
        "primary_area": "Computer Vision I",
        "author": "Jongseok Kim; Youngjae Yu; Hoeseong Kim; Gunhee Kim",
        "authorids": "",
        "aff": "Seoul National University; Seoul National University RippleAI; Seoul National University; Seoul National University RippleAI",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16271/16271-13-19765-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01771-dual-compositional-learning-in-interactive-image-retrieval/",
        "doi": "10.1609/aaai.v35i2.16271",
        "pdf_size": 1340448
    },
    {
        "id": "01054",
        "title": "Dual Distribution Alignment Network for Generalizable Person Re-Identification",
        "track": "main",
        "status": "Poster",
        "abstract": "Domain generalization (DG) offers a preferable real-world setting for Person Re-Identification (Re-ID), which trains a model using multiple source domain datasets and expects it to perform well in an unseen target domain without any model updating. Unfortunately, most DG approaches are designed explicitly for classification tasks, which fundamentally differs from the retrieval task Re-ID. Moreover, existing applications of DG in Re-ID cannot correctly handle the massive variation among Re-ID datasets. In this paper, we identify two fundamental challenges in DG for Person Re-ID: domain-wise variations and identity-wise similarities. To this end, we propose an end-to-end Dual Distribution Alignment Network (DDAN) to learn domain-invariant features with dual-level constraints: the domain-wise adversarial feature learning and the identity-wise similarity enhancement. These constraints effectively reduce the domain-shift among multiple source domains further while agreeing to real-world scenarios. We evaluate our method in a large-scale DG Re-ID benchmark and compare it with various cutting-edge DG approaches. Quantitative results show that DDAN achieves state-of-the-art performance.",
        "primary_area": "Computer Vision I",
        "author": "Peixian Chen; Pingyang Dai; Jianzhuang Liu; Feng Zheng; Mingliang Xu; Qi Tian; Rongrong Ji",
        "authorids": "",
        "aff": "Media Analytics and Computing Lab, Department of Artificial Intelligence, School of Informatics, Xiamen University; Media Analytics and Computing Lab, Department of Artificial Intelligence, School of Informatics, Xiamen University; Noah's Ark Lab, Huawei Tech; Department of Computer Science and Engineering, Southern University of Science and Technology; School of Information Engineering, Zhengzhou University; Cloud & AI, Huawei Tech; Media Analytics and Computing Lab, Department of Artificial Intelligence, School of Informatics, Xiamen University Institute of Artificial Intelligence, Xiamen University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16190/16190-13-19684-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01054-dual-distribution-alignment-network-for-generalizable-person-re-identification/",
        "doi": "10.1609/aaai.v35i2.16190",
        "pdf_size": 1351176
    },
    {
        "id": "06894",
        "title": "Dual Quaternion Knowledge Graph Embeddings",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we study the problem of learning representations of entities and relations in the knowledge graph for the link prediction task. Our idea is based on the observation that the vast majority of the related work only models the relation as a single geometric operation such as translation or rotation, which limits the representation power of the underlying models and makes it harder to match the complicated relations existed in real-world datasets. To embrace a richer set of relational information, we propose a new method called dual quaternion knowledge graph embedding (DualE), which introduces dual quaternions into knowledge graph embeddings. Specifically, a dual quaternion behaves like a \u201ccomplex quaternion\u201d with its real and imaginary part all being quaternary. The core of DualE lies a specific design of dual-quaternion-based multiplication, which universally models relations as the compositions of a series of translation and rotation operations. The major merits of DualE are three-fold:1) it is the first unified framework embracing both rotation based and translation-based models, 2) it expands the embedding space to the dual quaternion space with a more intuitive physical and geometric interpretation, 3) it  satisfies the key patterns and the multiple relations pattern of relational representation learning. Experimental results on four real-world datasets demonstrate the effectiveness of our DualE method.",
        "primary_area": "Machine Learning I",
        "author": "Zongsheng Cao; Qianqian Xu; Zhiyong Yang; Xiaochun Cao; Qingming Huang",
        "authorids": "",
        "aff": "State Key Laboratory of Information Security, Institute of Information Engineering, CAS, Beijing, China\uff1b School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China; Key Laboratory of Intelligent Information Processing, Institute of Computing Technology, Chinese Academy of Sciences; State Key Laboratory of Information Security, Institute of Information Engineering, CAS, Beijing, China\uff1b School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Information Security, Institute of Information Engineering, CAS, Beijing, China\uff1b School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China\uff1b Peng Cheng Laboratory, Shenzhen, China; Key Laboratory of Intelligent Information Processing, Institute of Computing Technology, CAS, Beijing, China\uff1b School of Computer Science and Technology, University of Chinese Academy of Sciences, Beijing, China\uff1b Key Laboratory of Big Data Mining and Knowledge Management, Chinese Academy of Sciences, Beijing, China\uff1b Peng Cheng Laboratory, Shenzhen, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16850/16850-13-20344-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06894-dual-quaternion-knowledge-graph-embeddings/",
        "doi": "10.1609/aaai.v35i8.16850",
        "pdf_size": 715555
    },
    {
        "id": "04635",
        "title": "Dual Sparse Attention Network For Session-based Recommendation",
        "track": "main",
        "status": "Poster",
        "abstract": "Session-based Recommendations recommend the next possible item for the user with anonymous sessions, whose challenge is that the user\u2019s behavioral preference can only be analyzed in a limited sequence to meet their need. Recent advances evaluate the effectiveness of the attention mechanism in the session-based recommendation. However, two simplifying assumptions are made by most of these attention-based models. One is to regard the last-click as the query vector to denote the user\u2019s current preference, and the other is to consider that all items within the session are favorable for the final result, including the effect of unrelated items (i.e., spurious user behaviors). In this paper, we propose a novel Dual Sparse Attention Network for the session-based recommendation called DSAN to address these shortcomings. In this proposed method, we explore a learned target item embedding to model the user\u2019s current preference and apply an adaptively sparse transformation function to eliminate the effect of the unrelated items. Experimental results on two real public datasets show that the proposed method is superior to the state-of-the-art session-based recommendation algorithm in all tests and also demonstrate that not all actions within the session are useful. To make our results reproducible, we have published our code on https://github.com/SamHaoYuan/DSANForAAAI2021.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Jiahao Yuan; Zihan Song; Mingyou Sun; Xiaoling Wang; Wayne Xin Zhao",
        "authorids": "",
        "aff": "East China Normal University; East China Normal University; East China Normal University; East China Normal University Tongji University; Renmin University of China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16593/16593-13-20087-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04635-dual-sparse-attention-network-for-session-based-recommendation/",
        "doi": "10.1609/aaai.v35i5.16593",
        "pdf_size": 3180729
    },
    {
        "id": "00116",
        "title": "Dual-Octave Convolution for Accelerated Parallel MR Image Reconstruction",
        "track": "main",
        "status": "Poster",
        "abstract": "Magnetic resonance (MR) image acquisition is an inherently prolonged process, whose acceleration by obtaining multiple undersampled images simultaneously through parallel imaging has always been the subject of research. In this paper, we propose the Dual-Octave Convolution (Dual-OctConv), which is capable of learning multi-scale spatial-frequency features from both real and imaginary components, for fast parallel MR image reconstruction. By reformulating the complex operations using octave convolutions, our model shows a strong ability to capture richer representations of MR images, while at the same time greatly reducing the spatial redundancy. More specifically, the input feature maps and convolutional kernels are first split into two components (i.e., real and imaginary), which are then divided into four groups according to their spatial frequencies. Then, our Dual-OctConv conducts intra-group information updating and inter-group information exchange to aggregate the contextual information across different groups. Our framework provides two appealing benefits: (i) it encourages interactions between real and imaginary components at various spatial frequencies to achieve richer representational capacity, and (ii) it enlarges the receptive field by learning multiple spatial-frequency features of both the real and imaginary components. We evaluate the performance of the proposed model on the acceleration of multi-coil MR image reconstruction. Extensive experiments are conducted on an {in vivo} knee dataset under different undersampling patterns and acceleration factors. The experimental results demonstrate the superiority of our model in accelerated parallel MR image reconstruction. Our code is available at: github.com/chunmeifeng/Dual-OctConv.",
        "primary_area": "Application Domains",
        "author": "Chun-Mei Feng; Zhanyuan Yang; Geng Chen; Yong Xu; Ling Shao",
        "authorids": "",
        "aff": "Shenzhen Key Laboratory of Visual Object Detection and Recognition, Harbin Institute of Technology (Shenzhen), China; School of Automation Engineering, University of Electronic Science and Technology of China, China; Inception Institute of Artificial Intelligence, Abu Dhabi, UAE; Shenzhen Key Laboratory of Visual Object Detection and Recognition, Harbin Institute of Technology (Shenzhen), China Peng Cheng Laboratory, Shenzhen, China; Inception Institute of Artificial Intelligence, Abu Dhabi, UAE",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16084/16084-13-19578-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00116-dual-octave-convolution-for-accelerated-parallel-mr-image-reconstruction/",
        "doi": "10.1609/aaai.v35i1.16084",
        "pdf_size": 1471327
    },
    {
        "id": "02286",
        "title": "Dual-level Collaborative Transformer for Image Captioning",
        "track": "main",
        "status": "Poster",
        "abstract": "Descriptive region features extracted by object detection networks have played an important role in the recent advancements of image captioning. However, they are still criticized for the lack of contextual information and fine-grained details, which in contrast are the merits of traditional grid features. In this paper, we introduce a novel Dual-Level Collaborative Transformer (DLCT) network to realize the complementary advantages of the two features. Concretely, in DLCT, these two features are first processed by a novel Dual-way Self Attenion (DWSA) to mine their intrinsic properties, where a Comprehensive Relation Attention component is also introduced to embed the geometric information. In addition, we propose a Locality-Constrained Cross Attention module to address the semantic noises caused by the direct fusion of these two features, where a geometric alignment graph is constructed to accurately align and reinforce region and grid features. To validate our model, we conduct extensive experiments on the highly competitive MS-COCO dataset, and achieve new state-of-the-art performance on both local and online test sets, i.e., 133.8% CIDEr on Karpathy split and 135.4% CIDEr on the official split.",
        "primary_area": "Computer Vision II",
        "author": "Yunpeng Luo; Jiayi Ji; Xiaoshuai Sun; Liujuan Cao; Yongjian Wu; Feiyue Huang; Chia-Wen Lin; Rongrong Ji",
        "authorids": "",
        "aff": "Xiamen University; Xiamen University; Xiamen University; Xiamen University; Tencent Youtu Lab; Tencent Youtu Lab; National Tsing Hua University; Xiamen University, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16328/16328-13-19822-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02286-dual-level-collaborative-transformer-for-image-captioning/",
        "doi": "10.1609/aaai.v35i3.16328",
        "pdf_size": 3873490
    },
    {
        "id": "02355",
        "title": "Dynamic Anchor Learning for Arbitrary-Oriented Object Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Arbitrary-oriented objects widely appear in natural scenes, aerial photographs, remote sensing images, etc., and thus arbitrary-oriented object detection has received considerable attention. Many current rotation detectors use plenty of anchors with different orientations to achieve spatial alignment with ground truth boxes. Intersection-over-Union (IoU) is then applied to sample the positive and negative candidates for training. However, we observe that the selected positive anchors cannot always ensure accurate detections after regression, while some negative samples can achieve accurate localization. It indicates that the quality assessment of anchors through IoU is not appropriate, and this further leads to inconsistency between classification confidence and localization accuracy. In this paper, we propose a dynamic anchor learning (DAL) method, which utilizes the newly defined matching degree to comprehensively evaluate the localization potential of the anchors and carries out a more efficient label assignment process. In this way, the detector can dynamically select high-quality anchors to achieve accurate object detection, and the divergence between classification and regression will be alleviated. With the newly introduced DAL, we can achieve superior detection performance for arbitrary-oriented objects with only a few horizontal preset anchors. Experimental results on three remote sensing datasets HRSC2016, DOTA, UCAS-AOD as well as a scene text dataset ICDAR 2015 show that our method achieves substantial improvement compared with the baseline model. Besides, our approach is also universal for object detection using horizontal bound box. The code and models are available at https://github.com/ming71/DAL.",
        "primary_area": "Computer Vision II",
        "author": "Qi Ming; Zhiqiang Zhou; Lingjuan Miao; Hongwei Zhang; Linhao Li",
        "authorids": "",
        "aff": "School of Automation, Beijing Institute of Technology, China; School of Automation, Beijing Institute of Technology, China; School of Automation, Beijing Institute of Technology, China; School of Automation, Beijing Institute of Technology, China; School of Automation, Beijing Institute of Technology, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16336/16336-13-19830-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02355-dynamic-anchor-learning-for-arbitrary-oriented-object-detection/",
        "doi": "10.1609/aaai.v35i3.16336",
        "pdf_size": 18421291
    },
    {
        "id": "12015",
        "title": "Dynamic Automaton-Guided Reward Shaping for Monte Carlo Tree Search",
        "track": "main",
        "status": "Poster",
        "abstract": "Reinforcement learning and planning have been revolutionized in recent years, due in part to the mass adoption of deep convolutional neural networks and the resurgence of powerful methods to refine decision-making policies. However, the problem of sparse reward signals and their representation remains pervasive in many domains. While various rewardshaping mechanisms and imitation learning approaches have been proposed to mitigate this problem, the use of humanaided artificial rewards introduces human error, sub-optimal behavior, and a greater propensity for reward hacking. In this paper, we mitigate this by representing objectives as automata in order to define novel reward shaping functions over this structured representation. In doing so, we address the sparse rewards problem within a novel implementation of Monte Carlo Tree Search (MCTS) by proposing a reward shaping function which is updated dynamically to capture statistics on the utility of each automaton transition as it pertains to satisfying the goal of the agent. We further demonstrate that such automaton-guided reward shaping can be utilized to facilitate transfer learning between different environments when the objective is the same.",
        "primary_area": "Planning, Routing, and Scheduling",
        "author": "Alvaro Velasquez; Brett Bissey; Lior Barak; Andre Beckus; Ismail Alkhouri; Daniel Melcer; George Atia",
        "authorids": "",
        "aff": "Air Force Research Laboratory; University of Central Florida; University of Central Florida; Air Force Research Laboratory; University of Central Florida; Northeastern University; University of Central Florida",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17427/17427-13-20921-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12015-dynamic-automaton-guided-reward-shaping-for-monte-carlo-tree-search/",
        "doi": "10.1609/aaai.v35i13.17427",
        "pdf_size": 1291410
    },
    {
        "id": "00651",
        "title": "Dynamic Gaussian Mixture based Deep Generative Model For Robust Forecasting on Sparse Multivariate Time Series",
        "track": "main",
        "status": "Poster",
        "abstract": "Forecasting on sparse multivariate time series (MTS) aims to model the predictors of future values of time series given their incomplete past, which is important for many emerging applications. However, most existing methods process MTS\u2019s individually, and do not leverage the dynamic distributions underlying the MTS\u2019s, leading to sub-optimal results when the sparsity is high. To address this challenge, we propose a novel generative model, which tracks the transition of latent clusters, instead of isolated feature representations, to achieve robust modeling. It is characterized by a newly designed dynamic Gaussian mixture distribution, which captures the dynamics of clustering structures, and is used for emitting time series. The generative model is parameterized by neural networks. A structured inference network is also designed for enabling inductive analysis.  A gating mechanism is further introduced to dynamically tune the Gaussian mixture distributions. Extensive experimental results on a variety of real-life datasets demonstrate the effectiveness of our method.",
        "primary_area": "Application Domains",
        "author": "Yinjun Wu; Jingchao Ni; Wei Cheng; Bo Zong; Dongjin Song; Zhengzhang Chen; Yanchi Liu; Xuchao Zhang; Haifeng Chen; Susan B Davidson",
        "authorids": "",
        "aff": "University of Pennsylvania; NEC Laboratories America; NEC Laboratories America; NEC Labs; University of Connecticut; NEC Laboratories America, Inc.; NEC Labs America; NEC Labs America; NEC Labs; University of Pennsylvania",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16145/16145-13-19639-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00651-dynamic-gaussian-mixture-based-deep-generative-model-for-robust-forecasting-on-sparse-multivariate-time-series/",
        "doi": "10.1609/aaai.v35i1.16145",
        "pdf_size": 1035313
    },
    {
        "id": "01415",
        "title": "Dynamic Graph Representation Learning for Video Dialog via Multi-Modal Shuffled Transformers",
        "track": "main",
        "status": "Poster",
        "abstract": "Given an input video, its associated audio, and a brief caption, the audio-visual scene aware dialog (AVSD) task requires an agent to indulge in a question-answer dialog with a human about the audio-visual content. This task thus poses a challenging multi-modal representation learning and reasoning scenario, advancements into which could influence several human-machine interaction applications. To solve this task, we introduce a semantics-controlled multi-modal shuffled Transformer reasoning framework, consisting of a sequence of Transformer modules, each taking a modality as input and producing representations conditioned on the input question. Our proposed Transformer variant uses a shuffling scheme on their multi-head outputs, demonstrating better regularization. To encode fine-grained visual information, we present a novel dynamic scene graph representation learning pipeline that consists of an intra-frame reasoning layer producing spatio-semantic graph representations for every frame, and an inter-frame aggregation module capturing temporal cues. Our entire pipeline is trained end-to-end. We present experiments on the benchmark AVSD dataset, both on answer generation and selection tasks. Our results demonstrate state-of-the-art performances on all evaluation metrics.",
        "primary_area": "Computer Vision I",
        "author": "Shijie Geng; Peng Gao; Moitreya Chatterjee; Chiori Hori; Jonathan Le Roux; Yongfeng Zhang; Hongsheng Li; Anoop Cherian",
        "authorids": "",
        "aff": "Rutgers University; The Chinese University of Hong Kong; University of Illinois at Urbana Champaign; Mitsubishi Electric Research Laboratories (MERL); Mitsubishi Electric Research Laboratories (MERL); Rutgers University; The Chinese University of Hong Kong; Mitsubishi Electric Research Laboratories (MERL)",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16231/16231-13-19725-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01415-dynamic-graph-representation-learning-for-video-dialog-via-multi-modal-shuffled-transformers/",
        "doi": "10.1609/aaai.v35i2.16231",
        "pdf_size": 14217071
    },
    {
        "id": "13116",
        "title": "Dynamic Hybrid Relation Exploration Network for Cross-Domain Context-Dependent Semantic Parsing",
        "track": "main",
        "status": "Poster",
        "abstract": "Semantic parsing has long been a fundamental problem in natural language processing. Recently, cross-domain context-dependent semantic parsing has become a new focus of research. Central to the problem is the challenge of leveraging contextual information of both natural language queries and database schemas in the interaction history.  In this paper, we present a dynamic graph framework that is capable of effectively modelling contextual utterances, tokens, database schemas, and their complicated interaction as the conversation proceeds. The framework employs a dynamic memory decay mechanism that incorporates inductive bias to integrate enriched contextual relation representation, which is further enhanced with a powerful reranking model. At the time of writing, we demonstrate that the proposed framework outperforms all existing models by large margins, achieving new state-of-the-art performance on two large-scale benchmarks, the SParC and CoSQL datasets. Specifically, the model attains a 55.8% question-match and 30.8% interaction-match accuracy on SParC, and a 46.8% question-match and 17.0% interaction-match accuracy on CoSQL.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Binyuan Hui; Ruiying Geng; Qiyu Ren; Binhua Li; Yongbin Li; Jian Sun; Fei Huang; Luo Si; Pengfei Zhu; Xiaodan Zhu",
        "authorids": "",
        "aff": "Tianjin University Alibaba Group; Alibaba Group; Beijing University of Posts and Telecommunications; Alibaba Group; Alibaba Group; Alibaba Group; Alibaba Group; Alibaba Group; Tianjin University; Ingenuity Labs Research Institute & ECE, Queen\u2019s University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17550/17550-13-21044-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13116-dynamic-hybrid-relation-exploration-network-for-cross-domain-context-dependent-semantic-parsing/",
        "doi": "10.1609/aaai.v35i14.17550",
        "pdf_size": 776580
    },
    {
        "id": "04564",
        "title": "Dynamic Knowledge Graph Alignment",
        "track": "main",
        "status": "Poster",
        "abstract": "Knowledge graph (KG for short) alignment aims at building a complete KG by linking the shared entities across complementary KGs. Existing approaches assume that KGs are static, despite the fact that almost every KG evolves over time. In this paper, we introduce the task of dynamic knowledge graph alignment, the main challenge of which is how to efficiently update entity embeddings for the evolving graph topology. Our key insight is to view the parameter matrix of GCN as a feature transformation operator and decouple the transformation process from the aggregation process. Based on that, we first propose a novel base algorithm (DINGAL-B) with topology-invariant mask gate and highway gate, which consistently outperforms 14 existing knowledge graph alignment methods in the static setting. More importantly, it naturally leads to two effective and efficient algorithms to align dynamic knowledge graph, including (1) DINGAL-O which leverages previous parameter matrices to update the embeddings of affected entities; and (2) DINGAL-U which resorts to newly obtained anchor links to fine-tune parameter matrices. Compared with their static counterpart (DINGAL-B), DINGAL-U and DINGAL-O are 10\u00d7 and 100\u00d7 faster respectively, with little alignment accuracy loss.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Yuchen Yan; Lihui Liu; Yikun Ban; Baoyu Jing; Hanghang Tong",
        "authorids": "",
        "aff": "University of Illinois at Urbana-Champaign; University of Illinois at Urbana-Champaign; University of Illinois at Urbana-Champaign; University of Illinois at Urbana-Champaign; University of Illinois at Urbana-Champaign",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16585/16585-13-20079-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04564-dynamic-knowledge-graph-alignment/",
        "doi": "10.1609/aaai.v35i5.16585",
        "pdf_size": 1155772
    },
    {
        "id": "04384",
        "title": "Dynamic Memory based Attention Network for Sequential Recommendation",
        "track": "main",
        "status": "Poster",
        "abstract": "Sequential recommendation has become increasingly essential in various online services. It aims to model the dynamic preferences of users from their historical interactions and predict their next items. The accumulated user behavior records on real systems could be very long. This rich data brings opportunities to track actual interests of users. Prior efforts mainly focus on making recommendations based on relatively recent behaviors. However, the overall sequential data may not be effectively utilized, as early interactions might affect users' current choices. Also, it has become intolerable to scan the entire behavior sequence when performing inference for each user, since real-world system requires short response time. To bridge the gap, we propose a novel long sequential recommendation model, called Dynamic Memory-based Attention Network (DMAN). It segments the overall long behavior sequence into a series of sub-sequences, then trains the model and maintains a set of memory blocks to preserve long-term interests of users. To improve memory fidelity, DMAN dynamically abstracts each user's long-term interest into its own memory blocks by minimizing an auxiliary reconstruction loss. Based on the dynamic memory, the user's short-term and long-term interests can be explicitly extracted and combined for efficient joint recommendation. Empirical results over four benchmark datasets demonstrate the superiority of our model in capturing long-term dependency over various state-of-the-art sequential models.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Qiaoyu Tan; Jianwei Zhang; Ninghao Liu; Xiao Huang; Hongxia Yang; Jingren Zhou; Xia Hu",
        "authorids": "",
        "aff": "Texas A&M University; Alibaba Group; Texas A&M University; The Hong Kong Polytechnic University; Alibaba Group; Alibaba Group; Texas A&M University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16564/16564-13-20058-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04384-dynamic-memory-based-attention-network-for-sequential-recommendation/",
        "doi": "10.1609/aaai.v35i5.16564",
        "pdf_size": 613523
    },
    {
        "id": "14515",
        "title": "Dynamic Modeling Cross- and Self-Lattice Attention Network for Chinese NER",
        "track": "main",
        "status": "Poster",
        "abstract": "Word-character lattice models have been proved to be effective for Chinese named entity recognition (NER), in which word boundary information is fused into character sequences for enhancing character representations. However, prior approaches have only used simple methods such as feature concatenation or position encoding to integrate word-character lattice information, but fail to capture fine-grained correlations in word-character spaces. In this paper, we propose DCSAN, a Dynamic Cross- and Self-lattice Attention Network that aims to model dense interactions over word-character lattice structure for Chinese NER. By carefully combining cross-lattice and self-lattice attention modules with gated word-character semantic fusion unit, the network can explicitly capture fine-grained correlations across different spaces (e.g., word-to-character and character-to-character), thus significantly improving model performance. Experiments on four Chinese NER datasets show that DCSAN obtains stateof-the-art results as well as efficiency compared to several competitive approaches.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Shan Zhao; Minghao Hu; Zhiping Cai; Haiwen Chen; Fang Liu",
        "authorids": "",
        "aff": "College of Computer, National University of Defense Technology; Information Research Center of Military Science, PLA Academy of Military Science; College of Computer, National University of Defense Technology; National University of Defense Technology; School of Design, Hunan University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17706/17706-13-21200-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14515-dynamic-modeling-cross-and-self-lattice-attention-network-for-chinese-ner/",
        "doi": "10.1609/aaai.v35i16.17706",
        "pdf_size": 1567298
    },
    {
        "id": "07953",
        "title": "Dynamic Multi-Context Attention Networks for Citation Forecasting of Scientific Publications",
        "track": "main",
        "status": "Poster",
        "abstract": "Forecasting citations of scientific patents and publications is a crucial task for understanding the evolution and development of technological domains and for foresight into emerging technologies. By construing citations as a time series, the task can be cast into the domain of temporal point processes. Most existing work on forecasting with temporal point processes, both conventional and neural network-based, only performs single-step forecasting. In citation forecasting, however, the more salient goal is n-step forecasting: predicting the arrival time and the technology class of the next n citations. In this paper, we propose Dynamic Multi-Context Attention Networks (DMA-Nets), a novel deep learning sequence-to-sequence (Seq2Seq) model with a novel hierarchical dynamic attention mechanism for long-term citation forecasting. Extensive experiments on two real-world datasets demonstrate that the proposed model learns better representations of conditional dependencies over historical sequences compared to state-of-the-art counterparts and thus achieves significant performance for citation predictions. The dataset and code have been made available online.",
        "primary_area": "Machine Learning II",
        "author": "Taoran Ji; Nathan Self; Kaiqun Fu; Zhiqian Chen; Naren Ramakrishnan; Chang-Tien Lu",
        "authorids": "",
        "aff": "Virginia Tech; Virginia Tech; Virginia Tech; Mississippi State University; Virginia Tech; Virginia Tech, USA",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16970/16970-13-20464-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07953-dynamic-multi-context-attention-networks-for-citation-forecasting-of-scientific-publications/",
        "doi": "10.1609/aaai.v35i9.16970",
        "pdf_size": 1424098
    },
    {
        "id": "04923",
        "title": "Dynamic Neuro-Symbolic Knowledge Graph Construction for Zero-shot Commonsense Question Answering",
        "track": "main",
        "status": "Poster",
        "abstract": "Understanding narratives requires reasoning about implicit world knowledge related to the causes, effects, and states of situations described in text. At the core of this challenge is how to access contextually relevant knowledge on demand and reason over it.  In this paper, we present initial studies toward zero-shot commonsense question answering by formulating the task as inference over dynamically generated commonsense knowledge graphs. In contrast to previous studies for knowledge integration that rely on retrieval of existing knowledge from static knowledge graphs, our study requires commonsense knowledge integration where contextually relevant knowledge is often not present in existing knowledge bases. Therefore, we present a novel approach that generates contextually-relevant symbolic knowledge structures on demand using generative neural commonsense knowledge models.  Empirical results on two datasets demonstrate the efficacy of our neuro-symbolic approach for dynamically constructing knowledge graphs for reasoning. Our approach achieves significant performance boosts over pretrained language models and vanilla knowledge models, all while providing interpretable reasoning paths for its predictions.",
        "primary_area": "Neuro-Symbolic AI",
        "author": "Antoine Bosselut; Ronan Le Bras; Yejin Choi",
        "authorids": "",
        "aff": "Stanford University Allen Institute for AI; Allen Institute for AI; University of Washington Allen Institute for AI",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16625/16625-13-20119-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04923-dynamic-neuro-symbolic-knowledge-graph-construction-for-zero-shot-commonsense-question-answering/",
        "doi": "10.1609/aaai.v35i6.16625",
        "pdf_size": 368341
    },
    {
        "id": "02791",
        "title": "Dynamic Position-aware Network for Fine-grained Image Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "Most weakly supervised fine-grained image recognition (WFGIR) approaches predominantly focus on learning the discriminative details which contain the visual variances and position clues. The position clues can be indirectly learnt by utilizing context information of discriminative visual content. However, this will cause the selected discriminative regions containing some non-discriminative information introduced by the position clues. These analysis motivate us to directly introduce position clues into visual content to only focus on the visual variances, achieving more precise discriminative region localization. Though important, position modelling usually requires significant pixel/region annotations and therefore is labor-intensive. To address this issue, we propose an end-to-end Dynamic Position-aware Network (DP-Net) to directly incorporate the position clues into visual content and dynamically align them without extra annotations, which eliminates the effect of position information for visual variances of subcategories. In particular, the DP-Net consists of: 1) Position Encoding Module, which learns a set of position-aware parts by directly adding the learnable position information into the horizontal/vertical visual content of images; 2) Position-vision Aligning Module, which dynamically aligns both visual content and learnable position information via performing graph convolution on position-aware parts; 3) Position-vision Reorganization Module, which projects the aligned position clues and visual content into the Euclidean space to construct a position-aware feature maps. Finally, the position-aware feature maps are used which is implicitly applied the aligned visual content and position clues for more accurate discriminative regions localization. Extensive experiments verify that DP-Net yields the best performance under the same settings with most competitive approaches, on CUB Bird, Stanford-Cars, and FGVC Aircraft datasets.",
        "primary_area": "Computer Vision III",
        "author": "Shijie Wang; Haojie Li; Zhihui Wang; Wanli Ouyang",
        "authorids": "",
        "aff": "International School of Information Science & Engineering, Dalian University of Technology, China Key Laboratory for Ubiquitous Network and Service Software of Liaoning Province, China; International School of Information Science & Engineering, Dalian University of Technology, China Key Laboratory for Ubiquitous Network and Service Software of Liaoning Province, China; International School of Information Science & Engineering, Dalian University of Technology, China Key Laboratory for Ubiquitous Network and Service Software of Liaoning Province, China; SenseTime Computer Vision Research Group, The University of Sydney, Australia",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16384/16384-13-19878-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02791-dynamic-position-aware-network-for-fine-grained-image-recognition/",
        "doi": "10.1609/aaai.v35i4.16384",
        "pdf_size": 2861032
    },
    {
        "id": "01836",
        "title": "Dynamic to Static Lidar Scan Reconstruction Using Adversarially Trained Auto Encoder",
        "track": "main",
        "status": "Poster",
        "abstract": "Accurate reconstruction of static environments from LiDAR scans of scenes containing dynamic objects, which we refer to as Dynamic to Static Translation (DST), is an important area of research in Autonomous Navigation. This problem has been recently explored for visual SLAM, but to the best of our knowledge no work has been attempted to address DST for LiDAR scans. The problem is of critical importance due to wide-spread adoption of LiDAR in Autonomous Vehicles. We show that state-of the art methods developed for the visual domain when adapted for LiDAR scans perform poorly. We develop DSLR, a deep generative model which learns a mapping between dynamic scan to its static counterpart through an adversarially trained autoencoder. Our model yields the first solution for DST on LiDAR that generates static scans without using explicit segmentation labels. DSLR cannot always be applied to real world data due to lack of paired dynamic-static scans. Using Unsupervised Domain Adaptation, we propose DSLR-UDA for transfer to real world data and experimentally show that this performs well in real world settings. Additionally, if segmentation information is available, we extend DSLR to DSLR-Seg to further improve the reconstruction quality. DSLR gives the state of the art performance on simulated and real-world datasets and also shows at least 4\u00d7 improvement. We show that DSLR, unlike the existing baselines, is a practically viable model with its reconstruction quality within the tolerable limits for tasks pertaining to autonomous navigation like SLAM in dynamic environments.",
        "primary_area": "Computer Vision II",
        "author": "Prashant Kumar; Sabyasachi Sahoo; Vanshil Shah; Vineetha Kondameedi; Abhinav Jain; Akshaj Verma; Chiranjib Bhattacharyya; Vinay Vishwanath",
        "authorids": "",
        "aff": "Indian Institute of Science, Bangalore, India; Indian Institute of Science, Bangalore, India; Indian Institute of Science, Bangalore, India; Indian Institute of Science, Bangalore, India; Indian Institute of Science, Bangalore, India; Indian Institute of Science, Bangalore, India; Indian Institute of Science, Bangalore, India; AMIDC Pvt Ltd, Bangalore, India Chennai Mathematical Institute, Chennai, India",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16278/16278-13-19772-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01836-dynamic-to-static-lidar-scan-reconstruction-using-adversarially-trained-auto-encoder/",
        "doi": "10.1609/aaai.v35i3.16278",
        "pdf_size": 7380553
    },
    {
        "id": "08680",
        "title": "Dynamically Grown Generative Adversarial Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent work introduced progressive network growing as a promising way to ease the training for large GANs, but the model design and architecture-growing strategy still remain under-explored and needs manual design for different image data. In this paper, we propose a method to dynamically grow a GAN during training, optimizing the network architecture and its parameters together with automation. The method embeds architecture search techniques as an interleaving step with gradient-based training to periodically seek the optimal architecture-growing strategy for the generator and discriminator. It enjoys the benefits of both eased training because of progressive growing and improved performance because of broader architecture design space. Experimental results demonstrate new state-of-the-art of image generation. Observations in the search procedure also provide constructive insights into the GAN model design such as generator-discriminator balance and convolutional layer choices.",
        "primary_area": "Machine Learning III",
        "author": "Lanlan Liu; Yuting Zhang; Jia Deng; Stefano Soatto",
        "authorids": "",
        "aff": "University of Michigan, Ann Arbor; Amazon Web Services; Princeton University; Amazon Web Services",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17052/17052-13-20546-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08680-dynamically-grown-generative-adversarial-networks/",
        "doi": "10.1609/aaai.v35i10.17052",
        "pdf_size": 876406
    },
    {
        "id": "00134",
        "title": "ECG ODE-GAN: Learning Ordinary Differential Equations of ECG Dynamics via Generative Adversarial Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Understanding the dynamics of complex biological and physiological systems has been explored  for many years in the form of physically-based mathematical simulators. The behavior of a physical system is often described via ordinary differential equations (ODE), referred to as the dynamics. In the standard case, the dynamics are derived from purely physical considerations. By contrast, in this work we study how the dynamics can be learned by a generative adversarial network which combines both physical and data considerations. As a use case, we focus on the dynamics of the heart signal electrocardiogram (ECG). We begin by introducing a new GAN framework, dubbed ODE-GAN, in which the generator learns the dynamics of a physical system in the form of an ordinary differential equation. Specifically, the generator network receives as input a value at a specific time step, and produces the derivative of the system at that time step. Thus, the ODE-GAN learns purely data-driven dynamics. We then show how to incorporate physical considerations into ODE-GAN. We achieve this through the introduction of an additional input to the ODE-GAN generator: physical parameters, which partially characterize the signal of interest. As we focus on ECG signals, we refer to this new framework as ECG-ODE-GAN. We perform an empirical evaluation and show that generating ECG heartbeats from our learned dynamics improves ECG heartbeat classification.",
        "primary_area": "Application Domains",
        "author": "Tomer Golany; Daniel Freedman; Kira Radinsky",
        "authorids": "",
        "aff": "Technion - Israel Institute of Technology; Google Israel; Technion - Israel Institute Of Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16086/16086-13-19580-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00134-ecg-ode-gan-learning-ordinary-differential-equations-of-ecg-dynamics-via-generative-adversarial-learning/",
        "doi": "10.1609/aaai.v35i1.16086",
        "pdf_size": 1928425
    },
    {
        "id": "12353",
        "title": "EECBS: A Bounded-Suboptimal Search for Multi-Agent Path Finding",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-Agent Path Finding (MAPF), i.e., finding collision-free paths for multiple robots, is important for many applications where small runtimes are necessary, including the kind of automated warehouses operated by Amazon. CBS is a leading two-level search algorithm for solving MAPF optimally. ECBS is a bounded-suboptimal variant of CBS that uses focal search to speed up CBS by sacrificing optimality and instead guaranteeing that the costs of its solutions are within a given factor of optimal. In this paper, we study how to decrease its runtime even further using inadmissible heuristics.  Motivated by Explicit Estimation Search (EES), we propose Explicit Estimation CBS (EECBS), a new bounded-suboptimal variant of CBS, that uses online learning to obtain inadmissible estimates of the cost of the solution of each high-level node and uses EES to choose which high-level node to expand next. We also investigate recent improvements of CBS and adapt them to EECBS.  We find that EECBS with the improvements runs significantly faster than the state-of-the-art bounded-suboptimal MAPF algorithms ECBS, BCP-7, and eMDD-SAT on a variety of MAPF instances. We hope that the scalability of EECBS enables additional applications for bounded-suboptimal MAPF algorithms.",
        "primary_area": "Search and Optimization",
        "author": "Jiaoyang Li; Wheeler Ruml; Sven Koenig",
        "authorids": "",
        "aff": "University of Southern California; University of New Hampshire; University of Southern California",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17466/17466-13-20960-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12353-eecbs-a-bounded-suboptimal-search-for-multi-agent-path-finding/",
        "doi": "10.1609/aaai.v35i14.17466",
        "pdf_size": 2337459
    },
    {
        "id": "03287",
        "title": "EMLight: Lighting Estimation via Spherical Distribution Approximation",
        "track": "main",
        "status": "Poster",
        "abstract": "Illumination estimation from a single image is critical in 3D rendering and it has been investigated extensively in the computer vision and computer graphic research community. On the other hand, existing works estimate illumination by either regressing light parameters or generating illumination maps that are often hard to optimize or tend to produce inaccurate predictions. We propose Earth Mover\u2019s Light (EMLight), an illumination estimation framework that leverages a regression network and a neural projector for accurate illumination estimation. We decompose the illumination map into spherical light distribution, light intensity and the ambient term, and define the illumination estimation as a parameter regression task for the three illumination components. Motivated by the Earth Mover's distance, we design a novel spherical mover's loss that guides to regress light distribution parameters accurately by taking advantage of the subtleties of spherical distribution. Under the guidance of the predicted spherical distribution, light intensity and ambient term, the neural projector synthesizes panoramic illumination maps with realistic light frequency. Extensive experiments show that EMLight achieves accurate illumination estimation and the generated relighting in 3D object embedding exhibits superior plausibility and fidelity as compared with state-of-the-art methods.",
        "primary_area": "Computer Vision III",
        "author": "Fangneng Zhan; Changgong Zhang; Yingchen Yu; Yuan Chang; Shijian Lu; Feiying Ma; Xuansong Xie",
        "authorids": "",
        "aff": "Nanyang Technological University; DAMO Academy, Alibaba Group; Nanyang Technological University; Beijing University of Posts and Telecommunications; Nanyang Technological University; DAMO Academy, Alibaba Group; DAMO Academy, Alibaba Group",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16440/16440-13-19934-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03287-emlight-lighting-estimation-via-spherical-distribution-approximation/",
        "doi": "10.1609/aaai.v35i4.16440",
        "pdf_size": 1952934
    },
    {
        "id": "13143",
        "title": "EQG-RACE: Examination-Type Question Generation",
        "track": "main",
        "status": "Poster",
        "abstract": "Question Generation (QG) is an essential component of the automatic intelligent tutoring systems, which aims to generate high-quality questions for facilitating the reading practice and assessments. However, existing QG technologies encounter several key issues concerning the biased and unnatural language sources of datasets which are mainly obtained from the Web (e.g. SQuAD).  In this paper, we propose an innovative Examination-type Question Generation approach (EQG-RACE) to generate exam-like questions based on a dataset extracted from RACE. Two main strategies are employed in EQG-RACE for dealing with discrete answer information and reasoning among long contexts. A Rough Answer and Key Sentence Tagging scheme is utilized to enhance the representations of input. An Answer-guided Graph Convolutional Network (AG-GCN) is designed to capture structure information in revealing the inter-sentences and intra-sentence relations. Experimental results show a state-of-the-art performance of EQG-RACE, which is apparently superior to the baselines. In addition, our work has established a new QG prototype with a reshaped dataset and QG method, which provides an important benchmark for related research in future work. We will make our data and code publicly available for further research.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Xin Jia; Wenjie Zhou; Xu Sun; Yunfang Wu",
        "authorids": "",
        "aff": "Peking University; Peking University; Peking University; Peking University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17553/17553-13-21047-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13143-eqg-race-examination-type-question-generation/",
        "doi": "10.1609/aaai.v35i14.17553",
        "pdf_size": 432731
    },
    {
        "id": "03208",
        "title": "ERNIE-ViL: Knowledge Enhanced Vision-Language Representations through Scene Graphs",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a knowledge-enhanced approach, ERNIE-ViL, which incorporates structured knowledge obtained from scene graphs to learn joint representations of vision-language. ERNIE-ViL tries to build the detailed semantic connections (objects, attributes of objects and relationships between objects) across vision and language, which are essential to vision-language cross-modal tasks. Utilizing scene graphs of visual scenes, ERNIE-ViL constructs Scene Graph Prediction tasks, i.e., Object Prediction, Attribute Prediction and Relationship Prediction tasks in the pre-training phase. Specifically, these prediction tasks are implemented by predicting nodes of different types in the scene graph parsed from the sentence. Thus, ERNIE-ViL can learn the joint representations characterizing the alignments of the detailed semantics across vision and language. After pre-training on large scale image-text aligned datasets, we validate the effectiveness of ERNIE-ViL on 5 cross-modal downstream tasks. ERNIE-ViL achieves state-of-the-art performances on all these tasks and ranks the first place on the VCR leaderboard with an absolute improvement of 3.7%.",
        "primary_area": "Computer Vision III",
        "author": "Fei Yu; Jiji Tang; Weichong Yin; Yu Sun; Hao Tian; Hua Wu; Haifeng Wang",
        "authorids": "",
        "aff": "Baidu Inc.; Baidu Inc.; Baidu Inc.; Baidu Inc.; Baidu, Inc; Baidu, Inc.; Baidu Inc.",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16431/16431-13-19925-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03208-ernie-vil-knowledge-enhanced-vision-language-representations-through-scene-graphs/",
        "doi": "10.1609/aaai.v35i4.16431",
        "pdf_size": 1525706
    },
    {
        "id": "09988",
        "title": "ESCAPED: Efficient Secure and Private Dot Product Framework for Kernel-based Machine Learning Algorithms with Applications in Healthcare",
        "track": "main",
        "status": "Poster",
        "abstract": "Training sophisticated machine learning models usually requires many training samples. Especially in healthcare settings these samples can be very expensive, meaning that one institution alone usually does not have enough. Merging privacy-sensitive data from different sources is usually restricted by data security and data protection measures. This can lead to approaches that reduce data quality by putting noise onto the variables (e.g., in epsilon-differential privacy) or omitting certain values (e.g., for k-anonymity). Other measures based on cryptographic methods can lead to very time-consuming computations, which is especially problematic for larger multi-omics data. We address this problem by introducing ESCAPED, which stands for Efficient SeCure And PrivatE Dot product framework. ESCAPED enables the computation of the dot product of vectors from multiple sources on a third-party, which later trains kernel-based machine learning algorithms, while neither sacrificing privacy nor adding noise. We have evaluated our framework on drug resistance prediction for HIV-infected people and multi-omics dimensionality reduction and clustering problems in precision medicine. In terms of execution time, our framework significantly outperforms the best-fitting existing approaches without sacrificing the performance of the algorithm. Even though we only present the benefit for kernel-based algorithms, our framework can open up new research opportunities for further machine learning models that require the dot product of vectors from multiple sources.",
        "primary_area": "Machine Learning IV",
        "author": "Ali Burak \u00dcnal; Mete Akg\u00fcn; Nico Pfeifer",
        "authorids": "",
        "aff": "Methods in Medical Informatics, Department of Computer Science, University of Tuebingen, Germany; Methods in Medical Informatics, Department of Computer Science, University of Tuebingen, Germany Translational Bioinformatics, University Hospital Tuebingen, Tuebingen, Germany; Methods in Medical Informatics, Department of Computer Science, University of Tuebingen, Germany Statistical Learning in Computational Biology, Max Planck Institute for Informatics, Saarbr\u00fccken, Germany",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17199/17199-13-20693-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09988-escaped-efficient-secure-and-private-dot-product-framework-for-kernel-based-machine-learning-algorithms-with-applications-in-healthcare/",
        "doi": "10.1609/aaai.v35i11.17199",
        "pdf_size": 390266
    },
    {
        "id": "01325",
        "title": "Edge-competing Pathological Liver Vessel Segmentation with Limited Labels",
        "track": "main",
        "status": "Poster",
        "abstract": "The microvascular invasion (MVI) is a major prognostic factor in hepatocellular carcinoma, which is one of the malignant tumors with the highest mortality rate. The diagnosis of MVI needs discovering the vessels that contain hepatocellular carcinoma cells and counting their number in each vessel, which depends heavily on experiences of the doctor, is largely subjective and  time-consuming. However, there is no algorithm as yet tailored for the MVI detection from  pathological images. This paper collects the first pathological liver image dataset containing $522$ whole slide images with labels of vessels, MVI, and hepatocellular carcinoma grades. The first and essential step for the automatic diagnosis of MVI is the accurate segmentation of vessels. The unique characteristics of pathological liver images, such as super-large size, multi-scale vessel, and blurred vessel edges, make the accurate vessel segmentation challenging. Based on the collected dataset, we propose an Edge-competing Vessel Segmentation Network (EVS-Net), which contains a segmentation network and two edge segmentation discriminators. The segmentation network, combined with an edge-aware self-supervision mechanism, is devised to conduct vessel segmentation with limited labeled patches. Meanwhile, two discriminators are introduced to distinguish whether the segmented vessel and background contain residual features in an adversarial manner. In the training stage, two discriminators are devised to compete for the predicted  position of edges. Exhaustive experiments demonstrate that, with only limited labeled patches, EVS-Net achieves a close performance of fully supervised methods, which provides a convenient tool for the pathological liver vessel segmentation. Code is publicly available at https://github.com/wang97zh/EVS-Net.",
        "primary_area": "Computer Vision I",
        "author": "Zunlei Feng; Zhonghua Wang; Xinchao Wang; Xiuming Zhang; Lechao Cheng; Jie Lei; Yuexuan Wang; Mingli Song",
        "authorids": "",
        "aff": "Zhejiang University Alibaba-Zhejiang University Joint Research Institute of Frontier Technologies; Zhejiang University; Stevens Institute of Technology; Zhejiang University; Zhejiang Lab; Zhejiang University of Technology; Zhejiang University; Zhejiang University Alibaba-Zhejiang University Joint Research Institute of Frontier Technologies",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16221/16221-13-19715-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01325-edge-competing-pathological-liver-vessel-segmentation-with-limited-labels/",
        "doi": "10.1609/aaai.v35i2.16221",
        "pdf_size": 1297913
    },
    {
        "id": "13952",
        "title": "Effective Slot Filling via Weakly-Supervised Dual-Model Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Slot filling is a challenging task in Spoken Language Understanding (SLU). Supervised methods usually require large amounts of annotation to maintain desirable performance. A solution to relieve the heavy dependency on labeled data is to employ bootstrapping, which leverages unlabeled data. However, bootstrapping is known to suffer from semantic drift. We argue that semantic drift can be tackled by exploiting the correlation between slot values (phrases) and their respective types.  By using some particular weakly labeled data, namely the plain phrases included in sentences, we propose a weakly-supervised slot filling approach.  Our approach trains two models, namely a classifier and a tagger, which can effectively learn from each other on the weakly labeled data.  The experimental results demonstrate that our approach achieves better results than standard baselines on multiple datasets, especially in the low-resource setting.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Jue Wang; Ke Chen; Lidan Shou; Sai Wu; Gang Chen",
        "authorids": "",
        "aff": "Zhejiang University; Zhejiang University; Zhejiang University; Zhejiang University; Zhejiang University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17643/17643-13-21137-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13952-effective-slot-filling-via-weakly-supervised-dual-model-learning/",
        "doi": "10.1609/aaai.v35i16.17643",
        "pdf_size": 390369
    },
    {
        "id": "12328",
        "title": "Efficient Bayesian Network Structure Learning via Parameterized Local Search on Topological Orderings",
        "track": "main",
        "status": "Poster",
        "abstract": "In Bayesian Network Structure Learning (BNSL), we are given a variable set and parent scores for each variable and aim to compute a DAG, called Bayesian network, that maximizes the sum of parent scores, possibly under some structural constraints. Even very restricted special cases of BNSL are computationally hard, and, thus, in practice heuristics such as local search are used. In a typical local search algorithm, we are given some BNSL solution and ask whether there is a better solution within some pre-defined neighborhood of the solution. We study ordering-based local search, where a solution is described via a topological ordering of the variables. We show that given such a topological ordering, we can compute an optimal DAG whose ordering is within inversion distance r in subexponential FPT time; the parameter r allows to balance between solution quality and running time of the local search algorithm. This running time bound can be achieved for BNSL without any structural constraints and for all structural constraints that can be expressed via a sum of weights that are associated with each parent set. We show that for other modification operations on the variable orderings, algorithms with an FPT time for r are unlikely. We also outline the limits of ordering-based local search by showing that it cannot be used for common structural constraints on the moralized graph of the network.",
        "primary_area": "Search and Optimization",
        "author": "Niels Gr\u00fcttemeier; Christian Komusiewicz; Nils Morawietz",
        "authorids": "",
        "aff": "Philipps-Universit\u00e4t Marburg; Philipps-Universit\u00e4t Marburg; Philipps-Universit\u00e4t Marburg",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17463/17463-13-20957-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12328-efficient-bayesian-network-structure-learning-via-parameterized-local-search-on-topological-orderings/",
        "doi": "10.1609/aaai.v35i14.17463",
        "pdf_size": 162921
    },
    {
        "id": "02504",
        "title": "Efficient Certification of Spatial Robustness",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent work has exposed the vulnerability of computer vision models to vector field attacks. Due to the widespread usage of such models in safety-critical applications, it is crucial to quantify their robustness against such spatial transformations. However, existing work only provides empirical robustness quantification against vector field deformations via adversarial attacks, which lack provable guarantees. In this work, we propose novel convex relaxations, enabling us, for the first time, to provide a certificate of robustness against vector field transformations. Our relaxations are model-agnostic and can be leveraged by a wide range of neural network verifiers. Experiments on various network architectures and different datasets demonstrate the effectiveness and scalability of our method.",
        "primary_area": "Computer Vision II",
        "author": "Anian Ruoss; Maximilian Baader; Mislav Balunovi\u0107; Martin Vechev",
        "authorids": "",
        "aff": "ETH Zurich; ETH Zurich; ETH Zurich; ETH Zurich",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16352/16352-13-19846-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02504-efficient-certification-of-spatial-robustness/",
        "doi": "10.1609/aaai.v35i3.16352",
        "pdf_size": 502544
    },
    {
        "id": "11007",
        "title": "Efficient Classification with Adaptive KNN",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose an adaptive kNN method for classification, in which different k are selected for different test samples. Our selection rule is easy to implement since it is completely adaptive and does not require any knowledge of the underlying distribution. The convergence rate of the risk of this classifier to the Bayes risk is shown to be minimax optimal for various settings. Moreover, under some special assumptions, the convergence rate is especially fast and does not decay with the increase of dimensionality.",
        "primary_area": "Machine Learning V",
        "author": "Puning Zhao; Lifeng Lai",
        "authorids": "",
        "aff": "University of California Davis; University of California Davis",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17314/17314-13-20808-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11007-efficient-classification-with-adaptive-knn/",
        "doi": "10.1609/aaai.v35i12.17314",
        "pdf_size": 219453
    },
    {
        "id": "03039",
        "title": "Efficient Deep Image Denoising via Class Specific Convolution",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep neural networks have been widely used in image denoising during the past few years. Even though they achieve great success on this problem, they are computationally inefficient which makes them inappropriate to be implemented in mobile devices. In this paper, we propose an efficient deep neural network for image denoising based on pixel-wise classification. Despite using a computationally efficient network cannot effectively remove the noises from any content, it is still capable to denoise from a specific type of pattern or texture. The proposed method follows such a divide and conquer scheme. We first use an efficient U-net to pixel-wisely classify pixels in the noisy image based on the local gradient statistics.Then we replace part of the convolution layers in existing denoising networks by the proposed Class Specific Convolution layers (CSConv) which use different weights for different classes of pixels. Quantitative and qualitative evaluations on public datasets demonstrate that the proposed method can reduce the computational costs without sacrificing the performance compared to state-of-the-art algorithms.",
        "primary_area": "Computer Vision III",
        "author": "Lu Xu; Jiawei Zhang; Xuanye Cheng; Feng Zhang; Xing Wei; Jimmy Ren",
        "authorids": "",
        "aff": "The Chinese University of Hong Kong; SenseTime Research; SenseTime Research; SenseTime Research; School of Software Engineering, Xi'an Jiaotong University; SenseTime Research Qing Yuan Research Institute, Shanghai Jiao Tong University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16412/16412-13-19906-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03039-efficient-deep-image-denoising-via-class-specific-convolution/",
        "doi": "10.1609/aaai.v35i4.16412",
        "pdf_size": 1951118
    },
    {
        "id": "10868",
        "title": "Efficient Folded Attention for Medical Image Reconstruction and Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "Recently, 3D medical image reconstruction (MIR) and segmentation (MIS) based on deep neural networks have been developed with promising results, and attention mechanism has been further designed for performance enhancement. However, the large size of 3D volume images poses a great computational challenge to traditional attention methods.  In this paper, we propose a folded attention (FA) approach to improve the computational efficiency of traditional attention methods on 3D medical images.  The main idea is that we apply tensor folding and unfolding operations to construct four small sub-affinity matrices to approximate the original affinity matrix. Through four consecutive sub-attention modules of FA, each element in the feature tensor can aggregate spatial-channel information from all other elements. Compared to traditional attention methods, with the moderate improvement of accuracy, FA can substantially reduce the computational complexity and GPU memory consumption. We demonstrate the superiority of our method on two challenging tasks for 3D MIR and MIS, which are quantitative susceptibility mapping and multiple sclerosis lesion segmentation.",
        "primary_area": "Machine Learning V",
        "author": "Hang Zhang; Jinwei Zhang; Rongguang Wang; Qihao Zhang; Pascal Spincemaille; Thanh D. Nguyen; Yi Wang",
        "authorids": "",
        "aff": "Cornell University Weill Cornell Medical College; Cornell University Weill Cornell Medical College; University of Pennsylvania; Cornell University Weill Cornell Medical College; Cornell University; Cornell University; Cornell University Weill Cornell Medical College",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17298/17298-13-20792-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10868-efficient-folded-attention-for-medical-image-reconstruction-and-segmentation/",
        "doi": "10.1609/aaai.v35i12.17298",
        "pdf_size": 4629862
    },
    {
        "id": "03438",
        "title": "Efficient License Plate Recognition via Holistic Position Attention",
        "track": "main",
        "status": "Poster",
        "abstract": "License plate recognition (LPR) is a fundamental component of various intelligent transportation systems, and is always expected to be accurate and efficient enough in real-world applications. Nowadays, recognition of single character has been sophisticated benefiting from the power of deep learning, and extracting position information for forming a character sequence becomes the main bottleneck of LPR. To tackle this issue, we propose a novel holistic position attention (HPA) in this paper that consists of position network and shared classifier. Specifically, the position network explicitly encodes the character position into the maps of HPA, and then the shared classifier performs the character recognition in a unified and parallel way. Here the extracted features are modulated by the attention maps before feeding into the classifier to yield the final recognition results. Note that our proposed method is end-to-end trainable, character recognition can be concurrently performed, and no post-processing is needed. Thus our LPR system can achieve good effectiveness and efficiency simultaneously. The experimental results on four public datasets, including AOLP, Media Lab, CCPD, and CLPD, well demonstrate the superiority of our method to previous state-of-the-art methods in both accuracy and speed.",
        "primary_area": "Computer Vision III",
        "author": "Yesheng Zhang; Zilei Wang; Jiafan Zhuang",
        "authorids": "",
        "aff": "University of Science and Technology of China; University of Science and Technology of China; University of Science and Technology of China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16457/16457-13-19951-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03438-efficient-license-plate-recognition-via-holistic-position-attention/",
        "doi": "10.1609/aaai.v35i4.16457",
        "pdf_size": 2428646
    },
    {
        "id": "02720",
        "title": "Efficient Object-Level Visual Context Modeling for Multimodal Machine Translation: Masking Irrelevant Objects Helps Grounding",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual context provides grounding information for multimodal machine translation (MMT). However, previous MMT models and probing studies on visual features suggest that visual information is less explored in MMT as it is often redundant to textual information. In this paper, we propose an Object-level Visual Context modeling framework (OVC) to efficiently capture and explore visual information for multimodal machine translation. With detected objects, the proposed OVC encourages MMT to ground translation on desirable visual objects by masking irrelevant objects in the visual modality. We equip the proposed with an additional object-masking loss to achieve this goal. The object-masking loss is estimated according to the similarity between masked objects and the source texts so as to encourage masking source-irrelevant objects. Additionally, in order to generate vision-consistent target words, we further propose a vision-weighted translation loss for OVC. Experiments on MMT datasets demonstrate that the proposed OVC model outperforms state-of-the-art MMT models and analyses show that masking irrelevant objects helps grounding in MMT.",
        "primary_area": "Computer Vision III",
        "author": "Dexin Wang; Deyi Xiong",
        "authorids": "",
        "aff": "Tianjin University; Tianjin University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16376/16376-13-19870-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02720-efficient-object-level-visual-context-modeling-for-multimodal-machine-translation-masking-irrelevant-objects-helps-grounding/",
        "doi": "10.1609/aaai.v35i4.16376",
        "pdf_size": 2556474
    },
    {
        "id": "07583",
        "title": "Efficient On-Chip Learning for Optical Neural Networks Through Power-Aware Sparse Zeroth-Order Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "Optical neural networks (ONNs) have demonstrated record-breaking potential in high-performance neuromorphic computing due to their ultra-high execution speed and low energy consumption. However, current learning protocols fail to provide scalable and efficient solutions to photonic circuit optimization in practical applications. In this work, we propose a novel on-chip learning framework to release the full potential of ONNs for power-efficient in situ training. Instead of deploying implementation-costly back-propagation, we directly optimize the device configurations with computation budgets and power constraints. We are the first to model the ONN on-chip learning as a resource-constrained stochastic noisy zeroth-order optimization problem, and propose a novel mixed-training strategy with two-level sparsity and power-aware dynamic pruning to offer a scalable on-chip training solution in practical ONN deployment. Compared with previous methods, we are the first to optimize over 2,500 optical components on chip. We can achieve much better optimization stability, 3.7x-7.6x higher efficiency, and save >90% power under practical device variations and thermal crosstalk.",
        "primary_area": "Machine Learning II",
        "author": "Jiaqi Gu; Chenghao Feng; Zheng Zhao; Zhoufeng Ying; Ray T. Chen; David Z. Pan",
        "authorids": "",
        "aff": "University of Texas at Austin; University of Texas at Austin; Synopsys, Inc.; Alpine Optoelectronics, Inc.; University of Texas at Austin; University of Texas at Austin",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16928/16928-13-20422-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07583-efficient-on-chip-learning-for-optical-neural-networks-through-power-aware-sparse-zeroth-order-optimization/",
        "doi": "10.1609/aaai.v35i9.16928",
        "pdf_size": 1660873
    },
    {
        "id": "03967",
        "title": "Efficient Optimal Selection for Composited Advertising Creatives with Tree Structure",
        "track": "main",
        "status": "Poster",
        "abstract": "Ad creatives are one of the prominent mediums for online e-commerce advertisements. Ad creatives with enjoyable visual appearance may increase the click-through rate (CTR) of products. Ad creatives are typically handcrafted by advertisers and then delivered to the advertising platforms for advertisement. In recent years, advertising platforms are capable of instantly compositing ad creatives with arbitrarily designated elements of each ingredient, so advertisers are only required to provide basic materials. While facilitating the advertisers, a great number of potential ad creatives can be composited, making it difficult to accurately estimate CTR for them given limited real-time feedback. To this end, we propose an Adaptive and Efficient ad creative Selection (AES) framework based on a tree structure. The tree structure on compositing ingredients enables dynamic programming for efficient ad creative selection on the basis of CTR. Due to limited feedback, the CTR estimator is usually of high variance. Exploration techniques based on Thompson sampling are widely used for reducing variances of the CTR estimator, alleviating feedback sparsity. Based on the tree structure, Thompson sampling is adapted with dynamic programming, leading to efficient exploration for potential ad creatives with the largest CTR. We finally evaluate the proposed algorithm on the synthetic dataset and the real-world dataset. The results show that our approach can outperform competing baselines in terms of convergence rate and overall CTR.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Jin Chen; Tiezheng Ge; Gangwei Jiang; Zhiqiang Zhang; Defu Lian; Kai Zheng",
        "authorids": "",
        "aff": "University of Electronic Science and Technology of China; Alibaba Group; University of Science and Technology of China; Alibaba group; University of Science and Technology of China; University of Electronic Science and Technology of China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16516/16516-13-20010-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03967-efficient-optimal-selection-for-composited-advertising-creatives-with-tree-structure/",
        "doi": "10.1609/aaai.v35i5.16516",
        "pdf_size": 686007
    },
    {
        "id": "00012",
        "title": "Efficient Poverty Mapping from High Resolution Remote Sensing Images",
        "track": "main",
        "status": "Poster",
        "abstract": "The combination of high-resolution satellite imagery and machine learning have proven useful in many sustainability-related tasks, including poverty prediction, infrastructure measurement, and forest monitoring. However, the accuracy afforded by high-resolution imagery comes at a cost, as such imagery is extremely expensive to purchase at scale. This creates a substantial hurdle to the efficient scaling and widespread adoption of high-resolution-based approaches.  To reduce acquisition costs while maintaining accuracy, we propose a reinforcement learning approach in which free low-resolution imagery is used to dynamically identify where to acquire costly high-resolution images, prior to performing a deep learning task on the high-resolution images. We apply this approach to the task of poverty prediction in Uganda, building on an earlier approach that used object detection to count objects and use these counts to predict poverty. Our approach exceeds previous performance benchmarks on this task while using 80% fewer high-resolution images, and could be useful in many domains that require high-resolution imagery.",
        "primary_area": "Application Domains",
        "author": "Kumar Ayush; Burak Uzkent; Kumar Tanmay; Marshall Burke; David Lobell; Stefano Ermon",
        "authorids": "",
        "aff": "Department of Computer Science, Stanford University; Department of Computer Science, Stanford University; Department of Electrical Engineering, IIT Kharagpur; Department of Earth Science, Stanford University; Department of Earth Science, Stanford University; Department of Computer Science, Stanford University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16072/16072-13-19566-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00012-efficient-poverty-mapping-from-high-resolution-remote-sensing-images/",
        "doi": "10.1609/aaai.v35i1.16072",
        "pdf_size": 3987455
    },
    {
        "id": "11378",
        "title": "Efficient Querying for Cooperative Probabilistic Commitments",
        "track": "main",
        "status": "Poster",
        "abstract": "Multiagent systems can use commitments as the core of a general coordination infrastructure, supporting both cooperative and non-cooperative interactions. Agents whose objectives are aligned, and where one agent can help another achieve greater reward by sacrificing some of its own reward, should choose a cooperative commitment to maximize their joint reward. We present a solution to the problem of how cooperative agents can efficiently find an (approximately) optimal commitment by querying about carefully-selected commitment choices. We prove structural properties of the agents' values as functions of the parameters of the commitment specification, and develop a greedy method for composing a query with provable approximation bounds, which we empirically show can find nearly optimal commitments in a fraction of the time methods that lack our insights require.",
        "primary_area": "Multiagent Systems",
        "author": "Qi Zhang; Edmund H. Durfee; Satinder Singh",
        "authorids": "",
        "aff": "University of South Carolina; University of Michigan; University of Michigan",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17356/17356-13-20850-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11378-efficient-querying-for-cooperative-probabilistic-commitments/",
        "doi": "10.1609/aaai.v35i13.17356",
        "pdf_size": 3369892
    },
    {
        "id": "05423",
        "title": "Efficient Truthful Scheduling and Resource Allocation through Monitoring",
        "track": "main",
        "status": "Poster",
        "abstract": "We study the power and limitations of the Vickrey-Clarke-Groves mechanism with monitoring (VCGmon) for cost minimization problems with objective functions that are more general than the social cost. We identify a simple and natural sufficient condition for VCGmon to be truthful for general objectives. As a consequence, we obtain that for any cost minimization problem with non-decreasing objective \u03bc, VCGmon is truthful, if the allocation is Maximal-in-Range and \u03bc is 1-Lipschitz (e.g., \u03bc can be the Lp-norm of the agents\u2019 costs, for any p \u2265 1 or p = \u221e). We apply VCGmon to scheduling on restricted-related machines and obtain a polynomial-time truthful-in-expectation 2-approximate (resp. O(1)-approximate) mechanism for makespan (resp. Lp- norm) minimization. Moreover, applying VCGmon, we obtain polynomial-time truthful O(1)-approximate mechanisms for some fundamental bottleneck network optimization problems with single-parameter agents. On the negative side, we provide strong evidence that VCGmon could not lead to computationally efficient truthful mechanisms with reasonable approximation ratios for binary covering social cost minimization problems. However, we show that VCGmon results in computationally efficient approximately truthful mechanisms for binary covering problems.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Dimitris Fotakis; Piotr Krysta; Carmine Ventre",
        "authorids": "",
        "aff": "National Technical University of Athens; University of Liverpool; King's College London",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16683/16683-13-20177-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05423-efficient-truthful-scheduling-and-resource-allocation-through-monitoring/",
        "doi": "10.1609/aaai.v35i6.16683",
        "pdf_size": 156813
    },
    {
        "id": "01487",
        "title": "EfficientDeRain: Learning Pixel-wise Dilation Filtering for High-Efficiency Single-Image Deraining",
        "track": "main",
        "status": "Poster",
        "abstract": "Single-image deraining is rather challenging due to the unknown rain model. Existing methods often make specific assumptions of the rain model, which can hardly cover many diverse circumstances in the real world, compelling them to employ complex optimization or progressive refinement. This, however, significantly affects these methods' efficiency and effectiveness for many efficiency-critical applications. To fill this gap, in this paper, we regard the single-image deraining as a general image-enhancing problem and originally propose a model-free deraining method, i.e., EfficientDeRain, which is able to process a rainy image within 10 ms (i.e., around 6 ms on average), over 80 times faster than the state-of-the-art method (i.e., RCDNet), while achieving similar de-rain effects. We first propose novel pixel-wise dilation filtering. In particular, a rainy image is filtered with the pixel-wise kernels estimated from a kernel prediction network, by which suitable multi-scale kernels for each pixel can be efficiently predicted. Then, to eliminate the gap between synthetic and real data, we further propose an effective data augmentation method (i.e., RainMix) that helps to train the network for handling real rainy images. We perform a comprehensive evaluation on both synthetic and real-world rainy datasets to demonstrate the effectiveness and efficiency of our method. We release the model and code in https://github.com/tsingqguo/efficientderain.git.",
        "primary_area": "Computer Vision I",
        "author": "Qing Guo; Jingyang Sun; Felix Juefei-Xu; Lei Ma; Xiaofei Xie; Wei Feng; Yang Liu; Jianjun Zhao",
        "authorids": "",
        "aff": "Nanyang Technological University, Singapore; Kyushu University, Japan; Alibaba Group, USA; Kyushu University, Japan; Nanyang Technological University, Singapore; College of Intelligence and Computing, Tianjin University, China; Nanyang Technology University, Singapore; Kyushu University, Japan",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16239/16239-13-19733-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01487-efficientderain-learning-pixel-wise-dilation-filtering-for-high-efficiency-single-image-deraining/",
        "doi": "10.1609/aaai.v35i2.16239",
        "pdf_size": 14831682
    },
    {
        "id": "09037",
        "title": "Elastic Consistency: A Practical Consistency Model for Distributed Stochastic Gradient Descent",
        "track": "main",
        "status": "Poster",
        "abstract": "One key element behind the recent progress of machine learning has been the ability to train machine learning models in large-scale distributed shared-memory and message-passing environments. Most of these models are trained  employing variants of stochastic gradient descent (SGD) based optimization, but most methods involve some type of consistency relaxation relative to sequential SGD, to mitigate its large communication or synchronization costs at scale.  In this paper, we introduce a general consistency condition covering communication-reduced and asynchronous distributed SGD implementations.  Our framework, called elastic consistency, decouples the system-specific aspects of the implementation from the SGD convergence requirements, giving a general way to obtain convergence bounds for a wide variety of distributed SGD methods used in practice. Elastic consistency can be used to re-derive or improve several previous convergence bounds in message-passing and shared-memory settings, but also to analyze new models and distribution schemes. As a direct application, we propose and analyze a new synchronization-avoiding scheduling scheme for distributed SGD, and show that it can be used to efficiently train deep convolutional models for image classification.",
        "primary_area": "Machine Learning III",
        "author": "Giorgi Nadiradze; Ilia Markov; Bapi Chatterjee; Vyacheslav Kungurtsev; Dan Alistarh",
        "authorids": "",
        "aff": "IST Austria; IST Austria; IST Austria; Czech Technical University in Prague; IST Austria",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17092/17092-13-20586-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09037-elastic-consistency-a-practical-consistency-model-for-distributed-stochastic-gradient-descent/",
        "doi": "10.1609/aaai.v35i10.17092",
        "pdf_size": 188275
    },
    {
        "id": "10147",
        "title": "Embedding Heterogeneous Networks into Hyperbolic Space Without Meta-path",
        "track": "main",
        "status": "Poster",
        "abstract": "Networks found in the real-world are numerous and varied. A common type of network is the heterogeneous network, where the nodes (and edges) can be of different types. Accordingly, there have been efforts at learning representations of these heterogeneous networks in low-dimensional space. However, most of the existing heterogeneous network embedding suffers from the following two drawbacks: (1) The target space is usually Euclidean. Conversely, many recent works have shown that complex networks may have hyperbolic latent anatomy, which is non-Euclidean. (2) These methods usually rely on meta-paths, which requires domain-specific prior knowledge for meta-path selection. Additionally, different down-streaming tasks on the same network might require different meta-paths in order to generate task-specific embeddings. In this paper, we propose a novel self-guided random walk method that does not require meta-path for embedding heterogeneous networks into hyperbolic space. We conduct thorough experiments for the tasks of network reconstruction and link prediction on two public datasets, showing that our model outperforms a variety of well-known baselines across all tasks.",
        "primary_area": "Machine Learning IV",
        "author": "Lili Wang; Chongyang Gao; Chenghan Huang; Ruibo Liu; Weicheng Ma; Soroush Vosoughi",
        "authorids": "",
        "aff": "Dartmouth College; Dartmouth College; Millennium Management Llc; Dartmouth College; Dartmouth College; Dartmouth College",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17217/17217-13-20711-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10147-embedding-heterogeneous-networks-into-hyperbolic-space-without-meta-path/",
        "doi": "10.1609/aaai.v35i11.17217",
        "pdf_size": 1090176
    },
    {
        "id": "02373",
        "title": "Embodied Visual Active Learning for Semantic Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "We study the task of embodied visual active learning, where an agent is set to explore a 3d environment with the goal to acquire visual scene understanding by actively selecting views for which to request annotation. While accurate on some benchmarks, today's deep visual recognition pipelines tend to not generalize well in certain real-world scenarios, or for unusual viewpoints. Robotic perception, in turn, requires the capability to refine the recognition capabilities for the conditions where the mobile system operates, including cluttered indoor environments or poor illumination. This motivates the proposed task, where an agent is placed in a novel environment with the objective of improving its visual recognition capability. To study embodied visual active learning, we develop a battery of agents - both learnt and pre-specified - and with different levels of knowledge of the environment. The agents are equipped with a semantic segmentation network and seek to acquire informative views, move and explore in order to propagate annotations in the neighbourhood of those views, then refine the underlying segmentation network by online retraining. The trainable method uses deep reinforcement learning with a reward function that balances two competing objectives: task performance, represented as visual recognition accuracy, which requires exploring the environment, and the necessary amount of annotated data requested during active exploration. We extensively evaluate the proposed models using the photorealistic Matterport3D simulator and show that a fully learnt method outperforms comparable pre-specified counterparts, even when requesting fewer annotations.",
        "primary_area": "Computer Vision II",
        "author": "David Nilsson; Aleksis Pirinen; Erik G\u00e4rtner; Cristian Sminchisescu",
        "authorids": "",
        "aff": "Lund University Google Research; Lund University; Lund University Google Research; Lund University Google Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16338/16338-13-19832-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02373-embodied-visual-active-learning-for-semantic-segmentation/",
        "doi": "10.1609/aaai.v35i3.16338",
        "pdf_size": 7456081
    },
    {
        "id": "00557",
        "title": "Embracing Domain Differences in Fake News: Cross-domain Fake News Detection using Multi-modal Data",
        "track": "main",
        "status": "Poster",
        "abstract": "With the rapid evolution of social media, fake news has become a significant social problem, which cannot be addressed in a timely manner using manual investigation. This has motivated numerous studies on automating fake news detection. Most studies explore supervised training models with different modalities (e.g., text, images, and propagation networks) of news records to identify fake news. However, the performance of such techniques generally drops if news records are coming from different domains (e.g., politics, entertainment), especially for domains that are unseen or rarely-seen during training. As motivation, we empirically show that news records from different domains have significantly different word usage and propagation patterns. Furthermore, due to the sheer volume of unlabelled news records, it is challenging to select news records for manual labelling so that the domain-coverage of the labelled dataset is maximised. Hence, this work: (1) proposes a novel framework that jointly preserves domain-specific and cross-domain knowledge in news records to detect fake news from different domains; and (2) introduces an unsupervised technique to select a set of unlabelled informative news records for manual labelling, which can be ultimately used to train a fake news detection model that performs well for many domains while minimizing the labelling cost. Our experiments show that the integration of the proposed fake news model and the selective annotation approach achieves state-of-the-art performance for cross-domain news datasets, while yielding notable improvements for rarely-appearing domains in news datasets.",
        "primary_area": "Application Domains",
        "author": "Amila Silva; Ling Luo; Shanika Karunasekera; Christopher Leckie",
        "authorids": "",
        "aff": "The University of Melbourne; University of Melbourne; The University of Melbourne, Australia; University of Melbourne",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16134/16134-13-19628-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00557-embracing-domain-differences-in-fake-news-cross-domain-fake-news-detection-using-multi-modal-data/",
        "doi": "10.1609/aaai.v35i1.16134",
        "pdf_size": 311711
    },
    {
        "id": "12471",
        "title": "Empirical Regularization for Synthetic Sentence Pairs in Unsupervised Neural Machine Translation",
        "track": "main",
        "status": "Poster",
        "abstract": "UNMT tackles translation on monolingual corpora in two required languages. Since there is no explicitly cross-lingual signal, pre-training and synthetic sentence pairs are significant to the success of UNMT. In this work, we empirically study the core training procedure of UNMT to analyze the synthetic sentence pairs obtained from back-translation. We introduce new losses to UNMT to regularize the synthetic sentence pairs by jointly training the UNMT objective and the regularization objective. Our comprehensive experiments support that our method can generally improve the performance of currently successful models on three similar pairs {French, German, Romanian}  English  and one dissimilar pair Russian  English  with acceptably additional cost.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Xi Ai; Bin Fang",
        "authorids": "",
        "aff": "College of Computer Science, Chongqing University; College of Computer Science, Chongqing University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17479/17479-13-20973-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12471-empirical-regularization-for-synthetic-sentence-pairs-in-unsupervised-neural-machine-translation/",
        "doi": "10.1609/aaai.v35i14.17479",
        "pdf_size": 147561
    },
    {
        "id": "12675",
        "title": "Empower Distantly Supervised Relation Extraction with Collaborative Adversarial Training",
        "track": "main",
        "status": "Poster",
        "abstract": "With recent advances in distantly supervised (DS) relation extraction (RE), considerable attention is attracted to leverage multi-instance learning (MIL) to distill high-quality supervision from the noisy DS. Here, we go beyond label noise and identify the key bottleneck of DS-MIL to be its low data utilization: as high-quality supervision being refined by MIL, MIL abandons a large amount of training instances, which leads to a low data utilization and hinders model training from having abundant supervision. In this paper, we propose collaborative adversarial training to improve the data utilization, which coordinates virtual adversarial training (VAT) and adversarial training (AT) at different levels. Specifically, since VAT is label-free, we employ the instance-level VAT to recycle instances abandoned by MIL. Besides, we deploy AT at the bag-level to unleash the full potential of the high-quality supervision got by MIL. Our proposed method brings consistent improvements (\u223c 5 absolute AUC score) to the previous state of the art, which verifies the importance of the data utilization issue and the effectiveness of our method.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Tao Chen; Haochen Shi; Liyuan Liu; Siliang Tang; Jian Shao; Zhigang Chen; Yueting Zhuang",
        "authorids": "",
        "aff": "Zhejiang University; Zhejiang University; University of Illinois at Urbana Champaign; Zhejiang University; Zhejiang University; iFLYTEK Research; Zhejiang University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17501/17501-13-20995-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12675-empower-distantly-supervised-relation-extraction-with-collaborative-adversarial-training/",
        "doi": "10.1609/aaai.v35i14.17501",
        "pdf_size": 1445987
    },
    {
        "id": "09825",
        "title": "Empowering Adaptive Early-Exit Inference with Latency Awareness",
        "track": "main",
        "status": "Poster",
        "abstract": "With the capability of trading accuracy for latency on-the-fly, the technique of adaptive early-exit inference has emerged as a promising line of research to accelerate the deep learning inference. However, studies in this line of research commonly use a group of thresholds to control the accuracy-latency trade-off, where a thorough and general methodology on how to determine these thresholds has not been conducted yet, especially with regard to the common requirements of average inference latency. To address this issue and enable latency-aware adaptive early-exit inference, in the present paper, we approximately formulate the threshold determination problem of finding the accuracy-maximum threshold setting that meets a given average latency requirement, and then propose a threshold determination method to tackle our formulated non-convex problem. Theoretically, we prove that, for certain parameter settings, our method finds an approximate stationary point of the formulated problem. Empirically, on top of various models across multiple datasets (CIFAR-10, CIFAR-100, ImageNet and two time-series datasets), we show that our method can well handle the average latency requirements, and consistently finds good threshold settings in negligible time.",
        "primary_area": "Machine Learning IV",
        "author": "Xinrui Tan; Hongjia Li; Liming Wang; Xueqing Huang; Zhen Xu",
        "authorids": "",
        "aff": "Institute of Information Engineering, Chinese Academy of Sciences; Institute of Information Engineering, Chinese Academy of Sciences; Institute of Information Engineering, Chinese Academy of Sciences; New York Institute of Technology; Institute of Information Engineering, Chinese Academy of Sciences",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17181/17181-13-20675-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09825-empowering-adaptive-early-exit-inference-with-latency-awareness/",
        "doi": "10.1609/aaai.v35i11.17181",
        "pdf_size": 2840176
    },
    {
        "id": "06075",
        "title": "Enabling Fast Instruction-Based Modification of Learned Robot Skills",
        "track": "main",
        "status": "Poster",
        "abstract": "Much research effort in HRI has focused on how to enable robots to learn new skills from observations, demonstrations, and instructions. Less work, however, has focused on how skills can be corrected if they were learned incorrectly, adapted to changing circumstances, or generalized/specialized to different contexts. In this paper, a skill modification framework is introduced that allows users to modify a robot\u2019s stored skills quickly through instructions to (1) reduce inefficiencies, (2) fix errors, and (3) enable generalizations, all in a way for modified skills to be immediately available for task performance. A thorough evaluation of the implemented framework shows the operation of the algorithms integrated in a cognitive robotic architecture on different fully autonomous robots in various HRI case studies. An additional online HRI user study verifies that subjects prefer to quickly modify robot knowledge in the way we proposed in the framework.",
        "primary_area": "Intelligent Robots",
        "author": "Tyler Frasca; Bradley Oosterveld; Meia Chita-Tegmark; Matthias Scheutz",
        "authorids": "",
        "aff": "Tufts University; Thinking Robots; Tufts University; Tufts University Thinking Robots",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16757/16757-13-20251-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06075-enabling-fast-instruction-based-modification-of-learned-robot-skills/",
        "doi": "10.1609/aaai.v35i7.16757",
        "pdf_size": 7834880
    },
    {
        "id": "14129",
        "title": "Enabling Fast and Universal Audio Adversarial Attack Using Generative Model",
        "track": "main",
        "status": "Poster",
        "abstract": "Recently, the vulnerability of deep neural network (DNN)-based audio systems to adversarial attacks has obtained increasing attention. However, the existing audio adversarial attacks allow the adversary to possess the entire user's audio input as well as granting sufficient time budget to generate the adversarial perturbations. These idealized assumptions, however, make the existing audio adversarial attacks mostly impossible to be launched in a timely fashion in practice (e.g., playing unnoticeable adversarial perturbations along with user's streaming input). To overcome these limitations, in this paper we propose fast audio adversarial perturbation generator (FAPG), which uses generative model to generate adversarial perturbations for the audio input in a single forward pass, thereby drastically improving the perturbation generation speed. Built on the top of FAPG, we further propose universal audio adversarial perturbation generator (UAPG), a scheme to craft universal adversarial perturbation that can be imposed on arbitrary benign audio input to cause misclassification. Extensive experiments on DNN-based audio systems show that our proposed FAPG can achieve high success rate with up to 214X speedup over the existing audio adversarial attack methods. Also our proposed UAPG generates universal adversarial perturbations that can achieve much better attack performance than the state-of-the-art solutions.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Yi Xie; Zhuohang Li; Cong Shi; Jian Liu; Yingying Chen; Bo Yuan",
        "authorids": "",
        "aff": "Rutgers University; The University of Tennessee, Knoxville; Rutgers University; The University of Tennessee, Knoxville; Rutgers University; Rutgers university",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17663/17663-13-21157-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14129-enabling-fast-and-universal-audio-adversarial-attack-using-generative-model/",
        "doi": "10.1609/aaai.v35i16.17663",
        "pdf_size": 351123
    },
    {
        "id": "12794",
        "title": "Encoder-Decoder Based Unified Semantic Role Labeling with Label-Aware Syntax",
        "track": "main",
        "status": "Poster",
        "abstract": "Currently the unified semantic role labeling (SRL) that achieves predicate identification and argument role labeling in an end-to-end manner has received growing interests. Recent works show that leveraging the syntax knowledge significantly enhances the SRL performances. In this paper, we investigate a novel unified SRL framework based on the sequence-to-sequence architecture with double enhancement in both the encoder and decoder sides. In the encoder side, we propose a novel label-aware graph convolutional network (LA-GCN) to encode both the syntactic dependent arcs and labels into BERT-based word representations. In the decoder side, we creatively design a pointer-network-based model for detecting predicates, arguments and roles jointly. Our pointer-net decoder is able to make decisions by consulting all the input elements in a global view, and meanwhile it is syntactic-aware by incorporating the syntax information from LA-GCN. Besides, a high-order interacted attention is introduced into the decoder for leveraging previously recognized triplets to help the current decision. Empirical experiments show that our framework significantly outperforms all existing graph-based methods on the CoNLL09 and Universal Proposition Bank datasets. In-depth analysis demonstrates that our model can effectively capture the correlations between syntactic and SRL structures.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Hao Fei; Fei Li; Bobo Li; Donghong Ji",
        "authorids": "",
        "aff": "Wuhan University; Wuhan University; Wuhan University; Wuhan University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17514/17514-13-21008-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12794-encoder-decoder-based-unified-semantic-role-labeling-with-label-aware-syntax/",
        "doi": "10.1609/aaai.v35i14.17514",
        "pdf_size": 522169
    },
    {
        "id": "05042",
        "title": "Encoding Human Domain Knowledge to Warm Start Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep reinforcement learning has been successful in a variety of tasks, such as game playing and robotic manipulation. However, attempting to learn tabula rasa disregards the logical structure of many domains as well as the wealth of readily available knowledge from domain experts that could help \"warm start\" the learning process. We present a novel reinforcement learning technique that allows for intelligent initialization of a neural network weights and architecture. Our approach permits the encoding domain knowledge directly into a neural decision tree, and improves upon that knowledge with policy gradient updates. We empirically validate our approach on two OpenAI Gym tasks and two modified StarCraft 2 tasks, showing that our novel architecture outperforms multilayer-perceptron and recurrent architectures. Our knowledge-based framework finds superior policies compared to imitation learning-based and prior knowledge-based approaches. Importantly, we demonstrate that our approach can be used by untrained humans to initially provide >80% increase in expected reward relative to baselines prior to training (p < 0.001), which results in a >60% increase in expected reward after policy optimization (p = 0.011).",
        "primary_area": "Neuro-Symbolic AI",
        "author": "Andrew Silva; Matthew Gombolay",
        "authorids": "",
        "aff": "Georgia Institute of Technology; Georgia Institute of Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16638/16638-13-20132-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05042-encoding-human-domain-knowledge-to-warm-start-reinforcement-learning/",
        "doi": "10.1609/aaai.v35i6.16638",
        "pdf_size": 2257538
    },
    {
        "id": "13943",
        "title": "Encoding Syntactic Knowledge in Transformer Encoder for Intent Detection and Slot Filling",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a novel Transformer encoder-based architecture with syntactical knowledge encoded for intent detection and slot filling. Specifically, we encode syntactic knowledge into the Transformer encoder by jointly training it to predict syntactic parse ancestors and part-of-speech of each token via multi-task learning. Our model is based on self-attention and feed-forward layers and does not require external syntactic information to be available at inference time. Experiments show that on two benchmark datasets, our models with only two Transformer encoder layers achieve state-of-the-art results. Compared to the previously best performed model without pre-training, our models achieve absolute F1 score and accuracy improvement of 1.59 % and 0.85 % for slot filling and intent detection on the SNIPS dataset, respectively. Our models also achieve absolute F1 score and accuracy improvement of 0.1 % and 0.34 % for slot filling and intent detection on the ATIS dataset, respectively, over the previously best performed model. Furthermore, the visualization of the self-attention weights illustrates the benefits of incorporating syntactic information during training.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Jixuan  Wang; Kai Wei; Martin Radfar; Weiwei Zhang; Clement Chung",
        "authorids": "",
        "aff": "University of Toronto Vector Institute; Amazon; Amazon; Amazon; Amazon",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17642/17642-13-21136-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13943-encoding-syntactic-knowledge-in-transformer-encoder-for-intent-detection-and-slot-filling/",
        "doi": "10.1609/aaai.v35i16.17642",
        "pdf_size": 2501046
    },
    {
        "id": "01780",
        "title": "End-to-End Differentiable Learning to HDR Image Synthesis for Multi-exposure Images",
        "track": "main",
        "status": "Poster",
        "abstract": "Recently, high dynamic range (HDR) image reconstruction based on the multiple exposure stack from a given single exposure utilizes a deep learning framework to generate high-quality HDR images. These conventional networks focus on the exposure transfer task to reconstruct the multi-exposure stack. Therefore, they often fail to fuse the multi-exposure stack into a perceptually pleasant HDR image as the inversion artifacts occur. We tackle the problem in stack reconstruction-based methods by proposing a novel framework with a fully differentiable high dynamic range imaging (HDRI) process. By explicitly using the loss, which compares the network's output with the ground truth HDR image, our framework enables a neural network that generates the multiple exposure stack for HDRI to train stably. In other words, our differentiable HDR synthesis layer helps the deep neural network to train to create multi-exposure stacks while reflecting the precise correlations between multi-exposure images in the HDRI process. In addition, our network uses the image decomposition and the recursive process to facilitate the exposure transfer task and to adaptively respond to recursion frequency. The experimental results show that the proposed network outperforms the state-of-the-art quantitative and qualitative results in terms of both the exposure transfer tasks and the whole HDRI process.",
        "primary_area": "Computer Vision I",
        "author": "Junghee Kim; Siyeong Lee; Suk-Ju Kang",
        "authorids": "",
        "aff": "Sogang University; NAVER LABS; Sogang University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16272/16272-13-19766-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01780-end-to-end-differentiable-learning-to-hdr-image-synthesis-for-multi-exposure-images/",
        "doi": "10.1609/aaai.v35i2.16272",
        "pdf_size": 3116790
    },
    {
        "id": "12803",
        "title": "End-to-end Semantic Role Labeling with Neural Transition-based Model",
        "track": "main",
        "status": "Poster",
        "abstract": "End-to-end semantic role labeling (SRL) has been received increasing interest. It performs the two subtasks of SRL: predicate identification and argument role labeling, jointly. Recent work is mostly focused on graph-based neural models, while the transition-based framework with neural networks which has been widely used in a number of closely-related tasks, has not been studied for the joint task yet. In this paper, we present the first work of transition-based neural models for end-to-end SRL. Our transition model incrementally discovers all sentential predicates as well as their arguments by a set of transition actions. The actions of the two subtasks are executed mutually for full interactions. Besides, we suggest high-order compositions to extract non-local features, which can enhance the proposed transition model further. Experimental results on CoNLL09 and Universal Proposition Bank show that our final model can produce state-of-the-art performance, and meanwhile keeps highly efficient in decoding. We also conduct detailed experimental analysis for a deep understanding of our proposed model.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Hao Fei; Meishan Zhang; Bobo Li; Donghong Ji",
        "authorids": "",
        "aff": "Wuhan University; Tianjin University; Wuhan University; Wuhan University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17515/17515-13-21009-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12803-end-to-end-semantic-role-labeling-with-neural-transition-based-model/",
        "doi": "10.1609/aaai.v35i14.17515",
        "pdf_size": 479197
    },
    {
        "id": "11835",
        "title": "Endomorphisms of Classical Planning Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "Detection of redundant operators that can be safely removed from the planning task is an essential technique allowing to greatly improve performance of planners. In this paper, we employ structure-preserving maps on labeled transition systems (LTSs), namely endomorphisms well known from model theory, in order to detect redundancy. Computing endomorphisms of an LTS induced by a planning task is typically infeasible, so we show how to compute some of them on concise representations of planning tasks such as finite domain representations and factored LTSs. We formulate the computation of endomorphisms as a constraint satisfaction problem (CSP) that can be solved by an off-the-shelf CSP solver. Finally, we experimentally verify that the proposed method can find a sizeable number of redundant operators on the standard benchmark set.",
        "primary_area": "Planning, Routing, and Scheduling",
        "author": "Rostislav Hor\u010d\u00edk; Daniel Fi\u0161er",
        "authorids": "",
        "aff": "Czech Technical University in Prague, Faculty of Electrical Engineering, Prague, Czech Republic; Czech Technical University in Prague, Faculty of Electrical Engineering, Prague, Czech Republic Saarland University, Saarland Informatics Campus, Saarbr\u00fccken, Germany",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17406/17406-13-20900-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11835-endomorphisms-of-classical-planning-tasks/",
        "doi": "10.1609/aaai.v35i13.17406",
        "pdf_size": 176812
    },
    {
        "id": "10709",
        "title": "Enhanced Audio Tagging via Multi- to Single-Modal Teacher-Student Mutual Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Recognizing ongoing events based on acoustic clues has been a critical yet challenging problem that has attracted significant research attention in recent years. Joint audio-visual analysis can improve the event detection accuracy but may not always be feasible as under many circumstances only audio recordings are available in real-world scenarios. To solve the challenges, we present a novel visual-assisted teacher-student mutual learning framework for robust sound event detection from audio recordings. Our model adopts a multi-modal teacher network based on both acoustic and visual clues, and a single-modal student network based on acoustic clues only. Conventional teacher-student learning performs unsatisfactorily for knowledge transfer from a multi-modality network to a single-modality network. We thus present a mutual learning framework by introducing a single-modal transfer loss and a cross-modal transfer loss to collaboratively learn the audio-visual correlations between the two networks. Our proposed solution takes the advantages of joint audio-visual analysis in training while maximizing the feasibility of the model in use cases. Our extensive experiments on the DCASE17 and the DCASE18 sound event detection datasets show that our proposed method outperforms the state-of-the-art audio tagging approaches.",
        "primary_area": "Machine Learning V",
        "author": "Yifang Yin; Harsh Shrivastava; Ying Zhang; Zhenguang Liu; Rajiv Ratn Shah; Roger Zimmermann",
        "authorids": "",
        "aff": "National University of Singapore; National University of Singapore; National University of Singapore Northwestern Polytechnical University, China; Zhejiang Gongshang University; IIIT Delhi; National University of Singapore",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17280/17280-13-20774-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10709-enhanced-audio-tagging-via-multi-to-single-modal-teacher-student-mutual-learning/",
        "doi": "10.1609/aaai.v35i12.17280",
        "pdf_size": 498030
    },
    {
        "id": "02532",
        "title": "Enhanced Regularizers for Attributional Robustness",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep neural networks are the default choice of learning models for computer vision tasks. Extensive work has been carried out in recent years on explaining deep models for vision tasks such as classification. However, recent work has shown that it is possible for these models to produce substantially different attribution maps even when two very similar images are given to the network, raising serious questions about trustworthiness. To address this issue, we propose a robust attribution training strategy to improve attributional robustness of deep neural networks. Our method carefully analyzes the requirements for attributional robustness and introduces two new regularizers that preserve a model's attribution map during attacks. Our method surpasses state-of-the-art attributional robustness methods by a margin of approximately 3% to 9% in terms of attribution robustness measures on several datasets including MNIST, FMNIST, Flower and GTSRB.",
        "primary_area": "Computer Vision II",
        "author": "Anindya Sarkar; Anirban Sarkar; Vineeth N Balasubramanian",
        "authorids": "",
        "aff": "Indian Institute of Technology, Hyderabad; Indian Institute of Technology, Hyderabad; Indian Institute of Technology, Hyderabad",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16355/16355-13-19849-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02532-enhanced-regularizers-for-attributional-robustness/",
        "doi": "10.1609/aaai.v35i3.16355",
        "pdf_size": 4427047
    },
    {
        "id": "03351",
        "title": "Enhancing Audio-Visual Association with Self-Supervised Curriculum Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "The recent success of audio-visual representations learning can be largely attributed to their pervasive concurrency property, which can be used as a self-supervision signal and extract correlation information. While most recent works focus on capturing the shared associations between the audio and visual modalities, they rarely consider multiple audio and video pairs at once and pay little attention to exploiting the valuable information within each modality. To tackle this problem,  we propose a novel audio-visual representation learning method dubbed self-supervised curriculum learning (SSCL) under the teacher-student learning manner. Specifically, taking advantage of contrastive learning, a two-stage scheme is exploited, which transfers the cross-modal information between teacher and student model as a phased process. The proposed SSCL approach regards the pervasive property of audiovisual concurrency as latent supervision and mutually distills the structure knowledge of visual to audio data. Notably, the SSCL method can learn discriminative audio and visual representations for various downstream applications. Extensive experiments conducted on both action video recognition and audio sound recognition tasks show the remarkably improved performance of the SSCL method compared with the state-of-the-art self-supervised audio-visual representation learning methods.",
        "primary_area": "Computer Vision III",
        "author": "Jingran Zhang; Xing Xu; Fumin Shen; Huimin Lu; Xin Liu; Heng Tao Shen",
        "authorids": "",
        "aff": "Center for Future Multimedia and School of Computer Science and Engineering, University of Electronic Science and Technology of China; Center for Future Multimedia and School of Computer Science and Engineering, University of Electronic Science and Technology of China; Center for Future Multimedia and School of Computer Science and Engineering, University of Electronic Science and Technology of China; Kyushu Institute of Technology; Huaqiao University; Center for Future Multimedia and School of Computer Science and Engineering, University of Electronic Science and Technology of China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16447/16447-13-19941-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03351-enhancing-audio-visual-association-with-self-supervised-curriculum-learning/",
        "doi": "10.1609/aaai.v35i4.16447",
        "pdf_size": 393036
    },
    {
        "id": "12336",
        "title": "Enhancing Balanced Graph Edge Partition with Effective Local Search",
        "track": "main",
        "status": "Poster",
        "abstract": "Graph partition is a key component to achieve workload balance and reduce job completion time in parallel graph processing systems. Among the various partition strategies, edge partition has demonstrated more promising performance in power-law graphs than vertex partition and thereby has been more widely adopted as the default partition strategy by existing graph systems. The graph edge partition problem, which is to split the edge set into multiple balanced parts with the objective of minimizing the total number of copied vertices, has been widely studied from the view of optimization and algorithms. In this paper, we study local search algorithms for this problem to further improve the partition results from existing methods. More specifically, we propose two novel concepts, namely adjustable edges and blocks. Based on these, we develop a greedy heuristic as well as an improved search algorithm utilizing the property of max-flow model. To evaluate the performance of our algorithms, we first provide adequate theoretical analysis in terms of approximation quality. We significantly improve the previous known approximation ratio for this problem. Then we conduct extensive experiments on a large number of benchmark datasets and state-of-the-art edge partition strategies. The results show that our proposed local search framework can further improve the quality of graph partition by a wide margin.",
        "primary_area": "Search and Optimization",
        "author": "Zhenyu Guo; Mingyu Xiao; Yi Zhou; Dongxiang Zhang; Kian-Lee Tan",
        "authorids": "",
        "aff": "University of Electronic Science and Technology of China; University of Electronic Science and Technology of China; University of Electronic Science and Technology of China; Zhejiang University; National University of Singapore",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17464/17464-13-20958-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12336-enhancing-balanced-graph-edge-partition-with-effective-local-search/",
        "doi": "10.1609/aaai.v35i14.17464",
        "pdf_size": 437264
    },
    {
        "id": "08324",
        "title": "Enhancing Parameter-Free Frank Wolfe with an Extra Subproblem",
        "track": "main",
        "status": "Poster",
        "abstract": "Aiming at convex optimization under structural constraints, this work introduces and analyzes a variant of the Frank Wolfe (FW) algorithm termed ExtraFW. The distinct feature of ExtraFW is the pair of gradients leveraged per iteration, thanks to which the decision variable is updated in a prediction-correction (PC) format. Relying on no problem dependent parameters in the step sizes, the convergence rate of ExtraFW for general convex problems is shown to be ${cal O}(frac{1}{k})$, which is optimal in the sense of matching the lower bound on the number of solved FW subproblems. However, the merit of ExtraFW is its faster rate ${cal O}big(frac{1}{k^2} big)$ on a class of machine learning problems. Compared with other parameter-free FW variants that have faster rates on the same problems, ExtraFW has improved rates and fine-grained analysis thanks to its PC update. Numerical tests on binary classification with different sparsity-promoting constraints demonstrate that the empirical performance of ExtraFW is significantly better than FW, and even faster than Nesterov's accelerated gradient on certain datasets. For matrix completion, ExtraFW enjoys smaller optimality gap, and lower rank than FW.",
        "primary_area": "Machine Learning II",
        "author": "Bingcong Li; Lingda Wang; Georgios B. Giannakis; Zhizhen Zhao",
        "authorids": "",
        "aff": "University of Minnesota; University of Illinois at Urbana-Champaign; University of Minnesota; University of Illinois at Urbana-Champaign",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17012/17012-13-20506-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08324-enhancing-parameter-free-frank-wolfe-with-an-extra-subproblem/",
        "doi": "10.1609/aaai.v35i9.17012",
        "pdf_size": 472495
    },
    {
        "id": "12498",
        "title": "Enhancing Scientific Papers Summarization with Citation Graph",
        "track": "main",
        "status": "Poster",
        "abstract": "Previous work for text summarization in scientific domain mainly focused on the content of the input document, but seldom considering its citation network. However, scientific papers are full of uncommon domain-specific terms, making it almost impossible for the model to understand its true meaning without the help of the relevant research community. In this paper, we redefine the task of scientific papers summarization by utilizing their citation graph and propose a citation graph-based summarization model CGSum which can incorporate the information of both the source paper and its references. In addition,  we construct a novel scientific papers summarization dataset Semantic Scholar Network (SSN) which contains 141K research papers in different domains and 661K citation relationships. The entire dataset constitutes a large connected citation graph. Extensive experiments show that our model can achieve competitive performance when compared with the pretrained models even with a simple architecture. The results also indicates the citation graph is crucial to better understand the content of papers and generate high-quality summaries.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Chenxin An; Ming Zhong; Yiran Chen; Danqing Wang; Xipeng Qiu; Xuanjing Huang",
        "authorids": "",
        "aff": "Fudan University; Fudan University; Fudan University; Fudan University; Fudan University; Fudan University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17482/17482-13-20976-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12498-enhancing-scientific-papers-summarization-with-citation-graph/",
        "doi": "10.1609/aaai.v35i14.17482",
        "pdf_size": 436227
    },
    {
        "id": "10129",
        "title": "Enhancing Unsupervised Video Representation Learning by Decoupling the Scene and the Motion",
        "track": "main",
        "status": "Poster",
        "abstract": "One significant factor we expect the video representation learning to capture, especially in contrast with the image representation learning, is the object motion. However, we found that in the current mainstream video datasets, some action categories are highly related with the scene where the action happens, making the model tend to degrade to a solution where only the scene information is encoded. For example, a trained model may predict a video as playing football simply because it sees the field, neglecting that the subject is dancing as a cheerleader on the field. This is against our original intention towards the video representation learning and may bring scene bias on a different dataset that can not be ignored. In order to tackle this problem, we propose to decouple the scene and the motion (DSM) with two simple operations, so that the model attention towards the motion information is better paid. Specifically, we construct a positive clip and a negative clip for each video. Compared to the original video, the positive/negative is motion-untouched/broken but scene-broken/untouched by Spatial Local Disturbance and Temporal Local Disturbance. Our objective is to pull the positive closer while pushing the negative farther to the original clip in the latent space. In this way, the impact of the scene is weakened while the temporal sensitivity of the network is further enhanced. We conduct experiments on two tasks with various backbones and different pre-training datasets, and find that our method surpass the SOTA methods with a remarkable 8.1% and 8.8% improvement towards action recognition task on the UCF101 and HMDB51 datasets respectively using the same backbone.",
        "primary_area": "Machine Learning IV",
        "author": "Jinpeng Wang; Yuting Gao; Ke Li; Jianguo Hu; Xinyang Jiang; Xiaowei Guo; Rongrong Ji; Xing Sun",
        "authorids": "",
        "aff": "Sun Yat-sen University\uff0cTencent Youtu Lab; Tencent Youtu Lab; Tencent Youtu Lab; Sun Yat-sen University; Tencent Youtu Lab; Tencent Youtu Lab; Xiamen University, China; Tencent Youtu Lab",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17215/17215-13-20709-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10129-enhancing-unsupervised-video-representation-learning-by-decoupling-the-scene-and-the-motion/",
        "doi": "10.1609/aaai.v35i11.17215",
        "pdf_size": 8683750
    },
    {
        "id": "13064",
        "title": "Entity Guided Question Generation with Contextual Structure and Sequence Information Capturing",
        "track": "main",
        "status": "Poster",
        "abstract": "Question generation is a challenging task and has attracted widespread attention in recent years. Although previous studies have made great progress, there are still two main shortcomings: First, previous work did not simultaneously capture the sequence information and structure information hidden in the context, which results in poor results of the generated questions. Second, the generated questions cannot be answered by the given context. To tackle these issues, we propose an entity guided question generation model with contextual structure information and sequence information capturing. We use a Graph Convolutional Network and a Bidirectional Long Short Term Memory Network to capture the structure information and sequence information of the context, simultaneously. In addition, to improve the answerability of the generated questions, we use an entity-guided approach to obtain question type from the answer, and jointly encode the answer and question type. Both automatic and manual metrics show that our model can generate comparable questions with state-of-the-art models. Our code is available at https://github.com/VISLANG-Lab/EGSS.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Qingbao Huang; Mingyi Fu; Linzhang Mo; Yi Cai; Jingyun Xu; Pijian Li; Qing Li; Ho-fung Leung",
        "authorids": "",
        "aff": "School of Software Engineering, South China University of Technology, Guangzhou, China School of Electrical Engineering, Guangxi University, Nanning, China; School of Electrical Engineering, Guangxi University, Nanning, China; School of Electrical Engineering, Guangxi University, Nanning, China; School of Software Engineering, South China University of Technology, Guangzhou, China Key Laboratory of Big Data and Intelligent Robot (SCUT), MOE of China; School of Software Engineering, South China University of Technology, Guangzhou, China; School of Electrical Engineering, Guangxi University, Nanning, China; Department of Computing, The Hong Kong Polytechnic University, Hong Kong, China; Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17544/17544-13-21038-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13064-entity-guided-question-generation-with-contextual-structure-and-sequence-information-capturing/",
        "doi": "10.1609/aaai.v35i14.17544",
        "pdf_size": 1079433
    },
    {
        "id": "14149",
        "title": "Entity Structure Within and Throughout: Modeling Mention Dependencies for Document-Level Relation Extraction",
        "track": "main",
        "status": "Poster",
        "abstract": "Entities, as the essential elements in relation extraction tasks, exhibit certain structure. In this work, we formulate such entity structure as distinctive dependencies between mention pairs. We then propose SSAN, which incorporates these structural dependencies within the standard self-attention mechanism and throughout the overall encoding stage. Specifically, we design two alternative transformation modules inside each self-attention building block to produce attentive biases so as to adaptively regularize its attention flow. Our experiments demonstrate the usefulness of the proposed entity structure and the effectiveness of SSAN. It significantly outperforms competitive baselines, achieving new state-of-the-art results on three popular document-level relation extraction datasets. We further provide ablation and visualization to show how the entity structure guides the model for better relation extraction. Our code is publicly available.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Benfeng Xu; Quan Wang; Yajuan Lyu; Yong Zhu; Zhendong Mao",
        "authorids": "",
        "aff": "University of Science and Technology of China; Baidu Inc.; Baidu Inc.; Baidu Inc.; University of Science and Technology of China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17665/17665-13-21159-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14149-entity-structure-within-and-throughout-modeling-mention-dependencies-for-document-level-relation-extraction/",
        "doi": "10.1609/aaai.v35i16.17665",
        "pdf_size": 684474
    },
    {
        "id": "11479",
        "title": "Epistemic Logic of Know-Who",
        "track": "main",
        "status": "Poster",
        "abstract": "The paper suggests a definition of \"know who\" as a modality using Grove-Halpern semantics of names. It also introduces a logical system that describes the interplay between modalities \"knows who\", \"knows\", and \"for all agents\". The main technical result is a completeness theorem for the proposed system.",
        "primary_area": "Philosophy and Ethics of AI",
        "author": "Sophia Epstein; Pavel Naumov",
        "authorids": "",
        "aff": "Claremont McKenna College; King's College",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17367/17367-13-20861-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11479-epistemic-logic-of-know-who/",
        "doi": "10.1609/aaai.v35i13.17367",
        "pdf_size": 145989
    },
    {
        "id": "11818",
        "title": "Equitable Scheduling on a Single Machine",
        "track": "main",
        "status": "Poster",
        "abstract": "We introduce a natural but seemingly yet unstudied generalization of the problem of scheduling jobs on a single machine so as to minimize the number of tardy jobs. Our generalization lies in simultaneously considering several instances of the problem at once. In particular, we have n clients over a period of m days, where each client has a single job with its own processing time and deadline per day. Our goal is to provide a schedule for each of the m days, so that each client is guaranteed to have their job meet its deadline in at least k",
        "primary_area": "Planning, Routing, and Scheduling",
        "author": "Klaus Heeger; Dan Hermelin; George B. Mertzios; Hendrik Molter; Rolf Niedermeier; Dvir Shabtay",
        "authorids": "",
        "aff": "TU Berlin, Faculty IV, Algorithmics and Computational Complexity, Germany; Ben Gurion University of the Negev, Beersheba, Israel; Department of Computer Science, Durham University, UK; TU Berlin, Faculty IV, Algorithmics and Computational Complexity, Germany; TU Berlin, Faculty IV, Algorithmics and Computational Complexity, Germany; Ben Gurion University of the Negev, Beersheba, Israel",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17404/17404-13-20898-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11818-equitable-scheduling-on-a-single-machine/",
        "doi": "10.1609/aaai.v35i13.17404",
        "pdf_size": 152848
    },
    {
        "id": "06202",
        "title": "Equivalent Causal Models",
        "track": "main",
        "status": "Poster",
        "abstract": "The aim of this paper is to offer the first systematic exploration and definition of equivalent causal models in the context where both models are not made up of the same variables. The idea is that two models are equivalent when they agree on all \"essential\" causal information that can be expressed using their common variables. I do so by focussing on the two main features of causal models, namely their structural relations and their functional relations. In particular, I define several relations of causal ancestry and several relations of causal sufficiency, and require that the most general of these relations are preserved across equivalent models.",
        "primary_area": "Knowledge Representation and Reasoning",
        "author": "Sander Beckers",
        "authorids": "",
        "aff": "Ludwig Maximilian University - Munich",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16771/16771-13-20265-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06202-equivalent-causal-models/",
        "doi": "10.1609/aaai.v35i7.16771",
        "pdf_size": 146916
    },
    {
        "id": "01540",
        "title": "Error-Aware Density Isomorphism Reconstruction for Unsupervised Cross-Domain Crowd Counting",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper focuses on the unsupervised domain adaptation problem for video-based crowd counting, in which we use labeled data as source domain and unlabelled video data as target domain. It is challenging as there is a huge gap between the source and the target domain and no annotations of samples are available in the target domain. The key issue is how to utilize unlabelled videos in the target domain for knowledge learning and transferring from the source domain. To tackle this problem, we propose a novel Error-aware Density Isomorphism REConstruction Network (EDIREC-Net) for cross-domain crowd counting. EDIREC-Net jointly transfers a pre-trained counting model to target domains using a density isomorphism reconstruction objective and models the reconstruction erroneousness by error reasoning. Specifically, as crowd flows in videos are consecutive, the density maps in adjacent frames turn out to be isomorphic. On this basis, we regard the density isomorphism reconstruction error as a self-supervised signal to transfer the pre-trained counting models to different target domains. Moreover, we leverage an estimation-reconstruction consistency to monitor the density reconstruction erroneousness and suppress unreliable density reconstructions during training. Experimental results on four benchmark datasets demonstrate the superiority of the proposed method and ablation studies investigate the efficiency and robustness. The source code is available at https://github.com/GehenHe/EDIREC-Net.",
        "primary_area": "Computer Vision I",
        "author": "Yuhang He; Zhiheng Ma; Xing Wei; Xiaopeng Hong; Wei Ke; Yihong Gong",
        "authorids": "",
        "aff": "Xi\u2019an Jiaotong University; Xi'an Jiaotong University; Xi'an Jiaotong University; Xi'an Jiaotong University Peng Cheng Laboratory; Xi'an Jiaotong University; Xi'an Jiaotong University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16245/16245-13-19739-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01540-error-aware-density-isomorphism-reconstruction-for-unsupervised-cross-domain-crowd-counting/",
        "doi": "10.1609/aaai.v35i2.16245",
        "pdf_size": 7509717
    },
    {
        "id": "09722",
        "title": "Error-Correcting Output Codes with Ensemble Diversity for Robust Learning in Neural Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Though deep learning has been applied successfully in many scenarios, malicious inputs with human-imperceptible perturbations can make it vulnerable in real applications. This paper proposes an error-correcting neural network (ECNN) that combines a set of binary classifiers to combat adversarial examples in the multi-class classification problem. To build an ECNN, we propose to design a code matrix so that the minimum Hamming distance between any two rows (i.e., two codewords) and the minimum shared information distance between any two columns (i.e., two partitions of class labels) are simultaneously maximized. Maximizing row distances can increase the system fault tolerance while maximizing column distances helps increase the diversity between binary classifiers. We propose an end-to-end training method for our ECNN, which allows further improvement of the diversity between binary classifiers. The end-to-end training renders our proposed ECNN different from the traditional error-correcting output code (ECOC) based methods that train binary classifiers independently. ECNN is complementary to other existing defense approaches such as adversarial training and can be applied in conjunction with them. We empirically demonstrate that our proposed ECNN is effective against the state-of-the-art white-box and black-box attacks on several datasets while maintaining good classification accuracy on normal examples.",
        "primary_area": "Machine Learning IV",
        "author": "Yang Song; Qiyu Kang; Wee Peng Tay",
        "authorids": "",
        "aff": "Nanyang Technological University; Nanyang Technological University; Nanyang Technological University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17169/17169-13-20663-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09722-error-correcting-output-codes-with-ensemble-diversity-for-robust-learning-in-neural-networks/",
        "doi": "10.1609/aaai.v35i11.17169",
        "pdf_size": 329733
    },
    {
        "id": "12275",
        "title": "Escaping Local Optima with Non-Elitist Evolutionary Algorithms",
        "track": "main",
        "status": "Poster",
        "abstract": "Most discrete evolutionary algorithms (EAs) implement elitism, meaning that they make the biologically implausible assumption that the fittest individuals never die. While elitism favours exploitation and ensures that the best seen solutions are not lost, it has been widely conjectured that non-elitism is necessary to explore promising fitness valleys without getting stuck in local optima. Determining when non-elitist EAs outperform elitist EAs has been one of the most fundamental open problems in evolutionary computation. A recent analysis of a non-elitist EA shows that this algorithm does not outperform its elitist counterparts on the benchmark problem JUMP.  We solve this open problem through rigorous runtime analysis of elitist and non-elitist population-based EAs on a class of multi-modal problems. We show that with 3-tournament selection and appropriate mutation rates, the non-elitist EA optimises the multi-modal problem in expected polynomial time, while an elitist EA requires exponential time with overwhelmingly high probability.  A key insight in our analysis is the non-linear selection profile of the tournament selection mechanism which, with appropriate mutation rates, allows a small sub-population to reside on the local optimum while the rest of the population explores the fitness valley. In contrast, we show that the comma-selection mechanism which does not have this non-linear profile, fails to optimise this problem in polynomial time.  The theoretical analysis is complemented with an empirical investigation on instances of the set cover problem, showing that non-elitist EAs can perform better than the elitist ones. We also provide examples where usage of mutation rates close to the error thresholds is beneficial when employing non-elitist population-based EAs.",
        "primary_area": "Search and Optimization",
        "author": "Duc-Cuong Dang; Anton Eremeev; Per Kristian Lehre",
        "authorids": "",
        "aff": "University of Southampton; Sobolev Institute of Mathematics SB RAS; University of Birmingham",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17457/17457-13-20951-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12275-escaping-local-optima-with-non-elitist-evolutionary-algorithms/",
        "doi": "10.1609/aaai.v35i14.17457",
        "pdf_size": 242293
    },
    {
        "id": "00240",
        "title": "Estimating Calibrated Individualized Survival Curves with Deep Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "In survival analysis, deep learning approaches have been proposed for estimating an individual's probability of survival over some time horizon. Such approaches can capture complex non-linear relationships, without relying on restrictive assumptions regarding the relationship between an individual's characteristics and their underlying survival process. To date, however, these methods have focused primarily on optimizing discriminative performance and have ignored model calibration. Well-calibrated survival curves present realistic and meaningful probabilistic estimates of the true underlying survival process for an individual. However, due to the lack of ground-truth regarding the underlying stochastic process of survival for an individual, optimizing and measuring calibration in survival analysis is an inherently difficult task. In this work, we i) highlight the shortcomings of existing approaches in terms of calibration and ii) propose a new training scheme for optimizing deep survival analysis models that maximizes discriminative performance, subject to good calibration. Compared to state-of-the-art approaches across two publicly available datasets, our proposed training scheme leads to significant improvements in calibration, while maintaining good discriminative performance.",
        "primary_area": "Application Domains",
        "author": "Fahad Kamran; Jenna Wiens",
        "authorids": "",
        "aff": "University of Michigan; University of Michigan",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16098/16098-13-19592-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00240-estimating-calibrated-individualized-survival-curves-with-deep-learning/",
        "doi": "10.1609/aaai.v35i1.16098",
        "pdf_size": 390293
    },
    {
        "id": "12113",
        "title": "Estimating Identifiable Causal Effects through Double Machine Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Identifying causal effects from observational data is a pervasive challenge found throughout the empirical sciences. Very general methods have been developed to decide the identifiability of a causal quantity from a combination of observational data and causal knowledge about the underlying system. In practice, however, there are still challenges to estimating identifiable causal functionals from finite samples. Recently, a method known as double/debiased machine learning (DML) (Chernozhukov et al. 2018) has been proposed to learn parameters leveraging modern machine learning techniques, which is both robust to model misspecification and bias-reducing. Still, DML has only been used for causal estimation in settings when the back-door condition (also known as conditional ignorability) holds. In this paper, we develop a new, general class of estimators for any identifiable causal functionals that exhibit DML properties, which we name DML-ID. In particular, we introduce a complete identification algorithm that returns an influence function (IF) for any identifiable causal functional. We then construct the DML estimator based on the derived IF. We show that DML-ID estimators hold the key properties of debiasedness and doubly robustness. Simulation results corroborate with the theory.",
        "primary_area": "Reasoning under Uncertainty",
        "author": "Yonghan Jung; Jin Tian; Elias Bareinboim",
        "authorids": "",
        "aff": "Purdue University; Iowa State University; Columbia University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17438/17438-13-20932-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12113-estimating-identifiable-causal-effects-through-double-machine-learning/",
        "doi": "10.1609/aaai.v35i13.17438",
        "pdf_size": 321916
    },
    {
        "id": "04045",
        "title": "Estimating the Number of Induced Subgraphs from Incomplete Data and Neighborhood Queries",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider a natural setting where network parameters are estimated from noisy and incomplete information about the network. More specifically, we investigate how we can efficiently estimate the number of small subgraphs (e.g., edges, triangles, etc.) based on full access to one or two noisy and incomplete samples of a large underlying network and on few queries revealing the neighborhood of carefully selected vertices. After specifying a random generator which removes edges from the underlying graph, we present estimators with strong provable performance guarantees, which exploit information from the noisy network samples and query a constant number of the most important vertices for the estimation. Our experimental evaluation shows that, in practice, a single noisy network sample and a couple of hundreds neighborhood queries suffice for accurately estimating the number of triangles in networks with millions of vertices and edges.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Dimitris Fotakis; Thanasis Pittas; Stratis Skoulakis",
        "authorids": "",
        "aff": "National Technical University of Athens; University of Wisconsin-Madison; Singapore University of Technology and Design",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16525/16525-13-20019-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04045-estimating-the-number-of-induced-subgraphs-from-incomplete-data-and-neighborhood-queries/",
        "doi": "10.1609/aaai.v35i5.16525",
        "pdf_size": 188012
    },
    {
        "id": "05673",
        "title": "Estimating \u03b1-Rank by Maximizing Information Gain",
        "track": "main",
        "status": "Poster",
        "abstract": "Game theory has been increasingly applied in settings where the game is not known outright, but has to be estimated by sampling. For example, meta-games that arise in multi-agent evaluation can only be accessed by running a succession of expensive experiments that may involve simultaneous deployment of several agents. In this paper, we focus on \u03b1-rank, a popular game-theoretic solution concept designed to perform well in such scenarios. We aim to estimate the \u03b1-rank of the game using as few samples as possible. Our algorithm maximizes information gain between an epistemic belief over the \u03b1-ranks and the observed payoff. This approach has two main benefits.  First, it allows us to focus our sampling on the entries that matter the most for identifying the \u03b1-rank. Second, the Bayesian formulation provides a facility to build in modeling assumptions by using a prior over game payoffs. We show the benefits of using information gain as compared to the confidence interval criterion of ResponseGraphUCB,  and provide theoretical results justifying our method.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Tabish Rashid; Cheng Zhang; Kamil Ciosek",
        "authorids": "",
        "aff": "University of Oxford; Microsoft; Microsoft",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16712/16712-13-20206-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05673-estimating-%ce%b1-rank-by-maximizing-information-gain/",
        "doi": "10.1609/aaai.v35i6.16712",
        "pdf_size": 1722922
    },
    {
        "id": "12166",
        "title": "Estimation of Spectral Risk Measures",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider the problem of estimating a spectral risk measure (SRM) from i.i.d. samples, and propose a novel method that is based on numerical integration. We show that our SRM estimate concentrates exponentially, when the underlying distribution has bounded support. Further, we also consider the case when the underlying distribution satisfies an exponential moment bound, which includes sub-Gaussian and subexponential distributions. For these distributions, we derive a concentration bound for our estimation scheme. We validate the theoretical findings on a synthetic setup, and in a vehicular traffic routing application.",
        "primary_area": "Reasoning under Uncertainty",
        "author": "Ajay Kumar Pandey; Prashanth L.A.; Sanjay P. Bhat",
        "authorids": "",
        "aff": "Department of Computer Science and Engineering, Indian Institute of Technology Madras, Chennai, India; Department of Computer Science and Engineering, Indian Institute of Technology Madras, Chennai, India; TCS Research, Hyderabad, India, and Department of Electrical Engineering, Indian Institute of Technology Madras, Chennai, India",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17444/17444-13-20938-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12166-estimation-of-spectral-risk-measures/",
        "doi": "10.1609/aaai.v35i13.17444",
        "pdf_size": 292729
    },
    {
        "id": "11613",
        "title": "Ethical Dilemmas in Strategic Games",
        "track": "main",
        "status": "Poster",
        "abstract": "An agent, or a coalition of agents, faces an ethical dilemma between several statements if she is forced to make a conscious choice between which of these statements will be true. This paper proposes to capture ethical dilemmas as a modality in strategic game settings with and without limit on sacrifice and for perfect and imperfect information games. The authors show that the dilemma modality cannot be defined through the earlier proposed blameworthiness modality. The main technical result is a sound and complete axiomatization of the properties of this modality with sacrifice in games with perfect information.",
        "primary_area": "Philosophy and Ethics of AI",
        "author": "Pavel Naumov; Rui-Jie Yew",
        "authorids": "",
        "aff": "King's College; Scripps College",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17381/17381-13-20875-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11613-ethical-dilemmas-in-strategic-games/",
        "doi": "10.1609/aaai.v35i13.17381",
        "pdf_size": 169464
    },
    {
        "id": "11657",
        "title": "Ethically Compliant Sequential Decision Making",
        "track": "main",
        "status": "Poster",
        "abstract": "Enabling autonomous systems to comply with an ethical theory is critical given their accelerating deployment in domains that impact society. While many ethical theories have been studied extensively in moral philosophy, they are still challenging to implement by developers who build autonomous systems. This paper proposes a novel approach for building ethically compliant autonomous systems that optimize completing a task while following an ethical framework. First, we introduce a definition of an ethically compliant autonomous system and its properties. Next, we offer a range of ethical frameworks for divine command theory, prima facie duties, and virtue ethics. Finally, we demonstrate the accuracy and usability of our approach in a set of autonomous driving simulations and a user study of planning and robotics experts.",
        "primary_area": "Philosophy and Ethics of AI",
        "author": "Justin Svegliato; Samer B. Nashed; Shlomo Zilberstein",
        "authorids": "",
        "aff": "University of Massachusetts Amherst; University of Massachusetts Amherst; University of Massachusetts Amherst",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17386/17386-13-20880-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11657-ethically-compliant-sequential-decision-making/",
        "doi": "10.1609/aaai.v35i13.17386",
        "pdf_size": 600156
    },
    {
        "id": "14602",
        "title": "EvaLDA: Efficient Evasion Attacks Towards Latent Dirichlet Allocation",
        "track": "main",
        "status": "Poster",
        "abstract": "As one of the most powerful topic models, Latent Dirichlet Allocation (LDA) has been used in a vast range of tasks, including document understanding, information retrieval and peer-reviewer assignment. Despite its tremendous popularity, the security of LDA has rarely been studied. This poses severe risks to security-critical tasks such as sentiment analysis and peer-reviewer assignment that are based on LDA. In this paper, we are interested in knowing whether LDA models are vulnerable to adversarial perturbations of benign document examples during inference time. We formalize the evasion attack to LDA models as an optimization problem and prove it to be NP-hard. We then propose a novel and efficient algorithm, EvaLDA to solve it. We show the effectiveness of EvaLDA via extensive empirical evaluations. For instance, in the NIPS dataset, EvaLDA can averagely promote the rank of a target topic from 10 to around 7 by only replacing 1% of the words with similar words in a victim document. Our work provides significant insights into the power and limitations of evasion attacks to LDA models.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Qi Zhou; Haipeng Chen; Yitao Zheng; Zhen Wang",
        "authorids": "",
        "aff": "Hangzhou Dianzi University; Harvard University; Hangzhou Dianzi University; Hangzhou Dianzi University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17716/17716-13-21210-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14602-evalda-efficient-evasion-attacks-towards-latent-dirichlet-allocation/",
        "doi": "10.1609/aaai.v35i16.17716",
        "pdf_size": 1988110
    },
    {
        "id": "14058",
        "title": "Evidence Inference Networks for Interpretable Claim Verification",
        "track": "main",
        "status": "Poster",
        "abstract": "Existing approaches construct appropriate interaction models to explore semantic conflicts between claims and relevant articles, which provides practical solutions for interpretable claim verification. However, these conflicts are not necessarily all about questioning the false part of claims, which makes considerable semantic conflicts difficult to be used as evidence to explain the results of claim verification. In this paper, we propose evidence inference networks (EVIN), which focus on the conflicts questioning the core semantics of claims and serve as evidence for interpretable claim verification. Specifically, EVIN first captures the core semantic segments of claims and the users' principal opinions in relevant articles. Then, it finely-grained identifies the semantic conflicts contained in each relevant article from these opinions. Finally, it constructs coherence modeling to match the conflicts that queries the core semantic fragments of claims as explainable evidence. Experiments on two widely used datasets demonstrate that EVIN not only achieves satisfactory performance but also provides explainable evidence for end-users.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Lianwei Wu; Yuan Rao; Ling Sun; Wangbo He",
        "authorids": "",
        "aff": "Xi'an Jiaotong University; xi'an Jiaotong university; Xi'an Jiaotong University; Xi'an JiaoTong University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17655/17655-13-21149-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14058-evidence-inference-networks-for-interpretable-claim-verification/",
        "doi": "10.1609/aaai.v35i16.17655",
        "pdf_size": 1161436
    },
    {
        "id": "05531",
        "title": "Evolution Strategies for Approximate Solution of Bayesian Games",
        "track": "main",
        "status": "Poster",
        "abstract": "We address the problem of solving complex Bayesian games, characterized by high-dimensional type and action spaces, many (> 2) players, and general-sum payoffs. Our approach applies to symmetric one-shot Bayesian games, with no given analytic structure. We represent agent strategies in parametric form as neural networks, and apply natural evolution strategies (NES) [wierstra2014natural] for deep model optimization. For pure equilibrium computation, we formulate the problem as bi-level optimization, and employ NES in an iterative algorithm to implement both inner-loop best response optimization and outer-loop regret minimization. In simple games including first- and second-price auctions, it is capable of recovering known analytic solutions. For mixed equilibrium computation, we adopt an incremental strategy generation framework, with NES as strategy generator producing a finite sequence of approximate best-response strategies. We then calculate equilibria over this finite strategy set via a model-based optimization process. Both our pure and mixed equilibrium computation methods employ NES to efficiently search for strategies over the functional space, given only black-box simulation access to noisy payoff samples. We experimentally demonstrate the efficacy of all methods on two simultaneous sealed-bid auction games with distinct type distributions, and observe that the solutions exhibit qualitatively different behavior in these two environments.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Zun Li; Michael P. Wellman",
        "authorids": "",
        "aff": "University of Michigan, Ann Arbor; University of Michigan, Ann Arbor",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16696/16696-13-20190-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05531-evolution-strategies-for-approximate-solution-of-bayesian-games/",
        "doi": "10.1609/aaai.v35i6.16696",
        "pdf_size": 244706
    },
    {
        "id": "09851",
        "title": "Evolutionary Approach for AutoAugment Using the Thermodynamical Genetic Algorithm",
        "track": "main",
        "status": "Poster",
        "abstract": "Data augmentation is one of the most effective ways to stabilize learning by improving the generalization of machine-learning models. In recent years, automatic data augmentation methods, such as AutoAugment or Fast AutoAugment have been attracting attention; and these methods improved the results of image classification and object detection tasks. However, several problems remain. Most notably, a larger training dataset requires higher computational costs. When searching with a small dataset in an attempt to determine the data augmentation approach, the true data space and sampling data space do not fully correspond with each other, thereby causing the generalization performance to deteriorate. Moreover, in the existing automatic augmentation methods, the search phase is often dominated by an exceptional sub-policy, which results in a loss of diversity of operations. In this study, we solved these problems by introducing evolutionary computation to previous methods. As mentioned earlier, maintaining diversity is essential. Therefore, we adopted the thermodynamical genetic algorithm (TDGA), which can control the population diversity with a specific genetic operator, known as the thermodynamical selection rule. To confirm the effectiveness of the proposed method, computational experiments were conducted using two benchmark datasets, CIFAR-10 and SVHN, as examples. The experimental results show that the proposed method can obtain various useful augmentation sub-policies for the problems while reducing the computational cost.",
        "primary_area": "Machine Learning IV",
        "author": "Akira Terauchi; Naoki Mori",
        "authorids": "",
        "aff": "Osaka Prefecture University; Osaka Prefecture University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17184/17184-13-20678-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09851-evolutionary-approach-for-autoaugment-using-the-thermodynamical-genetic-algorithm/",
        "doi": "10.1609/aaai.v35i11.17184",
        "pdf_size": 519397
    },
    {
        "id": "11343",
        "title": "Evolutionary Game Theory Squared: Evolving Agents in Endogenously Evolving Zero-Sum Games",
        "track": "main",
        "status": "Poster",
        "abstract": "The predominant paradigm in evolutionary game theory and more generally online learning in games is based on a clear distinction between a population of dynamic agents that interact given a fixed, static game. In this paper, we move away from the artificial divide between dynamic agents and static games, to introduce and analyze a large class of competitive settings where both the agents and the games they play evolve strategically over time. We focus on arguably the most archetypal game-theoretic setting---zero-sum games (as well as network generalizations)---and the most studied evolutionary learning dynamic---replicator, the continuous-time analogue of multiplicative weights. Populations of agents compete against each other in a zero-sum competition that itself evolves adversarially to the current population mixture. Remarkably, despite the chaotic coevolution of agents and games, we prove that the system exhibits a number of regularities. First, the system has conservation laws of an information-theoretic flavor that couple the behavior of all agents and games. Secondly, the system is Poincare recurrent, with effectively all possible initializations of agents and games lying on recurrent orbits that come arbitrarily close to their initial conditions infinitely often. Thirdly, the time-average agent behavior and utility converge to the Nash equilibrium values of the time-average game. Finally, we provide a polynomial time algorithm to efficiently predict this time-average behavior for any such coevolving network game.",
        "primary_area": "Multiagent Systems",
        "author": "Stratis Skoulakis; Tanner Fiez; Ryann Sim; Georgios Piliouras; Lillian Ratliff",
        "authorids": "",
        "aff": "Singapore University of Technology and Design; University of Washington; Singapore University of Technology and Design; Singapore University of Technology and Design; University of Washington",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17352/17352-13-20846-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11343-evolutionary-game-theory-squared-evolving-agents-in-endogenously-evolving-zero-sum-games/",
        "doi": "10.1609/aaai.v35i13.17352",
        "pdf_size": 966936
    },
    {
        "id": "06750",
        "title": "ExGAN: Adversarial Generation of Extreme Samples",
        "track": "main",
        "status": "Poster",
        "abstract": "Mitigating the risk arising from extreme events is a fundamental goal with many applications, such as the modelling of natural disasters, financial crashes, epidemics, and many others. To manage this risk, a vital step is to be able to understand or generate a wide range of extreme scenarios. Existing approaches based on Generative Adversarial Networks (GANs) excel at generating realistic samples, but seek to generate typical samples, rather than extreme samples. Hence, in this work, we propose ExGAN, a GAN-based approach to generate realistic and extreme samples. To model the extremes of the training distribution in a principled way, our work draws from Extreme Value Theory (EVT), a probabilistic approach for modelling the extreme tails of distributions. For practical utility, our framework allows the user to specify both the desired extremeness measure, as well as the desired extremeness probability they wish to sample at. Experiments on real US Precipitation data show that our method generates realistic samples, based on visual inspection and quantitative measures, in an efficient manner. Moreover, generating increasingly extreme examples using ExGAN can be done in constant time (with respect to the extremeness probability \u03c4), as opposed to the O(1/\u03c4) time required by the baseline approach.",
        "primary_area": "Machine Learning I",
        "author": "Siddharth Bhatia; Arjit Jain; Bryan Hooi",
        "authorids": "",
        "aff": "National University of Singapore; Indian Institute of Technology Bombay; National University of Singapore",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16834/16834-13-20328-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06750-exgan-adversarial-generation-of-extreme-samples/",
        "doi": "10.1609/aaai.v35i8.16834",
        "pdf_size": 4346588
    },
    {
        "id": "08930",
        "title": "Exacerbating Algorithmic Bias through Fairness Attacks",
        "track": "main",
        "status": "Poster",
        "abstract": "Algorithmic fairness has attracted significant attention in recent years, with many quantitative measures suggested for characterizing the fairness of different machine learning algorithms. Despite this interest, the robustness of those fairness measures with respect to an intentional adversarial attack has not been properly addressed. Indeed, most adversarial machine learning has focused on the impact of malicious attacks on the accuracy of the system, without any regard to the system's fairness. We propose new types of data poisoning attacks where an adversary intentionally targets the fairness of a system. Specifically, we propose two families of attacks that target fairness measures. In the anchoring attack, we skew the decision boundary by placing poisoned points near specific target points to bias the outcome. In the influence attack on fairness, we aim to maximize the covariance between the sensitive attributes and the decision outcome and affect the fairness of the model. We conduct extensive experiments that indicate the effectiveness of our proposed attacks.",
        "primary_area": "Machine Learning III",
        "author": "Ninareh Mehrabi; Muhammad Naveed; Fred Morstatter; Aram Galstyan",
        "authorids": "",
        "aff": "University of Southern California Information Sciences Institute; University of Southern California; University of Southern California Information Sciences Institute; University of Southern California Information Sciences Institute",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17080/17080-13-20574-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08930-exacerbating-algorithmic-bias-through-fairness-attacks/",
        "doi": "10.1609/aaai.v35i10.17080",
        "pdf_size": 1044493
    },
    {
        "id": "08874",
        "title": "Exact Reduction of Huge Action Spaces in General Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "The reinforcement learning (RL) framework formalizes the notion of learning with interactions. Many real-world problems have large state-spaces and/or action-spaces such as in Go, StarCraft, protein folding, and robotics or are non-Markovian, which cause significant challenges to RL algorithms. In this work we address the large action-space problem by sequentializing actions, which can reduce the action-space size significantly, even down to two actions at the expense of an increased planning horizon. We provide explicit and exact constructions and equivalence proofs for all quantities of interest for arbitrary history-based processes. In the case of MDPs, this could help RL algorithms that bootstrap. In this work we show how action-binarization in the non-MDP case can significantly improve Extreme State Aggregation (ESA) bounds. ESA allows casting any (non-MDP, non-ergodic, history-based) RL problem into a fixed-sized non-Markovian state-space with the help of a surrogate Markovian process. On the upside, ESA enjoys similar optimality guarantees as Markovian models do. But a downside is that the size of the aggregated state-space becomes exponential in the size of the action-space. In this work, we patch this issue by binarizing the action-space. We provide an upper bound on the number of states of this binarized ESA that is logarithmic in the original action-space size, a double-exponential improvement.",
        "primary_area": "Machine Learning III",
        "author": "Sultan J. Majeed; Marcus Hutter",
        "authorids": "",
        "aff": "Australian National University; DeepMind Australian National University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17074/17074-13-20568-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08874-exact-reduction-of-huge-action-spaces-in-general-reinforcement-learning/",
        "doi": "10.1609/aaai.v35i10.17074",
        "pdf_size": 172310
    },
    {
        "id": "09997",
        "title": "Expected Eligibility Traces",
        "track": "main",
        "status": "Poster",
        "abstract": "The question of how to determine which states and actions are responsible for a certain outcome is known as the credit assignment problem and remains a central research question in reinforcement learning and artificial intelligence. Eligibility traces enable efficient credit assignment to the recent sequence of states and actions experienced by the agent, but not to counterfactual sequences that could also have led to the current state. In this work, we introduce expected eligibility traces. Expected traces allow, with a single update, to update states and actions that could have preceded the current state, even if they did not do so on this occasion. We discuss when expected traces provide benefits over classic (instantaneous) traces in temporal-difference learning, and show that some- times substantial improvements can be attained. We provide a way to smoothly interpolate between instantaneous and expected traces by a mechanism similar to bootstrapping, which ensures that the resulting algorithm is a strict generalisation of TD(\u03bb). Finally, we discuss possible extensions and connections to related ideas, such as successor features.",
        "primary_area": "Machine Learning IV",
        "author": "Hado van Hasselt; Sephora Madjiheurem; Matteo Hessel; David Silver; Andr\u00e9 Barreto; Diana Borsa",
        "authorids": "",
        "aff": "DeepMind; University College London; DeepMind; DeepMind; DeepMind; DeepMind",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17200/17200-13-20694-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09997-expected-eligibility-traces/",
        "doi": "10.1609/aaai.v35i11.17200",
        "pdf_size": 1389803
    },
    {
        "id": "11290",
        "title": "Expected Value of Communication for Planning in Ad Hoc Teamwork",
        "track": "main",
        "status": "Poster",
        "abstract": "A desirable goal for autonomous agents is to be able to coordinate on the fly with previously unknown teammates.  Known as \u201cad hoc teamwork\u201d, enabling such a capability has been receiving increasing attention in the research community. One of the central challenges in ad hoc teamwork is quickly recognizing the current plans of other agents and planning accordingly.  In this paper, we focus on the scenario in which teammates can communicate with one another, but only at a cost.  Thus, they must carefully balance plan recognition based on observations vs. that based on communication.          This paper proposes a new metric for evaluating how similar are two policies that a teammate may be following - the Expected Divergence Point (EDP).     We then present a novel planning algorithm for ad hoc teamwork, determining which query to ask and planning accordingly. We demonstrate the effectiveness of this algorithm in a range of increasingly general communication in ad hoc teamwork problems.",
        "primary_area": "Multiagent Systems",
        "author": "William Macke; Reuth Mirsky; Peter Stone",
        "authorids": "",
        "aff": "University of Texas at Austin; University of Texas at Austin; University of Texas at Austin and Sony AI",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17346/17346-13-20840-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11290-expected-value-of-communication-for-planning-in-ad-hoc-teamwork/",
        "doi": "10.1609/aaai.v35i13.17346",
        "pdf_size": 732795
    },
    {
        "id": "02431",
        "title": "Explainable Models with Consistent Interpretations",
        "track": "main",
        "status": "Poster",
        "abstract": "Given the widespread deployment of black box deep neural networks in computer vision applications, the interpretability aspect of these black box systems has recently gained traction. Various methods have been proposed to explain the results of such deep neural networks. However, some recent works have shown that such explanation methods are biased and do not produce consistent interpretations. Hence, rather than introducing a novel explanation method, we learn models that are encouraged to be interpretable given an explanation method. We use Grad-CAM as the explanation algorithm and encourage the network to learn consistent interpretations along with maximizing the log-likelihood of the correct class. We show that our method outperforms the baseline on the pointing game evaluation on ImageNet and MS-COCO datasets respectively. We also introduce new evaluation metrics that penalize the saliency map if it lies outside the ground truth bounding box or segmentation mask, and show that our method outperforms the baseline on these metrics as well. Moreover, our model trained with interpretation consistency generalizes to other explanation algorithms on all the evaluation metrics. The code and models are publicly available.",
        "primary_area": "Computer Vision II",
        "author": "Vipin Pillai; Hamed Pirsiavash",
        "authorids": "",
        "aff": "University of Maryland, Baltimore County; University of Maryland, Baltimore County",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16344/16344-13-19838-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02431-explainable-models-with-consistent-interpretations/",
        "doi": "10.1609/aaai.v35i3.16344",
        "pdf_size": 2050002
    },
    {
        "id": "11396",
        "title": "Explaining A Black-box By Using A Deep Variational Information Bottleneck Approach",
        "track": "main",
        "status": "Poster",
        "abstract": "Interpretable machine learning has gained much attention recently. Briefness and comprehensiveness are necessary in order to provide a large amount of information concisely when explaining a black-box decision system. However, existing interpretable machine learning methods fail to consider briefness and comprehensiveness simultaneously, leading to redundant explanations. We propose the variational information bottleneck for interpretation, VIBI, a system-agnostic interpretable method that provides a brief but comprehensive explanation. VIBI adopts an information theoretic principle, information bottleneck principle, as a criterion for finding such explanations. For each instance, VIBI selects key features that are maximally compressed about an input (briefness), and informative about a decision made by a black-box system on that input (comprehensive). We evaluate VIBI on three datasets and compare with state-of-the-art interpretable machine learning methods in terms of both interpretability and fidelity evaluated by human and quantitative metrics.",
        "primary_area": "Philosophy and Ethics of AI",
        "author": "Seojin Bang; Pengtao Xie; Heewook Lee; Wei Wu; Eric Xing",
        "authorids": "",
        "aff": "Carnegie Mellon University; University of California San Diego Petuum Inc.; Arizona State University; Carnegie Mellon University; Carnegie Mellon University Petuum Inc.",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17358/17358-13-20852-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11396-explaining-a-black-box-by-using-a-deep-variational-information-bottleneck-approach/",
        "doi": "10.1609/aaai.v35i13.17358",
        "pdf_size": 353089
    },
    {
        "id": "11639",
        "title": "Explaining Convolutional Neural Networks through Attribution-Based Input Sampling and Block-Wise Feature Aggregation",
        "track": "main",
        "status": "Poster",
        "abstract": "As an emerging field in Machine Learning, Explainable AI (XAI) has been offering remarkable performance in interpreting the decisions made by Convolutional Neural Networks (CNNs). To achieve visual explanations for CNNs, methods based on class activation mapping and randomized input sampling have gained great popularity. However, the attribution methods based on these techniques provide lower-resolution and blurry explanation maps that limit their explanation power. To circumvent this issue, visualization based on various layers is sought. In this work, we collect visualization maps from multiple layers of the model based on an attribution-based input sampling technique and aggregate them to reach a fine-grained and complete explanation. We also propose a layer selection strategy that applies to the whole family of CNN-based models, based on which our extraction framework is applied to visualize the last layers of each convolutional block of the model. Moreover, we perform an empirical analysis of the efficacy of derived lower-level information to enhance the represented attributions. Comprehensive experiments conducted on shallow and deep models trained on natural and industrial datasets, using both ground-truth and model-truth based evaluation metrics validate our proposed algorithm by meeting or outperforming the state-of-the-art methods in terms of explanation ability and visual quality, demonstrating that our method shows stability regardless of the size of objects or instances to be explained.",
        "primary_area": "Philosophy and Ethics of AI",
        "author": "Sam Sattarzadeh; Mahesh Sudhakar; Anthony Lem; Shervin Mehryar; Konstantinos N Plataniotis; Jongseong Jang; Hyunwoo Kim; Yeonjeong Jeong; Sangmin Lee; Kyunghoon Bae",
        "authorids": "",
        "aff": "University of Toronto; University of Toronto; University of Toronto; University of Toronto; UofT; LG AI Research; LG AI Research; LG AI Research; LG AI Research; LG AI Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17384/17384-13-20878-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11639-explaining-convolutional-neural-networks-through-attribution-based-input-sampling-and-block-wise-feature-aggregation/",
        "doi": "10.1609/aaai.v35i13.17384",
        "pdf_size": 1601164
    },
    {
        "id": "04987",
        "title": "Explaining Neural Matrix Factorization with Gradient Rollback",
        "track": "main",
        "status": "Poster",
        "abstract": "Explaining the predictions of neural black-box models is an important problem, especially when such models are used in applications where user trust is crucial. Estimating the influence of training examples on a learned neural model's behavior allows us to identify training examples most responsible for a given prediction and, therefore, to faithfully explain the output of a black-box model. The most generally applicable existing method is based on influence functions, which scale poorly for larger sample sizes and models.    We propose gradient rollback, a general approach for influence estimation, applicable to neural models where each parameter update step during gradient descent touches a smaller number of parameters, even if the overall number of parameters is large. Neural matrix factorization models trained with gradient descent are part of this model class. These models are popular and have found a wide range of applications in industry. Especially knowledge graph embedding methods, which belong to this class, are used extensively. We show that gradient rollback is highly efficient at both training and test time. Moreover, we show theoretically that the difference between gradient rollback's influence approximation and the true influence on a model's behavior is smaller than known bounds on the stability of stochastic gradient descent. This establishes that gradient rollback is robustly estimating example influence. We also conduct experiments which show that gradient rollback provides faithful explanations for knowledge base completion and recommender datasets. An implementation and an appendix are available.",
        "primary_area": "Neuro-Symbolic AI",
        "author": "Carolin Lawrence; Timo Sztyler; Mathias Niepert",
        "authorids": "",
        "aff": "NEC Laboratories Europe, Heidelberg, Germany; NEC Laboratories Europe, Heidelberg, Germany; NEC Laboratories Europe, Heidelberg, Germany",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16632/16632-13-20126-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04987-explaining-neural-matrix-factorization-with-gradient-rollback/",
        "doi": "10.1609/aaai.v35i6.16632",
        "pdf_size": 378984
    },
    {
        "id": "07639",
        "title": "Explanation Consistency Training: Facilitating Consistency-Based Semi-Supervised Learning with Interpretability",
        "track": "main",
        "status": "Poster",
        "abstract": "Unlabeled data exploitation and interpretability are usually both required in reality. They, however, are conducted independently, and very few works try to connect the two. For unlabeled data exploitation, state-of-the-art semi-supervised learning (SSL) results have been achieved via encouraging the consistency of model output on data perturbation, that is, consistency assumption. However, it remains hard for users to understand how particular decisions are made by state-of-the-art SSL models. To this end, in this paper we first disclose that the consistency assumption is closely related to causality invariance, where causality invariance lies in the main reason why the consistency assumption is valid. We then propose ECT (Explanation Consistency Training) which encourages a consistent reason of model decision under data perturbation. ECT employs model explanation as a surrogate of the causality of model output, which is able to bridge state-of-the-art interpretability to SSL models and alleviate the high complexity of causality. We realize ECT-SM for vision and ECT-ATT for NLP tasks. Experimental results on real-world data sets validate the highly competitive performance and better explanation of the proposed algorithms.",
        "primary_area": "Machine Learning II",
        "author": "Tao Han; Wei-Wei Tu; Yu-Feng Li",
        "authorids": "",
        "aff": "Nanjing University; 4Paradigm Inc.; Nanjing University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16934/16934-13-20428-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07639-explanation-consistency-training-facilitating-consistency-based-semi-supervised-learning-with-interpretability/",
        "doi": "10.1609/aaai.v35i9.16934",
        "pdf_size": 2771897
    },
    {
        "id": "09799",
        "title": "Explicitly Modeled Attention Maps for Image Classification",
        "track": "main",
        "status": "Poster",
        "abstract": "Self-attention networks have shown remarkable progress in computer vision tasks such as image classification. The main benefit of the self-attention mechanism is the ability to capture long-range feature interactions in attention-maps. However, the computation of attention-maps requires a learnable key, query, and positional encoding, whose usage is often not intuitive and computationally expensive. To mitigate this problem, we propose a novel self-attention module with explicitly modeled attention-maps using only a single learnable parameter for low computational overhead. The design of explicitly modeled attention-maps using geometric prior is based on the observation that the spatial context for a given pixel within an image is mostly dominated by its neighbors, while more distant pixels have a minor contribution. Concretely, the attention-maps are parametrized via simple functions (e.g., Gaussian kernel) with a learnable radius, which is modeled independently of the input content. Our evaluation shows that our method achieves an accuracy improvement of up to 2.2% over the ResNet-baselines in ImageNet ILSVRC and outperforms other self-attention methods such as AA-ResNet152 in accuracy by 0.9% with 6.4% fewer parameters and 6.7% fewer GFLOPs. This result empirically indicates the value of incorporating geometric prior into self-attention mechanism when applied in image classification.",
        "primary_area": "Machine Learning IV",
        "author": "Andong Tan; Duc Tam Nguyen; Maximilian Dax; Matthias Nie\u00dfner; Thomas Brox",
        "authorids": "",
        "aff": "Technical University of Munich Robert Bosch GmbH; University of Freiburg Robert Bosch GmbH; University of Bonn Robert Bosch GmbH; Technical University of Munich; University of Freiburg",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17178/17178-13-20672-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09799-explicitly-modeled-attention-maps-for-image-classification/",
        "doi": "10.1609/aaai.v35i11.17178",
        "pdf_size": 1662706
    },
    {
        "id": "02056",
        "title": "Exploiting Audio-Visual Consistency with Partial Supervision for Spatial Audio Generation",
        "track": "main",
        "status": "Poster",
        "abstract": "Human perceives rich auditory experience with distinct sound heard by ears. Videos recorded with binaural audio particular simulate how human receives ambient sound. However, a large number of videos are with monaural audio only, which would degrade the user experience due to the lack of ambient information. To address this issue, we propose an audio spatialization framework to convert a monaural video into a binaural one exploiting the relationship across audio and visual components. By preserving the left-right consistency in both audio and visual modalities, our learning strategy can be viewed as a self-supervised learning technique, and alleviates the dependency on a large amount of video data with ground truth binaural audio data during training. Experiments on benchmark datasets confirm the effectiveness of our proposed framework in both semi-supervised and fully supervised scenarios, with ablation studies and visualization further support the use of our model for audio spatialization.",
        "primary_area": "Computer Vision II",
        "author": "Yan-Bo Lin; Yu-Chiang Frank Wang",
        "authorids": "",
        "aff": "Graduate Inst. Communication Engineering, National Taiwan University, Taiwan; Graduate Inst. Communication Engineering, National Taiwan University, Taiwan ASUS Intelligent Cloud Services, Taiwan",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16302/16302-13-19796-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02056-exploiting-audio-visual-consistency-with-partial-supervision-for-spatial-audio-generation/",
        "doi": "10.1609/aaai.v35i3.16302",
        "pdf_size": 507140
    },
    {
        "id": "04063",
        "title": "Exploiting Behavioral Consistence for Universal User Representation",
        "track": "main",
        "status": "Poster",
        "abstract": "User modeling is critical for developing personalized services in industry. A common way for user modeling is to learn user representations that can be distinguished by their interests or preferences. In this work, we focus on developing universal user representation model. The obtained universal representations are expected to contain rich information, and be applicable to various downstream applications without further modifications (e.g., user preference prediction and user profiling). Accordingly, we can be free from the heavy work of training task-specific models for every downstream task as in previous works. In specific, we propose Self-supervised User Modeling Network (SUMN) to encode behavior data into the universal representation. It includes two key components. The first one is a new learning objective, which guides the model to fully identify and preserve valuable user information under a self-supervised learning framework. The other one is a multi-hop aggregation layer, which benefits the model capacity in aggregating diverse behaviors. Extensive experiments on benchmark datasets show that our approach can outperform state-of-the-art unsupervised representation methods, and even compete with supervised ones.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Jie Gu; Feng Wang; Qinghui Sun; Zhiquan Ye; Xiaoxiao Xu; Jingmin Chen; Jun Zhang",
        "authorids": "",
        "aff": "Alibaba Group, Hangzhou, China; Alibaba Group, Hangzhou, China; Alibaba Group, Hangzhou, China; Alibaba Group, Hangzhou, China; Alibaba Group, Hangzhou, China; Alibaba Group, Hangzhou, China; Alibaba Group, Hangzhou, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16527/16527-13-20021-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04063-exploiting-behavioral-consistence-for-universal-user-representation/",
        "doi": "10.1609/aaai.v35i5.16527",
        "pdf_size": 1311310
    },
    {
        "id": "06850",
        "title": "Exploiting Diverse Characteristics and Adversarial Ambivalence for Domain Adaptive Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "Adapting semantic segmentation models to new domains is an important but challenging problem. Recently enlightening progress has been made, but the performance of existing methods is unsatisfactory on real datasets where the new target domain comprises of heterogeneous sub-domains (e.g. diverse weather characteristics). We point out that carefully reasoning about the multiple modalities in the target domain can improve the robustness of adaptation models. To this end, we propose a condition-guided adaptation framework that is empowered by a special attentive progressive adversarial training (APAT) mechanism and a novel self-training policy. The APAT strategy progressively performs condition-specific alignment and attentive global feature matching. The new self-training scheme exploits the adversarial ambivalences of easy and hard adaptation regions and the correlations among target sub-domains effectively. We evaluate our method (DCAA) on various adaptation scenarios where the target images vary in weather conditions. The comparisons against baselines and the state-of-the-art approaches demonstrate the superiority of DCAA over the competitors.",
        "primary_area": "Machine Learning I",
        "author": "Bowen Cai; Huan Fu; Rongfei Jia; Binqiang Zhao; Hua Li; Yinghui Xu",
        "authorids": "",
        "aff": "Alibaba Group Institute of Computing Technology, Chinese Academy of Sciences; Alibaba Group; Alibaba Group; Alibaba Group; Institute of Computing Technology, Chinese Academy of Sciences; Alibaba Group",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16845/16845-13-20339-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06850-exploiting-diverse-characteristics-and-adversarial-ambivalence-for-domain-adaptive-segmentation/",
        "doi": "10.1609/aaai.v35i8.16845",
        "pdf_size": 3940729
    },
    {
        "id": "01921",
        "title": "Exploiting Learnable Joint Groups for Hand Pose Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose to estimate 3D hand pose by recovering the 3D coordinates of joints in a group-wise manner, where less-related joints are automatically categorized into different groups and exhibit different features. This is different from the previous methods where all the joints are considered holistically and share the same feature. The benefits of our method are illustrated by the principle of multi-task learning (MTL), i.e., by separating less-related joints into different groups (as different tasks), our method learns different features for each of them, therefore efficiently avoids the negative transfer (among less related tasks/groups of joints). The key of our method is a novel binary selector that automatically selects related joints into the same group. We implement such a selector with binary values stochastically sampled from a Concretedistribution, which is constructed using Gumbel softmax on trainable parameters. This enables us to preserve the differentiable property of the whole network. We further exploit features from those less-related groups by carrying out an additional feature fusing scheme among them, to learn more discriminative features. This is realized by implementing multiple 1x1 convolutions on the concatenated features, where each joint group contains a unique 1x1convolution  for feature fusion.  The detailed ablation analysis and the extensive experiments on several benchmark datasets demonstrate the promising performance of the proposed method over the state-of-the-art (SOTA) methods. Besides, our method achieves top-1 among all the methods that do not exploit the dense 3D shape labels on the most recently released FreiHAND competition at the submission date. The source code and models are available at https://github.com/moranli-aca/LearnableGroups-Hand.",
        "primary_area": "Computer Vision II",
        "author": "Moran Li; Yuan Gao; Nong Sang",
        "authorids": "",
        "aff": "Huazhong University of Science and Technology; Tencent AI Lab Huazhong University of Science and Technology; Huazhong University of Science and Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16287/16287-13-19781-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01921-exploiting-learnable-joint-groups-for-hand-pose-estimation/",
        "doi": "10.1609/aaai.v35i3.16287",
        "pdf_size": 1479623
    },
    {
        "id": "01584",
        "title": "Exploiting Relationship for Complex-scene Image Generation",
        "track": "main",
        "status": "Poster",
        "abstract": "The significant progress on Generative Adversarial Networks (GANs) has facilitated realistic single-object image generation based on language input. However, complex-scene generation (with various interactions among multiple objects) still suffers from messy layouts and object distortions, due to diverse configurations in layouts and appearances. Prior methods are mostly object-driven and ignore their inter-relations that play a significant role in complex-scene images. This work explores relationship-aware complex-scene image generation, where multiple objects are inter-related as a scene graph. With the help of relationships, we propose three major updates in the generation framework. First, reasonable spatial layouts are inferred by jointly considering the semantics and relationships among objects. Compared to standard location regression, we show relative scales and distances serve a more reliable target. Second, since the relations between objects have significantly influenced an object's appearance, we design a relation-guided generator to generate objects reflecting their relationships. Third, a novel scene graph discriminator is proposed to guarantee the consistency between the generated image and the input scene graph. Our method tends to synthesize plausible layouts and objects, respecting the interplay of multiple objects in an image. Experimental results on Visual Genome and HICO-DET datasets show that our proposed method significantly outperforms prior arts in terms of IS and FID metrics. Based on our user study and visual inspection, our method is more effective in generating logical layout and appearance for complex-scenes.",
        "primary_area": "Computer Vision I",
        "author": "Tianyu Hua; Hongdong Zheng; Yalong Bai; Wei Zhang; Xiao-Ping Zhang; Tao Mei",
        "authorids": "",
        "aff": "JD AI Research; JD AI Research; JD AI Research; JD AI Research; Ryerson University; JD AI Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16250/16250-13-19744-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01584-exploiting-relationship-for-complex-scene-image-generation/",
        "doi": "10.1609/aaai.v35i2.16250",
        "pdf_size": 1408416
    },
    {
        "id": "03538",
        "title": "Exploiting Sample Uncertainty for Domain Adaptive Person Re-Identification",
        "track": "main",
        "status": "Poster",
        "abstract": "Many unsupervised domain adaptive (UDA)  person ReID approaches combine clustering-based pseudo-label prediction with feature fine-tuning. However, because of domain gap, the pseudo-labels are not always reliable and there are noisy/incorrect labels. This would mislead the feature representation learning and deteriorate the performance. In this paper, we propose to estimate and exploit the credibility of the assigned pseudo-label of each sample to alleviate the influence of noisy labels, by suppressing the contribution of noisy samples. We build our baseline framework using the mean teacher method together with an additional contrastive loss. We have observed that a sample with a wrong pseudo-label through clustering in general has a weaker consistency between the output of the mean teacher model and the student model. Based on this finding, we propose to exploit the uncertainty (measured by consistency levels) to evaluate the reliability of the pseudo-label of a sample and incorporate the uncertainty to re-weight its contribution within various ReID losses, including the ID classification loss per sample, the triplet loss, and the contrastive loss. Our uncertainty-guided optimization brings significant improvement and achieves the state-of-the-art performance on benchmark datasets.",
        "primary_area": "Computer Vision III",
        "author": "Kecheng Zheng; Cuiling Lan; Wenjun Zeng; Zhizheng Zhang; Zheng-Jun Zha",
        "authorids": "",
        "aff": "University of Science and Technology of China; Microsoft Research; Microsoft Research; University of Science and Technology of China; University of Science and Technology of China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16468/16468-13-19962-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03538-exploiting-sample-uncertainty-for-domain-adaptive-person-re-identification/",
        "doi": "10.1609/aaai.v35i4.16468",
        "pdf_size": 553482
    },
    {
        "id": "10973",
        "title": "Exploiting Unlabeled Data via Partial Label Assignment for Multi-Class Semi-Supervised Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "In semi-supervised learning, one key strategy in exploiting unlabeled data is trying to estimate its pseudo-label based on current predictive model, where the unlabeled data assigned with pseudo-label is further utilized to enlarge labeled data set for model update. Nonetheless, the supervision information conveyed by pseudo-label is  prone to error especially when the performance of initial predictive model is mediocre due to limited amount of labeled data. In this paper, an intermediate unlabeled data exploitation strategy is investigated via partial label assignment, i.e. a set of candidate labels other than a single pseudo-label are assigned to the unlabeled data. We only assume that the ground-truth label of unlabeled data resides in the assigned candidate label set, which is less error-prone than trying to identify the single ground-truth label via pseudo-labeling. Specifically, a multi-class classifier is induced from the partial label examples with candidate labels to facilitate model induction with labeled examples. An iterative procedure is designed to enable labeling information communication between the classifiers induced from partial label examples and labeled examples, whose classification outputs are integrated to yield the final prediction. Comparative studies against state-of-the-art approaches clearly show the effectiveness of the proposed unlabeled data exploitation strategy for multi-class semi-supervised learning.",
        "primary_area": "Machine Learning V",
        "author": "Zhen-Ru Zhang; Qian-Wen Zhang; Yunbo Cao; Min-Ling Zhang",
        "authorids": "",
        "aff": "Southeast University Key Laboratory of Computer Network and Information Integration (Southeast University), Ministry of Education Tencent Cloud Xiaowei; Tencent Cloud Xiaowei; Tencent Cloud Xiaowei; Southeast University Key Laboratory of Computer Network and Information Integration (Southeast University), Ministry of Education Collaborative Innovation Center of Wireless Communications Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17310/17310-13-20804-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10973-exploiting-unlabeled-data-via-partial-label-assignment-for-multi-class-semi-supervised-learning/",
        "doi": "10.1609/aaai.v35i12.17310",
        "pdf_size": 764289
    },
    {
        "id": "10859",
        "title": "Exploration by Maximizing Renyi Entropy for Reward-Free RL Framework",
        "track": "main",
        "status": "Poster",
        "abstract": "Exploration is essential for reinforcement learning (RL). To face the challenges of exploration, we consider a reward-free RL framework that completely separates exploration from exploitation and brings new challenges for exploration algorithms. In the exploration phase, the agent learns an exploratory policy by interacting with a reward-free environment and collects a dataset of transitions by executing the policy. In the planning phase, the agent computes a good policy for any reward function based on the dataset without further interacting with the environment. This framework is suitable for the meta RL setting where there are many reward functions of interest. In the exploration phase, we propose to maximize the Renyi entropy over the state-action space and justify this objective theoretically. The success of using Renyi entropy as the objective results from its encouragement to explore the hard-to-reach state-actions. We further deduce a policy gradient formulation for this objective and design a practical exploration algorithm that can deal with complex environments. In the planning phase, we solve for good policies given arbitrary reward functions using a batch RL algorithm. Empirically, we show that our exploration algorithm is effective and sample efficient, and results in superior policies for arbitrary reward functions in the planning phase.",
        "primary_area": "Machine Learning V",
        "author": "Chuheng Zhang; Yuanying Cai; Longbo Huang; Jian Li",
        "authorids": "",
        "aff": "IIIS, Tsinghua University; IIIS, Tsinghua University; IIIS, Tsinghua University; IIIS, Tsinghua University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17297/17297-13-20791-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10859-exploration-by-maximizing-renyi-entropy-for-reward-free-rl-framework/",
        "doi": "10.1609/aaai.v35i12.17297",
        "pdf_size": 980270
    },
    {
        "id": "08047",
        "title": "Exploration via State influence Modeling",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper studies the challenging problem of reinforcement learning (RL) in hard exploration tasks with sparse rewards. It focuses on the exploration stage before the agent gets the first positive reward, in which case, traditional RL algorithms with simple exploration strategies often work poorly. Unlike previous methods using some attribute of a single state as the intrinsic reward to encourage exploration, this work leverages the social influence between different states to permit more efficient exploration. It introduces a general intrinsic reward construction method to evaluate the social influence of states dynamically. Three kinds of social influence are introduced for a state: conformity, power, and authority. By measuring the state\u2019s social influence, agents quickly find the focus state during the exploration process. The proposed RL framework with state social influence evaluation works well in hard exploration task. Extensive experimental analyses and comparisons in Grid Maze and many hard exploration Atari 2600 games demonstrate its high exploration efficiency.",
        "primary_area": "Machine Learning II",
        "author": "Yongxin Kang; Enmin Zhao; Kai Li; Junliang Xing",
        "authorids": "",
        "aff": "School of artificial intelligence, University of Chinese Academy of Sciences;Institute of Automation, Chinese Academy of Sciences; Institute of Automation, Chinese Academy of Sciences\uff1bSchool of artificial intelligence, University of Chinese Academy of Sciences; Institute of Automation, Chinese Academy of Sciences; Institute of Automation, Chinese Academy of Sciences",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16981/16981-13-20475-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08047-exploration-via-state-influence-modeling/",
        "doi": "10.1609/aaai.v35i9.16981",
        "pdf_size": 2719206
    },
    {
        "id": "11263",
        "title": "Exploration-Exploitation in Multi-Agent Learning: Catastrophe Theory Meets Game Theory",
        "track": "main",
        "status": "Poster",
        "abstract": "Exploration-exploitation is a powerful and practical tool in multi-agent learning (MAL), however, its effects are far from understood. To make progress in this direction, we study a smooth analogue of Q-learning. We start by showing that our learning model has strong theoretical justification as an optimal model for studying exploration-exploitation. Specifically, we prove that smooth Q-learning has bounded regret in arbitrary games for a cost model that explicitly captures the balance between game and exploration costs and that it always converges to the set of quantal-response equilibria (QRE), the standard solution concept for games under bounded rationality, in weighted potential games with heterogeneous learning agents. In our main task, we then turn to measure the effect of exploration in collective system performance. We characterize the geometry of the QRE surface in low-dimensional MAL systems and link our findings with catastrophe (bifurcation) theory. In particular, as the exploration hyperparameter evolves over-time, the system undergoes phase transitions where the number and stability of equilibria can change radically given an infinitesimal change to the exploration parameter. Based on this, we provide a formal theoretical treatment of how tuning the exploration parameter can provably lead to equilibrium selection with both positive as well as negative (and potentially unbounded) effects to system performance.",
        "primary_area": "Multiagent Systems",
        "author": "Stefanos Leonardos; Georgios Piliouras",
        "authorids": "",
        "aff": "Singapore University of Technology and Design; Singapore University of Technology and Design",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17343/17343-13-20837-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11263-exploration-exploitation-in-multi-agent-learning-catastrophe-theory-meets-game-theory/",
        "doi": "10.1609/aaai.v35i13.17343",
        "pdf_size": 3652494
    },
    {
        "id": "10999",
        "title": "Exploratory Machine Learning with Unknown Unknowns",
        "track": "main",
        "status": "Poster",
        "abstract": "In conventional supervised learning, a training dataset is given with ground-truth labels from a known label set, and the learned model will classify unseen instances to known labels. In real situations, when the learned models do not work well, users generally attribute the failure to the inadequate selection of learning algorithms or the lack of enough labeled training samples. In this paper, we point out that there is an important category of failure, which owes to the fact that there are unknown classes in the training data misperceived as other labels, and thus their existence was unknown from the given supervision. Such problems of unknown unknown classes can hardly be addressed by common re-selection of algorithms or accumulation of training samples. For this purpose, we propose the exploratory machine learning, where in this paradigm once user encounters unsatisfactory learning performance, she can examine the possibility and, if unknown unknowns really exist, deploy the optimal strategy of feature space augmentation to make the unknown classes observable and be enabled for learning. Theoretical analysis and empirical study on both synthetic and real datasets validate the efficacy of our proposal.",
        "primary_area": "Machine Learning V",
        "author": "Peng Zhao; Yu-Jie Zhang; Zhi-Hua Zhou",
        "authorids": "",
        "aff": "Nanjing University; Nanjing University; Nanjing University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17313/17313-13-20807-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10999-exploratory-machine-learning-with-unknown-unknowns/",
        "doi": "10.1609/aaai.v35i12.17313",
        "pdf_size": 959737
    },
    {
        "id": "13701",
        "title": "Exploring Auxiliary Reasoning Tasks for Task-oriented Dialog Systems with Meta Cooperative Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a Meta Cooperative Learning (MCL) framework for task-oriented dialog systems (TDSs). Our model consists of an auxiliary KB reasoning task for learning meta KB knowledge, an auxiliary dialogue reasoning task for learning dialogue patterns, and a TDS task (primary task) that aims at not only retrieving accurate entities from KB but also generating natural responses, which are coordinated to achieve collective success in both retrieving accurate KB entities and generating human-like responses via meta learning. Concretely, the dialog generation model amalgamates complementary meta KB and dialog knowledge from two novel auxiliary reasoning tasks that together provide integrated guidance to build a high-quality TDS by adding regularization terms to force primary network to produce similar results to auxiliary networks. While MCL automatically learns appropriate labels for the two auxiliary reasoning tasks from the primary task, without requiring access to any further data. The key idea behind MCL is to use the performance of the primary task, which is trained alongside the auxiliary tasks in one iteration, to improve the auxiliary labels for the next iteration with meta learning. Experimental results on three benchmark datasets show that MCL can generate higher quality responses compared to several strong baselines in terms of both automatic and human evaluations. Code to reproduce the results in this paper is available at: https://github.com/siat-nlp/MCL.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Bowen Qin; Min Yang; Lidong Bing; Qingshan Jiang; Chengming Li; Ruifeng Xu",
        "authorids": "",
        "aff": "Chinese Academy of Sciences; Chinese Academy of Sciences; Alibaba Group; Shenzhen Institutes of Advanced Technology; Chinese Academy of Sciences; Harbin Institute of Technology (Shenzhen)",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17615/17615-13-21109-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13701-exploring-auxiliary-reasoning-tasks-for-task-oriented-dialog-systems-with-meta-cooperative-learning/",
        "doi": "10.1609/aaai.v35i15.17615",
        "pdf_size": 400102
    },
    {
        "id": "13933",
        "title": "Exploring Explainable Selection to Control Abstractive Summarization",
        "track": "main",
        "status": "Poster",
        "abstract": "Like humans, document summarization models can interpret a document\u2019s contents in a number of ways. Unfortunately, the  neural models of today are largely black boxes that provide little explanation of how or why they generated a summary in the way they did. Therefore, to begin prying open the black box and to inject a level of control into the substance of the final summary, we developed a novel select-and-generate framework that focuses on explainability. By revealing the latent centrality and interactions between sentences, along with scores for novelty and relevance, users are given a window into the choices a model is making and an opportunity to guide those choices in a more desirable direction. A novel pair-wise matrix captures the sentence interactions, centrality and attribute scores, and a mask with tunable attribute thresholds allows the user to control which sentences are likely to be included in the extraction. A sentence-deployed attention mechanism in the abstractor ensures the final summary emphasizes the desired content. Additionally, the encoder is adaptable, supporting both Transformer- and BERT-based configurations. In a series of experiments assessed with ROUGE metrics and two human evaluations, ESCA outperformed eight state-of-the-art models on the CNN/DailyMail and NYT50 benchmark datasets.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Haonan Wang; Yang Gao; Yu Bai; Mirella Lapata; Heyan Huang",
        "authorids": "",
        "aff": "School of Computer Science and Technology, Beijing Institute of Technology; School of Computer Science and Technology, Beijing Institute of Technology; School of Computer Science and Technology, Beijing Institute of Technology; Institute for Language, Cognition and Computation, School of Informatics, University of Edinburgh; Beijing Engineering Research Center of High Volume Language Information Processing and Cloud Computing Applications School of Computer Science and Technology, Beijing Institute of Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17641/17641-13-21135-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13933-exploring-explainable-selection-to-control-abstractive-summarization/",
        "doi": "10.1609/aaai.v35i15.17641",
        "pdf_size": 657625
    },
    {
        "id": "13754",
        "title": "Exploring Transfer Learning For End-to-End Spoken Language Understanding",
        "track": "main",
        "status": "Poster",
        "abstract": "Voice Assistants such as Alexa, Siri, and Google Assistant typically use a two-stage Spoken Language Understanding pipeline; first, an Automatic Speech Recognition (ASR) component to process customer speech and generate text transcriptions, followed by a Natural Language Understanding (NLU) component to map transcriptions to an actionable hypothesis. An end-to-end (E2E) system that goes directly from speech to a hypothesis is a more attractive option. These systems were shown to be smaller, faster, and better optimized. However, they require massive amounts of end-to-end training data and in addition, don't take advantage of the already available ASR and NLU training data.  In this work, we propose an E2E system that is designed to jointly train on multiple speech-to-text tasks, such as ASR (speech-transcription) and SLU (speech-hypothesis), and text-to-text tasks, such as NLU (text-hypothesis). We call this the Audio-Text All-Task (AT-AT) Model and we show that it beats the performance of E2E models trained on individual tasks, especially ones trained on limited data. We show this result on an internal music dataset and two public datasets, FluentSpeech and SNIPS Audio, where we achieve state-of-the-art results. Since our model can process both speech and text input sequences and learn to predict a target sequence, it also allows us to do zero-shot E2E SLU by training on only text-hypothesis data (without any speech) from a new domain. We evaluate this ability of our model on the Facebook TOP dataset and set a new benchmark for zeroshot E2E performance. We release the audio data collected for the TOP dataset for future research.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Subendhu Rongali; Beiye Liu; Liwei Cai; Konstantine Arkoudas; Chengwei Su; Wael Hamza",
        "authorids": "",
        "aff": "Amazon Alexa AI, New York University of Massachusetts Amherst; Amazon Alexa AI, New York; Amazon Alexa AI, New York; Amazon Alexa AI, New York; Amazon Alexa AI, New York; Amazon Alexa AI, New York",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17621/17621-13-21115-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13754-exploring-transfer-learning-for-end-to-end-spoken-language-understanding/",
        "doi": "10.1609/aaai.v35i15.17621",
        "pdf_size": 168193
    },
    {
        "id": "11648",
        "title": "Exploring the Vulnerability of Deep Neural Networks: A Study of Parameter Corruption",
        "track": "main",
        "status": "Poster",
        "abstract": "We argue that the vulnerability of model parameters is of crucial value to the study of model robustness and generalization but little research has been devoted to understanding this matter. In this work, we propose an indicator to measure the robustness of neural network parameters by exploiting their vulnerability via parameter corruption. The proposed indicator describes the maximum loss variation in the non-trivial worst-case scenario under parameter corruption. For practical purposes, we give a gradient-based estimation, which is far more effective than random corruption trials that can hardly induce the worst accuracy degradation. Equipped with theoretical support and empirical validation, we are able to systematically investigate the robustness of different model parameters and reveal vulnerability of deep neural networks that has been rarely paid attention to before. Moreover, we can enhance the models accordingly with the proposed adversarial corruption-resistant training, which not only improves the parameter robustness but also translates into accuracy elevation.",
        "primary_area": "Philosophy and Ethics of AI",
        "author": "Xu Sun; Zhiyuan Zhang; Xuancheng Ren; Ruixuan Luo; Liangyou Li",
        "authorids": "",
        "aff": "Peking University; Peking University; Peking University; Peking University; Huawei Noah's Ark Lab",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17385/17385-13-20879-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11648-exploring-the-vulnerability-of-deep-neural-networks-a-study-of-parameter-corruption/",
        "doi": "10.1609/aaai.v35i13.17385",
        "pdf_size": 8834141
    },
    {
        "id": "06956",
        "title": "Extending Multi-Sense Word Embedding to Phrases and Sentences for Unsupervised Semantic Applications",
        "track": "main",
        "status": "Poster",
        "abstract": "Most unsupervised NLP models represent each word with a single point or single region in semantic space, while the existing multi-sense word embeddings cannot represent longer word sequences like phrases or sentences. We propose a novel embedding method for a text sequence (a phrase or a sentence) where each sequence is represented by a distinct set of multi-mode codebook embeddings to capture different semantic facets of its meaning. The codebook embeddings can be viewed as the cluster centers which summarize the distribution of possibly co-occurring words in a pre-trained word embedding space. We introduce an end-to-end trainable neural model that directly predicts the set of cluster centers from the input text sequence during test time. Our experiments show that the per-sentence codebook embeddings significantly improve the performances in unsupervised sentence similarity and extractive summarization benchmarks. In phrase similarity experiments, we discover that the multi-facet embeddings provide an interpretable semantic representation but do not outperform the single-facet baseline.",
        "primary_area": "Machine Learning I",
        "author": "Haw-Shiuan Chang; Amol Agrawal; Andrew McCallum",
        "authorids": "",
        "aff": "University of Massachusetts Amherst; University of Massachusetts Amherst; University of Massachusetts Amherst",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16857/16857-13-20351-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06956-extending-multi-sense-word-embedding-to-phrases-and-sentences-for-unsupervised-semantic-applications/",
        "doi": "10.1609/aaai.v35i8.16857",
        "pdf_size": 212604
    },
    {
        "id": "12612",
        "title": "Extracting Zero-shot Structured Information from Form-like Documents: Pretraining with Keys and Triggers",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we revisit the problem of extracting the values of a given set of key fields from form-like documents. It is the vital step to support many downstream applications, such as knowledge base construction, question answering, document comprehension and so on. Previous studies ignore the semantics of the given keys by considering them only as the class labels, and thus might be incapable to handle zero-shot keys. Meanwhile, although these models often leverage the attention mechanism, the learned features might not reflect the true proxy of explanations on why humans would recognize the value for the key, and thus could not well generalize to new documents. To address these issues, we propose a Key-Aware and Trigger-Aware (KATA) extraction model. With the input key, it explicitly learns two mappings, namely from key representations to trigger representations and then from trigger representations to values. These two mappings might be intrinsic and invariant across different keys and documents. With a large training set automatically constructed based on the Wikipedia data, we pre-train these two mappings. Experiments with the fine-tuning step to two applications show that the proposed model achieves more than 70% accuracy for the extraction of zero-shot keys while previous methods all fail.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Rongyu Cao; Ping Luo",
        "authorids": "",
        "aff": "Key Lab of Intelligent Information Processing of Chinese Academy of Sciences University of Chinese Academy of Sciences; Key Lab of Intelligent Information Processing of Chinese Academy of Sciences University of Chinese Academy of Sciences Peng Cheng Laboratory",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17494/17494-13-20988-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12612-extracting-zero-shot-structured-information-from-form-like-documents-pretraining-with-keys-and-triggers/",
        "doi": "10.1609/aaai.v35i14.17494",
        "pdf_size": 1592409
    },
    {
        "id": "03941",
        "title": "Extreme k-Center Clustering",
        "track": "main",
        "status": "Poster",
        "abstract": "Metric clustering is a fundamental primitive in machine learning with several applications for mining massive datasets. An important example of metric clustering is the k-center problem. While this problem has been extensively studied in distributed settings, all previous algorithms use \u03a9(k) space per machine and \u03a9(n k) total work. In this paper, we develop the first highly scalable approximation algorithm for k-center clustering, with O~(n^\u03b5) space per machine and O~(n^(1+\u03b5)) total work, for arbitrary small constant \u03b5. It produces an O(log log log n)-approximate solution with k(1+o(1)) centers in O(log log n) rounds of computation.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "MohammadHossein Bateni; Hossein Esfandiari; Manuela Fischer; Vahab Mirrokni",
        "authorids": "",
        "aff": "Google Research; Google Research; ETH Zurich; Google Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16513/16513-13-20007-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03941-extreme-k-center-clustering/",
        "doi": "10.1609/aaai.v35i5.16513",
        "pdf_size": 765225
    },
    {
        "id": "02109",
        "title": "F2Net: Learning to Focus on the Foreground for Unsupervised Video Object Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "Although deep learning based methods have achieved great progress in unsupervised video object segmentation, difficult scenarios (e.g., visual similarity, occlusions, and appearance changing) are still no well-handled. To alleviate these issues, we propose a novel Focus on Foreground Network  (F2Net), which delves into the intra-inter frame details for the foreground objects and thus effectively improve the segmentation performance. Specifically, our proposed network consists of three main parts: Siamese Encoder Module, Center Guiding Appearance Diffusion Module, and Dynamic Information Fusion Module. Firstly, we take a siamese encoder to extract the feature representations of paired frames (reference frame and current frame). Then, a Center Guiding Appearance Diffusion Module is designed to capture the inter-frame feature (dense correspondences between reference frame and current frame), intra-frame feature (dense correspondences in current frame), and original semantic feature of current frame. Different from the Anchor Diffusion Network, we establish a Center Prediction Branch to predict the center location of the foreground object in current frame and leverage the center point information as spatial guidance prior to enhance the inter-frame and intra-frame feature extraction, and thus the feature representation considerably focus on the foreground objects. Finally, we propose a Dynamic Information Fusion Module to automatically select relatively important features through three aforementioned different level features. Extensive experiments on DAVIS, Youtube-object, and FBMS datasets show that our proposed F2Net achieves the state-of-the-art performance with significant improvement.",
        "primary_area": "Computer Vision II",
        "author": "Daizong Liu; Dongdong Yu; Changhu Wang; Pan Zhou",
        "authorids": "",
        "aff": "Huazhong University of Science and Technology, China; ByteDance AI Lab, China; ByteDance AI Lab, China; Huazhong University of Science and Technology, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16308/16308-13-19802-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02109-f2net-learning-to-focus-on-the-foreground-for-unsupervised-video-object-segmentation/",
        "doi": "10.1609/aaai.v35i3.16308",
        "pdf_size": 2717557
    },
    {
        "id": "09233",
        "title": "FC-GAGA: Fully Connected Gated Graph Architecture for Spatio-Temporal Traffic Forecasting",
        "track": "main",
        "status": "Poster",
        "abstract": "Forecasting of multivariate time-series is an important problem that has applications in traffic management, cellular network configuration, and quantitative finance. A special case of the problem arises when there is a graph available that captures the relationships between the time-series. In this paper we propose a novel learning architecture that achieves performance competitive with or better than the best existing algorithms, without requiring knowledge of the graph. The key element of our proposed architecture is the learnable fully connected hard graph gating mechanism that enables the use of the state-of-the-art and highly computationally efficient fully connected time-series forecasting architecture in traffic forecasting applications. Experimental results for two public traffic network datasets illustrate the value of our approach, and ablation studies confirm the importance of each element of the architecture. The code is available here: https://github.com/boreshkinai/fc-gaga.",
        "primary_area": "Machine Learning III",
        "author": "Boris  N. Oreshkin; Arezou Amini; Lucy Coyle; Mark Coates",
        "authorids": "",
        "aff": "Unity Technologies; McGill University; McGill University; McGill University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17114/17114-13-20608-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09233-fc-gaga-fully-connected-gated-graph-architecture-for-spatio-temporal-traffic-forecasting/",
        "doi": "10.1609/aaai.v35i10.17114",
        "pdf_size": 1056760
    },
    {
        "id": "02136",
        "title": "FCFR-Net: Feature Fusion based Coarse-to-Fine Residual Learning for Depth Completion",
        "track": "main",
        "status": "Poster",
        "abstract": "Depth completion aims to recover a dense depth map from a sparse depth map with the corresponding color image as input. Recent approaches mainly formulate the depth completion as a one-stage end-to-end learning task, which outputs dense depth maps directly. However, the feature extraction and supervision in one-stage frameworks are insufficient, limiting the performance of these approaches. To address this problem, we propose a novel end-to-end residual learning framework, which formulates the depth completion as a two-stage learning task, i.e., a sparse-to-coarse stage and a coarse-to-fine stage. First, a coarse dense depth map is obtained by a simple CNN framework. Then, a refined depth map is further obtained using a residual learning strategy in the coarse-to-fine stage with coarse depth map and color image as input. Specially, in the coarse-to-fine stage, a channel shuffle extraction operation is utilized to extract more representative features from color image and coarse depth map, and an energy based fusion operation is exploited to effectively fuse these features obtained by channel shuffle operation, thus leading to more accurate and refined depth maps. We achieve SoTA performance in RMSE on KITTI benchmark. Extensive experiments on other datasets future demonstrate the superiority of our approach over current state-of-the-art depth completion approaches.",
        "primary_area": "Computer Vision II",
        "author": "Lina Liu; Xibin Song; Xiaoyang Lyu; Junwei Diao; Mengmeng Wang; Yong Liu; Liangjun Zhang",
        "authorids": "",
        "aff": "Institute of Cyber-Systems and Control, Zhejiang University, China Baidu Research, China; Baidu Research, China National Engineering Laboratory of Deep Learning Technology and Application, China; Institute of Cyber-Systems and Control, Zhejiang University, China; Institute of Cyber-Systems and Control, Zhejiang University, China; Institute of Cyber-Systems and Control, Zhejiang University, China; Institute of Cyber-Systems and Control, Zhejiang University, China; Baidu Research, China National Engineering Laboratory of Deep Learning Technology and Application, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16311/16311-13-19805-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02136-fcfr-net-feature-fusion-based-coarse-to-fine-residual-learning-for-depth-completion/",
        "doi": "10.1609/aaai.v35i3.16311",
        "pdf_size": 9632565
    },
    {
        "id": "12776",
        "title": "FILTER: An Enhanced Fusion Method for Cross-lingual Language Understanding",
        "track": "main",
        "status": "Poster",
        "abstract": "Large-scale cross-lingual language models (LM), such as mBERT, Unicoder and XLM, have achieved great success in cross-lingual representation learning. However, when applied to zero-shot cross-lingual transfer tasks, most existing methods use only single-language input for LM finetuning, without leveraging the intrinsic cross-lingual alignment between different languages that proves essential for multilingual tasks. In this paper, we propose FILTER, an enhanced fusion method that takes cross-lingual data as input for XLM finetuning. Specifically, FILTER first encodes text input in the source language and its translation in the target language independently in the shallow layers, then performs cross-language fusion to extract multilingual knowledge in the intermediate layers, and finally performs further language-specific encoding. During inference, the model makes predictions based on the text input in the target language and its translation in the source language. For simple tasks such as classification, translated text in the target language shares the same label as the source language. However, this shared label becomes less accurate or even unavailable for more complex tasks such as question answering, NER and POS tagging. To tackle this issue, we further propose an additional KL-divergence self-teaching loss for model training, based on auto-generated soft pseudo-labels for translated text in the target language.  Extensive experiments demonstrate that FILTER achieves new state of the art on two challenging multilingual multi-task benchmarks, XTREME and XGLUE.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Yuwei Fang; Shuohang Wang; Zhe Gan; Siqi Sun; Jingjing Liu",
        "authorids": "",
        "aff": "Microsoft Dynamics 365 AI Research; Microsoft Dynamics 365 AI Research; Microsoft Dynamics 365 AI Research; Microsoft Dynamics 365 AI Research; Microsoft Dynamics 365 AI Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17512/17512-13-21006-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12776-filter-an-enhanced-fusion-method-for-cross-lingual-language-understanding/",
        "doi": "10.1609/aaai.v35i14.17512",
        "pdf_size": 377726
    },
    {
        "id": "11433",
        "title": "FIMAP: Feature Importance by Minimal Adversarial Perturbation",
        "track": "main",
        "status": "Poster",
        "abstract": "Instance-based model-agnostic feature importance explanations (LIME, SHAP, L2X) are a popular form of algorithmic transparency. These methods generally return either a weighting or subset of input features as an explanation for the classification of an instance. An alternative literature argues instead that counterfactual instances, which alter the black-box model's classification, provide a more actionable form of explanation. We present Feature Importance by Minimal Adversarial Perturbation (FIMAP), a neural network based approach that unifies feature importance and counterfactual explanations. We show that this approach combines the two paradigms, recovering the output of feature-weighting methods in continuous feature spaces, whilst indicating the direction in which the nearest counterfactuals can be found. Our method also provides an implicit confidence estimate in its own explanations, something existing methods lack. Additionally, FIMAP improves upon the speed of sampling-based methods, such as LIME, by an order of magnitude, allowing for explanation deployment in time-critical applications. We extend our approach to categorical features using a partitioned Gumbel layer and demonstrate its efficacy on standard datasets.",
        "primary_area": "Philosophy and Ethics of AI",
        "author": "Matt Chapman-Rounds; Umang Bhatt; Erik Pazos; Marc-Andre Schulz; Konstantinos Georgatzis",
        "authorids": "",
        "aff": "University of Edinburgh; University of Cambridge; QuantumBlack; Department of Psychiatry and Psychotherapy, Charit\u00e9\u2013Universit\u00e4tsmedizin Berlin,; QuantumBlack",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17362/17362-13-20856-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11433-fimap-feature-importance-by-minimal-adversarial-perturbation/",
        "doi": "10.1609/aaai.v35i13.17362",
        "pdf_size": 1118140
    },
    {
        "id": "13161",
        "title": "FIXMYPOSE: Pose Correctional Captioning and Retrieval",
        "track": "main",
        "status": "Poster",
        "abstract": "Interest in physical therapy and individual exercises such as yoga/dance has increased alongside the well-being trend, and people globally enjoy such exercises at home/office via video streaming platforms. However, such exercises are hard to follow without expert guidance. Even if experts can help, it is almost impossible to give personalized feedback to every trainee remotely. Thus, automated pose correction systems are required more than ever, and we introduce a new captioning dataset named FixMyPose to address this need. We collect natural language descriptions of correcting a \u201ccurrent\u201d pose to look like a \u201ctarget\u201d pose. To support a multilingual setup, we collect descriptions in both English and Hindi. The collected descriptions have interesting linguistic properties such as egocentric relations to the environment objects, analogous references, etc., requiring an understanding of spatial relations and commonsense knowledge about postures. Further, to avoid ML biases, we maintain a balance across characters with diverse demographics, who perform a variety of movements in several interior environments (e.g., homes, offices). From our FixMyPose dataset, we introduce two tasks: the pose-correctional-captioning task and its reverse, the target-pose-retrieval task. During the correctional-captioning task, models must generate the descriptions of how to move from the current to the target pose image, whereas in the retrieval task, models should select the correct target pose given the initial pose and the correctional description. We present strong cross-attention baseline models (uni/multimodal, RL, multilingual) and also show that our baselines are competitive with other models when evaluated on other image-difference datasets. We also propose new task-specific metrics (object-match, body-part-match, direction-match) and conduct human evaluation for more reliable evaluation, and we demonstrate a large human-model performance gap suggesting room for promising future work. Finally, to verify the sim-to-real transfer of our FixMyPose dataset, we collect a set of real images and show promising performance on these images. Data and code are available: https://fixmypose-unc.github.io.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Hyounghun Kim; Abhay Zala; Graham Burri; Mohit Bansal",
        "authorids": "",
        "aff": "University of North Carolina at Chapel Hill; University of North Carolina at Chapel Hill; University of North Carolina at Chapel Hill; University of North Carolina at Chapel Hill",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17555/17555-13-21049-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13161-fixmypose-pose-correctional-captioning-and-retrieval/",
        "doi": "10.1609/aaai.v35i14.17555",
        "pdf_size": 6945575
    },
    {
        "id": "13916",
        "title": "FL-MSRE: A Few-Shot Learning based Approach to Multimodal Social Relation Extraction",
        "track": "main",
        "status": "Poster",
        "abstract": "Social relation extraction (SRE for short), which aims to infer the social relation between two people in daily life, has been demonstrated to be of great value in reality. Existing methods for SRE consider extracting social relation only from unimodal information such as text or image, ignoring the high coupling of multimodal information. Moreover, previous studies overlook the serious unbalance distribution on social relations. To address these issues, this paper proposes FL-MSRE, a few-shot learning based approach to extracting social relations from both texts and face images. Considering the lack of multimodal social relation datasets, this paper also presents three multimodal datasets annotated from four classical masterpieces and corresponding TV series. Inspired by the success of BERT, we propose a strong BERT based baseline to extract social relation from text only. FL-MSRE is empirically shown to outperform the baseline significantly. This demonstrates that using face images benefits text-based SRE. Further experiments also show that using two faces from different images achieves similar performance as from the same image. This means that FL-MSRE is suitable for a wide range of SRE applications where the faces of two people can only be collected from different images.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Hai Wan; Manrong Zhang; Jianfeng Du; Ziling Huang; Yufei Yang; Jeff Z. Pan",
        "authorids": "",
        "aff": "School of Computer Science and Engineering, Sun Yat-sen University; School of Computer Science and Engineering, Sun Yat-sen University; Guangzhou Key Laboratory of Multilingual Intelligent Processing, Guangdong University of Foreign Studies Pazhou Lab; School of Computer Science and Engineering, Sun Yat-sen University; School of Computer Science and Engineering, Sun Yat-sen University; School of Informatics, The University of Edinburgh",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17639/17639-13-21133-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13916-fl-msre-a-few-shot-learning-based-approach-to-multimodal-social-relation-extraction/",
        "doi": "10.1609/aaai.v35i15.17639",
        "pdf_size": 2982719
    },
    {
        "id": "08688",
        "title": "FLAME: Differentially Private Federated Learning in the Shuffle Model",
        "track": "main",
        "status": "Poster",
        "abstract": "Federated Learning (FL) is a promising machine learning paradigm that enables the analyzer to train a model without collecting users' raw data. To ensure users' privacy, differentially private federated learning has been intensively studied. The existing works are mainly based on the curator model or local model of differential privacy. However, both of them have pros and cons. The curator model allows greater accuracy but requires a trusted analyzer.  In the local model where users randomize local data before sending them to the analyzer, a trusted analyzer is not required but the accuracy is limited. In this work, by leveraging the textit{privacy amplification} effect in the recently proposed shuffle model of differential privacy, we achieve the best of two worlds, i.e., accuracy in the curator model and strong privacy without relying on any trusted party. We first propose an FL framework in the shuffle model and a simple protocol (SS-Simple) extended from existing work. We find that SS-Simple only provides an insufficient privacy amplification effect in FL since the dimension of the model parameter is quite large. To solve this challenge, we propose an enhanced protocol (SS-Double) to increase the privacy amplification effect by subsampling. Furthermore, for boosting the utility when the model size is greater than the user population, we propose an advanced protocol (SS-Topk) with gradient sparsification techniques. We also provide theoretical analysis and numerical evaluations of the privacy amplification of the proposed protocols. Experiments on real-world dataset validate that SS-Topk improves the testing accuracy by 60.7% than the local model based FL. We highlight an observation that SS-Topk improves the accuracy by 33.94% than the curator model based FL without any trusted party. Compared with non-private FL, our protocol SS-Topk only lose 1.48% accuracy under (2.348, 5e-6)-DP per epoch.",
        "primary_area": "Machine Learning III",
        "author": "Ruixuan Liu; Yang Cao; Hong Chen; Ruoyang Guo; Masatoshi Yoshikawa",
        "authorids": "",
        "aff": "Renmin University of China; Kyoto University; Renmin University of China; Renmin University of China; Kyoto University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17053/17053-13-20547-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08688-flame-differentially-private-federated-learning-in-the-shuffle-model/",
        "doi": "10.1609/aaai.v35i10.17053",
        "pdf_size": 5135490
    },
    {
        "id": "03083",
        "title": "FaceController: Controllable Attribute Editing for Face in the Wild",
        "track": "main",
        "status": "Poster",
        "abstract": "Face attribute editing aims to generate faces with one or multiple desired face attributes manipulated while other details are preserved. Unlike prior works such as GAN inversion which has an expensive reverse mapping process, we propose a simple feed-forward network to generate high-fidelity manipulated faces. By simply employing some existing and easy-obtainable prior information, our method can control, transfer, and edit diverse attributes of faces in the wild. The proposed method can consequently be applied to various applications such as face swapping, face relighting, and makeup transfer. In our method, we decouple identity, expression, pose, and illumination by using 3D priors; separate texture and colors by using region-wise style codes. All the information is embedded into adversarial learning by our identity-style normalization module. Disentanglement losses are proposed to enhance the generator to extract information independently from each attribute. Comprehensive quantitative and qualitative evaluations have been conducted. In a single framework, our method achieves the best or competitive scores on a variety of face applications.",
        "primary_area": "Computer Vision III",
        "author": "Zhiliang Xu; Xiyu Yu; Zhibin Hong; Zhen Zhu; Junyu Han; Jingtuo Liu; Errui Ding; Xiang Bai",
        "authorids": "",
        "aff": "Huazhong University of Science and Technology; Baidu Inc.; Baidu Inc.; Huazhong University of Science and Technology; Baidu Inc.; Baidu Inc.; Baidu Inc.; Huazhong University of Science and Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16417/16417-13-19911-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03083-facecontroller-controllable-attribute-editing-for-face-in-the-wild/",
        "doi": "10.1609/aaai.v35i4.16417",
        "pdf_size": 2799504
    },
    {
        "id": "05734",
        "title": "Facility\u2019s Perspective to Fair Facility Location Problems",
        "track": "main",
        "status": "Poster",
        "abstract": "We study the problem faced by a decision maker who wants to locate a set of facilities on a real line and allocate agents/items to the facilities. The items have given locations on the line, and can only be assigned to one of their closest facilities. The facilities are controlled by managers, who have additive utility over the items. An optimal solution that maximizes the (utilitarian or egalitarian) social welfare of the facilities may present a very unbalanced allocation of the items to the facilities and hence be perceived as unfair. In this paper, we are interested in fair allocation among facility managers and consider the well-studied proportionality and envy-freeness fairness notions and their relaxations. We assess the availability, existence, approximability, and the quality (price of fairness) of fair solutions, where the quality measures the system efficiency loss under a fair allocation compared to the one that maximizes the social welfare. Further, we show that one can find a Pareto-optimal solution in polynomial time.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Chenhao Wang; Xiaoying Wu; Minming Li; Hau Chan",
        "authorids": "",
        "aff": "University of Nebraska-Lincoln; AMSS, Chinese Academy of Sciences University of Chinese Academy of Sciences; City University of Hong Kong; University of Nebraska-Lincoln",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16719/16719-13-20213-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05734-facilitys-perspective-to-fair-facility-location-problems/",
        "doi": "10.1609/aaai.v35i6.16719",
        "pdf_size": 159124
    },
    {
        "id": "13825",
        "title": "Fact-Enhanced Synthetic News Generation",
        "track": "main",
        "status": "Poster",
        "abstract": "The advanced text generation methods have witnessed great success in text summarization, language translation, and synthetic news generation. However, these techniques can be abused to generate disinformation and fake news. To better understand the potential threats of synthetic news, we develop a novel generation method FACTGEN to generate high-quality news content.  The majority of existing text generation methods either afford limited supplementary information or lose consistency between the input and output which makes the synthetic news less trustworthy. To address these issues, FACTGEN retrieves external facts to enrich the output and reconstructs the input claim from the generated content to improve the consistency among the input and the output. Experiment results on real-world datasets demonstrate that the generated news contents of FACTGEN are consistent and contain rich facts. We also discuss an effective defending technique to identify these synthetic news pieces if FACTGEN was used to generate fake news.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Kai Shu; Yichuan Li; Kaize Ding; Huan Liu",
        "authorids": "",
        "aff": "Illinois Institute of Technology, Chicago, IL, USA; Worcester Polytechnic Institute, Worcester, MA, USA; Arizona State University, Tempe, AZ, USA; Arizona State University, Tempe, AZ, USA",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17629/17629-13-21123-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13825-fact-enhanced-synthetic-news-generation/",
        "doi": "10.1609/aaai.v35i15.17629",
        "pdf_size": 484668
    },
    {
        "id": "11630",
        "title": "Fair Influence Maximization: a Welfare Optimization Approach",
        "track": "main",
        "status": "Poster",
        "abstract": "Several behavioral, social, and public health interventions, such as suicide/HIV prevention or community preparedness against natural disasters, leverage social network information to maximize outreach. Algorithmic influence maximization techniques have been proposed to aid with the choice of ``peer leaders'' or ``influencers'' in such interventions. Yet, traditional algorithms for influence maximization have not been designed with these interventions in mind. As a result, they may disproportionately exclude minority communities from the benefits of the intervention. This has motivated research on fair influence maximization. Existing techniques come with two major drawbacks. First, they require committing to a single fairness measure. Second, these measures are typically imposed as strict constraints leading to undesirable properties such as wastage of resources. To address these shortcomings, we provide a principled characterization of the properties that a fair influence maximization algorithm should satisfy. In particular, we propose a framework based on social welfare theory, wherein the cardinal utilities derived by each community are aggregated using the isoelastic social welfare functions. Under this framework, the trade-off between fairness and efficiency can be controlled by a single inequality aversion design parameter. We then show under what circumstances our proposed principles can be satisfied by a welfare function. The resulting optimization problem is monotone and submodular and can be solved efficiently with optimality guarantees. Our framework encompasses as special cases leximin and proportional fairness. Extensive experiments on synthetic and real world datasets including a case study on landslide risk management demonstrate the efficacy of the proposed framework.",
        "primary_area": "Philosophy and Ethics of AI",
        "author": "Aida Rahmattalabi; Shahin Jabbari; Himabindu Lakkaraju; Phebe Vayanos; Max Izenberg; Ryan Brown; Eric Rice; Milind Tambe",
        "authorids": "",
        "aff": "University of Southern California; Harvard University; Harvard University; University of Southern California; Pardee RAND Graduate School; RAND Corporation; University of Southern California; Harvard University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17383/17383-13-20877-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11630-fair-influence-maximization-a-welfare-optimization-approach/",
        "doi": "10.1609/aaai.v35i13.17383",
        "pdf_size": 2663741
    },
    {
        "id": "11506",
        "title": "Fair Representations by Compression",
        "track": "main",
        "status": "Poster",
        "abstract": "Organizations that collect and sell data face increasing scrutiny for the discriminatory use of data. We propose a novel unsupervised approach to map data into a compressed binary representation independent of sensitive attributes. We show that in an information bottleneck framework,  a parsimonious representation should filter out information related to sensitive attributes if they are provided directly to the decoder. Empirical results show that the method achieves state-of-the-art accuracy-fairness trade-off  and that explicit control of the entropy of the representation bit stream allows the user to move smoothly and simultaneously along both rate-distortion and rate-fairness curves.",
        "primary_area": "Philosophy and Ethics of AI",
        "author": "Xavier Gitiaux; Huzefa Rangwala",
        "authorids": "",
        "aff": "George Mason University; George Mason University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17370/17370-13-20864-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11506-fair-representations-by-compression/",
        "doi": "10.1609/aaai.v35i13.17370",
        "pdf_size": 629889
    },
    {
        "id": "05472",
        "title": "Fair and Efficient Allocations under Lexicographic Preferences",
        "track": "main",
        "status": "Poster",
        "abstract": "Envy-freeness up to any good (EFX) provides a strong and intuitive guarantee of fairness in the allocation of indivisible goods. But whether such allocations always exist or whether they can be efficiently computed remains an important open question. We study the existence and computation of EFX in conjunction with various other economic properties under lexicographic preferences--a well-studied preference restriction model in artificial intelligence and economics. In sharp contrast to the known results for additive valuations, we not only prove the existence of EFX and Pareto optimal allocations, but in fact provide an algorithmic characterization of these two properties. We also characterize the mechanisms that are, in addition, strategyproof, non-bossy, and neutral. When the efficiency notion is strengthened to rank-maximality, we obtain non-existence and computational hardness results, and show that tractability can be restored when EFX is relaxed to another well-studied fairness notion called maximin share guarantee (MMS).",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Hadi Hosseini; Sujoy Sikdar; Rohit Vaish; Lirong Xia",
        "authorids": "",
        "aff": "Pennsylvania State University; Binghamton University; Tata Institute of Fundamental Research; Rensselaer Polytechnic Institute",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16689/16689-13-20183-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05472-fair-and-efficient-allocations-under-lexicographic-preferences/",
        "doi": "10.1609/aaai.v35i6.16689",
        "pdf_size": 310280
    },
    {
        "id": "05269",
        "title": "Fair and Efficient Allocations under Subadditive Valuations",
        "track": "main",
        "status": "Poster",
        "abstract": "We study the problem of allocating a set of indivisible goods among agents with subadditive valuations in a fair and efficient manner. Envy-Freeness up to any good (EFX) is the most compelling notion of fairness in the context of indivisible goods. Although the existence of EFX is not known beyond the simple case of two agents with subadditive valuations, some good approximations of EFX are known to exist, namely 1/2-EFX allocation and EFX allocations with bounded charity.  Nash welfare (the geometric mean of agents' valuations) is one of the most commonly used measures of efficiency. In case of additive valuations, an allocation that maximizes Nash welfare also satisfies fairness properties like Envy-Free up to one good (EF1). Although there is substantial work on approximating Nash welfare when agents have additive valuations, very little is known when agents have subadditive valuations. In this paper, we design a polynomial-time algorithm that outputs an allocation that satisfies either of the two approximations of EFX as well as achieves an O(n) approximation to the Nash welfare. Our result also improves the current best-known approximation of O(n log n) and O(m) to Nash welfare when agents have submodular and subadditive valuations, respectively.  Furthermore, our technique also gives an O(n) approximation to a family of welfare measures, p-mean of valuations for p in (-infty, 1], thereby also matching asymptotically the current best approximation ratio for special cases like p = -infty while also retaining the remarkable fairness properties.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Bhaskar Ray Chaudhury; Jugal Garg; Ruta Mehta",
        "authorids": "",
        "aff": "Max Planck Institute for Informatics; University of Illinois at Urbana-Champaign; University of Illinois at Urbana-Champaign",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16665/16665-13-20159-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05269-fair-and-efficient-allocations-under-subadditive-valuations/",
        "doi": "10.1609/aaai.v35i6.16665",
        "pdf_size": 153956
    },
    {
        "id": "05620",
        "title": "Fair and Efficient Allocations with Limited Demands",
        "track": "main",
        "status": "Poster",
        "abstract": "We study the fair division problem of allocating multiple resources among a set of agents with Leontief preferences that are each required to complete a finite amount of work, which we term \"limited demands\". We examine the behavior of the classic Dominant Resource Fairness (DRF) mechanism in this setting and show it is fair but only weakly Pareto optimal and inefficient in many natural examples. We propose as an alternative the Least Cost Product (LCP) mechanism, a natural adaptation of Maximum Nash Welfare to this setting. We characterize the structure of allocation of the LCP mechanism in this setting, show that it is Pareto efficient, and that it satisfies the relatively weak fairness property of sharing incentives. While we prove that it satisfies the stronger fairness property of (expected) envy freeness in some special cases, we provide a counterexample showing it does not do so in general, a striking contrast to the \"unreasonable fairness\" of Maximum Nash Welfare in other settings. Simulations suggest, however, that these violations of envy freeness are rare in randomly generated examples.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Sushirdeep Narayana; Ian A. Kash",
        "authorids": "",
        "aff": "University of Illinois at Chicago; University of Illinois at Chicago",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16706/16706-13-20200-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05620-fair-and-efficient-allocations-with-limited-demands/",
        "doi": "10.1609/aaai.v35i6.16706",
        "pdf_size": 139433
    },
    {
        "id": "05440",
        "title": "Fair and Efficient Online Allocations with Normalized Valuations",
        "track": "main",
        "status": "Poster",
        "abstract": "A set of divisible resources becomes available over a sequence of rounds and needs to be allocated immediately and irrevocably. Our goal is to distribute these resources to maximize fairness and efficiency. Achieving any non-trivial guarantees in an adversarial setting is impossible. However, we show that normalizing the agent values, a very common assumption in fair division, allows us to escape this impossibility. Our main result is an online algorithm for the case of two agents that ensures the outcome is fair while guaranteeing 91.6% of the optimal social welfare. We also show that this is near-optimal: there is no fair algorithm that guarantees more than 93.3% of the optimal social welfare.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Vasilis Gkatzelis; Alexandros Psomas; Xizhi Tan",
        "authorids": "",
        "aff": "Drexel University; Purdue University; Drexel University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16685/16685-13-20179-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05440-fair-and-efficient-online-allocations-with-normalized-valuations/",
        "doi": "10.1609/aaai.v35i6.16685",
        "pdf_size": 186276
    },
    {
        "id": "05119",
        "title": "Fair and Truthful Mechanisms for Dichotomous Valuations",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider the problem of allocating a set on indivisible items to players with private preferences in an efficient and fair way. We focus on valuations that have dichotomous marginals, in which the added value of any item to a set is either 0 or 1, and aim to design truthful allocation mechanisms (without money) that maximize welfare and are fair. For the case that players have submodular valuations with dichotomous marginals, we design such a deterministic truthful allocation mechanism. The allocation output by our mechanism is Lorenz dominating, and consequently satisfies many desired fairness properties, such as being envy-free up to any item (EFX), and maximizing the Nash Social Welfare (NSW). We then show that our mechanism with random priorities is envy-free ex-ante, while having all the above properties ex-post. Furthermore, we present several impossibility results precluding similar results for the larger class of XOS valuations.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Moshe Babaioff; Tomer Ezra; Uriel Feige",
        "authorids": "",
        "aff": "Microsoft Research; Tel Aviv University; Weizmann Institute",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16647/16647-13-20141-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05119-fair-and-truthful-mechanisms-for-dichotomous-valuations/",
        "doi": "10.1609/aaai.v35i6.16647",
        "pdf_size": 149634
    },
    {
        "id": "11134",
        "title": "Fairness in Forecasting and Learning Linear Dynamical Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "In machine learning, training data often capture the behaviour of multiple subgroups of some underlying human population. When the amounts of training data for the subgroups are not controlled carefully, under-representation bias arises. We introduce two natural notions of subgroup fairness and instantaneous fairness to address such under-representation bias in time-series forecasting problems. In particular, we consider the subgroup-fair and instant-fair learning of a linear dynamical system (LDS) from multiple trajectories of varying lengths and the associated forecasting problems. We provide globally convergent methods for the learning problems using hierarchies of convexifications of non-commutative polynomial optimisation problems.  Our empirical results on a biased data set motivated by insurance applications and the well-known COMPAS data set demonstrate both the beneficial impact of fairness considerations on statistical performance and the encouraging effects of exploiting sparsity on run time.",
        "primary_area": "Machine Learning V",
        "author": "Quan Zhou; Jakub Marecek; Robert N. Shorten",
        "authorids": "",
        "aff": "University College Dublin, Ireland; Czech Technical University in Prague, the Czech Republic; University College Dublin, Ireland Imperial College London, UK",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17328/17328-13-20822-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11134-fairness-in-forecasting-and-learning-linear-dynamical-systems/",
        "doi": "10.1609/aaai.v35i12.17328",
        "pdf_size": 1741403
    },
    {
        "id": "06822",
        "title": "Fairness, Semi-Supervised Learning, and More: A General Framework for Clustering with Stochastic Pairwise Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "Metric clustering is fundamental in areas ranging from Combinatorial Optimization and Data Mining, to Machine Learning and Operations Research. However, in a variety of situations we may have additional requirements or knowledge, distinct from the underlying metric, regarding which pairs of points should be clustered together. To capture and analyze such scenarios, we introduce a novel family of stochastic pairwise constraints, which we incorporate into several essential clustering objectives (radius/median/means). Moreover, we demonstrate that these constraints can succinctly model an intriguing collection of applications, including among others Individual Fairness in clustering and Must-link constraints in semi-supervised learning. Our main result consists of a general framework that yields approximation algorithms with provable guarantees for important clustering objectives, while at the same time producing solutions that respect the stochastic pairwise constraints. Furthermore, for certain objectives we devise improved results in the case of Must-link constraints, which are also the best possible from a theoretical perspective. Finally, we present experimental evidence that validates the effectiveness of our algorithms.",
        "primary_area": "Machine Learning I",
        "author": "Brian Brubach; Darshan Chakrabarti; John P. Dickerson; Aravind Srinivasan; Leonidas Tsepenekas",
        "authorids": "",
        "aff": "Wellesley College; Carnegie Mellon University; University of Maryland, College Park; University of Maryland, College Park; University of Maryland, College Park",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16842/16842-13-20336-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06822-fairness-semi-supervised-learning-and-more-a-general-framework-for-clustering-with-stochastic-pairwise-constraints/",
        "doi": "10.1609/aaai.v35i8.16842",
        "pdf_size": 162903
    },
    {
        "id": "04462",
        "title": "Fairness-aware News Recommendation with Decomposed Adversarial Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "News recommendation is important for online news services. Existing news recommendation models are usually learned from users' news click behaviors. Usually the behaviors of users with the same sensitive attributes (e.g., genders) have similar patterns and news recommendation models can easily capture these patterns. It may lead to some biases related to sensitive user attributes in the recommendation results, e.g., always recommending sports news to male users, which is unfair since users may not receive diverse news information. In this paper, we propose a  fairness-aware news recommendation approach with decomposed adversarial learning and orthogonality regularization, which can alleviate unfairness in news recommendation brought by the biases of sensitive user attributes. In our approach, we propose to decompose the user interest model into two components. One component aims to learn a bias-aware user embedding that captures the bias information on sensitive user attributes, and the other aims to learn a bias-free user embedding that only encodes attribute-independent user interest information for fairness-aware news recommendation. In addition, we propose to apply an attribute prediction task to the bias-aware user embedding to enhance its ability on bias modeling, and we apply adversarial learning to the bias-free user embedding to remove the bias information from it. Moreover, we propose an orthogonality regularization method to encourage the bias-free user embeddings to be orthogonal to the bias-aware one to better distinguish the bias-free user embedding from the bias-aware one. For fairness-aware news ranking, we only use the bias-free user embedding. Extensive experiments on benchmark dataset show that our approach can effectively improve fairness in news recommendation with minor performance loss.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Chuhan Wu; Fangzhao Wu; Xiting Wang; Yongfeng Huang; Xing Xie",
        "authorids": "",
        "aff": "Department of Electronic Engineering & BNRist, Tsinghua University; Microsoft Research Asia; Microsoft Research Asia; Department of Electronic Engineering & BNRist, Tsinghua University; Microsoft Research Asia",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16573/16573-13-20067-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04462-fairness-aware-news-recommendation-with-decomposed-adversarial-learning/",
        "doi": "10.1609/aaai.v35i5.16573",
        "pdf_size": 834711
    },
    {
        "id": "12893",
        "title": "Fake it Till You Make it: Self-Supervised Semantic Shifts for Monolingual Word Embedding Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "The use of language is subject to variation over time as well as across social groups and knowledge domains, leading to differences even in the monolingual scenario. Such variation in word usage is often called lexical semantic change (LSC). The goal of LSC is to characterize and quantify language variations with respect to word meaning, to measure how distinct two language sources are (that is, people or language models). Because there is hardly any data available for such a task, most solutions involve unsupervised methods to align two embeddings and predict semantic change with respect to a distance measure. To that end, we propose a self-supervised approach to model lexical semantic change based on the perturbation of word vectors in the input corpora. We show that our method can be used for the detection of semantic change with any alignment method. Furthermore, it can be used to choose the landmark words to use in alignment and can lead to substantial improvements over the existing techniques for alignment.  We illustrate the utility of our techniques using experimental results on three different datasets, involving words with the same or different meanings. Our methods not only provide significant improvements but also can lead to novel findings for the LSC problem.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Maur\u00edcio Gruppi; Pin-Yu Chen; Sibel Adali",
        "authorids": "",
        "aff": "Rensselaer Polytechnic Institute, NY, USA; IBM Research, NY, USA; Rensselaer Polytechnic Institute, NY, USA",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17525/17525-13-21019-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12893-fake-it-till-you-make-it-self-supervised-semantic-shifts-for-monolingual-word-embedding-tasks/",
        "doi": "10.1609/aaai.v35i14.17525",
        "pdf_size": 162613
    },
    {
        "id": "09360",
        "title": "Fast Multi-view Discrete Clustering with Anchor Graphs",
        "track": "main",
        "status": "Poster",
        "abstract": "Generally, the existing graph-based multi-view clustering models consists of two steps: (1) graph construction; (2) eigen-decomposition on the graph Laplacian matrix to compute a continuous cluster assignment matrix, followed by a post-processing algorithm to get the discrete one. However, both the graph construction and eigen-decomposition are time-consuming, and the two-stage process may deviate from directly solving the primal problem. To this end, we propose Fast Multi-view Discrete Clustering (FMDC) with anchor graphs, focusing on directly solving the spectral clustering problem with a small time cost. We efficiently generate representative anchors and construct anchor graphs on different views. The discrete cluster assignment matrix is directly obtained by performing clustering on the automatically aggregated graph. FMDC has a linear computational complexity with respect to the data scale, which is a significant improvement compared to the quadratic one. Extensive experiments on benchmark datasets demonstrate its efficiency and effectiveness.",
        "primary_area": "Machine Learning IV",
        "author": "Qianyao Qiang; Bin Zhang; Fei Wang; Feiping Nie",
        "authorids": "",
        "aff": "Xi\u2019an Jiaotong University; Xi'an Jiaotong University; Xi'an Jiaotong University; Northwestern Polytechnical University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17128/17128-13-20622-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09360-fast-multi-view-discrete-clustering-with-anchor-graphs/",
        "doi": "10.1609/aaai.v35i11.17128",
        "pdf_size": 1008042
    },
    {
        "id": "09342",
        "title": "Fast PCA in 1-D Wasserstein Spaces via B-splines Representation and Metric Projection",
        "track": "main",
        "status": "Poster",
        "abstract": "We address the problem of performing Principal Component Analysis over a family of probability measures on the real line, using the Wasserstein geometry. We present a novel representation of the 2-Wasserstein space, based on a well known isometric bijection and a B-spline expansion. Thanks to this representation, we are able to reinterpret previous work and derive more efficient optimization routines for existing approaches. As shown in our simulations, the solution of these optimization problems can be costly in practice and thus pose a limit to their usage. We propose a novel definition of Principal Component Analysis in the Wasserstein space that, when used in combination with the B-spline representation, yields a straightforward optimization problem that is extremely fast to compute. Through extensive simulation studies, we show how our PCA performs similarly to the ones already proposed in the literature while retaining a much smaller computational cost. We apply our method to a real dataset of mortality rates due to Covid-19 in the US, concluding that our analyses are consistent with the current scientific consensus on the disease.",
        "primary_area": "Machine Learning III",
        "author": "Matteo Pegoraro; Mario Beraha",
        "authorids": "",
        "aff": "MOX - Department of Mathematics, Politecnico di Milano; Department of Mathematics, Politecnico di Milano Department of Computer Science, Universit\u00e0 di Bologna",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17126/17126-13-20620-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09342-fast-pca-in-1-d-wasserstein-spaces-via-b-splines-representation-and-metric-projection/",
        "doi": "10.1609/aaai.v35i10.17126",
        "pdf_size": 489894
    },
    {
        "id": "06803",
        "title": "Fast Training of Provably Robust Neural Networks by SingleProp",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent works have developed several methods of defending neural networks against adversarial attacks with certified guarantees. However, these techniques can be computationally costly due to the use of certification during training. We develop a new regularizer that is both more efficient than existing certified defenses, requiring only one additional forward propagation through a network, and can be used to train networks with similar certified accuracy. Through experiments on MNIST and CIFAR-10 we demonstrate improvements in training speed and comparable certified accuracy compared to state-of-the-art certified defenses.",
        "primary_area": "Machine Learning I",
        "author": "Akhilan Boopathy; Lily Weng; Sijia Liu; Pin-Yu Chen; Gaoyuan Zhang; Luca Daniel",
        "authorids": "",
        "aff": "Massachusetts Institute of Technology; Massachusetts Institute of Technology; MIT-IBM Watson AI Lab, IBM Research; MIT-IBM Watson AI Lab, IBM Research; MIT-IBM Watson AI Lab, IBM Research; Massachusetts Institute of Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16840/16840-13-20334-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06803-fast-training-of-provably-robust-neural-networks-by-singleprop/",
        "doi": "10.1609/aaai.v35i8.16840",
        "pdf_size": 157392
    },
    {
        "id": "03243",
        "title": "Fast and Compact Bilinear Pooling by Shifted Random Maclaurin",
        "track": "main",
        "status": "Poster",
        "abstract": "Bilinear pooling has achieved an excellent performance in many computer vision tasks such as fine-grained classification, scene recognition and texture recognition. However, the high-dimension features from bilinear pooling can sometimes be inefficient and prone to over-fitting. Random Maclaurin (RM) is a widely used GPU-friendly approximation method to reduce the dimensionality of bilinear features. However, to achieve good performance, large projection matrices are usually required in practice, making it costly in computation and memory. In this paper, we propose a Shifted Random Maclaurin (SRM) strategy for  fast and compact bilinear pooling. With merely negligible extra computational cost, the proposed SRM provides an estimator with a provably smaller variance than RM, which benefits accurate kernel approximation and thus the learning performance. Using a small projection matrix, the proposed SRM achieves a comparable estimation performance as RM based on a large projection matrix, and thus boosts the efficiency.  Furthermore, we upgrade the proposed SRM to SRM+ to further improve the efficiency and make the compact bilinear pooling compatible with fast matrix normalization.  Fast and Compact Bilinear Network (FCBN) built upon the proposed SRM+ is devised, achieving an end-to-end training. Systematic experiments  conducted on four public datasets demonstrate the effectiveness and efficiency of the proposed FCBN.",
        "primary_area": "Computer Vision III",
        "author": "Tan Yu; Xiaoyun Li; Ping Li",
        "authorids": "",
        "aff": "Baidu Research; Baidu Research; Baidu Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16435/16435-13-19929-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03243-fast-and-compact-bilinear-pooling-by-shifted-random-maclaurin/",
        "doi": "10.1609/aaai.v35i4.16435",
        "pdf_size": 447844
    },
    {
        "id": "10329",
        "title": "Fast and Scalable Adversarial Training of Kernel SVM via Doubly Stochastic Gradients",
        "track": "main",
        "status": "Poster",
        "abstract": "Adversarial attacks by generating examples which are almost indistinguishable from natural examples, pose a serious threat to learning models. Defending against adversarial attacks is a critical element for a reliable learning system. Support vector machine (SVM) is a classical yet still important learning algorithm even in the current deep learning era. Although a wide range of researches have been done in recent years to improve the adversarial robustness of learning models, but most of them are limited to deep neural networks (DNNs) and the work for kernel SVM is still vacant. In this paper, we aim at kernel SVM and propose adv-SVM to improve its adversarial robustness via adversarial training, which has been demonstrated to be the most promising defense techniques. To the best of our knowledge, this is the first work that devotes to the fast and scalable adversarial training of kernel SVM. Specifically, we first build connection of perturbations of samples between original and kernel spaces, and then give a reduced and equivalent formulation of adversarial training of kernel SVM based on the connection. Next, doubly stochastic gradients (DSG) based on two unbiased stochastic approximations (i.e., one is on training points and another is on random features) are applied to update the solution of our objective function. Finally, we prove that our algorithm optimized by DSG converges to the optimal solution at the rate of O(1/$t$) under the constant and diminishing stepsizes. Comprehensive experimental results show that our adversarial training algorithm enjoys robustness against various attacks and meanwhile has the similar efficiency and scalability with classical DSG algorithm.",
        "primary_area": "Machine Learning V",
        "author": "Huimin Wu; Zhengmian Hu; Bin Gu",
        "authorids": "",
        "aff": "School of Computer & Software, Nanjing University of Information Science & Technology, P.R.China; Department of Electrical & Computer Engineering, University of Pittsburgh, PA, USA; School of Computer & Software, Nanjing University of Information Science & Technology, P.R.China JD Finance America Corporation, Mountain View, CA, USA MBZUAI, United Arab Emirates",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17237/17237-13-20731-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10329-fast-and-scalable-adversarial-training-of-kernel-svm-via-doubly-stochastic-gradients/",
        "doi": "10.1609/aaai.v35i12.17237",
        "pdf_size": 317254
    },
    {
        "id": "13424",
        "title": "Faster Depth-Adaptive Transformers",
        "track": "main",
        "status": "Poster",
        "abstract": "Depth-adaptive neural networks can dynamically adjust depths according to the hardness of input words, and thus improve efficiency. The main challenge is how to measure such hardness and decide the required depths (i.e., layers) to conduct. Previous works generally build a halting unit to decide whether the computation should continue or stop at each layer. As there is no specific supervision of depth selection, the halting unit may be under-optimized and inaccurate, which results in suboptimal and unstable performance when modeling sentences. In this paper, we get rid of the halting unit and estimate the required depths in advance, which yields a faster depth-adaptive model. Specifically, two approaches are proposed to explicitly measure the hardness of input words and estimate corresponding adaptive depth, namely 1) mutual information (MI) based estimation and 2) reconstruction loss based estimation. We conduct experiments on the text classification task with 24 datasets in various sizes and domains. Results confirm that our approaches can speed up the vanilla Transformer (up to 7x) while preserving high accuracy. Moreover, efficiency and robustness are significantly improved when compared with other depth-adaptive approaches.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Yijin Liu; Fandong Meng; Jie Zhou; Yufeng Chen; Jinan Xu",
        "authorids": "",
        "aff": "Beijing Jiaotong University; Tencent WeChat AI - Pattern Recognition Center Tencent Inc.; Tencent WeChat AI - Pattern Recognition Center Tencent Inc.; Beijing Jiaotong University; Beijing Jiaotong University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17584/17584-13-21078-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13424-faster-depth-adaptive-transformers/",
        "doi": "10.1609/aaai.v35i15.17584",
        "pdf_size": 1167238
    },
    {
        "id": "05363",
        "title": "Faster Game Solving via Predictive Blackwell Approachability: Connecting Regret Matching and Mirror Descent",
        "track": "main",
        "status": "Poster",
        "abstract": "Blackwell approachability is a framework for reasoning about repeated games with vector-valued payoffs. We introduce predictive Blackwell approachability, where an estimate of the next payoff vector is given, and the decision maker tries to achieve better performance based on the accuracy of that estimator. In order to derive algorithms that achieve predictive Blackwell approachability, we start by showing a powerful connection between four well-known algorithms. Follow-the-regularized-leader (FTRL) and online mirror descent (OMD) are the most prevalent regret minimizers in online convex optimization. In spite of this prevalence, the regret matching (RM) and regret matching+ (RM+) algorithms have been preferred in the practice of solving large-scale games (as the local regret minimizers within the counterfactual regret minimization framework). We show that RM and RM+ are the algorithms that result from running FTRL and OMD, respectively, to select the halfspace to force at all times in the underlying Blackwell approachability game. By applying the predictive variants of FTRL or OMD to this connection, we obtain predictive Blackwell approachability algorithms, as well as predictive variants of RM and RM+. In experiments across 18 common zero-sum extensive-form benchmark games, we show that predictive RM+ coupled with counterfactual regret minimization converges vastly faster than the fastest prior algorithms (CFR+, DCFR, LCFR) across all games but two of the poker games, sometimes by two or more orders of magnitude.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Gabriele Farina; Christian Kroer; Tuomas Sandholm",
        "authorids": "",
        "aff": "Carnegie Mellon University; Columbia University; Carnegie Mellon University Strategy Robot, Inc. Optimized Markets, Inc. Strategic Machine, Inc.",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16676/16676-13-20170-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05363-faster-game-solving-via-predictive-blackwell-approachability-connecting-regret-matching-and-mirror-descent/",
        "doi": "10.1609/aaai.v35i6.16676",
        "pdf_size": 247582
    },
    {
        "id": "11998",
        "title": "Faster Stackelberg Planning via Symbolic Search and Information Sharing",
        "track": "main",
        "status": "Poster",
        "abstract": "Stackelberg planning is a recent framework where a leader and a follower each choose a plan in the same planning task, the leader's objective being to maximize plan cost for the follower. This formulation naturally captures security-related (leader=defender, follower=attacker) as well as robustness-related (leader=adversarial event, follower=agent) scenarios. Solving Stackelberg planning tasks requires solving many related planning tasks at the follower level (in the worst case, one for every possible leader plan). Here we introduce new methods to tackle this source of complexity, through sharing information across follower tasks. Our evaluation shows that these methods can significantly reduce both the time needed to solve follower tasks and the number of follower tasks that need to be solved in the first place.",
        "primary_area": "Planning, Routing, and Scheduling",
        "author": "\u00c1lvaro Torralba; Patrick Speicher; Robert K\u00fcnnemann; Marcel Steinmetz; J\u00f6rg Hoffmann",
        "authorids": "",
        "aff": "Aalborg University; CISPA Helmholtz Center for Information Security; CISPA Helmholtz Center for Information Security; Saarland University; Saarland University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17425/17425-13-20919-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11998-faster-stackelberg-planning-via-symbolic-search-and-information-sharing/",
        "doi": "10.1609/aaai.v35i13.17425",
        "pdf_size": 329720
    },
    {
        "id": "11913",
        "title": "Faster and Better Simple Temporal Problems",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper we give a structural characterization and extend the tractability frontier of the Simple Temporal Problem (STP) by defining the class of the Extended Simple Temporal Problem (ESTP), which augments STP with strict inequalities and monotone Boolean formulae on inequations (i.e., formulae involving the operations of conjunction, disjunction and parenthesization). A polynomial-time algorithm is provided to solve ESTP, faster than previous state-of-the-art algorithms for other extensions of STP that had been considered in the literature, all encompassed by ESTP.  We show the practical competitiveness of our approach through a proof-of-concept implementation and an experimental evaluation involving also state-of-the-art SMT solvers.",
        "primary_area": "Planning, Routing, and Scheduling",
        "author": "Dario Ostuni; Alice Raffaele; Romeo Rizzi; Matteo Zavatteri",
        "authorids": "",
        "aff": "University of Verona, Italy; University of Trento, Italy; University of Verona, Italy; University of Verona, Italy",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17415/17415-13-20909-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11913-faster-and-better-simple-temporal-problems/",
        "doi": "10.1609/aaai.v35i13.17415",
        "pdf_size": 1714340
    },
    {
        "id": "04224",
        "title": "FedRec++: Lossless Federated Recommendation with Explicit Feedback",
        "track": "main",
        "status": "Poster",
        "abstract": "With the marriage of federated machine learning and recommender systems for privacy-aware preference modeling and personalization, there comes a new research branch called federated recommender systems aiming to build a recommendation model in a distributed way, i.e., each user is represented as a distributed client where his/her original rating data are not shared with the server or the other clients. Notice that, besides the sensitive information of a specific rating score assigned to a certain item by a user, the information of a user's rated set of items shall also be well protected. Some very recent works propose to randomly sample some unrated items for each user and then assign some virtual ratings, so that the server can not identify the scores and the set of rated items easily during the server-client interactions. However, the virtual ratings assigned to the randomly sampled items will inevitably introduce some noise to the model training process, which will then cause loss in recommendation performance. In this paper, we propose a novel lossless federated recommendation method (FedRec++) by allocating some denoising clients (i.e., users) to eliminate the noise in a privacy-aware manner. We further analyse our FedRec++ in terms of security and losslessness, and discuss its generality in the context of existing works. Extensive empirical studies clearly show the effectiveness of our FedRec++ in providing accurate and privacy-aware recommendation without much additional communication cost.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Feng Liang; Weike Pan; Zhong Ming",
        "authorids": "",
        "aff": "Shenzhen University; Shenzhen University; Shenzhen University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16546/16546-13-20040-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04224-fedrec-lossless-federated-recommendation-with-explicit-feedback/",
        "doi": "10.1609/aaai.v35i5.16546",
        "pdf_size": 441051
    },
    {
        "id": "10355",
        "title": "Federated Block Coordinate Descent Scheme for Learning Global and Personalized Models",
        "track": "main",
        "status": "Poster",
        "abstract": "In federated learning, models are learned from users\u2019 data that are held private in their edge devices, by aggregating them in the service provider\u2019s \u201ccloud\u201d to obtain a global model. Such global model is of great commercial value in, e.g., improving the customers\u2019 experience. In this paper we focus on two possible areas of improvement of the state of the art. First, we take the difference between user habits into account and propose a quadratic penalty-based formulation, for efficient learning of the global model that allows to personalize local models. Second, we address the latency issue associated with the heterogeneous training time on edge devices, by exploiting a hierarchical structure modeling communication not only between the cloud and edge devices, but also within the cloud. Specifically, we devise a tailored block coordinate descent-based computation scheme, accompanied with communication protocols for both the synchronous and asynchronous cloud settings. We characterize the theoretical convergence rate of the algorithm, and provide a variant that performs empirically better. We also prove that the asynchronous protocol, inspired by multi-agent consensus technique, has the potential for large gains in latency compared to a synchronous setting when the edge-device updates are intermittent. Finally, experimental results are provided that corroborate not only the theory, but also show that the system leads to faster convergence for personalized models on the edge devices, compared to the state of the art.",
        "primary_area": "Machine Learning V",
        "author": "Ruiyuan Wu; Anna Scaglione; Hoi-To Wai; Nurullah Karakoc; Kari Hreinsson; Wing-Kin Ma",
        "authorids": "",
        "aff": "The Chinese University of Hong Kong; Arizona State University; The Chinese University of Hong Kong; Arizona State University; Arizona State University; The Chinese University of Hong Kong",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17240/17240-13-20734-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10355-federated-block-coordinate-descent-scheme-for-learning-global-and-personalized-models/",
        "doi": "10.1609/aaai.v35i12.17240",
        "pdf_size": 453908
    },
    {
        "id": "09603",
        "title": "Federated Multi-Armed Bandits",
        "track": "main",
        "status": "Poster",
        "abstract": "Federated multi-armed bandits (FMAB) is a new bandit paradigm that parallels the federated learning (FL) framework in supervised learning. It is inspired by practical applications in cognitive radio and recommender systems, and enjoys features that are analogous to FL. This paper proposes a general framework of FMAB and then studies two specific federated bandit models. We first study the approximate model where the heterogeneous local models are random realizations of the global model from an unknown distribution. This model introduces a new uncertainty of client sampling, as the global model may not be reliably learned even if the finite local models are perfectly known. Furthermore, this uncertainty cannot be quantified a priori without knowledge of the suboptimality gap. We solve the approximate model by proposing Federated Double UCB (Fed2-UCB), which constructs a novel \u201cdouble UCB\u201d principle accounting for uncertainties from both arm and client sampling. We show that gradually admitting new clients is critical in achieving an O(log(T)) regret while explicitly considering the communication loss. The exact model, where the global bandit model is the exact average of heterogeneous local models, is then studied as a special case. We show that, somewhat surprisingly, the order-optimal regret can be achieved independent of the number of clients with a careful choice of the update periodicity. Experiments using both synthetic and real-world datasets corroborate the theoretical analysis and demonstrate the effectiveness and efficiency of the proposed algorithms.",
        "primary_area": "Machine Learning IV",
        "author": "Chengshuai Shi; Cong Shen",
        "authorids": "",
        "aff": "University of Virginia; University of Virginia",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17156/17156-13-20650-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09603-federated-multi-armed-bandits/",
        "doi": "10.1609/aaai.v35i11.17156",
        "pdf_size": 696602
    },
    {
        "id": "01255",
        "title": "Few-Shot Class-Incremental Learning via Relation Knowledge Distillation",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we focus on the challenging few-shot class incremental learning (FSCIL) problem, which requires to transfer knowledge from old tasks to new ones and solves catastrophic forgetting. We propose the exemplar relation distillation incremental learning framework to balance the tasks of old-knowledge preserving and new-knowledge adaptation. First, we construct an exemplar relation graph to represent the knowledge learned by the original network and update gradually for new tasks learning. Then an exemplar relation loss function for discovering the relation knowledge between different classes is introduced to learn and transfer the structural information in relation graph. A large number of experiments demonstrate that relation knowledge does exist in the exemplars and our approach outperforms other state-of-the-art class-incremental learning methods on the CIFAR100, miniImageNet, and CUB200 datasets.",
        "primary_area": "Computer Vision I",
        "author": "Songlin Dong; Xiaopeng Hong; Xiaoyu Tao; Xinyuan Chang; Xing Wei; Yihong Gong",
        "authorids": "",
        "aff": "College of Artificial Intelligence, Xi'an Jiaotong University; School of Cyber Science and Engineering, Xi'an Jiaotong University; College of Artificial Intelligence, Xi'an Jiaotong University.; School of Software Engineering, Xi'an Jiaotong University; School of Software Engineering, Xi'an Jiaotong University; School of Software Engineering, Xi'an Jiaotong University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16213/16213-13-19707-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01255-few-shot-class-incremental-learning-via-relation-knowledge-distillation/",
        "doi": "10.1609/aaai.v35i2.16213",
        "pdf_size": 196916
    },
    {
        "id": "02337",
        "title": "Few-Shot Lifelong Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Many real-world classification problems often have classes with very few labeled training samples. Moreover, all possible classes may not be initially available for training, and may be given incrementally. Deep learning models need to deal with this two-fold problem in order to perform well in real-life situations. In this paper, we propose a novel Few-Shot Lifelong Learning (FSLL) method that enables deep learning models to perform lifelong/continual learning on few-shot data. Our method selects very few parameters from the model for training every new set of classes instead of training the full model. This helps in preventing overfitting. We choose the few parameters from the model in such a way that only the currently unimportant parameters get selected. By keeping the important parameters in the model intact, our approach minimizes catastrophic forgetting. Furthermore, we minimize the cosine similarity between the new and the old class prototypes in order to maximize their separation, thereby improving the classification performance. We also show that integrating our method with self-supervision improves the model performance significantly. We experimentally show that our method significantly outperforms existing methods on the miniImageNet, CIFAR-100, and CUB-200 datasets. Specifically, we outperform the state-of-the-art method by an absolute margin of 19.27% for the CUB dataset.",
        "primary_area": "Computer Vision II",
        "author": "Pratik Mazumder; Pravendra Singh; Piyush Rai",
        "authorids": "",
        "aff": "Department of Computer Science and Engineering, IIT Kanpur, India; Independent Researcher, India; Department of Computer Science and Engineering, IIT Kanpur, India",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16334/16334-13-19828-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02337-few-shot-lifelong-learning/",
        "doi": "10.1609/aaai.v35i3.16334",
        "pdf_size": 449114
    },
    {
        "id": "07448",
        "title": "Few-Shot One-Class Classification via Meta-Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Although few-shot learning and one-class classification (OCC), i.e., learning a binary classifier with data from only one class, have been separately well studied, their intersection remains rather unexplored. Our work addresses the few-shot OCC problem and presents a method to modify the episodic data sampling strategy of the model-agnostic meta-learning (MAML) algorithm to learn a model initialization particularly suited for learning few-shot OCC tasks. This is done by explicitly optimizing for an initialization which only requires few gradient steps with one-class minibatches to yield a performance increase on class-balanced test data. We provide a theoretical analysis that explains why our approach works in the few-shot OCC scenario, while other meta-learning algorithms fail, including the unmodified MAML. Our experiments on eight datasets from the image and time-series domains show that our method leads to better results than classical OCC and few-shot classification approaches, and demonstrate the ability to learn unseen tasks from only few normal class samples. Moreover, we successfully train anomaly detectors for a real-world application on sensor readings recorded during industrial manufacturing of workpieces with a CNC milling machine, by using few normal examples. Finally, we empirically demonstrate that the proposed data sampling technique increases the performance of more recent meta-learning algorithms in few-shot OCC and yields state-of-the-art results in this problem setting.",
        "primary_area": "Machine Learning I",
        "author": "Ahmed Frikha; Denis Krompa\u00df; Hans-Georg K\u00f6pken; Volker Tresp",
        "authorids": "",
        "aff": "Siemens Technology Siemens AI Lab Ludwig Maximilian University of Munich; Siemens Technology Siemens AI Lab; Siemens Digital Industries; Siemens Technology Ludwig Maximilian University of Munich",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16913/16913-13-20407-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07448-few-shot-one-class-classification-via-meta-learning/",
        "doi": "10.1609/aaai.v35i8.16913",
        "pdf_size": 166687
    },
    {
        "id": "02393",
        "title": "Few-shot Font Generation with Localized Style Representations and Factorization",
        "track": "main",
        "status": "Poster",
        "abstract": "Automatic few-shot font generation is a practical and widely studied problem because manual designs are expensive and sensitive to the expertise of designers. Existing few-shot font generation methods aim to learn to disentangle the style and content element from a few reference glyphs, and mainly focus on a universal style representation for each font style. However, such approach limits the model in representing diverse local styles, and thus makes it unsuitable to the most complicated letter system, e.g., Chinese, whose characters consist of a varying number of components (often called ``radical'') with a highly complex structure. In this paper, we propose a novel font generation method by learning localized styles, namely component-wise style representations, instead of universal styles. The proposed style representations enable us to synthesize complex local details in text designs. However, learning component-wise styles solely from reference glyphs is infeasible in the few-shot font generation scenario, when a target script has a large number of components, e.g., over 200 for Chinese. To reduce the number of reference glyphs, we simplify component-wise styles by a product of component factor and style factor, inspired by low-rank matrix factorization. Thanks to the combination of strong representation and a compact factorization strategy, our method shows remarkably better few-shot font generation results (with only 8 reference glyph images) than other state-of-the-arts, without utilizing strong locality supervision, e.g., location of each component, skeleton, or strokes. The source code is available at https://github.com/clovaai/lffont.",
        "primary_area": "Computer Vision II",
        "author": "Song Park; Sanghyuk Chun; Junbum Cha; Bado Lee; Hyunjung Shim",
        "authorids": "",
        "aff": "Yonsei University; NAVER AI LAB; NAVER CLOVA; NAVER CLOVA; Yonsei University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16340/16340-13-19834-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02393-few-shot-font-generation-with-localized-style-representations-and-factorization/",
        "doi": "10.1609/aaai.v35i3.16340",
        "pdf_size": 1510144
    },
    {
        "id": "13036",
        "title": "Few-shot Learning for Multi-label Intent Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we study the few-shot multi-label classification for user intent detection. For multi-label intent detection, state-of-the-art work estimates label-instance relevance scores and uses a threshold to select multiple associated intent labels. To determine appropriate thresholds with only a few examples, we first learn universal thresholding experience on data-rich domains, and then adapt the thresholds to certain few-shot domains with a calibration based on nonparametric learning. For better calculation of label-instance relevance score, we introduce label name embedding as anchor points in representation space, which refines representations of different classes to be well-separated from each other. Experiments on two datasets show that the proposed model significantly outperforms strong baselines in both one-shot and five-shot settings.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Yutai Hou; Yongkui Lai; Yushan Wu; Wanxiang Che; Ting Liu",
        "authorids": "",
        "aff": "Harbin Institute of Technology; Harbin Institute of Technology; Harbin Institute of Technology; Harbin Institute of Technology; Harbin Institute of Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17541/17541-13-21035-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13036-few-shot-learning-for-multi-label-intent-detection/",
        "doi": "10.1609/aaai.v35i14.17541",
        "pdf_size": 315455
    },
    {
        "id": "13406",
        "title": "Filling the Gap of Utterance-aware and Speaker-aware Representation for Multi-turn Dialogue",
        "track": "main",
        "status": "Poster",
        "abstract": "A multi-turn dialogue is composed of multiple utterances from two or more different speaker roles. Thus utterance- and speaker-aware clues are supposed to be well captured in models. However, in the existing retrieval-based multi-turn dialogue modeling, the pre-trained language models (PrLMs) as encoder represent the dialogues coarsely by taking the pairwise dialogue history and candidate response as a whole, the hierarchical information on either utterance interrelation or speaker roles coupled in such representations is not well addressed. In this work, we propose a novel model to fill such a gap by modeling the effective utterance-aware and speaker-aware representations entailed in a dialogue history. In detail, we decouple the contextualized word representations by masking mechanisms in Transformer-based PrLM, making each word only focus on the words in current utterance, other utterances, two speaker roles (i.e., utterances of sender and utterances of receiver), respectively. Experimental results show that our method boosts the strong ELECTRA baseline substantially in four public benchmark datasets, and achieves various new state-of-the-art performance over previous methods. A series of ablation studies are conducted to demonstrate the effectiveness of our method.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Longxiang Liu; Zhuosheng Zhang; Hai Zhao; Xi Zhou; Xiang Zhou",
        "authorids": "",
        "aff": "Department of Computer Science and Engineering, Shanghai Jiao Tong University Key Laboratory of Shanghai Education Commission for Intelligent Interaction and Cognitive Engineering, Shanghai Jiao Tong University MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University; Department of Computer Science and Engineering, Shanghai Jiao Tong University Key Laboratory of Shanghai Education Commission for Intelligent Interaction and Cognitive Engineering, Shanghai Jiao Tong University MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University; Department of Computer Science and Engineering, Shanghai Jiao Tong University Key Laboratory of Shanghai Education Commission for Intelligent Interaction and Cognitive Engineering, Shanghai Jiao Tong University MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University; CloudWalk Technology; CloudWalk Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17582/17582-13-21076-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13406-filling-the-gap-of-utterance-aware-and-speaker-aware-representation-for-multi-turn-dialogue/",
        "doi": "10.1609/aaai.v35i15.17582",
        "pdf_size": 517178
    },
    {
        "id": "03778",
        "title": "Finding Diverse Trees, Paths, and More",
        "track": "main",
        "status": "Poster",
        "abstract": "Mathematical modeling is a standard approach to solve many real-world problems and diversity of solutions is an important issue, emerging in applying solutions obtained from mathematical models to real-world problems. Many studies have been devoted to finding diverse solutions. Baste et al. (Algorithms 2019, IJCAI 2020) recently initiated the study of computing diverse solutions of combinatorial problems from the perspective of fixed-parameter tractability. They considered problems of finding r solutions that maximize some diversity measures (the minimum or sum of the pairwise Hamming distances among them) and gave some fixed-parameter tractable algorithms for the diverse version of several well-known problems, such as Vertex Cover, Feedback Vertex Set, d-Hitting Set}, and problems on bounded-treewidth graphs. In this work, we further investigate the (fixed-parameter) tractability of problems of finding diverse spanning trees, paths, and several subgraphs. In particular, we show that, given a graph G and an integer r, the problem of computing r spanning trees of G maximizing the sum of the pairwise Hamming distances among them can be solved in polynomial time.  To the best of the authors' knowledge, this is the first polynomial-time solvable case for finding diverse solutions of unbounded size.",
        "primary_area": "Constraint Satisfaction and Optimization",
        "author": "Tesshu Hanaka; Yasuaki Kobayashi; Kazuhiro Kurita; Yota Otachi",
        "authorids": "",
        "aff": "Chuo University; Kyoto University; National Institute of Informatics; Nagoya University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16495/16495-13-19989-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03778-finding-diverse-trees-paths-and-more/",
        "doi": "10.1609/aaai.v35i5.16495",
        "pdf_size": 164755
    },
    {
        "id": "13333",
        "title": "Finding Sparse Structures for Domain Specific Neural Machine Translation",
        "track": "main",
        "status": "Poster",
        "abstract": "Neural machine translation often adopts the fine-tuning approach to adapt to specific domains. However, nonrestricted fine-tuning can easily degrade on the general domain and over-fit to the target domain. To mitigate the issue, we propose Prune-Tune, a novel domain adaptation method via gradual pruning. It learns tiny domain-specific sub-networks during fine-tuning on new domains. Prune-Tune alleviates the over-fitting and the degradation problem without model modification. Furthermore, Prune-Tune is able to sequentially learn a single network with multiple disjoint domain-specific sub-networks for multiple domains. Empirical experiment results show that Prune-Tune outperforms several strong competitors in the target domain test set without sacrificing the quality on the general domain in both single and multi-domain settings. The source code and data are available at https://github.com/ohlionel/Prune-Tune.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Jianze Liang; Chengqi Zhao; Mingxuan Wang; Xipeng Qiu; Lei Li",
        "authorids": "",
        "aff": "Fudan University Bytedance AI Lab; Bytedance AI Lab; Bytedance AI Lab; Fudan University; ByteDance AI Lab",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17574/17574-13-21068-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13333-finding-sparse-structures-for-domain-specific-neural-machine-translation/",
        "doi": "10.1609/aaai.v35i15.17574",
        "pdf_size": 2562785
    },
    {
        "id": "05779",
        "title": "Finding and Certifying (Near-)Optimal Strategies in Black-Box Extensive-Form Games",
        "track": "main",
        "status": "Poster",
        "abstract": "Often---for example in war games, strategy video games, and financial simulations---the game is given to us only as a black-box simulator in which we can play it. In these settings, since the game may have unknown nature action distributions (from which we can only obtain samples) and/or be too large to expand fully, it can be difficult to compute strategies with guarantees on exploitability. Recent work (Zhang and Sandholm 2020) resulted in a notion of certificate for extensive-form games that allows exploitability guarantees while not expanding the full game tree. However, that work assumed that the black box could sample or expand arbitrary nodes of the game tree at any time, and that a series of exact game solves (via, for example, linear programming) can be conducted to compute the certificate. Each of those two assumptions severely restricts the practical applicability of that method. In this work, we relax both of the assumptions. We show that high-probability certificates can be obtained with a black box that can do nothing more than play through games, using only a regret minimizer as a subroutine. As a bonus, we obtain an equilibrium-finding algorithm with $tilde O(1/sqrt{T})$ convergence rate in the extensive-form game setting that does not rely on a sampling strategy with lower-bounded reach probabilities (which MCCFR assumes). We demonstrate experimentally that, in the black-box setting, our methods are able to provide nontrivial exploitability guarantees while expanding only a small fraction of the game tree.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Brian Hu Zhang; Tuomas Sandholm",
        "authorids": "",
        "aff": "Carnegie Mellon University; Carnegie Mellon University Strategy Robot, Inc. Optimized Markets, Inc. Strategic Machine, Inc.",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16724/16724-13-20218-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05779-finding-and-certifying-near-optimal-strategies-in-black-box-extensive-form-games/",
        "doi": "10.1609/aaai.v35i6.16724",
        "pdf_size": 308705
    },
    {
        "id": "10338",
        "title": "Fine-grained Generalization Analysis of Vector-Valued Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Many fundamental machine learning tasks can be formulated as a problem of learning with vector-valued functions, where we learn multiple scalar-valued functions together. Although there is some generalization analysis on different specific algorithms under the empirical risk minimization principle, a unifying analysis of vector-valued learning under a regularization framework is still lacking. In this paper, we initiate the generalization analysis of regularized vector-valued learning algorithms by presenting bounds with a mild dependency on the output dimension and a fast rate on the sample size. Our discussions relax the existing assumptions on the restrictive constraint of hypothesis spaces, smoothness of loss functions and low-noise condition. To understand the interaction between optimization and learning, we further use our results to derive the first generalization bounds for stochastic gradient descent with vector-valued functions. We apply our general results to multi-class classification and multi-label classification, which yield the first bounds with a logarithmic dependency on the output dimension for extreme multi-label classification with the Frobenius regularization. As a byproduct, we derive a Rademacher complexity bound for loss function classes defined in terms of a general strongly convex function.",
        "primary_area": "Machine Learning V",
        "author": "Liang Wu; Antoine Ledent; Yunwen Lei; Marius Kloft",
        "authorids": "",
        "aff": "Southwestern University of Finance and Economics; TU Kaiserslautern; University of Birmingham TU Kaiserslautern; TU Kaiserslautern",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17238/17238-13-20732-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10338-fine-grained-generalization-analysis-of-vector-valued-learning/",
        "doi": "10.1609/aaai.v35i12.17238",
        "pdf_size": 331594
    },
    {
        "id": "07064",
        "title": "Fitting the Search Space of Weight-sharing NAS with Graph Convolutional Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Neural architecture search has attracted wide attentions in both academia and industry. To accelerate it, researchers proposed weight-sharing methods which first train a super-network to reuse computation among different operators, from which exponentially many sub-networks can be sampled and efficiently evaluated. These methods enjoy great advantages in terms of computational costs, but the sampled sub-networks are not guaranteed to be estimated precisely unless an individual training process is taken. This paper owes such inaccuracy to the inevitable mismatch between assembled network layers, so that there is a random error term added to each estimation. We alleviate this issue by training a graph convolutional network to fit the performance of sampled sub-networks so that the impact of random errors becomes minimal. With this strategy, we achieve a higher rank correlation coefficient in the selected set of candidates, which consequently leads to better performance of the final architecture. In addition, our approach also enjoys the flexibility of being used under different hardware constraints, since the graph convolutional network has provided an efficient lookup table of the performance of architectures in the entire search space.",
        "primary_area": "Machine Learning I",
        "author": "Xin Chen; Lingxi Xie; Jun Wu; Longhui Wei; Yuhui Xu; Qi Tian",
        "authorids": "",
        "aff": "Huawei Cloud & AI; Huawei Cloud & AI; Fudan University; Huawei Cloud & AI; Shanghai Jiao Tong University; Huawei Cloud & AI",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16869/16869-13-20363-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07064-fitting-the-search-space-of-weight-sharing-nas-with-graph-convolutional-networks/",
        "doi": "10.1609/aaai.v35i8.16869",
        "pdf_size": 280110
    },
    {
        "id": "13134",
        "title": "Flexible Non-Autoregressive Extractive Summarization with Threshold: How to Extract a Non-Fixed Number of Summary Sentences",
        "track": "main",
        "status": "Poster",
        "abstract": "Sentence-level extractive summarization is a fundamental yet challenging task, and recent powerful approaches prefer to pick sentences sorted by the predicted probabilities until the length limit is reached, a.k.a. ``Top-K Strategy''. This length limit is fixed based on the validation set, resulting in the lack of flexibility. In this work, we propose a more flexible and accurate non-autoregressive method for single document extractive summarization, extracting a non-fixed number of summary sentences without the sorting step. We call our approach ThresSum as it picks sentences simultaneously and individually from the source document when the predicted probabilities exceed a threshold. During training, the model enhances sentence representation through iterative refinement and the intermediate latent variables receive some weak supervision with soft labels, which are generated progressively by adjusting the temperature with a knowledge distillation algorithm. Specifically, the temperature is initialized with high value and drops along with the iteration until a temperature of 1. Experimental results on CNN/DM and NYT datasets have demonstrated the effectiveness of ThresSum, which significantly outperforms BERTSUMEXT with a substantial improvement of 0.74 ROUGE-1 score on CNN/DM. Our source code will be available on Github.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Ruipeng Jia; Yanan Cao; Haichao Shi; Fang Fang; Pengfei Yin; Shi Wang",
        "authorids": "",
        "aff": "Institute of Information Engineering, Chinese Academy of Sciences School of Cyber Security, University of Chinese Academy of Sciences; Institute of Information Engineering, Chinese Academy of Sciences; Institute of Information Engineering, Chinese Academy of Sciences; Institute of Information Engineering, Chinese Academy of Sciences; Institute of Information Engineering, Chinese Academy of Sciences; Institute of Computing Technology, Chinese Academy of Sciences",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17552/17552-13-21046-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13134-flexible-non-autoregressive-extractive-summarization-with-threshold-how-to-extract-a-non-fixed-number-of-summary-sentences/",
        "doi": "10.1609/aaai.v35i14.17552",
        "pdf_size": 445392
    },
    {
        "id": "11042",
        "title": "Flow-based Generative Models for Learning Manifold to Manifold Mappings",
        "track": "main",
        "status": "Poster",
        "abstract": "Many measurements or observations in computer vision and machine learning manifest as non-Euclidean data. While recent proposals (like spherical CNN) have extended a number of deep neural network architectures to manifold-valued data, and this has often provided strong improvements in performance, the literature on generative models for manifold data is quite sparse. Partly due to this gap, there are also no modality transfer/translation models for manifold-valued data whereas numerous such methods based on generative models are available for natural images. This paper addresses this gap, motivated by a need in brain imaging -- in doing so, we expand the operating range of certain generative models (as well as generative models for modality transfer) from natural images to images with manifold-valued measurements. Our main result is the design of a two-stream version of GLOW (flow-based invertible generative models) that can synthesize information of a field of one type of manifold-valued measurements given another. On the theoretical side, we introduce three kinds of invertible layers for manifold-valued data, which are not only analogous to their functionality in flow-based generative models (e.g., GLOW) but also preserve the key benefits (determinants of the Jacobian are easy to calculate). For experiments, on a large dataset from the Human Connectome Project (HCP), we show promising results where we can reliably and accurately reconstruct brain images of a field of orientation distribution functions (ODF) from diffusion tensor images (DTI), where the latter has a 5\u00d7 faster acquisition time but at the expense of worse angular resolution.",
        "primary_area": "Machine Learning V",
        "author": "Xingjian Zhen; Rudrasis Chakraborty; Liu Yang; Vikas Singh",
        "authorids": "",
        "aff": "University of Wisconsin-Madison; University of California, Berkeley; University of Wisconsin-Madison; University of Wisconsin-Madison",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17318/17318-13-20812-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11042-flow-based-generative-models-for-learning-manifold-to-manifold-mappings/",
        "doi": "10.1609/aaai.v35i12.17318",
        "pdf_size": 11192791
    },
    {
        "id": "06522",
        "title": "Focused Inference and System P",
        "track": "main",
        "status": "Poster",
        "abstract": "We bring in the concept of focused inference into the field of qualitative nonmonotonic reasoning by applying focused inference to System P. The idea behind drawing focused inferences is to concentrate on knowledge which seems to be relevant for answering a query while completely disregarding the remaining knowledge even at the risk of missing some meaningful information. Focused inference is motivated by mimicking snap decisions of human reasoners and aims on rapidly drawing still reasonable inferences from large sets of knowledge. In this paper, we define a series of query-dependent, syntactically-driven focused inference relations, elaborate on their formal properties, and show that the series converges against System P. We take advantage of this result in form of an anytime algorithm for drawing inferences which is accompanied by a thorough complexity analysis.",
        "primary_area": "Knowledge Representation and Reasoning",
        "author": "Marco Wilhelm; Gabriele Kern-Isberner",
        "authorids": "",
        "aff": "TU Dortmund University; TU Dortmund University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16808/16808-13-20302-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06522-focused-inference-and-system-p/",
        "doi": "10.1609/aaai.v35i7.16808",
        "pdf_size": 164582
    },
    {
        "id": "02198",
        "title": "FontRL: Chinese Font Synthesis via Deep Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Automatic generation of Chinese fonts is a valuable but challenging task in areas of AI and Computer Graphics, mainly due to the huge amount of Chinese characters and their complex glyph structures. In this paper, we propose FontRL, a novel method for Chinese font synthesis by using deep reinforcement learning. Specifically, we first train a deep reinforcement learning model to obtain the Thin-Plate Spline (TPS) transformation that is able to modify the reference stroke skeleton in a mean font style into the skeleton of a required style for each stroke of every unseen Chinese character. Afterwards, we utilize a CNN model to predict the location and scale information of these strokes, and then assemble them to get the skeleton of the corresponding character. Finally, we convert each synthesized character skeleton into the glyph image via an image-to-image translation model. Both quantitative and qualitative experimental results demonstrate the superiority of the proposed FontRL compared to the state of the art. Our code is available at https://github.com/lsflyt-pku/FontRL.",
        "primary_area": "Computer Vision II",
        "author": "Yitian Liu; Zhouhui Lian",
        "authorids": "",
        "aff": "Peking University; Peking University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16318/16318-13-19812-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02198-fontrl-chinese-font-synthesis-via-deep-reinforcement-learning/",
        "doi": "10.1609/aaai.v35i3.16318",
        "pdf_size": 2358725
    },
    {
        "id": "03616",
        "title": "Fooling Thermal Infrared Pedestrian Detectors in Real World Using Small Bulbs",
        "track": "main",
        "status": "Poster",
        "abstract": "Thermal infrared detection systems play an important role in many areas such as night security, autonomous driving, and body temperature detection. They have the unique advantages of passive imaging, temperature sensitivity and penetration. But the security of these systems themselves has not been fully explored, which poses risks in applying these systems. We propose a physical attack method with small bulbs on a board against the state of-the-art pedestrian detectors. Our goal is to make infrared pedestrian detectors unable to detect real-world pedestrians. Towards this goal, we \ufb01rst showed that it is possible to use two kinds of patches to attack the infrared pedestrian detector based on YOLOv3. The average precision (AP) dropped by 64.12% in the digital world, while a blank board with the same size caused the AP to drop by 29.69% only. After that, we designed and manufactured a physical board and successfully attacked YOLOv3 in the real world. In recorded videos, the physical board caused AP of the target detector to drop by 34.48%, while a blank board with the same size caused the AP to drop by 14.91% only. With the ensemble attack techniques, the designed physical board had good transferability to unseen detectors.",
        "primary_area": "Computer Vision III",
        "author": "Xiaopei Zhu; Xiao Li; Jianmin Li; Zheyao Wang; Xiaolin Hu",
        "authorids": "",
        "aff": "Tsinghua University; Tsinghua University; Tsinghua University; Tsinghua University; Tsinghua University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16477/16477-13-19971-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03616-fooling-thermal-infrared-pedestrian-detectors-in-real-world-using-small-bulbs/",
        "doi": "10.1609/aaai.v35i4.16477",
        "pdf_size": 4353008
    },
    {
        "id": "09834",
        "title": "Foresee then Evaluate: Decomposing Value Estimation with Latent Future Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "Value function is the central notion of Reinforcement Learning (RL). Value estimation, especially with function approximation, can be challenging since it involves the stochasticity of environmental dynamics and reward signals that can be sparse and delayed in some cases. A typical model-free RL algorithm usually estimates the values of a policy by Temporal Difference (TD) or Monte Carlo (MC) algorithms directly from rewards, without explicitly taking dynamics into consideration. In this paper, we propose Value Decomposition with Future Prediction (VDFP), providing an explicit two-step understanding of the value estimation process: 1) first foresee the latent future, 2) and then evaluate it. We analytically decompose the value function into a latent future dynamics part and a policy-independent trajectory return part, inducing a way to model latent dynamics and returns separately in value estimation. Further, we derive a practical deep RL algorithm, consisting of a convolutional model to learn compact trajectory representation from past experiences, a conditional variational auto-encoder to predict the latent future dynamics and a convex return model that evaluates trajectory representation. In experiments, we empirically demonstrate the effectiveness of our approach for both off-policy and on-policy RL in several OpenAI Gym continuous control tasks as well as a few challenging variants with delayed reward.",
        "primary_area": "Machine Learning IV",
        "author": "Hongyao Tang; Zhaopeng Meng; Guangyong Chen; Pengfei Chen; Chen Chen; Yaodong Yang; Luo Zhang; Wulong Liu; Jianye Hao",
        "authorids": "",
        "aff": "College of Intelligence of Computing, Tianjin University; College of Intelligence of Computing, Tianjin University; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences; The Chinese University of Hong Kong; Huawei Noah\u2019s Ark Lab; Huawei Noah's Ark Lab; Tianjin University; Huawei Noah's Ark Lab; College of Intelligence of Computing, Tianjin University Huawei Noah's Ark Lab",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17182/17182-13-20676-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09834-foresee-then-evaluate-decomposing-value-estimation-with-latent-future-prediction/",
        "doi": "10.1609/aaai.v35i11.17182",
        "pdf_size": 1962612
    },
    {
        "id": "05094",
        "title": "Forming Better Stable Solutions in Group Formation Games Inspired by Internet Exchange Points (IXPs)",
        "track": "main",
        "status": "Poster",
        "abstract": "We study a coordination game motivated by the formation of Internet Exchange Points (IXPs), in which agents choose which facilities to join. Joining the same facility as other agents you communicate with has benefits, but different facilities have different costs for each agent. Thus, the players wish to join the same facilities as their \"friends\", but this is balanced by them not wanting to pay the cost of joining a facility. We first show that the Price of Stability (PoS) of this game is at most 2, and more generally there always exists an alpha-approximate equilibrium with cost at most 2/alpha of optimum. We then focus on how better stable solutions can be formed. If we allow agents to pay their neighbors to prevent them from deviating (i.e., a player i voluntarily pays another player j so that j joins the same facility), then we provide a payment scheme which stabilizes the solution with minimum social cost s*, i.e. PoS is 1. In our main technical result, we consider how much a central coordinator would have to pay the players in order to form good stable solutions. Let Delta denote the total amount of payments needed to be paid to the players in order to stabilize s*, i.e., these are payments that a player would lose if they changed their strategy from the one in s*. We prove that there is a tradeoff between Delta and the Price of Stability: Delta/cost(s*) < 1 - 2 PoS/5. Thus when there are no good stable solutions, only a small amount of extra payment is needed to stabilize s*; and when good stable solutions already exist (i.e., PoS is small), then we should be happy with those solutions instead. Finally, we consider the computational complexity of finding the optimum solution s*, and design a polynomial time O(log n) approximation algorithm for this problem.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Elliot Anshelevich; Wennan Zhu",
        "authorids": "",
        "aff": "Rensselaer Polytechnic Institute, Troy, NY 12180; Rensselaer Polytechnic Institute, Troy, NY 12180",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16644/16644-13-20138-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05094-forming-better-stable-solutions-in-group-formation-games-inspired-by-internet-exchange-points-ixps/",
        "doi": "10.1609/aaai.v35i6.16644",
        "pdf_size": 162448
    },
    {
        "id": "10612",
        "title": "FracBits: Mixed Precision Quantization via Fractional Bit-Widths",
        "track": "main",
        "status": "Poster",
        "abstract": "Model quantization helps to reduce model size and latency of deep neural networks. Mixed precision quantization is favorable with customized hardwares supporting arithmetic operations at multiple bit-widths to achieve maximum efficiency. We propose a novel learning-based algorithm to derive mixed precision models end-to-end under target computation constraints and model sizes. During the optimization, the bit-width of each layer / kernel in the model is at a fractional status of two consecutive bit-widths which can be adjusted gradually. With a differentiable regularization term, the resource constraints can be met during the quantization-aware training which results in an optimized mixed precision model. Our final models achieve comparable or better performance than previous quantization methods with mixed precision on MobilenetV1/V2, ResNet18 under different resource constraints on ImageNet dataset.",
        "primary_area": "Machine Learning V",
        "author": "Linjie Yang; Qing Jin",
        "authorids": "",
        "aff": "ByteDance Inc.; Northeastern University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17269/17269-13-20763-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10612-fracbits-mixed-precision-quantization-via-fractional-bit-widths/",
        "doi": "10.1609/aaai.v35i12.17269",
        "pdf_size": 1678475
    },
    {
        "id": "10370",
        "title": "Fractal Autoencoders for Feature Selection",
        "track": "main",
        "status": "Poster",
        "abstract": "Feature selection reduces the dimensionality of data by identifying a subset of the most informative features. In this paper, we propose an innovative framework for unsupervised feature selection, called fractal autoencoders (FAE). It trains a neural network to pinpoint informative features for global exploring of representability and for local excavating of diversity. Architecturally, FAE extends autoencoders by adding a one-to-one scoring layer and a small sub-neural network for feature selection in an unsupervised fashion. With such a concise architecture, FAE achieves state-of-the-art performances; extensive experimental results on fourteen datasets, including very high-dimensional data, have demonstrated the superiority of FAE over existing contemporary methods for unsupervised feature selection. In particular, FAE exhibits substantial advantages on gene expression data exploration, reducing measurement cost by about 15% over the widely used L1000 landmark genes. Further, we show that the FAE framework is easily extensible with an application.",
        "primary_area": "Machine Learning V",
        "author": "Xinxing Wu; Qiang Cheng",
        "authorids": "",
        "aff": "University of Kentucky; University of Kentucky",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17242/17242-13-20736-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10370-fractal-autoencoders-for-feature-selection/",
        "doi": "10.1609/aaai.v35i12.17242",
        "pdf_size": 2811928
    },
    {
        "id": "01664",
        "title": "Frequency Consistent Adaptation for Real World Super Resolution",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent deep-learning based Super-Resolution (SR) methods have achieved remarkable performance on images with known degradation. However, these methods always fail in real-world scene, since the Low-Resolution (LR) images after the ideal degradation (e.g., bicubic down-sampling) deviate from real source domain. The domain gap between the LR images and the real-world images can be observed clearly on frequency density, which inspires us to explicitly narrow the undesired gap caused by incorrect degradation. From this point of view, we design a novel Frequency Consistent Adaptation (FCA) that ensures the frequency domain consistency when applying existing SR methods to the real scene. We estimate degradation kernels from unsupervised images and generate the corresponding LR images. To provide useful gradient information for kernel estimation, we propose Frequency Density Comparator (FDC) by distinguishing the frequency density of images on different scales. Based on the domain-consistent LR-HR pairs, we train easy-implemented Convolutional Neural Network (CNN) SR models. Extensive experiments show that the proposed FCA improves the performance of the SR model under real-world setting achieving state-of-the-art results with high fidelity and plausible perception, thus providing a novel effective framework for real-world SR application.",
        "primary_area": "Computer Vision I",
        "author": "Xiaozhong Ji; Guangpin Tao; Yun Cao; Ying Tai; Tong Lu; Chengjie Wang; Jilin Li; Feiyue Huang",
        "authorids": "",
        "aff": "National Key Lab for Novel Software Technology, Nanjing University; National Key Lab for Novel Software Technology, Nanjing University; Tencent Youtu Lab; Tencent Youtu Lab; National Key Lab for Novel Software Technology, Nanjing University; Tencent Youtu Lab; Tencent Youtu Lab; Tencent Youtu Lab",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16259/16259-13-19753-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01664-frequency-consistent-adaptation-for-real-world-super-resolution/",
        "doi": "10.1609/aaai.v35i2.16259",
        "pdf_size": 1495001
    },
    {
        "id": "06921",
        "title": "Frivolous Units: Wider Networks Are Not Really That Wide",
        "track": "main",
        "status": "Poster",
        "abstract": "A remarkable characteristic of overparameterized deep neural networks (DNNs) is that their accuracy does not degrade when the network width is increased. Recent evidence suggests that developing compressible representations allows the complexity of large networks to be adjusted for the learning task at hand. However, these representations are poorly understood. A promising strand of research inspired from biology involves studying representations at the unit level as it offers a more granular interpretation of the neural mechanisms. In order to better understand what facilitates increases in width without decreases in accuracy, we ask: Are there mechanisms at the unit level by which networks control their effective complexity? If so, how do these depend on the architecture, dataset, and hyperparameters? We identify two distinct types of \u201cfrivolous\u201d units that proliferate when the network\u2019s width increases: prunable units which can be dropped out of the network without significant change to the output and redundant units whose activities can be expressed as a linear combination of others. These units imply complexity constraints as the function the network computes could be expressed without them. We also identify how the development of these units can be influenced by architecture and a number of training factors. Together, these results help to explain why the accuracy of DNNs does not degrade when width is increased and highlight the importance of frivolous units toward understanding implicit regularization in DNNs.",
        "primary_area": "Machine Learning I",
        "author": "Stephen Casper; Xavier Boix; Vanessa D'Amario; Ling Guo; Martin Schrimpf; Kasper Vinken; Gabriel Kreiman",
        "authorids": "",
        "aff": "Boston Children's Hospital, Harvard Medical School, USA Center for Brains, Minds, and Machines (CBMM); Boston Children's Hospital, Harvard Medical School Center for Brains, Minds, and Machines (CBMM) Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology, USA; Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology, USA; Neuroscience Graduate Program, University of California San Francisco, USA; Center for Brains, Minds, and Machines (CBMM) Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology, USA; Boston Children's Hospital, Harvard Medical School, USA Center for Brains, Minds, and Machines (CBMM); Boston Children's Hospital, Harvard Medical School, USA Center for Brains, Minds, and Machines (CBMM)",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16853/16853-13-20347-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06921-frivolous-units-wider-networks-are-not-really-that-wide/",
        "doi": "10.1609/aaai.v35i8.16853",
        "pdf_size": 2711149
    },
    {
        "id": "05637",
        "title": "From Behavioral Theories to Econometrics: Inferring Preferences of Human Agents from Data on Repeated Interactions",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider the problem of estimating preferences of human agents from data of strategic systems where the agents repeatedly interact. Recently, it was demonstrated that a new estimation method called \"quantal regret\" produces more accurate estimates for human agents than the classic approach that assumes that agents are rational and reach a Nash equilibrium; however, this method has not been compared to methods that take into account behavioral aspects of human play. In this paper we leverage equilibrium concepts from behavioral economics for this purpose and ask how well they perform compared to the quantal regret and Nash equilibrium methods. We develop four estimation methods based on established behavioral equilibrium models to infer the utilities of human agents from observed data of normal-form games. The equilibrium models we study are quantal-response equilibrium, action-sampling equilibrium, payoff-sampling equilibrium, and impulse-balance equilibrium. We show that in some of these concepts the inference is achieved analytically via closed formulas, while in the others the inference is achieved only algorithmically. We use experimental data of 2x2 games to evaluate the estimation success of these behavioral equilibrium methods. The results show that the estimates they produce are more accurate than the estimates of the Nash equilibrium. The comparison with the quantal-regret method shows that the behavioral methods have better hit rates, but the quantal-regret method performs better in terms of the overall mean squared error, and we discuss the differences between the methods.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Gali Noti",
        "authorids": "",
        "aff": "Harvard University The Hebrew University of Jerusalem",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16708/16708-13-20202-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05637-from-behavioral-theories-to-econometrics-inferring-preferences-of-human-agents-from-data-on-repeated-interactions/",
        "doi": "10.1609/aaai.v35i6.16708",
        "pdf_size": 334990
    },
    {
        "id": "08583",
        "title": "From Label Smoothing to Label Relaxation",
        "track": "main",
        "status": "Poster",
        "abstract": "Regularization of (deep) learning models can be realized at the model, loss, or data level. As a technique somewhere in-between loss and data, label smoothing turns deterministic class labels into probability distributions, for example by uniformly distributing a certain part of the probability mass over all classes. A predictive model is then trained on these distributions as targets, using cross-entropy as loss function. While this method has shown improved performance compared to non-smoothed cross-entropy, we argue that the use of a smoothed though still precise probability distribution as a target can be questioned from a theoretical perspective. As an alternative, we propose a generalized technique called label relaxation, in which the target is a set of probabilities represented in terms of an upper probability distribution. This leads to a genuine relaxation of the target instead of a distortion, thereby reducing the risk of incorporating an undesirable bias in the learning process. Methodically, label relaxation leads to the minimization of a novel type of loss function, for which we propose a suitable closed-form expression for model optimization. The effectiveness of the approach is demonstrated in an empirical study on image data.",
        "primary_area": "Machine Learning III",
        "author": "Julian Lienen; Eyke H\u00fcllermeier",
        "authorids": "",
        "aff": "Paderborn University; Paderborn University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17041/17041-13-20535-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08583-from-label-smoothing-to-label-relaxation/",
        "doi": "10.1609/aaai.v35i10.17041",
        "pdf_size": 434058
    },
    {
        "id": "10347",
        "title": "Frugal Optimization for Cost-related Hyperparameters",
        "track": "main",
        "status": "Poster",
        "abstract": "The increasing demand for democratizing machine learning algorithms calls for hyperparameter optimization (HPO) solutions at low cost. Many machine learning algorithms have hyperparameters which can cause a large variation in the training cost. But this effect is largely ignored in existing HPO methods, which are incapable to properly control cost during the optimization process. To address this problem, we develop a new cost-frugal HPO solution. The core of our solution is a simple but new randomized direct-search method, for which we provide theoretical guarantees on the convergence rate and the total cost incurred to achieve convergence. We provide strong empirical results in comparison with state-of-the-art HPO methods on large AutoML benchmarks.",
        "primary_area": "Machine Learning V",
        "author": "Qingyun Wu; Chi Wang; Silu Huang",
        "authorids": "",
        "aff": "Microsoft Research; Microsoft Research; Microsoft Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17239/17239-13-20733-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10347-frugal-optimization-for-cost-related-hyperparameters/",
        "doi": "10.1609/aaai.v35i12.17239",
        "pdf_size": 2285616
    },
    {
        "id": "00582",
        "title": "Fully Exploiting Cascade Graphs for Real-time Forwarding Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "Real-time forwarding prediction for predicting online contents' popularity is beneficial to various social applications for enhancing interactive social behaviors. Cascade graphs, formed by online contents' propagation, play a vital role in real-time forwarding prediction. Existing cascade graph modeling methods are inadequate to embed cascade graphs that have hub structures and deep cascade paths, or they fail to handle the short-term outbreak of forwarding amount. To this end, we propose a novel real-time forwarding prediction method that includes an effective approach for cascade graph embedding and a short-term variation sensitive method for time-series modeling, making the best of cascade graph features. Using two real world datasets, we demonstrate the significant superiority of the proposed method compared with the state-of-the-art. Our experiments also reveal interesting implications hidden in the performance differences between cascade graph embedding and time-series modeling.",
        "primary_area": "Application Domains",
        "author": "Xiangyun Tang; Dongliang Liao; Weijie Huang; Jin Xu; Liehuang Zhu; Meng Shen",
        "authorids": "",
        "aff": "School of Cyberspace Security, Beijing Institute of Technology, China; Data Quality Team, WeChat, Tencent Inc., China; Data Quality Team, WeChat, Tencent Inc., China; Data Quality Team, WeChat, Tencent Inc., China; School of Cyberspace Security, Beijing Institute of Technology, China; School of Cyberspace Security, Beijing Institute of Technology, China Cyberspace Security Research Center, Peng Cheng Laboratory, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16137/16137-13-19631-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00582-fully-exploiting-cascade-graphs-for-real-time-forwarding-prediction/",
        "doi": "10.1609/aaai.v35i1.16137",
        "pdf_size": 1225593
    },
    {
        "id": "11071",
        "title": "Fully-Connected Tensor Network Decomposition and Its Application to Higher-Order Tensor Completion",
        "track": "main",
        "status": "Poster",
        "abstract": "The popular tensor train (TT) and tensor ring (TR) decompositions have achieved promising results in science and engineering. However, TT and TR decompositions only establish an operation between adjacent two factors and are highly sensitive to the permutation of tensor modes, leading to an inadequate and inflexible representation. In this paper, we propose a generalized tensor decomposition, which decomposes an Nth-order tensor into a set of Nth-order factors and establishes an operation between any two factors. Since it can be graphically interpreted as a fully-connected network, we named it fully-connected tensor network (FCTN) decomposition. The superiorities of the FCTN decomposition lie in the outstanding capability for characterizing adequately the intrinsic correlations between any two modes of tensors and the essential invariance for transposition. Furthermore, we employ the FCTN decomposition to one representative task, i.e., tensor completion, and develop an efficient solving algorithm based on proximal alternating minimization. Theoretically, we prove the convergence of the developed algorithm, i.e., the sequence obtained by it globally converges to a critical point. Experimental results substantiate that the proposed method compares favorably to the state-of-the-art methods based on other tensor decompositions.",
        "primary_area": "Machine Learning V",
        "author": "Yu-Bang Zheng; Ting-Zhu Huang; Xi-Le Zhao; Qibin Zhao; Tai-Xiang Jiang",
        "authorids": "",
        "aff": "School of Mathematical Sciences, University of Electronic Science and Technology of China; School of Mathematical Sciences, University of Electronic Science and Technology of China; School of Mathematical Sciences, University of Electronic Science and Technology of China; Tensor Learning Team, RIKEN Center for Advanced Intelligence Project (AIP) School of Automation, Guangdong University of Technology; School of Economic Information Engineering, Southwestern University of Finance and Economics",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17321/17321-13-20815-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11071-fully-connected-tensor-network-decomposition-and-its-application-to-higher-order-tensor-completion/",
        "doi": "10.1609/aaai.v35i12.17321",
        "pdf_size": 2621286
    },
    {
        "id": "14428",
        "title": "Future-Guided Incremental Transformer for Simultaneous Translation",
        "track": "main",
        "status": "Poster",
        "abstract": "Simultaneous translation (ST) starts translations synchronously while reading source sentences, and is used in many online scenarios. The previous wait-k policy is concise and achieved good results in ST. However, wait-k policy faces two weaknesses: low training speed caused by the recalculation of hidden states and lack of future source information to guide training. For the low training speed, we propose an incremental Transformer with an average embedding layer (AEL) to accelerate the speed of calculation of the hidden states during training. For future-guided training, we propose a conventional Transformer as the teacher of the incremental Transformer, and try to invisibly embed some future information in the model through knowledge distillation. We conducted experiments on Chinese-English and German-English simultaneous translation tasks and compared with the wait-k policy to evaluate the proposed method. Our method can effectively increase the training speed by about 28 times on average at different k and implicitly embed some predictive abilities in the model, achieving better translation quality than wait-k baseline.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Shaolei Zhang; Yang Feng; Liangyou Li",
        "authorids": "",
        "aff": "Key Laboratory of Intelligent Information Processing, Institute of Computing Technology, Chinese Academy of Sciences (ICT/CAS) University of Chinese Academy of Sciences; Key Laboratory of Intelligent Information Processing, Institute of Computing Technology, Chinese Academy of Sciences (ICT/CAS) University of Chinese Academy of Sciences; Huawei Noah's Ark Lab",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17696/17696-13-21190-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14428-future-guided-incremental-transformer-for-simultaneous-translation/",
        "doi": "10.1609/aaai.v35i16.17696",
        "pdf_size": 3452541
    },
    {
        "id": "04090",
        "title": "GAN Ensemble for Anomaly Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "When formulated as an unsupervised learning problem, anomaly detection often requires a model to learn the distribution of normal data. Previous works modify Generative Adversarial Networks (GANs) by using encoder-decoders as generators and apply them to anomaly detection tasks. Previous studies indicate that GAN ensembles are often more stable than single GANs in image generation tasks. In this work, we propose to construct GAN ensembles for anomaly detection. In the proposed method, a group of generators interact with a group of discriminators, so every generator gets feedback from every discriminator, and vice versa. Compared to a single GAN, an ensemble of GANs can better model the distribution of normal data and thus better detect anomalies. We also make a theoretical analysis of GANs and GAN ensembles in the context of anomaly detection. The empirical study constructs ensembles based on four different types of detecting models, and the results show that the ensemble outperforms the single model for all four model types.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Xu Han; Xiaohui Chen; Li-Ping Liu",
        "authorids": "",
        "aff": "Tufts University; Tufts University; Tufts University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16530/16530-13-20024-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04090-gan-ensemble-for-anomaly-detection/",
        "doi": "10.1609/aaai.v35i5.16530",
        "pdf_size": 764757
    },
    {
        "id": "12462",
        "title": "GATE: Graph Attention Transformer Encoder for Cross-lingual Relation and Event Extraction",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent progress in cross-lingual relation and event extraction use graph convolutional networks (GCNs) with universal dependency parses to learn language-agnostic sentence representations such that models trained on one language can be applied to other languages. However, GCNs struggle to model words with long-range dependencies or are not directly connected in the dependency tree. To address these challenges, we propose to utilize the self-attention mechanism where we explicitly fuse structural information to learn the dependencies between words with different syntactic distances. We introduce GATE, a Graph Attention Transformer Encoder, and test its cross-lingual transferability on relation and event extraction tasks. We perform experiments on the ACE05 dataset that includes three typologically different languages: English, Chinese, and Arabic. The evaluation results show that GATE outperforms three recently proposed methods by a large margin. Our detailed analysis reveals that due to the reliance on syntactic dependencies, GATE produces robust representations that facilitate transfer across languages.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Wasi Uddin Ahmad; Nanyun Peng; Kai-Wei Chang",
        "authorids": "",
        "aff": "University of California, Los Angeles; University of California, Los Angeles; University of California, Los Angeles",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17478/17478-13-20972-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12462-gate-graph-attention-transformer-encoder-for-cross-lingual-relation-and-event-extraction/",
        "doi": "10.1609/aaai.v35i14.17478",
        "pdf_size": 318214
    },
    {
        "id": "14194",
        "title": "GDPNet: Refining Latent Multi-View Graph for Relation Extraction",
        "track": "main",
        "status": "Poster",
        "abstract": "Relation Extraction (RE) is to predict the relation type of two entities that are mentioned in a piece of text, e.g., a sentence or a dialogue. When the given text is long, it is challenging to identify indicative words for the relation prediction. Recent advances on RE task are from BERT-based sequence modeling and graph-based modeling of relationships among the tokens in the sequence. In this paper, we propose to construct a latent multi-view graph to capture various possible relationships among tokens. We then refine this graph to select important words for relation prediction. Finally, the representation of the refined graph and the BERT-based sequence representation are concatenated for relation extraction. Specifically, in our proposed GDPNet (Gaussian Dynamic Time Warping Pooling Net), we utilize Gaussian Graph Generator (GGG) to generate edges of the multi-view graph. The graph is then refined by Dynamic Time Warping Pooling (DTWPool). On DialogRE and TACRED, we show that GDPNet achieves the best performance on dialogue-level RE, and comparable performance with the state-of-the-arts on sentence-level RE. Our code is available at https://github.com/XueFuzhao/GDPNet.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Fuzhao Xue; Aixin Sun; Hao Zhang; Eng Siong Chng",
        "authorids": "",
        "aff": "School of Computer Science and Engineering, Nanyang Technological University, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17670/17670-13-21164-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14194-gdpnet-refining-latent-multi-view-graph-for-relation-extraction/",
        "doi": "10.1609/aaai.v35i16.17670",
        "pdf_size": 205266
    },
    {
        "id": "06444",
        "title": "GENSYNTH: Synthesizing Datalog Programs without Language Bias",
        "track": "main",
        "status": "Poster",
        "abstract": "Techniques for learning logic programs from data typically rely on language bias mechanisms to restrict the hypothesis space. These methods are therefore limited by the user's ability to tune them such that the hypothesis space is simultaneously large enough to include the target program but small enough to admit a tractable search. We propose a technique to learn Datalog programs from input-output examples without requiring the user to specify any language bias. It employs an evolutionary search strategy that mutates candidate programs and evaluates their fitness on the examples using an off-the-shelf Datalog interpreter. We have implemented our approach in a tool called GenSynth and evaluate it on diverse tasks from knowledge discovery, program analysis, and relational queries. Our experiments show that GenSynth can learn correct programs from few examples, including for tasks that require recursion and invented predicates, and is robust to noise.",
        "primary_area": "Knowledge Representation and Reasoning",
        "author": "Jonathan Mendelson; Aaditya Naik; Mukund Raghothaman; Mayur Naik",
        "authorids": "",
        "aff": "University of Pennsylvania; University of Pennsylvania; University of Southern California; University of Pennsylvania",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16799/16799-13-20293-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06444-gensynth-synthesizing-datalog-programs-without-language-bias/",
        "doi": "10.1609/aaai.v35i7.16799",
        "pdf_size": 378026
    },
    {
        "id": "03074",
        "title": "GIF Thumbnails: Attract More Clicks to Your Videos",
        "track": "main",
        "status": "Poster",
        "abstract": "With the rapid increase of mobile devices and online media, more and more people prefer posting/viewing videos online. Generally, these videos are presented on video streaming sites with image thumbnails and text titles. While facing huge amounts of videos, a viewer clicks through a certain video with high probability because of its eye-catching thumbnail. However, current video thumbnails are created manually, which is time-consuming and quality-unguaranteed. And static image thumbnails contain very limited information of the corresponding videos, which prevents users from successfully clicking what they really want to view.    In this paper, we address a novel problem, namely GIF thumbnail generation, which aims to automatically generate GIF thumbnails for videos and consequently boost their Click-Through-Rate (CTR). Here, a GIF thumbnail is an animated GIF file consisting of multiple segments from the video, containing more information of the target video than a static image thumbnail. To support this study, we build the first GIF thumbnails benchmark dataset that consists of 1070 videos covering a total duration of 69.1 hours, and 5394 corresponding manually-annotated GIFs. To solve this problem, we propose a learning-based automatic GIF thumbnail generation model, which is called Generative Variational Dual-Encoder (GEVADEN).  As not relying on any user interaction information (e.g. time-sync comments and real-time view counts), this model is applicable to newly-uploaded/rarely-viewed videos. Experiments on our built dataset show that GEVADEN significantly outperforms several baselines, including video-summarization and highlight-detection based ones. Furthermore, we develop a pilot application of the proposed model on an online video platform with 9814 videos covering 1231 hours, which shows that our model achieves a 37.5% CTR improvement over traditional image thumbnails. This further validates the effectiveness of the proposed model and the promising application prospect of GIF thumbnails.",
        "primary_area": "Computer Vision III",
        "author": "Yi Xu; Fan Bai; Yingxuan Shi; Qiuyu Chen; Longwen Gao; Kai Tian; Shuigeng Zhou; Huyang Sun",
        "authorids": "",
        "aff": "Fudan University; Fudan University; Bilibili; University of North Carolina at Charlotte; Bilibili; Fudan University; Fudan University; Bilibili",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16416/16416-13-19910-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03074-gif-thumbnails-attract-more-clicks-to-your-videos/",
        "doi": "10.1609/aaai.v35i4.16416",
        "pdf_size": 553236
    },
    {
        "id": "11782",
        "title": "GLIB: Efficient Exploration for Relational Model-Based Reinforcement Learning via Goal-Literal Babbling",
        "track": "main",
        "status": "Poster",
        "abstract": "We address the problem of efficient exploration for transition model learning in the relational model-based reinforcement learning setting without extrinsic goals or rewards. Inspired by human curiosity, we propose goal-literal babbling (GLIB), a simple and general method for exploration in such problems. GLIB samples relational conjunctive goals that can be understood as specific, targeted effects that the agent would like to achieve in the world, and plans to achieve these goals using the transition model being learned. We provide theoretical guarantees showing that exploration with GLIB will converge almost surely to the ground truth model. Experimentally, we find GLIB to strongly outperform existing methods in both prediction and planning on a range of tasks, encompassing standard PDDL and PPDDL planning benchmarks and a robotic manipulation task implemented in the PyBullet physics simulator. Video: https://youtu.be/F6lmrPT6TOY Code: https://git.io/JIsTB",
        "primary_area": "Planning, Routing, and Scheduling",
        "author": "Rohan Chitnis; Tom Silver; Joshua B. Tenenbaum; Leslie Pack Kaelbling; Tom\u00e1s Lozano-P\u00e9rez",
        "authorids": "",
        "aff": "Massachusetts Institute of Technology; Massachusetts Institute of Technology; Massachusetts Institute of Technology; Massachusetts Institute of Technology; Massachusetts Institute of Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17400/17400-13-20894-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11782-glib-efficient-exploration-for-relational-model-based-reinforcement-learning-via-goal-literal-babbling/",
        "doi": "10.1609/aaai.v35i13.17400",
        "pdf_size": 2860274
    },
    {
        "id": "08110",
        "title": "GLISTER: Generalization based Data Subset Selection for Efficient and Robust Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Large scale machine learning and deep models are extremely data-hungry. Unfortunately, obtaining large amounts of labeled data is expensive, and training state-of-the-art models (with hyperparameter tuning) requires significant computing resources and time. Secondly, real-world data is noisy and imbalanced. As a result, several recent papers try to make the training process more efficient and robust. However, most existing work either focuses on robustness or efficiency, but not both. In this work, we introduce GLISTER, a GeneraLIzation based data Subset selecTion for Efficient and Robust learning framework. We formulate GLISTER as a mixed discrete-continuous bi-level optimization problem to select a subset of the training data, which maximizes the log-likelihood on a held-out validation set. We then analyze GLISTER for simple classifiers such as gaussian and multinomial naive-bayes, k-nearest neighbor classifier, and linear regression and show connections to submodularity. Next, we propose an iterative online algorithm GLISTER-ONLINE, which performs data selection iteratively along with the parameter updates, and can be applied to any loss-based learning algorithm. We then show that for a rich class of loss functions including cross-entropy, hinge-loss, squared-loss, and logistic-loss, the inner discrete data selection is an instance of (weakly) submodular optimization, and we analyze conditions for which GLISTER-ONLINE reduces the validation loss and converges. Finally, we propose GLISTER-ACTIVE, an extension to batch active learning, and we empirically demonstrate the performance of GLISTER on a wide range of tasks including, (a) data selection to reduce training time, (b) robust learning under label noise and imbalance settings, and (c) batch-active learning with a number of deep and shallow models. We show that our framework improves upon the state of the art both in efficiency and accuracy (in cases (a) and (c)) and is more efficient compared to other state-of-the-art robust learning algorithms in case (b). The code for GLISTER is at: https://github.com/dssresearch/GLISTER.",
        "primary_area": "Machine Learning II",
        "author": "Krishnateja Killamsetty; Durga Sivasubramanian; Ganesh Ramakrishnan; Rishabh Iyer",
        "authorids": "",
        "aff": "University of Texas at Dallas; Indian Institute of Technology, Bombay; Indian Institute of Technology, Bombay; University of Texas at Dallas Indian Institute of Technology, Bombay",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16988/16988-13-20482-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08110-glister-generalization-based-data-subset-selection-for-efficient-and-robust-learning/",
        "doi": "10.1609/aaai.v35i9.16988",
        "pdf_size": 797498
    },
    {
        "id": "12060",
        "title": "GO Hessian for Expectation-Based Objectives",
        "track": "main",
        "status": "Poster",
        "abstract": "An unbiased low-variance gradient estimator, termed GO gradient, was proposed recently for expectation-based objectives E_q_\u03b3(y) [f(y)], where the random variable (RV) y may be drawn from a stochastic computation graph (SCG) with continuous (non-reparameterizable) internal nodes and continuous/discrete leaves. Based on the GO gradient, we present for E_q_\u03b3(y) [f(y)] an unbiased low-variance Hessian estimator, named GO Hessian, which contains the deterministic Hessian as a special case. Considering practical implementation, we reveal that the GO Hessian in expectation obeys the chain rule and is therefore easy-to-use with auto-differentiation and Hessian-vector products, enabling efficient cheap exploitation of curvature information over deep SCGs. As representative examples, we present the GO Hessian for non-reparameterizable gamma and negative binomial RVs/nodes. Leveraging the GO Hessian, we develop a new second-order method for E_q_\u03b3(y) [f(y)], with challenging experiments conducted to verify its effectiveness and efficiency.",
        "primary_area": "Reasoning under Uncertainty",
        "author": "Yulai Cong; Miaoyun Zhao; Jianqiao Li; Junya Chen; Lawrence Carin",
        "authorids": "",
        "aff": "Duke University; Duke University; Duke University; Duke University; Duke University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17432/17432-13-20926-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12060-go-hessian-for-expectation-based-objectives/",
        "doi": "10.1609/aaai.v35i13.17432",
        "pdf_size": 1880813
    },
    {
        "id": "00715",
        "title": "GRASP: Generic Framework for Health Status Representation Learning Based on Incorporating Knowledge from Similar Patients",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep learning models have been applied to many healthcare tasks based on electronic medical records (EMR) data and shown substantial performance. Existing methods commonly embed the records of a single patient into a representation for medical tasks. Such methods learn inadequate representations and lead to inferior performance, especially when the patient\u2019s data is sparse or low-quality. Aiming at the above problem, we propose GRASP, a generic framework for healthcare models. For a given patient, GRASP first finds patients in the dataset who have similar conditions and similar results (i.e., the similar patients), and then enhances the representation learning and prognosis of the given patient by leveraging knowledge extracted from these similar patients. GRASP defines similarities with different meanings between patients for different clinical tasks, and finds similar patients with useful information accordingly, and then learns cohort representation to extract valuable knowledge contained in the similar patients. The cohort information is fused with the current patient\u2019s representation to conduct final clinical tasks. Experimental evaluations on two real-world datasets show that GRASP can be seamlessly integrated into state-of-the-art models with consistent performance improvements. Besides, under the guidance of medical experts, we verified the findings extracted by GRASP, and the findings are consistent with the existing medical knowledge, indicating that GRASP can generate useful insights for relevant predictions.",
        "primary_area": "Application Domains",
        "author": "Chaohe Zhang; Xin Gao; Liantao Ma; Yasha Wang; Jiangtao Wang; Wen Tang",
        "authorids": "",
        "aff": "Key Laboratory of High Confidence Software Technologies, Ministry of Education, Beijing, China School of Electronics Engineering and Computer Science, Peking University, Beijing, China; Key Laboratory of High Confidence Software Technologies, Ministry of Education, Beijing, China School of Electronics Engineering and Computer Science, Peking University, Beijing, China; Key Laboratory of High Confidence Software Technologies, Ministry of Education, Beijing, China School of Electronics Engineering and Computer Science, Peking University, Beijing, China; Key Laboratory of High Confidence Software Technologies, Ministry of Education, Beijing, China National Engineering Research Center of Software Engineering, Peking University, Beijing, China; The Centre for Intelligent Healthcare, Coventry University, UK; Division of Nephrology, Peking University Third Hospital, Beijing, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16152/16152-13-19646-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00715-grasp-generic-framework-for-health-status-representation-learning-based-on-incorporating-knowledge-from-similar-patients/",
        "doi": "10.1609/aaai.v35i1.16152",
        "pdf_size": 1035084
    },
    {
        "id": "04402",
        "title": "GSNet: Learning Spatial-Temporal Correlations from Geographical and Semantic Aspects for Traffic Accident Risk Forecasting",
        "track": "main",
        "status": "Poster",
        "abstract": "Traffic accident forecasting is of great importance to urban public safety, emergency treatment, and construction planning. However, it is very challenging since traffic accidents are affected by multiple factors, and have multi-scale dependencies on both spatial and temporal dimensional features. Meanwhile, traffic accidents are rare events, which leads to the zero-inflated issue. Existing traffic accident forecasting methods cannot deal with all above problems simultaneously. In this paper, we propose a novel model, named GSNet, to learn the spatial-temporal correlations from geographical and semantic aspects for traffic accident risk forecasting. In the model, a Spatial-Temporal Geographical Module is designed to capture the geographical spatial-temporal correlations among regions, while a Spatial-Temporal Semantic Module is proposed to model the semantic spatial-temporal correlations among regions. In addition, a weighted loss function is designed to solve the zero-inflated issue. Extensive experiments on two real-world datasets demonstrate the superiority of GSNet against the state-of-the-art baseline methods.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Beibei Wang; Youfang Lin; Shengnan Guo; Huaiyu Wan",
        "authorids": "",
        "aff": "School of Computer and Information Technology, Beijing Jiaotong University, Beijing, China Beijing Key Laboratory of Traffic Data Analysis and Mining, Beijing, China; School of Computer and Information Technology, Beijing Jiaotong University, Beijing, China Beijing Key Laboratory of Traffic Data Analysis and Mining, Beijing, China CAAC Key Laboratory of Intelligent Passenger Service of Civil Aviation, Beijing, China Key Laboratory of Transport Industry of Big Data Appalication Technologies for Comprehensive Transport, Beijing, China; School of Computer and Information Technology, Beijing Jiaotong University, Beijing, China Beijing Key Laboratory of Traffic Data Analysis and Mining, Beijing, China Key Laboratory of Transport Industry of Big Data Appalication Technologies for Comprehensive Transport, Beijing, China; School of Computer and Information Technology, Beijing Jiaotong University, Beijing, China Beijing Key Laboratory of Traffic Data Analysis and Mining, Beijing, China CAAC Key Laboratory of Intelligent Passenger Service of Civil Aviation, Beijing, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16566/16566-13-20060-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04402-gsnet-learning-spatial-temporal-correlations-from-geographical-and-semantic-aspects-for-traffic-accident-risk-forecasting/",
        "doi": "10.1609/aaai.v35i5.16566",
        "pdf_size": 585581
    },
    {
        "id": "00531",
        "title": "GTA: Graph Truncated Attention for Retrosynthesis",
        "track": "main",
        "status": "Poster",
        "abstract": "Retrosynthesis is the task of predicting reactant molecules from a given product molecule and is, important in organic chemistry because the identification of a synthetic path is as demanding as the discovery of new chemical compounds. Recently, the retrosynthesis task has been solved automatically without human expertise using powerful deep learning models. Recent deep models are primarily based on seq2seq or graph neural networks depending on the function of molecular representation, sequence, or graph. Current state-of-the-art models represent a molecule as a graph, but they require joint training with auxiliary prediction tasks, such as the most probable reaction template or reaction center prediction. Furthermore, they require additional labels by experienced chemists, thereby incurring additional cost. Herein, we propose a novel template-free model, i.e., Graph Truncated Attention (GTA), which leverages both sequence and graph representations by inserting graphical information into a seq2seq model. The proposed GTA model masks the self-attention layer using the adjacency matrix of product molecule in the encoder and applies a new loss using atom mapping acquired from an automated algorithm to the cross-attention layer in the decoder. Our model achieves new state-of-the-art records, i.e., exact match top-1 and top-10 accuracies of 51.1% and 81.6% on the USPTO-50k benchmark dataset, respectively, and 46.0% and 70.0% on the USPTO-full dataset, respectively, both without any reaction class information. The GTA model surpasses prior graph-based template-free models by 2% and 7% in terms of the top-1 and top-10 accuracies on the USPTO-50k dataset, respectively, and by over 6% for both the top-1 and top-10 accuracies on the USPTO-full dataset.",
        "primary_area": "Application Domains",
        "author": "Seung-Woo Seo; You Young Song; June Yong Yang; Seohui Bae; Hankook Lee; Jinwoo Shin; Sung Ju Hwang; Eunho Yang",
        "authorids": "",
        "aff": "Samsung Advanced Institute of Technology; Samsung Advanced Institute of Technology; Korea Advanced Institute of Science and Technology; Korea Advanced Institute of Science and Technology; Korea Advanced Institute of Science and Technology; Korea Advanced Institute of Science and Technology; Korea Advanced Institute of Science and Technology; Korea Advanced Institute of Science and Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16131/16131-13-19625-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00531-gta-graph-truncated-attention-for-retrosynthesis/",
        "doi": "10.1609/aaai.v35i1.16131",
        "pdf_size": 368358
    },
    {
        "id": "04864",
        "title": "Gaining Insight into SARS-CoV-2 Infection and COVID-19 Severity Using Self-supervised Edge Features and Graph Neural Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "A molecular and cellular understanding of how SARS-CoV-2 variably infects and causes severe COVID-19 remains a bottleneck in developing interventions to end the pandemic. We sought to use deep learning (DL) to study the biology of SARS-CoV-2 infection and COVID-19 severity by identifying transcriptomic patterns and cell types associated with SARS-CoV-2 infection and COVID-19 severity. To do this, we developed a new approach to generating self-supervised edge features. We propose a model that builds on Graph Attention Networks (GAT), creates edge features using self-supervised learning, and ingests these edge features via a Set Transformer. This model achieves significant improvements in predicting the disease state of individual cells, given their transcriptome. We apply our model to single-cell RNA sequencing datasets of SARS-CoV-2 infected lung organoids and bronchoalveolar lavage fluid samples of patients with COVID-19, achieving state-of-the-art performance on both datasets with our model. We then borrow from the field of explainable AI (XAI) to identify the features (genes) and cell types that discriminate bystander vs. infected cells across time and moderate vs. severe COVID-19 disease. To the best of our knowledge, this represents the first application of DL to identifying the molecular and cellular determinants of SARS-CoV-2 infection and COVID-19 severity using single-cell omics data.",
        "primary_area": "AI Responses to the COVID-19 Pandemic",
        "author": "Arijit Sehanobish; Neal Ravindra; David van Dijk",
        "authorids": "",
        "aff": "Yale University; Yale University; Yale University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16619/16619-13-20113-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04864-gaining-insight-into-sars-cov-2-infection-and-covid-19-severity-using-self-supervised-edge-features-and-graph-neural-networks/",
        "doi": "10.1609/aaai.v35i6.16619",
        "pdf_size": 2232219
    },
    {
        "id": "09046",
        "title": "Game of Gradients: Mitigating Irrelevant Clients in Federated Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "The paradigm of Federated learning (FL) deals with multiple clients participating in collaborative training of a machine learning model under the orchestration of a central server. In this setup, each client\u2019s data is private to itself and is not transferable to other clients or the server. Though FL paradigm has received significant interest recently from the research community, the problem of selecting the relevant clients w.r.t. the central server's learning objective is under-explored. We refer to these problems as Federated Relevant Client Selection (FRCS). Because the server doesn't have explicit control over the nature of data possessed by each client, the problem of selecting relevant clients is significantly complex in FL settings. In this paper, we resolve important and related FRCS problems viz., selecting clients with relevant data, detecting clients that possess data relevant to a particular target label, and rectifying corrupted data samples of individual clients. We follow a principled approach to address the above FRCS problems and develop a new federated learning method using the Shapley value concept from cooperative game theory. Towards this end, we propose a cooperative game involving the gradients shared by the clients. Using this game, we compute Shapley values of clients and then present Shapley value based Federated Averaging (S-FedAvg) algorithm that empowers the server to select relevant clients with high probability. S-FedAvg turns out to be critical in designing specific algorithms to address the FRCS problems. We finally conduct a thorough empirical analysis on image classification and speech recognition tasks to show the superior performance of S-FedAvg than the baselines in the context of supervised federated learning settings.",
        "primary_area": "Machine Learning III",
        "author": "Lokesh Nagalapatti; Ramasuri Narayanam",
        "authorids": "",
        "aff": "IIT Bombay; IBM Research - India",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17093/17093-13-20587-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09046-game-of-gradients-mitigating-irrelevant-clients-in-federated-learning/",
        "doi": "10.1609/aaai.v35i10.17093",
        "pdf_size": 2494073
    },
    {
        "id": "10015",
        "title": "Gated Linear Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a new family of backpropagation-free neural architectures, Gated Linear Networks (GLNs). What distinguishes GLNs from contemporary neural networks is the distributed and local nature of their credit assignment mechanism; each neuron directly predicts the target, forgoing the ability to learn feature representations in favor of rapid online learning. Individual neurons are able to model nonlinear functions via the use of data-dependent gating in conjunction with online convex optimization. We show that this architecture gives rise to universal learning capabilities in the limit, with effective model capacity increasing as a function of network size in a manner comparable with deep ReLU networks. Furthermore, we demonstrate that the GLN learning mechanism possesses extraordinary resilience to catastrophic forgetting, performing almost on par to an MLP with dropout and Elastic Weight Consolidation on standard benchmarks.",
        "primary_area": "Machine Learning IV",
        "author": "Joel Veness; Tor Lattimore; David Budden; Avishkar Bhoopchand; Christopher Mattern; Agnieszka Grabska-Barwinska; Eren Sezener; Jianan Wang; Peter Toth; Simon Schmitt; Marcus Hutter",
        "authorids": "",
        "aff": "Deepmind; DeepMind; DeepMind; DeepMind; DeepMind; DeepMind; DeepMind; DeepMind; DeepMind; DeepMind; DeepMind",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17202/17202-13-20696-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10015-gated-linear-networks/",
        "doi": "10.1609/aaai.v35i11.17202",
        "pdf_size": 2117841
    },
    {
        "id": "07762",
        "title": "Gaussian Process Priors for View-Aware Inference",
        "track": "main",
        "status": "Poster",
        "abstract": "While frame-independent predictions with deep neural networks have become the prominent solutions to many computer vision tasks, the potential benefits of utilizing correlations between frames have received less attention. Even though probabilistic machine learning provides the ability to encode correlation as prior knowledge for inference, there is a tangible gap between the theory and practice of applying probabilistic methods to modern vision problems. For this, we derive a principled framework to combine information coupling between camera poses (translation and orientation) with deep models. We proposed a novel view kernel that generalizes the standard periodic kernel in SO(3). We show how this soft-prior knowledge can aid several pose-related vision tasks like novel view synthesis and predict arbitrary points in the latent space of generative models, pointing towards a range of new applications for inter-frame reasoning.",
        "primary_area": "Machine Learning II",
        "author": "Yuxin Hou; Ari Heljakka; Arno Solin",
        "authorids": "",
        "aff": "Aalto University; Aalto University GenMind Ltd.; Aalto University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16948/16948-13-20442-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07762-gaussian-process-priors-for-view-aware-inference/",
        "doi": "10.1609/aaai.v35i9.16948",
        "pdf_size": 2273963
    },
    {
        "id": "04393",
        "title": "GaussianPath:A Bayesian Multi-Hop Reasoning Framework for Knowledge Graph Reasoning",
        "track": "main",
        "status": "Poster",
        "abstract": "Recently, multi-hop reasoning over incomplete Knowledge Graphs (KGs) has attracted wide attention due to its desirable interpretability for downstream tasks, such as question answer and knowledge graph completion. Multi-Hop reasoning is a typical sequential decision problem, which can be formulated as a Markov decision process (MDP). Subsequently, some reinforcement learning (RL) based approaches are proposed and proven effective to train an agent for reasoning paths sequentially until reaching the target answer. However, these approaches assume that an entity/relation representation follows a one-point distribution. In fact, different entities and relations may contain different certainties. On the other hand, since REINFORCE used for updating the policy in these approaches is a biased policy gradients method, the agent is prone to be stuck in high reward paths rather than broad reasoning paths, which leads to premature and suboptimal exploitation. In this paper, we consider a Bayesian reinforcement learning paradigm to harness uncertainty into multi-hop reasoning. By incorporating uncertainty into the representation layer, the agent trained by RL has uncertainty in a region of the state space then it should be more efficient in exploring unknown or less known part of the KG. In our approach, we build a Bayesian Q-learning architecture as a state-action value function for estimating the expected long-term reward. As initialized by Gaussian prior or pre-trained prior distribution, the representation layer drives uncertainty that allows regularizing the training. We conducted extensive experiments on multiple KGs. Experimental results show a superior performance than other baselines, especially significant improvements on the automated extracted KG.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Guojia Wan; Bo Du",
        "authorids": "",
        "aff": "Wuhan University; Wuhan University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16565/16565-13-20059-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04393-gaussianpatha-bayesian-multi-hop-reasoning-framework-for-knowledge-graph-reasoning/",
        "doi": "10.1609/aaai.v35i5.16565",
        "pdf_size": 939183
    },
    {
        "id": "10263",
        "title": "Gene Regulatory Network Inference as Relaxed Graph Matching",
        "track": "main",
        "status": "Poster",
        "abstract": "Bipartite network inference is a ubiquitous problem across disciplines. One important example in the field molecular biology is gene regulatory network inference. Gene regulatory networks are an instrumental tool aiding in the discovery of the molecular mechanisms driving diverse diseases, including cancer. However, only noisy observations of the projections of these regulatory networks are typically assayed. In an effort to better estimate regulatory networks from their noisy projections, we formulate a non-convex but analytically tractable optimization problem called OTTER. This problem can be interpreted as relaxed graph matching between the two projections of the bipartite network. OTTER's solutions can be derived explicitly and inspire a spectral algorithm, for which we provide network recovery guarantees. We also provide an alternative approach based on gradient descent that is more robust to noise compared to the spectral algorithm. Interestingly, this gradient descent approach resembles the message passing equations of an established gene regulatory network inference method, PANDA. Using three cancer-related data sets, we show that OTTER outperforms state-of-the-art inference methods in predicting transcription factor binding to gene regulatory regions. To encourage new graph matching applications to this problem, we have made all networks and validation data publicly available.",
        "primary_area": "Machine Learning IV",
        "author": "Deborah Weighill; Marouen Ben Guebila; Camila Lopes-Ramos; Kimberly Glass; John Quackenbush; John Platig; Rebekka Burkholz",
        "authorids": "",
        "aff": "Harvard T.H. Chan School of Public Health, Boston, MA 02115; Harvard T.H. Chan School of Public Health, Boston, MA 02115; Harvard T.H. Chan School of Public Health, Boston, MA 02115; Harvard T.H. Chan School of Public Health, Boston, MA 02115 Channing Division of Network Medicine, Brigham and Women\u2019s Hospital Harvard Medical School, Boston, MA 02115; Harvard T.H. Chan School of Public Health, Boston, MA 02115 Channing Division of Network Medicine, Brigham and Women\u2019s Hospital Harvard Medical School, Boston, MA 02115; Channing Division of Network Medicine, Brigham and Women\u2019s Hospital Harvard Medical School, Boston, MA 02115; Harvard T.H. Chan School of Public Health, Boston, MA 02115",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17230/17230-13-20724-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10263-gene-regulatory-network-inference-as-relaxed-graph-matching/",
        "doi": "10.1609/aaai.v35i11.17230",
        "pdf_size": 886725
    },
    {
        "id": "00099",
        "title": "Gene Regulatory Network Inference using 3D Convolutional Neural Network",
        "track": "main",
        "status": "Poster",
        "abstract": "Gene regulatory networks (GRNs) consist of gene regulations between transcription factors (TFs) and their target genes. Single-cell RNA sequencing (scRNA-seq) brings both opportunities and challenges to the inference of GRNs. On the one hand, scRNA-seq data reveals statistic information of gene expressions at the single-cell resolution, which is conducive to the construction of GRNs; on the other hand, noises and dropouts pose great difficulties on the analysis of scRNA-seq data, causing low prediction accuracy by traditional methods. In this paper, we propose 3D Co-Expression Matrix Analysis (3DCEMA), which predicts regulatory relationships by classifying 3D co-expression matrices of gene triples using a 3D convolutional neural network. We found that by introducing a third gene as a comparison factor, our method can avoid the disturbance of noises and dropouts, and significantly increase the prediction accuracy of regulations between gene pairs. Compared with other existing GRN inference algorithms on both in-silico datasets and scRNA-Seq datasets, our algorithm based on deep learning shows higher stability and accuracy in the task of GRN inference.",
        "primary_area": "Application Domains",
        "author": "Yue Fan; Xiuli Ma",
        "authorids": "",
        "aff": "Peking University; Peking University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16082/16082-13-19576-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00099-gene-regulatory-network-inference-using-3d-convolutional-neural-network/",
        "doi": "10.1609/aaai.v35i1.16082",
        "pdf_size": 722313
    },
    {
        "id": "11764",
        "title": "General Policies, Representations, and Planning Width",
        "track": "main",
        "status": "Poster",
        "abstract": "It has been observed that in many of the benchmark planning domains, atomic goals can be reached with a simple polynomial exploration procedure, called IW, that runs in time exponential in the problem width. Such problems have indeed a bounded width: a width that does not grow with the number of problem variables and is often no greater than two. Yet, while the notion of width has become part of the state- of-the-art planning algorithms like BFWS, there is still no good explanation for why so many benchmark domains have bounded width. In this work, we address this question by relating bounded width and serialized width to ideas of generalized planning, where general policies aim to solve multiple instances of a planning problem all at once. We show that bounded width is a property of planning domains that admit optimal general policies in terms of features that are explicitly or implicitly represented in the domain encoding. The results are extended to the larger class of domains with bounded serialized width where the general policies do not have to be optimal. The study leads also to a new simple, meaningful, and expressive language for specifying domain serializations in the form of policy sketches which can be used for encoding domain control knowledge by hand or for learning it from traces. The use of sketches and the meaning of the theoretical results are all illustrated through a number of examples.",
        "primary_area": "Planning, Routing, and Scheduling",
        "author": "Blai Bonet; Hector Geffner",
        "authorids": "",
        "aff": "Universitat Pompeu Fabra; ICREA Universitat Pompeu Fabra",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17398/17398-13-20892-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11764-general-policies-representations-and-planning-width/",
        "doi": "10.1609/aaai.v35i13.17398",
        "pdf_size": 243579
    },
    {
        "id": "02889",
        "title": "Generalising without Forgetting for Lifelong Person Re-Identification",
        "track": "main",
        "status": "Poster",
        "abstract": "Existing person re-identification (Re-ID) methods mostly prepare all training data in advance, while real-world Re-ID data are inherently captured over time or from different locations, which requires a model to be incrementally generalised from sequential learning of piecemeal new data without forgetting what is already learned. In this work, we call this lifelong person Re-ID, characterised by solving a problem of unseen class identification subject to continuous new domain generalisation and adaptation with class imbalanced learning. We formulate a new Generalising without Forgetting method (GwFReID) for lifelong Re-ID and design a comprehensive learning objective that accounts for classification coherence, distribution coherence and representation coherence in a unified framework. This design helps to simultaneously learn new information, distil old knowledge and solve class imbalance, which enables GwFReID to incrementally improve model generalisation without catastrophic forgetting of what is already learned. Extensive experiments on eight Re-ID benchmarks, CIFAR-100 and ImageNet show the superiority of GwFReID over the state-of-the-art methods.",
        "primary_area": "Computer Vision III",
        "author": "Guile Wu; Shaogang Gong",
        "authorids": "",
        "aff": "Queen Mary University of London; Queen Mary University of London",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16395/16395-13-19889-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02889-generalising-without-forgetting-for-lifelong-person-re-identification/",
        "doi": "10.1609/aaai.v35i4.16395",
        "pdf_size": 284380
    },
    {
        "id": "01132",
        "title": "Generalizable Representation Learning for Mixture Domain Face Anti-Spoofing",
        "track": "main",
        "status": "Poster",
        "abstract": "Face anti-spoofing approach based on domain generalization (DG) has drawn growing attention due to its robustness for unseen scenarios. Existing DG methods assume that the domain label is known. However, in real-world applications, the collected dataset always contains mixture domains, where the domain label is unknown. In this case, most of existing methods may not work. Further, even if we can obtain the domain label as existing methods, we think this is just a sub-optimal partition. To overcome the limitation, we propose domain dynamic adjustment meta-learning (D$^2$AM) without using domain labels, which iteratively divides mixture domains via discriminative domain representation and trains a generalizable face anti-spoofing with meta-learning. Specifically, we design a domain feature based on Instance Normalization (IN)  and propose a domain representation learning module (DRLM) to extract discriminative domain features for clustering. Moreover, to reduce the side effect of outliers on clustering performance, we additionally utilize maximum mean discrepancy (MMD) to align the distribution of  sample features to a prior distribution, which improves the reliability of clustering. Extensive experiments show that the proposed method outperforms conventional DG-based face anti-spoofing methods, including those utilizing domain labels. Furthermore, we enhance the interpretability through visualization.",
        "primary_area": "Computer Vision I",
        "author": "Zhihong Chen; Taiping Yao; Kekai Sheng; Shouhong Ding; Ying Tai; Jilin Li; Feiyue Huang; Xinyu Jin",
        "authorids": "",
        "aff": "Zhejiang University Tencent, YouTu; Tencent, YouTu; Tencent, YouTu; Tencent, YouTu; Tencent, YouTu; Tencent, YouTu; Tencent, YouTu; Zhejiang University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16199/16199-13-19693-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01132-generalizable-representation-learning-for-mixture-domain-face-anti-spoofing/",
        "doi": "10.1609/aaai.v35i2.16199",
        "pdf_size": 1300088
    },
    {
        "id": "12225",
        "title": "Generalization in Portfolio-Based Algorithm Selection",
        "track": "main",
        "status": "Poster",
        "abstract": "Portfolio-based algorithm selection has seen tremendous practical success over the past two decades. This algorithm configuration procedure works by first selecting a portfolio of diverse algorithm parameter settings, and then, on a given problem instance, using an algorithm selector to choose a parameter setting from the portfolio with strong predicted performance. Oftentimes, both the portfolio and the algorithm selector are chosen using a training set of typical problem instances from the application domain at hand. In this paper, we provide the first provable guarantees for portfolio-based algorithm selection. We analyze how large the training set should be to ensure that the resulting algorithm selector's average performance over the training set is close to its future (expected) performance. This involves analyzing three key reasons why these two quantities may diverge: 1) the learning-theoretic complexity of the algorithm selector, 2) the size of the portfolio, and 3) the learning-theoretic complexity of the algorithm's performance as a function of its parameters. We introduce an end-to-end learning-theoretic analysis of the portfolio construction and algorithm selection together. We prove that if the portfolio is large, overfitting is inevitable, even with an extremely simple algorithm selector. With experiments, we illustrate a tradeoff exposed by our theoretical analysis: as we increase the portfolio size, we can hope to include a well-suited parameter setting for every possible problem instance, but it becomes impossible to avoid overfitting.",
        "primary_area": "Search and Optimization",
        "author": "Maria-Florina Balcan; Tuomas Sandholm; Ellen Vitercik",
        "authorids": "",
        "aff": "Carnegie Mellon University; Carnegie Mellon University Strategy Robot, Inc. Optimized Markets, Inc. Strategic Machine, Inc.; Carnegie Mellon University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17451/17451-13-20945-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12225-generalization-in-portfolio-based-algorithm-selection/",
        "doi": "10.1609/aaai.v35i14.17451",
        "pdf_size": 612668
    },
    {
        "id": "07474",
        "title": "Generalize a Small Pre-trained Model to Arbitrarily Large TSP Instances",
        "track": "main",
        "status": "Poster",
        "abstract": "For the traveling salesman problem (TSP), the existing supervised learning based algorithms suffer seriously from the lack of generalization ability. To overcome this drawback, this paper tries to train (in supervised manner) a small-scale model, which could be repetitively used to build heat maps for TSP instances of arbitrarily large size, based on a series of techniques such as graph sampling, graph converting and heat maps merging. Furthermore, the heat maps are fed into a reinforcement learning approach (Monte Carlo tree search), to guide the search of high-quality solutions. Experimental results based on a large number of instances (with up to 10,000 vertices) show that, this new approach clearly outperforms the existing machine learning based TSP algorithms, and significantly improves the generalization ability of the trained model.",
        "primary_area": "Machine Learning I",
        "author": "Zhang-Hua Fu; Kai-Bin Qiu; Hongyuan Zha",
        "authorids": "",
        "aff": "Shenzhen Institute of Artificial Intelligence and Robotics for Society The Chinese University of Hong Kong, Shenzhen; The Chinese University of Hong Kong, Shenzhen; Shenzhen Institute of Artificial Intelligence and Robotics for Society The Chinese University of Hong Kong, Shenzhen",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16916/16916-13-20410-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07474-generalize-a-small-pre-trained-model-to-arbitrarily-large-tsp-instances/",
        "doi": "10.1609/aaai.v35i8.16916",
        "pdf_size": 561510
    },
    {
        "id": "07185",
        "title": "Generalized Adversarially Learned Inference",
        "track": "main",
        "status": "Poster",
        "abstract": "Allowing effective inference of latent vectors while training GANs can greatly increase their applicability in various downstream tasks. Recent approaches, such as ALI and BiGAN frameworks, develop methods of inference of latent variables in GANs by adversarially training an image generator along with an encoder to match two joint distributions of image and latent vector pairs. We generalize these approaches to incorporate multiple layers of feedback on reconstructions, self-supervision, and other forms of supervision based on prior or learned knowledge about the desired solutions. We achieve this by modifying the discriminator's objective to correctly identify more than two joint distributions of tuples of an arbitrary number of random variables consisting of images, latent vectors, and other variables generated through auxiliary tasks, such as reconstruction and inpainting or as outputs of suitable pre-trained models. We design a non-saturating maximization objective for the generator-encoder pair and prove that the resulting adversarial game corresponds to a global optimum that simultaneously matches all the distributions. Within our proposed framework, we introduce a novel set of techniques for providing self-supervised feedback to the model based on properties, such as patch-level correspondence and cycle consistency of reconstructions. Through comprehensive experiments, we demonstrate the efficacy, scalability, and flexibility of the proposed approach for a variety of tasks. The appendix of the paper can be found at the following link: https://drive.google.com/file/d/1i99e682CqYWMEDXlnqkqrctGLVA9viiz/view?usp=sharing",
        "primary_area": "Machine Learning I",
        "author": "Yatin Dandi; Homanga Bharadhwaj; Abhishek Kumar; Piyush Rai",
        "authorids": "",
        "aff": "IIT Kanpur; University of Toronto, Vector Institute; Google Brain; IIT Kanpur",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16883/16883-13-20377-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07185-generalized-adversarially-learned-inference/",
        "doi": "10.1609/aaai.v35i8.16883",
        "pdf_size": 1542594
    },
    {
        "id": "04679",
        "title": "Generalized Relation Learning with Semantic Correlation Awareness for Link Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "Developing link prediction models to automatically complete knowledge graphs has recently been the focus of significant research interest. The current methods for the link prediction task have two natural problems: 1) the relation distributions in KGs are usually unbalanced, and 2) there are many unseen relations that occur in practical situations. These two problems limit the training effectiveness and practical applications of the existing link prediction models. We advocate a holistic understanding of KGs and we propose in this work a unified Generalized Relation Learning framework GRL to address the above two problems, which can be plugged into existing link prediction models. GRL conducts a generalized relation learning, which is aware of semantic correlations between relations that serve as a bridge to connect semantically similar relations. After training with GRL, the closeness of semantically similar relations in vector space and the discrimination of dissimilar relations are improved. We perform comprehensive experiments on six benchmarks to demonstrate the superior capability of GRL in the link prediction task. In particular, GRL is found to enhance the existing link prediction models making them insensitive to unbalanced relation distributions and capable of learning unseen relations.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Yao Zhang; Xu Zhang; Jun Wang; Hongru Liang; Wenqiang Lei; Zhe Sun; Adam Jatowt; Zhenglu Yang",
        "authorids": "",
        "aff": "Nankai university; Nankai university; Ludong University; Nankai University; National University of Singapore; RIKEN; University of Innsbruck; Nankai University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16598/16598-13-20092-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04679-generalized-relation-learning-with-semantic-correlation-awareness-for-link-prediction/",
        "doi": "10.1609/aaai.v35i5.16598",
        "pdf_size": 864303
    },
    {
        "id": "01966",
        "title": "Generalized Zero-Shot Learning via Disentangled Representation",
        "track": "main",
        "status": "Poster",
        "abstract": "Zero-Shot Learning (ZSL) aims to recognize images belonging to unseen classes that are unavailable in the training process, while Generalized Zero-Shot Learning (GZSL) is a more realistic variant that both seen and unseen classes appear during testing. Most GZSL approaches achieve knowledge transfer based on the features of samples that inevitably contain information irrelevant to recognition, bringing negative influence for the performance. In this work, we propose a novel method, dubbed Disentangled-VAE, which aims to disentangle category-distilling factors and category-dispersing factors from visual as well as semantic features, respectively. In addition, a batch re-combining strategy on latent features is introduced to guide the disentanglement, encouraging the distilling latent features to be more discriminative for recognition. Extensive experiments demonstrate that our method outperforms the state-of-the-art approaches on four challenging benchmark datasets",
        "primary_area": "Computer Vision II",
        "author": "Xiangyu Li; Zhe Xu; Kun Wei; Cheng Deng",
        "authorids": "",
        "aff": "Xidian University; Xidian University; Xidian University; Xidian University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16292/16292-13-19786-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01966-generalized-zero-shot-learning-via-disentangled-representation/",
        "doi": "10.1609/aaai.v35i3.16292",
        "pdf_size": 740744
    },
    {
        "id": "13516",
        "title": "Generate Your Counterfactuals: Towards Controlled Counterfactual Generation for Text",
        "track": "main",
        "status": "Poster",
        "abstract": "Machine Learning has seen tremendous growth recently, which has led to a larger adaptation of ML systems for educational assessments, credit risk, healthcare, employment, criminal justice, to name a few. The trustworthiness of ML and NLP systems is a crucial aspect and requires a guarantee that the decisions they make are fair and robust. Aligned with this, we propose a novel framework GYC, to generate a set of exhaustive counterfactual text, which are crucial for testing these ML systems. Our main contributions include a) We introduce GYC, a framework to generate counterfactual samples such that the generation is plausible, diverse, goal-oriented, and effective, b) We generate counterfactual samples, that can direct the generation towards a corresponding texttt{condition} such as named-entity tag, semantic role label, or sentiment. Our experimental results on various domains show that GYC generates counterfactual text samples exhibiting the above four properties. GYC generates counterfactuals that can act as test cases to evaluate a model and any text debiasing algorithm.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Nishtha Madaan; Inkit Padhi; Naveen Panwar; Diptikalyan Saha",
        "authorids": "",
        "aff": "IBM Research AI; IBM Research AI; IBM Research AI; IBM Research AI",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17594/17594-13-21088-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13516-generate-your-counterfactuals-towards-controlled-counterfactual-generation-for-text/",
        "doi": "10.1609/aaai.v35i15.17594",
        "pdf_size": 362203
    },
    {
        "id": "13443",
        "title": "Generating CCG Categories",
        "track": "main",
        "status": "Poster",
        "abstract": "Previous CCG supertaggers usually predict categories using multi-class classification. Despite their simplicity, internal structures of categories are usually ignored. The rich semantics inside these structures may help us to better handle relations among categories and bring more robustness into existing supertaggers. In this work, we propose to generate categories rather than classify them: each category is decomposed into a sequence of smaller atomic tags, and the tagger aims to generate the correct sequence. We show that with this finer view on categories, annotations of different categories could be shared and interactions with sentence contexts could be enhanced. The proposed category generator is able to achieve state-of-the-art tagging (95.5% accuracy) and parsing (89.8% labeled F1) performances on the standard CCGBank . Further-more, its performances on infrequent (even unseen) categories, out-of-domain texts and low resource language give promising results on introducing generation models to the general CCG analyses.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Yufang Liu; Tao Ji; Yuanbin Wu; Man Lan",
        "authorids": "",
        "aff": "East China Normal University; East China Normal University; East China Normal University; East China Normal University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17586/17586-13-21080-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13443-generating-ccg-categories/",
        "doi": "10.1609/aaai.v35i15.17586",
        "pdf_size": 231391
    },
    {
        "id": "13988",
        "title": "Generating Diversified Comments via Reader-Aware Topic Modeling and Saliency Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Automatic comment generation is a special and challenging task to verify the model ability on news content comprehension and language generation. Comments not only convey salient and interesting information in news articles, but also imply various and different reader characteristics which we treat as the essential clues for diversity. However, most of the comment generation approaches only focus on saliency information extraction, while the reader-aware factors implied by comments are neglected. To address this issue, we propose a unified reader-aware topic modeling and saliency information detection framework to enhance the quality of generated comments. For reader-aware topic modeling, we design a variational generative clustering algorithm for latent semantic learning and topic mining from reader comments. For saliency information detection, we introduce Bernoulli distribution estimating on news content to select saliency information. The obtained topic representations as well as the selected saliency information are incorporated into the decoder to generate diversified and informative comments. Experimental results on three datasets show that our framework outperforms existing baseline methods in terms of both automatic metrics and human evaluation. The potential ethical issues are also discussed in detail.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Wei Wang; Piji Li; Hai-Tao Zheng",
        "authorids": "",
        "aff": "Tsinghua University; Tencent AI Lab; Tsinghua University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17647/17647-13-21141-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13988-generating-diversified-comments-via-reader-aware-topic-modeling-and-saliency-detection/",
        "doi": "10.1609/aaai.v35i16.17647",
        "pdf_size": 853601
    },
    {
        "id": "13525",
        "title": "Generating Natural Language Attacks in a Hard Label Black Box Setting",
        "track": "main",
        "status": "Poster",
        "abstract": "We study an important and challenging task of attacking natural language processing models in a hard label black box setting. We propose a decision-based attack strategy that crafts high quality adversarial examples on text classification and entailment tasks. Our proposed attack strategy leverages population-based optimization algorithm to craft plausible and semantically similar adversarial examples by observing only the top label predicted by the target model. At each iteration, the optimization procedure allow word replacements that maximizes the overall semantic similarity between the original and the adversarial text. Further, our approach does not rely on using substitute models or any kind of training data. We demonstrate the efficacy of our proposed approach through extensive experimentation and ablation studies on five state-of-the-art target models across seven benchmark datasets. In comparison to attacks proposed in prior literature, we are able to achieve a higher success rate with lower word perturbation percentage that too in a highly restricted setting.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Rishabh Maheshwary; Saket Maheshwary; Vikram Pudi",
        "authorids": "",
        "aff": "Data Sciences and Analytics Center, Kohli Center on Intelligent Systems International Institute of Information Technology, Hyderabad, India; Data Sciences and Analytics Center, Kohli Center on Intelligent Systems International Institute of Information Technology, Hyderabad, India; Data Sciences and Analytics Center, Kohli Center on Intelligent Systems International Institute of Information Technology, Hyderabad, India",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17595/17595-13-21089-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13525-generating-natural-language-attacks-in-a-hard-label-black-box-setting/",
        "doi": "10.1609/aaai.v35i15.17595",
        "pdf_size": 938566
    },
    {
        "id": "06156",
        "title": "Generative Partial Visual-Tactile Fused Object Clustering",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual-tactile fused sensing for object clustering has achieved significant progresses recently, since the involvement of tactile modality can effectively improve clustering performance. However, the missing data (i.e., partial data) issues always happen due to occlusion and noises during the data collecting process. This issue is not well solved by most existing partial multi-view clustering methods for the heterogeneous modality challenge. Naively employing these methods would  inevitably induce a negative effect and further hurt the performance. To solve the mentioned challenges, we propose a Generative Partial Visual-Tactile Fused (i.e., GPVTF) framework for object clustering. More specifically, we first do partial visual and tactile features extraction from the partial visual and tactile data, respectively, and  encode the extracted features in modality-specific feature subspaces. A conditional cross-modal clustering generative adversarial network is then developed to synthesize one modality conditioning on the other modality, which can compensate missing samples and align the visual and tactile modalities naturally by adversarial learning. To the end, two pseudo-label based KL-divergence losses are employed to update the corresponding modality-specific encoders. Extensive comparative experiments on three public visual-tactile datasets prove the effectiveness of our method.",
        "primary_area": "Intelligent Robots",
        "author": "Tao Zhang; Yang Cong; Gan Sun; Jiahua Dong; Yuyang Liu; Zhengming Ding",
        "authorids": "",
        "aff": "State Key Laboratory of Robotics, Shenyang Institute of Automation, Chinese Academy of Sciences Institutes for Robotics and Intelligent Manufacturing Chinese Academy of Sciences University of Chinese Academy of Sciences; State Key Laboratory of Robotics, Shenyang Institute of Automation, Chinese Academy of Sciences; State Key Laboratory of Robotics, Shenyang Institute of Automation, Chinese Academy of Sciences; State Key Laboratory of Robotics, Shenyang Institute of Automation, Chinese Academy of Sciences Institutes for Robotics and Intelligent Manufacturing Chinese Academy of Sciences University of Chinese Academy of Sciences; State Key Laboratory of Robotics, Shenyang Institute of Automation, Chinese Academy of Sciences Institutes for Robotics and Intelligent Manufacturing Chinese Academy of Sciences University of Chinese Academy of Sciences; Department of Computer Science, Tulane University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16766/16766-13-20260-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06156-generative-partial-visual-tactile-fused-object-clustering/",
        "doi": "10.1609/aaai.v35i7.16766",
        "pdf_size": 4421731
    },
    {
        "id": "08983",
        "title": "Generative Semi-supervised Learning for Multivariate Time Series Imputation",
        "track": "main",
        "status": "Poster",
        "abstract": "The missing values, widely existed in multivariate time series data, hinder the effective data analysis. Existing time series imputation methods do not make full use of the label information in real-life time series data. In this paper, we propose a novel semi-supervised generative adversarial network model, named SSGAN, for missing value imputation in multivariate time series data. It consists of three players, i.e., a generator, a discriminator, and a classifier. The classifier predicts labels of time series data, and thus it drives the generator to estimate the missing values (or components), conditioned on observed components and data labels at the same time. We introduce a temporal reminder matrix to help the discriminator better distinguish the observed components from the imputed ones. Moreover, we theoretically prove that, SSGAN using the temporal reminder matrix and the classifier does learn to estimate missing values converging to the true data distribution when the Nash equilibrium is achieved. Extensive experiments on three public real-world datasets demonstrate that, SSGAN yields a more than 15% gain in performance, compared with the state-of-the-art methods.",
        "primary_area": "Machine Learning III",
        "author": "Xiaoye Miao; Yangyang Wu; Jun Wang; Yunjun Gao; Xudong Mao; Jianwei Yin",
        "authorids": "",
        "aff": "Zhejiang University; Zhejiang University; The Hong Kong University of Science and Technology; Zhejiang University; Xiamen University; Zhejiang University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17086/17086-13-20580-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08983-generative-semi-supervised-learning-for-multivariate-time-series-imputation/",
        "doi": "10.1609/aaai.v35i10.17086",
        "pdf_size": 351391
    },
    {
        "id": "02844",
        "title": "Geodesic-HOF: 3D Reconstruction Without Cutting Corners",
        "track": "main",
        "status": "Poster",
        "abstract": "Single-view 3D object reconstruction is a challenging fundamental problem in machine perception, largely due to the morphological diversity of objects in the natural world. In particular, high curvature regions are not always represented accurately by methods trained with common set-based loss functions such as Chamfer Distance, resulting in reconstructions short-circuiting the surface or \"cutting corners.\" To address this issue, we propose an approach to 3D reconstruction that embeds points on the surface of an object into a higher-dimensional space that captures both the original 3D surface as well as geodesic distances between points on the surface of the object. The precise specification of these additional \"lifted\" coordinates ultimately yields useful surface information without requiring excessive additional computation during either training or testing, in comparison with existing approaches. Our experiments show that taking advantage of these learned lifted coordinates yields better performance for estimating surface normals and generating surfaces than using point cloud reconstructions alone. Further, we find that this learned geodesic embedding space provides useful information for applications such as unsupervised object decomposition.",
        "primary_area": "Computer Vision III",
        "author": "Ziyun Wang; Eric A. Mitchell; Volkan Isler; Daniel D. Lee",
        "authorids": "",
        "aff": "Samsung AI Center; Samsung AI Center; Samsung AI Center; Samsung AI Center",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16390/16390-13-19884-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02844-geodesic-hof-3d-reconstruction-without-cutting-corners/",
        "doi": "10.1609/aaai.v35i4.16390",
        "pdf_size": 3288466
    },
    {
        "id": "08349",
        "title": "GoT: a Growing Tree Model for Clustering Ensemble",
        "track": "main",
        "status": "Poster",
        "abstract": "The clustering ensemble technique that integrates multiple clustering results can improve the accuracy and robustness of the final clustering. In many clustering ensemble algorithms, the co-association matrix (CA matrix), which reflects the frequency of any two samples being partitioned into the same cluster, plays an important role. However, generally, the CA matrix is highly sparse with low value density, which may limit the performance of an algorithm based on it. To handle these issues, in this paper, we propose a growing tree model (GoT). In this model, the CA matrix is firstly refined by the shortest path technique so that its sparsity will be mitigated. Then, a set of representative prototype examples is discovered. Finally, to handle the low value density of the CA matrix, the prototypes gradually connect to their neighborhood, which likes a set of trees growing up. The rationality of the discovered prototype examples is illustrated by theoretical analysis and experimental analysis. The working mechanism of the GoT is visually shown on synthetic data sets. Experimental analyses on eight UCI data sets and eight image data sets show that the GoT outperforms nine representative clustering ensemble algorithms.",
        "primary_area": "Machine Learning II",
        "author": "Feijiang Li; Yuhua Qian; Jieting Wang",
        "authorids": "",
        "aff": "Shanxi University; Shanxi University; Shanxi University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17015/17015-13-20509-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08349-got-a-growing-tree-model-for-clustering-ensemble/",
        "doi": "10.1609/aaai.v35i9.17015",
        "pdf_size": 756999
    },
    {
        "id": "05939",
        "title": "Goal Blending for Responsive Shared Autonomy in a Navigating Vehicle",
        "track": "main",
        "status": "Poster",
        "abstract": "Human-robot shared autonomy techniques for vehicle navigation hold promise for reducing a human driver\u2019s workload, ensuring safety, and improving navigation efficiency. However, because typical techniques achieve these improvements by effectively removing human control at critical moments, these approaches often exhibit poor responsiveness to human commands\u2014especially in cluttered environments. In this paper, we propose a novel goal-blending shared autonomy (GBSA) system, which aims to improve responsiveness in shared autonomy systems by blending human and robot input during the selection of local navigation goals as opposed to low-level motor (servo-level) commands. We validate the proposed approach by performing a human study involving an intelligent wheelchair and compare GBSA to a representative servo-level shared control system that uses a policy-blending approach. The results of both quantitative performance analysis and a subjective survey show that GBSA exhibits significantly better system responsiveness and induces higher user satisfaction than the existing approach.",
        "primary_area": "Humans and AI",
        "author": "Yu-Sian Jiang; Garrett Warnell; Peter Stone",
        "authorids": "",
        "aff": "The University of Texas at Austin; US Army Research Laboratory; The University of Texas at Austin Sony AI",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16742/16742-13-20236-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05939-goal-blending-for-responsive-shared-autonomy-in-a-navigating-vehicle/",
        "doi": "10.1609/aaai.v35i7.16742",
        "pdf_size": 876068
    },
    {
        "id": "11062",
        "title": "Going Deeper With Directly-Trained Larger Spiking Neural Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Spiking neural networks (SNNs) are promising in a bio-plausible coding for spatio-temporal information and event-driven signal processing, which is very suited for energy-efficient implementation in neuromorphic hardware. However, the unique working mode of SNNs makes them more difficult to train than traditional networks. Currently, there are two main routes to explore the training of deep SNNs with high performance. The first is to convert a pre-trained ANN model to its SNN version, which usually requires a long coding window for convergence and cannot exploit the spatio-temporal features during training for solving temporal tasks. The other is to directly train SNNs in the spatio-temporal domain. But due to the binary spike activity of the firing function and the problem of gradient vanishing or explosion, current methods are restricted to shallow architectures and thereby difficult in harnessing large-scale datasets (e.g. ImageNet). To this end, we propose a threshold-dependent batch normalization (tdBN) method based on the emerging spatio-temporal backpropagation, termed \u201cSTBP-tdBN\u201d, enabling direct training of a very deep SNN and the efficient implementation of its inference on neuromorphic hardware. With the proposed method and elaborated shortcut connection, we significantly extend directly-trained SNNs from a shallow structure (",
        "primary_area": "Machine Learning V",
        "author": "Hanle Zheng; Yujie Wu; Lei Deng; Yifan Hu; Guoqi Li",
        "authorids": "",
        "aff": "Center for Brain-Inspired Computing Research, Department of Precision Instrument, Tsinghua University, Beijing 100084, China; Center for Brain-Inspired Computing Research, Department of Precision Instrument, Tsinghua University, Beijing 100084, China; Center for Brain-Inspired Computing Research, Department of Precision Instrument, Tsinghua University, Beijing 100084, China Department of Electrical and Computer Engineering, University of California, Santa Barbara; Center for Brain-Inspired Computing Research, Department of Precision Instrument, Tsinghua University, Beijing 100084, China; Center for Brain-Inspired Computing Research, Department of Precision Instrument, Tsinghua University, Beijing 100084, China Beijing Innovation Center for Future Chip, Tsinghua University, Beijing 100084, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17320/17320-13-20814-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11062-going-deeper-with-directly-trained-larger-spiking-neural-networks/",
        "doi": "10.1609/aaai.v35i12.17320",
        "pdf_size": 3424861
    },
    {
        "id": "09843",
        "title": "Gradient Descent Averaging and Primal-dual Averaging for Strongly Convex Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "Averaging scheme has attracted extensive attention in deep learning as well as traditional machine learning. It achieves theoretically optimal convergence and also improves the empirical model performance. However, there is still a lack of sufficient convergence analysis for strongly convex optimization. Typically, the convergence about the last iterate of gradient descent methods, which is referred to as individual convergence, fails to attain its optimality due to the existence of logarithmic factor. In order to remove this factor, we first develop gradient descent averaging (GDA), which is a general projection-based dual averaging algorithm in the strongly convex setting. We further present primal-dual averaging for strongly convex cases (SC-PDA), where primal and dual averaging schemes are simultaneously utilized. We prove that GDA yields the optimal convergence rate in terms of output averaging, while SC-PDA derives the optimal individual convergence. Several experiments on SVMs and deep learning models validate the correctness of theoretical analysis and effectiveness of algorithms.",
        "primary_area": "Machine Learning IV",
        "author": "Wei Tao; Wei Li; Zhisong Pan; Qing Tao",
        "authorids": "",
        "aff": "Academy of Military Science Army Engineering University; Army Engineering University; Army Engineering University; Army Academy of Artillery and Air Defense Chinese Academy of Sciences",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17183/17183-13-20677-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09843-gradient-descent-averaging-and-primal-dual-averaging-for-strongly-convex-optimization/",
        "doi": "10.1609/aaai.v35i11.17183",
        "pdf_size": 3184884
    },
    {
        "id": "02665",
        "title": "Gradient Regularized Contrastive Learning for Continual Domain Adaptation",
        "track": "main",
        "status": "Poster",
        "abstract": "Human beings can quickly adapt to environmental changes by leveraging learning experience.  However, adapting deep neural networks to dynamic environments by machine learning algorithms remains a challenge. To better understand this issue, we study the problem of continual domain adaptation, where the model is presented with a labelled source domain and a sequence of unlabelled target domains. The obstacles in this problem are both domain shift and catastrophic forgetting. We propose Gradient Regularized Contrastive Learning (GRCL) to solve the obstacles. At the core of our method, gradient regularization plays two key roles: (1) enforcing the gradient not to harm the discriminative ability of source features which can, in turn, benefit the adaptation ability of the model to target domains; (2) constraining the gradient not to increase the classification loss on old target domains, which enables the model to preserve the performance on old target domains when adapting to an in-coming target domain. Experiments on Digits, DomainNet and Office-Caltech benchmarks demonstrate the strong performance of our approach when compared to the state-of-the-art.",
        "primary_area": "Computer Vision II",
        "author": "Shixiang Tang; Peng Su; Dapeng Chen; Wanli Ouyang",
        "authorids": "",
        "aff": "The University of Sydney Sensetime Group Limited; The Chinese University of Hong Kong; Sensetime Group Limited; The University of Sydney",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16370/16370-13-19864-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02665-gradient-regularized-contrastive-learning-for-continual-domain-adaptation/",
        "doi": "10.1609/aaai.v35i3.16370",
        "pdf_size": 950372
    },
    {
        "id": "01682",
        "title": "GradingNet: Towards Providing Reliable Supervisions for Weakly Supervised Object Detection by Grading the Box Candidates",
        "track": "main",
        "status": "Poster",
        "abstract": "Weakly-Supervised Object Detection (WSOD) aims at training a model with limited and coarse annotations for precisely locating the regions of objects. Existing works solve the WSOD problem by using a two-stage framework, i.e., generating candidate bounding boxes with weak supervision information and then refining them by directly employing supervised object detection models. However, most of such works mainly focus on the performance boosting of the first stage, while ignoring the better usage of generated candidate bounding boxes. To address this issue, we propose a new two-stage framework for WSOD, named GradingNet, which can make good use of the generated candidate bounding boxes. Specifically, the proposed GradingNet consists of two modules: Boxes Grading Module (BGM) and Informative Boosting Module (IBM). BGM generates proposals of the bounding boxes by using standard one-stage weakly-supervised methods, then utilizes Inclusion Principle to pick out highly-reliable boxes and evaluate the grade of each box. With the above boxes and their grade information, an effective anchor generator and a grade-aware loss are carefully designed to train the IBM. Taking the advantages of the grade information, our GradingNet achieves state-of-the-art performance on COCO, VOC 2007 and VOC 2012 benchmarks.",
        "primary_area": "Computer Vision I",
        "author": "Qifei Jia; Shikui Wei; Tao Ruan; Yufeng Zhao; Yao Zhao",
        "authorids": "",
        "aff": "Institute of Information Science, Beijing Jiaotong University, Beijing, China Beijing Key Laboratory of Advanced Information Science and Network Technology, Beijing, China; Institute of Information Science, Beijing Jiaotong University, Beijing, China Beijing Key Laboratory of Advanced Information Science and Network Technology, Beijing, China; Institute of Information Science, Beijing Jiaotong University, Beijing, China Beijing Key Laboratory of Advanced Information Science and Network Technology, Beijing, China; China Academy of Chinese Medical Sciences, Beijing, China; Institute of Information Science, Beijing Jiaotong University, Beijing, China Beijing Key Laboratory of Advanced Information Science and Network Technology, Beijing, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16261/16261-13-19755-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01682-gradingnet-towards-providing-reliable-supervisions-for-weakly-supervised-object-detection-by-grading-the-box-candidates/",
        "doi": "10.1609/aaai.v35i2.16261",
        "pdf_size": 11156957
    },
    {
        "id": "07711",
        "title": "Graph Game Embedding",
        "track": "main",
        "status": "Poster",
        "abstract": "Graph embedding aims to encode nodes/edges into low-dimensional continuous features, and has become a crucial tool for graph analysis including graph/node classification,  link prediction, etc. In this paper we propose a novel graph learning framework, named graph game embedding, to learn discriminative node representation as well as encode graph structures. Inspired by the spirit of game learning, node embedding is converted to the selection/searching process of player strategies, where each node corresponds to one player and each edge corresponds to the interaction of two players. Then, a utility function, which theoretically satisfies the Nash Equilibrium, is defined to measure the benefit/loss of players during graph evolution. Furthermore, a collaboration and competition mechanism is introduced to increase the discriminant learning ability. Under this graph game embedding framework, considering different interaction manners of nodes, we propose two specific models, named paired game embedding for paired nodes and group game embedding for group interaction. Comparing with existing graph embedding methods, our algorithm possesses two advantages: (1) the designed utility function ensures the stable graph evolution with theoretical convergence and Nash Equilibrium satisfaction; (2) the introduced collaboration and competition mechanism endows the graph game embedding framework with discriminative feature leaning ability by guiding each node to learn an optimal strategy distinguished from others. We test the proposed method on three public datasets about citation networks, and the experimental results verify the effectiveness of our method.",
        "primary_area": "Machine Learning II",
        "author": "Xiaobin Hong; Tong Zhang; Zhen Cui; Yuge Huang; Pengcheng Shen; Shaoxin Li; Jian Yang",
        "authorids": "",
        "aff": "Nanjing University of Science and Technology; Nanjing University of Science and Technology; Nanjing University of Science and Technology; Tencent YouTu; Tencent YouTu; Tencent YouTu; Nanjing University of Science and Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16942/16942-13-20436-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07711-graph-game-embedding/",
        "doi": "10.1609/aaai.v35i9.16942",
        "pdf_size": 676981
    },
    {
        "id": "03958",
        "title": "Graph Heterogeneous Multi-Relational Recommendation",
        "track": "main",
        "status": "Poster",
        "abstract": "Traditional studies on recommender systems usually leverage only one type of user behaviors (the optimization target, such as purchase), despite the fact that users also generate a large number of various types of interaction data (e.g., view, click, add-to-cart, etc). Generally, these heterogeneous multi-relational data provide well-structured information and can be used for high-quality recommendation. Early efforts towards leveraging these heterogeneous data fail to capture the high-hop structure of user-item interactions, which are unable to make full use of them and may only achieve constrained recommendation performance. In this work, we propose a new multi-relational recommendation model named Graph Heterogeneous Collaborative Filtering (GHCF). To explore the high-hop heterogeneous user-item interactions, we take the advantages of Graph Convolutional Network (GCN) and further improve it to jointly embed both representations of nodes (users and items) and relations for multi-relational prediction. Moreover, to fully utilize the whole heterogeneous data, we perform the advanced efficient non-sampling optimization under a multi-task learning framework. Experimental results on two public benchmarks show that GHCF significantly outperforms the state-of-the-art recommendation methods, especially for cold-start users who have few primary item interactions. Further analysis verifies the importance of the proposed embedding propagation for modelling high-hop heterogeneous user-item interactions, showing the rationality and effectiveness of GHCF. Our implementation has been released (https://github.com/chenchongthu/GHCF).",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Chong Chen; Weizhi Ma; Min Zhang; Zhaowei Wang; Xiuqiang He; Chenyang Wang; Yiqun Liu; Shaoping Ma",
        "authorids": "",
        "aff": "Tsinghua University; Tsinghua University; Tsinghua University; Noah`s Ark Lab, Huawei; Huawei Noah's Ark Lab; Tsinghua University; Tsinghua University; Tsinghua University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16515/16515-13-20009-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03958-graph-heterogeneous-multi-relational-recommendation/",
        "doi": "10.1609/aaai.v35i5.16515",
        "pdf_size": 443130
    },
    {
        "id": "00072",
        "title": "Graph Neural Network to Dilute Outliers for Refactoring Monolith Application",
        "track": "main",
        "status": "Poster",
        "abstract": "Microservices are becoming the defacto design choice for software architecture. It involves partitioning the software components into finer modules such that the development can happen independently. It also provides natural benefits when deployed on the cloud since resources can be allocated dynamically to necessary components based on demand. Therefore, enterprises as part of their journey to cloud, are increasingly looking to refactor their monolith application into one or more candidate microservices; wherein each service contains a group of software entities (e.g., classes) that are responsible for a common functionality. Graphs are a natural choice to represent a software system. Each software entity can be represented as nodes and its dependencies with other entities as links. Therefore, this problem of refactoring can be viewed as a graph based clustering task. In this work, we propose a novel method to adapt the recent advancements in graph neural networks in the context of code to better understand the software and apply them in the clustering task. In that process, we also identify the outliers in the graph which can be directly mapped to top refactor candidates in the software. Our solution is able to improve state-of-the-art performance compared to works from both software engineering and existing graph representation based techniques.",
        "primary_area": "Application Domains",
        "author": "Utkarsh Desai; Sambaran Bandyopadhyay; Srikanth Tamilselvam",
        "authorids": "",
        "aff": "IBM Research; IBM Research; IBM Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16079/16079-13-19573-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00072-graph-neural-network-to-dilute-outliers-for-refactoring-monolith-application/",
        "doi": "10.1609/aaai.v35i1.16079",
        "pdf_size": 3801493
    },
    {
        "id": "04027",
        "title": "Graph Neural Network-Based Anomaly Detection in Multivariate Time Series",
        "track": "main",
        "status": "Poster",
        "abstract": "Given high-dimensional time series data (e.g., sensor data), how can we detect anomalous events, such as system faults and attacks? More challengingly, how can we do this in a way that captures complex inter-sensor relationships, and detects and explains anomalies which deviate from these relationships? Recently, deep learning approaches have enabled improvements in anomaly detection in high-dimensional datasets; however, existing methods do not explicitly learn the structure of existing relationships between variables, or use them to predict the expected behavior of time series. Our approach combines a structure learning approach with graph neural networks, additionally using attention weights to provide explainability for the detected anomalies. Experiments on two real-world sensor datasets with ground truth anomalies show that our method detects anomalies more accurately than baseline approaches, accurately captures correlations between sensors, and allows users to deduce the root cause of a detected anomaly.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Ailin Deng; Bryan Hooi",
        "authorids": "",
        "aff": "National University of Singapore; National University of Singapore",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16523/16523-13-20017-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04027-graph-neural-network-based-anomaly-detection-in-multivariate-time-series/",
        "doi": "10.1609/aaai.v35i5.16523",
        "pdf_size": 1209141
    },
    {
        "id": "11168",
        "title": "Graph Neural Networks with Heterophily",
        "track": "main",
        "status": "Poster",
        "abstract": "Graph Neural Networks (GNNs) have proven to be useful for many different practical applications. However, many existing GNN models have implicitly assumed homophily among the nodes connected in the graph, and therefore have largely overlooked the important setting of heterophily, where most connected nodes are from different classes. In this work, we propose a novel framework called CPGNN that generalizes GNNs for graphs with either homophily or heterophily. The proposed framework incorporates an interpretable compatibility matrix for modeling the heterophily or homophily level in the graph, which can be learned in an end-to-end fashion, enabling it to go beyond the assumption of strong homophily. Theoretically, we show that replacing the compatibility matrix in our framework with the identity (which represents pure homophily) reduces to GCN. Our extensive experiments demonstrate the effectiveness of our approach in more realistic and challenging experimental settings with significantly less training data compared to previous works: CPGNN variants achieve state-of-the-art results in heterophily settings with or without contextual node features, while maintaining comparable performance in homophily settings.",
        "primary_area": "Machine Learning V",
        "author": "Jiong Zhu; Ryan A. Rossi; Anup Rao; Tung Mai; Nedim Lipka; Nesreen K. Ahmed; Danai Koutra",
        "authorids": "",
        "aff": "University of Michigan; Adobe Research; Adobe Research; Adobe Research; Adobe Research; Intel Labs; University of Michigan",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17332/17332-13-20826-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11168-graph-neural-networks-with-heterophily/",
        "doi": "10.1609/aaai.v35i12.17332",
        "pdf_size": 935007
    },
    {
        "id": "01157",
        "title": "Graph and Temporal Convolutional Networks for 3D Multi-person Pose Estimation in Monocular Videos",
        "track": "main",
        "status": "Poster",
        "abstract": "Despite the recent progress, 3D multi-person pose estimation from monocular videos is still challenging due to the commonly encountered problem of missing information caused by occlusion, partially out-of-frame target persons, and inaccurate person detection. To tackle this problem, we propose a novel framework integrating graph convolutional networks (GCNs) and temporal convolutional networks (TCNs) to robustly estimate camera-centric multi-person 3D poses that does not require camera parameters. In particular, we introduce a human-joint GCN, which unlike the existing GCN, is based on a directed graph that employs the 2D pose estimator's confidence scores to improve the pose estimation results. We also introduce a human-bone GCN, which models the bone connections and provides more information beyond human joints. The two GCNs work together to estimate the spatial frame-wise 3D poses and can make use of both visible joint and bone information in the target frame to estimate the occluded or missing human-part information. To further refine the 3D pose estimation, we use our temporal convolutional networks (TCNs) to enforce the temporal and human-dynamics constraints. We use a joint-TCN to estimate person-centric 3D poses across frames, and propose a velocity-TCN to estimate the speed of 3D joints to ensure the consistency of the 3D pose estimation in consecutive frames. Finally, to estimate the 3D human poses for multiple persons, we propose a root-TCN that estimates camera-centric 3D poses without requiring camera parameters. Quantitative and qualitative evaluations demonstrate the effectiveness of the proposed method.",
        "primary_area": "Computer Vision I",
        "author": "Yu Cheng; Bo Wang; Bo Yang; Robby T. Tan",
        "authorids": "",
        "aff": "National University of Singapore; Tencent America; Tencent America; National University of Singapore Yale-NUS College",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16202/16202-13-19696-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01157-graph-and-temporal-convolutional-networks-for-3d-multi-person-pose-estimation-in-monocular-videos/",
        "doi": "10.1609/aaai.v35i2.16202",
        "pdf_size": 7231583
    },
    {
        "id": "14463",
        "title": "Graph-Based Tri-Attention Network for Answer Ranking in CQA",
        "track": "main",
        "status": "Poster",
        "abstract": "In community-based question answering (CQA) platforms, automatic answer ranking for a given question is critical for finding potentially popular answers in early times. The mainstream approaches learn to generate answer ranking scores based on the matching degree between question and answer representations as well as the influence of respondents. However, they encounter two main limitations: (1) Correlations between answers in the same question are often overlooked. (2) Question and respondent representations are built independently of specific answers before affecting answer representations. To address the limitations, we devise a novel graph-based tri-attention network, namely GTAN, which has two innovations. First, GTAN proposes to construct a graph for each question and learn answer correlations from each graph through graph neural networks (GNNs). Second, based on the representations learned from GNNs, an alternating tri-attention method is developed to alternatively build target-aware respondent representations, answer-specific question representations, and context-aware answer representations by attention computation. GTAN finally integrates the above representations to generate answer ranking scores. Experiments on three real-world CQA datasets demonstrate GTAN significantly outperforms state-of-the-art answer ranking methods, validating the rationality of the network architecture.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Wei Zhang; Zeyuan Chen; Chao Dong; Wen Wang; Hongyuan Zha; Jianyong Wang",
        "authorids": "",
        "aff": "School of Computer Science and Technology, Shanghai Institute for AI Education, East China Normal University; School of Computer Science and Technology, Shanghai Institute for AI Education, East China Normal University; School of Computer Science and Technology, Shanghai Institute for AI Education, East China Normal University; School of Computer Science and Technology, Shanghai Institute for AI Education, East China Normal University; School of Data Science, Shenzhen Research Institute of Big Data, The Chinese University of Hong Kong, Shenzhen; Department of Computer Science and Technology, Tsinghua University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17700/17700-13-21194-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14463-graph-based-tri-attention-network-for-answer-ranking-in-cqa/",
        "doi": "10.1609/aaai.v35i16.17700",
        "pdf_size": 3057869
    },
    {
        "id": "04123",
        "title": "Graph-Enhanced Multi-Task Learning of Multi-Level Transition Dynamics for Session-based Recommendation",
        "track": "main",
        "status": "Poster",
        "abstract": "Session-based recommendation plays a central role in a wide spectrum of online applications, ranging from e-commerce to online advertising services. However, the majority of existing session-based recommendation techniques (e.g., attention-based recurrent network or graph neural network) are not well-designed for capturing the complex transition dynamics exhibited with temporally-ordered and multi-level interdependent relation structures. These methods largely overlook the relation hierarchy of item transitional patterns. In this paper, we propose a multi-task learning framework with Multi-level Transition Dynamics (MTD), which enables the jointly learning of intra- and inter-session item transition dynamics in automatic and hierarchical manner. Towards this end, we first develop a position-aware attention mechanism to learn item transitional regularities within individual session. Then, a graph-structured hierarchical relation encoder is proposed to explicitly capture the cross-session item transitions in the form of high-order connectivities by performing embedding propagation with the global graph context. The learning process of intra- and inter-session transition dynamics are integrated, to preserve the underlying low- and high-level item relationships in a common latent space. Extensive experiments on three real-world datasets demonstrate the superiority of MTD as compared to state-of-the-art baselines.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Chao Huang; Jiahui Chen; Lianghao Xia; Yong Xu; Peng Dai; Yanqing Chen; Liefeng Bo; Jiashu Zhao; Jimmy Xiangji Huang",
        "authorids": "",
        "aff": "JD Finance America Corporation, USA; South China University of Technology, China; South China University of Technology, China; South China University of Technology, China Peng Cheng Laboratory, China Communication and Computer Network Laboratory of Guangdong, China; JD Finance America Corporation, USA; JD Finance America Corporation, USA; JD Finance America Corporation, USA; Wilfrid Laurier University, Canada; York University, Canada",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16534/16534-13-20028-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04123-graph-enhanced-multi-task-learning-of-multi-level-transition-dynamics-for-session-based-recommendation/",
        "doi": "10.1609/aaai.v35i5.16534",
        "pdf_size": 1064987
    },
    {
        "id": "13362",
        "title": "Graph-Evolving Meta-Learning for Low-Resource Medical Dialogue Generation",
        "track": "main",
        "status": "Poster",
        "abstract": "Human doctors with well-structured medical knowledge can diagnose a disease merely via a few conversations with patients about symptoms. In contrast, existing knowledge-grounded dialogue systems often require a large number of dialogue instances to learn as they fail to capture the correlations between different diseases and neglect the diagnostic experience shared among them. To address this issue, we propose a more natural and practical paradigm, i.e., low-resource medical dialogue generation, which can transfer the diagnostic experience from source diseases to target ones with a handful of data for adaptation. It is capitalized on a commonsense knowledge graph to characterize the prior disease-symptom relations. Besides, we develop a Graph-Evolving Meta-Learning (GEML) framework that learns to evolve the commonsense graph for reasoning disease-symptom correlations in a new disease, which effectively alleviates the needs of a large number of dialogues. More importantly, by dynamically evolving disease-symptom graphs, GEML also well addresses the real-world challenges that the disease-symptom correlations of each disease may vary or evolve along with more diagnostic cases. Extensive experiment results on the CMDD dataset and our newly-collected Chunyu dataset testify the superiority of our approach over state-of-the-art approaches. Besides, our GEML can generate an enriched dialogue-sensitive knowledge graph in an online manner, which could benefit other tasks grounded on knowledge graph.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Shuai Lin; Pan Zhou; Xiaodan Liang; Jianheng Tang; Ruihui Zhao; Ziliang Chen; Liang Lin",
        "authorids": "",
        "aff": "Shenzhen Campus of Sun Yat-sen University; Salesforce Research; Shenzhen Campus of Sun Yat-sen University DarkMatter AI Inc.; Shenzhen Campus of Sun Yat-sen University; Tencent Jarvis Lab; Shenzhen Campus of Sun Yat-sen University; Shenzhen Campus of Sun Yat-sen University DarkMatter AI Inc.",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17577/17577-13-21071-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13362-graph-evolving-meta-learning-for-low-resource-medical-dialogue-generation/",
        "doi": "10.1609/aaai.v35i15.17577",
        "pdf_size": 534162
    },
    {
        "id": "02925",
        "title": "Graph-to-Graph: Towards Accurate and Interpretable Online Handwritten Mathematical Expression Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent handwritten mathematical expression recognition (HMER) approaches treat the problem as an image-to-markup generation task where the handwritten formula is translated into a sequence (e.g. LaTeX). The encoder-decoder framework is widely used to solve this image-to-sequence problem. However, (i) for structured mathematical formula, the hierarchical structure neither in the formula nor in the markup has been explored adequately. In addition, (ii) existing image-to-markup methods could not explicitly segment mathematical symbols in the formula corresponding to each target markup token. In this paper, we address the above issues by formulating the HMER as a graph-to-graph (G2G) learning problem. Graph is more flexible and general for structure representation and learning compared with image or sequence. At the core of our method lies the embedding of input formula and output markup into graphs on primitives, with Graph Neural Networks (GNN) to explore the structural information, and a novel sub-graph attention mechanism to match primitives in the input and output graphs. We conduct extensive experiments on CROHME datasets to demonstrate the benefits of the proposed G2G model. Our method yields significant improvements over previous SOTA image-to-markup systems. Moreover, it explicitly resolves the symbol segmentation problem while still being trained end-to-end, making the whole system much more accurate and interpretable.",
        "primary_area": "Computer Vision III",
        "author": "Jin-Wen Wu; Fei Yin; Yan-Ming Zhang; Xu-Yao Zhang; Cheng-Lin Liu",
        "authorids": "",
        "aff": "National Laboratory of Pattern Recognition, Institute of Automation of Chinese Academy of Sciences School of Artificial Intelligence, University of Chinese Academy of Sciences; National Laboratory of Pattern Recognition, Institute of Automation of Chinese Academy of Sciences; National Laboratory of Pattern Recognition, Institute of Automation of Chinese Academy of Sciences; National Laboratory of Pattern Recognition, Institute of Automation of Chinese Academy of Sciences School of Artificial Intelligence, University of Chinese Academy of Sciences; National Laboratory of Pattern Recognition, Institute of Automation of Chinese Academy of Sciences School of Artificial Intelligence, University of Chinese Academy of Sciences CAS Center for Excellence of Brain Science and Intelligence Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16399/16399-13-19893-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02925-graph-to-graph-towards-accurate-and-interpretable-online-handwritten-mathematical-expression-recognition/",
        "doi": "10.1609/aaai.v35i4.16399",
        "pdf_size": 378423
    },
    {
        "id": "04206",
        "title": "GraphMSE: Efficient Meta-path Selection in Semantically Aligned Feature Space for Graph Neural Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Heterogeneous information networks (HINs) are ideal for describing real-world data with different types of entities and relationships. To carry out machine learning on HINs, meta-paths are widely utilized to extract semantics with pre-defined patterns, and models such as graph convolutional networks (GCNs) are thus enabled. However, previous works generally assume a fixed set of meta-paths, which is unrealistic as real-world data are overwhelmingly diverse. Therefore, it is appealing if meta-paths can be automatically selected given an HIN, yet existing works aiming at such problem possess drawbacks, such as poor efficiency and ignoring feature heterogeneity. To address these drawbacks, we propose GraphMSE, an efficient heterogeneous GCN combined with automatic meta-path selection. Specifically, we design highly efficient meta-path sampling techniques, and then injectively project sampled meta-path instances to vectors. We then design a novel semantic feature space alignment, aiming to align the meta-path instance vectors and hence facilitate meta-path selection. Extensive experiments on real-world datasets demonstrate that GraphMSE outperforms state-of-the-art counterparts, figures out important meta-paths, and is dramatically (e.g. 200 times) more efficient.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Yi Li; Yilun Jin; Guojie Song; Zihao Zhu; Chuan Shi; Yiming Wang",
        "authorids": "",
        "aff": "Peking University, Beijing, China; The Hong Kong University of Science and Technology, Hong Kong SAR, China; Key Laboratory of Machine Perception (Ministry of Education), Peking University, Beijing, China; Beijing University of Posts and Telecommunications, Beijing, China; Beijing University of Posts and Telecommunications, Beijing, China; Peking University, Beijing, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16544/16544-13-20038-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04206-graphmse-efficient-meta-path-selection-in-semantically-aligned-feature-space-for-graph-neural-networks/",
        "doi": "10.1609/aaai.v35i5.16544",
        "pdf_size": 678720
    },
    {
        "id": "10024",
        "title": "GraphMix: Improved Training of GNNs for Semi-Supervised Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "We present GraphMix, a regularization method for Graph Neural Network based semi-supervised object classification, whereby we propose to train a fully-connected network jointly with the graph neural network via parameter sharing and interpolation-based regularization. Further, we provide a theoretical analysis of how GraphMix improves the generalization bounds of the underlying graph neural network, without making any assumptions about the \"aggregation\" layer or the depth of the graph neural networks. We experimentally validate this analysis by applying GraphMix to various architectures such as Graph Convolutional Networks, Graph Attention Networks and Graph-U-Net. Despite its simplicity, we demonstrate that GraphMix can consistently improve or closely match state-of-the-art performance using even simpler architectures such as Graph Convolutional Networks, across three established graph benchmarks:  Cora, Citeseer and Pubmed citation network datasets, as well as three newly proposed datasets: Cora-Full, Co-author-CS and Co-author-Physics.",
        "primary_area": "Machine Learning IV",
        "author": "Vikas Verma; Meng Qu; Kenji Kawaguchi; Alex Lamb; Yoshua Bengio; Juho Kannala; Jian Tang",
        "authorids": "",
        "aff": "Aalto University Mila - Qu\u00e9bec Artificial Intelligence Institute, Montr\u00e9al, Canada; Mila - Qu\u00e9bec Artificial Intelligence Institute, Montr\u00e9al, Canada,; Massachusetts Institute ofTechnology (MIT), USA; Universite de Montreal; Mila - Qu\u00e9bec Artificial Intelligence Institute, Montr\u00e9al, Canada,; Aalto University; Mila - Qu\u00e9bec Artificial Intelligence Institute, Montr\u00e9al, Canada,",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17203/17203-13-20697-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10024-graphmix-improved-training-of-gnns-for-semi-supervised-learning/",
        "doi": "10.1609/aaai.v35i11.17203",
        "pdf_size": 609305
    },
    {
        "id": "12051",
        "title": "Group Fairness by Probabilistic Modeling with Latent Fair Decisions",
        "track": "main",
        "status": "Poster",
        "abstract": "Machine learning systems are increasingly being used to make impactful decisions such as loan applications and criminal justice risk assessments, and as such, ensuring fairness of these systems is critical. This is often challenging as the labels in the data are biased. This paper studies learning fair probability distributions from biased data by explicitly modeling a latent variable that represents a hidden, unbiased label. In particular, we aim to achieve demographic parity by enforcing certain independencies in the learned model. We also show that group fairness guarantees are meaningful only if the distribution used to provide those guarantees indeed captures the real-world data. In order to closely model the data distribution, we employ probabilistic circuits, an expressive and tractable probabilistic model, and propose an algorithm to learn them from incomplete data. We show on real-world datasets that our approach not only is a better model of how the data was generated than existing methods but also achieves competitive accuracy. Moreover, we also evaluate our approach on a synthetic dataset in which observed labels indeed come from fair labels but with added bias, and demonstrate that the fair labels are successfully retrieved.",
        "primary_area": "Reasoning under Uncertainty",
        "author": "YooJung Choi; Meihua Dang; Guy Van den Broeck",
        "authorids": "",
        "aff": "UCLA; UCLA; UCLA",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17431/17431-13-20925-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12051-group-fairness-by-probabilistic-modeling-with-latent-fair-decisions/",
        "doi": "10.1609/aaai.v35i13.17431",
        "pdf_size": 3523715
    },
    {
        "id": "04348",
        "title": "Group Testing on a Network",
        "track": "main",
        "status": "Poster",
        "abstract": "Group testing---where multiple samples are tested together using a single test kit and individual tests are performed only for samples in positive groups---is a popular strategy to optimize the use of testing resources. We investigate how to effectively group samples for testing based on a transmission network. We formalize the group assembling problem as a graph partitioning problem, where the goal is to minimize the expected number of tests needed to screen the entire network. The problem is shown to be computationally hard and thus we focus on designing effective heuristics for it. Using realistic epidemic models on real contact networks, we show that our approaches save up to 33% of resources---compared to the best baseline---at 4% prevalence, are still effective at higher prevalence, and are robust to missing transmission data.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Arlei Silva; Ambuj Singh",
        "authorids": "",
        "aff": "UC, Santa Barbara; UC, Santa Barbara",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16560/16560-13-20054-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04348-group-testing-on-a-network/",
        "doi": "10.1609/aaai.v35i5.16560",
        "pdf_size": 2405502
    },
    {
        "id": "01984",
        "title": "Group-Wise Semantic Mining for Weakly Supervised Semantic Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "Acquiring sufficient ground-truth supervision to train deep vi- sual models has been a bottleneck over the years due to the data-hungry nature of deep learning. This is exacerbated in some structured prediction tasks, such as semantic segmen- tation, which requires pixel-level annotations. This work ad- dresses weakly supervised semantic segmentation (WSSS), with the goal of bridging the gap between image-level anno- tations and pixel-level segmentation. We formulate WSSS as a novel group-wise learning task that explicitly models se- mantic dependencies in a group of images to estimate more reliable pseudo ground-truths, which can be used for training more accurate segmentation models. In particular, we devise a graph neural network (GNN) for group-wise semantic min- ing, wherein input images are represented as graph nodes, and the underlying relations between a pair of images are char- acterized by an efficient co-attention mechanism. Moreover, in order to prevent the model from paying excessive atten- tion to common semantics only, we further propose a graph dropout layer, encouraging the model to learn more accurate and complete object responses. The whole network is end-to- end trainable by iterative message passing, which propagates interaction cues over the images to progressively improve the performance. We conduct experiments on the popular PAS- CAL VOC 2012 and COCO benchmarks, and our model yields state-of-the-art performance. Our code is available at: https://github.com/Lixy1997/Group-WSSS.",
        "primary_area": "Computer Vision II",
        "author": "Xueyi Li; Tianfei Zhou; Jianwu Li; Yi Zhou; Zhaoxiang Zhang",
        "authorids": "",
        "aff": "School of Computer Science and Technology, Beijing Institute of Technology, China; Computer Vision Laboratory, ETH Zurich, Switzerland; School of Computer Science and Technology, Beijing Institute of Technology, China; School of Computer Science and Engineering, Southeast University, China; Center for Research on Intelligent Perception and Computing, Chinese Academy of Sciences, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16294/16294-13-19788-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01984-group-wise-semantic-mining-for-weakly-supervised-semantic-segmentation/",
        "doi": "10.1609/aaai.v35i3.16294",
        "pdf_size": 1873551
    },
    {
        "id": "13727",
        "title": "Guiding Non-Autoregressive Neural Machine Translation Decoding with Reordering Information",
        "track": "main",
        "status": "Poster",
        "abstract": "Non-autoregressive neural machine translation (NAT) generates each target word in parallel and has achieved promising inference acceleration. However, existing NAT models still have a big gap in translation quality compared to autoregressive neural machine translation models due to the multimodality problem: the target words may come from multiple feasible translations. To address this problem, we propose a novel NAT framework ReorderNAT which explicitly models the reordering information to guide the decoding of NAT. Specially, ReorderNAT utilizes deterministic and non-deterministic decoding strategies that leverage reordering information as a proxy for the final translation to encourage the decoder to choose words belonging to the same translation. Experimental results on various widely-used datasets show that our proposed model achieves better performance compared to most existing NAT models, and even achieves comparable translation quality as autoregressive translation models with a significant speedup.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Qiu Ran; Yankai Lin; Peng Li; Jie Zhou",
        "authorids": "",
        "aff": "Pattern Recognition Center, WeChat AI, Tencent Inc., China; Pattern Recognition Center, WeChat AI, Tencent Inc., China; Pattern Recognition Center, WeChat AI, Tencent Inc., China; Pattern Recognition Center, WeChat AI, Tencent Inc., China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17618/17618-13-21112-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13727-guiding-non-autoregressive-neural-machine-translation-decoding-with-reordering-information/",
        "doi": "10.1609/aaai.v35i15.17618",
        "pdf_size": 601807
    },
    {
        "id": "13045",
        "title": "HARGAN: Heterogeneous Argument Attention Network for Persuasiveness Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "Argument structure elaborates the relation among claims and premises.  Previous works in persuasiveness prediction do not consider this relation in their architectures.  To take argument structure information into account, this paper proposes an approach to persuasiveness prediction with a novel graph-based neural network model, called heterogeneous argument attention network (HARGAN). By jointly training on the persuasiveness and stance of the replies, our model achieves the state-of-the-art performance on the ChangeMyView (CMV) dataset for the persuasiveness prediction task. Experimental results show that the graph setting enables our model to aggregate information across multiple paragraphs effectively. In the meanwhile, our stance prediction auxiliary task enables our model to identify the viewpoint of each party, and helps our model perform better on the persuasiveness prediction.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Kuo-Yu Huang; Hen-Hsen Huang; Hsin-Hsi Chen",
        "authorids": "",
        "aff": "Department of Computer Science and Information Engineering, National Taiwan University, Taiwan; Department of Computer Science, National Chengchi University, Taiwan MOST Joint Research Center for AI Technology and All Vista Healthcare, Taiwan; Department of Computer Science and Information Engineering, National Taiwan University, Taiwan MOST Joint Research Center for AI Technology and All Vista Healthcare, Taiwan",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17542/17542-13-21036-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13045-hargan-heterogeneous-argument-attention-network-for-persuasiveness-prediction/",
        "doi": "10.1609/aaai.v35i14.17542",
        "pdf_size": 315122
    },
    {
        "id": "08191",
        "title": "HINT: Hierarchical Invertible Neural Transport for Density Estimation and Bayesian Inference",
        "track": "main",
        "status": "Poster",
        "abstract": "Many recent invertible neural architectures are based on coupling block designs where variables are divided in two subsets which serve as inputs of an easily invertible (usually affine) triangular transformation. While such a transformation is invertible, its Jacobian is very sparse and thus may lack expressiveness. This work presents a simple remedy by noting that subdivision and (affine) coupling  can be repeated recursively within the resulting subsets, leading to an efficiently invertible block with dense, triangular Jacobian. By formulating our recursive coupling scheme via a hierarchical architecture, HINT allows sampling from a joint distribution p(y,x) and the corresponding posterior p(x|y) using a single invertible network. We evaluate our method on some standard data sets and benchmark its full power for density estimation and Bayesian inference on a novel data set of 2D shapes in Fourier parameterization, which enables consistent visualization of samples for different dimensionalities.",
        "primary_area": "Machine Learning II",
        "author": "Jakob Kruse; Gianluca Detommaso; Ullrich K\u00f6the; Robert Scheichl",
        "authorids": "",
        "aff": "Heidelberg University; amazon.com; University of Heidelberg; Heidelberg University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16997/16997-13-20491-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08191-hint-hierarchical-invertible-neural-transport-for-density-estimation-and-bayesian-inference/",
        "doi": "10.1609/aaai.v35i9.16997",
        "pdf_size": 1836918
    },
    {
        "id": "04232",
        "title": "HMS: A Hierarchical Solver with Dependency-Enhanced Understanding for Math Word Problem",
        "track": "main",
        "status": "Poster",
        "abstract": "Automatically solving math word problems is a crucial task for exploring the intelligence levels of machines in the general AI domain. It is highly challenging since it requires not only natural language understanding but also mathematical expression inference. Existing solutions usually explore sequence-to-sequence models to generate expressions, where the problems are simply encoded sequentially. However, such models are generally far from enough for understanding problems as similar to humans and lead to incorrect answers. To this end, in this paper, we propose a novel Hierarchical Math Solver (HMS) to make deep understanding and exploitation of problems. In problem understanding, imitating human reading habits, we propose a hierarchical word-clause-problem encoder. Specifically, we first split each problem into several clauses and learn problem semantics from the local clause level to the global problem level. Then, in clause understanding, we propose a dependency-based module to enhance clause semantics with the dependency structure of the problem. Next, in expression inference, we propose a novel tree-based decoder to generate the mathematical expression for the answer. In the decoder, we apply a hierarchical attention mechanism to enhance the problem semantics with context from different levels, and a pointer-generator network to guide the model to copy existing information and infer extra knowledge. Extensive experimental results on two widely used datasets demonstrate that HMS achieves not only better answers but also more reasonable inference.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Xin Lin; Zhenya Huang; Hongke Zhao; Enhong Chen; Qi Liu; Hao Wang; Shijin Wang",
        "authorids": "",
        "aff": "Anhui Province Key Lab. of Big Data Analysis and Application, School of Computer Science and Technology, University of Science and Technology of China; Anhui Province Key Lab. of Big Data Analysis and Application, School of Computer Science and Technology, University of Science and Technology of China; College of Management and Economics, Tianjin University; Anhui Province Key Lab. of Big Data Analysis and Application, School of Computer Science and Technology, University of Science and Technology of China; Anhui Province Key Lab. of Big Data Analysis and Application, School of Computer Science and Technology, University of Science and Technology of China; Anhui Province Key Lab. of Big Data Analysis and Application, School of Computer Science and Technology, University of Science and Technology of China; iFLYTEK Research & State Key Laboratory of Cognitive Intelligence, iFLYTEK Co., Ltd.",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16547/16547-13-20041-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04232-hms-a-hierarchical-solver-with-dependency-enhanced-understanding-for-math-word-problem/",
        "doi": "10.1609/aaai.v35i5.16547",
        "pdf_size": 1997043
    },
    {
        "id": "02294",
        "title": "HR-Depth: High Resolution Self-Supervised Monocular Depth Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Self-supervised learning shows great potential in monocular depth estimation, using image sequences as the only source of supervision. Although people try to use the high-resolution image  for  depth  estimation,  the  accuracy  of  prediction  has not  been  significantly  improved.  In  this  work,  we  find  the core  reason  comes  from  the  inaccurate  depth  estimation  in large gradient regions, making the bilinear interpolation error gradually disappear as the resolution increases. To obtain more accurate depth estimation in large gradient regions, it is  necessary  to  obtain  high-resolution  features  with  spatial and semantic information. Therefore, we present an improved DepthNet,  HR-Depth,  with  two  effective  strategies:  (1)  re-design  the  skip-connection  in  DepthNet  to  get  better  high-resolution features and (2) propose feature fusion Squeeze-and-Excitation(fSE) module to fuse feature more efficiently. Using Resnet-18 as the encoder, HR-Depth surpasses all previous  state-of-the-art(SoTA)  methods  with  the  least  parameters  at  both  high  and  low  resolution.  Moreover,  previous SoTA methods are based on fairly complex and deep networks with a mass of parameters which limits their real applications. Thus we also construct a lightweight network which uses MobileNetV3 as encoder. Experiments show that the lightweight network can perform on par with many large models like Monodepth2 at high-resolution with only20%parameters. All codes and models will be available at https://github.com/shawLyu/HR-Depth.",
        "primary_area": "Computer Vision II",
        "author": "Xiaoyang Lyu; Liang Liu; Mengmeng Wang; Xin Kong; Lina Liu; Yong Liu; Xinxin Chen; Yi Yuan",
        "authorids": "",
        "aff": "Zhejiang University; Zhejiang University; Zhejiang University; Zhejiang University; Zhejiang University; Zhejiang University; Zhejiang University; Fuxi AI Lab, NetEase",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16329/16329-13-19823-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02294-hr-depth-high-resolution-self-supervised-monocular-depth-estimation/",
        "doi": "10.1609/aaai.v35i3.16329",
        "pdf_size": 5062004
    },
    {
        "id": "01558",
        "title": "Hand-Model-Aware Sign Language Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "Hand gestures play a dominant role in the expression of sign language. Current deep-learning based video sign language recognition (SLR) methods usually follow a data-driven paradigm under the supervision of the category label. However, those methods suffer limited interpretability and may encounter the overfitting issue due to limited sign data sources. In this paper, we introduce the hand prior and propose a new hand-model-aware framework for isolated SLR with the modeling hand as the intermediate representation. We first transform the cropped hand sequence into the latent semantic feature. Then the hand model introduces the hand prior and provides a mapping from the semantic feature to the compact hand pose representation. Finally, the inference module enhances the spatio-temporal pose representation and performs the final recognition. Due to the lack of annotation on the hand pose under current sign language datasets, we further guide its learning by utilizing multiple weakly-supervised losses to constrain its spatial and temporal consistency. To validate the effectiveness of our method, we perform extensive experiments on four benchmark datasets, including NMFs-CSL, SLR500, MSASL and WLASL. Experimental results demonstrate that our method achieves state-of-the-art performance on all four popular benchmarks with a notable margin.",
        "primary_area": "Computer Vision I",
        "author": "Hezhen Hu; Wengang Zhou; Houqiang Li",
        "authorids": "",
        "aff": "CAS Key Laboratory of GIPAS, EEIS Department, University of Science and Technology of China; CAS Key Laboratory of GIPAS, EEIS Department, University of Science and Technology of China Institute of Artificial Intelligence, Hefei Comprehensive National Science Center; CAS Key Laboratory of GIPAS, EEIS Department, University of Science and Technology of China Institute of Artificial Intelligence, Hefei Comprehensive National Science Center",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16247/16247-13-19741-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01558-hand-model-aware-sign-language-recognition/",
        "doi": "10.1609/aaai.v35i2.16247",
        "pdf_size": 875985
    },
    {
        "id": "10218",
        "title": "Harmonized Dense Knowledge Distillation Training for Multi-Exit Architectures",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-exit architectures, in which a sequence of intermediate classifiers are introduced at different depths of the feature layers, perform adaptive computation by early exiting ``easy\" samples to speed up the inference. In this paper, a novel Harmonized Dense Knowledge Distillation (HDKD) training method for multi-exit architecture is designed to encourage each exit to flexibly learn from all its later exits. In particular, a general dense knowledge distillation training objective is proposed to incorporate all possible beneficial supervision information for multi-exit learning, where a harmonized weighting scheme is designed for the multi-objective optimization problem consisting of multi-exit classification loss and dense distillation loss. A bilevel optimization algorithm is introduced for alternatively updating the weights of multiple objectives and the multi-exit network parameters. Specifically, the loss weighting parameters are optimized with respect to its performance on validation set by gradient descent. Experiments on CIFAR100 and ImageNet show that the HDKD strategy harmoniously improves the performance of the state-of-the-art multi-exit neural networks. Moreover, this method does not require within architecture modifications and can be effectively combined with other previously-proposed training techniques and further boosts the performance.",
        "primary_area": "Machine Learning IV",
        "author": "Xinglu Wang; Yingming Li",
        "authorids": "",
        "aff": "Zhejiang University; Zhejiang University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17225/17225-13-20719-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10218-harmonized-dense-knowledge-distillation-training-for-multi-exit-architectures/",
        "doi": "10.1609/aaai.v35i11.17225",
        "pdf_size": 218808
    },
    {
        "id": "13208",
        "title": "Have We Solved The Hard Problem? It\u2019s Not Easy! Contextual Lexical Contrast as a Means to Probe Neural Coherence",
        "track": "main",
        "status": "Poster",
        "abstract": "Lexical cohesion is a fundamental mechanism for text which requires a pair of words to be interpreted as a certain type of lexical relation (e.g., similarity) to understand a coherent context; we refer to such relations as the contextual lexical relation. However, work on lexical cohesion has not modeled context comprehensively in considering lexical relations due to the lack of linguistic resources. In this paper, we take initial steps to address contextual lexical relations by focusing on the contrast relation, as it is a well-known relation though it is more subtle and relatively less resourced. We present a corpus named Cont 2 Lex to make Contextual Lexical Contrast Recognition a computationally feasible task. We benchmark this task with widely-adopted semantic representations; we discover that contextual embeddings (e.g. BERT) generally outperform static embeddings (e.g. Glove), but barely go beyond 70% in accuracy performance. In addition, we \ufb01nd that all embeddings perform better when CLC occurs within the same sentence, suggesting possible limitations of current computational coherence models. Another intriguing discovery is the improvement of BERT in CLC is largely attributed to its modeling of CLC word pairs co-occurring with other word repetitions. Such observations imply that the progress made in lexical coherence modeling remains relatively primitive even for semantic representations such as BERT that have been empowering numerous standard NLP tasks to approach human benchmarks. Through presenting our corpus and benchmark, we attempt to seed initial discussions and endeavors in advancing semantic representations from modeling syntactic and semantic levels to coherence and discourse levels.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Wenqiang Lei; Yisong Miao; Runpeng Xie; Bonnie Webber; Meichun Liu; Tat-Seng Chua; Nancy F. Chen",
        "authorids": "",
        "aff": "National University of Singapore; National University of Singapore; Fudan University; University of Edinburgh; City University of HongKong; National university of Singapore; Institute for Infocomm Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17560/17560-13-21054-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13208-have-we-solved-the-hard-problem-its-not-easy-contextual-lexical-contrast-as-a-means-to-probe-neural-coherence/",
        "doi": "10.1609/aaai.v35i15.17560",
        "pdf_size": 130643
    },
    {
        "id": "04697",
        "title": "Heterogeneous Graph Structure Learning for Graph Neural Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Heterogeneous Graph Neural Networks (HGNNs) have drawn increasing attention in recent years and achieved outstanding performance in many tasks. The success of the existing HGNNs relies on one fundamental assumption, i.e., the original heterogeneous graph structure is reliable. However, this assumption is usually unrealistic, since the heterogeneous graph in reality is inevitably noisy or incomplete. Therefore, it is vital to learn the heterogeneous graph structure for HGNNs rather than rely only on the raw graph structure. In light of this, we make the first attempt towards learning an optimal heterogeneous graph structure for HGNNs and propose a novel framework HGSL, which jointly performs Heterogeneous Graph Structure Learning and GNN parameters learning for classification task. Different from traditional GSL on homogeneous graph, considering the heterogeneity of different relations in heterogeneous graph, HGSL generates each relation subgraph independently. Specifically, in each generated relation subgraph, HGSL not only considers the feature similarity by generating feature similarity graph, but also considers the complex heterogeneous interactions in features and semantics by generating feature propagation graph and semantic graph. Then, these graphs are fused to a learned heterogeneous graph and optimized together with a GNN towards classification objective. Extensive experiments on real-world graphs demonstrate that the proposed framework significantly outperforms the state-of-the-art methods.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Jianan Zhao; Xiao Wang; Chuan Shi; Binbin Hu; Guojie Song; Yanfang Ye",
        "authorids": "",
        "aff": "School of CS, Beijing University of Posts and Telecommunications, Beijing, China Department of CDS, Case Western Reserve University, OH, USA; School of CS, Beijing University of Posts and Telecommunications, Beijing, China; School of CS, Beijing University of Posts and Telecommunications, Beijing, China; Ant Group; Key Laboratory of Machine Perception, Ministry of Education, Peking University; Department of CDS, Case Western Reserve University, OH, USA",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16600/16600-13-20094-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04697-heterogeneous-graph-structure-learning-for-graph-neural-networks/",
        "doi": "10.1609/aaai.v35i5.16600",
        "pdf_size": 4086280
    },
    {
        "id": "09747",
        "title": "HiABP: Hierarchical Initialized ABP for Unsupervised Representation Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Although Markov chain Monte Carlo (MCMC) is useful for generating samples from the posterior distribution, it often suffers from intractability when dealing with large-scale datasets. To address this issue, we propose Hierarchical Initialized Alternating Back-propagation (HiABP) for efficient Bayesian inference. Especially, we endow Alternating Backpropagation (ABP) method with a well-designed initializer and hierarchical structure, composing the pipeline of Initializing, Improving, and Learning back-propagation. It saves much time for the generative model to initialize the latent variable by constraining a sampler to be close to the true posterior distribution. The initialized latent variable is then improved significantly by an MCMC sampler. Thus the proposed method has the strengths of both methods, i.e., the effectiveness of MCMC and the efficiency of variational inference. Experimental results validate our framework can outperform other popular deep generative models in modeling natural images and learning from incomplete data. We further demonstrate the unsupervised disentanglement of hierarchical latent representation with controllable image synthesis.",
        "primary_area": "Machine Learning IV",
        "author": "Jiankai Sun; Rui Liu; Bolei Zhou",
        "authorids": "",
        "aff": "Centre for Perceptual and Interactive Intelligence The Chinese University of Hong Kong; The Chinese University of Hong Kong; Centre for Perceptual and Interactive Intelligence The Chinese University of Hong Kong",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17172/17172-13-20666-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09747-hiabp-hierarchical-initialized-abp-for-unsupervised-representation-learning/",
        "doi": "10.1609/aaai.v35i11.17172",
        "pdf_size": 1318490
    },
    {
        "id": "07484",
        "title": "HiGAN: Handwriting Imitation Conditioned on Arbitrary-Length Texts and Disentangled Styles",
        "track": "main",
        "status": "Poster",
        "abstract": "Given limited handwriting scripts, humans can easily visualize (or imagine) what the handwritten words/texts would look like with other arbitrary textual contents. Moreover, a person also is able to imitate the handwriting styles of provided reference samples. Humans can do such hallucinations, perhaps because they can learn to disentangle the calligraphic styles and textual contents from given handwriting scripts. However, computers cannot study to do such flexible handwriting imitation with existing techniques. In this paper, we propose a novel handwriting imitation generative adversarial network (HiGAN) to mimic such hallucinations. Specifically, HiGAN can generate variable-length handwritten words/texts conditioned on arbitrary textual contents, which are unconstrained to any predefined corpus or out-of-vocabulary words. Moreover, HiGAN can flexibly control the handwriting styles of synthetic images by disentangling calligraphic styles from the reference samples. Experiments on handwriting benchmarks validate our superiority in terms of visual quality and scalability when comparing to the state-of-the-art methods for handwritten word/text synthesis. The code and pre-trained models can be found at https://github.com/ganji15/HiGAN.",
        "primary_area": "Machine Learning II",
        "author": "Ji Gan; Weiqiang Wang",
        "authorids": "",
        "aff": "University of Chinese Academy of Sciences; University of Chinese Academy of Sciences",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16917/16917-13-20411-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07484-higan-handwriting-imitation-conditioned-on-arbitrary-length-texts-and-disentangled-styles/",
        "doi": "10.1609/aaai.v35i9.16917",
        "pdf_size": 3789558
    },
    {
        "id": "13353",
        "title": "Hierarchical Coherence Modeling for Document Quality Assessment",
        "track": "main",
        "status": "Poster",
        "abstract": "Text coherence plays a key role in document quality assessment. Most existing text coherence methods only focus on similarity of adjacent sentences. However, local coherence exists in sentences with broader contexts and diverse rhetoric relations, rather than just adjacent sentences similarity. Besides, the highlevel text coherence is also an important aspect of document quality. To this end, we propose a hierarchical coherence model for document quality assessment. In our model, we implement a local attention mechanism to capture the location semantics, bilinear tensor layer for measure coherence and max-coherence pooling for acquiring high-level coherence. We evaluate the proposed method on two realistic tasks: news quality judgement and automated essay scoring.   Experimental results demonstrate the validity and superiority of our work.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Dongliang Liao; Jin Xu; Gongfu Li; Yiru Wang",
        "authorids": "",
        "aff": "Data Quality Team WeChat Tencent Inc. China; Data Quality Team WeChat Tencent Inc. China; Data Quality Team WeChat Tencent Inc. China; Data Quality Team WeChat Tencent Inc. China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17576/17576-13-21070-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13353-hierarchical-coherence-modeling-for-document-quality-assessment/",
        "doi": "10.1609/aaai.v35i15.17576",
        "pdf_size": 928326
    },
    {
        "id": "10603",
        "title": "Hierarchical Graph Capsule Network",
        "track": "main",
        "status": "Poster",
        "abstract": "Graph Neural Networks (GNNs) draw their strength from explicitly modeling the topological information of structured data. However, existing GNNs suffer from limited capability in capturing the hierarchical graph representation which plays an important role in graph classification. In this paper, we innovatively propose hierarchical graph capsule network (HGCN) that can jointly learn node embeddings and extract graph hierarchies. Specifically, disentangled graph capsules are established by identifying heterogeneous factors underlying each node, such that their instantiation parameters represent different properties of the same entity. To learn the hierarchical representation, HGCN characterizes the part-whole relationship between lower-level capsules (part) and higher-level capsules (whole) by explicitly considering the structure information among the parts. Experimental studies demonstrate the effectiveness of HGCN and the contribution of each component. Code: https://github.com/uta-smile/HGCN",
        "primary_area": "Machine Learning V",
        "author": "Jinyu Yang; Peilin Zhao; Yu Rong; Chaochao Yan; Chunyuan Li; Hehuan Ma; Junzhou Huang",
        "authorids": "",
        "aff": "University of Texas at Arlington; Tencent AI Lab; Tencent AI Lab; University of Texas at Arlington; University of Texas at Arlington; University of Texas at Arlington; University of Texas at Arlington",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17268/17268-13-20762-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10603-hierarchical-graph-capsule-network/",
        "doi": "10.1609/aaai.v35i12.17268",
        "pdf_size": 425037
    },
    {
        "id": "00151",
        "title": "Hierarchical Graph Convolution Network for Traffic Forecasting",
        "track": "main",
        "status": "Poster",
        "abstract": "Traffic forecasting is attracting considerable interest due to its widespread application in intelligent transportation systems. Given the complex and dynamic traffic data, many methods focus on how to establish a spatial-temporal model to express the non-stationary traffic patterns. Recently, the latest Graph Convolution Network (GCN) has been introduced to learn spatial features while the time neural networks are used to learn temporal features. These GCN based methods obtain state-of-the-art performance. However, the current GCN based methods ignore the natural hierarchical structure of traffic systems which is composed of the micro layers of road networks and the macro layers of region networks, in which the nodes are obtained through pooling method and could include some hot traffic regions such as downtown and CBD etc., while the current GCN is only applied on the micro graph of road networks. In this paper, we propose a novel Hierarchical Graph Convolution Networks (HGCN) for traffic forecasting by operating on both the micro and macro traffic graphs. The proposed method is evaluated on two complex city traffic speed datasets. Compared to the latest GCN based methods like Graph WaveNet, the proposed HGCN gets higher traffic forecasting precision with lower computational cost.The website of the code is https://github.com/guokan987/HGCN.git.",
        "primary_area": "Application Domains",
        "author": "Kan Guo; Yongli Hu; Yanfeng Sun; Sean Qian; Junbin Gao; Baocai Yin",
        "authorids": "",
        "aff": "Beijing University of Technology Peng Cheng Laboratory; Beijing University of Technology; Beijing University of Technology; Carnegie Mellon University; University of Sydney, Australia; Beijing University of Technology Peng Cheng Laboratory",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16088/16088-13-19582-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00151-hierarchical-graph-convolution-network-for-traffic-forecasting/",
        "doi": "10.1609/aaai.v35i1.16088",
        "pdf_size": 1871858
    },
    {
        "id": "02207",
        "title": "Hierarchical Information Passing Based Noise-Tolerant Hybrid Learning for Semi-Supervised Human Parsing",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep learning based human parsing methods usually require a large amount of training data to reach high performance. However, it is costly and time-consuming to obtain manually annotated high quality labels for a large scale dataset. To alleviate annotation efforts, we propose a new semi-supervised human parsing method for which we only need a small number of labels for training.  First, we generate high quality pseudo labels on unlabeled images using a hierarchical information passing network (HIPN), which reasons human part segmentation in a coarse to fine manner.  Furthermore, we develop a noise-tolerant hybrid learning method, which takes advantage of positive and negative learning to better handle noisy pseudo labels.  When evaluated on standard human parsing benchmarks, our HIPN achieves a new state-of-the-art  performance. Moreover, our noise-tolerant hybrid learning method further improves the performance and outperforms the state-of-the-art semi-supervised method (i.e. GRN) by 4.47 points w.r.t mIoU on the LIP dataset.",
        "primary_area": "Computer Vision II",
        "author": "Yunan Liu; Shanshan Zhang; Jian Yang; PongChi Yuen",
        "authorids": "",
        "aff": "School of Computer Science and Engineering, Nanjing University of Science and Technology; School of Computer Science and Engineering, Nanjing University of Science and Technology; School of Computer Science and Engineering, Nanjing University of Science and Technology; Department of Computer Science, Hong Kong Baptist University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16319/16319-13-19813-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02207-hierarchical-information-passing-based-noise-tolerant-hybrid-learning-for-semi-supervised-human-parsing/",
        "doi": "10.1609/aaai.v35i3.16319",
        "pdf_size": 1055987
    },
    {
        "id": "13152",
        "title": "Hierarchical Macro Discourse Parsing Based on Topic Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "Hierarchically constructing micro (i.e., intra-sentence or inter-sentence) discourse structure trees using explicit boundaries (e.g., sentence and paragraph boundaries) has been proved to be an effective strategy. However, it is difficult to apply this strategy to document-level macro (i.e., inter-paragraph) discourse parsing, the more challenging task, due to the lack of explicit boundaries at the higher level. To alleviate this issue, we introduce a topic segmentation mechanism to detect implicit topic boundaries and then help the document-level macro discourse parser to construct better discourse trees hierarchically. In particular, our parser first splits a document into several sections using the topic boundaries that the topic segmentation detects. Then it builds a smaller and more accurate discourse sub-tree in each section and sequentially forms a whole tree for a document. The experimental results on both Chinese MCDTB and English RST-DT show that our proposed method outperforms the state-of-the-art baselines significantly.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Feng Jiang; Yaxin Fan; Xiaomin Chu; Peifeng Li; Qiaoming Zhu; Fang Kong",
        "authorids": "",
        "aff": "Soochow University; Soochow University; Soochow University; Soochow University; Soochow University; Soochow University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17554/17554-13-21048-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13152-hierarchical-macro-discourse-parsing-based-on-topic-segmentation/",
        "doi": "10.1609/aaai.v35i14.17554",
        "pdf_size": 218068
    },
    {
        "id": "08671",
        "title": "Hierarchical Multiple Kernel Clustering",
        "track": "main",
        "status": "Poster",
        "abstract": "Current multiple kernel clustering algorithms compute a partition with the consensus kernel or graph learned from the pre-specified ones, while the emerging late fusion methods firstly construct multiple partitions from each kernel separately, and then obtain a consensus one with them. However, both of them directly distill the clustering information from kernels or graphs to partition matrices, where the sudden dimension drop would result in loss of advantageous details for clustering. In this paper, we provide a brief insight  of the aforementioned issue and propose a hierarchical approach to perform clustering while preserving advantageous details maximumly. Specifically, we gradually group samples into fewer clusters, together with generating a sequence of intermediary matrices of descending sizes. The consensus partition with is simultaneously learned and conversely guides the construction of intermediary matrices. Nevertheless, this cyclic process is modeled into an unified objective and an alternative algorithm is designed to solve it. In addition, the proposed method is validated and compared with other representative multiple kernel clustering algorithms on benchmark datasets, demonstrating state-of-the-art performance by a large margin.",
        "primary_area": "Machine Learning III",
        "author": "Jiyuan Liu; Xinwang Liu; Siwei Wang; Sihang Zhou; Yuexiang Yang",
        "authorids": "",
        "aff": "National University of Defense Technology; National University of Defense Technology; National University of Defense Technology; National University of Defense Technology; National University of Defense Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17051/17051-13-20545-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08671-hierarchical-multiple-kernel-clustering/",
        "doi": "10.1609/aaai.v35i10.17051",
        "pdf_size": 1744773
    },
    {
        "id": "04181",
        "title": "Hierarchical Negative Binomial Factorization for Recommender Systems on Implicit Feedback",
        "track": "main",
        "status": "Poster",
        "abstract": "When exposed to an item in a recommender system, a user may consume it (known as success exposure) or neglect it (known as failure exposure). The recently proposed methods that consider both success and failure exposure merely regard failure exposure as a constant prior, thus being capable of neither modeling various user behavior nor adapting to overdispersed data. In this paper, we propose a novel model, hierarchical negative binomial factorization, which models data dispersion via a hierarchical Bayesian structure, thus alleviating the effect of data overdispersion to help with performance gain for recommendation. Moreover, we factorize the dispersion of zero entries approximately into two low-rank matrices, thus reducing the updating time linear to the number of nonzero entries. The experiment shows that the proposed model outperforms state-of-the-art Poisson-based methods merely with a slight loss of inference speed.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Li-Yen Kuo; Ming-Syan Chen",
        "authorids": "",
        "aff": "National Taiwan University; National Taiwan University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16541/16541-13-20035-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04181-hierarchical-negative-binomial-factorization-for-recommender-systems-on-implicit-feedback/",
        "doi": "10.1609/aaai.v35i5.16541",
        "pdf_size": 261685
    },
    {
        "id": "04521",
        "title": "Hierarchical Reinforcement Learning for Integrated Recommendation",
        "track": "main",
        "status": "Poster",
        "abstract": "Integrated recommendation aims to jointly recommend heterogeneous items in the main feed from different sources via multiple channels, which needs to capture user preferences on both item and channel levels. It has been widely used in practical systems by billions of users, while few works concentrate on the integrated recommendation systematically. In this work, we propose a novel Hierarchical reinforcement learning framework for integrated recommendation (HRL-Rec), which divides the integrated recommendation into two tasks to recommend channels and items sequentially. The low-level agent is a channel selector, which generates a personalized channel list. The high-level agent is an item recommender, which recommends specific items from heterogeneous channels under the channel constraints. We design various rewards for both recommendation accuracy and diversity,  and propose four losses for fast and stable model convergence. We also conduct an online exploration for sufficient training. In experiments, we conduct extensive offline and online experiments on a billion-level real-world dataset to show the effectiveness of HRL-Rec. HRL-Rec has also been deployed on WeChat Top Stories, affecting millions of users. The source codes are released in https://github.com/modriczhang/HRL-Rec.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Ruobing Xie; Shaoliang Zhang; Rui Wang; Feng Xia; Leyu Lin",
        "authorids": "",
        "aff": "WeChat Search Application Department, Tencent; WeChat Search Application Department, Tencent; WeChat Search Application Department, Tencent; WeChat Search Application Department, Tencent; WeChat Search Application Department, Tencent",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16580/16580-13-20074-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04521-hierarchical-reinforcement-learning-for-integrated-recommendation/",
        "doi": "10.1609/aaai.v35i5.16580",
        "pdf_size": 536224
    },
    {
        "id": "09730",
        "title": "Hierarchical Relational Inference",
        "track": "main",
        "status": "Poster",
        "abstract": "Common-sense physical reasoning in the real world requires learning about the interactions of objects and their dynamics. The notion of an abstract object, however, encompasses a wide variety of physical objects that differ greatly in terms of the complex behaviors they support. To address this, we propose a novel approach to physical reasoning that models objects as hierarchies of parts that may locally behave separately, but also act more globally as a single whole. Unlike prior approaches, our method learns in an unsupervised fashion directly from raw visual images to discover objects, parts, and their relations. It explicitly distinguishes multiple levels of abstraction and improves over a strong baseline at modeling synthetic and real-world videos.",
        "primary_area": "Machine Learning IV",
        "author": "Aleksandar Stani\u0107; Sjoerd van Steenkiste; J\u00fcrgen Schmidhuber",
        "authorids": "",
        "aff": "IDSIA; IDSIA; IDSIA",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17170/17170-13-20664-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09730-hierarchical-relational-inference/",
        "doi": "10.1609/aaai.v35i11.17170",
        "pdf_size": 500339
    },
    {
        "id": "00669",
        "title": "Hierarchically and Cooperatively Learning Traffic Signal Control",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep reinforcement learning (RL) has been applied to traffic signal control recently and demonstrated superior performance to conventional control methods. However, there are still several challenges we have to address before fully applying deep RL to traffic signal control. Firstly, the objective of traffic signal control is to optimize average travel time, which is a delayed reward in a long time horizon in the context of RL. However, existing work simplifies the optimization by using queue length, waiting time, delay, etc., as immediate reward and presumes these short-term targets are always aligned with the objective. Nevertheless, these targets may deviate from the objective in different road networks with various traffic patterns. Secondly, it remains unsolved how to cooperatively control traffic signals to directly optimize average travel time. To address these challenges, we propose a hierarchical and cooperative reinforcement learning method-HiLight. HiLight enables each agent to learn a high-level policy that optimizes the objective locally by selecting among the sub-policies that respectively optimize short-term targets. Moreover, the high-level policy additionally considers the objective in the neighborhood with adaptive weighting to encourage agents to cooperate on the objective in the road network. Empirically, we demonstrate that HiLight outperforms state-of-the-art RL methods for traffic signal control in real road networks with real traffic.",
        "primary_area": "Application Domains",
        "author": "Bingyu Xu; Yaowei Wang; Zhaozhi Wang; Huizhu Jia; Zongqing Lu",
        "authorids": "",
        "aff": "Peng Cheng Laboratory; Peng Cheng Laboratory; Peking University; Peking University; Peking University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16147/16147-13-19641-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00669-hierarchically-and-cooperatively-learning-traffic-signal-control/",
        "doi": "10.1609/aaai.v35i1.16147",
        "pdf_size": 3000025
    },
    {
        "id": "12095",
        "title": "High Dimensional Level Set Estimation with Bayesian Neural Network",
        "track": "main",
        "status": "Poster",
        "abstract": "Level Set Estimation (LSE) is an important problem with applications in various fields such as material design, biotechnology, machine operational testing, etc. Existing techniques suffer from the scalability issue, that is, these methods do not work well with high dimensional inputs. This paper proposes novel methods to solve the high dimensional LSE problems using Bayesian Neural Networks. In particular, we consider two types of LSE problems: (1) explicit LSE problem where the threshold level is a fixed user-specified value, and, (2) implicit LSE problem where the threshold level is defined as a percentage of the (unknown) maximum of the objective function. For each problem, we derive the corresponding theoretic information based acquisition function to sample the data points so as to maximally increase the level set accuracy. Furthermore, we also analyse theoretical time complexity of our proposed acquisition functions, and suggest a practical methodology to efficiently tune the network hyper-parameters to achieve high model accuracy. Numerical experiments on both synthetic and real-world datasets show that our proposed methods can achieve better results compared to existing state-of-the-art approaches.",
        "primary_area": "Reasoning under Uncertainty",
        "author": "Huong Ha; Sunil Gupta; Santu Rana; Svetha Venkatesh",
        "authorids": "",
        "aff": "Deakin University, Australia; Deakin University, Australia; Deakin University, Australia; Deakin University, Australia",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17436/17436-13-20930-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12095-high-dimensional-level-set-estimation-with-bayesian-neural-network/",
        "doi": "10.1609/aaai.v35i13.17436",
        "pdf_size": 476081
    },
    {
        "id": "08366",
        "title": "High Fidelity GAN Inversion via Prior Multi-Subspace Feature Composition",
        "track": "main",
        "status": "Poster",
        "abstract": "Generative Adversarial Networks (GANs) have shown impressive gains in image synthesis. GAN inversion was recently studied to understand and utilize the knowledge it learns, where a real image is inverted back to a latent code and can thus be reconstructed by the generator. Although increasing the number of latent codes can improve inversion quality to a certain extent, we find that important details may still be neglected when performing feature composition over all the intermediate feature channels. To address this issue, we propose a Prior multi-Subspace Feature Composition (PmSFC) approach for high-fidelity inversion. Considering that the intermediate features are highly correlated with each other, we incorporate a self-expressive layer in the generator to discover meaningful subspaces. In this case, the features at a channel can be expressed as a linear combination of those at other channels in the same subspace. We perform feature composition separately in the subspaces. The semantic differences between them benefit the inversion quality, since the inversion process is regularized based on different aspects of semantics. In the experiments, the superior performance of PmSFC demonstrates the effectiveness of prior subspaces in facilitating GAN inversion together with extended applications in visual manipulation.",
        "primary_area": "Machine Learning II",
        "author": "Guanyue Li; Qianfen Jiao; Sheng Qian; Si Wu; Hau-San Wong",
        "authorids": "",
        "aff": "South China University of Technology; City University of Hong Kong; Huawei Device Company Limited; South China University of Technology City University of Hong Kong; City University of Hong Kong",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17017/17017-13-20511-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08366-high-fidelity-gan-inversion-via-prior-multi-subspace-feature-composition/",
        "doi": "10.1609/aaai.v35i9.17017",
        "pdf_size": 3634409
    },
    {
        "id": "06939",
        "title": "High-Confidence Off-Policy (or Counterfactual) Variance Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Many sequential decision-making systems leverage data collected using prior policies to propose a new policy. For critical applications, it is important that high-confidence guarantees on the new policy\u2019s behavior are provided before deployment, to ensure that the policy will behave as desired. Prior works have studied high-confidence off-policy estimation of the expected return, however, high-confidence off-policy estimation of the variance of returns can be equally critical for high-risk applications. In this paper we tackle the previously open problem of estimating and bounding, with high confidence, the variance of returns from off-policy data.",
        "primary_area": "Machine Learning I",
        "author": "Yash Chandak; Shiv Shankar; Philip S. Thomas",
        "authorids": "",
        "aff": "University of Massachusetts; University of Massachusetts; University of Massachusetts",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16855/16855-13-20349-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06939-high-confidence-off-policy-or-counterfactual-variance-estimation/",
        "doi": "10.1609/aaai.v35i8.16855",
        "pdf_size": 376427
    },
    {
        "id": "07630",
        "title": "High-Dimensional Bayesian Optimization via Tree-Structured Additive Models",
        "track": "main",
        "status": "Poster",
        "abstract": "Bayesian Optimization (BO) has shown significant success in tackling expensive low-dimensional black-box optimization problems. Many optimization problems of interest are high-dimensional, and scaling BO to such settings remains an important challenge. In this paper, we consider generalized additive models in which low-dimensional functions with overlapping subsets of variables are composed to model a high-dimensional target function. Our goal is to lower the computational resources required and facilitate faster model learning by reducing the model complexity while retaining the sample-efficiency of existing methods. Specifically, we constrain the underlying dependency graphs to tree structures in order to facilitate both the structure learning and optimization of the acquisition function. For the former, we propose a hybrid graph learning algorithm based on Gibbs sampling and mutation. In addition, we propose a novel zooming-based algorithm that permits generalized additive models to be employed more efficiently in the case of continuous domains. We demonstrate and discuss the efficacy of our approach via a range of experiments on synthetic functions and real-world datasets.",
        "primary_area": "Machine Learning II",
        "author": "Eric Han; Ishank Arora; Jonathan Scarlett",
        "authorids": "",
        "aff": "School of Computing, National University of Singapore; Indian Institute of Technology (BHU) Varanasi; School of Computing, National University of Singapore Department of Mathematics & Institute of Data Science, National University of Singapore",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16933/16933-13-20427-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07630-high-dimensional-bayesian-optimization-via-tree-structured-additive-models/",
        "doi": "10.1609/aaai.v35i9.16933",
        "pdf_size": 437298
    },
    {
        "id": "03217",
        "title": "High-Resolution Deep Image Matting",
        "track": "main",
        "status": "Poster",
        "abstract": "Image matting is a key technique for image and video editing and composition. Conventionally, deep learning approaches take the whole input image and an associated trimap to infer the alpha matte using convolutional neural networks. Such approaches set state-of-the-arts in image matting; however, they may fail in real-world matting applications due to hardware limitations, since real-world input images for matting are mostly of very high resolution. In this paper, we propose HDMatt, a first deep learning based image matting approach for high-resolution inputs. More concretely, HDMatt runs matting in a patch-based crop-and-stitch manner for high-resolution inputs with a novel module design to address the contextual dependency and consistency issues between different patches. Compared with vanilla patch-based inference which computes each patch independently, we explicitly model the cross-patch contextual dependency with a newly-proposed Cross-Patch Contextual module (CPC) guided by the given trimap. Extensive experiments demonstrate the effectiveness of the proposed method and its necessity for high-resolution inputs. Our HDMatt approach also sets new state-of-the-art performance on Adobe Image Matting and AlphaMatting benchmarks and produce impressive visual results on more real-world high-resolution images.",
        "primary_area": "Computer Vision III",
        "author": "Haichao Yu; Ning Xu; Zilong Huang; Yuqian Zhou; Humphrey Shi",
        "authorids": "",
        "aff": "UIUC; Adobe Research; UIUC; UIUC; U of Oregon UIUC",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16432/16432-13-19926-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03217-high-resolution-deep-image-matting/",
        "doi": "10.1609/aaai.v35i4.16432",
        "pdf_size": 8053283
    },
    {
        "id": "05584",
        "title": "Hindsight and Sequential Rationality of Correlated Play",
        "track": "main",
        "status": "Poster",
        "abstract": "Driven by recent successes in two-player, zero-sum game solving and playing, artificial intelligence work on games has increasingly focused on algorithms that produce equilibrium-based strategies. However, this approach has been less effective at producing competent players in general-sum games or those with more than two players than in two-player, zero-sum games. An appealing alternative is to consider adaptive algorithms that ensure strong performance in hindsight relative to what could have been achieved with modified behavior. This approach also leads to a game-theoretic analysis, but in the correlated play that arises from joint learning dynamics rather than factored agent behavior at equilibrium. We develop and advocate for this hindsight rationality framing of learning in general sequential decision-making settings. To this end, we re-examine mediated equilibrium and deviation types in extensive-form games, thereby gaining a more complete understanding and resolving past misconceptions. We present a set of examples illustrating the distinct strengths and weaknesses of each type of equilibrium in the literature, and prove that no tractable concept subsumes all others. This line of inquiry culminates in the definition of the deviation and equilibrium classes that correspond to algorithms in the counterfactual regret minimization (CFR) family, relating them to all others in the literature. Examining CFR in greater detail further leads to a new recursive definition of rationality in correlated play that extends sequential rationality in a way that naturally applies to hindsight evaluation.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Dustin Morrill; Ryan D'Orazio; Reca Sarfati; Marc Lanctot; James R Wright; Amy R Greenwald; Michael Bowling",
        "authorids": "",
        "aff": "University of Alberta Alberta Machine Intelligence Institute; Universit\u00e9 de Montr\u00e9al Mila; Massachusetts Institute of Technology; DeepMind; University of Alberta; Brown University; University of Alberta Alberta Machine Intelligence Institute DeepMind",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16702/16702-13-20196-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05584-hindsight-and-sequential-rationality-of-correlated-play/",
        "doi": "10.1609/aaai.v35i6.16702",
        "pdf_size": 245841
    },
    {
        "id": "02870",
        "title": "Holistic Multi-View Building Analysis in the Wild with Projection Pooling",
        "track": "main",
        "status": "Poster",
        "abstract": "We address six different classification tasks related to fine-grained building attributes: construction type, number of floors, pitch and geometry of the roof, facade material, and occupancy class. Tackling such a remote building analysis problem became possible only recently due to growing large-scale datasets of urban scenes. To this end, we introduce a new benchmarking dataset, consisting of 49426 images (top-view and street-view) of 9674 buildings. These photos are further assembled, together with the geometric metadata. The dataset showcases various real-world challenges, such as occlusions, blur, partially visible objects, and a broad spectrum of buildings. We propose a new emph{projection pooling layer}, creating a unified, top-view representation of the top-view and the side views in a high-dimensional space. It allows us to utilize the building and imagery metadata seamlessly. Introducing this layer improves classification accuracy -- compared to highly tuned baseline models -- indicating its suitability for building analysis.",
        "primary_area": "Computer Vision III",
        "author": "Zbigniew Wojna; Krzysztof Maziarz; \u0141ukasz Jocz; Robert Pa\u0142uba; Robert Kozikowski; Iason Kokkinos",
        "authorids": "",
        "aff": "Tensorflight University College London; Jagiellonian University; Tensorflight; Tensorflight; Tensorflight; University College London",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16393/16393-13-19887-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02870-holistic-multi-view-building-analysis-in-the-wild-with-projection-pooling/",
        "doi": "10.1609/aaai.v35i4.16393",
        "pdf_size": 2679180
    },
    {
        "id": "13279",
        "title": "HopRetriever: Retrieve Hops over Wikipedia to Answer Complex Questions",
        "track": "main",
        "status": "Poster",
        "abstract": "Collecting supporting evidence from large corpora of text (e.g., Wikipedia) is of great challenge for open-domain Question Answering (QA). Especially, for multi-hop open-domain QA, scattered evidence pieces are required to be gathered together to support the answer extraction. In this paper, we propose a new retrieval target, hop, to collect the hidden reasoning evidence from Wikipedia for complex question answering. Specifically, the hop in this paper is defined as the combination of a hyperlink and the corresponding outbound link document. The hyperlink is encoded as the mention embedding which models the structured knowledge of how the outbound link entity is mentioned in the textual context, and the corresponding outbound link document is encoded as the document embedding representing the unstructured knowledge within it. Accordingly, we build HopRetriever which retrieves hops over Wikipedia to answer complex questions. Experiments on the HotpotQA dataset demonstrate that HopRetriever outperforms previously published evidence retrieval methods by large margins. Moreover, our approach also yields quantifiable interpretations of the evidence collection process.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Shaobo Li; Xiaoguang Li; Lifeng Shang; Xin Jiang; Qun Liu; Chengjie Sun; Zhenzhou Ji; Bingquan Liu",
        "authorids": "",
        "aff": "Harbin Institute of Technology; Huawei Noah's Ark Lab; Huawei Noah's Ark Lab; Huawei Noah's Ark Lab; Huawei Noah's Ark Lab; Harbin Institute of Technology; Harbin Institute of Technology; Harbin Institute of Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17568/17568-13-21062-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13279-hopretriever-retrieve-hops-over-wikipedia-to-answer-complex-questions/",
        "doi": "10.1609/aaai.v35i15.17568",
        "pdf_size": 358479
    },
    {
        "id": "04445",
        "title": "How Do We Move: Modeling Human Movement with System Dynamics",
        "track": "main",
        "status": "Poster",
        "abstract": "Modeling how human moves in the space is useful for policy-making in transportation, public safety, and public health. The human movements can be viewed as a dynamic process that human transits between states (e.g., locations) over time. In the human world where intelligent agents like humans or vehicles with human drivers play an important role, the states of agents mostly describe human activities, and the state transition is influenced by both the human decisions and physical constraints from the real-world system (e.g., agents need to spend time to move over a certain distance). Therefore, the modeling of state transition should include the modeling of the agent's decision process and the physical system dynamics.  In this paper, we propose MoveSD to model state transition in human movement from a novel perspective, by learning the decision model and integrating the system dynamics. MoveSD learns the human movement with Generative Adversarial Imitation Learning and integrates the stochastic constraints from system dynamics in the learning process. To the best of our knowledge, we are the first to learn to model the state transition of moving agents with system dynamics. In extensive experiments on real-world datasets, we demonstrate that the proposed method can generate trajectories similar to real-world ones, and outperform the state-of-the-art methods in predicting the next location and generating long-term future trajectories.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Hua Wei; Dongkuan Xu; Junjie Liang; Zhenhui (Jessie) Li",
        "authorids": "",
        "aff": "College of Information Sciences and Technology, The Pennsylvania State University; College of Information Sciences and Technology, The Pennsylvania State University; College of Information Sciences and Technology, The Pennsylvania State University; College of Information Sciences and Technology, The Pennsylvania State University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16571/16571-13-20065-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04445-how-do-we-move-modeling-human-movement-with-system-dynamics/",
        "doi": "10.1609/aaai.v35i5.16571",
        "pdf_size": 1964063
    },
    {
        "id": "10746",
        "title": "How Does Data Augmentation Affect Privacy in Machine Learning?",
        "track": "main",
        "status": "Poster",
        "abstract": "It is observed in the literature that data augmentation can significantly mitigate membership inference (MI) attack. However, in this work, we challenge this observation by proposing new MI attacks to utilize the information of augmented data.  MI attack  is widely used to measure the model's information leakage of the training set. We establish the optimal membership inference when the model is trained with augmented data, which inspires us to formulate the MI attack  as a set classification problem, i.e., classifying a set of augmented instances instead of a single data point, and design input permutation invariant features. Empirically, we demonstrate that the proposed approach universally outperforms original methods when the model is trained with data augmentation. Even further, we show that the proposed approach  can achieve higher MI attack success rates on models trained with some data augmentation than the existing methods on  models trained without data augmentation. Notably, we achieve a 70.1% MI attack success rate on CIFAR10 against a wide residual network while the previous best approach only attains 61.9%. This suggests the privacy risk of models trained with data augmentation could be largely underestimated.",
        "primary_area": "Machine Learning V",
        "author": "Da Yu; Huishuai Zhang; Wei Chen; Jian Yin; Tie-Yan Liu",
        "authorids": "",
        "aff": "Sun Yat-sen University; Microsoft Research; Microsoft Research; Sun Yat-Sen University; Microsoft Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17284/17284-13-20778-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10746-how-does-data-augmentation-affect-privacy-in-machine-learning/",
        "doi": "10.1609/aaai.v35i12.17284",
        "pdf_size": 2063619
    },
    {
        "id": "11079",
        "title": "How Does the Combined Risk Affect the Performance of Unsupervised Domain Adaptation Approaches?",
        "track": "main",
        "status": "Poster",
        "abstract": "Unsupervised domain adaptation (UDA) aims to train a target classifier with labeled samples from the source domain and unlabeled samples from the target domain. Classical UDA learning bounds show that target risk is upper bounded by three terms: source risk, distribution discrepancy, and combined risk. Based on the assumption that the combined risk is a small fixed value, methods based on this bound train a target classifier by only minimizing estimators of the source risk and the distribution discrepancy. However, the combined risk may increase when minimizing both estimators, which makes the target risk uncontrollable. Hence the target classifier cannot achieve ideal performance if we fail to control the combined risk. To control the combined risk, the key challenge takes root in the unavailability of the labeled samples in the target domain. To address this key challenge, we propose a method named E-MixNet. E-MixNet employs enhanced mixup, a generic vicinal distribution, on the labeled source samples and pseudo-labeled target samples to calculate a proxy of the combined risk. Experiments show that the proxy can effectively curb the increase of the combined risk when minimizing the source risk and distribution discrepancy. Furthermore, we show that if the proxy of the combined risk is added into loss functions of four representative UDA methods, their performance is also improved.",
        "primary_area": "Machine Learning V",
        "author": "Li Zhong; Zhen Fang; Feng Liu; Jie Lu; Bo Yuan; Guangquan Zhang",
        "authorids": "",
        "aff": "Tsinghua University University of Technology Sydney; University of Technology Sydney; University of Technology Sydney; University of Technology Sydney; Tsinghua University; University of Technology Sydney",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17322/17322-13-20816-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11079-how-does-the-combined-risk-affect-the-performance-of-unsupervised-domain-adaptation-approaches/",
        "doi": "10.1609/aaai.v35i12.17322",
        "pdf_size": 435896
    },
    {
        "id": "12710",
        "title": "How Linguistically Fair Are Multilingual Pre-Trained Language Models?",
        "track": "main",
        "status": "Poster",
        "abstract": "Massively multilingual pre-trained language models, such as mBERT and XLM-RoBERTa, have received significant attention in the recent NLP literature for their excellent capability towards crosslingual zero-shot transfer of NLP tasks. This is especially promising because a large number of languages have no or very little labeled data for supervised learning. Moreover, a substantially improved performance on low resource languages without any significant degradation of accuracy for high resource languages lead us to believe that these models will help attain a fairer distribution of language technologies despite the prevalent unfair and extremely skewed distribution of resources across the world\u2019s languages.  Nevertheless, these models, and the experimental approaches adopted by the researchers to arrive at those, have been criticised by some for lacking a nuanced and thorough comparison of benefits across languages and tasks. A related and important question that has received little attention is how to choose from a set of models, when no single model significantly outperforms the others on all tasks and languages. As we discuss in this paper, this is often the case, and the choices are usually made without a clear articulation of reasons or underlying fairness assumptions. In this work, we scrutinize the choices made in previous work, and propose a few different strategies for fair and efficient model selection based on the principles of fairness in economics and social choice theory. In particular, we emphasize Rawlsian fairness, which provides an appropriate framework for making fair (with respect to languages, or tasks, or both) choices while selecting multilingual pre-trained language models for a practical or scientific set-up.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Monojit Choudhury; Amit Deshpande",
        "authorids": "",
        "aff": "Microsoft Research Lab India; Microsoft Research Lab India",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17505/17505-13-20999-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12710-how-linguistically-fair-are-multilingual-pre-trained-language-models/",
        "doi": "10.1609/aaai.v35i14.17505",
        "pdf_size": 131360
    },
    {
        "id": "11586",
        "title": "How RL Agents Behave When Their Actions Are Modified",
        "track": "main",
        "status": "Poster",
        "abstract": "Reinforcement learning in complex environments may require supervision to prevent the agent from attempting dangerous actions. As a result of supervisor intervention, the executed action may differ from the action specified by the policy. How does this affect learning? We present the Modified-Action Markov Decision Process, an extension of the MDP model that allows actions to differ from the policy. We analyze the asymptotic behaviours of common reinforcement learning algorithms in this setting and show that they adapt in different ways: some completely ignore modifications while others go to various lengths in trying to avoid action modifications that decrease reward. By choosing the right algorithm, developers can prevent their agents from learning to circumvent interruptions or constraints, and better control agent responses to other kinds of action modification, like self-damage.",
        "primary_area": "Philosophy and Ethics of AI",
        "author": "Eric D. Langlois; Tom Everitt",
        "authorids": "",
        "aff": "University of Toronto Vector Institute DeepMind; DeepMind",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17378/17378-13-20872-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11586-how-rl-agents-behave-when-their-actions-are-modified/",
        "doi": "10.1609/aaai.v35i13.17378",
        "pdf_size": 1353599
    },
    {
        "id": "13561",
        "title": "How Robust are Model Rankings : A Leaderboard Customization Approach for Equitable Evaluation",
        "track": "main",
        "status": "Poster",
        "abstract": "Models that top leaderboards often perform unsatisfactorily when deployed in real world applications; this has necessitated rigorous and expensive pre-deployment model testing. A hitherto unexplored facet of model performance is: Are our leaderboards doing equitable evaluation? In this paper, we introduce a task-agnostic method to probe leaderboards by weighting samples based on their 'difficulty' level. We find that leaderboards can be adversarially attacked and top performing models may not always be the best models. We subsequently propose alternate evaluation metrics. Our experiments on 10 models show changes in model ranking and an overall reduction in previously reported performance- thus rectifying the overestimation of AI systems' capabilities. Inspired by behavioral testing principles, we further develop a prototype of a visual analytics tool that enables leaderboard revamping through customization, based on an end user's focus area. This helps users analyze models' strengths and weaknesses, and guides them in the selection of a model best suited for their application scenario. In a user study, members of various commercial product development teams, covering 5 focus areas, find that our prototype reduces pre-deployment development and testing effort by 41% on average.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Swaroop Mishra; Anjana Arunkumar",
        "authorids": "",
        "aff": "Arizona State University; Arizona State University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17599/17599-13-21093-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13561-how-robust-are-model-rankings-a-leaderboard-customization-approach-for-equitable-evaluation/",
        "doi": "10.1609/aaai.v35i15.17599",
        "pdf_size": 4972911
    },
    {
        "id": "01282",
        "title": "How to Save your Annotation Cost for Panoptic Segmentation?",
        "track": "main",
        "status": "Poster",
        "abstract": "How to properly reduce the annotation cost for panoptic segmentation? How to leverage and optimize the cost-quality trade-off for training data and model? These questions are key challenges towards a label-efficient and scalable panoptic segmentation system due to its expensive instance/semantic pixel-level annotation requirements. By closely examining different kinds of cheaper labels, we introduce a novel multi-objective framework to automatically determine the allocation of different annotations, so as to reach a better segmentation quality with a lower annotation cost. Specifically, we design a Cost-Quality Balanced Network (CQB-Net) to generate the panoptic segmentation map, which distills the crucial relations between various supervisions including panoptic labels, image-level classification labels, bounding boxes, and the semantic coherence information between the foreground and background. Instead of ad-hoc allocation during training, we formulate the optimization of cost-quality trade-off as a Multi-Objective Optimization Problem (MOOP). We model the marginal quality improvement of each annotation and approximate the Pareto-front to enable a label-efficient allocation ratio. Extensive experiments on COCO benchmark show the superiority of our method, e.g. achieving a segmentation quality of 43.4% compared to 43.0% of OCFusion while saving 2.4x annotation cost.",
        "primary_area": "Computer Vision I",
        "author": "Xuefeng Du; ChenHan Jiang; Hang Xu; Gengwei Zhang; Zhenguo Li",
        "authorids": "",
        "aff": "Xi'an Jiaotong University; Huawei Noah's Ark Lab; Huawei Noah's Ark Lab; Sun Yat-Sen University; Huawei Noah's Ark Lab",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16216/16216-13-19710-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01282-how-to-save-your-annotation-cost-for-panoptic-segmentation/",
        "doi": "10.1609/aaai.v35i2.16216",
        "pdf_size": 1123452
    },
    {
        "id": "13397",
        "title": "How to Train Your Agent to Read and Write",
        "track": "main",
        "status": "Poster",
        "abstract": "Reading and writing research papers is one of the most privileged abilities that a qualified researcher should master. However, it is difficult for new researchers (e.g., students) to fully grasp this ability. It would be fascinating if we could train an intelligent agent to help people read and summarize papers, and perhaps even discover and exploit the potential knowledge clues to write novel papers. Although there have been existing works focusing on summarizing (i.e., reading) the knowledge in a given text or generating (i.e., writing) a text based on the given knowledge, the ability of simultaneously reading and writing is still under development. Typically, this requires an agent to fully understand the knowledge from the given text materials and generate correct and fluent novel paragraphs, which is very challenging in practice. In this paper, we propose a Deep ReAder-Writer (DRAW) network, which consists of a Reader that can extract knowledge graphs (KGs) from input paragraphs and discover potential knowledge, a graph-to-text Writer that generates a novel paragraph, and a Reviewer that reviews the generated paragraph from three different aspects. Extensive experiments show that our DRAW network outperforms considered baselines and several state-of-the-art methods on AGENDA and M-AGENDA datasets. Our code and supplementary are released at https://github.com/menggehe/DRAW.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Li Liu; Mengge He; Guanghui Xu; Mingkui Tan; Qi Wu",
        "authorids": "",
        "aff": "South China University of Technology Pazhou Laboratory; South China University of Technology; South China University of Technology; South China University of Technology Key Laboratory of Big Data and Intelligent Robot, Ministry of Education; University of Adelaide",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17581/17581-13-21075-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13397-how-to-train-your-agent-to-read-and-write/",
        "doi": "10.1609/aaai.v35i15.17581",
        "pdf_size": 509717
    },
    {
        "id": "05877",
        "title": "Human Uncertainty Inference via Deterministic Ensemble Neural Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "The estimation and inference of human predictive uncertainty have great potential to improve the sampling efficiency and prediction reliability of human-in-the-loop systems for smart healthcare, smart education, and human-computer interactions. Predictive uncertainty in humans is highly interpretable, but its measurement is poorly accessible. Contrarily, the predictive uncertainty of machine learning models, albeit with poor interpretability, is relatively easily accessible. Here, we demonstrate that the poor accessibility of human uncertainty can be resolved by exploiting simple and universally accessible deterministic neural networks. We propose a new model for human uncertainty inference, called proxy ensemble network (PEN). Simulations with a few benchmark datasets demonstrated that the model can efficiently learn human uncertainty from a small amount of data. To show its applicability in real-world problems, we performed behavioral experiments, in which 64 physicians classified medical images and reported their level of confidence. We showed that the PEN could predict both the uncertainty range and diagnoses given by subjects with high accuracy. Our results demonstrate the ability of machine learning in guiding human decision making; it can also help humans in learning more efficiently and accurately. To the best of our knowledge, this is the first study that explored the possibility of accessing human uncertainty via the lens of deterministic neural networks.",
        "primary_area": "Humans and AI",
        "author": "Yujin Cha; Sang Wan Lee",
        "authorids": "",
        "aff": "Department of Bio and Brain Engineering, Korea Advanced Institute of Science and Technology (KAIST); Department of Bio and Brain Engineering, Korea Advanced Institute of Science and Technology (KAIST) Program of Brain and Cognitive Engineering, Korea Advanced Institute of Science and Technology (KAIST) Center for Neuroscience-inspired Artificial Intelligence, Korea Advanced Institute of Science and Technology (KAIST)",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16735/16735-13-20229-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05877-human-uncertainty-inference-via-deterministic-ensemble-neural-networks/",
        "doi": "10.1609/aaai.v35i7.16735",
        "pdf_size": 5107097
    },
    {
        "id": "14203",
        "title": "Human-Level Interpretable Learning for Aspect-Based Sentiment Analysis",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes human-interpretable learning of aspect-based sentiment analysis (ABSA), employing the recently introduced Tsetlin Machines (TMs). We attain interpretability by converting the intricate position-dependent textual semantics into binary form, mapping all the features into bag-of-words (BOWs). The binary form BOWs are encoded so that the information on the aspect and context words are nearly lossless for sentiment classification. We further adapt the BOWs as input to the TM, enabling learning of aspect-based sentiment patterns in propositional logic. To evaluate interpretability and accuracy, we conducted experiments on two widely used ABSA datasets of SemEval 2014: Restaurant 14 and Laptop 14. The experiments show how each relevant feature takes part in conjunctive clauses that contain the context information for the corresponding aspect word, demonstrating human-level interpretability. At the same time, the obtained accuracy is competitive with existing neural network models, reaching 78.02% on Restaurant 14 and 73.51% on Laptop 14.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Rohan K Yadav; Lei Jiao; Ole-Christoffer Granmo; Morten Goodwin",
        "authorids": "",
        "aff": "University of Agder; University of Agder; University of Agder; University of Agder",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17671/17671-13-21165-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14203-human-level-interpretable-learning-for-aspect-based-sentiment-analysis/",
        "doi": "10.1609/aaai.v35i16.17671",
        "pdf_size": 885314
    },
    {
        "id": "12972",
        "title": "Humor Knowledge Enriched Transformer for Understanding Multimodal Humor",
        "track": "main",
        "status": "Poster",
        "abstract": "Recognizing humor from a video utterance requires understanding the verbal and non-verbal components as well as incorporating the appropriate context and external knowledge. In this paper, we propose Humor Knowledge enriched Transformer (HKT) that can capture the gist of a multimodal humorous expression by integrating the preceding context and external knowledge. We incorporate humor centric external knowledge into the model by capturing the ambiguity and sentiment present in the language. We encode all the language, acoustic, vision, and humor centric features separately using Transformer based encoders, followed by a cross attention layer to exchange information among them. Our model achieves 77.36% and 79.41% accuracy in humorous punchline detection on UR-FUNNY and MUStaRD datasets -- achieving a new state-of-the-art on both datasets with the margin of 4.93% and 2.94% respectively. Furthermore, we demonstrate that our model can capture interpretable, humor-inducing patterns from all modalities.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Md Kamrul Hasan; Sangwu Lee; Wasifur Rahman; Amir Zadeh; Rada Mihalcea; Louis-Philippe Morency; Ehsan Hoque",
        "authorids": "",
        "aff": "Department of Computer Science, University of Rochester, USA; Department of Computer Science, University of Rochester, USA; Department of Computer Science, University of Rochester, USA; Language Technologies Institute, CMU, USA; Computer Science & Engineering, University of Michigan, USA; Language Technologies Institute, CMU, USA; Department of Computer Science, University of Rochester, USA",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17534/17534-13-21028-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12972-humor-knowledge-enriched-transformer-for-understanding-multimodal-humor/",
        "doi": "10.1609/aaai.v35i14.17534",
        "pdf_size": 423104
    },
    {
        "id": "07081",
        "title": "HyDRA: Hypergradient Data Relevance Analysis for Interpreting Deep Neural Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "The behaviors of deep neural networks (DNNs) are notoriously resistant to human interpretations. In this paper, we propose Hypergradient Data Relevance Analysis, or HyDRA, which interprets the predictions made by DNNs as effects of their training data. Existing approaches generally estimate data contributions around the final model parameters and ignore how the training data shape the optimization trajectory. By unrolling the hypergradient of test loss w.r.t. the weights of training data, HyDRA assesses the contribution of training data toward test data points throughout the training trajectory. In order to accelerate computation, we remove the Hessian from the calculation and prove that, under moderate conditions, the approximation error is bounded. Corroborating this theoretical claim, empirical results indicate the error is indeed small. In addition, we quantitatively demonstrate that HyDRA outperforms influence functions in accurately estimating data contribution and detecting noisy data labels. The source code is available at https://github.com/cyyever/aaai_hydra.",
        "primary_area": "Machine Learning I",
        "author": "Yuanyuan Chen; Boyang Li; Han Yu; Pengcheng Wu; Chunyan Miao",
        "authorids": "",
        "aff": "Nanyang Technological University; Nanyang Technological University Alibaba-NTU Singapore Joint Research Institute; Nanyang Technological University; Nanyang Technological University; Nanyang Technological University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16871/16871-13-20365-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07081-hydra-hypergradient-data-relevance-analysis-for-interpreting-deep-neural-networks/",
        "doi": "10.1609/aaai.v35i8.16871",
        "pdf_size": 523162
    },
    {
        "id": "04470",
        "title": "Hybrid-order Stochastic Block Model",
        "track": "main",
        "status": "Poster",
        "abstract": "Community detection is a research hotspot in machine learning and data mining. However, most of the existing community detection methods only rely on the lower-order connectivity patterns, while ignoring the higher-order connectivity patterns, and unable to capture the building blocks of the complex network. In recent years, some community detection methods based on higher-order structures have been developed, but they mainly focus on the motif network composed of higher-order structures, which violate the original lower-order topological structure and are affected by the fragmentation issue, resulting in the deviation of community detection results. Therefore, there is still a lack of community detection methods that can effectively utilize higher-order connectivity patterns and lower-order connectivity patterns. To overcome the above limitations, this paper proposes the Hybrid-order Stochastic Block Model (HSBM) from the perspective of the generative model. Based on the classical stochastic block model, the generation of lower-order structure and higher-order structure of the network is modeled uniformly, and the original topological properties of the network are maintained while using higher-order connectivity patterns. At the same time, a heuristic algorithm for community detection is proposed to optimize the objective function. Extensive experiments on six real-world datasets show that the proposed method outperforms the existing approaches.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Xunxun Wu; Chang-Dong Wang; Pengfei Jiao",
        "authorids": "",
        "aff": "School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China; School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China Guangdong Province Key Laboratory of Computational Science, Guangzhou, China Key Laboratory of Machine Intelligence and Advanced Computing, Ministry of Education, China; Center of Biosafety Research and Strategy, Law school of Tianjin University, Tianjin, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16574/16574-13-20068-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04470-hybrid-order-stochastic-block-model/",
        "doi": "10.1609/aaai.v35i5.16574",
        "pdf_size": 878927
    },
    {
        "id": "04375",
        "title": "Hyperbolic Variational Graph Neural Network for Modeling Dynamic Graphs",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning representations for graphs plays a critical role in a wide spectrum of downstream applications. In this paper, we summarize the limitations of the prior works in three folds: representation space, modeling dynamics and modeling uncertainty. To bridge this gap, we propose to learn dynamic graph representations  in hyperbolic space, for the first time, which aims to infer stochastic node representations. Working with hyperbolic space, we present a novel Hyperbolic Variational Graph Neural Network, referred to as HVGNN. In particular, to model the dynamics, we introduce a Temporal GNN (TGNN) based on a theoretically grounded time encoding approach. To model the uncertainty, we devise a hyperbolic graph variational autoencoder built upon the proposed TGNN to generate stochastic node representations of hyperbolic normal distributions. Furthermore, we introduce a reparameterisable sampling algorithm for the hyperbolic normal distribution to enable the gradient-based learning of HVGNN.  Extensive experiments show that HVGNN outperforms state-of-the-art baselines on real-world datasets.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Li Sun; Zhongbao Zhang; Jiawei Zhang; Feiyang Wang; Hao Peng; Sen Su; Philip  S. Yu",
        "authorids": "",
        "aff": "Beijing University of Posts and Telecommunications; Beijing University of Posts and Telecommunications; Florida State University; Beijing University of Posts and Telecommunications; Beihang University; Beijing University of Posts and Telecommunications; University of Illinois at Chicago",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16563/16563-13-20057-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04375-hyperbolic-variational-graph-neural-network-for-modeling-dynamic-graphs/",
        "doi": "10.1609/aaai.v35i5.16563",
        "pdf_size": 4099645
    },
    {
        "id": "08243",
        "title": "Hypothesis Disparity Regularized Mutual Information Maximization",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a hypothesis disparity regularized mutual information maximization (HDMI) approach to tackle unsupervised hypothesis transfer---as an effort towards unifying hypothesis transfer learning (HTL) and unsupervised domain adaptation (UDA)---where the knowledge from a source domain is transferred solely through hypotheses and adapted to the target domain in an unsupervised manner. In contrast to the prevalent HTL and UDA approaches that typically use a single hypothesis, HDMI employs multiple hypotheses to leverage the underlying distributions of the source and target hypotheses. To better utilize the crucial relationship among different hypotheses---as opposed to unconstrained optimization of each hypothesis independently---while adapting to the unlabeled target domain through mutual information maximization, HDMI incorporates a hypothesis disparity regularization that coordinates the target hypotheses jointly learn better target representations while preserving more transferable source knowledge with better-calibrated prediction uncertainty. HDMI achieves state-of-the-art adaptation performance on benchmark datasets for UDA in the context of HTL, without the need to access the source data during the adaptation.",
        "primary_area": "Machine Learning II",
        "author": "Qicheng Lao; Xiang Jiang; Mohammad Havaei",
        "authorids": "",
        "aff": "West China Biomedical Big Data Center, West China Hospital of Sichuan University Montreal Institute for Learning Algorithms (MILA), Universit\u00e9 de Montr\u00e9al Imagia; Imagia; Imagia",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17003/17003-13-20497-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08243-hypothesis-disparity-regularized-mutual-information-maximization/",
        "doi": "10.1609/aaai.v35i9.17003",
        "pdf_size": 6976493
    },
    {
        "id": "06066",
        "title": "I3DOL: Incremental 3D Object Learning without Catastrophic Forgetting",
        "track": "main",
        "status": "Poster",
        "abstract": "",
        "primary_area": "Intelligent Robots",
        "author": "Jiahua Dong; Yang Cong; Gan Sun; Bingtao Ma; Lichen Wang",
        "authorids": "",
        "aff": "",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16756/16756-13-20250-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06066-i3dol-incremental-3d-object-learning-without-catastrophic-forgetting/"
    },
    {
        "id": "03474",
        "title": "IA-GM: A Deep Bidirectional Learning Method for Graph Matching",
        "track": "main",
        "status": "Poster",
        "abstract": "Existing  deep  learning  methods  for  graph  matching(GM)  problems  usually  considered  affinity  learningto  assist  combinatorial  optimization  in  a feedforward pipeline, and parameter learning is executed by back-propagating the gradients of the matching loss. Such a pipeline pays little attention to the possible complementary benefit from the optimization layer to the learning component. In this paper, we overcome the above limitation under a deep bidirectional learning framework.Our method circulates the output of the GM optimization layer to fuse  with the input for affinity learning. Such direct feedback enhances the input by a  feature enrichment and fusion technique, which exploits andintegrates the global matching patterns from the deviation of the similarity permuted by the current matching estimate. As a result, the circulation enables the learning component to benefit from the optimization process, taking advantage of both global feature and  the embedding result which is calculated by local propagationthrough node-neighbors. Moreover, circulation consistency induces an unsupervised loss that can be implemented individually or jointly to regularize the supervised loss. Experiments on challenging datasets demonstrate the effectiveness of our methods for both supervised learning and unsupervised learning.",
        "primary_area": "Computer Vision III",
        "author": "Kaixuan Zhao; Shikui Tu; Lei Xu",
        "authorids": "",
        "aff": "Shanghai Jiao Tong University; Shanghai Jiao Tong University; Shanghai Jiao Tong University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16461/16461-13-19955-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03474-ia-gm-a-deep-bidirectional-learning-method-for-graph-matching/",
        "doi": "10.1609/aaai.v35i4.16461",
        "pdf_size": 1417927
    },
    {
        "id": "07926",
        "title": "IB-GAN: Disentangled Representation Learning with Information Bottleneck Generative Adversarial Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a new GAN-based unsupervised model for disentangled representation learning. The new model is discovered in an attempt to utilize the Information Bottleneck (IB) framework to the optimization of GAN, thereby named IB-GAN.  The architecture of IB-GAN is partially similar to that of InfoGAN but has a critical difference; an intermediate layer of the generator is leveraged to constrain the mutual information between the input and the generated output. The intermediate stochastic layer can serve as a learnable latent distribution that is trained with the generator jointly in an end-to-end fashion. As a result, the generator of IB-GAN can harness the latent space in a disentangled and interpretable manner. With the experiments on dSprites and Color-dSprites dataset, we demonstrate that IB-GAN achieves competitive disentanglement scores to those of state-of-the-art \u03b2-VAEs and outperforms InfoGAN. Moreover, the visual quality and the diversity of samples generated by IB-GAN are often better than those by \u03b2-VAEs and Info-GAN in terms of FID score on CelebA and 3D Chairs dataset.",
        "primary_area": "Machine Learning II",
        "author": "Insu Jeon; Wonkwang Lee; Myeongjang Pyeon; Gunhee Kim",
        "authorids": "",
        "aff": "Seoul National University; KAIST; Seoul National University; Seoul National University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16967/16967-13-20461-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07926-ib-gan-disentangled-representation-learning-with-information-bottleneck-generative-adversarial-networks/",
        "doi": "10.1609/aaai.v35i9.16967",
        "pdf_size": 4226876
    },
    {
        "id": "06128",
        "title": "IDOL: Inertial Deep Orientation-Estimation and Localization",
        "track": "main",
        "status": "Poster",
        "abstract": "Many smartphone applications use inertial measurement units (IMUs) to sense movement, but the use of these sensors for pedestrian localization can be challenging due to their noise characteristics. Recent data-driven inertial odometry approaches have demonstrated the increasing feasibility of inertial navigation. However, they still rely upon conventional smartphone orientation estimates that they assume to be accurate, while in fact these orientation estimates can be a significant source of error. To address the problem of inaccurate orientation estimates, we present a two-stage, data-driven pipeline using a commodity smartphone that first estimates device orientations and then estimates device position. The orientation module relies on a recurrent neural network and Extended Kalman Filter to obtain orientation estimates that are used to then rotate raw IMU measurements into the appropriate reference frame. The position module then passes those measurements through another recurrent network architecture to perform localization. Our proposed method outperforms state-of-the-art methods in both orientation and position error on a large dataset we constructed that contains 20 hours of pedestrian motion across 3 buildings and 15 subjects. Code and data are available at https://github.com/KlabCMU/IDOL.",
        "primary_area": "Intelligent Robots",
        "author": "Scott Sun; Dennis Melamed; Kris Kitani",
        "authorids": "",
        "aff": "Carnegie Mellon University; Carnegie Mellon University; Carnegie Mellon University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16763/16763-13-20257-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06128-idol-inertial-deep-orientation-estimation-and-localization/",
        "doi": "10.1609/aaai.v35i7.16763",
        "pdf_size": 3285289
    },
    {
        "id": "10737",
        "title": "Identity-aware Graph Neural Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Message passing Graph Neural Networks (GNNs) provide a powerful modeling framework for relational data. However, the expressive power of existing GNNs is upper-bounded by the 1-Weisfeiler-Lehman (1-WL) graph isomorphism test, which means GNNs that are not able to predict node clustering coefficients and shortest path distances, and cannot differentiate between different d-regular graphs. Here we develop a class of message passing GNNs, named Identity-aware Graph Neural Networks (ID-GNNs), with greater expressive power than the 1-WL test. ID-GNN offers a minimal but powerful solution to limitations of existing GNNs. ID-GNN extends existing GNN architectures by inductively considering nodes\u2019 identities during message passing. To embed a given node, ID-GNN first extracts the ego network centered at the node, then conducts rounds of heterogeneous message passing, where different sets of parameters are applied to the center node than to other surrounding nodes in the ego network. We further propose a simplified but faster version of ID-GNN that injects node identity information as augmented node features. Alto- gether, both versions of ID-GNN represent general extensions of message passing GNNs, where experiments show that transforming existing GNNs to ID-GNNs yields on average 40% accuracy improvement on challenging node, edge, and graph property prediction tasks; 3% accuracy improvement on node and graph classification benchmarks; and 15% ROC AUC improvement on real-world link prediction tasks. Additionally, ID-GNNs demonstrate improved or comparable performance over other task-specific graph networks.",
        "primary_area": "Machine Learning V",
        "author": "Jiaxuan You; Jonathan M Gomes-Selman; Rex Ying; Jure Leskovec",
        "authorids": "",
        "aff": "Stanford University; Stanford University; Stanford University; Stanford University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17283/17283-13-20777-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10737-identity-aware-graph-neural-networks/",
        "doi": "10.1609/aaai.v35i12.17283",
        "pdf_size": 1014203
    },
    {
        "id": "13898",
        "title": "Ideography Leads Us to the Field of Cognition: A Radical-Guided Associative Model for Chinese Text Classification",
        "track": "main",
        "status": "Poster",
        "abstract": "Cognitive psychology research shows that humans have the instinct for abstract thinking, where association plays an essential role in language comprehension. Especially for Chinese, its ideographic writing system allows radicals to trigger semantic association without the need of phonetics. In fact, subconsciously using the associative information guided by radicals is a key for readers to ensure the robustness of semantic understanding. Fortunately, many basic and extended concepts related to radicals are systematically included in Chinese language dictionaries, which leaves a handy but unexplored way for improving Chinese text representation and classification. To this end, we draw inspirations from cognitive principles between ideography and human associative behavior to propose a novel Radical-guided Associative Model (RAM) for Chinese text classification. RAM comprises two coupled spaces, namely Literal Space and Associative Space, which imitates the real process in people's mind when understanding a Chinese text. To be specific, we first devise a serialized modeling structure in Literal Space to thoroughly capture the sequential information of Chinese text. Then, based on the authoritative information provided by Chinese language dictionaries, we design an association module and put forward a strategy called Radical-Word Association to use ideographic radicals as the medium to associate prior concept words in Associative Space. Afterwards, we design an attention module to imitate people's matching and decision between Literal Space and Associative Space, which can balance the importance of each associative words under specific contexts. Finally, extensive experiments on two real-world datasets prove the effectiveness and rationality of RAM, with good cognitive insights for future language modeling.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Hanqing Tao; Shiwei Tong; Kun Zhang; Tong Xu; Qi Liu; Enhong Chen; Min Hou",
        "authorids": "",
        "aff": "Anhui Province Key Laboratory of Big Data Analysis and Application, University of Science and Technology of China; Anhui Province Key Laboratory of Big Data Analysis and Application, University of Science and Technology of China; School of Computer Science and Information Engineering, Hefei University of Technology; Anhui Province Key Laboratory of Big Data Analysis and Application, University of Science and Technology of China School of Data Science, University of Science and Technology of China; Anhui Province Key Laboratory of Big Data Analysis and Application, University of Science and Technology of China School of Data Science, University of Science and Technology of China; Anhui Province Key Laboratory of Big Data Analysis and Application, University of Science and Technology of China School of Data Science, University of Science and Technology of China; Anhui Province Key Laboratory of Big Data Analysis and Application, University of Science and Technology of China School of Data Science, University of Science and Technology of China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17637/17637-13-21131-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13898-ideography-leads-us-to-the-field-of-cognition-a-radical-guided-associative-model-for-chinese-text-classification/",
        "doi": "10.1609/aaai.v35i15.17637",
        "pdf_size": 14048366
    },
    {
        "id": "05751",
        "title": "If You Like Shapley Then You\u2019ll Love the Core",
        "track": "main",
        "status": "Poster",
        "abstract": "The prevalent approach to problems of credit assignment in machine learning -- such as feature and data valuation -- is to model the problem at hand as a cooperative game and apply the Shapley value. But cooperative game theory offers a rich menu of alternative solution concepts, which famously includes the core and its variants. Our goal is to challenge the machine learning community's current consensus around the Shapley value, and make a case for the core as a viable alternative. To that end, we prove that arbitrarily good approximations to the least core -- a core relaxation that is always feasible -- can be computed efficiently (but prove an impossibility for a more refined solution concept, the nucleolus). We also perform experiments that corroborate these theoretical results and shed light on settings where the least core may be preferable to the Shapley value.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Tom Yan; Ariel D. Procaccia",
        "authorids": "",
        "aff": "Carnegie Mellon University; Harvard University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16721/16721-13-20215-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05751-if-you-like-shapley-then-youll-love-the-core/",
        "doi": "10.1609/aaai.v35i6.16721",
        "pdf_size": 2466172
    },
    {
        "id": "05922",
        "title": "Illuminating Mario Scenes in the Latent Space of a Generative Adversarial Network",
        "track": "main",
        "status": "Poster",
        "abstract": "Generative adversarial networks (GANs) are quickly becoming a ubiquitous approach to procedurally generating video game levels. While GAN generated levels are stylistically similar to human-authored examples, human designers often want to explore the generative design space of GANs to extract interesting levels. However, human designers find latent vectors opaque and would rather explore along dimensions the designer specifies, such as number of enemies or obstacles. We propose using state-of-the-art quality diversity algorithms designed to optimize continuous spaces, i.e. MAP-Elites with a directional variation operator and Covariance Matrix Adaptation MAP-Elites, to efficiently explore the latent space of a GAN to extract levels that vary across a set of specified gameplay measures. In the benchmark domain of Super Mario Bros, we demonstrate how designers may specify gameplay measures to our system and extract high-quality (playable) levels with a diverse range of level mechanics, while still maintaining stylistic similarity to human authored examples. An online user study shows how the different mechanics of the automatically generated levels affect subjective ratings of their perceived difficulty and appearance.",
        "primary_area": "Humans and AI",
        "author": "Matthew C. Fontaine; Ruilin Liu; Ahmed Khalifa; Jignesh Modi; Julian Togelius; Amy K. Hoover; Stefanos Nikolaidis",
        "authorids": "",
        "aff": "University of Southern California; University of Southern California; New York University; University of Southern California; New York University; New Jersey Institute of Technology; University of Southern California",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16740/16740-13-20234-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05922-illuminating-mario-scenes-in-the-latent-space-of-a-generative-adversarial-network/",
        "doi": "10.1609/aaai.v35i7.16740",
        "pdf_size": 820084
    },
    {
        "id": "02584",
        "title": "Image Captioning with Context-Aware Auxiliary Guidance",
        "track": "main",
        "status": "Poster",
        "abstract": "Image captioning is a challenging computer vision task, which aims to generate a natural language description of an image. Most recent researches follow the encoder-decoder framework which depends heavily on the previous generated words for the current prediction. Such methods can not effectively take advantage of the future predicted information to learn complete semantics. In this paper, we propose  Context-Aware Auxiliary Guidance (CAAG) mechanism that can guide the captioning model to perceive global contexts. Upon the captioning model, CAAG performs semantic attention that selectively concentrates on useful information of the global predictions to reproduce the current generation. To validate the adaptability of the method, we apply CAAG to three popular captioners and our proposal achieves competitive performance on the challenging Microsoft COCO image captioning benchmark, e.g. 132.2 CIDEr-D score on Karpathy split and 130.7 CIDEr-D (c40) score on official online evaluation server.",
        "primary_area": "Computer Vision II",
        "author": "Zeliang Song; Xiaofei Zhou; Zhendong Mao; Jianlong Tan",
        "authorids": "",
        "aff": "Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China; University of Science and Technology of China, Hefei, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16361/16361-13-19855-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02584-image-captioning-with-context-aware-auxiliary-guidance/",
        "doi": "10.1609/aaai.v35i3.16361",
        "pdf_size": 7970141
    },
    {
        "id": "10718",
        "title": "Image-to-Image Retrieval by Learning Similarity between Scene Graphs",
        "track": "main",
        "status": "Poster",
        "abstract": "As a scene graph compactly summarizes the high-level content of an image in a structured and symbolic manner, the similarity between scene graphs of two images reflects the relevance of their contents. Based on this idea, we propose a novel approach for image-to-image retrieval using scene graph similarity measured by graph neural networks. In our approach, graph neural networks are trained to predict the proxy image relevance measure, computed from human-annotated captions using a pre-trained sentence similarity model. We collect and publish the dataset for image relevance measured by human annotators to evaluate retrieval algorithms. The collected dataset shows that our method agrees well with the human perception of image similarity than other competitive baselines.",
        "primary_area": "Machine Learning V",
        "author": "Sangwoong Yoon; Woo Young Kang; Sungwook Jeon; SeongEun Lee; Changjin Han; Jonghun Park; Eun-Sol Kim",
        "authorids": "",
        "aff": "Seoul National University; Kakao Brain; Seoul National University; Seoul National University; Seoul National University; Seoul National University; Kakao Brain",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17281/17281-13-20775-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10718-image-to-image-retrieval-by-learning-similarity-between-scene-graphs/",
        "doi": "10.1609/aaai.v35i12.17281",
        "pdf_size": 1693074
    },
    {
        "id": "03022",
        "title": "Imagine, Reason and Write: Visual Storytelling with Graph Knowledge and Relational Reasoning",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual storytelling is a task of creating a short story based on photo streams. Different from visual captions, stories contain not only factual descriptions, but also imaginary concepts that do not appear in the images. In this paper, we propose a novel imagine-reason-write generation framework (IRW) for visual storytelling, inspired by the logic of humans when they write the story. First, an imagine module is leveraged to learn the imaginative storyline explicitly, improving the coherence and reasonability of the generated story. Second, we employ a reason module to fully exploit the external knowledge (commonsense knowledge base) and task-specific knowledge (scene graph and event graph) with relational reasoning method based on the storyline. In this way, we can effectively capture the most informative commonsense and visual relationships among objects in images, which enhances the diversity and informativeness of the generated story. Finally, we integrate the imaginary concepts and relational knowledge to generate human-like story based on the original semantics of images. Extensive experiments on a benchmark dataset (i.e., VIST) demonstrate that the proposed IRW framework significantly outperforms the state-of-the-art methods across multiple evaluation metrics.",
        "primary_area": "Computer Vision III",
        "author": "Chunpu Xu; Min Yang; Chengming Li; Ying Shen; Xiang Ao; Ruifeng Xu",
        "authorids": "",
        "aff": "Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences; Sun Yat-Sen University; Institute of Computing Technology, CAS; Harbin Institute of Technology (Shenzhen)",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16410/16410-13-19904-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03022-imagine-reason-and-write-visual-storytelling-with-graph-knowledge-and-relational-reasoning/",
        "doi": "10.1609/aaai.v35i4.16410",
        "pdf_size": 554372
    },
    {
        "id": "09713",
        "title": "Implicit Kernel Attention",
        "track": "main",
        "status": "Poster",
        "abstract": "Attention computes the dependency between representations, and it encourages the model to focus on the important selective features. Attention-based models, such as Transformer and graph attention network (GAT), are widely utilized for sequential data and graph-structured data. This paper suggests a new interpretation and generalized structure of the attention in Transformer and GAT. For the attention in Transformer and GAT, we derive that the attention is a product of two parts: 1) the RBF kernel to measure the similarity of two instances and 2) the exponential of L2 norm to compute the importance of individual instances. From this decomposition, we generalize the attention in three ways. First, we propose implicit kernel attention with an implicit kernel function instead of manual kernel selection. Second, we generalize L2 norm as the Lp norm. Third, we extend our attention to structured multi-head attention. Our generalized attention shows better performance on classification, translation, and regression tasks.",
        "primary_area": "Machine Learning IV",
        "author": "Kyungwoo Song; Yohan Jung; Dongjun Kim; Il-Chul Moon",
        "authorids": "",
        "aff": "University of Seoul; KAIST; KAIST; KAIST",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17168/17168-13-20662-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09713-implicit-kernel-attention/",
        "doi": "10.1609/aaai.v35i11.17168",
        "pdf_size": 1034959
    },
    {
        "id": "11033",
        "title": "Improved Consistency Regularization for GANs",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent work has increased the performance of Generative Adversarial Networks (GANs) by enforcing a consistency cost on the discriminator. We improve on this technique in several ways. We first show that consistency regularization can introduce artifacts into the GAN samples and explain how to fix this issue. We then propose several modifications to the consistency regularization procedure designed to improve its performance. We carry out extensive experiments quantifying the benefit of our improvements. For unconditional image synthesis on CIFAR-10 and CelebA, our modifications yield the best known FID scores on various GAN architectures. For conditional image synthesis on CIFAR-10, we improve the state-of-the-art FID score from 11.48 to 9.21. Finally, on ImageNet-2012, we apply our technique to the original BigGAN model and improve the FID from 6.66 to 5.38, which is the best score at that model size.",
        "primary_area": "Machine Learning V",
        "author": "Zhengli Zhao; Sameer Singh; Honglak Lee; Zizhao Zhang; Augustus Odena; Han Zhang",
        "authorids": "",
        "aff": "UC Irvine Google; UC Irvine; Google; Google; Google; Google",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17317/17317-13-20811-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11033-improved-consistency-regularization-for-gans/",
        "doi": "10.1609/aaai.v35i12.17317",
        "pdf_size": 973832
    },
    {
        "id": "11954",
        "title": "Improved Knowledge Modeling and Its Use for Signaling in Multi-Agent Planning with Partial Observability",
        "track": "main",
        "status": "Poster",
        "abstract": "Collaborative Multi-Agent Planning (MAP) problems with uncertainty and partial observability are often modeled as Dec-POMDPs. Yet, in deterministic domains, Qualitative Dec-POMDPs can scale up to much larger problem sizes. The best current QDec solver (QDec-FP) reduces MAP problems to multiple single-agent problems. In this paper, we describe a planner that uses richer information about agents\u2019 knowledge to improve upon QDec-FP. With this change, the planner not only scales up to larger problems with more objects, but it can also support signaling, where agents signal information to each other by changing the state of the world.",
        "primary_area": "Planning, Routing, and Scheduling",
        "author": "Shashank Shekhar; Ronen I. Brafman; Guy Shani",
        "authorids": "",
        "aff": "Ben Gurion University; Ben Gurion University; Ben Gurion University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17420/17420-13-20914-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11954-improved-knowledge-modeling-and-its-use-for-signaling-in-multi-agent-planning-with-partial-observability/",
        "doi": "10.1609/aaai.v35i13.17420",
        "pdf_size": 317147
    },
    {
        "id": "09009",
        "title": "Improved Mutual Information Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose to estimate the KL divergence using a relaxed likelihood ratio  estimation  in a Reproducing Kernel Hilbert space. We show that the dual of our ratio estimator for KL in the particular case of Mutual Information estimation corresponds to a lower bound on the MI  that is related to the so called Donsker Varadhan lower bound.  In this dual form, MI is estimated via learning a witness function discriminating between the joint density and the product of marginal, as well as an auxiliary scalar variable that enforces a normalization constraint on the likelihood ratio. By extending the function space to neural networks, we propose an efficient neural MI estimator, and validate its performance on synthetic examples, showing advantage over the existing baselines. We demonstrate its strength in large-scale self-supervised representation learning through MI maximization.",
        "primary_area": "Machine Learning III",
        "author": "Youssef Mroueh; Igor Melnyk; Pierre Dognin; Jarret Ross; Tom Sercu",
        "authorids": "",
        "aff": "IBM Research AI; IBM Research AI; IBM Research AI; IBM Research AI; IBM Research AI",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17089/17089-13-20583-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09009-improved-mutual-information-estimation/",
        "doi": "10.1609/aaai.v35i10.17089",
        "pdf_size": 1498102
    },
    {
        "id": "11888",
        "title": "Improved POMDP Tree Search Planning with Prioritized Action Branching",
        "track": "main",
        "status": "Poster",
        "abstract": "Online solvers for partially observable Markov decision processes have difficulty scaling to problems with large action spaces. This paper proposes a method called PA-POMCPOW to sample a subset of the action space that provides varying mixtures of exploitation and exploration for inclusion in a search tree. The proposed method first evaluates the action space according to a score function that is a linear combination of expected reward and expected information gain. The actions with the highest score are then added to the search tree during tree expansion. Experiments show that PA-POMCPOW is able to outperform existing state-of-the-art solvers on problems with large discrete action spaces.",
        "primary_area": "Planning, Routing, and Scheduling",
        "author": "John Mern; Anil Yildiz; Lawrence Bush; Tapan Mukerji; Mykel J. Kochenderfer",
        "authorids": "",
        "aff": "Stanford University; Stanford University; General Motors Research & Development; Stanford University; Stanford University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17412/17412-13-20906-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11888-improved-pomdp-tree-search-planning-with-prioritized-action-branching/",
        "doi": "10.1609/aaai.v35i13.17412",
        "pdf_size": 423617
    },
    {
        "id": "09621",
        "title": "Improved Penalty Method via Doubly Stochastic Gradients for Bilevel Hyperparameter Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "Hyperparameter optimization (HO) is an important problem in machine learning which is normally formulated as a bilevel optimization problem. Gradient-based methods are dominant in bilevel optimization due to their high scalability to the number of hyperparameters, especially in a deep learning problem. However, traditional gradient-based bilevel optimization methods need intermediate steps to obtain the exact or approximate gradient of hyperparameters, namely hypergradient, for the upper-level objective, whose complexity is high especially for high dimensional datasets. Recently, a penalty method has been proposed to avoid the computation of the hypergradient, which speeds up the gradient-based BHO methods. However, the penalty method may result in a very large number of constraints, which greatly limits the efficiency of this method, especially for high dimensional data problems. To address this limitation, in this paper, we propose a doubly stochastic gradient descent algorithm (DSGPHO) to improve the efficiency of the penalty method.  Importantly, we not only prove the proposed method can converge to the KKT condition of the original problem in a convex setting, but also provide the convergence rate of  DSGPHO which is the first result in the references of gradient-based bilevel optimization as far as we know. We compare our method with three state-of-the-art gradient-based methods in three tasks, i.e., data denoising, few-shot learning, and training data poisoning, using several large-scale benchmark datasets. All the results demonstrate that our method outperforms or is comparable to the existing methods in terms of accuracy and efficiency.",
        "primary_area": "Machine Learning IV",
        "author": "Wanli Shi; Bin Gu",
        "authorids": "",
        "aff": "Nanjing University of Information Science & Technology, P.R.China; Nanjing University of Information Science & Technology, P.R.China MBZUAI, United Arab Emirates JD Finance America Corporation, Mountain View, CA, USA",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17158/17158-13-20652-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09621-improved-penalty-method-via-doubly-stochastic-gradients-for-bilevel-hyperparameter-optimization/",
        "doi": "10.1609/aaai.v35i11.17158",
        "pdf_size": 666175
    },
    {
        "id": "06566",
        "title": "Improved Worst-Case Regret Bounds for Randomized Least-Squares Value Iteration",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper studies regret minimization with randomized value functions in reinforcement learning. In tabular finite-horizon Markov Decision Processes, we introduce a clipping variant of one classical Thompson Sampling (TS)-like algorithm, randomized least-squares value iteration (RLSVI). Our $tilde{mathrm{O}}(H^2Ssqrt{AT})$ high-probability worst-case regret bound improves the previous sharpest worst-case regret bounds for RLSVI and matches the existing state-of-the-art worst-case TS-based regret bounds.",
        "primary_area": "Machine Learning I",
        "author": "Priyank Agrawal; Jinglin Chen; Nan Jiang",
        "authorids": "",
        "aff": "University of Illinois at Urbana-Champaign; University of Illinois at Urbana-Champaign; University of Illinois at Urbana-Champaign",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16813/16813-13-20307-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06566-improved-worst-case-regret-bounds-for-randomized-least-squares-value-iteration/",
        "doi": "10.1609/aaai.v35i8.16813",
        "pdf_size": 164672
    },
    {
        "id": "08482",
        "title": "Improving Adversarial Robustness via Probabilistically Compact Loss with Logit Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "Convolutional neural networks (CNNs) have achieved state-of-the-art performance on various tasks in computer vision. However, recent studies demonstrate that these models are vulnerable to carefully crafted adversarial samples and suffer from a significant performance drop when predicting them. Many methods have been proposed to improve adversarial robustness (e.g., adversarial training and new loss functions to learn adversarially robust feature representations). Here we offer a unique insight into the predictive behavior of CNNs that they tend to misclassify adversarial samples into the most probable false classes. This inspires us to propose a new Probabilistically Compact (PC) loss with logit constraints which can be used as a drop-in replacement for cross-entropy (CE) loss to improve CNN's adversarial robustness. Specifically, PC loss enlarges the probability gaps between true class and false classes meanwhile the logit constraints prevent the gaps from being melted by a small perturbation. We extensively compare our method with the state-of-the-art using large scale datasets under both white-box and black-box attacks to demonstrate its effectiveness. The source codes are available at https://github.com/xinli0928/PC-LC.",
        "primary_area": "Machine Learning III",
        "author": "Xin Li; Xiangrui Li; Deng Pan; Dongxiao Zhu",
        "authorids": "",
        "aff": "Wayne State Unversity, USA; Wayne State Unversity, USA; Wayne State Unversity, USA; Wayne State Unversity, USA",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17030/17030-13-20524-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08482-improving-adversarial-robustness-via-probabilistically-compact-loss-with-logit-constraints/",
        "doi": "10.1609/aaai.v35i10.17030",
        "pdf_size": 3247798
    },
    {
        "id": "08741",
        "title": "Improving Causal Discovery By Optimal Bayesian Network Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Many widely-used causal discovery methods such as Greedy Equivalent Search (GES), although with asymptotic correctness guarantees, have been reported to produce sub-optimal solutions on finite data, or when the causal faithfulness condition is violated. The constraint-based procedure with Boolean satisfiability (SAT) solver, and the recently proposed Sparsest Permutation (SP) algorithm have shown superb performance, but currently they do not scale well. In this work, we demonstrate that optimal score-based exhaustive search is remarkably useful for causal discovery: it requires weaker conditions to guarantee asymptotic correctness, and outperforms well-known methods including PC, GES, GSP, and NOTEARS. In order to achieve scalability, we also develop an approximation algorithm for larger systems based on the  A* method, which scales up to 60+ variables and obtains better results than existing greedy algorithms such as GES, MMHC, and GSP. Our results illustrate the risk of assuming the faithfulness assumption, the advantages of exhaustive search methods, and the limitations of greedy search methods, and shed light on the computational challenges and techniques in scaling up to larger networks and handling unfaithful data.",
        "primary_area": "Machine Learning III",
        "author": "Ni Y Lu; Kun Zhang; Changhe Yuan",
        "authorids": "",
        "aff": "Graduate Center, City University of New York, New York, NY; Department of Philosophy, Carnegie Mellon University, Pittsburgh, PA; Department of Computer Science, Queens College, Queens, NY",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17059/17059-13-20553-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08741-improving-causal-discovery-by-optimal-bayesian-network-learning/",
        "doi": "10.1609/aaai.v35i10.17059",
        "pdf_size": 409999
    },
    {
        "id": "13834",
        "title": "Improving Commonsense Causal Reasoning by Adversarial Training and Data Augmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "Determining the plausibility of causal relations between clauses is a commonsense reasoning task that requires complex inference ability. The general approach to this task is to train a large pretrained language model on a specific dataset. However, the available training data for the task is often scarce, which leads to instability of model training or reliance on the shallow features of the dataset. This paper presents a number of techniques for making models more robust in the domain of causal reasoning. Firstly, we perform adversarial training by generating perturbed inputs through synonym substitution. Secondly, based on a linguistic theory of discourse connectives, we perform data augmentation using a discourse parser for detecting causally linked clauses in large text, and a generative language model for generating distractors. Both methods boost model performance on the Choice of Plausible Alternatives (COPA) dataset, as well as on a Balanced COPA dataset, which is a modified version of the original data that has been developed to avoid superficial cues, leading to a more challenging benchmark. We show a statistically significant improvement in performance and robustness on both datasets, even with only a small number of additionally generated data points.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Ieva Stali\u016bnait\u0117; Philip John Gorinski; Ignacio Iacobacci",
        "authorids": "",
        "aff": "Huawei Noah's Ark Lab; Huawei Noah's Ark Lab; Huawei Noah's Ark Lab",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17630/17630-13-21124-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13834-improving-commonsense-causal-reasoning-by-adversarial-training-and-data-augmentation/",
        "doi": "10.1609/aaai.v35i15.17630",
        "pdf_size": 167958
    },
    {
        "id": "11220",
        "title": "Improving Continuous-time Conflict Based Search",
        "track": "main",
        "status": "Poster",
        "abstract": "Conflict-Based Search (CBS) is a powerful algorithmic framework for optimally solving classical multi-agent path finding (MAPF) problems, where time is discretized into the time steps. Continuous-time CBS (CCBS) is a recently proposed version of CBS that guarantees optimal solutions without the need to discretize time. However, the  scalability of CCBS is limited because it does not include any known improvements of CBS. In this paper, we begin to close this gap and explore how to adapt successful CBS improvements, namely, prioritizing conflicts (PC), disjoint splitting (DS), and high-level heuristics, to the continuous time setting of CCBS. These adaptions are not trivial, and require careful handling of different types of constraints, applying a generalized version of the Safe interval path planning (SIPP) algorithm, and extending the notion of cardinal conflicts. We evaluate the effect of the suggested enhancements by running experiments both on general graphs and 2^k-neighborhood grids. CCBS with these improvements significantly outperforms vanilla CCBS, solving problems with almost twice as many agents in some cases and pushing the limits of multi-agent path finding in continuous-time domains.",
        "primary_area": "Multiagent Systems",
        "author": "Anton Andreychuk,Konstantin Yakovlev,Eli Boyarski,Roni Stern",
        "authorids": "",
        "aff": "Peoples' Friendship University of Russia (RUDN University) Federal Research Center for Computer Science and Control of Russian Academy of Sciences,Federal Research Center for Computer Science and Control of Russian Academy of Sciences HSE University,Ben-Gurion University of the Negev,Ben-Gurion University Palo Alto Research Center",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17338/17338-13-20832-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11220-improving-continuous-time-conflict-based-search/",
        "doi": "10.1609/aaai.v35i13.17338",
        "pdf_size": 1710233
    },
    {
        "id": "06831",
        "title": "Improving Ensemble Robustness by Collaboratively Promoting and Demoting Adversarial Robustness",
        "track": "main",
        "status": "Poster",
        "abstract": "Ensemble-based Adversarial Training is a principled approach to achieve robustness against adversarial attacks. An important technicality of this approach is to control the transferability of adversarial examples between ensemble members. We propose in this work a simple, but effective strategy to collaborate among committee models of an ensemble model. This is achieved via the secure and insecure sets defined for each model member on a given sample, hence help us to quantify and regularize the transferability. Consequently, our proposed framework provides the flexibility to reduce the adversarial transferability as well as promote the diversity of ensemble members, which are two crucial factors for better robustness in our ensemble approach. We conduct extensive and comprehensive experiments to demonstrate that our proposed method outperforms the state-of-the-art ensemble baselines, at the same time can detect a wide range of adversarial examples with a near perfect accuracy.",
        "primary_area": "Machine Learning I",
        "author": "Anh Tuan Bui; Trung Le; He Zhao; Paul Montague; Olivier deVel; Tamas Abraham; Dinh Phung",
        "authorids": "",
        "aff": "Monash University, Australia; Monash University, Australia; Monash University, Australia; Defence Science and Technology Group, Australia; Defence Science and Technology Group, Australia; Defence Science and Technology Group, Australia; Monash University, Australia",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16843/16843-13-20337-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06831-improving-ensemble-robustness-by-collaboratively-promoting-and-demoting-adversarial-robustness/",
        "doi": "10.1609/aaai.v35i8.16843",
        "pdf_size": 922031
    },
    {
        "id": "08092",
        "title": "Improving Fairness and Privacy in Selection Problems",
        "track": "main",
        "status": "Poster",
        "abstract": "Supervised learning models have been increasingly used for making decisions about individuals in applications such as hiring, lending, and college admission. These models may inherit pre-existing biases from training datasets and discriminate against protected attributes (e.g., race or gender). In addition to unfairness, privacy concerns also arise when the use of models reveals sensitive personal information. Among various privacy notions, differential privacy has become popular in recent years. In this work, we study the possibility of using a differentially private exponential mechanism as a post-processing step to improve both fairness and privacy of supervised learning models. Unlike many existing works, we consider a scenario where a supervised model is used to select a limited number of applicants as the number of available positions is limited. This assumption is well-suited for various scenarios, such as job application and college admission. We use ``equal opportunity'' as the fairness notion and show that the exponential mechanisms can make the decision-making process perfectly fair. Moreover, the experiments on real-world datasets show that the exponential mechanism can improve both privacy and fairness, with a slight decrease in accuracy compared to the model without post-processing.",
        "primary_area": "Machine Learning II",
        "author": "Mohammad Mahdi Khalili; Xueru Zhang; Mahed Abroshan; Somayeh Sojoudi",
        "authorids": "",
        "aff": "University of Delaware; University of Michigan; Alan Turing Institute; UC Berkeley",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16986/16986-13-20480-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08092-improving-fairness-and-privacy-in-selection-problems/",
        "doi": "10.1609/aaai.v35i9.16986",
        "pdf_size": 301254
    },
    {
        "id": "09403",
        "title": "Improving Generative Moment Matching Networks with Distribution Partition",
        "track": "main",
        "status": "Poster",
        "abstract": "Generative moment matching networks (GMMN) present a theoretically sound approach to learning deep generative mod-els. However, such methods are typically limited by the high sample complexity, thereby impractical in generating complex data. In this paper, we present a new strategy to train GMMN with a low sample complexity while retaining the theoretical soundness. Our method introduces some auxiliary variables, whose values are provided by a pre-trained model such as an encoder network in practice. Conditioned on these variables, we partition the distribution into a set of conditional distributions, which can be effectively matched with a low sample complexity. We instantiate this strategy by presenting an amortized network called GMMN-DP with shared auxiliary variable information for the data generation task, as well as developing an efficient stochastic training algorithm.The experimental results show that GMMN-DP can generate complex samples on datasets such as CelebA and CIFAR-10, where the vanilla GMMN fails.",
        "primary_area": "Machine Learning IV",
        "author": "Yong Ren; Yucen Luo; Jun Zhu",
        "authorids": "",
        "aff": "Tsinghua University; Tsinghua University; Tsinghua University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17133/17133-13-20627-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09403-improving-generative-moment-matching-networks-with-distribution-partition/",
        "doi": "10.1609/aaai.v35i11.17133",
        "pdf_size": 5548016
    },
    {
        "id": "09704",
        "title": "Improving Gradient Flow with Unrolled Highway Expectation Maximization",
        "track": "main",
        "status": "Poster",
        "abstract": "Integrating model-based machine learning methods into deep neural architectures allows one to leverage both the expressive power of deep neural nets and the ability of model-based methods to incorporate domain-specific knowledge. In particular, many works have employed the expectation maximization (EM) algorithm in the form of an unrolled layer-wise structure that is jointly trained with a backbone neural network. However, it is difficult to discriminatively train the backbone network by backpropagating through the EM iterations as they are prone to the vanishing gradient problem. To address this issue, we propose Highway Expectation Maximization Networks (HEMNet), which is comprised of unrolled iterations of the generalized EM (GEM) algorithm based on the Newton-Rahpson method. HEMNet features scaled skip connections, or highways, along the depths of the unrolled architecture, resulting in improved gradient flow during backpropagation while incurring negligible additional computation and memory costs compared to standard unrolled EM. Furthermore, HEMNet preserves the underlying EM procedure, thereby fully retaining the convergence properties of the original EM algorithm. We achieve significant improvement in performance on several semantic segmentation benchmarks and empirically show that HEMNet effectively alleviates gradient decay.",
        "primary_area": "Machine Learning IV",
        "author": "Chonghyuk Song; Eunseok Kim; Inwook Shim",
        "authorids": "",
        "aff": "Ground Technology Research Institute, Agency for Defense Development; Ground Technology Research Institute, Agency for Defense Development; Ground Technology Research Institute, Agency for Defense Development",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17167/17167-13-20661-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09704-improving-gradient-flow-with-unrolled-highway-expectation-maximization/",
        "doi": "10.1609/aaai.v35i11.17167",
        "pdf_size": 1398669
    },
    {
        "id": "01655",
        "title": "Improving Image Captioning by Leveraging Intra- and Inter-layer Global Representation in Transformer Network",
        "track": "main",
        "status": "Poster",
        "abstract": "Transformer-based architectures have shown great success in image captioning, where object regions are encoded and then attended into the vectorial representations to guide the caption decoding. However, such vectorial representations only contain region-level information without considering the global information reflecting the entire image, which fails to expand the capability of complex multi-modal reasoning in image captioning. In this paper, we introduce a Global Enhanced Transformer (termed GET) to enable the extraction of a more comprehensive global representation, and then adaptively guide the decoder to generate high-quality captions.  In GET, a Global Enhanced Encoder  is designed for the embedding of the global feature,  and a Global Adaptive Decoder are designed for the guidance of the caption generation. The former models intra- and inter-layer global representation by taking advantage of the proposed Global Enhanced Attention and a layer-wise fusion module. The latter  contains a Global Adaptive Controller that can adaptively fuse the global information into the decoder to guide the caption generation.  Extensive experiments on MS COCO dataset demonstrate the superiority of our GET over many state-of-the-arts.",
        "primary_area": "Computer Vision I",
        "author": "Jiayi Ji; Yunpeng Luo; Xiaoshuai Sun; Fuhai Chen; Gen Luo; Yongjian Wu; Yue Gao; Rongrong Ji",
        "authorids": "",
        "aff": "Media Analytics and Computing Lab, Department of Arti\ufb01cial Intelligence, School of Informatics, Xiamen University, 361005, China; Media Analytics and Computing Lab, Department of Arti\ufb01cial Intelligence, School of Informatics, Xiamen University, 361005, China; Media Analytics and Computing Lab, Department of Arti\ufb01cial Intelligence, School of Informatics, Xiamen University, 361005, China Institute of Arti\ufb01cial Intelligence, Xiamen University; Media Analytics and Computing Lab, Department of Arti\ufb01cial Intelligence, School of Informatics, Xiamen University, 361005, China; Media Analytics and Computing Lab, Department of Arti\ufb01cial Intelligence, School of Informatics, Xiamen University, 361005, China; Tencent Youtu Lab; Tsinghua University; Media Analytics and Computing Lab, Department of Arti\ufb01cial Intelligence, School of Informatics, Xiamen University, 361005, China Institute of Arti\ufb01cial Intelligence, Xiamen University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16258/16258-13-19752-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01655-improving-image-captioning-by-leveraging-intra-and-inter-layer-global-representation-in-transformer-network/",
        "doi": "10.1609/aaai.v35i2.16258",
        "pdf_size": 2364248
    },
    {
        "id": "12453",
        "title": "Improving Maximum k-plex Solver via Second-Order Reduction and Graph Color Bounding",
        "track": "main",
        "status": "Poster",
        "abstract": "In a graph, a k-plex is a vertex set in which every vertex is not adjacent to at most k vertices of this set. The maximum k-plex problem, which asks for the largest k-plex from the given graph, is a key primitive in a variety of real-world applications like community detection and so on. In the paper, we develop an exact algorithm, Maplex, for solving this problem in real world graphs practically. Based on the existing first-order and the novel second-order reduction rules, we design a powerful preprocessing method which efficiently removes redundant vertices and edges for Maplex. Also, the graph color heuristic is widely used for overestimating the maximum clique of a graph. For the first time, we generalize this technique for bounding the size of maximum k-plex in Maplex. Experiments are carried out to compare our algorithm with other state-of-the-art solvers on a wide range of publicly available graphs. Maplex outperforms all other algorithms on large real world graphs and is competitive with existing solvers on artificial dense graphs. Finally, we shed light on the effectiveness of each key component of Maplex.",
        "primary_area": "Search and Optimization",
        "author": "Yi Zhou; Shan Hu; Mingyu Xiao; Zhang-Hua Fu",
        "authorids": "",
        "aff": "University of Electronic Science and Technology of China; University of Electronic Science and Technology of China; University of Electronic Science and Technology of China; Shenzhen Institute of Artificial Intelligence and Robotics for Society; The Chinese University of Hong Kong, Shenzhen",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17477/17477-13-20971-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12453-improving-maximum-k-plex-solver-via-second-order-reduction-and-graph-color-bounding/",
        "doi": "10.1609/aaai.v35i14.17477",
        "pdf_size": 1930031
    },
    {
        "id": "09161",
        "title": "Improving Model Robustness by Adaptively Correcting Perturbation Levels with Active Queries",
        "track": "main",
        "status": "Poster",
        "abstract": "In addition to high accuracy, robustness is becoming increasingly important for machine learning models in various applications. Recently, much research has been devoted to improving the model robustness by training with noise perturbations. Most existing studies assume a fixed perturbation level for all training examples, which however hardly holds in real tasks. In fact, excessive perturbations may destroy the discriminative content of an example, while deficient perturbations may fail to provide helpful information for improving the robustness. Motivated by this observation, we propose to adaptively adjust the perturbation levels for each example in the training process. Specifically, a novel active learning framework is proposed to allow the model interactively querying the correct perturbation level from human experts. By designing a cost-effective sampling strategy along with a new query type, the robustness can be significantly improved with a few queries. Both theoretical analysis and experimental studies validate the effectiveness of the proposed approach.",
        "primary_area": "Machine Learning III",
        "author": "Kun-Peng Ning; Lue Tao; Songcan Chen; Sheng-Jun Huang",
        "authorids": "",
        "aff": "Nanjing University of Aeronautics and Astronautics; Nanjing University of Aeronautics and Astronautics; Nanjing University of Aeronautics and Astronautics; Nanjing University of Aeronautics and Astronautics",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17106/17106-13-20600-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09161-improving-model-robustness-by-adaptively-correcting-perturbation-levels-with-active-queries/",
        "doi": "10.1609/aaai.v35i10.17106",
        "pdf_size": 1179663
    },
    {
        "id": "11666",
        "title": "Improving Robustness to Model Inversion Attacks via Mutual Information Regularization",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper studies defense mechanisms against model inversion (MI) attacks -- a type of privacy attacks aimed at inferring information about the training data distribution given the access to a target machine learning model. Existing defense mechanisms rely on model-specific heuristics or noise injection. While being able to mitigate attacks, existing methods significantly hinder model performance. There remains a question of how to design a defense mechanism that is applicable to a variety of models and achieves better utility-privacy tradeoff.  In this paper, we propose the Mutual Information Regularization based Defense (MID) against MI attacks. The key idea is to limit the information about the model input contained in the prediction, thereby limiting the ability of an adversary to infer the private training attributes from the model prediction. Our defense principle is model-agnostic and we present tractable approximations to the regularizer for linear regression, decision trees, and neural networks, which have been successfully attacked by prior work if not attached with any defenses. We present a formal study of MI attacks by devising a rigorous game-based definition and quantifying the associated information leakage. Our theoretical analysis sheds light on the inefficacy of DP in defending against MI attacks, which has been empirically observed in several prior works. Our experiments demonstrate that MID leads to state-of-the-art performance for a variety of MI attacks, target models and datasets.",
        "primary_area": "Philosophy and Ethics of AI",
        "author": "Tianhao Wang; Yuheng Zhang; Ruoxi Jia",
        "authorids": "",
        "aff": "Harvard University; University of Illinois Urbana-Champaign; Virginia Tech",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17387/17387-13-20881-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11666-improving-robustness-to-model-inversion-attacks-via-mutual-information-regularization/",
        "doi": "10.1609/aaai.v35i13.17387",
        "pdf_size": 2120653
    },
    {
        "id": "10674",
        "title": "Improving Sample Efficiency in Model-Free Reinforcement Learning from Images",
        "track": "main",
        "status": "Poster",
        "abstract": "Training an agent to solve control tasks directly from high-dimensional images with model-free reinforcement learning (RL) has proven difficult. A promising approach is to learn a latent representation together with the control policy. However, fitting a high-capacity encoder using a scarce reward signal is sample inefficient and leads to poor performance. Prior work has shown that auxiliary losses, such as image reconstruction, can aid efficient representation learning.   However, incorporating reconstruction loss into an off-policy learning algorithm often leads to training instability. We explore the underlying reasons and  identify variational autoencoders, used by previous investigations, as the cause of the divergence.    Following these findings, we propose effective techniques to improve training stability.  This results in a simple approach capable of matching state-of-the-art model-free and model-based algorithms on MuJoCo control tasks. Furthermore, our approach demonstrates robustness to observational noise, surpassing existing approaches in this setting. Code, results, and videos are anonymously available at https://sites.google.com/view/sac-ae/home.",
        "primary_area": "Machine Learning V",
        "author": "Denis Yarats; Amy Zhang; Ilya Kostrikov; Brandon Amos; Joelle Pineau; Rob Fergus",
        "authorids": "",
        "aff": "New York University Facebook AI Research; McGill University MILA Facebook AI Research; New York University; Facebook AI Research; McGill University MILA Facebook AI Research; New York University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17276/17276-13-20770-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10674-improving-sample-efficiency-in-model-free-reinforcement-learning-from-images/",
        "doi": "10.1609/aaai.v35i12.17276",
        "pdf_size": 1947154
    },
    {
        "id": "14121",
        "title": "Improving Tree-Structured Decoder Training for Code Generation via Mutual Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Code generation aims to automatically generate a piece of code given an input natural language utterance. Currently, among dominant models, it is treated as a sequence-to-tree task, where a decoder outputs a sequence of actions corresponding to the pre-order traversal of an Abstract Syntax Tree. However, such a decoder only exploits the pre-order traversal based preceding actions, which are insufficient to ensure correct action predictions. In this paper, we first throughly analyze the context modeling difference between neural code generation models with different traversals based decodings (preorder traversal vs breadth-first traversal), and then propose to introduce a mutual learning framework to jointly train these models. Under this framework, we continuously enhance both two models via mutual distillation, which involves synchronous executions of two one-to-one knowledge transfers at each training step. More specifically, we alternately choose one model as the student and the other as its teacher, and require the student to fit the training data and the action prediction distributions of its teacher. By doing so, both models can fully absorb the knowledge from each other and thus could be improved simultaneously. Experimental results and in-depth analysis on several benchmark datasets demonstrate the effectiveness of our approach. We release our code at https://github.com/DeepLearnXMU/CGML.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Binbin Xie; Jinsong Su; Yubin Ge; Xiang Li; Jianwei Cui; Junfeng Yao; Bin Wang",
        "authorids": "",
        "aff": "Xiamen University Peng Cheng Laboratory; Xiamen University Peng Cheng Laboratory; University of Illinois at Urbana-Champaign; Xiaomi AI Lab; Xiaomi AI Lab; Xiamen University; Xiaomi AI Lab",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17662/17662-13-21156-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14121-improving-tree-structured-decoder-training-for-code-generation-via-mutual-learning/",
        "doi": "10.1609/aaai.v35i16.17662",
        "pdf_size": 268583
    },
    {
        "id": "13226",
        "title": "Improving the Efficiency and Effectiveness for BERT-based Entity Resolution",
        "track": "main",
        "status": "Poster",
        "abstract": "BERT has set a new state-of-the-art performance on entity resolution (ER) task, largely owed to fine-tuning pre-trained language models and the deep pair-wise interaction. Albeit being remarkably effective, it comes with a steep increase in computational cost, as the deep-interaction requires to exhaustively compute every tuple pair to search for co-references. For ER task, it is often prohibitively expensive due to the large cardinality to be matched. To tackle this, we introduce a siamese network structure that independently encodes tuples using BERT but delays the pair-wise interaction via an enhanced alignment network. This siamese structure enables a dedicated blocking module to quickly filter out obviously dissimilar tuple pairs, and thus drastically reduces the cardinality of fine-grained matching. Further, the blocking and entity matching are integrated into a multi-task learning framework for facilitating both tasks. Extensive experiments on multiple datasets demonstrate that our model significantly outperforms state-of-the-art models (including BERT) in both efficiency and effectiveness.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Bing Li; Yukai Miao; Yaoshu Wang; Yifang Sun; Wei Wang",
        "authorids": "",
        "aff": "University of New South Wales, Australia; University of New South Wales, Australia; Shenzhen Institute of Computing Sciences, Shenzhen University, China; School of Computer Science and Engineering, Northeastern University, China; Dongguan University of Technology, China University of New South Wales, Australia",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17562/17562-13-21056-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13226-improving-the-efficiency-and-effectiveness-for-bert-based-entity-resolution/",
        "doi": "10.1609/aaai.v35i15.17562",
        "pdf_size": 400136
    },
    {
        "id": "05967",
        "title": "Improving the Performance-Compatibility Tradeoff with Personalized Objective Functions",
        "track": "main",
        "status": "Poster",
        "abstract": "AI-systems that model and interact with their users can up-date their models over time to reflect new information and changes in the environment. Although these updates may improve the overall performance of the AI-system, they may actually hurt the performance with respect to individual users. Prior work has studied the tradeoff between improving the system\u2019s performance following an update and the compatibility of the updated system with prior user experience. The more the model is forced to be compatible with a prior version, the higher loss in performance it will incur. This paper challenges this assumption by showing that by personalizing the loss function to specific users, it is possible to increase the prediction performance of the AI-system while sacrificing less compatibility for these users. Our approach updates the sample weights to reflect their contribution to the compatibility of the model for a particular user following the update. We construct a portfolio of different models that vary in how they personalize the loss function for a user. We select the best model to use for a target user based on a validation set. We apply this approach to three supervised learning tasks commonly used in the human-computer decision-making literature. We show that using our approach leads to significant improvements in the performance-compatibility tradeoff over the non-personalized approach of Bansal et al., achieving up to 300% improvement for certain users. We present several use cases that illustrate the difference between the personalized and non-personalized approach for two of our domains.",
        "primary_area": "Humans and AI",
        "author": "Jonathan Martinez; Kobi Gal; Ece Kamar; Levi H. S. Lelis",
        "authorids": "",
        "aff": "Ben-Gurion University; Ben-Gurion University, University of Edinburgh; Microsoft Research; University of Alberta Alberta Machine Intelligence Institute (Amii)",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16745/16745-13-20239-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05967-improving-the-performance-compatibility-tradeoff-with-personalized-objective-functions/",
        "doi": "10.1609/aaai.v35i7.16745",
        "pdf_size": 469464
    },
    {
        "id": "00336",
        "title": "In-game Residential Home Planning via Visual Context-aware Global Relation Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "",
        "primary_area": "Application Domains",
        "author": "Lijuan Liu; Yin Yang; Yi Yuan; Tianjia Shao; He Wang; Kun Zhou",
        "authorids": "",
        "aff": "",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16109/16109-13-19603-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00336-in-game-residential-home-planning-via-visual-context-aware-global-relation-learning/",
        "doi": "",
        "pdf_size": 1755970
    },
    {
        "id": "05797",
        "title": "Incentive-Aware PAC Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "We study PAC learning in the presence of strategic manipulation, where data points may modify their features in certain predefined ways in order to receive a better outcome. We show that the vanilla ERM principle fails to achieve any nontrivial guarantee in this context. Instead, we propose an incentive-aware version of the ERM principle which has asymptotically optimal sample complexity. We then focus our attention on incentive-compatible classifiers, which provably prevent any kind of strategic manipulation. We give a sample complexity bound that is, curiously, independent of the hypothesis class, for the ERM principle restricted to incentive-compatible classifiers. This suggests that incentive compatibility alone can act as an effective means of regularization. We further show that it is without loss of generality to consider only incentive-compatible classifiers when opportunities for strategic manipulation satisfy a transitivity condition. As a consequence, in such cases, our hypothesis-class-independent sample complexity bound applies even without incentive compatibility. Our results set the foundations of incentive-aware PAC learning.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Hanrui Zhang; Vincent Conitzer",
        "authorids": "",
        "aff": "Duke University; Duke University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16726/16726-13-20220-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05797-incentive-aware-pac-learning/",
        "doi": "10.1609/aaai.v35i6.16726",
        "pdf_size": 145573
    },
    {
        "id": "05347",
        "title": "Incentivizing Truthfulness Through Audits in Strategic Classification",
        "track": "main",
        "status": "Poster",
        "abstract": "In many societal resource allocation domains, machine learning methods are increasingly used to either score or rank agents in order to decide which ones should receive either resources (e.g., homeless services) or scrutiny (e.g., child welfare investigations) from social services agencies. An agency's scoring function typically operates on a feature vector that contains a combination of self-reported features and information available to the agency about individuals or households.     This can create incentives for agents to misrepresent their self-reported features in order to receive resources or avoid scrutiny, but agencies may be able to selectively audit agents to verify the veracity of their reports.          We study the problem of optimal auditing of agents in such settings. When decisions are made using a threshold on an agent's score, the optimal audit policy has a surprisingly simple structure, uniformly auditing all agents who could benefit from lying.     While this policy can, in general be hard to compute because of the difficulty of identifying the set of agents who could benefit from lying given a complete set of reported types, we also present sufficient conditions under which it is tractable.     We show that the scarce resource setting is more difficult, and exhibit an approximately optimal audit policy in this case.     In addition, we show that in either setting verifying whether it is possible to incentivize exact truthfulness is hard even to approximate.     However, we also exhibit sufficient conditions for solving this problem optimally, and for obtaining good approximations.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Andrew Estornell; Sanmay Das; Yevgeniy Vorobeychik",
        "authorids": "",
        "aff": "Washington University in St Louis; George Mason University; Washington University in St. Louis",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16674/16674-13-20168-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05347-incentivizing-truthfulness-through-audits-in-strategic-classification/",
        "doi": "10.1609/aaai.v35i6.16674",
        "pdf_size": 149605
    },
    {
        "id": "07537",
        "title": "Increasing Iterate Averaging for Solving Saddle-Point Problems",
        "track": "main",
        "status": "Poster",
        "abstract": "Many problems in machine learning and game theory can be formulated as saddle-point problems, for which various first-order methods have been developed and proven efficient in practice. Under the general convex-concave assumption, most first-order methods only guarantee an ergodic convergence rate, that is, the uniform averages of the iterates converge at a O(1/T) rate in terms of the saddle-point residual. However, numerically, the iterates themselves can often converge much faster than the uniform averages. This observation motivates increasing averaging schemes that put more weight on later iterates, in contrast to the usual uniform averaging. We show that such increasing averaging schemes, applied to various first-order methods, are able to preserve the O(1/T) convergence rate with no additional assumptions or computational overhead. Extensive numerical experiments on zero-sum game solving, market equilibrium computation and image denoising demonstrate the effectiveness of the proposed schemes. In particular, the increasing averages consistently outperform the uniform averages in all test problems by orders of magnitude. When solving matrix and extensive-form games, increasing averages consistently outperform the last iterates as well. For matrix games, a first-order method equipped with increasing averaging outperforms the highly competitive CFR+ algorithm.",
        "primary_area": "Machine Learning II",
        "author": "Yuan Gao; Christian Kroer; Donald Goldfarb",
        "authorids": "",
        "aff": "Columbia University; Columbia University; Columbia University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16923/16923-13-20417-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07537-increasing-iterate-averaging-for-solving-saddle-point-problems/",
        "doi": "10.1609/aaai.v35i9.16923",
        "pdf_size": 4769094
    },
    {
        "id": "10254",
        "title": "Incremental Embedding Learning via Zero-Shot Translation",
        "track": "main",
        "status": "Poster",
        "abstract": "Modern deep learning methods have achieved great success in machine learning and computer vision fields by learning a set of pre-defined datasets. Howerver, these methods perform unsatisfactorily when applied into real-world situations. The reason of this phenomenon is that learning new tasks leads the trained model quickly forget the knowledge of old tasks, which is referred to as catastrophic forgetting. Current state-of-the-art incremental learning methods tackle catastrophic forgetting problem in traditional classification networks and ignore the problem existing in embedding networks, which are the basic networks for image retrieval, face recognition, zero-shot learning, etc. Different from traditional incremental classification networks, the semantic gap between the embedding spaces of two adjacent tasks is the main challenge for embedding networks under incremental learning setting. Thus, we propose a novel class-incremental method for embedding network, named as zero-shot translation class-incremental method (ZSTCI), which leverages zero-shot translation to estimate and compensate the semantic gap without any exemplars. Then, we try to learn a unified representation for two adjacent tasks in sequential learning process, which captures the relationships of previous classes and current classes precisely. In addition, ZSTCI can easily be combined with existing regularization-based incremental learning methods to further improve performance of embedding networks. We conduct extensive experiments on CUB-200-2011 and CIFAR100, and the experiment results prove the effectiveness of our method. The code of our method has been released in https://github.com/Drkun/ZSTCI.",
        "primary_area": "Machine Learning IV",
        "author": "Kun Wei; Cheng Deng; Xu Yang; Maosen Li",
        "authorids": "",
        "aff": "Xidian University; Xidian University; Xidian University; Xidian University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17229/17229-13-20723-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10254-incremental-embedding-learning-via-zero-shot-translation/",
        "doi": "10.1609/aaai.v35i11.17229",
        "pdf_size": 239707
    },
    {
        "id": "05975",
        "title": "Indecision Modeling",
        "track": "main",
        "status": "Poster",
        "abstract": "AI systems are often used to make or contribute to important decisions in a growing range of applications, including criminal justice, hiring, and medicine. Since these decisions impact human lives, it is important that the AI systems act in ways which align with human values. Techniques for preference modeling and social choice help researchers learn and aggregate peoples' preferences, which are used to guide AI behavior; thus, it is imperative that these learned preferences are accurate. These techniques often assume that people are willing to express strict preferences over alternatives; which is not true in practice. People are often indecisive, and especially so when their decision has moral implications. The philosophy and psychology literature shows that indecision is a measurable and nuanced behavior---and that there are several different reasons people are indecisive. This complicates the task of both learning and aggregating preferences, since most of the relevant literature makes restrictive assumptions on the meaning of indecision. We begin to close this gap by formalizing several mathematical indecision models based on theories from philosophy, psychology, and economics; these models can be used to describe (indecisive) agent decisions, both when they are allowed to express indecision and when they are not. We test these models using data collected from an online survey where participants choose how to (hypothetically) allocate organs to patients waiting for a transplant.",
        "primary_area": "Humans and AI",
        "author": "Duncan C. McElfresh; Lok Chan; Kenzie Doyle; Walter Sinnott-Armstrong; Vincent Conitzer; Jana Schaich Borg; John P. Dickerson",
        "authorids": "",
        "aff": "University of Maryland; Duke University; University of Oregon; Duke University; Duke University; Duke University; University of Maryland",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16746/16746-13-20240-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05975-indecision-modeling/",
        "doi": "10.1609/aaai.v35i7.16746",
        "pdf_size": 174554
    },
    {
        "id": "11496",
        "title": "Individual Fairness in Kidney Exchange Programs",
        "track": "main",
        "status": "Poster",
        "abstract": "Kidney transplant is the preferred method of treatment for patients suffering from kidney failure. However, not all patients can find a donor which matches their physiological characteristics. Kidney exchange programs (KEPs) seek to match such incompatible patient-donor pairs together, usually with the main objective of maximizing the total number of transplants.  Since selecting one optimal solution translates to a decision on who receives a transplant, it has a major effect on the lives of patients. The current practice in selecting an optimal solution does not necessarily ensure fairness in the selection process. In this paper, the existence of multiple optimal plans for a KEP is explored as a mean to achieve individual fairness. We propose the use of randomized policies for selecting an optimal solution in which patients' equal opportunity to receive a transplant is promoted. Our approach gives rise to the problem of enumerating all optimal solutions, which we tackle using a hybrid of constraint programming and linear programming. The advantages of our proposed method over the common practice of using the optimal solution obtained by a solver are stressed through computational experiments. Our methodology enables decision makers to fully control KEP outcomes, overcoming any potential bias or vulnerability intrinsic to a deterministic solver.",
        "primary_area": "Philosophy and Ethics of AI",
        "author": "Golnoosh Farnadi; William St-Arnaud; Behrouz Babaki; Margarida Carvalho",
        "authorids": "",
        "aff": "HEC Montr\u00e9al Mila Universit\u00e9 de Montr\u00e9al CIRRELT; Universit\u00e9 de Montr\u00e9al; Polytechnique Montr\u00e9al; Universit\u00e9 de Montr\u00e9al CIRRELT",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17369/17369-13-20863-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11496-individual-fairness-in-kidney-exchange-programs/",
        "doi": "10.1609/aaai.v35i13.17369",
        "pdf_size": 689483
    },
    {
        "id": "04478",
        "title": "Inductive Graph Neural Networks for Spatiotemporal Kriging",
        "track": "main",
        "status": "Poster",
        "abstract": "Time series forecasting and spatiotemporal kriging are the two most important tasks in spatiotemporal data analysis. Recent research on graph neural networks has made substantial progress in time series forecasting, while little attention has been paid to the kriging problem---recovering signals for unsampled locations/sensors. Most existing scalable kriging methods (e.g., matrix/tensor completion) are transductive, and thus full retraining is required when we have a new sensor to interpolate. In this paper, we develop an Inductive Graph Neural Network Kriging (IGNNK) model to recover data for unsampled sensors on a network/graph structure. To generalize the effect of distance and reachability, we generate random subgraphs as samples and the corresponding adjacency matrix for each sample. By reconstructing all signals on each sample subgraph, IGNNK can effectively learn the spatial message passing mechanism. Empirical results on several real-world spatiotemporal datasets demonstrate the effectiveness of our model. In addition, we also find that the learned model can be successfully transferred to the same type of kriging tasks on an unseen dataset. Our results show that: 1) GNN is an efficient and effective tool for spatial kriging; 2) inductive GNNs can be trained using dynamic adjacency matrices; 3) a trained model can be transferred to new graph structures and 4) IGNNK can be used to generate virtual sensors.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Yuankai Wu; Dingyi Zhuang; Aurelie Labbe; Lijun Sun",
        "authorids": "",
        "aff": "McGill University; McGill University; HEC Montreal; McGill University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16575/16575-13-20069-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04478-inductive-graph-neural-networks-for-spatiotemporal-kriging/",
        "doi": "10.1609/aaai.v35i5.16575",
        "pdf_size": 732178
    },
    {
        "id": "01993",
        "title": "Inference Fusion with Associative Semantics for Unseen Object Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "We study the problem of object detection when training and test objects are disjoint, i.e. no training examples of the target classes are available. Existing unseen object detection approaches usually combine generic detection frameworks with a single-path unseen classifier, by aligning object regions with semantic class embeddings. In this paper, inspired from human cognitive experience, we propose a simple but effective dual-path detection model that further explores associative semantics to supplement the basic visual-semantic knowledge transfer. We use a novel target-centric multiple-association strategy to establish concept associations, to ensure that the predictor generalized to unseen domain can be learned during training. In this way, through a reasonable inference fusion mechanism, those two parallel reasoning paths can strengthen the correlation between seen and unseen objects, thus improving detection performance. Experiments show that our inductive method can significantly boost the performance by 7.42% over inductive models, and even 5.25% over transductive models on MSCOCO dataset.",
        "primary_area": "Computer Vision II",
        "author": "Yanan Li; Pengyang Li; Han Cui; Donghui Wang",
        "authorids": "",
        "aff": "Zhejiang Lab; Zhejiang University; University of California at Los Angeles; Zhejiang University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16295/16295-13-19789-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01993-inference-fusion-with-associative-semantics-for-unseen-object-detection/",
        "doi": "10.1609/aaai.v35i3.16295",
        "pdf_size": 1226716
    },
    {
        "id": "11228",
        "title": "Inference-Based Deterministic Messaging For Multi-Agent Communication",
        "track": "main",
        "status": "Poster",
        "abstract": "Communication is essential for coordination among humans and animals. Therefore, with the introduction of intelligent agents into the world, agent-to-agent and agent-to-human communication becomes necessary. In this paper, we first study learning in matrix-based signaling games to empirically show that decentralized methods can converge to a suboptimal policy. We then propose a modification to the messaging policy, in which the sender deterministically chooses the best message that helps the receiver to infer the sender's observation. Using this modification, we see, empirically, that the agents converge to the optimal policy in nearly all the runs. We then apply this method to a partially observable gridworld environment which requires cooperation between two agents and show that, with appropriate approximation methods, the proposed sender modification can enhance existing decentralized training methods for more complex domains as well.",
        "primary_area": "Multiagent Systems",
        "author": "Varun Bhatt; Michael Buro",
        "authorids": "",
        "aff": "University of Alberta; University of Alberta",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17339/17339-13-20833-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11228-inference-based-deterministic-messaging-for-multi-agent-communication/",
        "doi": "10.1609/aaai.v35i13.17339",
        "pdf_size": 11093697
    },
    {
        "id": "03599",
        "title": "Inferring Camouflaged Objects by Texture-Aware Interactive Guidance Network",
        "track": "main",
        "status": "Poster",
        "abstract": "Camouflaged objects, similar to the background, show indefinable boundaries and deceptive textures, which increases the difficulty of detection task and makes the model rely on features with more information. Herein, we design a texture label to facilitate our network for accurate camouflaged object segmentation. Motivated by the complementary relationship between texture labels and camouflaged object labels, we propose an interactive guidance framework named TINet, which focuses on finding the indefinable boundary and the texture difference by progressive interactive guidance. It maximizes the guidance effect of refined multi-level texture cues on segmentation. Specifically, texture perception decoder (TPD) makes a comprehensive analysis of texture information in multiple scales. Feature interaction guidance decoder (FGD) interactively refines multi-level features of camouflaged object detection and texture detection level by level. Holistic perception decoder (HPD) enhances FGD results by multi-level holistic perception. In addition, we propose a boundary weight map to help the loss function pay more attention to the object boundary. Sufficient experiments conducted on COD and SOD datasets demonstrate that the proposed method performs favorably against 23 state-of-the-art methods.",
        "primary_area": "Computer Vision III",
        "author": "Jinchao Zhu; Xiaoyu Zhang; Shuo Zhang; Junnan Liu",
        "authorids": "",
        "aff": "Nankai University; Nankai University; Nankai University; Harbin Engineering University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16475/16475-13-19969-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03599-inferring-camouflaged-objects-by-texture-aware-interactive-guidance-network/",
        "doi": "10.1609/aaai.v35i4.16475",
        "pdf_size": 1709002
    },
    {
        "id": "06039",
        "title": "Inferring Emotion from Large-scale Internet Voice Data: A Semi-supervised Curriculum Augmentation based Deep Learning Approach",
        "track": "main",
        "status": "Poster",
        "abstract": "Effective emotion inference from user queries helps to give a more personified response for Voice Dialogue Applications(VDAs). The tremendous amounts of VDA users bring in diverse emotion expressions. How to achieve a high emotion inferring performance from large-scale Internet Voice Data in VDAs? Traditionally, researches on speech emotion recognition are based on acted voice datasets, which have limited speakers but strong and clear emotion expressions. Inspired by this, in this paper, we propose a novel approach to leverage acted voice data with strong emotion expressions to enhance large-scale unlabeled internet voice data with diverse emotion expressions for emotion inferring. Specifically, we propose a novel semi-supervised multi-modal curriculum augmentation deep learning framework. First, to learn more general emotion cues, we adopt a curriculum learning based epoch-wise training strategy, which trains our model guided by strong and balanced emotion samples from acted voice data and sub-sequently leverages weak and unbalanced emotion samples from internet voice data.Second, to employ more diverse emotion expressions, we design a Multi-path Mix-match Multimodal Deep Neural Network(MMMD), which effectively learns feature representations for multiple modalities and trains labeled and unlabeled data in hybrid semi-supervised methods for superior generalization and robustness. Experiments on an internet voice dataset with 500,000 utterances show our method outperforms (+10.09% in terms of F1) several alternative baselines,  while an acted corpus with 2,397 utterances contributes 4.35%. To further compare our method with state-of-the-art techniques in traditionally acted voice datasets, we also conduct experiments on public dataset IEMOCAP. The results reveal the effectiveness of the proposed approach.",
        "primary_area": "Humans and AI",
        "author": "Suping Zhou; Jia Jia; Zhiyong Wu; Zhihan Yang; Yanfeng Wang; Wei Chen; Fanbo Meng; Shuo Huang; Jialie Shen; Xiaochuan Wang",
        "authorids": "",
        "aff": "Tsinghua University; Tsinghua University; Tsinghua University; Tsinghua University; Sogou Corporation, Beijing, China; Sogou Corporation, Beijing, China; Sogou Corporation, Beijing, China; Tsinghua University; Queen's University, Belfast, U.K; Sogou Corporation, Beijing, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16753/16753-13-20247-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06039-inferring-emotion-from-large-scale-internet-voice-data-a-semi-supervised-curriculum-augmentation-based-deep-learning-approach/",
        "doi": "10.1609/aaai.v35i7.16753",
        "pdf_size": 4551095
    },
    {
        "id": "08921",
        "title": "Infinite Gaussian Mixture Modeling with an Improved Estimation of the Number of Clusters",
        "track": "main",
        "status": "Poster",
        "abstract": "Infinite Gaussian mixture modeling (IGMM) is a modeling method that determines all the parameters of a Gaussian mixture model (GMM), including its order. It has been well documented that it is a consistent estimator for probability density functions in the sense that, given enough training data from sufficiently regular probability density functions, it will converge to the shape of the original density curve. It is also known, however, that IGMM provides an inconsistent estimation of the number of clusters. The current paper shows that the nature of this inconsistency is an overestimation, and we pinpoint that this problem is an inherent part of the training algorithm. It stems mostly from a \"self-reinforcing feedback'' which is a certain relation between the likelihood function of one of the model hyperparameters (alpha) and the probability of sampling the number of components, that sustain their mutual growth during the Gibbs iterations. We show that this problem can be resolved by using informative priors for alpha and propose a modified training procedure that uses the inverse chi-square for this purpose. The modified algorithm successfully recovers the ``known\" order in all the experiments with synthetic data sets. It also demonstrates good results when compared to other methods used to evaluate model order, using real-world databases. Furthermore, the improved performance is attained without undermining the fidelity of estimating the original PDFs and with a significant reduction in computational cost.",
        "primary_area": "Machine Learning III",
        "author": "Avi Matza; Yuval Bistritz",
        "authorids": "",
        "aff": "Tel-Aviv University; Tel-Aviv University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17079/17079-13-20573-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08921-infinite-gaussian-mixture-modeling-with-an-improved-estimation-of-the-number-of-clusters/",
        "doi": "10.1609/aaai.v35i10.17079",
        "pdf_size": 393185
    },
    {
        "id": "05432",
        "title": "Infinite-Dimensional Fisher Markets: Equilibrium, Duality and Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper considers a linear Fisher market with n buyers and a continuum of items. In order to compute market equilibria, we introduce (infinite-dimensional) convex programs over Banach spaces, thereby generalizing the Eisenberg-Gale convex program and its dual. Regarding the new convex programs, we establish existence of optimal solutions, KKT conditions, as well as strong duality. All these properties are established via non-standard arguments, which circumvent the limitations of duality theory in optimization over infinite-dimensional vector spaces. Furthermore, we show that there exists a pure equilibrium allocation, i.e., a division of the item space. Similar to the finite-dimensional case, a market equilibrium under the infinite-dimensional Fisher market is Pareto optimal, envy-free and proportional. We also show how to obtain the (a.e. unique) equilibrium prices and a pure equilibrium allocation from the (unique) equilibrium utility prices. When the item space is the unit interval [0,1] and buyers have piecewise linear utilities, we show that approximate equilibrium prices can be computed in polynomial time. This is achieved by solving a finite-dimensional convex program using the ellipsoid method. To this end, we give nontrivial and efficient subgradient and separation oracles. For general buyer valuations, we propose computing market equilibrium using stochastic dual averaging, which finds approximate equilibrium prices with high probability.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Yuan Gao; Christian Kroer",
        "authorids": "",
        "aff": "Columbia University; Columbia University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16684/16684-13-20178-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05432-infinite-dimensional-fisher-markets-equilibrium-duality-and-optimization/",
        "doi": "10.1609/aaai.v35i6.16684",
        "pdf_size": 1299151
    },
    {
        "id": "11106",
        "title": "Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting",
        "track": "main",
        "status": "Poster",
        "abstract": "Many real-world applications require the prediction of long sequence time-series, such as electricity consumption planning. Long sequence time-series forecasting (LSTF) demands a high prediction capacity of the model, which is the ability to capture precise long-range dependency coupling between output and input efficiently. Recent studies have shown the potential of Transformer to increase the prediction capacity. However, there are several severe issues with Transformer that prevent it from being directly applicable to LSTF, including quadratic time complexity, high memory usage, and inherent limitation of the encoder-decoder architecture. To address these issues, we design an efficient transformer-based model for LSTF, named Informer, with three distinctive characteristics: (i) a ProbSparse self-attention mechanism, which achieves O(L log L) in time complexity and memory usage, and has comparable performance on sequences' dependency alignment. (ii) the self-attention distilling highlights dominating attention by halving cascading layer input, and efficiently handles extreme long input sequences. (iii) the generative style decoder, while conceptually simple, predicts the long time-series sequences at one forward operation rather than a step-by-step way, which drastically improves the inference speed of long-sequence predictions. Extensive experiments on four large-scale datasets demonstrate that Informer significantly outperforms existing methods and provides a new solution to the LSTF problem.",
        "primary_area": "Machine Learning V",
        "author": "Haoyi Zhou; Shanghang Zhang; Jieqi Peng; Shuai Zhang; Jianxin Li; Hui Xiong; Wancai Zhang",
        "authorids": "",
        "aff": "Beihang University, Beijing, China; UC Berkeley, California, US; Beihang University, Beijing, China; Beihang University, Beijing, China; Beihang University, Beijing, China; Rutgers University, New Jersey, US; Beijing Guowang Fuda Science & Technology Development Company",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17325/17325-13-20819-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11106-informer-beyond-efficient-transformer-for-long-sequence-time-series-forecasting/",
        "doi": "10.1609/aaai.v35i12.17325",
        "pdf_size": 4872493
    },
    {
        "id": "13343",
        "title": "Infusing Multi-Source Knowledge with Heterogeneous Graph Neural Network for Emotional Conversation Generation",
        "track": "main",
        "status": "Poster",
        "abstract": "The success of emotional conversation systems depends on sufficient perception and appropriate expression of emotions. In a real-world conversation, we firstly instinctively perceive emotions from multi-source information, including the emotion flow of dialogue history, facial expressions, and personalities of speakers, and then express suitable emotions according to our personalities, but these multiple types of information are insufficiently exploited in emotional conversation fields. To address this issue, we propose a heterogeneous graph-based model for emotional conversation generation. Specifically, we design a Heterogeneous Graph-Based Encoder to represent the conversation content (i.e., the dialogue history, its emotion flow, facial expressions, and speakers' personalities) with a heterogeneous graph neural network, and then predict suitable emotions for feedback. After that, we employ an Emotion-Personality-Aware Decoder to generate a response not only relevant to the conversation context but also with appropriate emotions, by taking the encoded graph representations, the predicted emotions from the encoder and the personality of the current speaker as inputs. Experimental results show that our model can effectively perceive emotions from multi-source knowledge and generate a satisfactory response, which significantly outperforms previous state-of-the-art models.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Yunlong Liang; Fandong Meng; Ying Zhang; Yufeng Chen; Jinan Xu; Jie Zhou",
        "authorids": "",
        "aff": "Beijing Jiaotong University, Beijing, China; Tencent WeChat AI - Pattern Recognition Center Tencent Inc, Beijing, China; Beijing Jiaotong University, Beijing, China; Beijing Jiaotong University, Beijing, China; Beijing Jiaotong University, Beijing, China; Tencent WeChat AI - Pattern Recognition Center Tencent Inc, Beijing, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17575/17575-13-21069-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13343-infusing-multi-source-knowledge-with-heterogeneous-graph-neural-network-for-emotional-conversation-generation/",
        "doi": "10.1609/aaai.v35i15.17575",
        "pdf_size": 542180
    },
    {
        "id": "01619",
        "title": "Initiative Defense against Facial Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Benefiting from the development of generative adversarial networks (GAN), facial manipulation has achieved significant progress in both academia and industry recently. It inspires an increasing number of entertainment applications but also incurs severe threats to individual privacy and even political security meanwhile. To mitigate such risks, many countermeasures have been proposed. However, the great majority methods are designed in a passive manner, which is to detect whether the facial images or videos are tampered after their wide propagation. These detection-based methods have a fatal limitation, that is, they only work for ex-post forensics but can not prevent the engendering of malicious behavior.  To address the limitation, in this paper, we propose a novel framework of initiative defense to degrade the performance of facial manipulation models controlled by malicious users. The basic idea is to actively inject imperceptible venom into target facial data before manipulation. To this end, we first imitate the target manipulation model with a surrogate model, and then devise a poison perturbation generator to obtain the desired venom. An alternating training strategy are further leveraged to train both the surrogate model and the perturbation generator. Two typical facial manipulation tasks: face attribute editing and face reenactment, are considered in our initiative defense framework. Extensive experiments demonstrate the effectiveness and robustness of our framework in different settings. Finally, we hope this work can shed some light on initiative countermeasures against more adversarial scenarios.",
        "primary_area": "Computer Vision I",
        "author": "Qidong Huang; Jie Zhang; Wenbo Zhou; Weiming Zhang; Nenghai Yu",
        "authorids": "",
        "aff": "University of Science and Technology of China; University of Science and Technology of China; University of Science and Technology of China; University of Science and Technology of China; University of Science and Technology of China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16254/16254-13-19748-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01619-initiative-defense-against-facial-manipulation/",
        "doi": "10.1609/aaai.v35i2.16254",
        "pdf_size": 8345702
    },
    {
        "id": "03190",
        "title": "Instance Mining with Class Feature Banks for Weakly Supervised Object Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent progress on weakly supervised object detection (WSOD) is characterized by formulating WSOD as a Multiple Instance Learning (MIL) problem and taking online refinement with the selected region proposals from MIL. However, MIL inclines to select the most discriminative part rather than the entire instance as the top-scoring region proposals, which leads to weak localization capability for weakly supervised object detectors. We attribute this problem to the limited intra-class diversity within a single image. Specifically, due to the lack of annotated bounding boxes, the network tends to focus on the most common parts of each class and neglect the diverse parts of objects. To solve the problem, we introduce a novel Instance Mining with Class Feature Banks (IM-CFB) framework, which includes a Class Feature Banks (CFB) module and a Feature Guided Instance Mining (FGIM) algorithm. Concretely, Class Feature Banks (CFB) consist of sub-banks for each class, which are utilized to collect diversity information from a broader view. At the training stage, the RoI features of reliable region proposals are recorded and updated in the CFB. Then, FGIM leverages the features recorded in the CFB to ameliorate the region proposal selection of the MIL branch. Extensive experiments conducted on two publicly available datasets, Pascal VOC 2007 and 2012, demonstrate the effectiveness of our method. More remarkably, our method achieves 54.3% on mAP and 70.7% on CorLoc on Pascal VOC 2007. When further re-trained by a Fast-RCNN detector, we obtain to-date the best reported mAP and CorLoc of 55.8% and 72.2%, respectively.",
        "primary_area": "Computer Vision III",
        "author": "Yufei Yin; Jiajun Deng; Wengang Zhou; Houqiang Li",
        "authorids": "",
        "aff": "University of Science and Technology of China; University of Science and Technology of China; University of Science and Technology of China Hefei Comprehensive National Science Center; University of Science and Technology of China Hefei Comprehensive National Science Center",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16429/16429-13-19923-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03190-instance-mining-with-class-feature-banks-for-weakly-supervised-object-detection/",
        "doi": "10.1609/aaai.v35i4.16429",
        "pdf_size": 1249765
    },
    {
        "id": "12131",
        "title": "Instrumental Variable-based Identification for Causal Effects using Covariate Information",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper deals with the identification problem of causal effects in randomized trials with noncompliance. In this problem, generally, causal effects are not identifiable and thus have been evaluated under some strict assumptions, or through the bounds. Different from existing studies, we propose novel identification conditions of joint probabilities of potential outcomes, which allow us to derive a consistent estimator of the causal effect. Regarding the identification conditions of joint probabilities of potential outcomes, the assumptions of monotonicity (Pearl, 2009), independence between potential outcomes (Robins & Richardson, 2011), gain equality (Li & Pearl, 2019) and specific functional relationships between cause and effect (Pearl, 2009) have been utilized. In contrast, without such assumptions, the proposed conditions enable us to evaluate joint probabilities of potential outcomes using an instrumental variable and a proxy variable of potential outcomes. The results of this paper extend the range of solvable identification problems in causal inference.",
        "primary_area": "Reasoning under Uncertainty",
        "author": "Yuta Kawakami",
        "authorids": "",
        "aff": "Yokohama National University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17440/17440-13-20934-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12131-instrumental-variable-based-identification-for-causal-effects-using-covariate-information/",
        "doi": "10.1609/aaai.v35i13.17440",
        "pdf_size": 209669
    },
    {
        "id": "03796",
        "title": "Integrated Optimization of Bipartite Matching and Its Stochastic Behavior: New Formulation and Approximation Algorithm via Min-cost Flow Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "The research field of stochastic matching has yielded many developments for various applications. In most stochastic matching problems, the probability distributions inherent in the nodes and edges are set a priori, and are not controllable. However, many matching services have options, which we call control variables, that affect the probability distributions and thus what constitutes an optimum matching. Although several methods for optimizing the values of the control variables have been developed, their optimization in consideration of the matching problem is still in its infancy. In this paper, we formulate an optimization problem for determining the values of the control variables so as to maximize the expected value of matching weights. Since this problem involves hard to evaluate objective values and is non-convex, we construct an approximation algorithm via a minimum-cost flow algorithm that can find 3-approximation solutions rapidly. Simulations on real data from a ride-hailing platform and a crowd-sourcing market show that the proposed method can find solutions with high profits of the service provider in practical time.",
        "primary_area": "Constraint Satisfaction and Optimization",
        "author": "Yuya Hikima; Yasunori Akagi; Hideaki Kim; Masahiro Kohjima; Takeshi Kurashima; Hiroyuki Toda",
        "authorids": "",
        "aff": "NTT Service Evolution Laboratories, NTT Corporation; NTT Service Evolution Laboratories, NTT Corporation; NTT Service Evolution Laboratories, NTT Corporation; NTT Service Evolution Laboratories, NTT Corporation; NTT Service Evolution Laboratories, NTT Corporation; NTT Service Evolution Laboratories, NTT Corporation",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16497/16497-13-19991-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03796-integrated-optimization-of-bipartite-matching-and-its-stochastic-behavior-new-formulation-and-approximation-algorithm-via-min-cost-flow-optimization/",
        "doi": "10.1609/aaai.v35i5.16497",
        "pdf_size": 371948
    },
    {
        "id": "00522",
        "title": "Integrating Static and Dynamic Data for Improved Prediction of Cognitive Declines Using Augmented Genotype-Phenotype Representations",
        "track": "main",
        "status": "Poster",
        "abstract": "Alzheimer\u2019s Disease (AD) is a chronic neurodegenerative disease that causes severe problems in patients\u2019 thinking, memory, and behavior. An early diagnosis is crucial to prevent AD progression; to this end, many algorithmic approaches have recently been proposed to predict cognitive decline. However, these predictive models often fail to integrate heterogeneous genetic and neuroimaging biomarkers and struggle to handle missing data. In this work we propose a novel objective function and an associated optimization algorithm to identify cognitive decline related to AD. Our approach is designed to incorporate dynamic neuroimaging data by way of a participant-specific augmentation combined with multimodal data integration aligned via a regression task. Our approach, in order to incorporate additional side-information, utilizes structured regularization techniques popularized in recent AD literature. Armed with the fixed-length vector representation learned from the multimodal dynamic and static modalities, conventional machine learning methods can be used to predict the clinical outcomes associated with AD.  Our experimental results show that the proposed augmentation model improves the prediction performance on cognitive assessment scores for a collection of popular machine learning algorithms. The results of our approach are interpreted to validate existing genetic and neuroimaging biomarkers that have been shown to be predictive of cognitive decline.",
        "primary_area": "Application Domains",
        "author": "Hoon Seo; Lodewijk Brand; Hua Wang; Feiping Nie",
        "authorids": "",
        "aff": "Colorado School of Mines; Colorado School of Mines; Colorado School of Mines; Northwestern Polytechnical University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16130/16130-13-19624-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00522-integrating-static-and-dynamic-data-for-improved-prediction-of-cognitive-declines-using-augmented-genotype-phenotype-representations/",
        "doi": "10.1609/aaai.v35i1.16130",
        "pdf_size": 461178
    },
    {
        "id": "14549",
        "title": "Interactive Speech and Noise Modeling for Speech Enhancement",
        "track": "main",
        "status": "Poster",
        "abstract": "Speech enhancement is challenging because of the diversity of background noise types. Most of the existing methods are focused on modelling the speech rather than the noise. In this paper, we propose a novel idea to model speech and noise simultaneously in a two-branch convolutional neural network, namely SN-Net. In SN-Net, the two branches predict speech and noise, respectively. Instead of information fusion only at the final output layer, interaction modules are introduced at several intermediate feature domains between the two branches to benefit each other. Such an interaction can leverage features learned from one branch to counteract the undesired part and restore the missing component of the other and thus enhance their discrimination capabilities. We also design a feature extraction module, namely residual-convolution-and-attention (RA), to capture the correlations along temporal and frequency dimensions for both the speech and the noises. Evaluations on public datasets show that the interaction module plays a key role in simultaneous modeling and the SN-Net outperforms the state-of-the-art by a large margin on various evaluation metrics. The proposed SN-Net also shows superior performance for speaker separation.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Chengyu Zheng; Xiulian Peng; Yuan Zhang; Sriram Srinivasan; Yan Lu",
        "authorids": "",
        "aff": "Communication University of China; Microsoft Research Asia; Communication University of China; Microsoft Corporation; Microsoft Research Asia",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17710/17710-13-21204-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14549-interactive-speech-and-noise-modeling-for-speech-enhancement/",
        "doi": "10.1609/aaai.v35i16.17710",
        "pdf_size": 3657706
    },
    {
        "id": "04912",
        "title": "Interpretable Actions: Controlling Experts with Understandable Commands",
        "track": "main",
        "status": "Poster",
        "abstract": "Despite the prevalence of deep neural networks, their single most cited drawback is that, even when successful, their operations are inscrutable.  For many applications, the desired outputs are the composition of externally-defined bases.  For such decomposable domains, we present a two-stage learning procedure producing combinations of the external bases which are trivially extractable from the network. In the first stage, the set of external bases that will form the solution are modeled as differentiable generator modules, controlled by the same parameters as the external bases.  In the second stage, a controller network is created that selects parameters for those generators, either successively or in parallel, to compose the final solution.  Through three tasks, we concretely demonstrate how our system yields readily understandable commands.  In one, we introduce a new form of artistic style transfer, learning to draw and color with crayons, in which the transformation of a photograph or painting occurs not as a single monolithic computation, but by the composition of thousands of individual, visualizable strokes.  The other two tasks, single-pass function approximation with arbitrary bases and shape-based synthesis, show how our approach produces understandable and extractable actions in two disparate domains.",
        "primary_area": "Neuro-Symbolic AI",
        "author": "Shumeet Baluja; David Marwood; Michele Covell",
        "authorids": "",
        "aff": "Google, Inc.; Google, Inc.; Google, Inc.",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16624/16624-13-20118-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04912-interpretable-actions-controlling-experts-with-understandable-commands/",
        "doi": "10.1609/aaai.v35i6.16624",
        "pdf_size": 10725826
    },
    {
        "id": "04608",
        "title": "Interpretable Clustering on Dynamic Graphs with Recurrent Graph Neural Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "We study the problem of clustering nodes in a dynamic graph, where the connections between nodes and nodes' cluster memberships may change over time, e.g., due to community migration. We first propose a dynamic stochastic block model that captures these changes, and a simple decay-based clustering algorithm that clusters nodes based on weighted connections between them, where the weight decreases at a fixed rate over time. This decay rate can then be interpreted as signifying the importance of including historical connection information in the clustering. However, the optimal decay rate may differ for clusters with different rates of turnover. We characterize the optimal decay rate for each cluster and propose a clustering method that achieves almost exact recovery of the true clusters. We then demonstrate the efficacy of our clustering algorithm with optimized decay rates on simulated graph data. Recurrent neural networks (RNNs), a popular algorithm for sequence learning, use a similar decay-based method, and we use this insight to propose two new RNN-GCN (graph convolutional network) architectures for semi-supervised graph clustering. We finally demonstrate that the proposed architectures perform well on real data compared to state-of-the-art graph clustering algorithms.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Yuhang Yao; Carlee Joe-Wong",
        "authorids": "",
        "aff": "Carnegie Mellon University; Carnegie Mellon University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16590/16590-13-20084-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04608-interpretable-clustering-on-dynamic-graphs-with-recurrent-graph-neural-networks/",
        "doi": "10.1609/aaai.v35i5.16590",
        "pdf_size": 239056
    },
    {
        "id": "08297",
        "title": "Interpretable Embedding Procedure Knowledge Transfer via Stacked Principal Component Analysis and Graph Neural Network",
        "track": "main",
        "status": "Poster",
        "abstract": "Knowledge distillation (KD) is one of the most useful techniques for light-weight neural networks. Although neural networks have a clear purpose of embedding datasets into the low-dimensional space, the existing knowledge was quite far from this purpose and provided only limited information. We argue that good knowledge should be able to interpret the embedding procedure. This paper proposes a method of generating interpretable embedding procedure (IEP) knowledge based on principal component analysis, and distilling it based on a message passing neural network. Experimental results show that the student network trained by the proposed KD method improves 2.28% in the CIFAR100 dataset, which is a higher performance than the state-of-the-art (SOTA) method. We also demonstrate that the embedding procedure knowledge is interpretable via visualization of the proposed KD process. The implemented code is available at https://github.com/sseung0703/IEPKT.",
        "primary_area": "Machine Learning II",
        "author": "Seunghyun Lee; Byung Cheol Song",
        "authorids": "",
        "aff": "Inha University; Inha University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17009/17009-13-20503-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08297-interpretable-embedding-procedure-knowledge-transfer-via-stacked-principal-component-analysis-and-graph-neural-network/",
        "doi": "10.1609/aaai.v35i9.17009",
        "pdf_size": 1082624
    },
    {
        "id": "01469",
        "title": "Interpretable Graph Capsule Networks for Object Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "Capsule Networks, as alternatives to Convolutional Neural Networks, have been proposed to recognize objects from images. The current literature demonstrates many advantages of CapsNets over CNNs. However, how to create explanations for individual classifications of CapsNets has not been well explored. The widely used saliency methods are mainly proposed for explaining CNN-based classifications; they create saliency map explanations by combining activation values and the corresponding gradients, e.g., Grad-CAM. These saliency methods require a specific architecture of the underlying classifiers and cannot be trivially applied to CapsNets due to the iterative routing mechanism therein. To overcome the lack of interpretability, we can either propose new post-hoc interpretation methods for CapsNets or modifying the model to have build-in explanations. In this work, we explore the latter. Specifically, we propose interpretable Graph Capsule Networks (GraCapsNets), where we replace the routing part with a multi-head attention-based Graph Pooling approach. In the proposed model, individual classification explanations can be created effectively and efficiently. Our model also demonstrates some unexpected benefits, even though it replaces the fundamental part of CapsNets. Our GraCapsNets achieve better classification performance with fewer parameters and better adversarial robustness, when compared to CapsNets. Besides, GraCapsNets also keep other advantages of CapsNets, namely, disentangled representations and affine transformation robustness.",
        "primary_area": "Computer Vision I",
        "author": "Jindong Gu",
        "authorids": "",
        "aff": "University of Munich Siemens AG, Corporate Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16237/16237-13-19731-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01469-interpretable-graph-capsule-networks-for-object-recognition/",
        "doi": "10.1609/aaai.v35i2.16237",
        "pdf_size": 873487
    },
    {
        "id": "13306",
        "title": "Interpretable NLG for Task-oriented Dialogue Systems with Heterogeneous Rendering Machines",
        "track": "main",
        "status": "Poster",
        "abstract": "End-to-end neural networks have achieved promising performances in natural language generation (NLG). However, they are treated as black boxes and lack interpretability. To address this problem, we propose a novel framework, heterogeneous rendering machines (HRM), that interprets how neural generators render an input dialogue act (DA) into an utterance. HRM consists of a renderer set and a mode switcher. The renderer set contains multiple decoders that vary in both structure and functionality. For every generation step, the mode switcher selects an appropriate decoder from the renderer set to generate an item (a word or a phrase). To verify the effectiveness of our method, we have conducted extensive experiments on 5 benchmark datasets. In terms of automatic metrics (e.g., BLEU), our model is competitive with the current state-of-the-art method. The qualitative analysis shows that our model can interpret the rendering process of neural generators well. Human evaluation also confirms the interpretability of our proposed approach.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Yangming Li; Kaisheng Yao",
        "authorids": "",
        "aff": "Harbin Institute of Technology; Ant Group",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17571/17571-13-21065-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13306-interpretable-nlg-for-task-oriented-dialogue-systems-with-heterogeneous-rendering-machines/",
        "doi": "10.1609/aaai.v35i15.17571",
        "pdf_size": 238488
    },
    {
        "id": "00818",
        "title": "Interpretable Self-Supervised Facial Micro-Expression Learning to Predict Cognitive State and Neurological Disorders",
        "track": "main",
        "status": "Poster",
        "abstract": "Human behavior is the confluence of output from voluntary and involuntary motor systems. The neural activities that mediate behavior, from individual cells to distributed networks, are in a state of constant flux. Artificial intelligence (AI) research over the past decade shows that behavior, in the form of facial muscle activity, can reveal information about fleeting voluntary and involuntary motor system activity related to emotion, pain, and deception. However, the AI algorithms often lack an explanation for their decisions, and learning meaningful representations requires large datasets labeled by a subject-matter expert. Motivated by the success of using facial muscle movements to classify brain states and the importance of learning from small amounts of data, we propose an explainable self-supervised representation-learning paradigm that learns meaningful temporal facial muscle movement patterns from limited samples. We validate our methodology by carrying out comprehensive empirical study to predict future speech behavior in a real-world dataset of adults who stutter (AWS). Our explainability study found facial muscle movements around the eyes (p",
        "primary_area": "Cognitive Modeling and Cognitive Systems",
        "author": "Arun Das; Jeffrey Mock; Yufei Huang; Edward Golob; Peyman Najafirad",
        "authorids": "",
        "aff": "University of Texas at San Antonio; University of Texas at San Antonio; University of Texas at San Antonio; University of Texas at San Antonio; University of Texas at San Antonio",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16164/16164-13-19658-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00818-interpretable-self-supervised-facial-micro-expression-learning-to-predict-cognitive-state-and-neurological-disorders/",
        "doi": "10.1609/aaai.v35i1.16164",
        "pdf_size": 1847585
    },
    {
        "id": "09647",
        "title": "Interpretable Sequence Classification via Discrete Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "Sequence classification is the task of predicting a class label given a sequence of observations.  In many applications such as healthcare monitoring or intrusion detection, early classification is crucial to prompt intervention. In this work, we learn sequence classifiers that favour early classification from an evolving observation trace. While many state-of-the-art sequence classifiers are neural networks, and in particular LSTMs, our classifiers take the form of finite state automata and are learned via discrete optimization. Our automata-based classifiers are interpretable---supporting explanation, counterfactual reasoning, and human-in-the-loop modification---and have strong empirical performance. Experiments over a suite of goal recognition and behaviour classification datasets show our learned automata-based classifiers to have comparable test performance to LSTM-based classifiers, with the added advantage of  being interpretable.",
        "primary_area": "Machine Learning IV",
        "author": "Maayan Shvo; Andrew C. Li; Rodrigo Toro Icarte; Sheila A. McIlraith",
        "authorids": "",
        "aff": "University of Toronto Vector Institute Schwartz Reisman Institute for Technology and Society; University of Toronto Vector Institute; University of Toronto Vector Institute; University of Toronto Vector Institute Schwartz Reisman Institute for Technology and Society",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17161/17161-13-20655-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09647-interpretable-sequence-classification-via-discrete-optimization/",
        "doi": "10.1609/aaai.v35i11.17161",
        "pdf_size": 357293
    },
    {
        "id": "11604",
        "title": "Interpreting Deep Neural Networks with Relative Sectional Propagation by Analyzing Comparative Gradients and Hostile Activations",
        "track": "main",
        "status": "Poster",
        "abstract": "The clear transparency of Deep Neural Networks (DNNs) is hampered by complex internal structures and nonlinear transformations along deep hierarchies. In this paper, we propose a new attribution method, Relative Sectional Propagation (RSP), for fully decomposing the output predictions with the characteristics of class-discriminative attributions and clear objectness. We carefully revisit some shortcomings of backpropagation-based attribution methods, which are trade-off relations in decomposing DNNs. We define hostile factor as an element that interferes with finding the attributions of the target and propagate it in a distinguishable way to overcome the non-suppressed nature of activated neurons. As a result, it is possible to assign the bi-polar relevance scores of the target (positive) and hostile (negative) attributions while maintaining each attribution aligned with the importance. We also present the purging techniques to prevent the decrement of the gap between the relevance scores of the target and hostile attributions during backward propagation by eliminating the conflicting units to channel attribution map. Therefore, our method makes it possible to decompose the predictions of DNNs with clearer class-discriminativeness and detailed elucidations of activation neurons compared to the conventional attribution methods. In a verified experimental environment, we report the results of the assessments: (i) Pointing Game, (ii) mIoU, and (iii) Model Sensitivity with PASCAL VOC 2007, MS COCO 2014, and ImageNet datasets. The results demonstrate that our method outperforms existing backward decomposition methods, including distinctive and intuitive visualizations.",
        "primary_area": "Philosophy and Ethics of AI",
        "author": "Woo-Jeoung Nam; Jaesik Choi; Seong-Whan Lee",
        "authorids": "",
        "aff": "Korea University; KAIST; Korea University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17380/17380-13-20874-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11604-interpreting-deep-neural-networks-with-relative-sectional-propagation-by-analyzing-comparative-gradients-and-hostile-activations/",
        "doi": "10.1609/aaai.v35i13.17380",
        "pdf_size": 7535938
    },
    {
        "id": "10877",
        "title": "Interpreting Multivariate Shapley Interactions in DNNs",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper aims to explain deep neural networks (DNNs) from the perspective of multivariate interactions. In this paper, we define and quantify the significance of interactions among multiple input variables of the DNN. Input variables with strong interactions usually form a coalition and reflect prototype features, which are memorized and used by the DNN for inference. We define the significance of interactions based on the Shapley value, which is designed to assign the attribution value of each input variable to the inference. We have conducted experiments with various DNNs. Experimental results have demonstrated the effectiveness of the proposed method.",
        "primary_area": "Machine Learning V",
        "author": "Hao Zhang; Yichen Xie; Longjie Zheng; Die Zhang; Quanshi Zhang",
        "authorids": "",
        "aff": "Shanghai Jiao Tong University; Shanghai Jiao Tong University; Shanghai Jiao Tong University; Shanghai Jiao Tong University; Shanghai Jiao Tong University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17299/17299-13-20793-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10877-interpreting-multivariate-shapley-interactions-in-dnns/",
        "doi": "10.1609/aaai.v35i12.17299",
        "pdf_size": 1483602
    },
    {
        "id": "06463",
        "title": "Interpreting Neural Networks as Quantitative Argumentation Frameworks",
        "track": "main",
        "status": "Poster",
        "abstract": "We show that an interesting class of feed-forward neural networks can be understood as quantitative argumentation frameworks.  This connection creates a bridge between research in Formal Argumentation and Machine Learning. We generalize the semantics of feed-forward neural networks to acyclic graphs and study the resulting computational and semantical properties in argumentation graphs. As it turns out, the semantics gives stronger guarantees than existing semantics  that have been tailor-made for the argumentation setting.  From a machine-learning perspective, the connection does not seem immediately helpful. While it gives intuitive meaning to some feed-forward-neural networks, they remain difficult to understand due to their size and density. However, the connection seems helpful for combining background knowledge in form of sparse argumentation networks with dense neural networks that have been trained for complementary purposes and for learning the parameters of quantitative argumentation frameworks in an end-to-end fashion from data.",
        "primary_area": "Knowledge Representation and Reasoning",
        "author": "Nico Potyka",
        "authorids": "",
        "aff": "University of Stuttgart",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16801/16801-13-20295-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06463-interpreting-neural-networks-as-quantitative-argumentation-frameworks/",
        "doi": "10.1609/aaai.v35i7.16801",
        "pdf_size": 837285
    },
    {
        "id": "07961",
        "title": "Intrinsic Certified Robustness of Bagging against Data Poisoning Attacks",
        "track": "main",
        "status": "Poster",
        "abstract": "In a data poisoning attack, an attacker modifies, deletes, and/or inserts some training examples to corrupt the learnt machine learning model. Bootstrap Aggregating (bagging) is a well known ensemble learning method,  which trains multiple base models on random subsamples of a training dataset using a base learning algorithm and uses majority vote to predict labels of testing examples. We prove the intrinsic certified robustness of bagging against data poisoning attacks. Specifically, we show that bagging with an arbitrary base learning algorithm provably predicts the same label for a testing example when the number of modified, deleted, and/or inserted training examples is bounded by a threshold. Moreover, we show that our derived threshold is tight if no assumptions on the base learning algorithm are made.  We evaluate our method on  MNIST and CIFAR10. For instance, our method achieves a certified accuracy of 91.1% on MNIST when arbitrarily modifying, deleting, and/or inserting 100 training examples. Code is available at: https://github.com/jjy1994/BaggingCertifyDataPoisoning.",
        "primary_area": "Machine Learning II",
        "author": "Jinyuan Jia; Xiaoyu Cao; Neil Zhenqiang Gong",
        "authorids": "",
        "aff": "Duke University; Duke University; Duke University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16971/16971-13-20465-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07961-intrinsic-certified-robustness-of-bagging-against-data-poisoning-attacks/",
        "doi": "10.1609/aaai.v35i9.16971",
        "pdf_size": 476241
    },
    {
        "id": "03013",
        "title": "Invariant Teacher and Equivariant Student for Unsupervised 3D Human Pose Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a novel method based on teacher-student learning framework for 3D human pose estimation without any 3D annotation or side information. To solve this unsupervised-learning problem, the teacher network adopts pose-dictionary-based modeling for regularization to estimate a physically plausible 3D pose. To handle the decomposition ambiguity in the teacher network, we propose a cycle-consistent architecture promoting a 3D rotation-invariant property to train the teacher network. To further improve the estimation accuracy, the student network adopts a novel graph convolution network for flexibility to directly estimate the 3D coordinates. Another cycle-consistent architecture promoting 3D rotation-equivariant property is adopted to exploit geometry consistency, together with knowledge distillation from the teacher network to improve the pose estimation performance. We conduct extensive experiments on Human3.6M and MPI-INF-3DHP. Our method reduces the 3D joint prediction error by 11.4% compared to state-of-the-art unsupervised methods and also outperforms many weakly-supervised methods that use side information on Human3.6M.  Code will be available at https://github.com/sjtuxcx/ITES.",
        "primary_area": "Computer Vision III",
        "author": "Chenxin Xu; Siheng Chen; Maosen Li; Ya Zhang",
        "authorids": "",
        "aff": "Cooperative Medianet Innovation Center, Shanghai Jiao Tong University; Cooperative Medianet Innovation Center, Shanghai Jiao Tong University; Cooperative Medianet Innovation Center, Shanghai Jiao Tong University; Cooperative Medianet Innovation Center, Shanghai Jiao Tong University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16409/16409-13-19903-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03013-invariant-teacher-and-equivariant-student-for-unsupervised-3d-human-pose-estimation/",
        "doi": "10.1609/aaai.v35i4.16409",
        "pdf_size": 6128168
    },
    {
        "id": "09197",
        "title": "Inverse Reinforcement Learning From Like-Minded Teachers",
        "track": "main",
        "status": "Poster",
        "abstract": "We study the problem of learning a policy in a Markov decision process (MDP) based on observations of the actions taken by multiple teachers. We assume that the teachers are like-minded in that their reward functions -- while different from each other -- are random perturbations of an underlying reward function. Under this assumption, we demonstrate that inverse reinforcement learning algorithms that satisfy a certain property -- that of matching feature expectations -- yield policies that are approximately optimal with respect to the underlying reward function, and that no algorithm can do better in the worst case. We also show how to efficiently recover the optimal policy when the MDP has one state -- a setting that is akin to multi-armed bandits.",
        "primary_area": "Machine Learning III",
        "author": "Ritesh Noothigattu; Tom Yan; Ariel D. Procaccia",
        "authorids": "",
        "aff": "Carnegie Mellon University; Carnegie Mellon University; Harvard University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17110/17110-13-20604-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09197-inverse-reinforcement-learning-from-like-minded-teachers/",
        "doi": "10.1609/aaai.v35i10.17110",
        "pdf_size": 799736
    },
    {
        "id": "09472",
        "title": "Inverse Reinforcement Learning with Explicit Policy Estimates",
        "track": "main",
        "status": "Poster",
        "abstract": "Various methods for solving the inverse reinforcement learning (IRL) problem have been developed independently in machine learning and economics. In particular, the method of Maximum Causal Entropy IRL is based on the perspective of entropy maximization, while related advances in the field of economics instead assume the existence of unobserved action shocks to explain expert behavior (Nested Fixed Point Algorithm, Conditional Choice Probability method, Nested Pseudo-Likelihood Algorithm). In this work, we make previously unknown connections between these related methods from both fields. We achieve this by showing that they all belong to a class of optimization problems, characterized by a common form of the objective, the associated policy and the objective gradient. We demonstrate key computational and algorithmic differences which arise between the methods due to an approximation of the optimal soft value function, and describe how this leads to more efficient algorithms. Using insights which emerge from our study of this class of optimization problems, we identify various problem scenarios and investigate each method's suitability for these problems.",
        "primary_area": "Machine Learning IV",
        "author": "Navyata Sanghvi; Shinnosuke Usami; Mohit Sharma; Joachim Groeger; Kris Kitani",
        "authorids": "",
        "aff": "Carnegie Mellon University; Sony Corporation Carnegie Mellon University; Carnegie Mellon University; Carnegie Mellon University; Carnegie Mellon University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17141/17141-13-20635-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09472-inverse-reinforcement-learning-with-explicit-policy-estimates/",
        "doi": "10.1609/aaai.v35i11.17141",
        "pdf_size": 437368
    },
    {
        "id": "11116",
        "title": "Inverse Reinforcement Learning with Natural Language Goals",
        "track": "main",
        "status": "Poster",
        "abstract": "Humans generally use natural language to communicate task requirements to each other. Ideally, natural language should also be usable for communicating goals to autonomous machines (e.g., robots) to minimize friction in task specification. However, understanding and mapping natural language goals to sequences of states and actions is challenging. Specifically, existing work along these lines has encountered difficulty in generalizing learned policies to new natural language goals and environments. In this paper, we propose a novel adversarial inverse reinforcement learning algorithm to learn a language-conditioned policy and reward function. To improve generalization of the learned policy and reward function, we use a variational goal generator to relabel trajectories and sample diverse goals during training. Our algorithm outperforms multiple baselines by a large margin on a vision-based natural language instruction following dataset (Room-2-Room), demonstrating a promising advance in enabling the use of natural language instructions in specifying agent goals.",
        "primary_area": "Machine Learning V",
        "author": "Li Zhou; Kevin Small",
        "authorids": "",
        "aff": "Amazon; Amazon",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17326/17326-13-20820-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11116-inverse-reinforcement-learning-with-natural-language-goals/",
        "doi": "10.1609/aaai.v35i12.17326",
        "pdf_size": 779616
    },
    {
        "id": "11682",
        "title": "Invertible Concept-based Explanations for CNN Models with Non-negative Concept Activation Vectors",
        "track": "main",
        "status": "Poster",
        "abstract": "Convolutional neural network (CNN) models for computer vision are powerful but lack explainability in their most basic form. This deficiency remains a key challenge when applying CNNs in important domains. Recent work on explanations through feature importance of approximate linear models has moved from input-level features (pixels or segments) to features from mid-layer feature maps in the form of concept activation vectors (CAVs).  CAVs contain concept-level information and could be learned via clustering. In this work, we rethink the ACE algorithm of Ghorbani et~al., proposing an alternative invertible concept-based explanation (ICE) framework to overcome its shortcomings. Based on the requirements of fidelity (approximate models to target models) and interpretability (being meaningful to people), we design measurements and evaluate a range of matrix factorization methods with our framework. We find that non-negative concept activation vectors (NCAVs) from non-negative matrix factorization provide superior performance in interpretability and fidelity based on computational and human subject experiments. Our framework provides both local and global concept-level explanations for pre-trained CNN models.",
        "primary_area": "Philosophy and Ethics of AI",
        "author": "Ruihan Zhang; Prashan Madumal; Tim Miller; Krista A. Ehinger; Benjamin I. P. Rubinstein",
        "authorids": "",
        "aff": "School of Computing and Information Systems, The University of Melbourne; School of Computing and Information Systems, The University of Melbourne; School of Computing and Information Systems, The University of Melbourne; School of Computing and Information Systems, The University of Melbourne; School of Computing and Information Systems, The University of Melbourne",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17389/17389-13-20883-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11682-invertible-concept-based-explanations-for-cnn-models-with-non-negative-concept-activation-vectors/",
        "doi": "10.1609/aaai.v35i13.17389",
        "pdf_size": 2051358
    },
    {
        "id": "03047",
        "title": "Investigate Indistinguishable Points in Semantic Segmentation of 3D Point Cloud",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper investigates the indistinguishable points (difficult to predict label) in semantic segmentation for large-scale 3D point clouds. The indistinguishable points consist of those located in complex boundary, points with similar local textures but different categories, and points in isolate small hard areas, which largely harm the performance of 3D semantic segmentation. To address this challenge, we propose a novel Indistinguishable Area Focalization Network (IAF-Net), which select indistinguishable points adaptively by utilizing the hierarchical semantic features and enhance fine-grained features for points especially those indistinguishable points. We also introduce multi-stage loss to improve the feature representation in a progressive way. Moreover, in order to analyze the segmentation performances of indistinguishable areas, we propose a new evaluation metric called Indistinguishable Points Based Metric (IPBM). Our IAF-Net achieves the state-of-the-art performance on several popular 3D point datasets e.g. S3DIS and ScanNet, and clearly outperform other methods on IPBM. Our code will be available at  https://github.com/MingyeXu/IAF-Net.",
        "primary_area": "Computer Vision III",
        "author": "Mingye Xu; Zhipeng Zhou; Junhao Zhang; Yu Qiao",
        "authorids": "",
        "aff": "Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences ShenZhen Key Lab of Computer Vision and Pattern Recognition, SIAT-SenseTime Joint Lab, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences University of Chinese Academy of Sciences, China; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences ShenZhen Key Lab of Computer Vision and Pattern Recognition, SIAT-SenseTime Joint Lab, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences SIAT Branch, Shenzhen Institute of Artificial Intelligence and Robotics for Society; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences ShenZhen Key Lab of Computer Vision and Pattern Recognition, SIAT-SenseTime Joint Lab, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences ShenZhen Key Lab of Computer Vision and Pattern Recognition, SIAT-SenseTime Joint Lab, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences Shanghai AI Lab, Shanghai, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16413/16413-13-19907-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03047-investigate-indistinguishable-points-in-semantic-segmentation-of-3d-point-cloud/",
        "doi": "10.1609/aaai.v35i4.16413",
        "pdf_size": 11968981
    },
    {
        "id": "11405",
        "title": "Is the Most Accurate AI the Best Teammate? Optimizing AI for Teamwork",
        "track": "main",
        "status": "Poster",
        "abstract": "AI practitioners typically strive to develop the most  accurate systems,  making an implicit assumption that the AI system will function autonomously. However, in practice, AI systems often are used to provide advice to people in domains ranging from criminal justice and finance to healthcare. In such AI-advised decision making, humans and machines form a team, where the human is responsible for making final decisions.   But is the most accurate AI the best teammate? We argue \"not necessarily\" --- predictable performance may be worth a slight sacrifice in AI accuracy. Instead, we argue that AI systems should be trained in a human-centered manner, directly optimized for team performance. We study this proposal for a specific type of human-AI teaming, where the human overseer chooses to either accept the AI recommendation or solve the task themselves. To optimize the team performance for this setting we maximize the team's expected utility, expressed in terms of the quality of the final decision, cost of verifying, and individual accuracies of people and machines. Our experiments with linear and non-linear models on real-world, high-stakes datasets show that the most accuracy AI may not lead to highest team performance and show the benefit of modeling teamwork during training through improvements in expected team utility across datasets, considering parameters such as human skill and the cost of mistakes. We discuss the shortcoming of current optimization approaches beyond well-studied loss functions such as log-loss, and encourage future work on AI optimization problems motivated by human-AI collaboration.",
        "primary_area": "Philosophy and Ethics of AI",
        "author": "Gagan Bansal; Besmira Nushi; Ece Kamar; Eric Horvitz; Daniel S. Weld",
        "authorids": "",
        "aff": "University of Washington; Microsoft Research; Microsoft Research; Microsoft Research; University of Washington Allen Institute for AI",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17359/17359-13-20853-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11405-is-the-most-accurate-ai-the-best-teammate-optimizing-ai-for-teamwork/",
        "doi": "10.1609/aaai.v35i13.17359",
        "pdf_size": 641970
    },
    {
        "id": "14621",
        "title": "IsoBN: Fine-Tuning BERT with Isotropic Batch Normalization",
        "track": "main",
        "status": "Poster",
        "abstract": "Fine-tuning pre-trained language models (PTLMs), such as BERT and its better variant RoBERTa, has been a common practice for advancing performance in natural language understanding (NLU) tasks. Recent advance in representation learning shows that isotropic (i.e., unit-variance and uncorrelated) embeddings can significantly improve performance on downstream tasks with faster convergence and better generalization. The isotropy of the pre-trained embeddings in PTLMs, however, is relatively under-explored. In this paper, we analyze the isotropy of the pre-trained [CLS] embeddings of PTLMs with straightforward visualization, and point out two major issues: high variance in their standard deviation, and high correlation between different dimensions. We also propose a new network regularization method, isotropic batch normalization (IsoBN) to address the issues, towards learning more isotropic representations in fine-tuning by dynamically penalizing dominating principal components. This simple yet effective fine-tuning method yields about 1.0 absolute increment on the average of seven NLU tasks.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Wenxuan Zhou; Bill Yuchen Lin; Xiang Ren",
        "authorids": "",
        "aff": "University of Southern California; University of Southern California; University of Southern California",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17718/17718-13-21212-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14621-isobn-fine-tuning-bert-with-isotropic-batch-normalization/",
        "doi": "10.1609/aaai.v35i16.17718",
        "pdf_size": 3828685
    },
    {
        "id": "10487",
        "title": "Isolation Graph Kernel",
        "track": "main",
        "status": "Poster",
        "abstract": "A recent Wasserstein Weisfeiler-Lehman (WWL) Graph Kernel has a distinctive feature: Representing the distribution of Weisfeiler-Lehman (WL)-embedded node vectors of a graph in a histogram that enables a dissimilarity measurement of two graphs using Wasserstein distance. It has been shown to produce better classification accuracy than other graph kernels which do not employ such distribution and Wasserstein distance.  This paper introduces an alternative called Isolation Graph Kernel (IGK) that measures the similarity between two attributed graphs. IGK is unique in two aspects among existing graph kernels. First, it is the first graph kernel which employs a distributional kernel in the framework of kernel mean embedding. This avoids the need to use the computationally expensive Wasserstein distance. Second, it is the first graph kernel that incorporates the distribution of attributed nodes (ignoring the edges) in a dataset of graphs. We reveal that this distributional information, extracted in the form of a feature map of Isolation Kernel, is crucial in building an efficient and effective graph kernel. We show that IGK is better than WWL in terms of classification accuracy, and it runs orders of magnitude faster in large datasets when used in the context of SVM classification.",
        "primary_area": "Machine Learning V",
        "author": "Bi-Cun Xu; Kai Ming Ting; Yuan Jiang",
        "authorids": "",
        "aff": "Nanjing University; Nanjing University; Nanjing University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17255/17255-13-20749-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10487-isolation-graph-kernel/",
        "doi": "10.1609/aaai.v35i12.17255",
        "pdf_size": 368838
    },
    {
        "id": "13018",
        "title": "It Takes Two to Empathize: One to Seek and One to Provide",
        "track": "main",
        "status": "Poster",
        "abstract": "Empathy describes the capacity to feel, understand, and emotionally engage with what other people are experiencing. People have recently started to turn to online health communities to seek empathetic support when they undergo difficult situations such as suffering from a life-threatening disease, while others are there to provide empathetic support to those who need it. It is, therefore, important to detect the direction of empathy expressed in natural language. Previous studies only focus on the presence of empathy at a high-level and do not distinguish the direction of empathy that is expressed in textual messages. In this paper, we take one step further in the identification of perceived empathy from text by introducing IEMPATHIZE, a dataset of messages annotated with the direction of empathy exchanged in an online cancer network. We analyze user messages to identify the direction of empathy at a fine-grained level: seeking or providing empathy. Our dataset IEMPATHIZE serves as a challenging benchmark for studying empathy at a fine-grained level.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Mahshid Hosseini; Cornelia Caragea",
        "authorids": "",
        "aff": "Computer science, University of Illinois at Chicago; Computer science, University of Illinois at Chicago",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17539/17539-13-21033-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13018-it-takes-two-to-empathize-one-to-seek-and-one-to-provide/",
        "doi": "10.1609/aaai.v35i14.17539",
        "pdf_size": 748065
    },
    {
        "id": "09923",
        "title": "Iterative Bounding MDPs: Learning Interpretable Policies via Non-Interpretable Methods",
        "track": "main",
        "status": "Poster",
        "abstract": "Current work in explainable reinforcement learning generally produces policies in the form of a decision tree over the state space. Such policies can be used for formal safety verification, agent behavior prediction, and manual inspection of important features. However, existing approaches fit a decision tree after training or use a custom learning procedure which is not compatible with new learning techniques, such as those which use neural networks. To address this limitation, we propose a novel Markov Decision Process (MDP) type for learning decision tree policies: Iterative Bounding MDPs (IBMDPs). An IBMDP is constructed around a base MDP so each IBMDP policy is guaranteed to correspond to a decision tree policy for the base MDP when using a method-agnostic masking procedure. Because of this decision tree equivalence, any function approximator can be used during training, including a neural network, while yielding a decision tree policy for the base MDP. We present the required masking procedure as well as a modified value update step which allows IBMDPs to be solved using existing algorithms. We apply this procedure to produce IBMDP variants of recent reinforcement learning methods. We empirically show the benefits of our approach by solving IBMDPs to produce decision tree policies for the base MDPs.",
        "primary_area": "Machine Learning IV",
        "author": "Nicholay Topin; Stephanie Milani; Fei Fang; Manuela Veloso",
        "authorids": "",
        "aff": "Carnegie Mellon University; Carnegie Mellon University; Carnegie Mellon University; Carnegie Mellon University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17192/17192-13-20686-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09923-iterative-bounding-mdps-learning-interpretable-policies-via-non-interpretable-methods/",
        "doi": "10.1609/aaai.v35i11.17192",
        "pdf_size": 1097641
    },
    {
        "id": "12937",
        "title": "Iterative Utterance Segmentation for Neural Semantic Parsing",
        "track": "main",
        "status": "Poster",
        "abstract": "Neural semantic parsers usually fail to parse long and complex utterances into correct meaning representations, due to the lack of exploiting the principle of compositionality. To address this issue, we present a novel framework for boosting neural semantic parsers via iterative utterance segmentation. Given an input utterance, our framework iterates between two neural modules: a segmenter for segmenting a span from the utterance, and a parser for mapping the span into a partial meaning representation. Then, these intermediate parsing results are composed into the final meaning representation. One key advantage is that this framework does not require any handcraft templates or additional labeled data for utterance segmentation: we achieve this through proposing a novel training method, in which the parser provides pseudo supervision for the segmenter. Experiments on Geo, ComplexWebQuestions and Formulas show that our framework can consistently improve performances of neural semantic parsers in different domains. On data splits that require compositional generalization, our framework brings significant accuracy gains: Geo 63.1~81.2, Formulas 59.7~72.7, ComplexWebQuestions 27.1~56.3.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Yinuo Guo; Zeqi Lin; Jian-Guang Lou; Dongmei Zhang",
        "authorids": "",
        "aff": "Peking University; Microsoft Research; Microsoft Research; Microsoft Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17530/17530-13-21024-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12937-iterative-utterance-segmentation-for-neural-semantic-parsing/",
        "doi": "10.1609/aaai.v35i14.17530",
        "pdf_size": 266713
    },
    {
        "id": "04081",
        "title": "Joint Air Quality and Weather Prediction Based on Multi-Adversarial Spatiotemporal Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Accurate and timely air quality and weather predictions are of great importance to urban governance and human livelihood. Though many efforts have been made for air quality or weather prediction, most of them simply employ one another as feature input, which ignores the inner-connection between two predictive tasks. On the one hand, the accurate prediction of one task can help improve another task's performance. On the other hand, geospatially distributed air quality and weather monitoring stations provide additional hints for city-wide spatiotemporal dependency modeling. Inspired by the above two insights, in this paper, we propose the Multi-adversarial spatiotemporal recurrent Graph Neural Networks (MasterGNN) for joint air quality and weather prediction. Specifically, we first propose a heterogeneous recurrent graph neural network to model the spatiotemporal autocorrelation among air quality and weather monitoring stations. Then, we develop a multi-adversarial graph learning framework to against observation noise propagation introduced by spatiotemporal modeling. Moreover, we introduce an adaptive training strategy by formulating multi-adversarial learning as a multi-task learning problem. Finally, extensive experiments on two real-world datasets show that MasterGNN achieves the best performance compared with seven baselines on both air quality and weather prediction tasks.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Jindong Han; Hao Liu; Hengshu Zhu; Hui Xiong; Dejing Dou",
        "authorids": "",
        "aff": "Baidu Research, Beijing, China; Baidu Research, Beijing, China; Baidu Talent Intelligence Center, Baidu Inc, Beijing, China; Rutgers University, USA; Baidu Research, Beijing, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16529/16529-13-20023-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04081-joint-air-quality-and-weather-prediction-based-on-multi-adversarial-spatiotemporal-networks/",
        "doi": "10.1609/aaai.v35i5.16529",
        "pdf_size": 7703634
    },
    {
        "id": "03520",
        "title": "Joint Color-irrelevant Consistency Learning and Identity-aware Modality Adaptation for Visible-infrared Cross Modality Person Re-identification",
        "track": "main",
        "status": "Poster",
        "abstract": "Visible-infrared cross modality person re-identification (VI-ReID) is a core but challenging technology in the 24-hours intelligent surveillance system. How to eliminate the large modality gap lies in the heart of VI-ReID. Conventional methods mainly focus on directly aligning the heterogeneous modalities into the same space. However, due to the unbalanced color information between the visible and infrared images, the features of visible images tend to overfit the clothing color information, which would be harmful to the modality alignment. Besides, these methods mainly align the heterogeneous feature distributions in dataset-level while ignoring the valuable identity information, which may cause the feature misalignment of some identities and weaken the discrimination of features. To tackle above problems, we propose a novel approach for VI-ReID. It learns the color-irrelevant features through the color-irrelevant consistency learning (CICL) and aligns the identity-level feature distributions by the identity-aware modality adaptation (IAMA). The CICL and IAMA are integrated into a joint learning framework and can promote each other. Extensive experiments on two popular datasets SYSU-MM01 and RegDB demonstrate the superiority and effectiveness of our approach against the state-of-the-art methods.",
        "primary_area": "Computer Vision III",
        "author": "Zhiwei Zhao; Bin Liu; Qi Chu; Yan Lu; Nenghai Yu",
        "authorids": "",
        "aff": "School of Information Science and Technology, University of Science and Technology of China, Hefei, China Key Laboratory of Electromagnetic Space Information, Chinese Academy of Science, Hefei, China; School of Information Science and Technology, University of Science and Technology of China, Hefei, China Key Laboratory of Electromagnetic Space Information, Chinese Academy of Science, Hefei, China; School of Information Science and Technology, University of Science and Technology of China, Hefei, China Key Laboratory of Electromagnetic Space Information, Chinese Academy of Science, Hefei, China; School of Information Science and Technology, University of Science and Technology of China, Hefei, China Key Laboratory of Electromagnetic Space Information, Chinese Academy of Science, Hefei, China; School of Information Science and Technology, University of Science and Technology of China, Hefei, China Key Laboratory of Electromagnetic Space Information, Chinese Academy of Science, Hefei, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16466/16466-13-19960-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03520-joint-color-irrelevant-consistency-learning-and-identity-aware-modality-adaptation-for-visible-infrared-cross-modality-person-re-identification/",
        "doi": "10.1609/aaai.v35i4.16466",
        "pdf_size": 754652
    },
    {
        "id": "01018",
        "title": "Joint Demosaicking and Denoising in the Wild: The Case of Training Under Ground Truth Uncertainty",
        "track": "main",
        "status": "Poster",
        "abstract": "Image demosaicking and denoising are the two key fundamental steps in digital camera pipelines, aiming to reconstruct clean color images from noisy luminance readings. In this paper, we propose and study Wild-JDD, a novel learning framework for joint demosaicking and denoising in the wild. In contrast to previous works which generally assume the ground truth of training data is a perfect reflection of the reality, we consider here the more common imperfect case of ground truth uncertainty in the wild. We first illustrate its manifestation as various kinds of artifacts including zipper effect, color moire and residual noise. Then we formulate a two-stage data degradation process to capture such ground truth uncertainty, where a conjugate prior distribution is imposed upon a base distribution. After that, we derive an evidence lower bound (ELBO) loss to train a neural network that approximates the parameters of the conjugate prior distribution conditioned on the degraded input. Finally, to further enhance the performance for out-of-distribution input, we design a simple but effective fine-tuning strategy by taking the input as a weakly informative prior. Taking into account ground truth uncertainty, Wild-JDD enjoys good interpretability during optimization. Extensive experiments validate that it outperforms state-of-the-art schemes on joint demosaicking and denoising tasks on both synthetic and realistic raw datasets.",
        "primary_area": "Computer Vision I",
        "author": "Jierun Chen; Song Wen; S.-H. Gary Chan",
        "authorids": "",
        "aff": "The Hong Kong University of Science and Technology; The Hong Kong University of Science and Technology; The Hong Kong University of Science and Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16186/16186-13-19680-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01018-joint-demosaicking-and-denoising-in-the-wild-the-case-of-training-under-ground-truth-uncertainty/",
        "doi": "10.1609/aaai.v35i2.16186",
        "pdf_size": 17593188
    },
    {
        "id": "12516",
        "title": "Joint Semantic Analysis with Document-Level Cross-Task Coherence Rewards",
        "track": "main",
        "status": "Poster",
        "abstract": "Coreference resolution and semantic role labeling are NLP tasks that capture different aspects of semantics, indicating respectively, which expressions refer to the same entity, and what semantic roles expressions serve in the sentence. However, they are often closely interdependent, and both generally necessitate natural language understanding. Do they form a coherent abstract representation of documents? We present a neural network architecture for joint coreference resolution and semantic role labeling for English, and train graph neural networks to model the 'coherence' of the combined shallow semantic graph. Using the resulting coherence score as a reward for our joint semantic analyzer, we use reinforcement learning to encourage global coherence over the document and between semantic annotations. This leads to improvements on both tasks in multiple datasets from different domains, and across a range of encoders of different expressivity, calling, we believe, for a more holistic approach for semantics in NLP.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Rahul Aralikatte; Mostafa Abdou; Heather C Lent; Daniel Hershcovich; Anders S\u00f8gaard",
        "authorids": "",
        "aff": "University of Copenhagen; University of Copenhagen; University of Copenhagen; University of Copenhagen; University of Copenhagen",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17484/17484-13-20978-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12516-joint-semantic-analysis-with-document-level-cross-task-coherence-rewards/",
        "doi": "10.1609/aaai.v35i14.17484",
        "pdf_size": 477673
    },
    {
        "id": "01958",
        "title": "Joint Semantic-geometric Learning for Polygonal Building Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "Building extraction from aerial or satellite images has been an important research issue in remote sensing and computer vision domains for decades. Compared with pixel-wise semantic segmentation models that output raster building segmentation map, polygonal building segmentation approaches produce more realistic building polygons that are in the desirable vector format for practical applications. Despite the substantial efforts over recent years, state-of-the-art polygonal building segmentation methods still suffer from several limitations, e.g., (1) relying on a perfect segmentation map to guarantee the vectorization quality; (2) requiring a complex post-processing procedure; (3) generating inaccurate vertices with a fixed quantity, a wrong sequential order, self-intersections, etc. To tackle the above issues, in this paper, we propose a polygonal building segmentation approach and make the following contributions: (1) We design a multi-task segmentation network for joint semantic and geometric learning via three tasks, i.e., pixel-wise building segmentation, multi-class corner prediction, and edge orientation prediction. (2) We propose a simple but effective vertex generation module for transforming the segmentation contour into high-quality polygon vertices. (3) We further propose a polygon refinement network that automatically moves the polygon vertices into more accurate locations. Results on two popular building segmentation datasets demonstrate that our approach achieves significant improvements for both building instance segmentation (with 2% F1-score gain) and polygon vertex prediction (with 6% F1-score gain) compared with current state-of-the-art methods.",
        "primary_area": "Computer Vision II",
        "author": "Weijia Li; Wenqian Zhao; Huaping Zhong; Conghui He; Dahua Lin",
        "authorids": "",
        "aff": "The Chinese University of Hong Kong Shanghai SenseTime Intelligent Technology Co., Ltd.; The Chinese University of Hong Kong; Sensetime Group Limited; SenseTime Group Limited Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences; The Chinese University of Hong Kong",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16291/16291-13-19785-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01958-joint-semantic-geometric-learning-for-polygonal-building-segmentation/",
        "doi": "10.1609/aaai.v35i3.16291",
        "pdf_size": 13106305
    },
    {
        "id": "08847",
        "title": "Joint-Label Learning by Dual Augmentation for Time Series Classification",
        "track": "main",
        "status": "Poster",
        "abstract": "Recently, deep neural networks (DNNs) have achieved excellent performance on time series classification. However, DNNs require large amounts of labeled data for supervised training. Although data augmentation can alleviate this problem, the standard approach assigns the same label to all augmented samples from the same source. This leads to the expansion of the data distribution such that the classification boundaries may be even harder to determine. In this paper, we propose Joint-label learning by Dual Augmentation (JobDA), which can enrich the training samples without expanding the distribution of the original data. Instead, we apply simple transformations to the time series and give these modified time series new labels, so that the model has to distinguish between these and the original data, as well as separating the original classes. This approach sharpens the boundaries around the original time series, and results in superior classification performance. We use Time Series Warping for our transformations: We shrink and stretch different regions of the original time series, like a fun-house mirror. Experiments conducted on extensive time-series datasets show that JobDA can improve the model performance on small datasets. Moreover, we verify that JobDA has better generalization ability compared with conventional data augmentation, and the visualization analysis further demonstrates that JobDA can learn more compact clusters.",
        "primary_area": "Machine Learning III",
        "author": "Qianli Ma; Zhenjing Zheng; Jiawei Zheng; Sen Li; Wanqing Zhuang; Garrison W. Cottrell",
        "authorids": "",
        "aff": "South China University of Technology; South China University of Technology; South China University of Technology; South China University of Technology; South China University of Technology; University of California, San Diego",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17071/17071-13-20565-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08847-joint-label-learning-by-dual-augmentation-for-time-series-classification/",
        "doi": "10.1609/aaai.v35i10.17071",
        "pdf_size": 8161783
    },
    {
        "id": "12866",
        "title": "Judgment Prediction via Injecting Legal Knowledge into Neural Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Legal Judgment Prediction (LJP) is a key problem in legal artificial intelligence, which is aimed to predict a law case's judgment based on a given text describing the facts of the law case. Most of the previous work treats LJP as a text classification task and generally adopts deep neural networks (DNNs) based methods to solve it. However, existing DNNs based work is data-hungry and hard to explain which legal knowledge is based on to make such a prediction. Thus, injecting legal knowledge into neural networks to interpret the model and improve performance remains a significant problem. In this paper, we propose to represent declarative legal knowledge as a set of first-order logic rules and integrate these logic rules into a co-attention network-based model explicitly. The use of logic rules enhances neural networks with explicit logical reason capabilities and makes the model more interpretable. We take the civil loan scenario as a case study and demonstrate the effectiveness of the proposed method through comprehensive experiments and analysis conducted on the collected dataset.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Leilei Gan; Kun Kuang; Yi Yang; Fei Wu",
        "authorids": "",
        "aff": "Zhejiang University; Zhejiang University; Zhejiang University; Zhejiang University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17522/17522-13-21016-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12866-judgment-prediction-via-injecting-legal-knowledge-into-neural-networks/",
        "doi": "10.1609/aaai.v35i14.17522",
        "pdf_size": 230867
    },
    {
        "id": "07554",
        "title": "Justicia: A Stochastic SAT Approach to Formally Verify Fairness",
        "track": "main",
        "status": "Poster",
        "abstract": "As a technology ML is oblivious to societal good or bad, and thus, the field of fair machine learning has stepped up to propose multiple mathematical definitions, algorithms, and systems to ensure different notions of fairness in ML applications. Given the multitude of propositions, it has become imperative to formally verify the fairness metrics satisfied by different algorithms on different datasets. In this paper, we propose a stochastic satisfiability (SSAT) framework, Justicia, that formally verifies different fairness measures of supervised learning algorithms with respect to the underlying data distribution. We instantiate Justicia on multiple classification and bias mitigation algorithms, and datasets to verify different fairness metrics, such as disparate impact, statistical parity, and equalized odds. Justicia is scalable, accurate, and operates on non-Boolean and compound sensitive attributes unlike existing distribution-based verifiers, such as FairSquare and VeriFair. Being distribution-based by design, Justicia is more robust than the verifiers, such as AIF360, that operate on specific test samples. We also theoretically bound the finite-sample error of the verified fairness measure.",
        "primary_area": "Machine Learning II",
        "author": "Bishwamittra Ghosh; Debabrota Basu; Kuldeep S. Meel",
        "authorids": "",
        "aff": "National University of Singapore, Singapore; Chalmers University of Technology, G\u00f6teborg, Sweden Scool, Inria Lille- Nord Europe, France; National University of Singapore, Singapore",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16925/16925-13-20419-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07554-justicia-a-stochastic-sat-approach-to-formally-verify-fairness/",
        "doi": "10.1609/aaai.v35i9.16925",
        "pdf_size": 2832989
    },
    {
        "id": "00081",
        "title": "KAN: Knowledge-aware Attention Network for Fake News Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "The explosive growth of fake news on social media has drawn great concern both from industrial and academic communities. There has been an increasing demand for fake news detection due to its detrimental effects. Generally, news content is condensed and full of knowledge entities. However, existing methods usually focus on the textual contents and social context, and ignore the knowledge-level relationships among news entities. To address this limitation, in this paper, we propose a novel Knowledge-aware Attention Network (KAN) that incorporates external knowledge from knowledge graph for fake news detection. Firstly, we identify entity mentions in news contents and align them with the entities in knowledge graph. Then, the entities and their contexts are used as external knowledge to provide complementary information. Finally, we design News towards Entities (N-E) attention and News towards Entities and Entity Contexts (N-E^2C) attention to measure the importances of knowledge. Thus, our proposed model can incorporate both semantic-level and knowledge-level representations of news to detect fake news. Experimental results on three public datasets show that our model outperforms the state-of-the-art methods, and also validate the effectiveness of knowledge attention.",
        "primary_area": "Application Domains",
        "author": "Yaqian Dun; Kefei Tu; Chen Chen; Chunyan Hou; Xiaojie Yuan",
        "authorids": "",
        "aff": "College of Computer Science, Nankai University, Tianjin, China Tianjin Key Laboratory of Network and Data Security Technology, Tianjin, China; College of Computer Science, Nankai University, Tianjin, China Tianjin Key Laboratory of Network and Data Security Technology, Tianjin, China; College of Computer Science, Nankai University, Tianjin, China Tianjin Key Laboratory of Network and Data Security Technology, Tianjin, China; School of Computer Science and Engineering, Tianjin University of Technology, Tianjin, China; College of Computer Science, Nankai University, Tianjin, China Tianjin Key Laboratory of Network and Data Security Technology, Tianjin, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16080/16080-13-19574-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00081-kan-knowledge-aware-attention-network-for-fake-news-detection/",
        "doi": "10.1609/aaai.v35i1.16080",
        "pdf_size": 1293786
    },
    {
        "id": "13924",
        "title": "KEML: A Knowledge-Enriched Meta-Learning Framework for Lexical Relation Classification",
        "track": "main",
        "status": "Poster",
        "abstract": "Lexical relations describe how concepts are semantically related, in the form of relation triples. The accurate prediction of lexical relations between concepts is challenging, due to the sparsity of patterns indicating the existence of such relations. We propose the Knowledge-Enriched Meta-Learning (KEML) framework to address lexical relation classification. In KEML, the LKB-BERT (Lexical Knowledge Base-BERT) model is first presented to learn concept representations from text corpora, with rich lexical knowledge injected by distant supervision. A probabilistic distribution of auxiliary tasks is defined to increase the model's ability to recognize different types of lexical relations. We further propose a neural classifier integrated with special relation recognition cells, in order to combine meta-learning over the auxiliary task distribution and supervised learning for LRC. Experiments over multiple datasets show KEML outperforms state-of-the-art methods.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Chengyu Wang; Minghui Qiu; Jun Huang; Xiaofeng He",
        "authorids": "",
        "aff": "Zhejiang Lab Alibaba Group; Alibaba Group; Alibaba Group; East China Normal University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17640/17640-13-21134-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13924-keml-a-knowledge-enriched-meta-learning-framework-for-lexical-relation-classification/",
        "doi": "10.1609/aaai.v35i15.17640",
        "pdf_size": 271719
    },
    {
        "id": "06418",
        "title": "KG-BART: Knowledge Graph-Augmented BART for Generative Commonsense Reasoning",
        "track": "main",
        "status": "Poster",
        "abstract": "Generative commonsense reasoning which aims to empower machines to generate sentences with the capacity of reasoning over a set of concepts is a critical bottleneck for text generation. Even the state-of-the-art pre-trained language generation models struggle at this task and often produce implausible and anomalous sentences. One reason is that they rarely consider incorporating the knowledge graph which can provide rich relational information among the commonsense concepts. To promote the ability of commonsense reasoning for text generation, we propose a novel knowledge graph augmented pre-trained language generation model KG-BART, which encompasses the complex relations of concepts through the knowledge graph and produces more logical and natural sentences as output. Moreover, KG-BART can leverage the graph attention to aggregate the rich concept semantics that enhances the model generalization on unseen concept sets. Experiments on benchmark CommonGen dataset verify the effectiveness of our proposed approach by comparing with several strong pre-trained language generation models, particularly KG-BART outperforms BART by 5.80, 4.60, in terms of BLEU-3, 4. Moreover, we also show that the generated context by our model can work as background scenarios to benefit downstream commonsense QA tasks.",
        "primary_area": "Knowledge Representation and Reasoning",
        "author": "Ye Liu; Yao Wan; Lifang He; Hao Peng; Philip  S. Yu",
        "authorids": "",
        "aff": "University Of Illinois at Chicago; Huazhong University of Science and Technology; Lehigh University; Beihang University; University Of Illinois at Chicago",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16796/16796-13-20290-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06418-kg-bart-knowledge-graph-augmented-bart-for-generative-commonsense-reasoning/",
        "doi": "10.1609/aaai.v35i7.16796",
        "pdf_size": 1790550
    },
    {
        "id": "02449",
        "title": "KGDet: Keypoint-Guided Fashion Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Locating and classifying clothes, usually referred to as clothing detection, is a fundamental task in fashion analysis. Motivated by the strong structural characteristics of clothes, we pursue a detection method enhanced by clothing keypoints, which is a compact and effective representation of structures. To incorporate the keypoint cues into clothing detection, we design a simple yet effective Keypoint-Guided clothing Detector, named KGDet. Such a detector can fully utilize information provided by keypoints with the following two aspects: i) integrating local features around keypoints to benefit both classification and regression; ii) generating accurate bounding boxes from keypoints. To effectively incorporate local features , two alternative modules are proposed. One is a multi-column keypoint-encoding-based feature aggregation module; the other is a keypoint-selection-based feature aggregation module. With either of the above modules as a bridge, a cascade strategy is introduced to refine detection performance progressively. Thanks to the keypoints, our KGDet obtains superior performance on the DeepFashion2 dataset and the FLD dataset with high efficiency.",
        "primary_area": "Computer Vision II",
        "author": "Shenhan Qian; Dongze Lian; Binqiang Zhao; Tong Liu; Bohui Zhu; Hai Li; Shenghua Gao",
        "authorids": "",
        "aff": "ShanghaiTech University Alibaba Group; ShanghaiTech University; Alibaba Group; Alibaba Group; Alibaba Group; Ant Group; ShanghaiTech University Shanghai Engineering Research Center of Intelligent Vision and Imaging",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16346/16346-13-19840-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02449-kgdet-keypoint-guided-fashion-detection/",
        "doi": "10.1609/aaai.v35i3.16346",
        "pdf_size": 1896161
    },
    {
        "id": "08155",
        "title": "Kernel-convoluted Deep Neural Networks with Data Augmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "The Mixup method, which uses linearly interpolated data, has emerged as an effective data augmentation tool to improve generalization performance and the robustness to adversarial examples. The motivation is to curtail undesirable oscillations by its implicit model constraint to behave linearly at in-between observed data points and promote smoothness. In this work, we formally investigate this premise, propose a way to impose smoothness constraints explicitly, and extend it to incorporate implicit model constraints. First, we derive a new function class composed of kernel-convoluted models (KCM) where the smoothness constraint is directly imposed by locally averaging the original functions with a kernel function. Second, we propose to incorporate the Mixup method into KCM to expand the domains of smoothness. In both cases of the KCM and the KCM adapted with the Mixup, we provide risk analysis, respectively, under mild conditions on kernel functions. As a result, we show that the upper bound of the excess risk over a new function class is not slower than that of the excess risk over the original function class. Using CIFAR-10 and CIFAR-100 datasets, our experiments demonstrate that the KCM with the Mixup outperforms the Mixup method in terms of generalization and robustness to adversarial examples.",
        "primary_area": "Machine Learning II",
        "author": "Minjin Kim; Young-geun Kim; Dongha Kim; Yongdai Kim; Myunghee Cho Paik",
        "authorids": "",
        "aff": "Seoul National University; Seoul National University; Seoul National University; Seoul National University; Seoul National University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16993/16993-13-20487-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08155-kernel-convoluted-deep-neural-networks-with-data-augmentation/",
        "doi": "10.1609/aaai.v35i9.16993",
        "pdf_size": 277578
    },
    {
        "id": "14568",
        "title": "Keyword-Guided Neural Conversational Model",
        "track": "main",
        "status": "Poster",
        "abstract": "We study the problem of imposing conversational goals/keywords on open-domain conversational agents, where the agent is required to lead the conversation to a target keyword smoothly and fast. Solving this problem enables the application of conversational agents in many real-world scenarios, e.g., recommendation and psychotherapy. The dominant paradigm for tackling this problem is to 1) train a next-turn keyword classifier, and 2) train a keyword-augmented response retrieval model. However, existing approaches in this paradigm have two limitations: 1) the training and evaluation datasets for next-turn keyword classification are directly extracted from conversations without human annotations, thus, they are noisy and have low correlation with human judgements, and 2) during keyword transition, the agents solely rely on the similarities between word embeddings to move closer to the target keyword, which may not reflect how humans converse. In this paper, we assume that human conversations are grounded on commonsense and propose a keyword-guided neural conversational model that can leverage external commonsense knowledge graphs (CKG) for both keyword transition and response retrieval. Automatic evaluations suggest that commonsense improves the performance of both next-turn keyword prediction and keyword-augmented response retrieval. In addition, both self-play and human evaluations show that our model produces responses with smoother keyword transition and reaches the target keyword faster than competitive baselines.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Peixiang Zhong; Yong Liu; Hao Wang; Chunyan Miao",
        "authorids": "",
        "aff": "Alibaba-NTU Singapore Joint Research Institute, Nanyang Technological University (NTU), Singapore Joint NTU-UBC Research Centre of Excellence in Active Living for the Elderly, NTU, Singapore; Alibaba-NTU Singapore Joint Research Institute, Nanyang Technological University (NTU), Singapore Joint NTU-UBC Research Centre of Excellence in Active Living for the Elderly, NTU, Singapore; Alibaba Group, China; Alibaba-NTU Singapore Joint Research Institute, Nanyang Technological University (NTU), Singapore Joint NTU-UBC Research Centre of Excellence in Active Living for the Elderly, NTU, Singapore",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17712/17712-13-21206-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14568-keyword-guided-neural-conversational-model/",
        "doi": "10.1609/aaai.v35i16.17712",
        "pdf_size": 347099
    },
    {
        "id": "07271",
        "title": "Knowledge Refactoring for Inductive Program Synthesis",
        "track": "main",
        "status": "Poster",
        "abstract": "Humans constantly restructure knowledge to use it more efficiently. Our goal is to give a machine learning system similar abilities so that it can learn more efficiently. We introduce the knowledge refactoring problem, where the goal is to restructure a learner's knowledge base to reduce its size and to minimise redundancy in it. We focus on inductive logic programming, where the knowledge base is a logic program. We introduce Knorf, a system which solves the refactoring problem using constraint optimisation. A key feature of Knorf is that, rather than simply removing knowledge, it also introduces new knowledge through predicate invention. We evaluate our approach on two domains: building Lego structures and real-world string transformations. Our experiments show that learning from refactored knowledge can improve predictive accuracies fourfold and reduce learning times by half.",
        "primary_area": "Machine Learning I",
        "author": "Sebastijan Dumancic; Tias Guns; Andrew Cropper",
        "authorids": "",
        "aff": "KU Leuven, Belgium; KU Leuven, Belgium; Oxford University, United Kingdom",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16893/16893-13-20387-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07271-knowledge-refactoring-for-inductive-program-synthesis/",
        "doi": "10.1609/aaai.v35i8.16893",
        "pdf_size": 285858
    },
    {
        "id": "07228",
        "title": "Knowledge Refinery: Learning from Decoupled Label",
        "track": "main",
        "status": "Poster",
        "abstract": "Recently, a variety of regularization techniques have been widely applied in deep neural networks, which mainly focus on the regularization of weight parameters to encourage generalization effectively. Label regularization techniques are also proposed with the motivation of softening the labels while neglecting the relation of classes. Among them, the technique of knowledge distillation proposes to distill the soft label, which contains the knowledge of class relations. However, this technique needs to pre-train an extra cumbersome teacher model. In this paper, we propose a method called Knowledge Refinery (KR), which enables the neural network to learn the relation of classes on-the-fly without the teacher-student training strategy. We propose the definition of decoupled labels, which consist of the original hard label and the residual label. To exhibit the generalization of KR, we evaluate our method in both fields of computer vision and natural language processing. Our empirical results show consistent performance gains under all experimental settings.",
        "primary_area": "Machine Learning I",
        "author": "Qianggang Ding; Sifan Wu; Tao Dai; Hao Sun; Jiadong Guo; Zhang-Hua Fu; Shutao Xia",
        "authorids": "",
        "aff": "Tsinghua University; Tsinghua University; Tsinghua University PCL Research Center of Networks and Communications, Peng Cheng Laboratory; The Chinese University of Hong Kong; The Hong Kong University of Science and Technology International Digital Economy Academy; The Chinese University of Hong Kong, Shenzhen Shenzhen Institute of Artificial Intelligence and Robotics for Society; Tsinghua University PCL Research Center of Networks and Communications, Peng Cheng Laboratory",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16888/16888-13-20382-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07228-knowledge-refinery-learning-from-decoupled-label/",
        "doi": "10.1609/aaai.v35i8.16888",
        "pdf_size": 635660
    },
    {
        "id": "06349",
        "title": "Knowledge-Base Degrees of Inconsistency: Complexity and Counting",
        "track": "main",
        "status": "Poster",
        "abstract": "Description logics (DLs) are knowledge representation languages that are used in the field of artificial intelligence (AI). A common technique is to query DL knowledge bases, e.g., by Boolean Datalog queries, and ask for entailment.  But real world knowledge-bases are often obtained by combining data from various sources.  This, inherently, might result in certain inconsistencies (with respect to a given query) and requires to estimate a degree of inconsistency before using a knowledge-base. In this paper, we provide a complexity analysis of fixed-domain non-entailment (NE) on Datalog programs for well-established families of knowledge bases (KBs). We exhibit a detailed complexity map for the decision cases, counting and projected counting, which may serve as a quantitative measure for inconsistency of a KB with respect to a query. Our results show that NE is natural for the second, third, and fourth level of the polynomial (counting) hierarchy depending on the type of the studied query (stratified, normal, disjunctive) and one level higher for the projected versions. Further, we show fixed-parameter tractability by bounding the treewidth, provide a constructive algorithm, and show its theoretical limitation in terms of conditional lower bounds.",
        "primary_area": "Knowledge Representation and Reasoning",
        "author": "Johannes K. Fichte; Markus Hecher; Arne Meier",
        "authorids": "",
        "aff": "TU Dresden; TU Wien; Leibniz Universit\u00e4t Hannover",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16788/16788-13-20282-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06349-knowledge-base-degrees-of-inconsistency-complexity-and-counting/",
        "doi": "10.1609/aaai.v35i7.16788",
        "pdf_size": 255793
    },
    {
        "id": "04339",
        "title": "Knowledge-Driven Distractor Generation for Cloze-Style Multiple Choice Questions",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a novel configurable framework to automatically generate distractive choices for open-domain cloze-style multiple-choice questions. The framework incorporates a general-purpose knowledge base to effectively create a small distractor candidate set, and a feature-rich learning-to-rank model to select distractors that are both plausible and reliable. Experimental results on a new dataset across four domains show that our framework yields distractors outperforming previous methods both by automatic and human evaluation. The dataset can also be used as a benchmark for distractor generation research in the future.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Siyu Ren; Kenny Q. Zhu",
        "authorids": "",
        "aff": "Shanghai Jiao Tong University; Shanghai Jiao Tong University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16559/16559-13-20053-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04339-knowledge-driven-distractor-generation-for-cloze-style-multiple-choice-questions/",
        "doi": "10.1609/aaai.v35i5.16559",
        "pdf_size": 534380
    },
    {
        "id": "04486",
        "title": "Knowledge-Enhanced Hierarchical Graph Transformer Network for Multi-Behavior Recommendation",
        "track": "main",
        "status": "Poster",
        "abstract": "Accurate user and item embedding learning is crucial for modern recommender systems. However, most existing recommendation techniques have thus far focused on modeling users' preferences over singular type of user-item interactions. Many practical recommendation scenarios involve multi-typed user interactive behaviors (e.g., page view, add-to-favorite and purchase), which presents unique challenges that cannot be handled by current recommendation solutions. In particular: i) complex inter-dependencies across different types of user behaviors; ii) the incorporation of knowledge-aware item relations into the multi-behavior recommendation framework; iii) dynamic characteristics of multi-typed user-item interactions. To tackle these challenges, this work proposes a Knowledge-Enhanced Hierarchical Graph Transformer Network (KHGT), to investigate multi-typed interactive patterns between users and items in recommender systems. Specifically, KHGT is build upon a graph-structured neural architecture to i) capture type-specific behavior semantics; ii) explicitly discriminate which types of user-item interactions are more important in assisting the forecasting task on the target behavior. Additionally, we further integrate the multi-modal graph attention layer with temporal encoding strategy, to empower the learned embeddings be reflective of both dedicated multiplex user-item and item-item collaborative relations, as well as the underlying interaction dynamics. Extensive experiments conducted on three real-world datasets show that KHGT consistently outperforms many state-of-the-art recommendation methods across various evaluation settings. Our implementation is available in https://github.com/akaxlh/KHGT.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Lianghao Xia; Chao Huang; Yong Xu; Peng Dai; Xiyue Zhang; Hongsheng Yang; Jian Pei; Liefeng Bo",
        "authorids": "",
        "aff": "South China University of Technology; JD Finance America Corporation; South China University of Technology Communication and Computer Network Laboratory of Guangdong Peng Cheng Laboratory; JD Finance America Corporation; South China University of Technology; JD Finance America Corporation; Simon Fraser University; JD Finance America Corporation",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16576/16576-13-20070-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04486-knowledge-enhanced-hierarchical-graph-transformer-network-for-multi-behavior-recommendation/",
        "doi": "10.1609/aaai.v35i5.16576",
        "pdf_size": 975433
    },
    {
        "id": "04285",
        "title": "Knowledge-Enhanced Top-K Recommendation in Poincar\u00e9 Ball",
        "track": "main",
        "status": "Poster",
        "abstract": "Personalized recommender systems are increasingly important as more content and services become available and users struggle to identify what might interest them. Thanks to the ability for providing rich information, knowledge graphs (KGs) are being incorporated to enhance the recommendation performance and interpretability. To effectively make use of the knowledge graph, we propose a recommendation model in the hyperbolic space, which facilitates the learning of the hierarchical structure of knowledge graphs. Furthermore, a hyperbolic attention network is employed to determine the relative importances of neighboring entities of a certain item. In addition, we propose an adaptive and fine-grained regularization mechanism to adaptively regularize items and their neighboring representations. Via a comparison using three real-world datasets with state-of-the-art methods, we show that the proposed model outperforms the best existing models by 2-16% in terms of NDCG@K on Top-K recommendation.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Chen Ma; Liheng Ma; Yingxue Zhang; Haolun Wu; Xue Liu; Mark Coates",
        "authorids": "",
        "aff": "McGill University; McGill University; Huawei Noah's Ark Lab Montreal; McGill University; McGill University; McGill University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16553/16553-13-20047-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04285-knowledge-enhanced-top-k-recommendation-in-poincare-ball/",
        "doi": "10.1609/aaai.v35i5.16553",
        "pdf_size": 1892370
    },
    {
        "id": "10798",
        "title": "Knowledge-Guided Object Discovery with Acquired Deep Impressions",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a framework called Acquired Deep Impressions (ADI) which continuously learns knowledge of objects as ``impressions'' for compositional scene understanding. In this framework, the model first acquires knowledge from scene images containing a single object in a supervised manner, and then continues to learn from novel multi-object scene images which may contain objects that have not been seen before without any further supervision, under the guidance of the learned knowledge as humans do. By memorizing impressions of objects into parameters of neural networks and applying the generative replay strategy, the learned knowledge can be reused to generate images with pseudo-annotations and in turn assist the learning of novel scenes. The proposed ADI framework focuses on the acquisition and utilization of knowledge, and is complementary to existing deep generative models proposed for compositional scene representation. We adapt a base model to make it fall within the ADI framework and conduct experiments on two types of datasets. Empirical results suggest that the proposed framework is able to effectively utilize the acquired impressions and improve the scene decomposition performance.",
        "primary_area": "Machine Learning V",
        "author": "Jinyang Yuan; Bin Li; Xiangyang Xue",
        "authorids": "",
        "aff": "Fudan University; Fudan University; Fudan University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17290/17290-13-20784-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10798-knowledge-guided-object-discovery-with-acquired-deep-impressions/",
        "doi": "10.1609/aaai.v35i12.17290",
        "pdf_size": 1667737
    },
    {
        "id": "04115",
        "title": "Knowledge-aware Coupled Graph Neural Network for Social Recommendation",
        "track": "main",
        "status": "Poster",
        "abstract": "Social recommendation task aims to predict users' preferences over items with the incorporation of social connections among users, so as to alleviate the sparse issue of collaborative filtering. While many recent efforts show the effectiveness of neural network-based social recommender systems, several important challenges have not been well addressed yet: (i) The majority of models only consider users\u2019 social connections, while ignoring the inter-dependent knowledge across items; (ii) Most of existing solutions are designed for singular type of user-item interactions, making them infeasible to capture the interaction heterogeneity; (iii) The dynamic nature of user-item interactions has been less explored in many social-aware recommendation techniques. To tackle the above challenges, this work proposes a Knowledge-aware Coupled Graph Neural Network (KCGN) that jointly injects the inter-dependent knowledge across items and users into the recommendation framework. KCGN enables the high-order user- and item-wise relation encoding by exploiting the mutual information for global graph structure awareness. Additionally, we further augment KCGN with the capability of capturing dynamic multi-typed user-item interactive patterns. Experimental studies on real-world datasets show the effectiveness of our method against many strong baselines in a variety of settings. Source codes are available at: https://github.com/xhcdream/KCGN.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Chao Huang; Huance Xu; Yong Xu; Peng Dai; Lianghao Xia; Mengyin Lu; Liefeng Bo; Hao Xing; Xiaoping Lai; Yanfang Ye",
        "authorids": "",
        "aff": "JD Finance America Corporation, USA; South China University of Technology, China; South China University of Technology, China Peng Cheng Laboratory, China Communication and Computer Network Laboratory of Guangdong, China; JD Finance America Corporation, USA; South China University of Technology, China; JD Finance America Corporation, USA; JD Finance America Corporation, USA; VIPS Research, China; VIPS Research, China; Case Western Reserve University, USA",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16533/16533-13-20027-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04115-knowledge-aware-coupled-graph-neural-network-for-social-recommendation/",
        "doi": "10.1609/aaai.v35i5.16533",
        "pdf_size": 638092
    },
    {
        "id": "12768",
        "title": "Knowledge-aware Leap-LSTM: Integrating Prior Knowledge into Leap-LSTM towards Faster Long Text Classification",
        "track": "main",
        "status": "Poster",
        "abstract": "While widely used in industry,  recurrent neural networks (RNNs) are known to have deficiencies in dealing with long sequences (e.g. slow inference, vanishing gradients etc.). Recent research has attempted to accelerate RNN models by developing mechanisms to skip irrelevant words in input. Due to the lack of labelled data, it remains as a challenge to decide which words to skip, especially for low-resource classification tasks. In this paper, we propose Knowledge-AwareLeap-LSTM (KALL), a novel architecture which integrates prior human knowledge (created either manually or automatically)  like in-domain keywords,  terminologies or lexicons into Leap-LSTM to partially supervise the skipping process. More specifically,  we propose a knowledge-oriented cost function for KALL; furthermore, we propose two strategies to integrate the knowledge: (1) the Factored KALL approach involves a keyword indicator as a soft constraint for the skip-ping process, and (2) the Gated KALL enforces the inclusion of keywords while maintaining a differentiable network in training. Experiments on different public datasets show that our approaches are1.1x~2.6x faster than LSTM with better accuracy and 23.6x faster than XLNet in a resource-limited CPU-only environment.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Jinhua Du; Yan Huang; Karo Moilanen",
        "authorids": "",
        "aff": "Investments AI, AIG; Investments AI, AIG; Investments AI, AIG",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17511/17511-13-21005-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12768-knowledge-aware-leap-lstm-integrating-prior-knowledge-into-leap-lstm-towards-faster-long-text-classification/",
        "doi": "10.1609/aaai.v35i14.17511",
        "pdf_size": 220367
    },
    {
        "id": "13595",
        "title": "Knowledge-aware Named Entity Recognition with Alleviating Heterogeneity",
        "track": "main",
        "status": "Poster",
        "abstract": "Named Entity Recognition (NER) is a fundamental and important research topic for many downstream NLP tasks, aiming at detecting and classifying named entities (NEs) mentioned in unstructured text into pre-defined categories. Learning from labeled data only is far from enough when it comes to domain-specific or temporally-evolving entities (medical terminologies or restaurant names). Luckily, open-source Knowledge Bases (KBs) (Wikidata and Freebase) contain NEs that are manually labeled with predefined types in different domains, which is potentially beneficial to identify entity boundaries and recognize entity types more accurately.  However, the type system of a domain-specific NER task is typically independent of that of current KBs and thus exhibits heterogeneity issue inevitably, which makes matching between the original NER and KB types (Person in NER potentially matches President in KBs) less likely, or introduces unintended noises without considering domain-specific knowledge (Band in NER should be mapped to Out_of_Entity_Types in the restaurant-related task). To better incorporate and denoise the abundant knowledge in KBs, we propose a new KB-aware NER framework (KaNa), which utilizes type-heterogeneous knowledge to improve NER. Specifically, for an entity mention along with a set of candidate entities that are linked from KBs, KaNa first uses a type projection mechanism that maps the mention type and entity types into a shared space to homogenize the heterogeneous entity types. Then, based on projected types, a noise detector filters out certain less-confident candidate entities in an unsupervised manner. Finally, the filtered mention-entity pairs are injected into a NER model as a graph to predict answers.  The experimental results demonstrate KaNa's state-of-the-art performance on five public benchmark datasets from different domains.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Binling Nie; Ruixue Ding; Pengjun Xie; Fei Huang; Chen Qian; Luo Si",
        "authorids": "",
        "aff": "Hangzhou Dianzi University; Alibaba Group; Alibaba; Alibaba; Tsinghua University; Alibaba Group",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17603/17603-13-21097-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13595-knowledge-aware-named-entity-recognition-with-alleviating-heterogeneity/",
        "doi": "10.1609/aaai.v35i15.17603",
        "pdf_size": 587164
    },
    {
        "id": "13507",
        "title": "Knowledge-driven Data Construction for Zero-shot Evaluation in Commonsense Question Answering",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent developments in pre-trained neural language modeling have led to leaps in accuracy on common-sense question-answering benchmarks. However,  there is increasing concern that models overfit to specific tasks, without learning to utilize external knowledge or perform general semantic reasoning. In contrast, zero-shot evaluations have shown promise as a more robust measure of a model\u2019s general reasoning abilities. In this paper, we propose a novel neuro-symbolic framework for zero-shot question answering across commonsense tasks. Guided by a set of hypotheses,  the framework studies how to transform various pre-existing knowledge resources into a form that is most effective for pre-training models. We vary the set of language models, training regimes, knowledge sources, and data generation strategies, and measure their impact across tasks. Extending on prior work, we devise and compare four constrained distractor-sampling strategies. We provide empirical results across five commonsense question-answering tasks with data generated from five external knowledge resources. We show that, while an individual knowledge graph is better suited for specific tasks, a global knowledge graph brings consistent gains across different tasks. In addition, both preserving the structure of the task as well as generating fair and informative questions help language models learn more effectively.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Kaixin Ma; Filip Ilievski; Jonathan Francis; Yonatan Bisk; Eric Nyberg; Alessandro Oltramari",
        "authorids": "",
        "aff": "Language Technologies Institute, School of Computer Science, Carnegie Mellon University; Information Sciences Institute, Viterbi School of Engineering, University of Southern California; Language Technologies Institute, School of Computer Science, Carnegie Mellon University Human-Machine Collaboration, Bosch Research Pittsburgh; Language Technologies Institute, School of Computer Science, Carnegie Mellon University; Language Technologies Institute, School of Computer Science, Carnegie Mellon University; Human-Machine Collaboration, Bosch Research Pittsburgh",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17593/17593-13-21087-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13507-knowledge-driven-data-construction-for-zero-shot-evaluation-in-commonsense-question-answering/",
        "doi": "10.1609/aaai.v35i15.17593",
        "pdf_size": 275928
    },
    {
        "id": "12554",
        "title": "Knowledge-driven Natural Language Understanding of English Text and its Applications",
        "track": "main",
        "status": "Poster",
        "abstract": "Understanding the meaning of a text is a fundamental challenge of natural language understanding (NLU) research. An ideal NLU system should process a language in a way that is not exclusive to a single task or a dataset. Keeping this in mind, we have introduced a novel knowledge driven semantic representation approach for English text. By leveraging the VerbNet lexicon, we are able to map syntax tree of the text to its commonsense meaning represented using basic knowledge primitives. The general purpose knowledge represented from our approach can be used to build any reasoning based NLU system that can also provide justification. We applied this approach to construct two NLU applications that we present here: SQuARE (Semantic-based Question Answering and Reasoning Engine) and StaCACK (Stateful Conversational Agent using Commonsense Knowledge). Both these systems work by ``truly understanding'' the natural language text they process and both provide natural language explanations for their responses while maintaining high accuracy.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Kinjal Basu; Sarat Chandra Varanasi; Farhad Shakerin; Joaqu\u00edn Arias; Gopal Gupta",
        "authorids": "",
        "aff": "University of Texas at Dallas; University of Texas at Dallas; University of Texas at Dallas; Universidad Rey Juan Carlos; University of Texas at Dallas",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17488/17488-13-20982-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12554-knowledge-driven-natural-language-understanding-of-english-text-and-its-applications/",
        "doi": "10.1609/aaai.v35i14.17488",
        "pdf_size": 339911
    },
    {
        "id": "03913",
        "title": "LCollision: Fast Generation of Collision-Free Human Poses using Learned Non-Penetration Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "We present LCollision, a learning-based method that synthesizes collision-free 3D human poses. At the crux of our approach is a novel deep architecture that simultaneously decodes new human poses from the latent space and predicts colliding body parts. These two components of our architecture are used as the objective function and surrogate hard constraints in a constrained optimization for collision-free human pose generation. A novel aspect of our approach is the use of a bilevel autoencoder that decomposes whole-body collisions into groups of collisions between localized body parts. By solving the constrained optimizations, we show that a significant amount of collision artifacts can be resolved. Furthermore, in a large test set of 2.5 \u00d7 10 6 randomized poses from SCAPE, our architecture achieves a collision-prediction accuracy of 94.1% with 80\u00d7 speedup over exact collision detection algorithms. To the best of our knowledge, LCollision is the \ufb01rst approach that accelerates collision detection and resolves penetrations using a neural network.",
        "primary_area": "Constraint Satisfaction and Optimization",
        "author": "Qingyang Tan; Zherong Pan; Dinesh Manocha",
        "authorids": "",
        "aff": "University of Maryland at College Park; University of Illinois at Urbana-Champaign; University of Maryland at College Park",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16510/16510-13-20004-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03913-lcollision-fast-generation-of-collision-free-human-poses-using-learned-non-penetration-constraints/",
        "doi": "10.1609/aaai.v35i5.16510",
        "pdf_size": 5561620
    },
    {
        "id": "13498",
        "title": "LET: Linguistic Knowledge Enhanced Graph Transformer for Chinese Short Text Matching",
        "track": "main",
        "status": "Poster",
        "abstract": "Chinese short text matching is a fundamental task in natural language processing. Existing approaches usually take Chinese characters or words as input tokens. They have two limitations: 1) Some Chinese words are polysemous, and semantic information is not fully utilized. 2) Some models suffer potential issues caused by word segmentation. Here we introduce HowNet as an external knowledge base and propose a Linguistic knowledge Enhanced graph Transformer (LET) to deal with word ambiguity. Additionally, we adopt the word lattice graph as input to maintain multi-granularity information. Our model is also complementary to pre-trained language models. Experimental results on two Chinese datasets show that our models outperform various typical text matching approaches. Ablation study also indicates that both semantic information and multi-granularity information are important for text matching modeling.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Boer Lyu; Lu Chen; Su Zhu; Kai Yu",
        "authorids": "",
        "aff": "X-LANCE Lab, Department of Computer Science and Engineering, Shanghai Jiao Tong University; X-LANCE Lab, Department of Computer Science and Engineering, Shanghai Jiao Tong University; X-LANCE Lab, Department of Computer Science and Engineering, Shanghai Jiao Tong University; X-LANCE Lab, Department of Computer Science and Engineering, Shanghai Jiao Tong University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17592/17592-13-21086-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13498-let-linguistic-knowledge-enhanced-graph-transformer-for-chinese-short-text-matching/",
        "doi": "10.1609/aaai.v35i15.17592",
        "pdf_size": 320091
    },
    {
        "id": "14532",
        "title": "LIREx: Augmenting Language Inference with Relevant Explanations",
        "track": "main",
        "status": "Poster",
        "abstract": "Natural language explanations (NLEs) are a special form of data annotation in which annotators identify rationales (most significant text tokens) when assigning labels to data instances, and write out explanations for the labels in natural language based on the rationales. NLEs have been shown to capture human reasoning better, but not as beneficial for natural language inference (NLI). In this paper, we analyze two primary flaws in the way NLEs are currently used to train explanation generators for language inference tasks. We find that the explanation generators do not take into account the variability inherent in human explanation of labels, and that the current explanation generation models generate spurious explanations. To overcome these limitations, we propose a novel framework, LIREx, that incorporates both a rationale-enabled explanation generator and an instance selector to select only relevant, plausible NLEs to augment NLI models. When evaluated on the standardized SNLI data set, LIREx achieved an accuracy of 91.87%, an improvement of 0.32 over the baseline and matching the best-reported performance on the data set. It also achieves significantly better performance than previous studies when transferred to the out-of-domain MultiNLI data set. Qualitative analysis shows that LIREx generates flexible, faithful, and relevant NLEs that allow the model to be more robust to spurious explanations. The code is available at https://github.com/zhaoxy92/LIREx.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Xinyan Zhao; V.G.Vinod Vydiswaran",
        "authorids": "",
        "aff": "School of Information, University of Michigan; Department of Learning Health Sciences, University of Michigan School of Information, University of Michigan",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17708/17708-13-21202-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14532-lirex-augmenting-language-inference-with-relevant-explanations/",
        "doi": "10.1609/aaai.v35i16.17708",
        "pdf_size": 318767
    },
    {
        "id": "12830",
        "title": "LRC-BERT: Latent-representation Contrastive Knowledge Distillation for Natural Language Understanding",
        "track": "main",
        "status": "Poster",
        "abstract": "The pre-training models such as BERT have achieved great results in various natural language processing problems. However, a large number of parameters need significant amounts of memory and the consumption of inference time, which makes it difficult to deploy them on edge devices. In this work, we propose a knowledge distillation method LRC-BERT based on contrastive learning to fit the output of the intermediate layer from the angular distance aspect, which is not considered by the existing distillation methods. Furthermore, we introduce a gradient perturbation-based training architecture in the training phase to increase the robustness of LRC-BERT, which is the first attempt in knowledge distillation. Additionally, in order to better capture the distribution characteristics of the intermediate layer, we design a two-stage training method for the total distillation loss. Finally, by verifying 8 datasets on the General Language Understanding Evaluation (GLUE) benchmark, the performance of the proposed LRC-BERT exceeds the existing state-of-the-art methods, which proves the effectiveness of our method.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Hao Fu; Shaojun Zhou; Qihong Yang; Junjie Tang; Guiquan Liu; Kaikui Liu; Xiaolong Li",
        "authorids": "",
        "aff": "University of Science and Technology of China; Alibaba Group; Alibaba Group; Alibaba Group; University of Science and Technology of China; Alibaba Group; Alibaba Group",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17518/17518-13-21012-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12830-lrc-bert-latent-representation-contrastive-knowledge-distillation-for-natural-language-understanding/",
        "doi": "10.1609/aaai.v35i14.17518",
        "pdf_size": 273692
    },
    {
        "id": "04139",
        "title": "LREN: Low-Rank Embedded Network for Sample-Free Hyperspectral Anomaly Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Hyperspectral anomaly detection (HAD) is a challenging task because it explores the intrinsic structure of complex high-dimensional signals without any samples at training time. Deep neural networks (DNNs) can dig out the underlying distribution of hyperspectral data but are limited by the labeling of large-scale hyperspectral datasets, especially the low spatial resolution of hyperspectral data, which makes labeling more difficult. To tackle this problem while ensuring the detection performance, we present an unsupervised low-rank embedded network (LREN) in this paper. LREN is a joint learning network in which the latent representation is specifically designed for HAD, rather than merely as a feature input for the detector. And it searches the lowest rank representation based on a representative and discriminative dictionary in the deep latent space to estimate the residual efficiently. Considering the physically mixing properties in hyperspectral imaging, we develop a trainable density estimation module based on Gaussian mixture model (GMM) in the deep latent space to construct a dictionary that can better characterize the complex hyperspectral images (HSIs). The closed-form solution of the proposed low-rank learner surpasses existing approaches on four real hyperspectral datasets with different anomalies. We argue that this unified framework paves a novel way to combine feature extraction and anomaly estimation-based methods for HAD, which intends to learn the underlying representation tailored for HAD without the prerequisite of manually labeled data. Code available at https://github.com/xdjiangkai/LREN.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Kai Jiang; Weiying Xie; Jie Lei; Tao Jiang; Yunsong Li",
        "authorids": "",
        "aff": "Xidian University; Xidian University; Xidian University; Xidian University; Xidian University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16536/16536-13-20030-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04139-lren-low-rank-embedded-network-for-sample-free-hyperspectral-anomaly-detection/",
        "doi": "10.1609/aaai.v35i5.16536",
        "pdf_size": 1094933
    },
    {
        "id": "08340",
        "title": "LRSC: Learning Representations for Subspace Clustering",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep learning based subspace clustering methods have attracted increasing attention in recent years, where a basic theme is to non-linearly map data into a latent space, and then uncover subspace structures based upon the data self-expressiveness property. However, almost all existing deep subspace clustering methods only rely on target domain data, and always resort to shallow neural networks for modeling data, leaving huge room to design more effective representation learning mechanisms tailored for subspace clustering. In this paper, we propose a novel subspace clustering framework through learning precise sample representations. In contrast to previous approaches, the proposed method aims to leverage external data through constructing lots of relevant tasks to guide the training of the encoder, motivated by the idea of meta-learning. Considering limited layer structures of current deep subspace clustering models, we intend to distill knowledge from a deeper network trained on the external data, and transfer it into the shallower model. To reach the above two goals, we propose a new loss function to realize them in a joint framework. Moreover, we propose to construct a new pretext task for self-supervised training of the model, such that the representation ability of the model can be further improved. Extensive experiments are performed on four publicly available datasets, and experimental results clearly demonstrate the efficacy of our method, compared to state-of-the-art methods.",
        "primary_area": "Machine Learning II",
        "author": "Changsheng Li; Chen Yang; Bo Liu; Ye Yuan; Guoren Wang",
        "authorids": "",
        "aff": "Beijing Institute of Technology; University of Electronic Science and Technology of China; JD Digits; Beijing Institute of Technology; Beijing Institute of Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17014/17014-13-20508-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08340-lrsc-learning-representations-for-subspace-clustering/",
        "doi": "10.1609/aaai.v35i9.17014",
        "pdf_size": 1372551
    },
    {
        "id": "12929",
        "title": "Label Confusion Learning to Enhance Text Classification Models",
        "track": "main",
        "status": "Poster",
        "abstract": "Representing the true label as one-hot vector is the common practice in training text classification models. However, the one-hot representation may not adequately reflect the relation between the instance and labels, as labels are often not completely independent and instances may relate to multiple labels in practice. The inadequate one-hot representations tend to train the model to be over-confident, which may result in arbitrary prediction and model overfitting, especially for confused datasets (datasets with very similar labels) or noisy datasets (datasets with labeling errors). While training models with label smoothing can ease this problem in some degree, it still fails to capture the realistic relation among labels. In this paper, we propose a novel Label Confusion Model (LCM) as an enhancement component to current popular text classification models. LCM can learn label confusion to capture semantic overlap among labels by calculating the similarity between instance and labels during training and generate a better label distribution to replace the original one-hot label vector, thus improving the final classification performance. Extensive experiments on five text classification benchmark datasets reveal the effectiveness of LCM for several widely used deep learning classification models. Further experiments also verify that LCM is especially helpful for confused or noisy datasets and superior to the label smoothing method.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Biyang Guo; Songqiao Han; Xiao Han; Hailiang Huang; Ting Lu",
        "authorids": "",
        "aff": "AI Lab, School of Information Management and Engineering, Shanghai University of Finance and Economics; AI Lab, School of Information Management and Engineering, Shanghai University of Finance and Economics; AI Lab, School of Information Management and Engineering, Shanghai University of Finance and Economics; AI Lab, School of Information Management and Engineering, Shanghai University of Finance and Economics; AI Lab, School of Information Management and Engineering, Shanghai University of Finance and Economics",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17529/17529-13-21023-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12929-label-confusion-learning-to-enhance-text-classification-models/",
        "doi": "10.1609/aaai.v35i14.17529",
        "pdf_size": 1062794
    },
    {
        "id": "11826",
        "title": "Landmark Generation in HTN Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Landmarks (LMs) are state features that need to be made true or tasks that need to be contained in every solution of a planning problem. They are a valuable source of information in planning and can be exploited in various ways. LMs have been used both in classical and hierarchical planning, but while there is much work in classical planning, the techniques in hierarchical planning are less evolved. We introduce a novel LM generation method for Hierarchical Task Network (HTN) planning and show that it is sound and incomplete. We show that every complete approach is as hard as the co-class of the underlying HTN problem, i.e. coNP-hard for our setting (while our approach is in P). On a widely used benchmark set, our approach finds more than twice the number of landmarks than the approach from the literature. Though our focus is on LM generation, we show that the newly discovered landmarks bear information beneficial for solvers.",
        "primary_area": "Planning, Routing, and Scheduling",
        "author": "Daniel H\u00f6ller; Pascal Bercher",
        "authorids": "",
        "aff": "Saarland University, Saarland Informatics Campus, Saarbr\u00fccken, Germany; The Australian National University, College of Engineering and Computer Science, Canberra, Australia",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17405/17405-13-20899-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11826-landmark-generation-in-htn-planning/",
        "doi": "10.1609/aaai.v35i13.17405",
        "pdf_size": 231777
    },
    {
        "id": "07883",
        "title": "Large Batch Optimization for Deep Learning Using New Complete Layer-Wise Adaptive Rate Scaling",
        "track": "main",
        "status": "Poster",
        "abstract": "Training deep neural networks using a large batch size has shown promising results and benefits many real-world applications. Warmup is one of nontrivial techniques to stabilize the convergence of large batch training. However, warmup is an empirical method and it is still unknown whether there is a better algorithm with theoretical underpinnings. In this paper, we propose a novel Complete Layer-wise Adaptive Rate Scaling (CLARS) algorithm for large-batch training. We prove the convergence of our algorithm by introducing a new fine-grained analysis of gradient-based methods. Furthermore, the new analysis also helps to understand two other empirical tricks, layer-wise adaptive rate scaling and linear learning rate scaling. We conduct extensive experiments and demonstrate that the proposed algorithm outperforms gradual warmup technique by a large margin and defeats the convergence of the state-of-the-art large-batch optimizer  in training advanced deep neural networks (ResNet, DenseNet, MobileNet) on ImageNet dataset.",
        "primary_area": "Machine Learning II",
        "author": "Zhouyuan Huo; Bin Gu; Heng Huang",
        "authorids": "",
        "aff": "Google; MBZUAI JD Finance America Corporation; University of Pittsburgh JD Finance America Corporation",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16962/16962-13-20456-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07883-large-batch-optimization-for-deep-learning-using-new-complete-layer-wise-adaptive-rate-scaling/",
        "doi": "10.1609/aaai.v35i9.16962",
        "pdf_size": 297027
    },
    {
        "id": "02127",
        "title": "Large Motion Video Super-Resolution with Dual Subnet and Multi-Stage Communicated Upsampling",
        "track": "main",
        "status": "Poster",
        "abstract": "Video super-resolution (VSR) aims at restoring a video in low-resolution (LR) and improving it to higher-resolution (HR). Due to the characteristics of video tasks, it is very important that motion information among frames should be well concerned, summarized and utilized for guidance in a VSR algorithm. Especially, when a video contains large motion, conventional methods easily bring incoherent results or artifacts. In this paper, we propose a novel deep neural network with Dual Subnet and Multi-stage Communicated Upsampling (DSMC) for super-resolution of videos with large motion. We design a new module named U-shaped residual dense network with 3D convolution (U3D-RDN) for fine implicit motion estimation and motion compensation (MEMC) as well as coarse spatial feature extraction. And we present a new Multi-Stage Communicated Upsampling (MSCU) module to make full use of the intermediate results of upsampling for guiding the VSR. Moreover, a novel dual subnet is devised to aid the training of our DSMC, whose dual loss helps to reduce the solution space as well as enhance the generalization ability. Our experimental results confirm that our method achieves superior performance on videos with large motion compared to state-of-the-art methods.",
        "primary_area": "Computer Vision II",
        "author": "Hongying Liu; Peng Zhao; Zhubo Ruan; Fanhua Shang; Yuanyuan Liu",
        "authorids": "",
        "aff": "Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, School of Artificial Intelligence, Xidian University; Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, School of Artificial Intelligence, Xidian University; Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, School of Artificial Intelligence, Xidian University; Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, School of Artificial Intelligence, Xidian University Peng Cheng Lab, Shenzhen; Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, School of Artificial Intelligence, Xidian University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16310/16310-13-19804-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02127-large-motion-video-super-resolution-with-dual-subnet-and-multi-stage-communicated-upsampling/",
        "doi": "10.1609/aaai.v35i3.16310",
        "pdf_size": 616071
    },
    {
        "id": "08565",
        "title": "Large Norms of CNN Layers Do Not Hurt Adversarial Robustness",
        "track": "main",
        "status": "Poster",
        "abstract": "Since the Lipschitz properties of convolutional neural networks (CNNs) are widely considered to be related to adversarial robustness, we theoretically characterize the L-1 norm and L-infinity norm of 2D multi-channel convolutional layers and provide efficient methods to compute the exact L-1 norm and L-infinity norm. Based on our theorem, we propose a novel regularization method termed norm decay, which can effectively reduce the norms of convolutional layers and fully-connected layers. Experiments show that norm-regularization methods, including norm decay, weight decay, and singular value clipping, can improve generalization of CNNs. However, they can slightly hurt adversarial robustness. Observing this unexpected phenomenon, we compute the norms of layers in the CNNs trained with three different adversarial training frameworks and surprisingly find that adversarially robust CNNs have comparable or even larger layer norms than their non-adversarially robust counterparts. Furthermore, we prove that under a mild assumption, adversarially robust classifiers can be achieved using neural networks, and an adversarially robust neural network can have an arbitrarily large Lipschitz constant. For this reason, enforcing small norms on CNN layers may be neither necessary nor effective in achieving adversarial robustness. The code is available at https://github.com/youweiliang/norm_robustness.",
        "primary_area": "Machine Learning III",
        "author": "Youwei Liang; Dong Huang",
        "authorids": "",
        "aff": "South China Agricultural University; South China Agricultural University Pazhou Lab, Guangzhou, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17039/17039-13-20533-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08565-large-norms-of-cnn-layers-do-not-hurt-adversarial-robustness/",
        "doi": "10.1609/aaai.v35i10.17039",
        "pdf_size": 840963
    },
    {
        "id": "11921",
        "title": "Latent Independent Excitation for Generalizable Sensor-based Cross-Person Activity Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "In wearable-sensor-based activity recognition, it is often assumed that the training and test samples follow the same data distribution. This assumption neglects practical scenarios where the activity patterns inevitably vary from person to person. To solve this problem, transfer learning and domain adaptation approaches are often leveraged to reduce the gaps between different participants. Nevertheless, these approaches require additional information (i.e., labeled or unlabeled data, meta-information) from the target domain during the training stage. In this paper, we introduce a novel method named Generalizable Independent Latent Excitation (GILE) for human activity recognition, which greatly enhances the cross-person generalization capability of the model. Our proposed method is superior to existing methods in the sense that it does not require any access to the target domain information. Besides, this novel model can be directly applied to various target domains without re-training or fine-tuning. Specifically, the proposed model learns to automatically disentangle domain-agnostic and domain-specific features, the former of which are expected to be invariant across various persons. To further remove correlations between the two types of features, a novel Independent Excitation mechanism is incorporated in the latent feature space. Comprehensive experimental evaluations are conducted on three benchmark datasets to demonstrate the superiority of the proposed method over the state-of-the-art solutions.",
        "primary_area": "Planning, Routing, and Scheduling",
        "author": "Hangwei Qian; Sinno Jialin Pan; Chunyan Miao",
        "authorids": "",
        "aff": "Nanyang Technological University, Singapore; Nanyang Technological University, Singapore; Nanyang Technological University, Singapore",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17416/17416-13-20910-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11921-latent-independent-excitation-for-generalizable-sensor-based-cross-person-activity-recognition/",
        "doi": "10.1609/aaai.v35i13.17416",
        "pdf_size": 993337
    },
    {
        "id": "08288",
        "title": "Learnable Dynamic Temporal Pooling for Time Series Classification",
        "track": "main",
        "status": "Poster",
        "abstract": "With the increase of available time series data, predicting their class labels has been one of the most important challenges in a wide range of disciplines. Recent studies on time series classification show that convolutional neural networks (CNN) achieved the state-of-the-art performance as a single classifier. In this work, pointing out that the global pooling layer that is usually adopted by existing CNN classifiers discards the temporal information of high-level features, we present a dynamic temporal pooling (DTP) technique that reduces the temporal size of hidden representations by aggregating the features at the segment-level. For the partition of a whole series into multiple segments, we utilize dynamic time warping (DTW) to align each time point in a temporal order with the prototypical features of the segments, which can be optimized simultaneously with the network parameters of CNN classifiers. The DTP layer combined with a fully-connected layer helps to extract further discriminative features considering their temporal position within an input time series. Extensive experiments on both univariate and multivariate time series datasets show that our proposed pooling significantly improves the classification performance.",
        "primary_area": "Machine Learning II",
        "author": "Dongha Lee; Seonghyeon Lee; Hwanjo Yu",
        "authorids": "",
        "aff": "POSTECH, Republic of Korea; POSTECH, Republic of Korea; POSTECH, Republic of Korea",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17008/17008-13-20502-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08288-learnable-dynamic-temporal-pooling-for-time-series-classification/",
        "doi": "10.1609/aaai.v35i9.17008",
        "pdf_size": 3323125
    },
    {
        "id": "06592",
        "title": "Learned Bi-Resolution Image Coding using Generalized Octave Convolutions",
        "track": "main",
        "status": "Poster",
        "abstract": "Learned image compression has recently shown the potential to outperform the standard codecs. State-of-the-art rate-distortion (R-D) performance has been achieved by context-adaptive entropy coding approaches in which hyperprior and autoregressive models are jointly utilized to effectively capture the spatial dependencies in the latent representations. However, the latents are feature maps of the same spatial resolution in previous works, which contain some redundancies that affect the R-D performance. In this paper, we propose a learned bi-resolution image coding approach that is based on the recently developed octave convolutions to factorize the latents into high and low resolution components. Therefore, the spatial redundancy is reduced, which improves the R-D performance. Novel generalized octave convolution and octave transposed-convolution architectures with internal activation layers are also proposed to preserve more spatial structure of the information. Experimental results show that the proposed scheme outperforms all existing learned methods as well as standard codecs such as the next-generation video coding standard VVC (4:2:0) in both PSNR and MS-SSIM. We also show that the proposed generalized octave convolution can improve the performance of other auto-encoder-based schemes such as semantic segmentation and image denoising.",
        "primary_area": "Machine Learning I",
        "author": "Mohammad Akbari; Jie Liang; Jingning Han; Chengjie Tu",
        "authorids": "",
        "aff": "Simon Fraser University, Canada; Simon Fraser University, Canada; Google Inc., Mountain View; Tencent Technologies",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16816/16816-13-20310-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06592-learned-bi-resolution-image-coding-using-generalized-octave-convolutions/",
        "doi": "10.1609/aaai.v35i8.16816",
        "pdf_size": 4254930
    },
    {
        "id": "08501",
        "title": "Learned Extragradient ISTA with Interpretable Residual Structures for Sparse Coding",
        "track": "main",
        "status": "Poster",
        "abstract": "Recently, the study on learned iterative shrinkage thresholding algorithm (LISTA) has attracted increasing attentions. A large number of experiments as well as some theories have proved the high efficiency of LISTA for solving sparse coding problems. However, existing LISTA methods are all serial connection. To address this issue, we propose a novel extragradient based LISTA (ELISTA), which has a  residual structure and theoretical guarantees. Moreover, most LISTA methods use the soft thresholding function, which has been found to cause a large estimation bias. Therefore, we propose a  thresholding function for ELISTA instead of soft thresholding. From a theoretical perspective, we prove that our method attains linear convergence. Through ablation experiments, the improvements of our method on the network structure and the thresholding function are verified in practice. Extensive empirical results verify the advantages of our method.",
        "primary_area": "Machine Learning III",
        "author": "Yangyang Li; Lin Kong; Fanhua Shang; Yuanyuan Liu; Hongying Liu; Zhouchen Lin",
        "authorids": "",
        "aff": "Key Lab. of Intelligent Perception and Image Understanding of Ministry of Education, School of Artificial Intelligence, Xidian University; Key Lab. of Intelligent Perception and Image Understanding of Ministry of Education, School of Artificial Intelligence, Xidian University; Key Lab. of Intelligent Perception and Image Understanding of Ministry of Education, School of Artificial Intelligence, Xidian University Peng Cheng Lab; Key Lab. of Intelligent Perception and Image Understanding of Ministry of Education, School of Artificial Intelligence, Xidian University; Key Lab. of Intelligent Perception and Image Understanding of Ministry of Education, School of Artificial Intelligence, Xidian University; Key Lab. of Machine Perception (MoE), School of EECS, Peking University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17032/17032-13-20526-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08501-learned-extragradient-ista-with-interpretable-residual-structures-for-sparse-coding/",
        "doi": "10.1609/aaai.v35i10.17032",
        "pdf_size": 554882
    },
    {
        "id": "04303",
        "title": "Learning Accurate and Interpretable Decision Rule Sets from Neural Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a new paradigm for learning a set of independent logical rules in disjunctive normal form as an interpretable model for classification. We consider the problem of learning an interpretable decision rule set as training a neural network in a specific, yet very simple two-layer architecture. Each neuron in the first layer directly maps to an interpretable if-then rule after training, and the output neuron in the second layer directly maps to a disjunction of the first layer rules to form the decision rule set. Our representation of neurons in this first rules layer enables us to encode both the positive and the negative association of features in a decision rule. State-of-the-art neural net training approaches can be leveraged for learning highly accurate classification models. Moreover, we propose a sparsity-based regularization approach to balance between classification accuracy and the simplicity of the derived rules. Our experimental results show that our method can generate more accurate decision rule sets than other state-of-the-art rule-learning algorithms with better accuracy-simplicity trade-offs. Further, when compared with uninterpretable black-box machine learning approaches such as random forests and full-precision deep neural networks, our approach can easily find interpretable decision rule sets that have comparable predictive performance.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Litao Qiao; Weijia Wang; Bill Lin",
        "authorids": "",
        "aff": "University of California San Diego; University of California San Diego; University of California San Diego",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16555/16555-13-20049-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04303-learning-accurate-and-interpretable-decision-rule-sets-from-neural-networks/",
        "doi": "10.1609/aaai.v35i5.16555",
        "pdf_size": 1455607
    },
    {
        "id": "09940",
        "title": "Learning Adjustment Sets from Observational and Limited Experimental Data",
        "track": "main",
        "status": "Poster",
        "abstract": "Estimating causal effects from observational data is not always possible due to confounding. Identifying a set of appropriate covariates (adjustment set) and adjusting for their influence can remove confounding bias; however, such a set is often not identifiable from observational data alone. Experimental data allow unbiased causal effect estimation, but are typically limited in sample size and can therefore yield estimates of high variance. Moreover, experiments are often performed on a different (specialized) population than the population of interest. In this work, we introduce a method that combines large observational and limited experimental data to identify adjustment sets and improve the estimation of causal effects for a target population. The method scores an adjustment set by calculating the marginal likelihood for the experimental data given an observationally-derived causal effect estimate, using a putative adjustment set. The method can make inferences that are not possible using constraint-based methods. We show that the method can improve causal effect estimation, and  can  make additional inferences when compared to state-of-the-art methods.",
        "primary_area": "Machine Learning IV",
        "author": "Sofia Triantafillou; Greg Cooper",
        "authorids": "",
        "aff": "University of Pittsburgh; University of Pittsburgh",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17194/17194-13-20688-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09940-learning-adjustment-sets-from-observational-and-limited-experimental-data/",
        "doi": "10.1609/aaai.v35i11.17194",
        "pdf_size": 310480
    },
    {
        "id": "12427",
        "title": "Learning Branching Heuristics for Propositional Model Counting",
        "track": "main",
        "status": "Poster",
        "abstract": "Propositional model counting, or #SAT, is the problem of computing the number of satisfying assignments of a Boolean formula. Many problems from different application areas, including many discrete probabilistic inference problems, can be translated into model counting problems to be solved by #SAT solvers. Exact #SAT solvers, however, are often not scalable to industrial size instances. In this paper, we present Neuro#, an approach for learning branching heuristics to improve the performance of exact #SAT solvers on instances from a given family of problems. We experimentally show that our method reduces the step count on similarly distributed held-out instances and generalizes to much larger instances from the same problem family. It is able to achieve these results on a number of different problem families having very different structures. In addition to step count improvements, Neuro# can also achieve orders of magnitude wall-clock speedups over the vanilla solver on larger instances in some problem families, despite the runtime overhead of querying the model.",
        "primary_area": "Search and Optimization",
        "author": "Pashootan Vaezipoor; Gil Lederman; Yuhuai Wu; Chris Maddison; Roger B Grosse; Sanjit A. Seshia; Fahiem Bacchus",
        "authorids": "",
        "aff": "University of Toronto; UC Berkeley; University of Toronto Vector Institute; University of Toronto Vector Institute; University of Toronto Vector Institute; UC Berkeley; University of Toronto",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17474/17474-13-20968-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12427-learning-branching-heuristics-for-propositional-model-counting/",
        "doi": "10.1609/aaai.v35i14.17474",
        "pdf_size": 720714
    },
    {
        "id": "01343",
        "title": "Learning Complex 3D Human Self-Contact",
        "track": "main",
        "status": "Poster",
        "abstract": "Monocular estimation of three dimensional human self-contact is fundamental for detailed scene analysis including body language understanding and behaviour modeling.  Existing 3d reconstruction methods do not focus on body regions in self-contact and consequently recover configurations that are either far from each other or self-intersecting, when they should just touch. This leads to perceptually incorrect estimates and limits impact in those very fine-grained analysis domains where detailed 3d models are expected to play an important role. To address such challenges we detect self-contact and design 3d losses to explicitly enforce it. Specifically, we develop a model for Self-Contact Prediction (SCP), that estimates the body surface signature of self-contact, leveraging the localization of self-contact in the image, during both training and inference. We collect two large datasets to support learning and evaluation: (1) HumanSC3D, an accurate 3d motion capture repository containing 1,032 sequences with 5,058 contact events and 1,246,487 ground truth 3d poses synchronized with images collected from multiple views, and (2) FlickrSC3D, a repository of 3,969 images, containing 25,297 surface-to-surface correspondences with annotated image spatial support. We also illustrate how more expressive 3d reconstructions can be recovered under self-contact signature constraints and present monocular detection of face-touch as one of the multiple applications made possible by more accurate self-contact models.",
        "primary_area": "Computer Vision I",
        "author": "Mihai Fieraru; Mihai Zanfir; Elisabeta Oneata; Alin-Ionut Popa; Vlad Olaru; Cristian Sminchisescu",
        "authorids": "",
        "aff": "Institute of Mathematics of the Romanian Academy; Institute of Mathematics of the Romanian Academy; Institute of Mathematics of the Romanian Academy; Institute of Mathematics of the Romanian Academy; Institute of Mathematics of the Romanian Academy; Lund University Institute of Mathematics of the Romanian Academy",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16223/16223-13-19717-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01343-learning-complex-3d-human-self-contact/",
        "doi": "10.1609/aaai.v35i2.16223",
        "pdf_size": 16108668
    },
    {
        "id": "09906",
        "title": "Learning Compositional Sparse Gaussian Processes with a Shrinkage Prior",
        "track": "main",
        "status": "Poster",
        "abstract": "Choosing a proper set of kernel functions is an important problem in learning Gaussian Process (GP) models since each kernel structure has different model complexity and data fitness. Recently, automatic kernel composition methods provide not only accurate prediction but also attractive interpretability through search-based methods. However, existing methods suffer from slow kernel composition learning. To tackle large-scaled data, we propose a new sparse approximate posterior for GPs, MultiSVGP, constructed from groups of inducing points associated with individual additive kernels in compositional kernels. We demonstrate that this approximation provides a better fit to learn compositional kernels given empirical observations. We also provide theoretically justification on error bound when compared to the traditional sparse GP. In contrast to the search-based approach, we present a novel probabilistic algorithm to learn a kernel composition by handling the sparsity in the kernel selection with Horseshoe prior. We demonstrate that our model can capture characteristics of time series with significant reductions in computational time and have competitive regression performance on real-world data sets.",
        "primary_area": "Machine Learning IV",
        "author": "Anh Tong; Toan M Tran; Hung Bui; Jaesik Choi",
        "authorids": "",
        "aff": "Ulsan National Institute of Science and Technology; VinAI Research; VinAI Research; Korea Advanced Institute of Science and Technology INEEJI",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17190/17190-13-20684-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09906-learning-compositional-sparse-gaussian-processes-with-a-shrinkage-prior/",
        "doi": "10.1609/aaai.v35i11.17190",
        "pdf_size": 1774597
    },
    {
        "id": "02934",
        "title": "Learning Comprehensive Motion Representation for Action Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "For action recognition learning, 2D CNN-based methods are efficient but may yield redundant features due to applying the same 2D convolution kernel to each frame. Recent efforts attempt to capture motion information by establishing inter-frame connections while still suffering the limited temporal receptive field or high latency. Moreover, the feature enhancement is often only performed by channel or space dimension in action recognition. To address these issues, we first devise a Channel-wise Motion Enhancement (CME) module to adaptively emphasize the channels related to dynamic information with a channel-wise gate vector. The channel gates generated by CME incorporate the information from all the other frames in the video. We further propose a Spatial-wise Motion Enhancement (SME) module to focus on the regions with the critical target in motion, according to the point-to-point similarity between adjacent feature maps. The intuition is that the change of background is typically slower than the motion area. Both CME and SME have clear physical meaning in capturing action clues. By integrating the two modules into the off-the-shelf 2D network, we finally obtain a Comprehensive Motion Representation (CMR) learning method for action recognition, which achieves competitive performance on  Something-Something V1 & V2 and Kinetics-400. On the temporal reasoning datasets Something-Something V1 and V2, our method outperforms the current state-of-the-art by 2.3% and 1.9% when using 16 frames as input, respectively.",
        "primary_area": "Computer Vision III",
        "author": "Mingyu Wu; Boyuan Jiang; Donghao Luo; Junchi Yan; Yabiao Wang; Ying Tai; Chengjie Wang; Jilin Li; Feiyue Huang; Xiaokang Yang",
        "authorids": "",
        "aff": "MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University; Youtu Lab, Tencent; Youtu Lab, Tencent; MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University Department of Computer Science and Engineering, Shanghai Jiao Tong University; Youtu Lab, Tencent; Youtu Lab, Tencent; Youtu Lab, Tencent; Youtu Lab, Tencent; Youtu Lab, Tencent; MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16400/16400-13-19894-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02934-learning-comprehensive-motion-representation-for-action-recognition/",
        "doi": "10.1609/aaai.v35i4.16400",
        "pdf_size": 721548
    },
    {
        "id": "13806",
        "title": "Learning Contextual Representations for Semantic Parsing with Generation-Augmented Pre-Training",
        "track": "main",
        "status": "Poster",
        "abstract": "Most recently, there has been significant interest in learning contextual representations for various NLP tasks, by leveraging large scale text corpora to train powerful language models with self-supervised learning objectives, such as Masked Language Model (MLM). Based on a pilot study, we observe three issues of existing general-purpose language models when they are applied in the text-to-SQL semantic parsers: fail to detect the column mentions in the utterances, to infer the column mentions from the cell values, and to compose target SQL queries when they are complex. To mitigate these issues, we present a model pretraining framework, Generation-Augmented Pre-training (GAP), that jointly learns representations of natural language utterance and table schemas, by leveraging generation models to generate high-quality pre-train data. GAP Model is trained on 2 million utterance-schema pairs and 30K utterance-schema-SQL triples, whose utterances are generated by generation models. Based on experimental results, neural semantic parsers that leverage GAP Model as a representation encoder obtain new state-of-the-art results on both Spider and Criteria-to-SQL benchmarks.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Peng Shi; Patrick Ng; Zhiguo Wang; Henghui Zhu; Alexander Hanbo Li; Jun Wang; Cicero Nogueira dos Santos; Bing Xiang",
        "authorids": "",
        "aff": "University of Waterloo; Amazon AWS AI; Amazon AWS AI; Amazon AWS AI; Amazon AWS AI; Amazon AWS AI; Amazon AWS AI; Amazon AWS AI",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17627/17627-13-21121-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13806-learning-contextual-representations-for-semantic-parsing-with-generation-augmented-pre-training/",
        "doi": "10.1609/aaai.v35i15.17627",
        "pdf_size": 191386
    },
    {
        "id": "12139",
        "title": "Learning Continuous High-Dimensional Models using Mutual Information and Copula Bayesian Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a new framework to learn non-parametric graphical models from continuous observational data. Our method is based on concepts from information theory in order to discover independences and causality between variables: the conditional and multivariate mutual information (such as cite{verny2017learning} for discrete models). To estimate these quantities, we propose non-parametric estimators relying on the Bernstein copula and that are constructed by exploiting the relation between the mutual information and the copula entropy cite{ma2011mutual, belalia2017testing}. To our knowledge, this relation is only documented for the bivariate case and, for the need of our algorithms, is here extended to the conditional and multivariate mutual information. This framework leads to a new algorithm to learn continuous non-parametric Bayesian network. Moreover, we use this estimator to  speed up the BIC algorithm proposed in cite{elidan2010copula} by taking advantage of the decomposition of the likelihood function in a sum of mutual  information cite{koller2009probabilistic}. Finally, our method is compared in terms of performances and complexity with other state of the art techniques to learn Copula Bayesian Networks and shows superior results. In particular, it needs less data to recover the true structure and generalizes better on data that are not sampled from Gaussian distributions.",
        "primary_area": "Reasoning under Uncertainty",
        "author": "Marvin Lasserre; R\u00e9gis Lebrun; Pierre-Henri Wuillemin",
        "authorids": "",
        "aff": "Laboratoire d'Informatique de Paris 6; Airbus Central Research & Technology; Laboratoire d'Informatique de Paris 6",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17441/17441-13-20935-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12139-learning-continuous-high-dimensional-models-using-mutual-information-and-copula-bayesian-networks/",
        "doi": "10.1609/aaai.v35i13.17441",
        "pdf_size": 781619
    },
    {
        "id": "10430",
        "title": "Learning Cycle-Consistent Cooperative Networks via Alternating MCMC Teaching for Unsupervised Cross-Domain Translation",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper studies the unsupervised cross-domain translation problem by proposing a generative framework, in which the probability distribution of each domain is represented by a generative cooperative network that consists of an energy-based model and a latent variable model. The use of generative cooperative network enables maximum likelihood learning of the domain model by MCMC teaching, where the energy-based model seeks to fit the data distribution of domain and distills its knowledge to the latent variable model via MCMC. Specifically, in the MCMC teaching process, the latent variable model parameterized by an encoder-decoder maps examples from the source domain to the target domain, while the energy-based model further refines the mapped results by Langevin revision such that the revised results match to the examples in the target domain in terms of the statistical properties, which are defined by the learned energy function. For the purpose of building up a correspondence between two unpaired domains, the proposed framework simultaneously learns a pair of cooperative networks with cycle consistency, accounting for a two-way translation between two domains, by alternating MCMC teaching. Experiments show that the proposed framework is useful for unsupervised image-to-image translation and unpaired image sequence translation.",
        "primary_area": "Machine Learning V",
        "author": "Jianwen Xie; Zilong Zheng; Xiaolin Fang; Song-Chun Zhu; Ying Nian Wu",
        "authorids": "",
        "aff": "Baidu Research; University of California, Los Angeles; Massachusetts Institute of Technology; University of California, Los Angeles Tsinghua University Peking University; University of California, Los Angeles",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17249/17249-13-20743-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10430-learning-cycle-consistent-cooperative-networks-via-alternating-mcmc-teaching-for-unsupervised-cross-domain-translation/",
        "doi": "10.1609/aaai.v35i12.17249",
        "pdf_size": 5556880
    },
    {
        "id": "09214",
        "title": "Learning Deep Generative Models for Queuing Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "Modern  society  is  heavily  dependent  on  large  scale client-server  systems  with  applications  ranging  from Internet and Communication Services to sophisticated logistics and deployment of goods. To maintain and improve such a system, a careful study of client and server dynamics is needed \u2013 e.g. response/service times, aver-age number of clients at given times, etc. To this end, one traditionally relies, within the queuing theory formalism,on parametric analysis and explicit distribution forms.However, parametric forms limit the model\u2019s expressiveness and could struggle on extensively large datasets. We propose a novel data-driven approach towards queuing systems: the Deep Generative Service Times. Our methodology delivers a flexible and scalable model for service and response times. We leverage the representation capabilities of Recurrent Marked Point Processes for the temporal dynamics of clients, as well as Wasserstein Generative  Adversarial  Network  techniques,  to  learn deep generative models which are able to represent complex conditional service time distributions. We provide extensive experimental analysis on both empirical and synthetic datasets, showing the effectiveness of the proposed models",
        "primary_area": "Machine Learning III",
        "author": "Cesar Ojeda; Kostadin Cvejoski; Bodgan Georgiev; Christian Bauckhage; Jannis Schuecker; Ramses J. Sanchez",
        "authorids": "",
        "aff": "Berlin Center for Machine Learning TU Berlin; Competence Center Machine Learning Rhine-Ruhr Fraunhofer Center for Machine Learning Fraunhofer IAIS; Competence Center Machine Learning Rhine-Ruhr Fraunhofer Center for Machine Learning Fraunhofer IAIS; Competence Center Machine Learning Rhine-Ruhr Fraunhofer Center for Machine Learning Fraunhofer IAIS; Bayer AG; Competence Center Machine Learning Rhine-Ruhr B-IT University of Bonn",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17112/17112-13-20606-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09214-learning-deep-generative-models-for-queuing-systems/",
        "doi": "10.1609/aaai.v35i10.17112",
        "pdf_size": 555077
    },
    {
        "id": "02403",
        "title": "Learning Disentangled Representation for Fair Facial Attribute Classification via Fairness-aware Information Alignment",
        "track": "main",
        "status": "Poster",
        "abstract": "Although AI systems archive a great success in various societal fields, there still exists a challengeable issue of outputting discriminatory results with respect to protected attributes (e.g., gender and age). The popular approach to solving the issue is to remove protected attribute information in the decision process. However, this approach has a limitation that beneficial information for target tasks may also be eliminated. To overcome the limitation, we propose Fairness-aware Disentangling Variational Auto-Encoder (FD-VAE) that disentangles data representation into three subspaces: 1) Target Attribute Latent (TAL), 2) Protected Attribute Latent (PAL), 3) Mutual Attribute Latent (MAL). On top of that, we propose a decorrelation loss that aligns the overall information into each subspace, instead of removing the protected attribute information. After learning the representation, we re-encode MAL to include only target information and combine it with TAL to perform downstream tasks. In our experiments on CelebA and UTK Face datasets, we show that the proposed method mitigates unfairness in facial attribute classification tasks with respect to gender and age. Ours outperforms previous methods by large margins on two standard fairness metrics, equal opportunity and equalized odds.",
        "primary_area": "Computer Vision II",
        "author": "Sungho Park; Sunhee Hwang; Dohyung Kim; Hyeran Byun",
        "authorids": "",
        "aff": "Yonsei University, Seoul, Korea; Yonsei University, Seoul, Korea; Yonsei University, Seoul, Korea; Yonsei University, Seoul, Korea",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16341/16341-13-19835-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02403-learning-disentangled-representation-for-fair-facial-attribute-classification-via-fairness-aware-information-alignment/",
        "doi": "10.1609/aaai.v35i3.16341",
        "pdf_size": 5009236
    },
    {
        "id": "09782",
        "title": "Learning Dynamics Models with Stable Invariant Sets",
        "track": "main",
        "status": "Poster",
        "abstract": "Invariance and stability are essential notions in dynamical systems study, and thus it is of great interest to learn a dynamics model with a stable invariant set. However, existing methods can only handle the stability of an equilibrium. In this paper, we propose a method to ensure that a dynamics model has a stable invariant set of general classes such as limit cycles and line attractors. We start with the approach by Manek and Kolter (2019), where they use a learnable Lyapunov function to make a model stable with regard to an equilibrium. We generalize it for general sets by introducing projection onto them. To resolve the difficulty of specifying a to-be stable invariant set analytically, we propose defining such a set as a primitive shape (e.g., sphere) in a latent space and learning the transformation between the original and latent spaces. It enables us to compute the projection easily, and at the same time, we can maintain the model's flexibility using various invertible neural networks for the transformation. We present experimental results that show the validity of the proposed method and the usefulness for long-term prediction.",
        "primary_area": "Machine Learning IV",
        "author": "Naoya Takeishi; Yoshinobu Kawahara",
        "authorids": "",
        "aff": "RIKEN Center for Advanced Intelligence Project University of Applied Sciences and Arts Western Switzerland; Kyushu University RIKEN Center for Advanced Intelligence Project",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17176/17176-13-20670-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09782-learning-dynamics-models-with-stable-invariant-sets/",
        "doi": "10.1609/aaai.v35i11.17176",
        "pdf_size": 2450858
    },
    {
        "id": "10441",
        "title": "Learning Energy-Based Model with Variational Auto-Encoder as Amortized Sampler",
        "track": "main",
        "status": "Poster",
        "abstract": "Due to the intractable partition function, training energy-based models (EBMs) by maximum likelihood requires Markov chain Monte Carlo (MCMC) sampling to approximate the gradient of the Kullback-Leibler divergence between data and model distributions. However, it is non-trivial to sample from an EBM because of the difficulty of mixing between modes. In this paper, we propose to learn a variational auto-encoder (VAE) to initialize the finite-step MCMC, such as Langevin dynamics that is derived from the energy function, for efficient amortized sampling of the EBM. With these amortized MCMC samples, the EBM can be trained by maximum likelihood, which follows an \"analysis by synthesis\" scheme; while the VAE learns from these MCMC samples via variational Bayes. We call this joint training algorithm the variational MCMC teaching, in which the VAE chases the EBM toward data distribution. We interpret the learning algorithm as a dynamic alternating projection in the context of information geometry. Our proposed models can generate samples comparable to GANs and EBMs. Additionally, we demonstrate that our model can learn effective probabilistic distribution toward supervised conditional learning tasks.",
        "primary_area": "Machine Learning V",
        "author": "Jianwen Xie; Zilong Zheng; Ping Li",
        "authorids": "",
        "aff": "Baidu Research; Baidu Research; Baidu Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17250/17250-13-20744-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10441-learning-energy-based-model-with-variational-auto-encoder-as-amortized-sampler/",
        "doi": "10.1609/aaai.v35i12.17250",
        "pdf_size": 3511914
    },
    {
        "id": "03465",
        "title": "Learning Flexibly Distributional Representation for Low-quality 3D Face Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "Due to the superiority of using geometric information, 3D Face Recognition (FR) has achieved great successes. Existing methods focus on high-quality 3D FR which is unpractical in real scenarios. Low-quality 3D FR is a more realistic scenario but the low-quality data are born with heavy noises. Therefore, exploring noise-robust low-quality 3D FR methods becomes an urgent and challenging problem. To solve this issue, in this paper, we propose to learn flexibly distributional representation for low-quality 3D FR. Firstly, we introduce the distributional representation for low-quality 3D faces due to that it can weaken the impact of noises. Generally, the distributional representation of a given 3D face is restricted to a specific distribution such as Gaussian distribution. However, the specific distribution may be not up to describing the complex low-quality face. Therefore, we propose to transform this specific distribution to a flexible one via Continuous Normalizing Flow (CNF), which can get rid of the form limitation. This kind of flexible distribution can approximate the latent distribution of the given noisy face more accurately, which further improves accuracy of low-quality 3D FR. Comprehensive experiments show that our proposed method improves both low-quality and cross-quality 3D FR performances on low-quality benchmarks. Furthermore, the improvements are more remarkable on low-quality 3D faces when the intensity of noise increases which indicate the robustness",
        "primary_area": "Computer Vision III",
        "author": "Zihui Zhang; Cuican Yu; Shuang Xu; Huibin Li",
        "authorids": "",
        "aff": "Xi'an Jiaotong University; Xi'an Jiaotong University; Xi'an Jiaotong University; Xi'an Jiaotong University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16460/16460-13-19954-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03465-learning-flexibly-distributional-representation-for-low-quality-3d-face-recognition/",
        "doi": "10.1609/aaai.v35i4.16460",
        "pdf_size": 774201
    },
    {
        "id": "04950",
        "title": "Learning Game-Theoretic Models of Multiagent Trajectories Using Implicit Layers",
        "track": "main",
        "status": "Poster",
        "abstract": "For prediction of interacting agents' trajectories,  we propose an end-to-end trainable architecture that hybridizes neural nets with game-theoretic reasoning, has interpretable intermediate representations, and transfers to downstream decision making. It uses a net that reveals preferences from the agents' past joint trajectory, and a differentiable implicit layer that maps these preferences to local Nash equilibria, forming the modes of the predicted future trajectory. Additionally, it learns an equilibrium refinement concept. For tractability, we introduce a new class of continuous potential games and an equilibrium-separating partition of the action space. We provide theoretical results for explicit gradients and soundness. In experiments, we evaluate our approach on two real-world data sets, where we predict highway drivers' merging trajectories, and on a simple decision-making transfer task.",
        "primary_area": "Neuro-Symbolic AI",
        "author": "Philipp Geiger; Christoph-Nikolas Straehle",
        "authorids": "",
        "aff": "Bosch Center for Artificial Intelligence; Bosch Center for Artificial Intelligence",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16628/16628-13-20122-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04950-learning-game-theoretic-models-of-multiagent-trajectories-using-implicit-layers/",
        "doi": "10.1609/aaai.v35i6.16628",
        "pdf_size": 504111
    },
    {
        "id": "11801",
        "title": "Learning General Planning Policies from Small Examples Without Supervision",
        "track": "main",
        "status": "Poster",
        "abstract": "Generalized planning is concerned with the computation of general policies that solve multiple instances of a planning domain all at once. It has been recently shown that these policies can be computed in two steps: first, a suitable abstraction in the form of a qualitative numerical planning problem (QNP) is learned from sample plans, then the general policies are obtained from the learned QNP using a planner. In this work, we introduce an alternative approach for computing more expressive general policies which does not require sample plans or a QNP planner. The new formulation is very simple and can be cast in terms that are more standard in machine learning: a large but finite pool of features is defined from the predicates in the planning examples using a general grammar, and a small subset of features is sought for separating \u201cgood\u201d from \u201cbad\u201d state transitions, and goals from non-goals. The problems of finding such a \u201cseparating surface\u201d while labeling the transitions as \u201cgood\u201d or \u201cbad\u201d are jointly addressed as a single combinatorial optimization problem expressed as a Weighted Max-SAT problem. The advantage of looking for the simplest policy in the given feature space that solves the given examples, possibly non-optimally, is that many domains have no general, compact policies that are optimal. The approach yields general policies for a number of benchmark domains.",
        "primary_area": "Planning, Routing, and Scheduling",
        "author": "Guillem Franc\u00e8s; Blai Bonet; Hector Geffner",
        "authorids": "",
        "aff": "Universitat Pompeu Fabra; Universitat Pompeu Fabra; ICREA and Universitat Pompeu Fabra",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17402/17402-13-20896-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11801-learning-general-planning-policies-from-small-examples-without-supervision/",
        "doi": "10.1609/aaai.v35i13.17402",
        "pdf_size": 148215
    },
    {
        "id": "08064",
        "title": "Learning Generalized Relational Heuristic Networks for Model-Agnostic Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Computing goal-directed behavior is essential to designing efficient AI systems. Due to the computational complexity of planning, current approaches rely primarily upon hand-coded symbolic action models and hand-coded heuristic function generators for efficiency. Learned heuristics for such problems have been of limited utility as they are difficult to apply to problems with objects and object quantities that are significantly different from those in the training data. This paper develops a new approach for learning generalized heuristics in the absence of symbolic action models using deep neural networks that utilize an input predicate vocabulary but are agnostic to object names and quantities.  It uses an abstract state representation to facilitate data-efficient, generalizable learning. Empirical evaluation on a range of benchmark domains shows that in contrast to prior approaches, generalized heuristics computed by this method can be transferred easily to problems with different objects and with object quantities much larger than those in the training data.",
        "primary_area": "Machine Learning II",
        "author": "Rushang Karia; Siddharth Srivastava",
        "authorids": "",
        "aff": "Arizona State University; Arizona State University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16983/16983-13-20477-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08064-learning-generalized-relational-heuristic-networks-for-model-agnostic-planning/",
        "doi": "10.1609/aaai.v35i9.16983",
        "pdf_size": 433624
    },
    {
        "id": "03056",
        "title": "Learning Geometry-Disentangled Representation for Complementary Understanding of 3D Object Point Cloud",
        "track": "main",
        "status": "Poster",
        "abstract": "In 2D image processing, some attempts decompose images into high and low frequency components for describing edge and smooth parts respectively. Similarly, the contour and flat area of 3D objects, such as the boundary and seat area of a chair, describe different but also complementary geometries. However, such investigation is lost in previous deep networks that understand point clouds by directly treating all points or local patches equally. To solve this problem, we propose Geometry-Disentangled Attention Network (GDANet). GDANet introduces Geometry-Disentangle Module to dynamically disentangle point clouds into the contour and flat part of 3D objects, respectively denoted by sharp and gentle variation components. Then GDANet exploits Sharp-Gentle Complementary Attention Module that regards the features from sharp and gentle variation components as two holistic representations, and pays different attentions to them while fusing them respectively with original point cloud features. In this way, our method captures and refines the holistic and complementary 3D geometric semantics from two distinct disentangled components to supplement the local information. Extensive experiments on 3D object classification and segmentation benchmarks demonstrate that GDANet achieves the state-of-the-arts with fewer parameters.",
        "primary_area": "Computer Vision III",
        "author": "Mutian Xu; Junhao Zhang; Zhipeng Zhou; Mingye Xu; Xiaojuan Qi; Yu Qiao",
        "authorids": "",
        "aff": "Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences; The University of Hong Kong; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences; University of Chinese Academy of Sciences, China; The University of Hong Kong; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16414/16414-13-19908-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03056-learning-geometry-disentangled-representation-for-complementary-understanding-of-3d-object-point-cloud/",
        "doi": "10.1609/aaai.v35i4.16414",
        "pdf_size": 4900218
    },
    {
        "id": "08438",
        "title": "Learning Graph Neural Networks with Approximate Gradient Descent",
        "track": "main",
        "status": "Poster",
        "abstract": "The first provably efficient algorithm for learning graph neural networks (GNNs) with one hidden layer for node information convolution is provided in this paper. Two types of GNNs are investigated, depending on whether labels are attached to nodes or graphs. A comprehensive framework for designing and analyzing convergence of GNN training algorithms is developed. The algorithm proposed is applicable to a wide range of activation functions including ReLU, Leaky ReLU, Sigmod, Softplus and Swish. It is shown that the proposed algorithm guarantees a linear convergence rate to the underlying true parameters of GNNs. For both types of GNNs, sample complexity in terms of the number of nodes or the number of graphs is characterized. The impact of feature dimension and GNN structure on the convergence rate is also theoretically characterized. Numerical experiments are further provided to validate our theoretical analysis.",
        "primary_area": "Machine Learning III",
        "author": "Qunwei  Li; Shaofeng Zou; Wenliang Zhong",
        "authorids": "",
        "aff": "Ant Group, Hangzhou, China; University at Buffalo, the State University of New York; Ant Group, Hangzhou, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17025/17025-13-20519-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08438-learning-graph-neural-networks-with-approximate-gradient-descent/",
        "doi": "10.1609/aaai.v35i10.17025",
        "pdf_size": 234291
    },
    {
        "id": "10505",
        "title": "Learning Graphons via Structured Gromov-Wasserstein Barycenters",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a novel and principled method to learn a nonparametric graph model called graphon, which is defined in an infinite-dimensional space and represents arbitrary-size graphs.  Based on the weak regularity lemma from the theory of graphons, we leverage a step function to approximate a graphon.  We show that the cut distance of graphons can be relaxed to the Gromov-Wasserstein distance of their step functions.  Accordingly, given a set of graphs generated by an underlying graphon, we learn the corresponding step function as the Gromov-Wasserstein barycenter of the given graphs. Furthermore, we develop several enhancements and extensions of the basic algorithm, e.g., the smoothed Gromov-Wasserstein barycenter for guaranteeing the continuity of the learned graphons and the mixed Gromov-Wasserstein barycenters for learning multiple structured graphons.  The proposed approach overcomes drawbacks of prior state-of-the-art methods, and outperforms them on both synthetic and real-world data.  The code is available at https://github.com/HongtengXu/SGWB-Graphon.",
        "primary_area": "Machine Learning V",
        "author": "Hongteng Xu; Dixin Luo; Lawrence Carin; Hongyuan Zha",
        "authorids": "",
        "aff": "Gaoling School of Artificial Intelligence, Renmin University of China Beijing Key Laboratory of Big Data Management and Analysis Methods; School of Computer Science and Technology, Beijing Institue of Technology; Department of Electrical and Computer Engineering, Duke University; School of Data Science, Shenzhen Research Institute of Big Data, The Chinese University of Hong Kong, Shenzhen",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17257/17257-13-20751-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10505-learning-graphons-via-structured-gromov-wasserstein-barycenters/",
        "doi": "10.1609/aaai.v35i12.17257",
        "pdf_size": 9327068
    },
    {
        "id": "02172",
        "title": "Learning Hybrid Relationships for Person Re-identification",
        "track": "main",
        "status": "Poster",
        "abstract": "Recently, the relationship among individual pedestrian images and the relationship among pairwise pedestrian images have become attractive for person re-identification (re-ID) as they effectively improve the ability of feature representation. In this paper, we propose a novel method named Hybrid Relationship Network (HRNet) to learn the two types of relationships in a unified framework that makes use of their own advantages. Specifically, for the relationship among individual pedestrian images, we take the features of pedestrian images as the nodes to construct a locally-connected graph, so as to improve the discriminative ability of nodes. Meanwhile, we propose the consistent node constraint to inject the identity information into the graph learning process and guide the information to propagate accurately. As for the relationship among pairwise pedestrian images, we treat the feature differences of pedestrian images as the nodes to construct a fully-connected graph so as to estimate robust similarity of nodes. Furthermore, we propose the inter-graph propagation to alleviate the information loss for the fully-connected graph. Extensive experiments on Market-1501, DukeMTMCreID, CUHK03 and MSMT17 demonstrate that the proposed HRNet outperforms the state-of-the-art methods.",
        "primary_area": "Computer Vision II",
        "author": "Shuang Liu; Wenmin Huang; Zhong Zhang",
        "authorids": "",
        "aff": "Tianjin Normal University; Tianjin Normal University; Tianjin Normal University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16315/16315-13-19809-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02172-learning-hybrid-relationships-for-person-re-identification/",
        "doi": "10.1609/aaai.v35i3.16315",
        "pdf_size": 282775
    },
    {
        "id": "08401",
        "title": "Learning Intact Features by Erasing-Inpainting for Few-shot Classification",
        "track": "main",
        "status": "Poster",
        "abstract": "Few-shot classification aims to categorize the samples from unseen classes with only few labeled samples. To address such a challenge, many methods exploit a base set consisting of massive labeled samples to learn an instance embedding function, i.e., image feature extractor, and it is expected to possess good transferability among different tasks. Such characteristics of few-shot learning are essentially different from that of traditional image classification only pursuing to get discriminative image representations. In this paper, we propose to learn intact features by erasing-inpainting for few-shot classification. Specifically,     we argue that extracting intact features of target objects is more transferable, and then propose a novel cross-set erasing-inpainting (CSEI) method. CSEI processes the images in the support set using erasing and inpainting, and then uses them to augment the query set of the same task. Consequently, the feature embedding produced by our proposed method can contain more complete information of target objects. In addition, we propose task-specific feature modulation to make the features adaptive to the current task. The extensive experiments on two widely used benchmarks well demonstrates the effectiveness of our proposed method, which can consistently get considerable performance gains for different baseline methods.",
        "primary_area": "Machine Learning II",
        "author": "Junjie Li; Zilei Wang; Xiaoming Hu",
        "authorids": "",
        "aff": "University of Science and Technology of China; University of Science and Technology of China; University of Science and Technology of China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17021/17021-13-20515-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08401-learning-intact-features-by-erasing-inpainting-for-few-shot-classification/",
        "doi": "10.1609/aaai.v35i9.17021",
        "pdf_size": 8443369
    },
    {
        "id": "10727",
        "title": "Learning Interpretable Models for Coupled Networks Under Domain Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "Modeling the behavior of coupled networks is challenging due to their intricate dynamics. For example in neuroscience, it is of critical importance to understand the relationship between the functional neural processes and the anatomical connectivities. Modern neuroimaging techniques allow us to separately measure functional connectivities through fMRI imaging and measure underlying white matter wirings through diffusion imaging. Previous studies have shown that structural edges in brain networks improve the inference of functional edges and vice versa. In this paper, we investigate the idea of coupled networks through an optimization framework by focusing on interactions between structural edges and functional edges of brain networks. We consider both types of edges as observed instances of random variables that represent different underlying network processes. The proposed framework does not depend on the Gaussian functional form and achieves a more robust selection on non-Gaussian data compared with existing approaches. To incorporate existing domain knowledge into such studies, we propose a novel formulation to place hard network constraints on the noise term while estimating interactions. This not only leads to a cleaner way of applying network constraints but also brings a more scalable solution when the network connectivity is sparse. We validate our method on multishell diffusion and task-evoked fMRI datasets from Human Connectome Project, leading to both important insights on structural backbones that support various types of task activities performed during the scanning sessions as well as general solutions to the study of coupled networks.",
        "primary_area": "Machine Learning V",
        "author": "Hongyuan You; Sikun Lin; Ambuj Singh",
        "authorids": "",
        "aff": "University of California, Santa Barbara; University of California, Santa Barbara; University of California, Santa Barbara",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17282/17282-13-20776-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10727-learning-interpretable-models-for-coupled-networks-under-domain-constraints/",
        "doi": "10.1609/aaai.v35i12.17282",
        "pdf_size": 6445316
    },
    {
        "id": "06110",
        "title": "Learning Intuitive Physics with Multimodal Generative Models",
        "track": "main",
        "status": "Poster",
        "abstract": "Predicting the future interaction of objects when they come into contact with their environment is key for  autonomous agents to take intelligent and anticipatory actions. This paper presents a perception framework that fuses  visual and tactile feedback to make predictions about the expected motion of objects in dynamic scenes. Visual information captures object properties such as 3D shape and location, while tactile information provides critical cues about interaction forces and resulting object motion when it  makes contact with the environment. Utilizing a novel See-Through-your-Skin (STS) sensor that provides high resolution  multimodal sensing of contact surfaces, our system captures both the visual appearance and the tactile properties of objects. We interpret the dual stream signals from the sensor using a Multimodal Variational Autoencoder (MVAE), allowing us to capture both modalities of contacting objects and to develop a mapping from visual to tactile interaction and vice-versa. Additionally, the perceptual system can be used to infer the outcome of future physical interactions, which we validate through simulated and real-world experiments in which the resting state of an object  is predicted from given initial conditions.",
        "primary_area": "Intelligent Robots",
        "author": "Sahand Rezaei-Shoshtari; Francois R. Hogan; Michael Jenkin; David Meger; Gregory Dudek",
        "authorids": "",
        "aff": "Samsung AI Center Montreal McGill University; Samsung AI Center Montreal; Samsung AI Center Montreal York University; Samsung AI Center Montreal McGill University; Samsung AI Center Montreal McGill University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16761/16761-13-20255-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06110-learning-intuitive-physics-with-multimodal-generative-models/",
        "doi": "10.1609/aaai.v35i7.16761",
        "pdf_size": 17249254
    },
    {
        "id": "06582",
        "title": "Learning Invariant Representations using Inverse  Contrastive Loss",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning invariant representations is a critical first step in a number of machine learning tasks. A common approach is given by the so-called information bottleneck principle in which an application dependent function of mutual information is carefully chosen and optimized. Unfortunately, in practice, these functions are not suitable for optimization purposes since these losses are agnostic of the metric structure of the parameters of the model. In our paper, we introduce a class of losses for learning representations that are invariant to some extraneous variable of interest by inverting the class of contrastive losses, i.e., inverse contrastive loss (ICL). We show that if the extraneous variable is binary, then optimizing ICL is equivalent to optimizing a regularized MMD divergence. More generally, we also show that if we are provided a metric on the sample space, our formulation of ICL can be decomposed into a sum of convex functions of the given distance metric. Our experimental results indicate that models obtained by optimizing ICL achieve significantly better invariance to the extraneous variable for a fixed desired level of accuracy. In a variety of experimental settings, we show applicability of ICL for learning invariant representations for both continuous and discrete protected/extraneous variables. The project page with code is available at https://github.com/adityakumarakash/ICL",
        "primary_area": "Machine Learning I",
        "author": "Aditya Kumar Akash; Vishnu  Suresh Lokhande; Sathya N. Ravi; Vikas Singh",
        "authorids": "",
        "aff": "University of Wisconsin Madison; University of Wisconsin-Madison; University of Illinois at Chicago; University of Wisconsin Madison",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16815/16815-13-20309-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06582-learning-invariant-representations-using-inverse-contrastive-loss/",
        "doi": "10.1609/aaai.v35i8.16815",
        "pdf_size": 2298885
    },
    {
        "id": "13217",
        "title": "Learning Light-Weight Translation Models from Deep Transformer",
        "track": "main",
        "status": "Poster",
        "abstract": "Recently, deep models have shown tremendous improvements in neural machine translation (NMT). However, systems of this kind are computationally expensive and memory intensive. In this paper, we take a natural step towards learning strong but light-weight NMT systems. We proposed a novel group-permutation based knowledge distillation approach to compressing the deep Transformer model into a shallow model. The experimental results on several benchmarks validate the effectiveness of our method. Our compressed model is 8 times shallower than the deep model, with almost no loss in BLEU. To further enhance the teacher model, we present a Skipping Sub-Layer method to randomly omit sub-layers to introduce perturbation into training, which achieves a BLEU score of 30.63 on English-German newstest2014. The code is publicly available at https://github.com/libeineu/GPKD.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Bei Li; Ziyang Wang; Hui Liu; Quan Du; Tong Xiao; Chunliang Zhang; Jingbo Zhu",
        "authorids": "",
        "aff": "Northeastern University, China; Northeastern University; Northeastern University; Northeastern University NiuTrans Research; Northeastern University NiuTrans Research; Northeastern University, China NiuTrans Research; Northeastern University, China NiuTrans Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17561/17561-13-21055-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13217-learning-light-weight-translation-models-from-deep-transformer/",
        "doi": "10.1609/aaai.v35i15.17561",
        "pdf_size": 157728
    },
    {
        "id": "01397",
        "title": "Learning Local Neighboring Structure for Robust 3D Shape Representation",
        "track": "main",
        "status": "Poster",
        "abstract": "Mesh is a powerful data structure for 3D shapes. Representation learning for 3D meshes is important in many computer vision and graphics applications. The recent success of convolutional neural networks (CNNs) for structured data (e.g., images) suggests the value of adapting insight from CNN for 3D shapes. However, 3D shape data are irregular since each node's neighbors are unordered. Various graph neural networks for 3D shapes have been developed with isotropic filters or predefined local coordinate systems to overcome the node inconsistency on graphs. However, isotropic filters or predefined local coordinate systems limit the representation power. In this paper, we propose a local structure-aware anisotropic convolutional operation (LSA-Conv) that learns adaptive weighting matrices for each node according to the local neighboring structure and performs shared anisotropic filters. In fact, the learnable weighting matrix is similar to the attention matrix in random synthesizer -- a new Transformer model for natural language processing (NLP). Comprehensive experiments demonstrate that our model produces significant improvement in 3D shape reconstruction compared to state-of-the-art methods.",
        "primary_area": "Computer Vision I",
        "author": "Zhongpai Gao; Junchi Yan; Guangtao Zhai; Juyong Zhang; Yiyan Yang; Xiaokang Yang",
        "authorids": "",
        "aff": "Shanghai Jiao Tong University; Shanghai Jiao Tong University; Shanghai Jiao Tong University; University of Science and Technology of China; Shanghai Jiao Tong University; Shanghai Jiao Tong University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16229/16229-13-19723-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01397-learning-local-neighboring-structure-for-robust-3d-shape-representation/",
        "doi": "10.1609/aaai.v35i2.16229",
        "pdf_size": 3555657
    },
    {
        "id": "10790",
        "title": "Learning Modality-Specific Representations with Self-Supervised Multi-Task Learning for Multimodal Sentiment Analysis",
        "track": "main",
        "status": "Poster",
        "abstract": "Representation Learning is a significant and challenging task in multimodal learning. Effective modality representations should contain two parts of characteristics: the consistency and the difference. Due to the unified multimodal annota- tion, existing methods are restricted in capturing differenti- ated information. However, additional unimodal annotations are high time- and labor-cost. In this paper, we design a la- bel generation module based on the self-supervised learning strategy to acquire independent unimodal supervisions. Then, joint training the multimodal and uni-modal tasks to learn the consistency and difference, respectively. Moreover, dur- ing the training stage, we design a weight-adjustment strat- egy to balance the learning progress among different sub- tasks. That is to guide the subtasks to focus on samples with the larger difference between modality supervisions. Last, we conduct extensive experiments on three public multimodal baseline datasets. The experimental results validate the re- liability and stability of auto-generated unimodal supervi- sions. On MOSI and MOSEI datasets, our method surpasses the current state-of-the-art methods. On the SIMS dataset, our method achieves comparable performance than human- annotated unimodal labels. The full codes are available at https://github.com/thuiar/Self-MM.",
        "primary_area": "Machine Learning V",
        "author": "Wenmeng Yu; Hua Xu; Ziqi Yuan; Jiele Wu",
        "authorids": "",
        "aff": "State Key Laboratory of Intelligent Technology and Systems, Department of Computer Science and Technology, Tsinghua University, Beijing 100084, China; State Key Laboratory of Intelligent Technology and Systems, Department of Computer Science and Technology, Tsinghua University, Beijing 100084, China; State Key Laboratory of Intelligent Technology and Systems, Department of Computer Science and Technology, Tsinghua University, Beijing 100084, China; State Key Laboratory of Intelligent Technology and Systems, Department of Computer Science and Technology, Tsinghua University, Beijing 100084, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17289/17289-13-20783-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10790-learning-modality-specific-representations-with-self-supervised-multi-task-learning-for-multimodal-sentiment-analysis/",
        "doi": "10.1609/aaai.v35i12.17289",
        "pdf_size": 742179
    },
    {
        "id": "07702",
        "title": "Learning Model-Based Privacy Protection under Budget Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "Protecting privacy in gradient-based learning has become increasingly critical as more sensitive information is being used. Many existing solutions seek to protect the sensitive gradients by constraining the overall privacy cost within a constant budget, where the protection is hand-designed and empirically calibrated to boost the utility of the resulting model. However, it remains challenging to choose the proper protection adapted for specific constraints so that the utility is maximized. To this end, we propose a novel Learning-to-Protect algorithm that automatically learns a model-based protector from a set of non-private learning tasks. The learned protector can be applied to private learning tasks to improve utility within the specific privacy budget constraint. Our empirical studies on both synthetic and real datasets demonstrate that the proposed algorithm can achieve a superior utility with a given privacy constraint and generalize well to new private datasets distributed differently as compared to the hand-designed competitors.",
        "primary_area": "Machine Learning II",
        "author": "Junyuan Hong; Haotao Wang; Zhangyang Wang; Jiayu  Zhou",
        "authorids": "",
        "aff": "Michigan State University; University of Texas at Austin; University of Texas at Austin; Michigan State University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16941/16941-13-20435-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07702-learning-model-based-privacy-protection-under-budget-constraints/",
        "doi": "10.1609/aaai.v35i9.16941",
        "pdf_size": 722566
    },
    {
        "id": "02458",
        "title": "Learning Modulated Loss for Rotated Object Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Popular rotated detection methods usually use five parameters (coordinates of the central point, width, height, and rotation angle) or eight parameters (coordinates of four vertices) to describe the rotated bounding box and l1 loss as the loss function. In this paper, we argue that the aforementioned integration can cause training instability and performance degeneration. The main reason is the discontinuity of loss which is caused by the contradiction between the definition of the rotated bounding box and the loss function. We refer to the above issues as rotation sensitivity error (RSE) and propose a modulated rotation loss to dismiss the discontinuity of loss. The modulated rotation loss can achieve consistent improvement on the five parameter methods and the eight parameter methods. Experimental results using one stage and two stages detectors demonstrate the effectiveness of our loss. The integrated network achieves competitive performances on several benchmarks including DOTA and UCAS AOD. The code is available at https://github.com/yangxue0827/RotationDetection.",
        "primary_area": "Computer Vision II",
        "author": "Wen Qian; Xue Yang; Silong Peng; Junchi Yan; Yue Guo",
        "authorids": "",
        "aff": "Institute of Automation, Chinese Academy of Sciences University of Chinese Academy of Sciences; Department of Computer Science and Engineering, Shanghai Jiao Tong University MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University; Institute of Automation, Chinese Academy of Sciences University of Chinese Academy of Sciences; Department of Computer Science and Engineering, Shanghai Jiao Tong University MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University; Institute of Automation, Chinese Academy of Sciences University of Chinese Academy of Sciences",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16347/16347-13-19841-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02458-learning-modulated-loss-for-rotated-object-detection/",
        "doi": "10.1609/aaai.v35i3.16347",
        "pdf_size": 4904432
    },
    {
        "id": "01863",
        "title": "Learning Monocular Depth in Dynamic Scenes via Instance-Aware Projection Consistency",
        "track": "main",
        "status": "Poster",
        "abstract": "We present an end-to-end joint training framework that explicitly models 6-DoF motion of multiple dynamic objects, ego-motion, and depth in a monocular camera setup without supervision. Our technical contributions are three-fold. First, we highlight the fundamental difference between inverse and forward projection while modeling the individual motion of each rigid object, and propose a geometrically correct projection pipeline using a neural forward projection module. Second, we design a unified instance-aware photometric and geometric consistency loss that holistically imposes self-supervisory signals for every background and object region. Lastly, we introduce a general-purpose auto-annotation scheme using any off-the-shelf instance segmentation and optical flow models to produce video instance segmentation maps that will be utilized as input to our training pipeline. These proposed elements are validated in a detailed ablation study. Through extensive experiments conducted on the KITTI and Cityscapes dataset, our framework is shown to outperform the state-of-the-art depth and motion estimation methods. Our code, dataset, and models are publicly available.",
        "primary_area": "Computer Vision II",
        "author": "Seokju Lee; Sunghoon Im; Stephen Lin; In So Kweon",
        "authorids": "",
        "aff": "Korea Advanced Institute of Science and Technology (KAIST); Daegu Gyeongbuk Institute of Science and Technology (DGIST); Microsoft Research; Korea Advanced Institute of Science and Technology (KAIST)",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16281/16281-13-19775-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01863-learning-monocular-depth-in-dynamic-scenes-via-instance-aware-projection-consistency/",
        "doi": "10.1609/aaai.v35i3.16281",
        "pdf_size": 2887694
    },
    {
        "id": "01975",
        "title": "Learning Omni-Frequency Region-adaptive Representations for Real Image Super-Resolution",
        "track": "main",
        "status": "Poster",
        "abstract": "Traditional single image super-resolution (SISR) methods that focus on solving single and uniform degradation (i.e., bicubic down-sampling), typically suffer from poor performance when applied into real-world low-resolution (LR) images due to the complicated realistic degradations. The key to solving this more challenging real image super-resolution (RealSR) problem lies in learning feature representations that are both informative and content-aware. In this paper, we propose a Omni-frequency Region-adaptive Network (OR-Net) to address both challenges, here we call features of all low, middle and high frequencies omni-frequency features. Specifically, we start from the frequency perspective and design a Frequency Decomposition (FD) module to separate different frequency components to comprehensively compensate the information lost for real LR image. Then, considering the different regions of real LR image have different frequency information lost, we further design a Region-adaptive Frequency Aggregation (RFA) module by leveraging dynamic convolution and spatial attention to adaptively restore frequency components for different regions. The extensive experiments endorse the high-efficient, effective, and scenario-agnostic nature of our OR-Net for RealSR.",
        "primary_area": "Computer Vision II",
        "author": "Xin Li; Xin Jin; Tao Yu; Simeng Sun; Yingxue Pang; Zhizheng Zhang; Zhibo Chen",
        "authorids": "",
        "aff": "University of Science and Technology of China; University of Science and Technology of China; University of Science and Technology of China; University of Science and Technology of China; University of Science and Technology of China; University of Science and Technology of China; University of Science and Technology of China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16293/16293-13-19787-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01975-learning-omni-frequency-region-adaptive-representations-for-real-image-super-resolution/",
        "doi": "10.1609/aaai.v35i3.16293",
        "pdf_size": 929049
    },
    {
        "id": "09505",
        "title": "Learning Precise Temporal Point Event Detection with Misaligned Labels",
        "track": "main",
        "status": "Poster",
        "abstract": "This work addresses the problem of robustly learning precise temporal point event detection despite only having access to poorly aligned labels for training. While standard (cross entropy-based) methods work well in noise-free setting, they often fail when labels are unreliable since they attempt to strictly fit the annotations. A common solution to this drawback is to transform the point prediction problem into a distribution prediction problem. However, we show  that this approach raises several issues that negatively affect the robust learning of temporal localization. Thus, in an attempt to overcome these shortcomings, we introduce a simple and versatile training paradigm combining soft localization learning with counting-based sparsity regularization. In fact, unlike its counterparts, our approach allows to directly infer clear-cut point predictions in an end-to-end fashion while relaxing the reliance of the training on the exact position of labels. We achieve state-of-the-art performance against standard benchmarks in a number of challenging experiments (e.g., detection of instantaneous events in videos and music transcription) by simply replacing the original loss function with our novel alternative---without any additional fine-tuning.",
        "primary_area": "Machine Learning IV",
        "author": "Julien Schroeter; Kirill Sidorov; David Marshall",
        "authorids": "",
        "aff": "Cardiff University; Cardiff University; Cardiff University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17145/17145-13-20639-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09505-learning-precise-temporal-point-event-detection-with-misaligned-labels/",
        "doi": "10.1609/aaai.v35i11.17145",
        "pdf_size": 422468
    },
    {
        "id": "07305",
        "title": "Learning Prediction Intervals for Model Performance",
        "track": "main",
        "status": "Poster",
        "abstract": "Understanding model performance on unlabeled data is a fundamental challenge of developing, deploying, and maintaining AI systems. Model performance is typically evaluated using test sets or periodic manual quality assessments, both of which require laborious manual data labeling. Automated performance prediction techniques aim to mitigate this burden, but potential inaccuracy and a lack of trust in their predictions has prevented their widespread adoption. We address this core problem of performance prediction uncertainty with a method to compute prediction intervals for model performance. Our methodology uses transfer learning to train an uncertainty model to estimate the uncertainty of model performance predictions. We evaluate our approach across a wide range of drift conditions and show substantial improvement over competitive baselines. We believe this result makes prediction intervals, and performance prediction in general, significantly more practical for real-world use.",
        "primary_area": "Machine Learning I",
        "author": "Benjamin Elder; Matthew Arnold; Anupama Murthi; Ji\u0159\u00ed Navr\u00e1til",
        "authorids": "",
        "aff": "IBM Research; IBM Research; IBM Research; IBM Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16897/16897-13-20391-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07305-learning-prediction-intervals-for-model-performance/",
        "doi": "10.1609/aaai.v35i8.16897",
        "pdf_size": 268447
    },
    {
        "id": "08837",
        "title": "Learning Representations for Incomplete Time Series Clustering",
        "track": "main",
        "status": "Poster",
        "abstract": "Time-series clustering is an essential unsupervised technique for data analysis, applied to many real-world fields, such as medical analysis and DNA microarray. Existing clustering methods are usually based on the assumption that the data is complete. However, time series in real-world applications often contain missing values. Traditional strategy (imputing first and then clustering) does not optimize the imputation and clustering process as a whole, which not only makes per- formance dependent on the combination of imputation and clustering methods but also fails to achieve satisfactory re- sults. How to best improve the clustering performance on incomplete time series remains a challenge. This paper pro- poses a novel unsupervised temporal representation learning model, named Clustering Representation Learning on Incom- plete time-series data (CRLI). CRLI jointly optimizes the im- putation and clustering process to impute more discrimina- tive values for clustering and make the learned representa- tions possessed good clustering property. Also, to reduce the error propagation from imputation to clustering, we introduce a discriminator to make the distribution of imputation values close to the true one and train CRLI in an alternating train- ing manner. An experiment conducted on eight real-world in- complete time-series datasets shows that CRLI outperforms existing methods. We demonstrates the effectiveness of the learned representations and the convergence of the model through visualization analysis. Moreover, we reveal that the joint training strategy can impute values close to the true ones in those important sub-sequences, and impute more discrim- inative values in those less important sub-sequences at the same time, making the imputed sequence cluster-friendly.",
        "primary_area": "Machine Learning III",
        "author": "Qianli Ma; Chuxin Chen; Sen Li; Garrison W. Cottrell",
        "authorids": "",
        "aff": "South China University of Technology Key Laboratory of Big Data and Intelligent Robot (South China University of Technology), Ministry of Education; South China University of Technology; South China University of Technology; University of California, San Diego",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17070/17070-13-20564-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08837-learning-representations-for-incomplete-time-series-clustering/",
        "doi": "10.1609/aaai.v35i10.17070",
        "pdf_size": 2838904
    },
    {
        "id": "06002",
        "title": "Learning Rewards From Linguistic Feedback",
        "track": "main",
        "status": "Poster",
        "abstract": "We explore unconstrained natural language feedback as a learning signal for artificial agents. Humans use rich and varied language to teach, yet most prior work on interactive learning from language assumes a particular form of input (e.g., commands). We propose a general framework which does not make this assumption, instead using aspect-based sentiment analysis to decompose feedback into sentiment over the features of a Markov decision process. We then infer the teacher's reward function by regressing the sentiment on the features, an analogue of inverse reinforcement learning. To evaluate our approach, we first collect a corpus of teaching behavior in a cooperative task where both teacher and learner are human. We implement three artificial learners: sentiment-based \"literal\" and \"pragmatic\" models, and an inference network trained end-to-end to predict rewards. We then re-run our initial experiment, pairing human teachers with these artificial learners. All three models successfully learn from interactive human feedback. The inference network approaches the performance of the \"literal\" sentiment model, while the \"pragmatic\" model nears human performance. Our work provides insight into the information structure of naturalistic linguistic feedback as well as methods to leverage it for reinforcement learning.",
        "primary_area": "Humans and AI",
        "author": "Theodore R. Sumers; Mark K. Ho; Robert D. Hawkins; Karthik Narasimhan; Thomas L. Griffiths",
        "authorids": "",
        "aff": "Princeton University; Princeton University; Princeton University; Princeton University; Princeton University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16749/16749-13-20243-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06002-learning-rewards-from-linguistic-feedback/",
        "doi": "10.1609/aaai.v35i7.16749",
        "pdf_size": 904829
    },
    {
        "id": "03110",
        "title": "Learning Semantic Context from Normal Samples for Unsupervised Anomaly Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Unsupervised anomaly detection aims to identify data samples that have low probability density from a set of input samples, and only the normal samples are provided for model training. The inference of abnormal regions on the input image requires an understanding of the surrounding semantic context. This work presents a Semantic Context based Anomaly Detection Network, SCADN, for unsupervised anomaly detection by learning the semantic context from the normal samples. To achieve this, we first generate multi-scale striped masks to remove a part of regions  from the normal samples, and then train a generative adversarial network to reconstruct the unseen regions. Note that the masks are designed in multiple scales and stripe directions, and various training examples are generated to obtain the rich semantic context . In testing, we obtain an error map by computing the difference between the reconstructed image and the input image for all samples, and infer the abnormal samples based on the error maps. Finally, we perform various experiments on three public benchmark datasets and a new dataset LaceAD collected by us, and show that our method clearly outperforms the current state-of-the-art methods.",
        "primary_area": "Computer Vision III",
        "author": "Xudong Yan; Huaidong Zhang; Xuemiao Xu; Xiaowei Hu; Pheng-Ann Heng",
        "authorids": "",
        "aff": "South China University of Technology; South China University of Technology; South China University of Technology Ministry of Education Key Laboratory of Big Data and Intelligent Robot Guangdong Provincial Key Lab of Computational Intelligence and Cyberspace Information State Key Laboratory of Subtropical Building Science; The Chinese University of Hong Kong; The Chinese Univsersity of Hong Kong Shenzhen Key Laboratory of Virtual Reality and Human Interaction Technology, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16420/16420-13-19914-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03110-learning-semantic-context-from-normal-samples-for-unsupervised-anomaly-detection/",
        "doi": "10.1609/aaai.v35i4.16420",
        "pdf_size": 10154125
    },
    {
        "id": "10283",
        "title": "Learning Set Functions that are Sparse in Non-Orthogonal Fourier Bases",
        "track": "main",
        "status": "Poster",
        "abstract": "Many applications of machine learning on discrete domains, such as learning preference functions in recommender systems or auctions, can be reduced to estimating a set function that is sparse in the Fourier domain. In this work, we present a new family of algorithms for learning Fourier-sparse set functions. They require at most nk \u2212 k log k + k queries (set function evaluations), under mild conditions on the Fourier coefficients, where n is the size of the ground set and k the number of non-zero Fourier coefficients. In contrast to other work that focused on the orthogonal Walsh-Hadamard transform (WHT), our novel algorithms operate with recently introduced non-orthogonal Fourier transforms that offer different notions of Fourier-sparsity. These naturally arise when modeling, e.g., sets of items forming substitutes and complements. We  demonstrate effectiveness on several real-world applications.",
        "primary_area": "Machine Learning V",
        "author": "Chris Wendler; Andisheh Amrollahi; Bastian Seifert; Andreas Krause; Markus P\u00fcschel",
        "authorids": "",
        "aff": "ETH Zurich; ETH Zurich; ETH Zurich; ETH Zurich; ETH Zurich",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17232/17232-13-20726-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10283-learning-set-functions-that-are-sparse-in-non-orthogonal-fourier-bases/",
        "doi": "10.1609/aaai.v35i12.17232",
        "pdf_size": 305396
    },
    {
        "id": "11210",
        "title": "Learning Task-Distribution Reward Shaping with Meta-Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Reward shaping is one of the most effective methods to tackle the crucial yet challenging problem of credit assignment and accelerate Reinforcement Learning. However, designing shaping functions usually requires rich expert knowledge and hand-engineering, and the difficulties are further exacerbated given multiple tasks to solve. In this paper, we consider reward shaping on a distribution of tasks that share state spaces but not necessarily action spaces. We provide insights into optimal reward shaping, and propose a novel meta-learning framework to automatically learn such reward shaping to apply on newly sampled tasks. Theoretical analysis and extensive experiments establish us as the state-of-the-art in learning task-distribution reward shaping, outperforming previous such works (Konidaris and Barto 2006; Snel and Whiteson 2014). We further show that our method outperforms learning intrinsic rewards (Yang et al. 2019; Zheng et al. 2020), outperforms Rainbow (Hessel et al. 2018) in complex pixel-based CoinRun games, and is also better than hand-designed reward shaping on grids. While the goal of this paper is to learn reward shaping rather than to propose new general meta-learning algorithms as PEARL (Rakelly et al. 2019) or MQL (Fakoor et al. 2020), our framework based on MAML (Finn, Abbeel, and Levine 2017) also outperforms PEARL / MQL, and could combine with them for further improvement.",
        "primary_area": "Machine Learning V",
        "author": "Haosheng Zou; Tongzheng Ren; Dong Yan; Hang Su; Jun Zhu",
        "authorids": "",
        "aff": "Tsinghua University; UT Austin; Tsinghua University; Tsinghua Univiersity; Tsinghua University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17337/17337-13-20831-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11210-learning-task-distribution-reward-shaping-with-meta-learning/",
        "doi": "10.1609/aaai.v35i12.17337",
        "pdf_size": 3962226
    },
    {
        "id": "06410",
        "title": "Learning Term Embeddings for Lexical Taxonomies",
        "track": "main",
        "status": "Poster",
        "abstract": "Lexical taxonomies, a special kind of knowledge graph, are essential for natural language understanding. This paper studies the problem of lexical taxonomy embedding. Most existing graph embedding methods are difficult to apply to lexical taxonomies since 1) they ignore implicit but important information, namely, sibling relations, which are not explicitly mentioned in lexical taxonomies and 2) there are lots of polysemous terms in lexical taxonomies. In this paper, we propose a novel method for lexical taxonomy embedding. This method optimizes an objective function that models both hyponym-hypernym relations and sibling relations. A term-level attention mechanism and a random walk based metric are then proposed to assist the modeling of these two kinds of relations, respectively. Finally, a novel training method based on curriculum learning is proposed. We conduct extensive experiments on two tasks to show that our approach outperforms other embedding methods and we use the learned term embeddings to enhance the performance of the state-of-the-art models that are based on BERT and RoBERTa on text classification.",
        "primary_area": "Knowledge Representation and Reasoning",
        "author": "Jingping Liu; Menghui Wang; Chao Wang; Jiaqing Liang; Lihan Chen; Haiyun Jiang; Yanghua Xiao; Yunwen Chen",
        "authorids": "",
        "aff": "Fudan University; Fudan University; Fudan University; Fudan University; Fudan University; Fudan University; Fudan University; DataGrand Inc.",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16795/16795-13-20289-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06410-learning-term-embeddings-for-lexical-taxonomies/",
        "doi": "10.1609/aaai.v35i7.16795",
        "pdf_size": 192423
    },
    {
        "id": "03661",
        "title": "Learning To Scale Mixed-Integer Programs",
        "track": "main",
        "status": "Poster",
        "abstract": "Many practical applications require the solution of numerically challenging linear programs (LPs) and mixed integer programs (MIPs). Scaling is a widely used preconditioning technique that aims at reducing the error propagation of the involved linear systems, thereby improving the numerical behavior of the dual simplex algorithm and, consequently, LP-based branch-and-bound. A reliable scaling method often makes the difference whether these problems can be solved correctly or not. In this paper, we investigate the use of machine learning to choose at the beginning of the solution process between two common scaling methods: Standard scaling and Curtis-Reid scaling. The latter often, but not always, leads to a more robust solution process, but may suffer from longer solution times.  Rather than training for overall solution time, we propose to use the attention level of a MIP solution process as a learning label. We evaluate the predictive power of a random forest approach and a linear regressor that learns the (square-root of the) difference in attention level. It turns out that the resulting classification not only reduces various types of numerical errors by large margins, but it also improves the performance of the dual simplex algorithm.  The learned model has been implemented within the FICO Xpress MIP solver and it is used by default since release 8.9, May 2020, to determine the scaling algorithm Xpress applies before solving an LP or a MIP.",
        "primary_area": "Constraint Satisfaction and Optimization",
        "author": "Timo Berthold; Gregor Hendel",
        "authorids": "",
        "aff": "FICO; FICO",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16482/16482-13-19976-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03661-learning-to-scale-mixed-integer-programs/",
        "doi": "10.1609/aaai.v35i5.16482",
        "pdf_size": 315207
    },
    {
        "id": "03261",
        "title": "Learning Visual Context for Group Activity Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "Group activity recognition aims to recognize an overall activity in a multi-person scene. Previous methods strive to reason on individual features. However, they under-explore the person-specific contextual information, which is significant and informative in computer vision tasks. In this paper, we propose a new reasoning paradigm to incorporate global contextual information. Specifically, we propose two modules to bridge the gap between group activity and visual context. The first is Transformer based Context Encoding (TCE) module, which enhances individual representation by encoding global contextual information to individual features and refining the aggregated information. The second is Spatial-Temporal Bilinear Pooling (STBiP) module. It firstly further explores pairwise relationships for the context encoded individual representation, then generates semantic representations via gated message passing on a constructed spatial-temporal graph. On their basis, we further design a two-branch model that integrates the designed modules into a pipeline. Systematic experiments demonstrate each module's effectiveness on either branch. Visualizations indicate that visual contextual cues can be aggregated globally by TCE. Moreover, our method achieves state-of-the-art results on two widely used benchmarks using only RGB images as input and 2D backbones.",
        "primary_area": "Computer Vision III",
        "author": "Hangjie Yuan; Dong Ni",
        "authorids": "",
        "aff": "Zhejiang University College of Control Science and Engineering, Zhejiang University, Hangzhou, China; Zhejiang University College of Control Science and Engineering, Zhejiang University, Hangzhou, China State Key Laboratory of Industrial Control Technology, Zhejiang University, Hangzhou, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16437/16437-13-19931-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03261-learning-visual-context-for-group-activity-recognition/",
        "doi": "10.1609/aaai.v35i4.16437",
        "pdf_size": 563746
    },
    {
        "id": "08635",
        "title": "Learning a Few-shot Embedding Model with Contrastive Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Few-shot learning (FSL) aims to recognize target classes by adapting the prior knowledge learned from source classes. Such knowledge usually resides in a deep embedding model for a general matching purpose of the support and query image pairs. The objective of this paper is to repurpose the contrastive learning for such matching to learn a few-shot embedding model. We make the following contributions: (i) We investigate the contrastive learning with Noise Contrastive Estimation (NCE) in a supervised manner for training a few-shot embedding model; (ii) We propose a novel contrastive training scheme dubbed infoPatch, exploiting the patch-wise relationship to substantially improve the popular infoNCE; (iii) We show that the embedding learned by the proposed infoPatch is more effective; (iv) Our model is thoroughly evaluated on few-shot recognition task; and demonstrates state-of-the-art results on miniImageNet and appealing performance on tieredImageNet, Fewshot-CIFAR100 (FC-100).",
        "primary_area": "Machine Learning III",
        "author": "Chen Liu; Yanwei Fu; Chengming Xu; Siqian Yang; Jilin Li; Chengjie Wang; Li Zhang",
        "authorids": "",
        "aff": "Fudan University; Fudan University; Fudan University; Tencent; Tencent; Tencent; Fudan University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17047/17047-13-20541-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08635-learning-a-few-shot-embedding-model-with-contrastive-learning/",
        "doi": "10.1609/aaai.v35i10.17047",
        "pdf_size": 2018631
    },
    {
        "id": "07377",
        "title": "Learning a Gradient-free Riemannian Optimizer on Tangent Spaces",
        "track": "main",
        "status": "Poster",
        "abstract": "A principal way of addressing constrained optimization problems is to model them as problems on Riemannian manifolds. Recently, Riemannian meta-optimization provides a promising way for solving constrained optimization problems by learning optimizers on Riemannian manifolds in a data-driven fashion, making it possible to design task-specific constrained optimizers.  A close look at the Riemannian meta-optimization reveals that learning optimizers on Riemannian manifolds needs to differentiate through the nonlinear Riemannian optimization, which is complex and computationally expensive.  In this paper, we propose a simple yet efficient Riemannian meta-optimization method that learns to optimize on tangent spaces of manifolds. In doing so, we present a gradient-free optimizer on tangent spaces, which takes parameters of the model along with the training data as inputs, and generates the updated parameters directly.  As a result, the constrained optimization is transformed from Riemannian manifolds to tangent spaces where complex Riemannian operations (e.g., retraction operations) are removed from the optimizer, and learning the optimizer does not need to differentiate through the Riemannian optimization. We empirically show that our method brings efficient learning of the optimizer, while enjoying a good optimization trajectory in a data-driven manner.",
        "primary_area": "Machine Learning I",
        "author": "Xiaomeng Fan; Zhi Gao; Yuwei Wu; Yunde Jia; Mehrtash Harandi",
        "authorids": "",
        "aff": "Beijing Institute of Technology; Beijing Institute of Technology; Beijing Institute of Technology; Beijing Institute of Technology; Monash University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16905/16905-13-20399-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07377-learning-a-gradient-free-riemannian-optimizer-on-tangent-spaces/",
        "doi": "10.1609/aaai.v35i8.16905",
        "pdf_size": 948665
    },
    {
        "id": "14158",
        "title": "Learning an Effective Context-Response Matching Model with Self-Supervised Tasks for Retrieval-based Dialogues",
        "track": "main",
        "status": "Poster",
        "abstract": "Building an intelligent dialogue system with the ability to select a proper response according to a multi-turn context is a great challenging task. Existing studies focus on building a context-response matching model with various neural architectures or pretrained language models (PLMs) and typically learning with a single response prediction task. These approaches overlook many potential training signals contained in dialogue data, which might be beneficial for context understanding and produce better features for response prediction.  Besides, the response retrieved from existing dialogue systems supervised by the conventional way still faces some critical challenges, including incoherence and inconsistency. To address these issues, in this paper, we propose learning a context-response matching model with auxiliary self-supervised tasks designed for the dialogue data based on pre-trained language models. Specifically, we introduce four self-supervised tasks including next session prediction, utterance restoration, incoherence detection and consistency discrimination, and jointly train the PLM-based response selection model with these auxiliary tasks in a multi-task manner.   By this means, the auxiliary tasks can guide the learning of the matching model to achieve a better local optimum and select a more proper response. Experiment results on two benchmarks indicate that the proposed auxiliary self-supervised tasks bring significant improvement for multi-turn response selection in retrieval-based dialogues, and our model achieves new state-of-the-art results on both datasets.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Ruijian Xu; Chongyang Tao; Daxin Jiang; Xueliang Zhao; Dongyan Zhao; Rui Yan",
        "authorids": "",
        "aff": "Peking University, Beijing, China; Microsoft Corporation, Beijing, China; Microsoft Corporation, Beijing, China; Peking University, Beijing, China; Peking University, Beijing, China; Peking University, Beijing, China Beijing Academy of Artificial Intelligence, Beijing, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17666/17666-13-21160-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14158-learning-an-effective-context-response-matching-model-with-self-supervised-tasks-for-retrieval-based-dialogues/",
        "doi": "10.1609/aaai.v35i16.17666",
        "pdf_size": 336479
    },
    {
        "id": "04959",
        "title": "Learning by Fixing: Solving Math Word Problems with Weak Supervision",
        "track": "main",
        "status": "Poster",
        "abstract": "Previous neural solvers of math word problems (MWPs) are learned with full supervision and fail to generate diverse solutions. In this paper, we address this issue by introducing a weakly-supervised paradigm for learning MWPs. Our method only requires the annotations of the final answers and can generate various solutions for a single problem. To boost weakly-supervised learning, we propose a novel learning-by-fixing (LBF) framework, which corrects the misperceptions of the neural network via symbolic reasoning. Specifically, for an incorrect solution tree generated by the neural network, the fixing mechanism propagates the error from the root node to the leaf nodes and infers the most probable fix that can be executed to get the desired answer. To generate more diverse solutions, tree regularization is applied to guide the efficient shrinkage and exploration of the solution space, and a memory buffer is designed to track and save the discovered various fixes for each problem. Experimental results on the Math23K dataset show the proposed LBF framework significantly outperforms reinforcement learning baselines in weakly-supervised learning. Furthermore, it achieves comparable top-1 and much better top-3/5 answer accuracies than fully-supervised methods, demonstrating its strength in producing diverse solutions.",
        "primary_area": "Neuro-Symbolic AI",
        "author": "Yining Hong; Qing Li; Daniel Ciao; Siyuan Huang; Song-Chun Zhu",
        "authorids": "",
        "aff": "University of California, Los Angeles; University of California, Los Angeles; University of California, Los Angeles; University of California, Los Angeles; University of California, Los Angeles",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16629/16629-13-20123-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04959-learning-by-fixing-solving-math-word-problems-with-weak-supervision/",
        "doi": "10.1609/aaai.v35i6.16629",
        "pdf_size": 416641
    },
    {
        "id": "05832",
        "title": "Learning from Crowds by Modeling Common Confusions",
        "track": "main",
        "status": "Poster",
        "abstract": "Crowdsourcing provides a practical way to obtain large amounts of labeled data at a low cost. However, the annotation quality of annotators varies considerably, which imposes new challenges in learning a high-quality model from the crowdsourced annotations. In this work, we provide a new perspective to decompose annotation noise into common noise and individual noise and differentiate the source of confusion based on instance difficulty and annotator expertise on a per-instance-annotator basis. We realize this new crowdsourcing model by an end-to-end learning solution with two types of noise adaptation layers: one is shared across annotators to capture their commonly shared confusions, and the other one is pertaining to each annotator to realize individual confusion. To recognize the source of noise in each annotation, we use an auxiliary network to choose from the two noise adaptation layers with respect to both instances and annotators. Extensive experiments on both synthesized and real-world benchmarks demonstrate the effectiveness of our proposed common noise adaptation solution.",
        "primary_area": "Human-Computation and Crowd Sourcing",
        "author": "Zhendong Chu; Jing Ma; Hongning Wang",
        "authorids": "",
        "aff": "University of Virginia; University of Virginia; University of Virginia",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16730/16730-13-20224-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05832-learning-from-crowds-by-modeling-common-confusions/",
        "doi": "10.1609/aaai.v35i7.16730",
        "pdf_size": 1810340
    },
    {
        "id": "04732",
        "title": "Learning from History: Modeling Temporal Knowledge Graphs with Sequential Copy-Generation Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Large knowledge graphs often grow to store temporal facts that model the dynamic relations or interactions of entities along the timeline. Since such temporal knowledge graphs often suffer from incompleteness, it is important to develop time-aware representation learning models that help to infer the missing temporal facts. While the temporal facts are typically evolving, it is observed that many facts often show a repeated pattern along the timeline, such as economic crises and diplomatic activities. This observation indicates that a model could potentially learn much from the known facts appeared in history. To this end, we propose a new representation learning model for temporal knowledge graphs, namely CyGNet, based on a novel time-aware copy-generation mechanism. CyGNet is not only able to predict future facts from the whole entity vocabulary, but also capable of identifying facts with repetition and accordingly predicting such future facts with reference to the known facts in the past. We evaluate the proposed method on the knowledge graph completion task using five benchmark datasets. Extensive experiments demonstrate the effectiveness of CyGNet for predicting future facts with repetition as well as de novo fact prediction.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Cunchao Zhu; Muhao Chen; Changjun Fan; Guangquan Cheng; Yan Zhang",
        "authorids": "",
        "aff": "National University of Defense Technology; University of Southern California; National University of Defense Technology; National University of Defense Technology; \u00c9cole Pour l'Informatique et les Techniques Avanc\u00e9es",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16604/16604-13-20098-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04732-learning-from-history-modeling-temporal-knowledge-graphs-with-sequential-copy-generation-networks/",
        "doi": "10.1609/aaai.v35i5.16604",
        "pdf_size": 952446
    },
    {
        "id": "13907",
        "title": "Learning from My Friends: Few-Shot Personalized Conversation Systems via Social Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Personalized conversation models (PCMs) generate responses according to speaker preferences. Existing personalized conversation tasks typically require models to extract speaker preferences from user descriptions or their conversation histories, which are scarce for newcomers and inactive users. In this paper, we propose a few-shot personalized conversation task with an auxiliary social network. The task requires models to generate personalized responses for a speaker given a few conversations from the speaker and a social network. Existing methods are mainly designed to incorporate descriptions or conversation histories. Those methods can hardly model speakers with so few conversations or connections between speakers. To better cater for newcomers with few resources, we propose a personalized conversation model (PCM) that learns to adapt to new speakers as well as enabling new speakers to learn from resource-rich speakers. Particularly, based on a meta-learning based PCM, we propose a task aggregator (TA) to collect other speakers' information from the social network. The TA provides prior knowledge of the new speaker in its meta-learning. Experimental results show our methods outperform all baselines in appropriateness, diversity, and consistency with speakers.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Zhiliang Tian; Wei Bi; Zihan Zhang; Dongkyu Lee; Yiping Song; Nevin L. Zhang",
        "authorids": "",
        "aff": "Hong Kong University of Science and Technology HKUST Xiao-i Robot Joint Lab; Tencent AI Lab; Hong Kong University of Science and Technology; Hong Kong University of Science and Technology; National University of Defense Science and Technology; Hong Kong University of Science and Technology HKUST Xiao-i Robot Joint Lab",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17638/17638-13-21132-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13907-learning-from-my-friends-few-shot-personalized-conversation-systems-via-social-networks/",
        "doi": "10.1609/aaai.v35i15.17638",
        "pdf_size": 373229
    },
    {
        "id": "10111",
        "title": "Learning from Noisy Labels with Complementary Loss Functions",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent researches reveal that deep neural networks are sensitive to label noises hence leading to poor generalization performance in some tasks. Although different robust loss functions have been proposed to remedy this issue, they suffer from an underfitting problem, thus are not sufficient to learn accurate models. On the other hand, the commonly used Cross Entropy (CE) loss, which shows high performance in standard supervised learning (with clean supervision), is non-robust to label noise. In this paper, we propose a general framework to learn robust deep neural networks with complementary loss functions. In our framework, CE and robust loss play complementary roles in a joint learning objective as per their learning sufficiency and robustness properties respectively. Specifically, we find that by exploiting the memorization effect of neural networks, we can easily filter out a proportion of hard samples and generate reliable pseudo labels for easy samples, and thus reduce the label noise to a quite low level. Then, we simply learn with CE on pseudo supervision and robust loss on original noisy supervision. In this procedure, CE can guarantee the sufficiency of optimization while the robust loss can be regarded as the supplement. Experimental results on benchmark classification datasets indicate that the proposed method helps achieve robust and sufficient deep neural network training simultaneously.",
        "primary_area": "Machine Learning IV",
        "author": "Deng-Bao Wang; Yong Wen; Lujia Pan; Min-Ling Zhang",
        "authorids": "",
        "aff": "Southeast University Key Laboratory of Computer Network and Information Integration (Southeast University), Ministry of Education; Noah\u2019s Ark Lab, Huawei Technologies; Noah\u2019s Ark Lab, Huawei Technologies NSKEYLAB, Xi\u2019an Jiaotong University; Southeast University Key Laboratory of Computer Network and Information Integration (Southeast University), Ministry of Education Collaborative Innovation Center of Wireless Communications Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17213/17213-13-20707-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10111-learning-from-noisy-labels-with-complementary-loss-functions/",
        "doi": "10.1609/aaai.v35i11.17213",
        "pdf_size": 506539
    },
    {
        "id": "08732",
        "title": "Learning from eXtreme Bandit Feedback",
        "track": "main",
        "status": "Poster",
        "abstract": "We study the problem of batch learning from bandit feedback in the setting of extremely large action spaces. Learning from extreme bandit feedback is ubiquitous in recommendation systems, in which billions of decisions are made over sets consisting of millions of choices in a single day, yielding massive observational data. In these large-scale real-world applications, supervised learning frameworks such as eXtreme Multi-label Classification (XMC) are widely used despite the fact that they incur significant biases due to the mismatch between bandit feedback and supervised labels. Such biases can be mitigated by importance sampling techniques, but these techniques suffer from impractical variance when dealing with a large number of actions.  In this paper, we introduce a selective importance sampling estimator (sIS) that operates in a significantly more favorable bias-variance regime. The sIS estimator is obtained by performing importance sampling on the conditional expectation of the reward with respect to a small subset of actions for each instance (a form of Rao-Blackwellization). We employ this estimator in a novel algorithmic procedure---named Policy Optimization for eXtreme Models (POXM)---for learning from bandit feedback on XMC tasks. In POXM, the selected actions for the sIS estimator are the top-p actions of the logging policy, where p is adjusted from the data and is significantly smaller than the size of the action space.  We use a supervised-to-bandit conversion on three XMC datasets to benchmark our POXM method against three competing methods: BanditNet, a previously applied partial matching pruning strategy, and a supervised learning baseline. Whereas BanditNet sometimes improves marginally over the logging policy, our experiments show that POXM systematically and significantly improves over all baselines.",
        "primary_area": "Machine Learning III",
        "author": "Romain Lopez; Inderjit S. Dhillon; Michael I. Jordan",
        "authorids": "",
        "aff": "University of California, Berkeley; The University of Texas at Austin Amazon.com; University of California, Berkeley Amazon.com",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17058/17058-13-20552-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08732-learning-from-extreme-bandit-feedback/",
        "doi": "10.1609/aaai.v35i10.17058",
        "pdf_size": 490369
    },
    {
        "id": "13771",
        "title": "Learning from the Best: Rationalizing Predictions by Adversarial Information Calibration",
        "track": "main",
        "status": "Poster",
        "abstract": "Explaining the predictions of AI models is paramount in safety-critical applications, such as in legal or medical domains. One form of explanation for a prediction is an extractive rationale, i.e., a subset of features of an instance that lead the model to give its prediction on the instance. Previous works on generating extractive rationales usually employ a two-phase model: a selector that selects the most important features (i.e., the rationale) followed by a predictor that makes the prediction based exclusively on the selected features. One disadvantage of these works is that the main signal for learning to select features comes from the comparison of the final answers given by the predictor and the ground-truth answers. In this work, we propose to squeeze more information from the predictor via an information calibration method. More precisely, we train two models jointly: one is a typical neural model that solves the task at hand in an accurate but black-box manner, and the other is a selector-predictor model that additionally produces a rationale for its prediction. The first model is used as a guide to the second model. We use an adversarial-based technique to calibrate the information extracted by the two models such that the difference between them is an indicator of the missed or over-selected features. In addition, for natural language tasks, we propose to use a language-model-based regularizer to encourage the extraction of fluent rationales. Experimental results on a sentiment analysis task as well as on three tasks from the legal domain show the effectiveness of our approach to rationale extraction.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Lei Sha; Oana-Maria Camburu; Thomas Lukasiewicz",
        "authorids": "",
        "aff": "University of Oxford; University of Oxford Alan Turing Institute; University of Oxford Alan Turing Institute",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17623/17623-13-21117-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13771-learning-from-the-best-rationalizing-predictions-by-adversarial-information-calibration/",
        "doi": "10.1609/aaai.v35i15.17623",
        "pdf_size": 393915
    },
    {
        "id": "09170",
        "title": "Learning of Structurally Unambiguous Probabilistic Grammars",
        "track": "main",
        "status": "Poster",
        "abstract": "The problem of identifying a probabilistic context free grammar has two aspects: the first is determining the grammar's topology (the rules of the grammar) and the second is estimating probabilistic weights for each rule. Given the hardness results for learning context-free grammars in general, and probabilistic grammars in particular, most of the literature has concentrated on the second problem. In this work we address the first problem.  We restrict attention to structurally unambiguous weighted context-free grammars (SUWCFG) and provide a query learning algorithm for strucuturally unambiguous probabilistic context-free grammars  (SUPCFG). We show that SUWCFG can be represented using co-linear multiplicity tree automata (CMTA), and provide a polynomial learning algorithm that learns CMTAs.  We show that the learned CMTA can be converted into a probabilistic grammar, thus providing  a complete algorithm for learning  a strucutrally unambiguous probabilistic context free grammar (both the grammar topology and the probabilistic weights) using structured membership queries and structured equivalence queries. We demonstrate the usefulness of our algorithm in learning PCFGs over genomic data.",
        "primary_area": "Machine Learning III",
        "author": "Dolav Nitay; Dana Fisman; Michal Ziv-Ukelson",
        "authorids": "",
        "aff": "Ben Gurion University; Ben Gurion University; Ben Gurion University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17107/17107-13-20601-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09170-learning-of-structurally-unambiguous-probabilistic-grammars/",
        "doi": "10.1609/aaai.v35i10.17107",
        "pdf_size": 279351
    },
    {
        "id": "12190",
        "title": "Learning the Parameters of Bayesian Networks from Uncertain Data",
        "track": "main",
        "status": "Poster",
        "abstract": "The creation of Bayesian networks often requires the specification of a large number of parameters, making it highly desirable to be able to learn these parameters from historical data. In many cases, such data has uncertainty associated with it, including cases in which this data comes from unstructured analysis or from sensors. When creating diagnosis networks, for example, unstructured analysis algorithms can be run on the historical text descriptions or images of previous cases so as to extract data for learning Bayesian network parameters, but such derived data has inherent uncertainty associated with it due to the nature of such algorithms.  Because of the inability of current Bayesian network parameter learning algorithms to incorporate such uncertainty, common approaches either ignore this uncertainty, thus reducing the resulting accuracy, or completely disregard such data. We present an approach for learning Bayesian network parameters that explicitly incorporates such uncertainty, and which is a natural extension of the Bayesian network formalism.  We present a generalization of the Expectation Maximization parameter learning algorithm that enables it to handle any historical data with likelihood-evidence-based uncertainty, as well as an empirical validation demonstrating the improved accuracy and convergence enabled by our approach. We also prove that our extended algorithm maintains the convergence and correctness properties of the original EM algorithm, while explicitly incorporating data uncertainty in the learning process.",
        "primary_area": "Reasoning under Uncertainty",
        "author": "Segev Wasserkrug; Radu Marinescu; Sergey Zeltyn; Evgeny Shindin; Yishai A Feldman",
        "authorids": "",
        "aff": "IBM Research - Haifa; IBM Research Europe; IBM Research - Haifa; IBM Research - Haifa; IBM Research - Haifa",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17447/17447-13-20941-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12190-learning-the-parameters-of-bayesian-networks-from-uncertain-data/",
        "doi": "10.1609/aaai.v35i13.17447",
        "pdf_size": 202240
    },
    {
        "id": "03128",
        "title": "Learning to Attack Real-World Models for Person Re-identification via Virtual-Guided Meta-Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent advances in person re-identification (re-ID) have led to impressive retrieval accuracy. However, existing re-ID models are challenged by the adversarial examples crafted by adding quasi-imperceptible perturbations. Moreover, re-ID systems face the domain shift issue that training and testing domains are not consistent. In this study, we argue that learning powerful attackers with high universality that works well on unseen domains is an important step in promoting the robustness of re-ID systems. Therefore, we introduce a novel universal attack algorithm called ``MetaAttack'' for person re-ID. MetaAttack can mislead re-ID models on unseen domains by a universal adversarial perturbation. Specifically, to capture common patterns across different domains, we propose a meta-learning scheme to seek the universal perturbation via the gradient interaction between meta-train and meta-test formed by two datasets. We also take advantage of a virtual dataset (PersonX), instead of real ones, to conduct meta-test. This scheme not only enables us to learn with more comprehensive variation factors but also mitigates the negative effects caused by biased factors of real datasets. Experiments on three large-scale re-ID datasets demonstrate the effectiveness of our method in attacking re-ID models on unseen domains. Our final visualization results reveal some new properties of existing re-ID systems, which can guide us in designing a more robust re-ID model. Code and supplemental material are available at url{https://github.com/FlyingRoastDuck/MetaAttack_AAAI21}.",
        "primary_area": "Computer Vision III",
        "author": "Fengxiang Yang; Zhun Zhong; Hong Liu; Zheng Wang; Zhiming Luo; Shaozi Li; Nicu Sebe; Shin'ichi Satoh",
        "authorids": "",
        "aff": "Xiamen University; University of Trento; National Institute of Informatics; National Institute of Informatics; Xiamen University; Xiamen University; University of Trento Huawei Research; National Institute of Informatics",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16422/16422-13-19916-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03128-learning-to-attack-real-world-models-for-person-re-identification-via-virtual-guided-meta-learning/",
        "doi": "10.1609/aaai.v35i4.16422",
        "pdf_size": 4354305
    },
    {
        "id": "07422",
        "title": "Learning to Augment for Data-scarce Domain BERT Knowledge Distillation",
        "track": "main",
        "status": "Poster",
        "abstract": "Despite pre-trained language models such as BERT have achieved appealing performance in a wide range of Natural Language Processing (NLP) tasks, they are computationally expensive to be deployed in real-time applications. A typical method is to adopt knowledge distillation to compress these large pre-trained models (teacher models) to small student models. However, for a target domain with scarce training data, the teacher can hardly pass useful knowledge to the student, which yields performance degradation for the student models. To tackle this problem, we propose a method to learn to augment data for BERT Knowledge Distillation in target domains with scarce labeled data, by learning a cross-domain manipulation scheme that automatically augments the target domain with the help of resource-rich source domains. Specifically, the proposed method generates samples acquired from a stationary distribution near the target data and adopts a reinforced controller to automatically refine the augmentation strategy according to the performance of the student. Extensive experiments demonstrate that the proposed method significantly outperforms state-of-the-art baselines on different NLP tasks, and for the data-scarce domains, the compressed student models even perform better than the original large teacher model, with much fewer parameters (only ~13.3%) when only a few labeled examples available.",
        "primary_area": "Machine Learning I",
        "author": "Lingyun Feng; Minghui Qiu; Yaliang Li; Hai-Tao Zheng; Ying Shen",
        "authorids": "",
        "aff": "Tsinghua University; Alibaba Group; Alibaba Group; Tsinghua University; Sun Yat-Sen University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16910/16910-13-20404-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07422-learning-to-augment-for-data-scarce-domain-bert-knowledge-distillation/",
        "doi": "10.1609/aaai.v35i8.16910",
        "pdf_size": 637927
    },
    {
        "id": "07331",
        "title": "Learning to Cascade: Confidence Calibration for Improving the Accuracy and Computational Cost of Cascade Inference Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "Recently, deep neural networks have become to be used in a variety of applications. While the accuracy of deep neural networks is increasing, the confidence score, which indicates the reliability of the prediction results, is becoming more important. Deep neural networks are seen as highly accurate but known to be overconfident, making it important to calibrate the confidence score. Many studies have been conducted on confidence calibration. They calibrate the confidence score of the model to match its accuracy, but it is not clear whether these confidence scores can improve the performance of systems that use confidence scores. This paper focuses on cascade inference systems, one kind of systems using confidence scores, and discusses the desired confidence score to improve system performance in terms of inference accuracy and computational cost. Based on the discussion, we propose a new confidence calibration method, Learning to Cascade. Learning to Cascade is a simple but novel method that optimizes the loss term for confidence calibration simultaneously with the original loss term. Experiments are conducted using two datasets, CIFAR-100 and ImageNet, in two system settings, and show that naive application of existing calibration methods to cascade inference systems sometimes performs worse. However, Learning to Cascade always achieves a better trade-off between inference accuracy and computational cost. The simplicity of Learning to Cascade allows it to be easily applied to improve the performance of existing systems.",
        "primary_area": "Machine Learning I",
        "author": "Shohei Enomoro; Takeharu Eda",
        "authorids": "",
        "aff": "NTT Software Innovation Center; NTT Software Innovation Center",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16900/16900-13-20394-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07331-learning-to-cascade-confidence-calibration-for-improving-the-accuracy-and-computational-cost-of-cascade-inference-systems/",
        "doi": "10.1609/aaai.v35i8.16900",
        "pdf_size": 374744
    },
    {
        "id": "14446",
        "title": "Learning to Check Contract Inconsistencies",
        "track": "main",
        "status": "Poster",
        "abstract": "Contract consistency is important in ensuring the legal validity of the contract. In many scenarios, a contract is written by filling the blanks in a precompiled form. Due to carelessness, two blanks that should be filled with the same (or different) content may be incorrectly filled with different (or same) content. This will result in the issue of contract inconsistencies, which may severely impair the legal validity of the contract. Traditional methods to address this issue mainly rely on manual contract review, which is labor-intensive and costly. In this work, we formulate a novel Contract Inconsistency Checking (CIC) problem, and design an end-to-end framework, called Pair-wise Blank Resolution (PBR), to solve the CIC problem with high accuracy. Our PBR model contains a novel BlankCoder to address the challenge of modeling meaningless blanks. BlankCoder adopts a two-stage attention mechanism that adequately associates a meaningless blank with its relevant descriptions while avoiding the incorporation of irrelevant context words. Experiments conducted on real-world datasets show the promising performance of our method with a balanced accuracy of 94.05% and an F1 score of 90.90% in the CIC problem.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Shuo Zhang; Junzhou Zhao; Pinghui Wang; Nuo Xu; Yang Yang; Yiting Liu; Yi Huang; Junlan Feng",
        "authorids": "",
        "aff": "Xi'an Jiaotong University; Xi'an Jiaotong University; Xi'an Jiaotong University; Xi'an Jiaotong University; Xi\u2019an Jiaotong University; Xi'an Jiaotong University; China Mobile Research; China Mobile Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17698/17698-13-21192-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14446-learning-to-check-contract-inconsistencies/",
        "doi": "10.1609/aaai.v35i16.17698",
        "pdf_size": 762283
    },
    {
        "id": "12535",
        "title": "Learning to Copy Coherent Knowledge for Response Generation",
        "track": "main",
        "status": "Poster",
        "abstract": "Knowledge-driven dialog has shown remarkable performance to alleviate the problem of generating uninformative responses in the dialog system. However, incorporating knowledge coherently and accurately into response generation is still far from being solved. Previous works dropped into the paradigm of non-goal-oriented knowledge-driven dialog, they are prone to ignore the effect of dialog goal, which has potential impacts on knowledge exploitation and response generation. To address this problem, this paper proposes a Goal-Oriented Knowledge Copy network, GOKC. Specifically, a goal-oriented knowledge discernment mechanism is designed to help the model discern the knowledge facts that are highly correlated to the dialog goal and the dialog context. Besides, a context manager is devised to copy facts not only from the discerned knowledge but also from the dialog goal and the dialog context, which allows the model to accurately restate the facts in the generated response. The empirical studies are conducted on two benchmarks of goal-oriented knowledge-driven dialog generation. The results show that our model can significantly outperform several state-of-the-art models in terms of both automatic evaluation and human judgments.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Jiaqi Bai; Ze Yang; Xinnian Liang; Wei Wang; Zhoujun Li",
        "authorids": "",
        "aff": "School of Cyber Science and Technology, Beihang University, Beijing, China; State Key Lab of Software Development Environment, Beihang University, Beijing, China; State Key Lab of Software Development Environment, Beihang University, Beijing, China; China Resources Group, Shenzhen, China; School of Cyber Science and Technology, Beihang University, Beijing, China State Key Lab of Software Development Environment, Beihang University, Beijing, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17486/17486-13-20980-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12535-learning-to-copy-coherent-knowledge-for-response-generation/",
        "doi": "10.1609/aaai.v35i14.17486",
        "pdf_size": 538453
    },
    {
        "id": "02319",
        "title": "Learning to Count via Unbalanced Optimal Transport",
        "track": "main",
        "status": "Poster",
        "abstract": "Counting dense crowds through computer vision technology has attracted widespread attention. Most crowd counting datasets use point annotations. In this paper, we formulate crowd counting as a measure regression problem to minimize the distance between two measures with different supports and unequal total mass. Specifically, we adopt the unbalanced optimal transport distance, which remains stable under spatial perturbations, to quantify the discrepancy between predicted density maps and point annotations. An efficient optimization algorithm based on the regularized semi-dual formulation of UOT is introduced, which alternatively learns the optimal transportation and optimizes the density regressor. The quantitative and qualitative results illustrate that our method achieves state-of-the-art counting and localization performance.",
        "primary_area": "Computer Vision II",
        "author": "Zhiheng Ma; Xing Wei; Xiaopeng Hong; Hui Lin; Yunfeng Qiu; Yihong Gong",
        "authorids": "",
        "aff": "Xi'an Jiaotong University; Xi'an Jiaotong University; Xi'an Jiaotong University Peng Cheng Laboratory; Xi\u2019an Jiaotong University; Xi'an Jiaotong University; Xi'an Jiaotong University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16332/16332-13-19826-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02319-learning-to-count-via-unbalanced-optimal-transport/",
        "doi": "10.1609/aaai.v35i3.16332",
        "pdf_size": 20189092
    },
    {
        "id": "04276",
        "title": "Learning to Pre-train Graph Neural Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Graph neural networks (GNNs) have become the defacto standard for representation learning on graphs, which derive effective node representations by recursively aggregating information from graph neighborhoods.  While GNNs can be trained from scratch, pre-training GNNs to learn transferable knowledge for downstream tasks has recently been demonstrated to improve the state of the art.  However, conventional GNN pre-training methods follow a two-step paradigm: 1) pre-training on abundant unlabeled data and 2) fine-tuning on downstream labeled data, between which there exists a significant gap due to the divergence of optimization objectives in the two steps.  In this paper, we conduct an analysis to show the divergence between pre-training and fine-tuning, and to alleviate such divergence, we propose L2P-GNN, a self-supervised pre-training strategy for GNNs.  The key insight is that L2P-GNN attempts to learn how to fine-tune during the pre-training process in the form of transferable prior knowledge. To encode both local and global information into the prior, L2P-GNN is further designed with a dual adaptation mechanism at both node and graph levels.  Finally, we conduct a systematic empirical study on the pre-training of various GNN models, using both a public collection of protein graphs and a new compilation of bibliographic graphs for pre-training. Experimental results show that L2P-GNN is capable of learning effective and transferable prior knowledge that yields powerful representations for downstream tasks.  (Code and datasets are available at https://github.com/rootlu/L2P-GNN.)",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Yuanfu Lu; Xunqiang Jiang; Yuan Fang; Chuan Shi",
        "authorids": "",
        "aff": "Beijing University of Posts and Telecommunications WeChat Search Application Department, Tencent Inc. China; Beijing University of Posts and Telecommunications; Singapore Management University; Beijing University of Posts and Telecommunications Peng Cheng Laboratory, Shenzhen, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16552/16552-13-20046-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04276-learning-to-pre-train-graph-neural-networks/",
        "doi": "10.1609/aaai.v35i5.16552",
        "pdf_size": 799123
    },
    {
        "id": "10388",
        "title": "Learning to Purify Noisy Labels via Meta Soft Label Corrector",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent deep neural networks (DNNs) can easily overfit to biased training data with noisy labels. Label correction strategy is commonly used to alleviate this issue by identifying suspected noisy labels and then correcting them. Current approaches to correcting corrupted labels usually need manually pre-defined label correction rules, which makes it hard to apply in practice due to the large variations of such manual strategies with respect to different problems. To address this issue, we propose a meta-learning model, aiming at attaining an automatic scheme which can estimate soft labels through meta-gradient descent step under the guidance of a small amount of noise-free meta data. By viewing the label correction procedure as a meta-process and using a meta-learner to automatically correct labels, our method can adaptively obtain rectified soft labels gradually in iteration according to current training problems. Besides, our method is model-agnostic and can be combined with any other existing classification models with ease to make it available to noisy label cases. Comprehensive experiments substantiate the superiority of our method in both synthetic and real-world problems with noisy labels compared with current state-of-the-art label correction strategies.",
        "primary_area": "Machine Learning V",
        "author": "Yichen Wu; Jun Shu; Qi Xie; Qian Zhao; Deyu Meng",
        "authorids": "",
        "aff": "Xi'an Jiaotong University, Shaanxi, China; Xi'an Jiaotong University, Shaanxi, China; Xi'an Jiaotong University, Shaanxi, China; Xi'an Jiaotong University, Shaanxi, China; Xi'an Jiaotong University, Shaanxi, China Pazhou Lab, Guangzhou, 510330, China Macau University of Science and Technology, Macau, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17244/17244-13-20738-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10388-learning-to-purify-noisy-labels-via-meta-soft-label-corrector/",
        "doi": "10.1609/aaai.v35i12.17244",
        "pdf_size": 643755
    },
    {
        "id": "12592",
        "title": "Learning to Rationalize for Nonmonotonic Reasoning with Distant Supervision",
        "track": "main",
        "status": "Poster",
        "abstract": "The black-box nature of neural models has motivated a line of research that aims to generate natural language rationales to explain why a model made certain predictions. Such rationale generation models, to date, have been trained on dataset-specific crowdsourced rationales, but this approach is costly and is not generalizable to new tasks and domains. In this paper, we investigate the extent to which neural models can reason about natural language rationales that explain model predictions, relying only on distant supervision with no additional annotation cost for human-written rationales. We investigate multiple ways to automatically generate rationales using pre-trained language models, neural knowledge models, and distant supervision from related tasks, and train generative models capable of composing explanatory rationales for unseen instances. We demonstrate our approach on the defeasible inference task, a nonmonotonic reasoning task in which an inference may be strengthened or weakened when new information (an update) is introduced. Our model shows promises at generating post-hoc rationales explaining why an inference is more or less likely given the additional information, however, it mostly generates trivial rationales reflecting the fundamental limitations of neural language models. Conversely, the more realistic setup of jointly predicting the update or its type and generating rationale is more challenging, suggesting an important future direction.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Faeze Brahman; Vered Shwartz; Rachel Rudinger; Yejin Choi",
        "authorids": "",
        "aff": "University of California, Santa Cruz; Allen Institute for AI Paul G. Allen School of Computer Science & Engineering, University of Washington; University of Maryland, College Park, MD; Allen Institute for AI Paul G. Allen School of Computer Science & Engineering, University of Washington",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17492/17492-13-20986-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12592-learning-to-rationalize-for-nonmonotonic-reasoning-with-distant-supervision/",
        "doi": "10.1609/aaai.v35i14.17492",
        "pdf_size": 832087
    },
    {
        "id": "04436",
        "title": "Learning to Recommend from Sparse Data via Generative User Feedback",
        "track": "main",
        "status": "Poster",
        "abstract": "Traditional collaborative filtering (CF) based recommender systems tend to perform poorly when the user-item interactions/ratings are highly scarce. To address this, we propose a learning framework that improves collaborative filtering with a synthetic feedback loop (CF-SFL) to simulate the user feedback. The proposed framework consists of a recommender and a virtual user. The recommender is formulated as a CF model, recommending items according to observed user preference. The virtual user estimates rewards from the recommended items and generates a feedback in addition to the observed user preference. The recommender connected with the virtual user constructs a closed loop, that recommends users with items and imitates the unobserved feedback of the users to the recommended items. The synthetic feedback is used to augment the observed user preference and improve recommendation results. Theoretically, such model design can be interpreted as inverse reinforcement learning, which can be learned effectively via rollout (simulation). Experimental results show that the proposed framework is able to enrich the learning of user preference and boost the performance of existing collaborative filtering methods on multiple datasets.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Wenlin Wang",
        "authorids": "",
        "aff": "Duke University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16570/16570-13-20064-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04436-learning-to-recommend-from-sparse-data-via-generative-user-feedback/",
        "doi": "10.1609/aaai.v35i5.16570",
        "pdf_size": 546719
    },
    {
        "id": "11246",
        "title": "Learning to Resolve Conflicts for Multi-Agent Path Finding with Conflict-Based Search",
        "track": "main",
        "status": "Poster",
        "abstract": "Conflict-Based Search (CBS) is a state-of-the-art algorithm for multi-agent path finding. On the high level, CBS repeatedly detects conflicts and resolves one of them by splitting the current problem into two subproblems. Previous work chooses the conflict to resolve by categorizing conflicts into three classes and always picking one from the highest-priority class. In this work, we propose an oracle for conflict selection that results in smaller search tree sizes than the one used in previous work. However, the computation of the oracle is slow. Thus, we propose a machine-learning (ML) framework for conflict selection that observes the decisions made by the oracle and learns a conflict-selection strategy represented by a linear ranking function that imitates the oracle's decisions accurately and quickly. Experiments on benchmark maps indicate that our approach, ML-guided CBS, significantly improves the success rates, search tree sizes and runtimes of the current state-of-the-art CBS solver.",
        "primary_area": "Multiagent Systems",
        "author": "Taoan Huang; Sven Koenig; Bistra Dilkina",
        "authorids": "",
        "aff": "University of Southern California; University of Southern California; University of Southern California",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17341/17341-13-20835-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11246-learning-to-resolve-conflicts-for-multi-agent-path-finding-with-conflict-based-search/",
        "doi": "10.1609/aaai.v35i13.17341",
        "pdf_size": 3553655
    },
    {
        "id": "07848",
        "title": "Learning to Reweight Imaginary Transitions for Model-Based Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Model-based reinforcement learning (RL) is more sample efficient than model-free RL by using imaginary trajectories generated by the learned dynamics model. When the model is inaccurate or biased, imaginary trajectories may be deleterious for training the action-value and policy functions. To alleviate such problem, this paper proposes to adaptively reweight the imaginary transitions, so as to reduce the negative effects of poorly generated trajectories. More specifically, we evaluate the effect of an imaginary transition by calculating the change of the loss computed on the real samples when we use the transition to train the action-value and policy functions. Based on this evaluation criterion, we construct the idea of reweighting each imaginary transition by a well-designed meta-gradient algorithm. Extensive experimental results demonstrate that our method outperforms state-of-the-art model-based and model-free RL algorithms on multiple tasks. Visualization of our changing weights further validates the necessity of utilizing reweight scheme.",
        "primary_area": "Machine Learning II",
        "author": "Wenzhen Huang; Qiyue Yin; Junge Zhang; Kaiqi Huang",
        "authorids": "",
        "aff": "School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China CRISE, Institute of Automation, Chinese Academy of Sciences, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China CRISE, Institute of Automation, Chinese Academy of Sciences, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China CRISE, Institute of Automation, Chinese Academy of Sciences, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China CRISE, Institute of Automation, Chinese Academy of Sciences, Beijing, China CAS Center for Excellence in Brain Science and Intelligence Technology, Beijing, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16958/16958-13-20452-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07848-learning-to-reweight-imaginary-transitions-for-model-based-reinforcement-learning/",
        "doi": "10.1609/aaai.v35i9.16958",
        "pdf_size": 5522606
    },
    {
        "id": "07385",
        "title": "Learning to Reweight with Deep Interactions",
        "track": "main",
        "status": "Poster",
        "abstract": "Recently the concept of teaching has been introduced into machine learning, in which a teacher model is used to guide the training of a student model (which will be used in real tasks) through  data selection, loss function design, etc. Learning to reweight, which is a specific kind of teaching that reweights training data using a teacher model, receives much attention due to its simplicity and effectiveness. In existing learning to reweight works, the teacher model only utilizes shallow/surface information such as training iteration number and loss/accuracy of the student model from training/validation sets, but ignores the internal states of the student model, which limits the potential of learning to reweight. In this work, we propose an improved data reweighting algorithm, in which the student model provides its internal states to the teacher model, and the teacher model returns adaptive weights of training samples to enhance the training of the student model. The teacher model is jointly trained with the student model using meta gradients propagated from a validation set. Experiments on image classification with clean/noisy labels and neural machine translation empirically demonstrate that our algorithm makes significant improvement over previous methods.",
        "primary_area": "Machine Learning I",
        "author": "Yang Fan; Yingce Xia; Lijun Wu; Shufang Xie; Weiqing Liu; Jiang Bian; Tao Qin; Xiang-Yang Li",
        "authorids": "",
        "aff": "University of Science and Technology of China; Microsoft Research Asia; Microsoft Research Asia; Microsoft Research Asia; Microsoft Research Asia; Microsoft Research Asia; Microsoft Research Asia; University of Science and Technology of China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16906/16906-13-20400-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07385-learning-to-reweight-with-deep-interactions/",
        "doi": "10.1609/aaai.v35i8.16906",
        "pdf_size": 643781
    },
    {
        "id": "05887",
        "title": "Learning to Sit: Synthesizing Human-Chair Interactions via Hierarchical Control",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent progress on physics-based character animation has shown impressive breakthroughs on human motion synthesis, through imitating motion capture data via deep reinforcement learning. However, results have mostly been demonstrated on imitating a single distinct motion pattern, and do not generalize to interactive tasks that require flexible motion patterns due to varying human-object spatial configurations. To bridge this gap, we focus on one class of interactive tasks---sitting onto a chair. We propose a hierarchical reinforcement learning framework which relies on a collection of subtask controllers trained to imitate simple, reusable mocap motions, and a meta controller trained to execute the subtasks properly to complete the main task. We experimentally demonstrate the strength of our approach over different non-hierarchical and hierarchical baselines. We also show that our approach can be applied to motion prediction given an image input. A supplementary video can be found at https://youtu.be/3CeN0OGz2cA.",
        "primary_area": "Humans and AI",
        "author": "Yu-Wei Chao; Jimei Yang; Weifeng Chen; Jia Deng",
        "authorids": "",
        "aff": "NVIDIA; Adobe; University of Michigan, Ann Arbor; Princeton University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16736/16736-13-20230-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05887-learning-to-sit-synthesizing-human-chair-interactions-via-hierarchical-control/",
        "doi": "10.1609/aaai.v35i7.16736",
        "pdf_size": 5089253
    },
    {
        "id": "00259",
        "title": "Learning to Stop: Dynamic Simulation Monte-Carlo Tree Search",
        "track": "main",
        "status": "Poster",
        "abstract": "Monte Carlo tree search (MCTS) has achieved state-of-the-art results in many domains such as Go and Atari games when combining with deep neural networks (DNNs). When more simulations are executed, MCTS can achieve higher performance but also requires enormous amounts of CPU and GPU resources. However, not all states require a long searching time to identify the best action that the agent can find. For example, in 19x19 Go and NoGo, we found that for more than half of the states, the best action predicted by DNN remains unchanged even after searching 2 minutes. This implies that a significant amount of resources can be saved if we are able to stop the searching earlier when we are confident with the current searching result. In this paper, we propose to achieve this goal by predicting the uncertainty of the current searching status and use the result to decide whether we should stop searching. With our algorithm, called Dynamic Simulation MCTS (DS-MCTS), we can speed up a NoGo agent trained by AlphaZero 2.5 times faster while maintaining a similar winning rate, which is critical for training and conducting experiments. Also, under the same average simulation count, our method can achieve a 61% winning rate against the original program.",
        "primary_area": "Application Domains",
        "author": "Li-Cheng Lan; Ti-Rong Wu; I-Chen Wu; Cho-Jui Hsieh",
        "authorids": "",
        "aff": "Department of Computer Science, UCLA; Department of Computer Science, National Chiao-Tung University, Taiwan; Department of Computer Science, National Chiao-Tung University, Taiwan Research Center for IT Innovation, Academia Sinica, Taiwan; Department of Computer Science, UCLA",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16100/16100-13-19594-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00259-learning-to-stop-dynamic-simulation-monte-carlo-tree-search/",
        "doi": "10.1609/aaai.v35i1.16100",
        "pdf_size": 493127
    },
    {
        "id": "04453",
        "title": "Learning to Truncate Ranked Lists for Information Retrieval",
        "track": "main",
        "status": "Poster",
        "abstract": "Ranked list truncation is of critical importance in a variety of professional information retrieval applications such as patent search or legal search. The goal is to dynamically determine the number of returned documents according to some user-defined objectives, in order to reach a balance between the overall utility of the results and user efforts. Existing methods formulate this task as a sequential decision problem and take some pre-defined loss as a proxy objective, which suffers from the limitation of local decision and non-direct optimization. In this work, we propose a global decision based truncation model named AttnCut, which directly optimizes user-defined objectives for the ranked list truncation. Specifically, we take the successful transformer architecture to capture the global dependency within the ranked list for truncation decision, and employ the reward augmented maximum likelihood (RAML) for direct optimization. We consider two types of user-defined objectives which are of practical usage. One is the widely adopted metric such as F1 which acts as a balanced objective, and the other is the best F1 under some minimal recall constraint which represents a typical objective in professional search. Empirical results over the Robust04 and MQ2007 datasets demonstrate the effectiveness of our approach as compared with the state-of-the-art baselines.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Chen Wu; Ruqing Zhang; Jiafeng Guo; Yixing Fan; Yanyan Lan; Xueqi Cheng",
        "authorids": "",
        "aff": "Institute of Computing Technology, Chinese Academy of Sciences; University of Chinese Academy of Sciences; Institute of Computing Technology, Chinese Academy of Sciences; University of Chinese Academy of Sciences; Institute of Computing Technology, Chinese Academy of Sciences; University of Chinese Academy of Sciences; Institute of Computing Technology, Chinese Academy of Sciences; University of Chinese Academy of Sciences; Institute of Computing Technology, Chinese Academy of Sciences; University of Chinese Academy of Sciences; Institute of Computing Technology, Chinese Academy of Sciences; University of Chinese Academy of Sciences",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16572/16572-13-20066-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04453-learning-to-truncate-ranked-lists-for-information-retrieval/",
        "doi": "10.1609/aaai.v35i5.16572",
        "pdf_size": 522454
    },
    {
        "id": "10192",
        "title": "Learning with Group Noise",
        "track": "main",
        "status": "Poster",
        "abstract": "Machine learning in the context of noise is a challenging but practical setting to plenty of real-world applications. Most of the previous approaches in this area focus on the pairwise relation (casual or correlational relationship) with noise, such as learning with noisy labels. However, the group noise, which is parasitic on the coarse-grained accurate relation with the fine-grained uncertainty, is also universal and has not been well investigated. The challenge under this setting is how to discover true pairwise connections concealed by the group relation with its fine-grained noise. To overcome this issue, we propose a novel Max-Matching method for learning with group noise. Specifically, it utilizes a matching mechanism to evaluate the relation confidence of each object w.r.t. the target, meanwhile considers the Non-IID characteristics among objects in the group. Only the most confident one of the objects is used to learn the model, so that the \ufb01ne-grained noise is mostly dropped. The performance on a range of real-world datasets in the area of several learning paradigms demonstrates the effectiveness of Max-Matching.",
        "primary_area": "Machine Learning IV",
        "author": "Qizhou Wang; Jiangchao Yao; Chen Gong; Tongliang Liu; Mingming Gong; Hongxia Yang; Bo Han",
        "authorids": "",
        "aff": "Department of Computer Science, Hong Kong Baptist University Key Laboratory of Intelligent Perception and Systems for High-Dimensional Information of MoE, School of Computer Science and Engineering, Nanjing University of Science and Technology; Data Analytics and Intelligence Lab, Alibaba Group; Key Laboratory of Intelligent Perception and Systems for High-Dimensional Information of MoE, School of Computer Science and Engineering, Nanjing University of Science and Technology Department of Computing, Hong Kong Polytechnic University; Trustworthy Machine Learning Lab, School of Computer Science, Faculty of Engineering, The University of Sydney; School of Mathematics and Statistics, The University of Melbourne; Data Analytics and Intelligence Lab, Alibaba Group; Department of Computer Science, Hong Kong Baptist University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17222/17222-13-20716-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10192-learning-with-group-noise/",
        "doi": "10.1609/aaai.v35i11.17222",
        "pdf_size": 1900112
    },
    {
        "id": "07201",
        "title": "Learning with Retrospection",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep neural networks have been successfully deployed in various domains of artificial intelligence, including computer vision and natural language processing. We observe that the current standard procedure for training DNNs discards all the learned information in the past epochs except the current learned weights. An interesting question is: is this discarded information indeed useless? We argue that the discarded information can benefit the subsequent training. In this paper, we propose learning with retrospection (LWR) which makes use of the learned information in the past epochs to guide the subsequent training. LWR is a simple yet effective training framework to improve accuracies, calibration, and robustness of DNNs without introducing any additional network parameters or inference cost, but only with a negligible training overhead. Extensive experiments on several benchmark datasets demonstrate the superiority of LWR for training DNNs.",
        "primary_area": "Machine Learning I",
        "author": "Xiang Deng; Zhongfei Zhang",
        "authorids": "",
        "aff": "State University of New York at Binghamton; State University of New York at Binghamton",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16885/16885-13-20379-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07201-learning-with-retrospection/",
        "doi": "10.1609/aaai.v35i8.16885",
        "pdf_size": 3238208
    },
    {
        "id": "07667",
        "title": "Learning with Safety Constraints: Sample Complexity of Reinforcement Learning for Constrained MDPs",
        "track": "main",
        "status": "Poster",
        "abstract": "Many physical systems have underlying safety considerations that require that the policy employed ensures the satisfaction of a set of constraints.  The analytical formulation usually takes the form of a Constrained Markov Decision Process (CMDP). We focus on the case where the CMDP is unknown, and RL algorithms obtain samples to discover the model and compute an optimal constrained policy.  Our goal is to characterize the relationship between safety constraints and the number of samples needed to ensure a desired level of accuracy---both objective maximization and constraint satisfaction---in a PAC sense.  We explore two classes of RL algorithms, namely, (i) a generative model based approach, wherein samples are taken initially to estimate a model, and (ii) an online approach, wherein the model is updated as samples are obtained.  Our main finding is that compared to the best known bounds of the unconstrained regime, the sample complexity of constrained RL algorithms are increased by a factor that is logarithmic in the number of constraints, which suggests that the approach may be easily utilized in real systems.",
        "primary_area": "Machine Learning II",
        "author": "Aria HasanzadeZonuzy; Archana Bura; Dileep Kalathil; Srinivas Shakkottai",
        "authorids": "",
        "aff": "Texas A&M University; Texas A&M University; Texas A&M University; Texas A&M University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16937/16937-13-20431-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07667-learning-with-safety-constraints-sample-complexity-of-reinforcement-learning-for-constrained-mdps/",
        "doi": "10.1609/aaai.v35i9.16937",
        "pdf_size": 368428
    },
    {
        "id": "08950",
        "title": "Lenient Regret for Multi-Armed Bandits",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider the Multi-Armed Bandit (MAB) problem, where an agent sequentially chooses actions and observes rewards for the actions it took. While the majority of algorithms try to minimize the regret, i.e., the cumulative difference between the reward of the best action and the agent's action, this criterion might lead to undesirable results. For example, in large problems, or when the interaction with the environment is brief, finding an optimal arm is infeasible, and regret-minimizing algorithms tend to over-explore. To overcome this issue, algorithms for such settings should instead focus on playing near-optimal arms. To this end, we suggest a new, more lenient, regret criterion that ignores suboptimality gaps smaller than some \u03b5. We then present a variant of the Thompson Sampling (TS) algorithm, called \u03b5-TS, and prove its asymptotic optimality in terms of the lenient regret. Importantly, we show that when the mean of the optimal arm is high enough, the lenient regret of \u03b5-TS is bounded by a constant. Finally, we show that \u03b5-TS can be applied to improve the performance when the agent knows a lower bound of the suboptimality gaps.",
        "primary_area": "Machine Learning III",
        "author": "Nadav Merlis; Shie Mannor",
        "authorids": "",
        "aff": "Technion - Israel Institute of Technology; Technion - Israel Institute of Technology Nvidia Research, Israel",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17082/17082-13-20576-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08950-lenient-regret-for-multi-armed-bandits/",
        "doi": "10.1609/aaai.v35i10.17082",
        "pdf_size": 1892128
    },
    {
        "id": "03992",
        "title": "Leveraging Table Content for Zero-shot Text-to-SQL  with Meta-Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Single-table text-to-SQL aims to transform a natural language question into a SQL query according to one single table.  Recent work has made promising progress on this task by pre-trained language models and a multi-submodule framework. However, zero-shot table, that is, the invisible table in the training set, is currently the most critical bottleneck restricting the application of existing approaches to real-world scenarios. Although some work has utilized auxiliary tasks to help handle zero-shot tables, expensive extra manual annotation limits their practicality. In this paper, we propose a new approach for the zero-shot text-to-SQL task which does not rely on any additional manual annotations. Our approach consists of two parts. First, we propose a new model that leverages the abundant information of table content to help establish the mapping between questions and zero-shot tables. Further, we propose a simple but efficient meta-learning strategy to train our model. The strategy utilizes the two-step gradient update to force the model to learn a generalization ability towards zero-shot tables. We conduct extensive experiments on a public open-domain text-to-SQL dataset WikiSQL and a domain-specific dataset ESQL. Compared to existing approaches using the same pre-trained model, our approach achieves significant improvements on both datasets. Compared to the larger pre-trained model and the tabular-specific pre-trained model, our approach is still competitive. More importantly, on the zero-shot subsets of both the datasets, our approach further increases the improvements.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Yongrui Chen; Xinnan Guo; Chaojie Wang; Jian Qiu; Guilin Qi; Meng Wang; Huiying Li",
        "authorids": "",
        "aff": "Southeast University; Southeast University; Alibaba Group; Alibaba Group; Southeast University; Southeast University; Southeast University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16519/16519-13-20013-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03992-leveraging-table-content-for-zero-shot-text-to-sql-with-meta-learning/",
        "doi": "10.1609/aaai.v35i5.16519",
        "pdf_size": 561111
    },
    {
        "id": "12630",
        "title": "Lexically Constrained Neural Machine Translation with Explicit Alignment Guidance",
        "track": "main",
        "status": "Poster",
        "abstract": "Lexically constrained neural machine translation (NMT), which leverages pre-specified translation to constrain NMT, has practical significance in interactive translation and NMT domain adaption. Previous work either modify the decoding algorithm or train the model on augmented dataset. These methods suffer from either high computational overheads or low copying success rates. In this paper, we investigate Att-Input and Att-Output, two alignment-based constrained decoding methods. These two methods revise the target tokens during decoding based on word alignments derived from encoder-decoder attention weights. Our study shows that Att-Input translates better while Att-Output is more computationally efficient. Capitalizing on both strengths, we further propose EAM-Output by introducing an explicit alignment module (EAM) to a pretrained Transformer. It decodes similarly as EAM-Output, except using alignments derived from the EAM. We leverage the word alignments induced from Att-Input as labels and train the EAM while keeping the parameters of the Transformer frozen. Experiments on WMT16 De-En and WMT16 Ro-En show the effectiveness of our approaches on constrained NMT. In particular, the proposed EAM-Output method consistently outperforms previous approaches in translation quality, with light computational overheads over unconstrained baseline.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Guanhua Chen; Yun Chen; Victor O.K. Li",
        "authorids": "",
        "aff": "The University of Hong Kong; Shanghai University of Finance and Economics; The University of Hong Kong",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17496/17496-13-20990-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12630-lexically-constrained-neural-machine-translation-with-explicit-alignment-guidance/",
        "doi": "10.1609/aaai.v35i14.17496",
        "pdf_size": 239646
    },
    {
        "id": "11272",
        "title": "Lifelong Multi-Agent Path Finding in Large-Scale Warehouses",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-Agent Path Finding (MAPF) is the problem of moving a team of agents to their goal locations without collisions. In this paper, we study the lifelong variant of MAPF, where agents are constantly engaged with new goal locations, such as in large-scale automated warehouses. We propose a new framework Rolling-Horizon Collision Resolution (RHCR) for solving lifelong MAPF by decomposing the problem into a sequence of Windowed MAPF instances, where a Windowed MAPF solver resolves collisions among the paths of the agents only within a bounded time horizon and ignores collisions beyond it. RHCR is particularly well suited to generating pliable plans that adapt to continually arriving new goal locations. We empirically evaluate RHCR with a variety of MAPF solvers and show that it can produce high-quality solutions for up to 1,000 agents (= 38.9% of the empty cells on the map) for simulated warehouse instances, significantly outperforming existing work.",
        "primary_area": "Multiagent Systems",
        "author": "Jiaoyang Li; Andrew Tinka; Scott Kiesel; Joseph W. Durham; T. K. Satish Kumar; Sven Koenig",
        "authorids": "",
        "aff": "University of Southern California; Amazon Robotics; Amazon Robotics; Amazon Robotics; University of Southern California; University of Southern California",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17344/17344-13-20838-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11272-lifelong-multi-agent-path-finding-in-large-scale-warehouses/",
        "doi": "10.1609/aaai.v35i13.17344",
        "pdf_size": 1704454
    },
    {
        "id": "07987",
        "title": "LightXML: Transformer with Dynamic Negative Sampling for High-Performance Extreme Multi-label Text Classification",
        "track": "main",
        "status": "Poster",
        "abstract": "Extreme multi-label text classification(XMC) is a task for finding the most relevant labels from a large label set. Nowadays deep learning-based methods have shown significant success in XMC. However, the existing methods (e.g., AttentionXML and X-Transformer etc) still suffer from 1) combining several models to train and predict for one dataset, and 2) sampling negative labels statically during the process of training label ranking model, which will harm the performance and accuracy of model. To address the above problems, we propose LightXML, which adopts end-to-end training and dynamical negative labels sampling. In LightXML, we use GAN like networks to recall and rank labels. The label recalling part will generate negative and positive labels, and the label ranking part will distinguish positive labels from these labels. Based on these networks, negative labels are sampled dynamically during label ranking part training. With feeding both label recalling and ranking parts with the same text representation, LightXML can reach high performance. Extensive experiments show that LightXML outperforms state-of-the-art methods in five extreme multi-label datasets with much smaller model size and lower computational complexity. In particular, on the Amazon dataset with  670K labels, LightXML can reduce the model size up to 72% compared to AttentionXML. Our code is available at http://github.com/kongds/LightXML.",
        "primary_area": "Machine Learning II",
        "author": "Ting Jiang; Deqing Wang; Leilei Sun; Huayi Yang; Zhengyang Zhao; Fuzhen Zhuang",
        "authorids": "",
        "aff": "SKLSDE and BDBC Lab, Beihang University, Beijing, China; SKLSDE and BDBC Lab, Beihang University, Beijing, China; SKLSDE and BDBC Lab, Beihang University, Beijing, China; SKLSDE and BDBC Lab, Beihang University, Beijing, China; SKLSDE and BDBC Lab, Beihang University, Beijing, China; Key Lab of Intelligent Information Processing of CAS, Institute of Computing Technology, CAS Beijing Advanced Innovation Center for Imaging Theory and Technology, Academy for Multidisciplinary Studies, Capital Normal University, Beijing, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16974/16974-13-20468-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07987-lightxml-transformer-with-dynamic-negative-sampling-for-high-performance-extreme-multi-label-text-classification/",
        "doi": "10.1609/aaai.v35i9.16974",
        "pdf_size": 271363
    },
    {
        "id": "08021",
        "title": "Linearly Replaceable Filters for Deep Network Channel Pruning",
        "track": "main",
        "status": "Poster",
        "abstract": "Convolutional neural networks (CNNs) have achieved remarkable results; however, despite the development of deep learning, practical user applications are fairly limited because heavy networks can be used solely with the latest hardware and software supports. Therefore, network pruning is gaining attention for general applications in various fields. This paper proposes a novel channel pruning method, Linearly Replaceable Filter (LRF), which suggests that a filter that can be approximated by the linear combination of other filters is replaceable. Moreover, an additional method called Weights Compensation is proposed to support the LRF method. This is a technique that effectively reduces the output difference caused by removing filters via direct weight modification. Through various experiments, we have confirmed that our method achieves state-of-the-art performance in several benchmarks. In particular, on ImageNet, LRF-60 reduces approximately 56% of FLOPs on ResNet-50 without top-5 accuracy drop. Further, through extensive analyses, we proved the effectiveness of our approaches.",
        "primary_area": "Machine Learning II",
        "author": "Donggyu Joo; Eojindl Yi; Sunghyun Baek; Junmo Kim",
        "authorids": "",
        "aff": "KAIST; KAIST; KAIST; KAIST",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16978/16978-13-20472-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08021-linearly-replaceable-filters-for-deep-network-channel-pruning/",
        "doi": "10.1609/aaai.v35i9.16978",
        "pdf_size": 366318
    },
    {
        "id": "08270",
        "title": "Lipschitz Lifelong Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider the problem of knowledge transfer when an agent is facing a series of Reinforcement Learning (RL) tasks. We introduce a novel metric between Markov Decision Processes and establish that close MDPs have close optimal value functions. Formally, the optimal value functions are Lipschitz continuous with respect to the tasks space. These theoretical results lead us to a value-transfer method for Lifelong RL, which we use to build a PAC-MDP algorithm with improved convergence rate. Further, we show the method to experience no negative transfer with high probability. We illustrate the benefits of the method in Lifelong RL experiments.",
        "primary_area": "Machine Learning II",
        "author": "Erwan Lecarpentier; David Abel; Kavosh Asadi; Yuu Jinnai; Emmanuel Rachelson; Michael L. Littman",
        "authorids": "",
        "aff": "ISAE-SUPAERO Universit\u00e9 de Toulouse ONERA - The French Aerospace Lab; Brown University; Brown University Amazon Web Service; Brown University; ISAE-SUPAERO Universit\u00e9 de Toulouse; Brown University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17006/17006-13-20500-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08270-lipschitz-lifelong-reinforcement-learning/",
        "doi": "10.1609/aaai.v35i9.17006",
        "pdf_size": 454327
    },
    {
        "id": "07657",
        "title": "Liquid Time-constant Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "We introduce a new class of time-continuous recurrent neural network models. Instead of declaring a learning system's dynamics by implicit nonlinearities, we construct networks of linear first-order dynamical systems modulated via nonlinear interlinked gates. The resulting models represent dynamical systems with varying (i.e., liquid) time-constants coupled to their hidden state, with outputs being computed by numerical differential equation solvers. These neural networks exhibit stable and bounded behavior, yield superior expressivity within the family of neural ordinary differential equations, and give rise to improved performance on time-series prediction tasks. To demonstrate these properties, we first take a theoretical approach to find bounds over their dynamics, and compute their expressive power by the trajectory length measure in a latent trajectory space. We then conduct a series of time-series prediction experiments to manifest the approximation capability of Liquid Time-Constant Networks (LTCs) compared to classical and modern RNNs.",
        "primary_area": "Machine Learning II",
        "author": "Ramin Hasani; Mathias Lechner; Alexander Amini; Daniela Rus; Radu Grosu",
        "authorids": "",
        "aff": "Massachusetts Institute of Technology (MIT) Technische Universit\u00e4t Wien (TU Wien); Institute of Science and Technology Austria (IST Austria); Massachusetts Institute of Technology (MIT); Massachusetts Institute of Technology (MIT); Technische Universit\u00e4t Wien (TU Wien)",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16936/16936-13-20430-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07657-liquid-time-constant-networks/",
        "doi": "10.1609/aaai.v35i9.16936",
        "pdf_size": 4302669
    },
    {
        "id": "12749",
        "title": "Listen, Understand and Translate: Triple Supervision Decouples End-to-end Speech-to-text Translation",
        "track": "main",
        "status": "Poster",
        "abstract": "An end-to-end speech-to-text translation (ST) takes audio in a source language and outputs the text in a target language. Existing methods are limited by the amount of parallel corpus. Can we build a system to fully utilize signals in a parallel ST corpus? We are inspired by human understanding system which is composed of auditory perception and cognitive processing. In this paper, we propose Listen-Understand-Translate, (LUT), a unified framework with triple supervision signals to decouple the end-to-end speech-to-text translation task. LUT is able to guide the acoustic encoder to extract as much information from the auditory input. In addition, LUT utilizes a pre-trained BERT model to enforce the upper encoder to produce as much semantic information as possible, without extra data. We perform experiments on a diverse set of speech translation benchmarks, including Librispeech English-French, IWSLT English-German and TED English-Chinese. Our results demonstrate LUT achieves the state-of-the-art performance, outperforming previous methods. The code is available at https://github.com/dqqcasia/st.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Qianqian Dong; Rong Ye; Mingxuan Wang; Hao Zhou; Shuang Xu; Bo Xu; Lei Li",
        "authorids": "",
        "aff": "Institute of Automation, Chinese Academy of Sciences, China School of Artificial Intelligence, University of Chinese Academy of Sciences, China; ByteDance AI Lab; ByteDance AI Lab; ByteDance AI Lab; Institute of Automation, Chinese Academy of Sciences, China; Institute of Automation, Chinese Academy of Sciences, China School of Artificial Intelligence, University of Chinese Academy of Sciences, China; ByteDance AI Lab",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17509/17509-13-21003-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12749-listen-understand-and-translate-triple-supervision-decouples-end-to-end-speech-to-text-translation/",
        "doi": "10.1609/aaai.v35i14.17509",
        "pdf_size": 1450354
    },
    {
        "id": "06193",
        "title": "Living Without Beth and Craig: Definitions and Interpolants in Description Logics with Nominals and Role Inclusions",
        "track": "main",
        "status": "Poster",
        "abstract": "The Craig interpolation property (CIP) states that an interpolant for an implication exists iff it is valid. The projective Beth definability property (PBDP) states that an explicit definition exists iff a formula stating implicit definability is valid. Thus, the CIP and PBDP transform potentially hard existence problems into deduction problems in the underlying logic. Description Logics with nominals and/or role inclusions do not enjoy the CIP nor PBDP, but interpolants and explicit definitions have many potential applications in ontology engineering and ontology-based data management. In this article we show the following: even without Craig and Beth, the existence of interpolants and explicit definitions is decidable in description logics with nominals and/or role inclusions such as ALCO, ALCH and ALCHIO. However, living without Craig and Beth makes this problem harder than deduction: we prove that the existence problems become 2EXPTIME-complete, thus one exponential harder than validity. The existence of explicit definitions is 2EXPTIME-hard even if one asks for a definition of a nominal using any symbol distinct from that nominal, but it becomes EXPTIME-complete if one asks for a definition of a concept name using any symbol distinct from that concept name.",
        "primary_area": "Knowledge Representation and Reasoning",
        "author": "Alessandro Artale; Jean Christoph Jung; Andrea Mazzullo; Ana Ozaki; Frank Wolter",
        "authorids": "",
        "aff": "Free University of Bozen-Bolzano; University of Hildesheim; Free University of Bozen-Bolzano; University of Bergen; University of Liverpool",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16770/16770-13-20264-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06193-living-without-beth-and-craig-definitions-and-interpolants-in-description-logics-with-nominals-and-role-inclusions/",
        "doi": "10.1609/aaai.v35i7.16770",
        "pdf_size": 156996
    },
    {
        "id": "11152",
        "title": "Local Differential Privacy for Bayesian Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "Motivated by the increasing concern about privacy in nowadays data-intensive online learning systems, we consider a black-box optimization in the nonparametric Gaussian process setting with local differential privacy (LDP) guarantee. Specifically, the rewards from each user are further corrupted to protect privacy and the learner only has access to the corrupted rewards to minimize the regret. We first derive the regret lower bounds for any LDP mechanism and any learning algorithm. Then, we present three almost optimal algorithms based on the GP-UCB framework and Laplace DP mechanism. In this process, we also propose a new Bayesian optimization (BO) method (called MoMA-GP-UCB) based on median-of-means techniques and kernel approximations, which complements previous BO algorithms under heavy-tailed payoffs with reduced complexity. Further, empirical comparisons of different algorithms on both synthetic and real-world datasets highlight the superior performance of MoMA-GP-UCB in both private and non-private scenarios.",
        "primary_area": "Machine Learning V",
        "author": "Xingyu Zhou; Jian Tan",
        "authorids": "",
        "aff": "The Ohio State University; Alibaba Group, Sunnyvale",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17330/17330-13-20824-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11152-local-differential-privacy-for-bayesian-optimization/",
        "doi": "10.1609/aaai.v35i12.17330",
        "pdf_size": 581129
    },
    {
        "id": "01081",
        "title": "Local Relation Learning for Face Forgery Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "With the rapid development of facial manipulation techniques, face forgery has received considerable attention in digital media forensics due to security concerns. Most existing methods formulate face forgery detection as a classification problem and utilize binary labels or manipulated region masks as supervision. However, without considering the correlation between local regions, these global supervisions are insufficient to learn a generalized feature and prone to overfitting. To address this issue, we propose a novel perspective of face forgery detection via local relation learning. Specifically, we propose a Multi-scale Patch Similarity Module (MPSM), which measures the similarity between features of local regions and forms a robust and generalized similarity pattern. Moreover, we propose an RGB-Frequency Attention Module (RFAM) to fuse information in both RGB and frequency domains for more comprehensive local feature representation, which further improves the reliability of the similarity pattern. Extensive experiments show that the proposed method consistently outperforms the state-of-the-arts on widely-used benchmarks. Furthermore, detailed visualization shows the robustness and interpretability of our method.",
        "primary_area": "Computer Vision I",
        "author": "Shen Chen; Taiping Yao; Yang Chen; Shouhong Ding; Jilin Li; Rongrong Ji",
        "authorids": "",
        "aff": "Media Analytics and Computing Lab, Department of Artificial Intelligence, School of Informatics, Xiamen University. YouTu Lab, Tencent; YouTu Lab, Tencent; YouTu Lab, Tencent; YouTu Lab, Tencent; YouTu Lab, Tencent; Media Analytics and Computing Lab, Department of Artificial Intelligence, School of Informatics, Xiamen University. Institute of Artificial Intelligence, Xiamen University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16193/16193-13-19687-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01081-local-relation-learning-for-face-forgery-detection/",
        "doi": "10.1609/aaai.v35i2.16193",
        "pdf_size": 1895536
    },
    {
        "id": "00872",
        "title": "Localization in the Crowd with Topological Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "We address the problem of crowd localization, i.e., the prediction of dots corresponding to people in a crowded scene. Due to various challenges, a localization method is prone to spatial semantic errors, i.e., predicting multiple dots within a same person or collapsing multiple dots in a cluttered region. We propose a topological approach targeting these semantic errors. We introduce a topological constraint that teaches the model to reason about the spatial arrangement of dots. To enforce this constraint, we define a persistence loss based on the theory of persistent homology. The loss compares the topographic landscape of the likelihood map and the topology of the ground truth. Topological reasoning improves the quality of the localization algorithm especially near cluttered regions. On multiple public benchmarks, our method outperforms previous localization methods. Additionally, we demonstrate the potential of our method in improving the performance in the crowd counting task.",
        "primary_area": "Computer Vision I",
        "author": "Shahira Abousamra; Minh Hoai; Dimitris Samaras; Chao Chen",
        "authorids": "",
        "aff": "Stony Brook University; Stony Brook University; Stony Brook University; Stony Brook University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16170/16170-13-19664-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00872-localization-in-the-crowd-with-topological-constraints/",
        "doi": "10.1609/aaai.v35i2.16170",
        "pdf_size": 2040723
    },
    {
        "id": "03004",
        "title": "Locate Globally, Segment Locally: A Progressive Architecture With Knowledge Review Network for Salient Object Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Salient object location and segmentation are two different tasks in salient object detection (SOD). The former aims to globally find the most attractive objects in an image, whereas the latter can be achieved only using local regions that contain salient objects. However, previous methods mainly accomplish the two tasks simultaneously in a simple end-to-end manner, which leads to the ignorance of the differences between them. We assume that the human vision system orderly locates and segments objects, so we propose a novel progressive architecture with knowledge review network (PA-KRN) for SOD. It consists of three parts. (1) A coarse locating module (CLM) that uses body-attention label locates rough areas containing salient objects without boundary details. (2) An attention-based sampler highlights salient object regions with high resolution based on body-attention maps. (3) A fine segmenting module (FSM) finely segments salient objects. The networks applied in CLM and FSM are mainly based on our proposed knowledge review network (KRN) that utilizes the finest feature maps to reintegrate all previous layers, which can make up for the important information that is continuously diluted in the top-down path. Experiments on five benchmarks demonstrate that our single KRN can outperform state-of-the-art methods. Furthermore, our PA-KRN performs better and substantially surpasses the aforementioned methods.",
        "primary_area": "Computer Vision III",
        "author": "Binwei Xu; Haoran Liang; Ronghua Liang; Peng Chen",
        "authorids": "",
        "aff": "Zhejiang University of Technology; Zhejiang University of Technology; Zhejiang University of Technology; Zhejiang University of Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16408/16408-13-19902-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03004-locate-globally-segment-locally-a-progressive-architecture-with-knowledge-review-network-for-salient-object-detection/",
        "doi": "10.1609/aaai.v35i4.16408",
        "pdf_size": 2069640
    },
    {
        "id": "08556",
        "title": "Longitudinal Deep Kernel Gaussian Process Regression",
        "track": "main",
        "status": "Poster",
        "abstract": "Gaussian processes offer an attractive framework for predictive modeling from longitudinal data, ie irregularly sampled, sparse observations from a set of individuals over time. However, such methods have two key shortcomings: (i) They rely on ad hoc heuristics or expensive trial and error to choose the effective kernels, and (ii) They fail to handle multilevel correlation structure in the data. We introduce Longitudinal deep kernel Gaussian process regression (L-DKGPR) to overcome these limitations by fully automating the discovery of complex multilevel correlation structure from longitudinal data.  Specifically, L-DKGPR eliminates the need for ad hoc heuristics or trial and error using a novel adaptation of deep kernel learning that combines the expressive power of deep neural networks with the flexibility of non-parametric kernel methods. L-DKGPR effectively learns the multilevel correlation with a novel additive kernel that simultaneously accommodates both time-varying and the time-invariant effects. We derive an efficient algorithm to train L-DKGPR using latent space inducing points and variational inference. Results of extensive experiments on several benchmark data sets demonstrate that L-DKGPR significantly outperforms the state-of-the-art longitudinal data analysis (LDA) methods.",
        "primary_area": "Machine Learning III",
        "author": "Junjie Liang; Yanting Wu; Dongkuan Xu; Vasant G Honavar",
        "authorids": "",
        "aff": "Pennsylvania State University; Pennsylvania State University; Pennsylvania State University; Pennsylvania State University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17038/17038-13-20532-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08556-longitudinal-deep-kernel-gaussian-process-regression/",
        "doi": "10.1609/aaai.v35i10.17038",
        "pdf_size": 647677
    },
    {
        "id": "10981",
        "title": "Looking Wider for Better Adaptive Representation in Few-Shot Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Building a good feature space is essential for the metric-based few-shot algorithms to recognize a novel class with only a few samples. The feature space is often built by Convolutional Neural Networks (CNNs). However, CNNs primarily focus on local information with the limited receptive field, and the global information generated by distant pixels is not well used. Meanwhile, having a global understanding of the current task and focusing on distinct regions of the same sample for different queries are important for the few-shot classification. To tackle these problems, we propose the Cross Non-Local Neural Network (CNL) for capturing the long-range dependency of the samples and the current task. CNL extracts the task-specific and context-aware features dynamically by strengthening the features of the sample at a position via aggregating information from all positions of itself and the current task. To reduce losing important information, we maximize the mutual information between the original and refined features as a constraint. Moreover, we add a task-specific scaling to deal with multi-scale and task-specific features extracted by CNL. We conduct extensive experiments for validating our proposed algorithm, which achieves new state-of-the-art performances on two public benchmarks.",
        "primary_area": "Machine Learning V",
        "author": "Jiabao Zhao; Yifan Yang; Xin Lin; Jing Yang; Liang He",
        "authorids": "",
        "aff": "Shanghai Key Laboratory of Multidimensional Information Processing, ECNU, Shanghai, China School of Computer Science and Technology, East China Normal University, Shanghai, China; Transwarp Technology (Shanghai) Co., Ltd, China; Shanghai Key Laboratory of Multidimensional Information Processing, ECNU, Shanghai, China School of Computer Science and Technology, East China Normal University, Shanghai, China; School of Computer Science and Technology, East China Normal University, Shanghai, China; Shanghai Key Laboratory of Multidimensional Information Processing, ECNU, Shanghai, China School of Computer Science and Technology, East China Normal University, Shanghai, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17311/17311-13-20805-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10981-looking-wider-for-better-adaptive-representation-in-few-shot-learning/",
        "doi": "10.1609/aaai.v35i12.17311",
        "pdf_size": 680826
    },
    {
        "id": "07169",
        "title": "Loop Estimator for Discounted Values in Markov Reward Processes",
        "track": "main",
        "status": "Poster",
        "abstract": "At the working heart of policy iteration algorithms commonly used and studied in the discounted setting of reinforcement learning, the policy evaluation step estimates the value of states with samples from a Markov reward process induced by following a Markov policy in a Markov decision process. We propose a simple and efficient estimator called loop estimator that exploits the regenerative structure of Markov reward processes without explicitly estimating a full model. Our method enjoys a space complexity of O(1) when estimating the value of a single positive recurrent state s unlike TD with O(S) or model-based methods with O(S^2). Moreover, the regenerative structure enables us to show, without relying on the generative model approach, that the estimator has an instance-dependent convergence rate of O~(sqrt{tau_s/T}) over steps T on a single sample path, where tau_s is the maximal expected hitting time to state s. In preliminary numerical experiments, the loop estimator outperforms model-free methods, such as TD(k), and is competitive with the model-based estimator.",
        "primary_area": "Machine Learning I",
        "author": "Falcon Z. Dai; Matthew R. Walter",
        "authorids": "",
        "aff": "Toyota Technological Institute at Chicago; Toyota Technological Institute at Chicago",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16881/16881-13-20375-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07169-loop-estimator-for-discounted-values-in-markov-reward-processes/",
        "doi": "10.1609/aaai.v35i8.16881",
        "pdf_size": 2225617
    },
    {
        "id": "00399",
        "title": "Low-Rank Registration Based Manifolds for Convection-Dominated PDEs",
        "track": "main",
        "status": "Poster",
        "abstract": "We develop an auto-encoder-type nonlinear dimensionality reduction algorithm to enable the construction of reduced order models of systems governed by convection-dominated nonlinear partial differential equations (PDEs), i.e. snapshots of solutions with large Kolmogorov n-width. Although several existing nonlinear manifold learning methods, such as LLE, ISOMAP, MDS, etc., appear as compelling candidates to reduce the dimensionality of such data, most are not applicable to reduced order modeling of PDEs, because: (i) they typically lack a straightforward mapping from the latent space to the high-dimensional physical space, and (ii) the identified latent variables are often difficult to interpret. In our proposed method, these limitations are overcome by training a low-rank diffeomorphic spatio-temporal grid that registers the output sequence of the PDEs on a non-uniform parameter/time-varying grid, such that the Kolmogorov n-width of the mapped data on the learned grid is minimized. We demonstrate the efficacy and interpretability of our proposed approach on several challenging manufactured computer vision-inspired tasks and physical systems.",
        "primary_area": "Application Domains",
        "author": "Rambod Mojgani; Maciej Balajewicz",
        "authorids": "",
        "aff": "University of Illinois at Urbana-Champaign Rice University; University of Illinois at Urbana-Champaign Siemens Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16116/16116-13-19610-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00399-low-rank-registration-based-manifolds-for-convection-dominated-pdes/",
        "doi": "10.1609/aaai.v35i1.16116",
        "pdf_size": 1634479
    },
    {
        "id": "02620",
        "title": "MAMBA: Multi-level Aggregation via Memory Bank for Video Object Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "State-of-the-art video object detection methods maintain a memory structure, either a sliding window or a memory queue, to enhance the current frame using attention mechanisms. However, we argue that these memory structures are not efficient or sufficient because of two implied operations: (1) concatenating all features in memory for enhancement, leading to a heavy computational cost; (2) frame-wise memory updating, preventing the memory from capturing more temporal information. In this paper, we propose a multi-level aggregation architecture via memory bank called MAMBA. Specifically, our memory bank employs two novel operations to eliminate disadvantages of existing methods: (1) light-weight key-set construction which can significantly reduce the computational cost; (2) fine-grained feature-wise updating strategy which enables our method to utilize knowledge from the whole video. To better enhance features from complementary levels, i.e., feature maps and proposals, we further propose a generalized enhancement operation (GEO) to aggregate multi-level features in a unified manner. We conduct extensive evaluations on the challenging ImageNetVID dataset. Compared with existing state-of-the-art methods, our method achieves superior performance in terms of both speed and accuracy. More remarkably, MAMBA achieves mAP of 83.7%/84.6% at 12.6/9.1 FPS with ResNet-101.",
        "primary_area": "Computer Vision II",
        "author": "Guanxiong Sun; Yang Hua; Guosheng Hu; Neil Robertson",
        "authorids": "",
        "aff": "Queen's University Belfast AnyVision; Queen's University Belfast; AnyVision Queen's University Belfast; Queen's University Belfast",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16365/16365-13-19859-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02620-mamba-multi-level-aggregation-via-memory-bank-for-video-object-detection/",
        "doi": "10.1609/aaai.v35i3.16365",
        "pdf_size": 352206
    },
    {
        "id": "02467",
        "title": "MANGO: A Mask Attention Guided One-Stage Scene Text Spotter",
        "track": "main",
        "status": "Poster",
        "abstract": "Recently end-to-end scene text spotting has become a popular research topic due to its advantages of global optimization and high maintainability in real applications. Most methods attempt to develop various region of interest (RoI) operations to concatenate the detection part and the sequence recognition part into a two-stage text spotting framework. However, in such framework, the recognition part is highly sensitive to the detected results (e.g., the compactness of text contours). To address this problem, in this paper, we propose a novel Mask AttentioN Guided One-stage text spotting framework named MANGO, in which character sequences can be directly recognized without RoI operation. Concretely, a position-aware mask attention module is developed to generate attention weights on each text instance and its characters. It allows different text instances in an image to be allocated on different feature map channels which are further grouped as a batch of instance features. Finally, a lightweight sequence decoder is applied to generate the character sequences. It is worth noting that MANGO inherently adapts to arbitrary-shaped text spotting and can be trained end-to-end with only coarse position information (e.g., rectangular bounding box) and text annotations. Experimental results show that the proposed method achieves competitive and even new state-of-the-art performance on both regular and irregular text spotting benchmarks, i.e., ICDAR 2013, ICDAR 2015, Total-Text, and SCUT-CTW1500.",
        "primary_area": "Computer Vision II",
        "author": "Liang Qiao; Ying Chen; Zhanzhan Cheng; Yunlu Xu; Yi Niu; Shiliang Pu; Fei Wu",
        "authorids": "",
        "aff": "Hikvision Research Institute; Tongji University; Zhejiang University Hikvision Research Institute; Hikvision Research Institute; Hikvision Research Institute; Hikvision Research Institute; Zhejiang University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16348/16348-13-19842-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02467-mango-a-mask-attention-guided-one-stage-scene-text-spotter/",
        "doi": "10.1609/aaai.v35i3.16348",
        "pdf_size": 3014511
    },
    {
        "id": "05868",
        "title": "MARTA: Leveraging Human Rationales for Explainable Text Classification",
        "track": "main",
        "status": "Poster",
        "abstract": "Explainability is a key requirement for text classification in many application domains ranging from sentiment analysis to medical diagnosis or legal reviews. Existing methods often rely on \"attention\" mechanisms for explaining classification results by estimating the relative importance of input units. However, recent studies have shown that such mechanisms tend to mis-identify irrelevant input units in their explanation. In this work, we propose a hybrid human-AI approach that incorporates human rationales into attention-based text classification models to improve the explainability of classification results. Specifically, we ask workers to provide rationales for their annotation by selecting relevant pieces of text. We introduce MARTA, a Bayesian framework that jointly learns an attention-based model and the reliability of workers while injecting human rationales into model training. We derive a principled optimization algorithm based on variational inference with efficient updating rules for learning MARTA parameters. Extensive validation on real-world datasets shows that our framework significantly improves the state of the art both in terms of classification explainability and accuracy.",
        "primary_area": "Humans and AI",
        "author": "Ines Arous; Ljiljana Dolamic; Jie Yang; Akansha Bhardwaj; Giuseppe Cuccu; Philippe Cudr\u00e9-Mauroux",
        "authorids": "",
        "aff": "University of Fribourg; armasuisse; Delft University of Technology; University of Fribourg; University of Fribourg; University of Fribourg",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16734/16734-13-20228-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05868-marta-leveraging-human-rationales-for-explainable-text-classification/",
        "doi": "10.1609/aaai.v35i7.16734",
        "pdf_size": 192362
    },
    {
        "id": "13578",
        "title": "MASKER: Masked Keyword Regularization for Reliable Text Classification",
        "track": "main",
        "status": "Poster",
        "abstract": "Pre-trained language models have achieved state-of-the-art accuracies on various text classification tasks, e.g., sentiment analysis, natural language inference, and semantic textual similarity. However, the reliability of the fine-tuned text classifiers is an often underlooked performance criterion. For instance, one may desire a model that can detect out-of-distribution (OOD) samples (drawn far from training distribution) or be robust against domain shifts. We claim that one central obstacle to the reliability is the over-reliance of the model on a limited number of keywords, instead of looking at the whole context. In particular, we find that (a) OOD samples often contain in-distribution keywords, while (b) cross-domain samples may not always contain keywords; over-relying on the keywords can be problematic for both cases. In light of this observation, we propose a simple yet effective fine-tuning method, coined masked keyword regularization (MASKER), that facilitates context-based prediction. MASKER regularizes the model to reconstruct the keywords from the rest of the words and make low-confidence predictions without enough context. When applied to various pre-trained language models (e.g., BERT, RoBERTa, and ALBERT), we demonstrate that MASKER improves OOD detection and cross-domain generalization without degrading classification accuracy. Code is available at https://github.com/alinlab/MASKER.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Seung Jun Moon; Sangwoo Mo; Kimin Lee; Jaeho Lee; Jinwoo Shin",
        "authorids": "",
        "aff": "KAIST; KAIST; UC Berkeley; KAIST; KAIST",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17601/17601-13-21095-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13578-masker-masked-keyword-regularization-for-reliable-text-classification/",
        "doi": "10.1609/aaai.v35i15.17601",
        "pdf_size": 3041607
    },
    {
        "id": "14076",
        "title": "MELINDA: A Multimodal Dataset for Biomedical Experiment Method Classification",
        "track": "main",
        "status": "Poster",
        "abstract": "We introduce a new dataset, MELINDA, for Multimodal biomEdicaL experImeNt methoD clAssification. The dataset is collected in a fully automated distant supervision manner, where the labels are obtained from an existing curated database, and the actual contents are extracted from papers associated with each of the records in the database. We benchmark various state-of-the-art NLP and computer vision models, including unimodal models which only take either caption texts or images as inputs, and multimodal models. Extensive experiments and analysis show that multimodal models, despite outperforming unimodal ones, still need improvements especially on a less-supervised way of grounding visual concepts with languages, and better transferability to low resource domains. We release our dataset and the benchmarks to facilitate future research in multimodal learning, especially to motivate targeted improvements for applications in scientific domains.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Te-Lin Wu; Shikhar Singh; Sayan Paul; Gully Burns; Nanyun Peng",
        "authorids": "",
        "aff": "University of California, Los Angeles (UCLA); University of Southern California; Intuit; Chan Zuckerberg Initiative; University of California, Los Angeles (UCLA)",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17657/17657-13-21151-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14076-melinda-a-multimodal-dataset-for-biomedical-experiment-method-classification/",
        "doi": "10.1609/aaai.v35i16.17657",
        "pdf_size": 6913373
    },
    {
        "id": "14420",
        "title": "MERL: Multimodal Event Representation Learning in Heterogeneous Embedding Spaces",
        "track": "main",
        "status": "Poster",
        "abstract": "Previous work has shown the effectiveness of using event representations for tasks such as script event prediction and stock market prediction. It is however still challenging to learn the subtle semantic differences between events based solely on textual descriptions of events often represented as (subject, predicate, object) triples. As an alternative, images offer a more intuitive way of understanding event semantics. We observe that event described in text and in images show different abstraction levels and therefore should be projected onto heterogeneous embedding spaces, as opposed to what have been done in previous approaches which project signals from different modalities onto a homogeneous space. In this paper, we propose a Multimodal Event Representation Learning framework (MERL) to learn event representations based on both text and image modalities simultaneously. Event textual triples are projected as Gaussian density embeddings by a dual-path Gaussian triple encoder, while event images are projected as point embeddings by a visual event component-aware image encoder. Moreover, a novel score function motivated by statistical hypothesis testing is introduced to coordinate two embedding spaces. Experiments are conducted on various multimodal event-related tasks and results show that MERL outperforms a number of unimodal and multimodal baselines, demonstrating the effectiveness of the proposed framework.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Linhai Zhang; Deyu Zhou; Yulan He; Zeng Yang",
        "authorids": "",
        "aff": "Southeast University; Southeast University; University of Warwick; Southeast University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17695/17695-13-21189-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14420-merl-multimodal-event-representation-learning-in-heterogeneous-embedding-spaces/",
        "doi": "10.1609/aaai.v35i16.17695",
        "pdf_size": 446287
    },
    {
        "id": "08491",
        "title": "MFES-HB: Efficient Hyperband with Multi-Fidelity Quality Measurements",
        "track": "main",
        "status": "Poster",
        "abstract": "Hyperparameter optimization (HPO) is a fundamental problem in automatic machine learning (AutoML). However, due to the expensive evaluation cost of models (e.g., training deep learning models or training models on large datasets), vanilla Bayesian optimization (BO) is typically computationally infeasible.  To alleviate this issue, Hyperband (HB) utilizes the early stopping mechanism to speed up configuration evaluations by terminating those badly-performing configurations in advance. This leads to two kinds of quality measurements: (1) many low-fidelity measurements for configurations that get early-stopped, and (2) few high-fidelity measurements for configurations that are evaluated without being early stopped. The state-of-the-art HB-style method, BOHB, aims to combine the benefits of both BO and HB.  Instead of sampling configurations randomly in HB, BOHB samples configurations based on a BO surrogate model, which is constructed with the high-fidelity measurements only. However, the scarcity of high-fidelity measurements greatly hampers the efficiency of BO to guide the configuration search.  In this paper, we present MFES-HB, an efficient Hyperband method that is capable of utilizing both the high-fidelity and low-fidelity measurements to accelerate the convergence of HPO tasks. Designing MFES-HB is not trivial as the low-fidelity measurements can be biased yet informative to guide the configuration search. Thus we propose to build a Multi-Fidelity Ensemble Surrogate (MFES) based on the generalized Product of Experts framework, which can integrate useful information from multi-fidelity measurements effectively. The empirical studies on the real-world AutoML tasks demonstrate that MFES-HB can achieve 3.3-8.9x speedups over the state-of-the-art approach --- BOHB.",
        "primary_area": "Machine Learning III",
        "author": "Yang Li; Yu Shen; Jiawei Jiang; Jinyang Gao; Ce Zhang; Bin Cui",
        "authorids": "",
        "aff": "Peking University Kuaishou Technology; Peking University Kuaishou Technology; ETH Zurich; Alibaba Group; ETH Zurich; Peking University Institute of Computational Social Science, Peking University (Qingdao), China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17031/17031-13-20525-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08491-mfes-hb-efficient-hyperband-with-multi-fidelity-quality-measurements/",
        "doi": "10.1609/aaai.v35i10.17031",
        "pdf_size": 803206
    },
    {
        "id": "01264",
        "title": "MIEHDR CNN: Main Image Enhancement based Ghost-Free High Dynamic Range Imaging using Dual-Lens Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "We study the High Dynamic Range (HDR) imaging problem using two Low Dynamic Range (LDR) images that are shot from dual-lens systems in a single shot time with different exposures. In most of the related HDR imaging methods, the problem is usually solved by Multiple Images Merging, i.e. the final HDR image is fused from pixels of all the input LDR images. However, ghost artifacts can be hardly avoided using this strategy. Instead of directly merging the multiple LDR inputs, we use an indirect way which enhances the main image, i.e. the short exposure image IS, using the long exposure image IL serving as guidance. In detail, we propose a new model, named MIEHDR CNN model, which consists of three subnets, i.e. Soft Warp CNN, 3D Guided Denoising CNN and Fusion CNN. The Soft Warp CNN aligns IL to get the aligned result ILA using the soft exposed result of IS as reference. The 3D Guided Denoising CNN denoises the soft exposed result of IS using ILA as guidance, whose result are fed into the Fusion CNN with IS to get the HDR result. The MIEHDR CNN model is implemented by MindSpore and experimental results show that we can outperform related methods largely and avoid ghost artifacts.",
        "primary_area": "Computer Vision I",
        "author": "Xuan Dong; Xiaoyan Hu; Weixin Li; Xiaojie Wang; Yunhong Wang",
        "authorids": "",
        "aff": "Beijing University of Posts and Telecommunications; Beijing University of Posts and Telecommunications; Beihang University; Beijing University of Posts and Telecommunications; Beihang University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16214/16214-13-19708-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01264-miehdr-cnn-main-image-enhancement-based-ghost-free-high-dynamic-range-imaging-using-dual-lens-systems/",
        "doi": "10.1609/aaai.v35i2.16214",
        "pdf_size": 18517010
    },
    {
        "id": "00125",
        "title": "MIMOSA: Multi-constraint Molecule Sampling for Molecule Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "",
        "primary_area": "Application Domains",
        "author": "Tianfan Fu; Cao Xiao; Xinhao Li; Lucas M. Glass; Jimeng Sun",
        "authorids": "",
        "aff": "",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16085/16085-13-19579-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00125-mimosa-multi-constraint-molecule-sampling-for-molecule-optimization/",
        "doi": "",
        "pdf_size": 269015
    },
    {
        "id": "14032",
        "title": "MLE-Guided Parameter Search for Task Loss Minimization in Neural Sequence Modeling",
        "track": "main",
        "status": "Poster",
        "abstract": "Neural autoregressive sequence models are used to generate sequences in a variety of natural language processing (NLP) tasks, where they are evaluated according to sequence-level task losses. These models are typically trained with maximum likelihood estimation, which ignores the task loss, yet empirically performs well as a surrogate objective. Typical approaches to directly optimizing the task loss such as policy gradient and minimum risk training are based around sampling in the sequence space to obtain candidate update directions that are scored based on the loss of a single sequence. In this paper, we develop an alternative method based on random search in the parameter space that leverages access to the maximum likelihood gradient. We propose maximum likelihood guided parameter search (MGS), which samples from a distribution over update directions that is a mixture of random search around the current parameters and around the maximum likelihood gradient, with each direction weighted by its improvement in the task loss. MGS shifts sampling to the parameter space, and scores candidates using losses that are pooled from multiple sequences. Our experiments show that MGS is capable of optimizing sequence-level losses, with substantial reductions in repetition and non-termination in sequence completion, and similar improvements to those of minimum risk training in machine translation.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Sean Welleck; Kyunghyun Cho",
        "authorids": "",
        "aff": "New York University; New York University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17652/17652-13-21146-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14032-mle-guided-parameter-search-for-task-loss-minimization-in-neural-sequence-modeling/",
        "doi": "10.1609/aaai.v35i16.17652",
        "pdf_size": 609048
    },
    {
        "id": "14586",
        "title": "MTAAL: Multi-Task Adversarial Active Learning for Medical Named Entity Recognition and Normalization",
        "track": "main",
        "status": "Poster",
        "abstract": "Automated medical named entity recognition and normalization are fundamental for constructing knowledge graphs and building QA systems. When it comes to medical text, the annotation demands a foundation of expertise and professionalism. Existing methods utilize active learning to reduce costs in corpus annotation, as well as the multi-task learning strategy to model the correlations between different tasks. However, existing models do not take task-specific features for different tasks and diversity of query samples into account. To address these limitations, this paper proposes a multi-task adversarial active learning model for medical named entity recognition and normalization. In our model, the adversarial learning keeps the effectiveness of multi-task learning module and active learning module. The task discriminator eliminates the influence of irregular task-specific features. And the diversity discriminator exploits the heterogeneity between samples to meet the diversity constraint. The empirical results on two medical benchmarks demonstrate the effectiveness of our model against the existing methods.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Baohang Zhou; Xiangrui Cai; Ying Zhang; Wenya Guo; Xiaojie Yuan",
        "authorids": "",
        "aff": "College of Computer Science, Nankai University, Tianjin 300350, China Tianjin Key Laboratory of Network and Data Security Technology, Tianjin 300350, China; College of Cyber Science, Nankai University, Tianjin 300350, China Tianjin Key Laboratory of Network and Data Security Technology, Tianjin 300350, China; College of Computer Science, Nankai University, Tianjin 300350, China Tianjin Key Laboratory of Network and Data Security Technology, Tianjin 300350, China; College of Computer Science, Nankai University, Tianjin 300350, China Tianjin Key Laboratory of Network and Data Security Technology, Tianjin 300350, China; College of Computer Science, Nankai University, Tianjin 300350, China Tianjin Key Laboratory of Network and Data Security Technology, Tianjin 300350, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17714/17714-13-21208-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14586-mtaal-multi-task-adversarial-active-learning-for-medical-named-entity-recognition-and-normalization/",
        "doi": "10.1609/aaai.v35i16.17714",
        "pdf_size": 1342090
    },
    {
        "id": "10532",
        "title": "MUFASA: Multimodal Fusion Architecture Search for Electronic Health Records",
        "track": "main",
        "status": "Poster",
        "abstract": "One important challenge of applying deep learning to electronic health records (EHR) is the complexity of their multimodal structure. EHR usually contains a mixture of structured (codes) and unstructured (free-text) data with sparse and irregular longitudinal features -- all of which doctors utilize when making decisions. In the deep learning regime, determining how different modality representations should be fused together is a difficult problem, which is often addressed by handcrafted modeling and intuition. In this work, we extend state-of-the-art neural architecture search (NAS) methods and propose MUltimodal Fusion Architecture SeArch (MUFASA) to simultaneously search across multimodal fusion strategies and modality-specific architectures for the first time. We demonstrate empirically that our MUFASA method outperforms established unimodal NAS on public EHR data with comparable computation costs. In addition, MUFASA produces architectures that outperform Transformer and Evolved Transformer. Compared with these baselines on CCS diagnosis code prediction, our discovered models improve top-5 recall from 0.88 to 0.91 and demonstrate the ability to generalize to other EHR tasks. Studying our top architecture in depth, we provide empirical evidence that MUFASA's improvements are derived from its ability to both customize modeling for each modality and find effective fusion strategies.",
        "primary_area": "Machine Learning V",
        "author": "Zhen Xu; David R. So; Andrew  M. Dai",
        "authorids": "",
        "aff": "Google Research; Google Research; Google Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17260/17260-13-20754-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10532-mufasa-multimodal-fusion-architecture-search-for-electronic-health-records/",
        "doi": "10.1609/aaai.v35i12.17260",
        "pdf_size": 363522
    },
    {
        "id": "02943",
        "title": "MVFNet: Multi-View Fusion Network for Efficient Video Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "Conventionally, spatiotemporal modeling network and its complexity are the two most concentrated research topics in video action recognition. Existing state-of-the-art methods have achieved excellent accuracy regardless of the complexity meanwhile efficient spatiotemporal modeling solutions are slightly inferior in performance. In this paper, we attempt to acquire both efficiency and effectiveness simultaneously. First of all, besides traditionally treating H x W x T video frames as space-time signal (viewing from the Height-Width spatial plane), we propose to also model video from the other two Height-Time and Width-Time planes, to capture the dynamics of video thoroughly. Secondly, our model is designed based on 2D CNN backbones and model complexity is well kept in mind by design. Specifically, we introduce a novel multi-view fusion (MVF) module to exploit video dynamics using separable convolution for efficiency. It is a plug-and-play module and can be inserted into off-the-shelf 2D CNNs to form a simple yet effective model called MVFNet. Moreover, MVFNet can be thought of as a generalized video modeling framework and it can specialize to be existing methods such as C2D, SlowOnly, and TSM under different settings. Extensive experiments are conducted on popular benchmarks (i.e., Something-Something V1 & V2, Kinetics, UCF-101, and HMDB-51) to show its superiority. The proposed MVFNet can achieve state-of-the-art performance with 2D CNN's complexity.",
        "primary_area": "Computer Vision III",
        "author": "Wenhao Wu; Dongliang He; Tianwei Lin; Fu Li; Chuang Gan; Errui Ding",
        "authorids": "",
        "aff": "Department of Computer Vision Technology (VIS), Baidu Inc.; Department of Computer Vision Technology (VIS), Baidu Inc.; Department of Computer Vision Technology (VIS), Baidu Inc.; Department of Computer Vision Technology (VIS), Baidu Inc.; MIT-IBM Watson AI Lab; Department of Computer Vision Technology (VIS), Baidu Inc.",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16401/16401-13-19895-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02943-mvfnet-multi-view-fusion-network-for-efficient-video-recognition/",
        "doi": "10.1609/aaai.v35i4.16401",
        "pdf_size": 184818
    },
    {
        "id": "11369",
        "title": "Maintenance of Social Commitments in Multiagent Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "We introduce and formalize a concept of a maintenance commitment, a kind of social commitment characterized by states whose truthhood an agent commits to maintain. This concept of maintenance commitments enables us to capture a richer variety of real-world scenarios than possible using achievement commitments with a temporal condition.  By developing a rule-based operational semantics, we study the relationship between agents' achievement and maintenance goals, achievement commitments, and maintenance commitments. We motivate a notion of coherence which captures alignment between an agents' achievement and maintenance cognitive and social constructs, and prove that, under specified conditions, the goals and commitments of both rational agents individually and of a multiagent system are coherent.",
        "primary_area": "Multiagent Systems",
        "author": "Pankaj Telang; Munindar P. Singh; Neil Yorke-Smith",
        "authorids": "",
        "aff": "SAS Institute, Inc.; North Carolina State University; Delft University of Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17355/17355-13-20849-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11369-maintenance-of-social-commitments-in-multiagent-systems/",
        "doi": "10.1609/aaai.v35i13.17355",
        "pdf_size": 219465
    },
    {
        "id": "05611",
        "title": "Majority Opinion Diffusion in Social Networks: An Adversarial Approach",
        "track": "main",
        "status": "Poster",
        "abstract": "We introduce and study a novel majority based opinion diffusion model. Consider a graph G, which represents a social network. Assume that initially a subset of nodes, called seed nodes or early adopters, are colored either black or white, which correspond to positive or negative opinion regarding a consumer product or a technological innovation. Then, in each round an uncolored node, which is adjacent to at least one colored node, chooses the most frequent color among its neighbors.  Consider a marketing campaign which advertises a product of poor quality and its ultimate goal is that more than half of the population believe in the quality of the product at the end of the opinion diffusion process. We focus on three types of attackers which can select the seed nodes in a deterministic or random fashion and manipulate almost half of them to adopt a positive opinion toward the product (that is, to choose black color). We say that an attacker succeeds if a majority of nodes are black at the end of the process. Our main purpose is to characterize classes of graphs where an attacker cannot succeed. In particular, we prove that if the maximum degree of the underlying graph is not too large or if it has strong expansion properties, then it is fairly resilient to such attacks.  Furthermore, we prove tight bounds on the stabilization time of the process (that is, the number of rounds it needs to end) in both settings of choosing the seed nodes deterministically and randomly. We also provide several hardness results for some optimization problems regarding stabilization time and choice of seed nodes.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Ahad N. Zehmakan",
        "authorids": "",
        "aff": "ETH Zurich",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16705/16705-13-20199-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05611-majority-opinion-diffusion-in-social-networks-an-adversarial-approach/",
        "doi": "10.1609/aaai.v35i6.16705",
        "pdf_size": 158580
    },
    {
        "id": "14411",
        "title": "Making the Relation Matters: Relation of Relation Learning Network for Sentence Semantic Matching",
        "track": "main",
        "status": "Poster",
        "abstract": "Sentence semantic matching is one of the fundamental tasks in natural language processing, which requires an agent to determine the semantic relation among input sentences. Recently, deep neural networks have achieved impressive performance in this area, especially BERT. Despite the effectiveness of these models, most of them treat output labels as meaningless one-hot vectors, underestimating the semantic information and guidance of relations that these labels reveal, especially for  tasks with a small number of labels. To address this problem, we propose a Relation of Relation Learning Network (R2-Net) for sentence semantic matching. Specifically, we first employ BERT to encode the input sentences from a global perspective. Then a CNN-based encoder is designed to capture keywords and phrase information from a local perspective. To fully leverage labels for better relation information extraction, we introduce a self-supervised relation of relation classification task for guiding R2-Net to consider more about labels. Meanwhile, a triplet loss is employed to distinguish the intra-class and inter-class relations in a finer granularity. Empirical experiments on two sentence semantic matching tasks demonstrate the superiority of our proposed model. As a byproduct, we have released the codes to facilitate other researches.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Kun Zhang; Le Wu; Guangyi Lv; Meng Wang; Enhong Chen; Shulan Ruan",
        "authorids": "",
        "aff": "School of Computer Science and Information Engineering, Hefei University of Technology; School of Computer Science and Information Engineering, Hefei University of Technology Institute of Artificial Intelligence, Hefei Comprehensive National Science Center; Anhui Province Key Laboratory of Big Data Analysis and Application, University of Science and Technology of China; School of Computer Science and Information Engineering, Hefei University of Technology Institute of Artificial Intelligence, Hefei Comprehensive National Science Center; Anhui Province Key Laboratory of Big Data Analysis and Application, University of Science and Technology of China; Anhui Province Key Laboratory of Big Data Analysis and Application, University of Science and Technology of China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17694/17694-13-21188-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14411-making-the-relation-matters-relation-of-relation-learning-network-for-sentence-semantic-matching/",
        "doi": "10.1609/aaai.v35i16.17694",
        "pdf_size": 400101
    },
    {
        "id": "02611",
        "title": "MangaGAN: Unpaired Photo-to-Manga Translation Based on The Methodology of Manga Drawing",
        "track": "main",
        "status": "Poster",
        "abstract": "Manga is a world popular comic form originated in Japan, which typically employs black-and-white stroke lines and geometric exaggeration to describe humans' appearances, poses, and actions. In this paper, we propose MangaGAN, the first method based on Generative Adversarial Network (GAN) for unpaired photo-to-manga translation. Inspired by the drawing process of experienced manga artists, MangaGAN generates geometric features and converts each facial region into the manga domain with a tailored multi-GANs architecture. For training MangaGAN, we collect a new data-set from a popular manga work with extensive features. To produce high-quality manga faces, we propose a structural smoothing loss to smooth stroke-lines and avoid noisy pixels, and a similarity preserving module to improve the similarity between domains of photo and manga. Extensive experiments show that MangaGAN can produce high-quality manga faces preserving both the facial similarity and manga style, and outperforms other reference methods.",
        "primary_area": "Computer Vision II",
        "author": "Hao Su; Jianwei Niu; Xuefeng Liu; Qingfeng Li; Jiahe Cui; Ji Wan",
        "authorids": "",
        "aff": "State Key Lab of VR Technology and System, School of Computer Science and Engineering, Beihang University; State Key Lab of VR Technology and System, School of Computer Science and Engineering, Beihang University Industrial Technology Research Institute, School of Information Engineering, Zhengzhou University Hangzhou Innovation Institute, Beihang University; State Key Lab of VR Technology and System, School of Computer Science and Engineering, Beihang University; State Key Lab of VR Technology and System, School of Computer Science and Engineering, Beihang University; State Key Lab of VR Technology and System, School of Computer Science and Engineering, Beihang University; State Key Lab of VR Technology and System, School of Computer Science and Engineering, Beihang University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16364/16364-13-19858-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02611-mangagan-unpaired-photo-to-manga-translation-based-on-the-methodology-of-manga-drawing/",
        "doi": "10.1609/aaai.v35i3.16364",
        "pdf_size": 6868776
    },
    {
        "id": "00768",
        "title": "Many-to-One Distribution Learning and K-Nearest Neighbor Smoothing for Thoracic Disease Identification",
        "track": "main",
        "status": "Poster",
        "abstract": "Chest X-rays are an important and accessible clinical imaging tool for the detection of many thoracic diseases. Over the past decade, deep learning, with a focus on the convolutional neural network (CNN), has become the most powerful computer-aided diagnosis technology for improving disease identification performance. However, training an effective and robust deep CNN usually requires a large amount of data with high annotation quality. For chest X-ray imaging, annotating large-scale data requires professional domain knowledge and is time-consuming. Thus, existing public chest X-ray datasets usually adopt language pattern based methods to automatically mine labels from reports. However, this results in label uncertainty and inconsistency. In this paper, we propose many-to-one distribution learning (MODL) and K-nearest neighbor smoothing (KNNS) methods from two perspectives to improve a single model's disease identification performance, rather than focusing on an ensemble of models. MODL integrates multiple models to obtain a soft label distribution for optimizing the single target model, which can reduce the effects of original label uncertainty. Moreover, KNNS aims to enhance the robustness of the target model to provide consistent predictions on images with similar medical findings. Extensive experiments on the public NIH Chest X-ray and CheXpert datasets show that our model achieves consistent improvements over the state-of-the-art methods.",
        "primary_area": "Application Domains",
        "author": "Yi Zhou; Lei Huang; Tianfei Zhou; Ling Shao",
        "authorids": "",
        "aff": "Southeast University, Nanjing, China; Beihang University, Beijing, China; ETH Zurich, Switzerland; Inception Institute of Artificial Intelligence, Abu Dhabi, UAE",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16158/16158-13-19652-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00768-many-to-one-distribution-learning-and-k-nearest-neighbor-smoothing-for-thoracic-disease-identification/",
        "doi": "10.1609/aaai.v35i1.16158",
        "pdf_size": 3164483
    },
    {
        "id": "05228",
        "title": "Margin of Victory in Tournaments: Structural and Experimental Results",
        "track": "main",
        "status": "Poster",
        "abstract": "Tournament solutions are standard tools for identifying winners based on pairwise comparisons between competing alternatives. The recently studied notion of margin of victory (MoV) offers a general method for refining the winner set of any given tournament solution, thereby increasing the discriminative power of the solution. In this paper, we reveal a number of structural insights on the MoV by investigating fundamental properties such as monotonicity and consistency with respect to the covering relation. Furthermore, we provide experimental evidence on the extent to which the MoV notion refines winner sets in tournaments generated according to various stochastic models.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Markus Brill; Ulrike Schmidt-Kraepelin; Warut Suksompong",
        "authorids": "",
        "aff": "TU Berlin; TU Berlin; National University of Singapore",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16660/16660-13-20154-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05228-margin-of-victory-in-tournaments-structural-and-experimental-results/",
        "doi": "10.1609/aaai.v35i6.16660",
        "pdf_size": 892616
    },
    {
        "id": "05656",
        "title": "Market-Based Explanations of Collective Decisions",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider approval-based committee elections, in which a size-k subset of available candidates must be selected given approval sets for each voter, indicating the candidates approved by the voter. A number of axioms capturing ideas of fairness and proportionality have been proposed for this framework. We argue that even the strongest of them, such as priceability and the core, only rule out certain undesirable committees, but fail to ensure that the selected committee is fair in all cases. We propose two new solution concepts, stable priceability and balanced stable priceability, and show that they select arguably fair committees. Our solution concepts come with a non-trivial-to-construct but easy-to-understand market-based explanation for why the chosen committee is fair. We show that stable priceability is closely related to the notion of Lindahl equilibrium from economics.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Dominik Peters; Grzegorz Pierczy\u0144ski; Nisarg Shah; Piotr Skowron",
        "authorids": "",
        "aff": "Harvard University; University of Warsaw; University of Toronto; University of Warsaw",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16710/16710-13-20204-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05656-market-based-explanations-of-collective-decisions/",
        "doi": "10.1609/aaai.v35i6.16710",
        "pdf_size": 143369
    },
    {
        "id": "01673",
        "title": "Matching on Sets: Conquer Occluded Person Re-identification Without Alignment",
        "track": "main",
        "status": "Poster",
        "abstract": "Occluded person re-identification (re-ID) is a challenging task as different human parts may become invisible in cluttered scenes, making it hard to match person images of different identities. Most existing methods address this challenge by aligning spatial features of body parts according to semantic information (e.g. human poses) or feature similarities but this approach is complicated and sensitive to noises. This paper presents Matching on Sets (MoS), a novel method that positions occluded person re-ID as a set matching task without requiring spatial alignment. MoS encodes a person image by a pattern set as represented by a `global vector\u2019 with each element capturing one specific visual pattern, and it introduces Jaccard distance as a metric to compute the distance between pattern sets and measure image similarity. To enable Jaccard distance over continuous real numbers, we employ minimization and maximization to approximate the operations of intersection and union, respectively. In addition, we design a Jaccard triplet loss that enhances the pattern discrimination and allows to embed set matching into deep neural networks for end-to-end training. In the inference stage, we introduce a conflict penalty mechanism that detects mutually exclusive patterns in the pattern union of image pairs and decreases their similarities accordingly. Extensive experiments over three widely used datasets (Market1501, DukeMTMC and Occluded-DukeMTMC) show that MoS achieves superior re-ID performance. Additionally, it is tolerant of occlusions and outperforms the state-of-the-art by large margins for Occluded-DukeMTMC.",
        "primary_area": "Computer Vision I",
        "author": "Mengxi Jia; Xinhua Cheng; Yunpeng Zhai; Shijian Lu; Siwei Ma; Yonghong Tian; Jian Zhang",
        "authorids": "",
        "aff": "School of Electronic and Computer Engineering, Peking University, China; College of Computer Science, Sichuan University, China; School of Electronic and Computer Engineering, Peking University, China; Nanyang Technological University, Singapore; School of Electronics Engineering and Computer Science, Peking University, China; School of Electronics Engineering and Computer Science, Peking University, China; School of Electronic and Computer Engineering, Peking University, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16260/16260-13-19754-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01673-matching-on-sets-conquer-occluded-person-re-identification-without-alignment/",
        "doi": "10.1609/aaai.v35i2.16260",
        "pdf_size": 1108274
    },
    {
        "id": "05167",
        "title": "Maximin Fairness with Mixed Divisible and Indivisible Goods",
        "track": "main",
        "status": "Poster",
        "abstract": "We study fair resource allocation when the resources contain a mixture of divisible and indivisible goods, focusing on the well-studied fairness notion of maximin share fairness (MMS). With only indivisible goods, a full MMS allocation may not exist, but a constant multiplicative approximate allocation always does. We analyze how the MMS approximation guarantee would be affected when the resources to be allocated also contain divisible goods. In particular, we show that the worst-case MMS approximation guarantee with mixed goods is no worse than that with only indivisible goods. However, there exist problem instances to which adding some divisible resources would strictly decrease the MMS approximation ratios of the instances. On the algorithmic front, we propose a constructive algorithm that will always produce an alpha-MMS allocation for any number of agents, where alpha takes values between 1/2 and 1 and is a monotonically increasing function determined by how agents value the divisible goods relative to their MMS values.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Xiaohui Bei; Shengxin Liu; Xinhang Lu; Hongao Wang",
        "authorids": "",
        "aff": "Nanyang Technological University, Singapore; Harbin Institute of Technology, Shenzhen, China; Nanyang Technological University, Singapore; Nanyang Technological University, Singapore",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16653/16653-13-20147-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05167-maximin-fairness-with-mixed-divisible-and-indivisible-goods/",
        "doi": "10.1609/aaai.v35i6.16653",
        "pdf_size": 149875
    },
    {
        "id": "09331",
        "title": "Maximum Roaming Multi-Task Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-task learning has gained popularity due to the advantages it provides with respect to resource usage and performance. Nonetheless, the joint optimization of parameters with respect to multiple tasks remains an active research topic. Sub-partitioning the parameters between different tasks has proven to be an efficient way to relax the optimization constraints over the shared weights, may the partitions be disjoint or overlapping. However, one drawback of this approach is that it can weaken the inductive bias generally set up by the joint task optimization. In this work, we present a novel way to partition the parameter space without weakening the inductive bias. Specifically, we propose Maximum Roaming, a method inspired by dropout that randomly varies the parameter partitioning, while forcing them to visit as many tasks as possible at a regulated frequency, so that the network fully adapts to each update. We study the properties of our method through experiments on a variety of visual multi-task data sets. Experimental results suggest that the regularization brought by roaming has more impact on performance than usual partitioning optimization strategies. The overall method is flexible, easily applicable, provides superior regularization and consistently achieves improved performances compared to recent multi-task learning formulations.",
        "primary_area": "Machine Learning III",
        "author": "Lucas Pascal; Pietro Michiardi; Xavier Bost; Benoit Huet; Maria A. Zuluaga",
        "authorids": "",
        "aff": "EURECOM Orkis; EURECOM; Orkis; Median Technologies; EURECOM",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17125/17125-13-20619-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09331-maximum-roaming-multi-task-learning/",
        "doi": "10.1609/aaai.v35i10.17125",
        "pdf_size": 865180
    },
    {
        "id": "00311",
        "title": "MeInGame: Create a Game Character Face from a Single Portrait",
        "track": "main",
        "status": "Poster",
        "abstract": "Many deep learning based 3D face reconstruction methods have been proposed recently, however, few of them have applications in games. Current game character customization systems either require players to manually adjust considerable face attributes to obtain the desired face, or have limited freedom of facial shape and texture. In this paper, we propose an automatic character face creation method that predicts both facial shape and texture from a single portrait, and it can be integrated into most existing 3D games. Although 3D Morphable Face Model (3DMM) based methods can restore accurate 3D faces from single images, the topology of 3DMM mesh is different from the meshes used in most games. To acquire fidelity texture, existing methods require a large amount of face texture data for training, while building such datasets is time-consuming and laborious. Besides, such a dataset collected under laboratory conditions may not generalized well to in-the-wild situations. To tackle these problems, we propose 1) a low-cost facial texture acquisition method, 2) a shape transfer algorithm that can transform the shape of a 3DMM mesh to games, and 3) a new pipeline for training 3D game face reconstruction networks. The proposed method not only can produce detailed and vivid game characters similar to the input portrait, but can also eliminate the influence of lighting and occlusions. Experiments show that our method outperforms state-of-the-art methods used in games. Code and dataset are available at https://github.com/FuxiCV/MeInGame.",
        "primary_area": "Application Domains",
        "author": "Jiangke Lin; Yi Yuan; Zhengxia Zou",
        "authorids": "",
        "aff": "Netease Fuxi AI Lab; Netease Fuxi AI Lab; University of Michigan",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16106/16106-13-19600-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00311-meingame-create-a-game-character-face-from-a-single-portrait/",
        "doi": "10.1609/aaai.v35i1.16106",
        "pdf_size": 2559724
    },
    {
        "id": "10905",
        "title": "Mean-Variance Policy Iteration for Risk-Averse Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a mean-variance policy iteration (MVPI) framework for risk-averse control in a discounted infinite horizon MDP optimizing the variance of a per-step reward random variable. MVPI enjoys great flexibility in that any policy evaluation method and risk-neutral control method can be dropped in for risk-averse control off the shelf, in both on- and off-policy settings. This flexibility reduces the gap between risk-neutral control and risk-averse control and is achieved by working on a novel augmented MDP directly. We propose risk-averse TD3 as an example instantiating MVPI, which outperforms vanilla TD3 and many previous risk-averse control methods in challenging Mujoco robot simulation tasks under a risk-aware performance metric. This risk-averse TD3 is the first to introduce deterministic policies and off-policy learning into risk-averse reinforcement learning, both of which are key to the performance boost we show in Mujoco domains.",
        "primary_area": "Machine Learning V",
        "author": "Shangtong Zhang; Bo Liu; Shimon Whiteson",
        "authorids": "",
        "aff": "University of Oxford; Auburn University; University of Oxford",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17302/17302-13-20796-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10905-mean-variance-policy-iteration-for-risk-averse-reinforcement-learning/",
        "doi": "10.1609/aaai.v35i12.17302",
        "pdf_size": 266805
    },
    {
        "id": "10781",
        "title": "Measuring Dependence with Matrix-based Entropy Functional",
        "track": "main",
        "status": "Poster",
        "abstract": "Measuring the dependence of data plays a central role in statistics and machine learning. In this work, we summarize and generalize the main idea of existing information-theoretic dependence measures into a higher-level perspective by the Shearer's inequality. Based on our generalization, we then propose two measures, namely the matrix-based normalized total correlation and the matrix-based normalized dual total correlation, to quantify the dependence of multiple variables in arbitrary dimensional space, without explicit estimation of the underlying data distributions. We show that our measures are differentiable and statistically more powerful than prevalent ones. We also show the impact of our measures in four different machine learning problems, namely the gene regulatory network inference, the robust machine learning under covariate shift and non-Gaussian noises, the subspace outlier detection, and the understanding of the learning dynamics of convolutional neural networks, to demonstrate their utilities, advantages, as well as implications to those problems.",
        "primary_area": "Machine Learning V",
        "author": "Shujian Yu; Francesco Alesiani; Xi Yu; Robert Jenssen; Jose Principe",
        "authorids": "",
        "aff": "NEC Laboratories Europe; NEC Laboratories Europe; University of Florida; UiT - The Arctic University of Norway; University of Florida",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17288/17288-13-20782-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10781-measuring-dependence-with-matrix-based-entropy-functional/",
        "doi": "10.1609/aaai.v35i12.17288",
        "pdf_size": 300304
    },
    {
        "id": "09549",
        "title": "Membership Privacy for Machine Learning Models Through Knowledge Transfer",
        "track": "main",
        "status": "Poster",
        "abstract": "Large capacity machine learning (ML) models are prone to membership inference attacks (MIAs), which aim to infer whether the target sample is a member of the target model's training dataset. The serious privacy concerns due to the membership inference have motivated multiple defenses against MIAs, e.g., differential privacy and adversarial regularization. Unfortunately, these defenses produce ML models with unacceptably low classification performances.  Our work proposes a new defense, called distillation for membership privacy (DMP), against MIAs that preserves the utility of the resulting models significantly better than prior defenses.  DMP leverages knowledge distillation to train ML models with membership privacy. We provide a novel criterion to tune the data used for knowledge transfer in order to amplify the membership privacy of DMP.  Our extensive evaluation shows that DMP provides significantly better tradeoffs between membership privacy and classification accuracies compared to state-of-the-art MIA defenses. For instance, DMP achieves ~100% accuracy improvement over adversarial regularization for DenseNet trained on CIFAR100, for similar membership privacy (measured using MIA risk): when the MIA risk is 53.7%, adversarially regularized DenseNet is 33.6% accurate, while DMP-trained DenseNet is 65.3% accurate. We have released our code at github.com/vrt1shjwlkr/AAAI21-MIA-Defense.",
        "primary_area": "Machine Learning IV",
        "author": "Virat Shejwalkar; Amir Houmansadr",
        "authorids": "",
        "aff": "University of Massachusetts Amherst; University of Massachusetts Amherst",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17150/17150-13-20644-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09549-membership-privacy-for-machine-learning-models-through-knowledge-transfer/",
        "doi": "10.1609/aaai.v35i11.17150",
        "pdf_size": 636269
    },
    {
        "id": "08316",
        "title": "Memory and Computation-Efficient Kernel SVM via Binary Embedding and Ternary Model Coefficients",
        "track": "main",
        "status": "Poster",
        "abstract": "Kernel approximation is widely used to scale up kernel SVM training and prediction. However, the memory and computation costs of kernel approximation models are still too large if we want to deploy them on memory-limited devices such as mobile phones, smart watches and IoT devices. To address this challenge, we propose a novel memory and computation-efficient kernel SVM model by using both binary embedding and binary model coefficients. First, we propose an efficient way to generate compact binary embedding of the data which can preserve the kernel similarity. Second, we propose a simple but effective algorithm to learn a linear classification model with binary coefficients which can support different types of loss function and regularizer. Our algorithm can achieve better generalization accuracy than existing works on learning binary coefficients since we allow coefficient to be -1, 0 or 1 during the training stage and coefficient 0 can be removed during model inference. Moreover, we provide detailed analysis on the convergence of our algorithm and the inference complexity of our model. The analysis shows that the convergence to a local optimum is guaranteed and the inference complexity of our model is much lower than other competing methods. Our experimental results on five large real-world datasets have demonstrated that our proposed method can build accurate nonlinear SVM model with memory cost less than 30KB.",
        "primary_area": "Machine Learning II",
        "author": "Zijian Lei; Liang Lan",
        "authorids": "",
        "aff": "Department of Computer Science, Hong Kong Baptist University; Department of Computer Science, Hong Kong Baptist University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17011/17011-13-20505-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08316-memory-and-computation-efficient-kernel-svm-via-binary-embedding-and-ternary-model-coefficients/",
        "doi": "10.1609/aaai.v35i9.17011",
        "pdf_size": 717241
    },
    {
        "id": "01317",
        "title": "Memory-Augmented Image Captioning",
        "track": "main",
        "status": "Poster",
        "abstract": "Current deep learning-based image captioning systems have been proven to store practical knowledge with their parameters and achieve competitive performances in the public datasets. Nevertheless, their ability to access and precisely manipulate the mastered knowledge is still limited. Besides, providing evidence for decisions and updating memory information are also important yet under explored. Towards this goal, we introduce a memory-augmented method, which extends an existing image caption model by incorporating extra explicit knowledge from a memory bank. Adequate knowledge is recalled according to the similarity distance in the embedding space of history context, and the memory bank can be constructed conveniently from any matched image-text set, e.g., the previous training data. Incorporating such non-parametric memory-augmented method to various captioning baselines, the performance of resulting captioners imporves consistently on the evaluation benchmark. More encouragingly, extensive experiments demonstrate that our approach holds the capability for efficiently adapting to larger training datasets, by simply transferring the memory bank without any additional training.",
        "primary_area": "Computer Vision I",
        "author": "Zhengcong Fei",
        "authorids": "",
        "aff": "Key Lab of Intelligent Information Processing of Chinese Academy of Sciences (CAS), Institute of Computing Technology, CAS, Beijing 100190, China University of Chinese Academy of Sciences, Beijing 100049, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16220/16220-13-19714-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01317-memory-augmented-image-captioning/",
        "doi": "10.1609/aaai.v35i2.16220",
        "pdf_size": 1415520
    },
    {
        "id": "10956",
        "title": "Memory-Gated Recurrent Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "The essence of multivariate sequential learning is all about how to extract dependencies in data. These data sets, such as hourly medical records in intensive care units and multi-frequency phonetic time series, often time exhibit not only strong serial dependencies in the individual components (the \"marginal\" memory) but also non-negligible memories in the cross-sectional dependencies (the \"joint\" memory). Because of the multivariate complexity in the evolution of the joint distribution that underlies the data generating process, we take a data-driven approach and construct a novel recurrent network architecture, termed Memory-Gated Recurrent Networks (mGRN), with gates explicitly regulating two distinct types of memories: the marginal memory and the joint memory. Through a combination of comprehensive simulation studies and empirical experiments on a range of public datasets, we show that our proposed mGRN architecture consistently outperforms state-of-the-art architectures targeting multivariate time series.",
        "primary_area": "Machine Learning V",
        "author": "Yaquan Zhang; Qi Wu; Nanbo Peng; Min Dai; Jing Zhang; Hu Wang",
        "authorids": "",
        "aff": "National University of Singapore, Department of Mathematics and Risk Management Institute; City University of Hong Kong; JD Digits; National University of Singapore, Department of Mathematics, Risk Management Institute, and Chong-Qing & Suzhou Research Institutes; City University of Hong Kong; JD Digits",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17308/17308-13-20802-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10956-memory-gated-recurrent-networks/",
        "doi": "10.1609/aaai.v35i12.17308",
        "pdf_size": 371867
    },
    {
        "id": "07210",
        "title": "Mercer Features for Efficient Combinatorial Bayesian Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "Bayesian optimization (BO) is an efficient framework for solving black-box optimization problems with expensive function evaluations. This paper addresses the BO problem setting for combinatorial spaces (e.g., sequences and graphs) that occurs naturally in science and engineering applications. A prototypical example is molecular optimization guided by expensive experiments. The key challenge is to balance the complexity of statistical models and tractability of search to select combinatorial structures for evaluation. In this paper, we propose an efficient approach referred as Mercer Features for Combinatorial Bayesian Optimization (MerCBO). The key idea behind MerCBO is to provide explicit feature maps for diffusion kernels over discrete objects by exploiting the structure of their combinatorial graph representation. These Mercer features combined with Thompson sampling as the acquisition function allows us to employ efficient solvers for finding the next structure for evaluation. Experimental evaluation on diverse real-world benchmarks demonstrates that MerCBO performs similarly or better than prior methods.",
        "primary_area": "Machine Learning I",
        "author": "Aryan Deshwal; Syrine Belakaria; Janardhan Rao Doppa",
        "authorids": "",
        "aff": "Washington State University; Washington State University; Washington State University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16886/16886-13-20380-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07210-mercer-features-for-efficient-combinatorial-bayesian-optimization/",
        "doi": "10.1609/aaai.v35i8.16886",
        "pdf_size": 3278368
    },
    {
        "id": "13288",
        "title": "Merging Statistical Feature via Adaptive Gate for Improved Text Classification",
        "track": "main",
        "status": "Poster",
        "abstract": "Currently, text classification studies mainly focus on training classifiers by using textual input only, or enhancing semantic features by introducing external knowledge (e.g., hand-craft lexicons and domain knowledge). In contrast, some intrinsic statistical features of the corpus, like word frequency and distribution over labels, are not well exploited. Compared with external knowledge, the statistical features are deterministic and naturally compatible with corresponding tasks. In this paper, we propose an Adaptive Gate Network (AGN) to consolidate semantic representation with statistical features selectively. In particular, AGN encodes statistical features through a variational component and merges information via a well-designed valve mechanism. The valve adapts the information flow into the classifier according to the confidence of semantic features in decision making, which can facilitate training a robust classifier and can address the overfitting caused by using statistical features. Extensive experiments on datasets of various scales show that, by incorporating statistical information, AGN can improve the classification performance of CNN, RNN, Transformer, and Bert based models effectively. The experiments also indicate the robustness of AGN against adversarial attacks of manipulating statistical information.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Xianming Li; Zongxi Li; Haoran Xie; Qing Li",
        "authorids": "",
        "aff": "Ant Group; Department of Computer Science, City University of Hong Kong; Lingnan University; The Hong Kong Polytechnic University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17569/17569-13-21063-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13288-merging-statistical-feature-via-adaptive-gate-for-improved-text-classification/",
        "doi": "10.1609/aaai.v35i15.17569",
        "pdf_size": 4504510
    },
    {
        "id": "11053",
        "title": "Meta Label Correction for Noisy Label Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Leveraging weak or noisy supervision for building effective machine learning models has long been an important research problem. Its importance has further increased recently due to the growing need for large-scale datasets to train deep learning models. Weak or noisy supervision could originate from multiple sources including non-expert annotators or automatic labeling based on heuristics or user interaction signals. There is an extensive amount of previous work focusing on leveraging noisy labels. Most notably, recent work has shown impressive gains by using a meta-learned instance re-weighting approach where a meta-learning framework is used to assign instance weights to noisy labels. In this paper, we extend this approach via posing the problem as a label correction problem within a meta-learning framework. We view the label correction procedure as a meta-process and propose a new meta-learning based framework termed MLC (Meta Label Correction) for learning with noisy labels. Specifically, a label correction network is adopted as a meta-model to produce corrected labels for noisy labels while the main model is trained to leverage the corrected labels. Both models are jointly trained by solving a bi-level optimization problem. We run extensive experiments with different label noise levels and types on both image recognition and text classification tasks. We compare the re-weighing and correction approaches showing that the correction framing addresses some of the limitations of re-weighting. We also show that the proposed MLC approach outperforms previous methods in both image and language tasks.",
        "primary_area": "Machine Learning V",
        "author": "Guoqing Zheng; Ahmed Hassan Awadallah; Susan Dumais",
        "authorids": "",
        "aff": "Microsoft Research; Microsoft Research; Microsoft Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17319/17319-13-20813-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11053-meta-label-correction-for-noisy-label-learning/",
        "doi": "10.1609/aaai.v35i12.17319",
        "pdf_size": 3328117
    },
    {
        "id": "09897",
        "title": "Meta Learning for Causal Direction",
        "track": "main",
        "status": "Poster",
        "abstract": "The inaccessibility of controlled randomized trials due to inherent constraints in many fields of science has been a fundamental issue in causal inference. In this paper, we focus on distinguishing the cause from effect in the bivariate setting under limited observational data. Based on recent developments in meta learning as well as in causal inference, we introduce a novel generative model that allows distinguishing cause and effect in the small data setting. Using a learnt task variable that contains distributional information of each dataset, we propose an end-to-end algorithm that makes use of similar training datasets at test time. We demonstrate our method on various synthetic as well as real-world data and show that it is able to maintain high accuracy in detecting directions across varying dataset sizes.",
        "primary_area": "Machine Learning IV",
        "author": "Jean-Fran\u00e7ois Ton; Dino Sejdinovic; Kenji Fukumizu",
        "authorids": "",
        "aff": "University of Oxford, Oxford, UK; University of Oxford, Oxford, UK; The Institute of Statistical Mathematics, Tokyo, Japan",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17189/17189-13-20683-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09897-meta-learning-for-causal-direction/",
        "doi": "10.1609/aaai.v35i11.17189",
        "pdf_size": 732494
    },
    {
        "id": "14310",
        "title": "Meta-Curriculum Learning for Domain Adaptation in Neural Machine Translation",
        "track": "main",
        "status": "Poster",
        "abstract": "Meta-learning has been sufficiently validated to be beneficial for low-resource neural machine translation (NMT). However, we find that meta-trained NMT fails to improve the translation performance of the domain unseen at the meta-training stage. In this paper, we aim to alleviate this issue by proposing a novel meta-curriculum learning for domain adaptation in NMT. During meta-training, the NMT first learns the similar curricula from each domain to avoid falling into a bad local optimum early, and finally learns the curricula of individualities to improve the model robustness for learning domain-specific knowledge. Experimental results on 10 different low-resource domains show that meta-curriculum learning can improve the translation performance of both familiar and unfamiliar domains. All the codes and data are freely available at https://github.com/NLP2CT/Meta-Curriculum.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Runzhe Zhan; Xuebo Liu; Derek F. Wong; Lidia S. Chao",
        "authorids": "",
        "aff": "University of Macau; University of Macau; University of Macau; University of Macau",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17683/17683-13-21177-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14310-meta-curriculum-learning-for-domain-adaptation-in-neural-machine-translation/",
        "doi": "10.1609/aaai.v35i16.17683",
        "pdf_size": 316368
    },
    {
        "id": "09541",
        "title": "Meta-Learning Effective Exploration Strategies for Contextual Bandits",
        "track": "main",
        "status": "Poster",
        "abstract": "In contextual bandits, an algorithm must choose actions given ob- served contexts, learning from a reward signal that is observed only for the action chosen. This leads to an exploration/exploitation trade-off: the algorithm must balance taking actions it already believes are good with taking new actions to potentially discover better choices. We develop a meta-learning algorithm, M\u00eal\u00e9e, that learns an exploration policy based on simulated, synthetic con- textual bandit tasks. M\u00eal\u00e9e uses imitation learning against these simulations to train an exploration policy that can be applied to true contextual bandit tasks at test time. We evaluate M\u00eal\u00e9e on both a natural contextual bandit problem derived from a learning to rank dataset as well as hundreds of simulated contextual ban- dit problems derived from classification tasks. M\u00eal\u00e9e outperforms seven strong baselines on most of these datasets by leveraging a rich feature representation for learning an exploration strategy.",
        "primary_area": "Machine Learning IV",
        "author": "Amr Sharaf; Hal Daum\u00e9 III",
        "authorids": "",
        "aff": "University of Maryland; University of Maryland Microsoft Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17149/17149-13-20643-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09541-meta-learning-effective-exploration-strategies-for-contextual-bandits/",
        "doi": "10.1609/aaai.v35i11.17149",
        "pdf_size": 751166
    },
    {
        "id": "09242",
        "title": "Meta-Learning Framework with Applications to Zero-Shot Time-Series Forecasting",
        "track": "main",
        "status": "Poster",
        "abstract": "Can meta-learning discover generic ways of processing time series (TS) from a diverse dataset so as to greatly improve generalization on new TS coming from different datasets? This work provides positive evidence to this using a broad meta-learning framework which we show subsumes many existing meta-learning algorithms. Our theoretical analysis suggests that residual connections act as a meta-learning adaptation mechanism, generating a subset of task-specific parameters based on a given TS input, thus gradually expanding the expressive power of the architecture on-the-fly. The same mechanism is shown via linearization analysis to have the interpretation of a sequential update of the final linear layer. Our empirical results on a wide range of data emphasize the importance of the identified meta-learning mechanisms for successful zero-shot univariate forecasting, suggesting that it is viable to train a neural network on a source TS dataset and deploy it on a different target TS dataset without retraining, resulting in performance that is at least as good as that of state-of-practice univariate forecasting models.",
        "primary_area": "Machine Learning III",
        "author": "Boris  N. Oreshkin; Dmitri Carpov; Nicolas Chapados; Yoshua Bengio",
        "authorids": "",
        "aff": "Element AI; Element AI; Element AI; Mila",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17115/17115-13-20609-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09242-meta-learning-framework-with-applications-to-zero-shot-time-series-forecasting/",
        "doi": "10.1609/aaai.v35i10.17115",
        "pdf_size": 176821
    },
    {
        "id": "12692",
        "title": "Meta-Transfer Learning for Low-Resource Abstractive Summarization",
        "track": "main",
        "status": "Poster",
        "abstract": "Neural abstractive summarization has been studied in many pieces of literature and achieves great success with the aid of large corpora. However, when encountering novel tasks, one may not always benefit from transfer learning due to the domain shifting problem, and overfitting could happen without adequate labeled examples. Furthermore, the annotations of abstractive summarization are costly, which often demand domain knowledge to ensure the ground-truth quality. Thus, there are growing appeals for Low-Resource Abstractive Summarization, which aims to leverage past experience to improve the performance with limited labeled examples of target corpus. In this paper, we propose to utilize two knowledge-rich sources to tackle this problem, which are large pre-trained models and diverse existing corpora. The former can provide the primary ability to tackle summarization tasks; the latter can help discover common syntactic or semantic information to improve the generalization ability. We conduct extensive experiments on various summarization corpora with different writing styles and forms. The results demonstrate that our approach achieves the state-of-the-art on 6 corpora in low-resource scenarios, with only 0.7% of trainable parameters compared to previous work.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Yi-Syuan Chen; Hong-Han Shuai",
        "authorids": "",
        "aff": "National Chiao Tung University; National Chiao Tung University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17503/17503-13-20997-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12692-meta-transfer-learning-for-low-resource-abstractive-summarization/",
        "doi": "10.1609/aaai.v35i14.17503",
        "pdf_size": 467843
    },
    {
        "id": "11097",
        "title": "MetaAugment: Sample-Aware Data Augmentation Policy Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Automated data augmentation has shown superior performance in image recognition. Existing works search for dataset-level augmentation policies without considering individual sample variations, which are likely to be sub-optimal. On the other hand, learning different policies for different samples naively could greatly increase the computing cost. In this paper, we learn a sample-aware data augmentation policy efficiently by formulating it as a sample reweighting problem. Specifically, an augmentation policy network takes a transformation and the corresponding augmented image as inputs, and outputs a weight to adjust the augmented image loss computed by a task network. At training stage, the task network minimizes the weighted losses of augmented training images, while the policy network minimizes the loss of the task network on a validation set via meta-learning. We theoretically prove the convergence of the training procedure and further derive the exact convergence rate. Superior performance is achieved on widely-used benchmarks including CIFAR-10/100, Omniglot, and ImageNet.",
        "primary_area": "Machine Learning V",
        "author": "Fengwei Zhou; Jiawei Li; Chuanlong Xie; Fei Chen; Lanqing Hong; Rui Sun; Zhenguo Li",
        "authorids": "",
        "aff": "Huawei Noah's Ark Lab; Huawei Noah's Ark Lab; Huawei Noah's Ark Lab; Huawei Noah's Ark Lab; Huawei Noah's Ark Lab; Huawei Noah Ark's Lab; Huawei Noah's Ark Lab",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17324/17324-13-20818-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11097-metaaugment-sample-aware-data-augmentation-policy-learning/",
        "doi": "10.1609/aaai.v35i12.17324",
        "pdf_size": 4795700
    },
    {
        "id": "08261",
        "title": "Metrics and Continuity in Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "In most practical applications of reinforcement learning, it is untenable to maintain direct estimates for individual states; in continuous-state systems, it is impossible. Instead, researchers often leverage {em state similarity}  (whether explicitly or implicitly) to build models that can generalize well from a limited set of samples. The notion of state similarity used, and the neighbourhoods and topologies they induce, is thus of crucial importance, as it will directly affect the performance of the algorithms. Indeed, a number of recent works introduce algorithms assuming the existence of \"well-behaved\" neighbourhoods, but leave the full specification of such topologies for future work. In this paper we introduce a unified formalism for defining these topologies through the lens of metrics. We establish a hierarchy amongst these metrics and demonstrate their theoretical implications on the Markov Decision Process specifying the reinforcement learning problem. We complement our theoretical results with empirical evaluations showcasing the differences between the metrics considered.",
        "primary_area": "Machine Learning II",
        "author": "Charline Le Lan; Marc G. Bellemare; Pablo Samuel Castro",
        "authorids": "",
        "aff": "University of Oxford; Google Research, Brain Team; Google Research, Brain Team",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17005/17005-13-20499-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08261-metrics-and-continuity-in-reinforcement-learning/",
        "doi": "10.1609/aaai.v35i9.17005",
        "pdf_size": 2022998
    },
    {
        "id": "05330",
        "title": "Mind the Gap: Cake Cutting With Separation",
        "track": "main",
        "status": "Poster",
        "abstract": "We study the problem of fairly allocating a divisible resource, also known as cake cutting, with an additional requirement that the shares that different agents receive should be sufficiently separated from one another. This captures, for example, constraints arising from social distancing guidelines. While it is sometimes impossible to allocate a proportional share to every agent under the separation requirement, we show that the well-known criterion of maximin share fairness can always be attained. We then establish several computational properties of maximin share fairness---for instance, the maximin share of an agent cannot be computed exactly by any finite algorithm, but can be approximated with an arbitrarily small error. In addition, we consider the division of a pie (i.e., a circular cake) and show that an ordinal relaxation of maximin share fairness can be achieved.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Edith Elkind; Erel Segal-Halevi; Warut Suksompong",
        "authorids": "",
        "aff": "University of Oxford; Ariel University; National University of Singapore",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16672/16672-13-20166-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05330-mind-the-gap-cake-cutting-with-separation/",
        "doi": "10.1609/aaai.v35i6.16672",
        "pdf_size": 144619
    },
    {
        "id": "01072",
        "title": "Mind-the-Gap! Unsupervised Domain Adaptation  for Text-Video Retrieval",
        "track": "main",
        "status": "Poster",
        "abstract": "When can we expect a text-video retrieval system to work effectively on datasets that differ from its training domain?  In this work, we investigate this question through the lens of unsupervised domain adaptation in which the objective is to match natural language queries and video content in the presence of domain shift at query-time.  Such systems have significant practical applications since they are capable generalising to new data sources without requiring corresponding text annotations. We make the following contributions: (1) We propose the  UDAVR (Unsupervised Domain Adaptation for Video Retrieval) benchmark and employ it to study the performance of text-video retrieval in the presence of domain shift. (2) We propose Concept-Aware-Pseudo-Query (CAPQ), a method for learning discriminative and transferable features that bridge these cross-domain discrepancies to enable effective target domain retrieval using source domain supervision. (3) We show that CAPQ outperforms alternative domain adaptation strategies on UDAVR.",
        "primary_area": "Computer Vision I",
        "author": "Qingchao Chen; Yang Liu; Samuel Albanie",
        "authorids": "",
        "aff": "Peking University University of Oxford; Peking University University of Oxford; University of Oxford",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16192/16192-13-19686-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01072-mind-the-gap-unsupervised-domain-adaptation-for-text-video-retrieval/",
        "doi": "10.1609/aaai.v35i2.16192",
        "pdf_size": 3544739
    },
    {
        "id": "04846",
        "title": "MiniSeg: An Extremely Minimum Network for Efficient COVID-19 Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "The rapid spread of the new pandemic, i.e., COVID-19, has severely threatened global health. Deep-learning-based computer-aided screening, e.g., COVID-19 infected CT area segmentation, has attracted much attention. However, the publicly available COVID-19 training data are limited, easily causing overfitting for traditional deep learning methods that are usually data-hungry with millions of parameters. On the other hand, fast training/testing and low computational cost are also necessary for quick deployment and development of COVID-19 screening systems, but traditional deep learning methods are usually computationally intensive. To address the above problems, we propose MiniSeg, a lightweight deep learning model for efficient COVID-19 segmentation. Compared with traditional segmentation methods, MiniSeg has several significant strengths: i) it only has 83K parameters and is thus not easy to overfit; ii) it has high computational efficiency and is thus convenient for practical deployment; iii) it can be fast retrained by other users using their private COVID-19 data for further improving performance. In addition, we build a comprehensive COVID-19 segmentation benchmark for comparing MiniSeg to traditional methods.",
        "primary_area": "AI Responses to the COVID-19 Pandemic",
        "author": "Yu Qiu; Yun Liu; Shijie Li; Jing Xu",
        "authorids": "",
        "aff": "Nankai University; Nankai University; Bonn University; Nankai University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16617/16617-13-20111-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04846-miniseg-an-extremely-minimum-network-for-efficient-covid-19-segmentation/",
        "doi": "10.1609/aaai.v35i6.16617",
        "pdf_size": 1997456
    },
    {
        "id": "11930",
        "title": "Minimax Regret Optimisation for Robust Planning in Uncertain Markov Decision Processes",
        "track": "main",
        "status": "Poster",
        "abstract": "The parameters for a Markov Decision Process (MDP) often cannot be specified exactly. Uncertain MDPs (UMDPs) capture this model ambiguity by defining sets which the parameters belong to. Minimax regret has been proposed as an objective for planning in UMDPs to find robust policies which are not overly conservative. In this work, we focus on planning for Stochastic Shortest Path (SSP) UMDPs with uncertain cost and transition functions. We introduce a Bellman equation to compute the regret for a policy. We propose a dynamic programming algorithm that utilises the regret Bellman equation, and show that it optimises minimax regret exactly for UMDPs with independent uncertainties. For coupled uncertainties, we extend our approach to use options to enable a trade off between computation and solution quality. We evaluate our approach on both synthetic and real-world domains, showing that it significantly outperforms existing baselines.",
        "primary_area": "Planning, Routing, and Scheduling",
        "author": "Marc Rigter; Bruno Lacerda; Nick Hawes",
        "authorids": "",
        "aff": "Oxford Robotics Institute, University of Oxford, United Kingdom; Oxford Robotics Institute, University of Oxford, United Kingdom; Oxford Robotics Institute, University of Oxford, United Kingdom",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17417/17417-13-20911-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11930-minimax-regret-optimisation-for-robust-planning-in-uncertain-markov-decision-processes/",
        "doi": "10.1609/aaai.v35i13.17417",
        "pdf_size": 1679490
    },
    {
        "id": "00697",
        "title": "Minimizing Labeling Cost for Nuclei Instance Segmentation and Classification with Cross-domain Images and Weak Labels",
        "track": "main",
        "status": "Poster",
        "abstract": "Nucleus instance segmentation and classification in histopathological images is an essential prerequisite in pathology diagnosis/prognosis. However, nucleus annotations (e.g., segmentation and labeling) require domain experts, and annotating nuclei at pixel-level is time-consuming and labor-intensive. Moreover, nuclei from different cancer types vary in shapes and appearances. These inter-cancer variations require careful annotations for specific cancer types. Therefore, to minimize the labeling cost, we propose a novel application that considers each cancer type as an individual domain and apply domain adaptation techniques to improve the segmentation/classification performance among different cancer types. Unlike the previous studies that focus on unsupervised or weakly-supervised domain adaptation independently, we would like to discover what kinds of labeling can achieve the most cost-effective domain adaptation performance in nucleus instance segmentation and classification. Specifically, we propose a unified framework that is applicable to different level annotations: no annotations, image-level, and point-level annotations. Cyclic adaptation with pseudo labels and adversarial discriminator are utilized for unsupervised domain alignment. Image-level or point-level annotations are additionally adopted to supervise the nucleus classification and refine the pseudo labels. Experiments demonstrate the effectiveness and efficacy of the proposed framework (jointly using unsupervised and weakly supervised learning) on adapting the segmentation and classification model from one cancer type to 18 other cancer types.",
        "primary_area": "Application Domains",
        "author": "Siqi Yang; Jun Zhang; Junzhou Huang; Brian  C. Lovell; Xiao Han",
        "authorids": "",
        "aff": "University of Queensland; Tencent AI Lab; Tencent AI Lab; University of Queensland; Tencent AI Lab",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16150/16150-13-19644-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00697-minimizing-labeling-cost-for-nuclei-instance-segmentation-and-classification-with-cross-domain-images-and-weak-labels/",
        "doi": "10.1609/aaai.v35i1.16150",
        "pdf_size": 1331878
    },
    {
        "id": "09109",
        "title": "Minimum Robust Multi-Submodular Cover for Fairness",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we study a novel problem, Minimum Robust Multi-Submodular Cover for Fairness (MinRF), as follows: given a ground set V; m monotone submodular functions f_1,...,f_m; m thresholds T_1,...,T_m and a non-negative integer r; MinRF asks for the smallest set S such that f_i(S  X) \u2265 T_i for all i \u2208 [m] and |X| \u2264 r. We prove that MinRF is inapproximable within (1- \u03b5) ln m; and no algorithm, taking fewer than exponential number of queries in term of r, is able to output a feasible set to MinRF with high certainty. Three bicriteria approximation algorithms with performance guarantees are proposed: one for r = 0, one for r = 1, and one for general r. We further investigate our algorithms' performance in two applications of MinRF, Information Propagation for Multiple Groups and Movie Recommendation for Multiple Users. Our algorithms have shown to outperform baseline heuristics in both solution quality and the number of queries in most cases.",
        "primary_area": "Machine Learning III",
        "author": "Lan N. Nguyen; My T. Thai",
        "authorids": "",
        "aff": "University of Florida; University of Florida",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17100/17100-13-20594-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09109-minimum-robust-multi-submodular-cover-for-fairness/",
        "doi": "10.1609/aaai.v35i10.17100",
        "pdf_size": 250727
    },
    {
        "id": "06367",
        "title": "Mining EL Bases with Adaptable Role Depth",
        "track": "main",
        "status": "Poster",
        "abstract": "In Formal Concept Analysis, a base for a finite structure is a set of implications that characterizes all valid implications of the structure. This notion can be adapted to the context of Description Logic, where the base consists of a set of concept inclusions instead of implications. In this setting, concept expressions can be arbitrarily large. Thus, it is not clear whether a finite base exists and, if so, how large concept expressions may need to be. We first revisit results in the literature for mining EL bases from finite interpretations. Those mainly focus on finding a finite base or on fixing the role depth but potentially losing some of the valid concept inclusions with higher role depth. We then present a new strategy for mining EL bases which is adaptable in the sense that it can bound the role depth of concepts depending on the local structure of the interpretation. Our strategy guarantees to capture all EL concept inclusions holding in the interpretation, not only the ones up to a fixed role depth.",
        "primary_area": "Knowledge Representation and Reasoning",
        "author": "Ricardo Guimar\u00e3es; Ana Ozaki; Cosimo Persia; Baris Sertkaya",
        "authorids": "",
        "aff": "University of Bergen; University of Bergen; University of Bergen; Frankfurt University of Applied Sciences",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16790/16790-13-20284-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06367-mining-el-bases-with-adaptable-role-depth/",
        "doi": "10.1609/aaai.v35i7.16790",
        "pdf_size": 174410
    },
    {
        "id": "03581",
        "title": "Model Uncertainty Guides Visual Object Tracking",
        "track": "main",
        "status": "Poster",
        "abstract": "Model object trackers largely rely on the online learning of a discriminative classifier from potentially diverse sample frames. However, noisy or insufficient amounts of samples can deteriorate the classifiers' performance and cause tracking drift. Furthermore, alterations such as occlusion and blurring can cause the target to be lost. In this paper, we make several improvements aimed at tackling uncertainty and improving robustness in object tracking. Our first and most important contribution is to propose a sampling method for the online learning of object trackers based on uncertainty adjustment: our method effectively selects representative sample frames to feed the discriminative branch of the tracker, while filtering out noise samples. Furthermore, to improve the robustness of the tracker to various challenging scenarios, we propose a novel data augmentation procedure, together with a specific improved backbone architecture. All our improvements fit together in one model, which we refer to as the Uncertainty Adjusted Tracker (UATracker), and can be trained in a joint and end-to-end fashion. Experiments on the LaSOT, UAV123, OTB100 and VOT2018 benchmarks demonstrate that our UATracker outperforms state-of-the-art real-time trackers by significant margins.",
        "primary_area": "Computer Vision III",
        "author": "Lijun Zhou; Antoine Ledent; Qintao Hu; Ting Liu; Jianlin Zhang; Marius Kloft",
        "authorids": "",
        "aff": "Alibaba Group Institute of Optics and Electronics, Chinese Academy of Sciences University of Chinese Academy of Sciences Department of Computer Science, TU Kaiserslautern; Department of Computer Science, TU Kaiserslautern; Institute of Optics and Electronics, Chinese Academy of Sciences University of Chinese Academy of Sciences; Alibaba Group; Institute of Optics and Electronics, Chinese Academy of Sciences; Department of Computer Science, TU Kaiserslautern",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16473/16473-13-19967-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03581-model-uncertainty-guides-visual-object-tracking/",
        "doi": "10.1609/aaai.v35i4.16473",
        "pdf_size": 776651
    },
    {
        "id": "00784",
        "title": "Model-Agnostic Fits for Understanding Information Seeking Patterns in Humans",
        "track": "main",
        "status": "Poster",
        "abstract": "In decision making tasks under uncertainty, humans display characteristic biases in seeking, integrating, and acting upon information relevant to the task. Here, we reexamine data from previous carefully designed experiments, collected at scale, that measured and catalogued these biases in aggregate form. We design deep learning models that replicate these biases in aggregate, while also capturing individual variation in behavior. A key finding of our work is that paucity of data collected from each individual subject can be overcome by sampling large numbers of subjects from the population, while still capturing individual differences. We predict human behavior with high accuracy without making any assumptions about task goals, reward structure, or individual biases, thus providing a model-agnostic fit to human behavior in the task. Such an approach can sidestep potential limitations in modeler-specified inductive biases, and has implications for computational modeling of human cognitive function in general, and of human-AI interfaces in particular.",
        "primary_area": "Cognitive Modeling and Cognitive Systems",
        "author": "Soumya Chatterjee; Pradeep Shenoy",
        "authorids": "",
        "aff": "Indian Institute of Technology Bombay; Google Research India",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16160/16160-13-19654-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00784-model-agnostic-fits-for-understanding-information-seeking-patterns-in-humans/",
        "doi": "10.1609/aaai.v35i1.16160",
        "pdf_size": 4555275
    },
    {
        "id": "05381",
        "title": "Model-Free Online Learning in Unknown Sequential Decision Making Problems and Games",
        "track": "main",
        "status": "Poster",
        "abstract": "Regret minimization has proved to be a versatile tool for tree-form sequential decision making and extensive-form games. In large two-player zero-sum imperfect-information games, modern extensions of counterfactual regret minimization (CFR) are currently the practical state of the art for computing a Nash equilibrium. Most regret-minimization algorithms for tree-form sequential decision making, including CFR, require (i) an exact model of the player\u2019s decision nodes, observation nodes, and how they are linked, and (ii) full knowledge, at all times t, about the payoffs\u2014even in parts of the decision space that are not encountered at time t. Recently, there has been growing interest towards relaxing some of those restrictions and making regret minimization applicable to settings for which reinforcement learning methods have traditionally been used\u2014for example, those in which only black-box access to the environment is available. We give the first, to our knowledge, regret-minimization algorithm that guarantees sublinear regret with high probability even when requirement (i)\u2014and thus also (ii)\u2014is dropped. We formalize an online learning setting in which the strategy space is not known to the agent and gets revealed incrementally whenever the agent encounters new decision points. We give an efficient algorithm that achieves O(T^3/4) regret with high probability for that setting, even when the agent faces an adversarial environment. Our experiments show it significantly outperforms the prior algorithms for the problem, which do not have such guarantees. It can be used in any application for which regret minimization is useful: approximating Nash equilibrium or quantal response equilibrium, approximating coarse correlated equilibrium in multi-player games, learning a best response, learning safe opponent exploitation, and online play against an unknown opponent/environment.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Gabriele Farina; Tuomas Sandholm",
        "authorids": "",
        "aff": "Carnegie Mellon University; Carnegie Mellon University Strategy Robot, Inc. Optimized Markets, Inc. Strategic Machine, Inc.",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16678/16678-13-20172-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05381-model-free-online-learning-in-unknown-sequential-decision-making-problems-and-games/",
        "doi": "10.1609/aaai.v35i6.16678",
        "pdf_size": 418435
    },
    {
        "id": "05303",
        "title": "Model-sharing Games: Analyzing Federated Learning Under Voluntary Participation",
        "track": "main",
        "status": "Poster",
        "abstract": "Federated learning is a setting where agents, each with access to their own data source, combine models learned from local data to create a global model. If agents are drawing their data from different distributions, though, federated learning might produce a biased global model that is not optimal for each agent. This means that agents face\u00a0a fundamental question: should they join the global model or stay with their local model? In this work, we show how this situation can be naturally analyzed through the framework of coalitional game theory.\u00a0  Motivated by these considerations, we propose the following game:\u00a0there are heterogeneous players with\u00a0different model parameters\u00a0governing their data distribution and different amounts of data they have noisily drawn from their own distribution. Each player's goal is to obtain a model with minimal expected mean squared error (MSE) on their own distribution. They have a choice of fitting a model based solely on their own data, or combining their learned parameters with those of some subset of the other players. Combining models reduces the variance component of their error through access to more data, but increases the bias because of the heterogeneity of distributions. In this work, we derive exact expected MSE values for problems in linear regression and mean estimation. We use these values to analyze the resulting game in the framework of hedonic game theory; we study how players might divide into coalitions, where each set of players within a coalition jointly constructs a single model.\u00a0 In a case with arbitrarily many players that each have either a \"small\" or \"large\" amount of data, we constructively show that there always exists a stable partition of players into coalitions.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Kate Donahue; Jon Kleinberg",
        "authorids": "",
        "aff": "Cornell University; Cornell University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16669/16669-13-20163-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05303-model-sharing-games-analyzing-federated-learning-under-voluntary-participation/",
        "doi": "10.1609/aaai.v35i6.16669",
        "pdf_size": 142255
    },
    {
        "id": "01593",
        "title": "Modeling Deep Learning Based Privacy Attacks on Physical Mail",
        "track": "main",
        "status": "Poster",
        "abstract": "Mail privacy protection aims to prevent unauthorized access to hidden content within an envelope since normal paper envelopes are not as safe as we think. In this paper, for the first time, we show that with a well designed deep learning model, the hidden content may be largely recovered without opening the envelope. We start by modeling deep learning-based privacy attacks on physical mail content as learning the mapping from the camera-captured envelope front face image to the hidden content, then we explicitly model the mapping as a combination of perspective transformation, image dehazing and denoising using a deep convolutional neural network, named Neural-STE (See-Through-Envelope). We show experimentally that hidden content details, such as texture and image structure, can be clearly recovered. Finally, our formulation and model allow us to design envelopes that can counter deep learning-based privacy attacks on physical mail.",
        "primary_area": "Computer Vision I",
        "author": "Bingyao Huang; Ruyi Lian; Dimitris Samaras; Haibin Ling",
        "authorids": "",
        "aff": "Stony Brook University; Stony Brook University; Stony Brook University; Stony Brook University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16251/16251-13-19745-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01593-modeling-deep-learning-based-privacy-attacks-on-physical-mail/",
        "doi": "10.1609/aaai.v35i2.16251",
        "pdf_size": 1966407
    },
    {
        "id": "04723",
        "title": "Modeling Heterogeneous Relations across Multiple Modes for Potential Crowd Flow Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "Potential crowd flow prediction for new planned transportation\u00a0sites is a fundamental task for urban planners and administrators. Intuitively, the potential crowd flow of the new coming\u00a0site can be implied by exploring the nearby sites. However, the transportation modes of nearby sites (e.g. bus stations,\u00a0bicycle stations) might be different from the target site (e.g. subway station), which results in severe data scarcity issues. To this end, we propose a data-driven approach, named MOHER, to predict the potential crowd flow in a certain mode for a new planned site. Specifically, we first identify the neighbor regions of the target site by examining the geographical proximity as well as the urban function similarity. Then, to aggregate these heterogeneous relations, we devise a cross-mode relational GCN, a novel relation-specific transformation model, which can learn not only the correlation but also the differences between different transportation modes. Afterward, we design an aggregator for inductive potential flow representation. Finally, an LTSM module is used for sequential flow prediction. Extensive experiments on real-world data sets demonstrate the superiority of the MOHER framework compared\u00a0with the state-of-the-art algorithms.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Qiang Zhou; Jingjing Gu; Xinjiang Lu; Fuzhen Zhuang; Yanchao Zhao; Qiuhong Wang; Xiao Zhang",
        "authorids": "",
        "aff": "Nanjing University of Aeronautics and Astronautics; Nanjing University of Aeronautics and Astronautics; Business Intelligence Lab, Baidu Research; Key Lab of IntelligentInformation Processing of Chinese Academy of Sciences (CAS), ICT, Beijing, China University of Chinese Academy ofSciences, Beijing, China; Nanjing University of Aeronautics and Astronautics; Nanjing University of Aeronautics and Astronautics; Shandong University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16603/16603-13-20097-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04723-modeling-heterogeneous-relations-across-multiple-modes-for-potential-crowd-flow-prediction/",
        "doi": "10.1609/aaai.v35i5.16603",
        "pdf_size": 2969190
    },
    {
        "id": "05709",
        "title": "Modeling Voters in Multi-Winner Approval Voting",
        "track": "main",
        "status": "Poster",
        "abstract": "In many real world situations, collective decisions are made using voting and, in scenarios such as committee or board elections, employing voting rules that return multiple winners. In multi-winner approval voting (AV), an agent submits a ballot consisting of approvals for as many candidates as they wish, and winners are chosen by tallying up the votes and choosing the top-k candidates receiving the most approvals. In many scenarios, an agent may manipulate the ballot they submit in order to achieve a better outcome by voting in a way that does not reflect their true preferences. In complex and uncertain situations, agents may use heuristics instead of incurring the additional effort required to compute the manipulation which most favors them. In this paper, we examine voting behavior in single-winner and multi-winner approval voting scenarios with varying degrees of uncertainty using behavioral data obtained from Mechanical Turk. We find that people generally manipulate their vote to obtain a better outcome, but often do not identify the optimal manipulation. There are a number of predictive models of agent behavior in the social choice and psychology literature that are based on cognitively plausible heuristic strategies.  We show that the existing approaches do not adequately model our real-world data. We propose a novel model that takes into account the size of the winning set and human cognitive constraints; and demonstrate that this model is more effective at capturing real-world behaviors in multi-winner approval voting scenarios.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Jaelle Scheuerman; Jason Harman; Nicholas Mattei; K. Brent Venable",
        "authorids": "",
        "aff": "U.S. Naval Research Laboratory, Stennis Space Center, MS, USA; U.S. Naval Research Laboratory and Louisiana State University, Baton Rouge, LA, USA; Tulane University, New Orleans, LA, USA; University of West Florida and Institute for Human and Machine Cognition, Pensacola, FL, USA",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16716/16716-13-20210-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05709-modeling-voters-in-multi-winner-approval-voting/",
        "doi": "10.1609/aaai.v35i6.16716",
        "pdf_size": 300045
    },
    {
        "id": "00187",
        "title": "Modeling the Compatibility of Stem Tracks to Generate Music Mashups",
        "track": "main",
        "status": "Poster",
        "abstract": "A music mashup combines audio elements from two or more songs to create a new work. To reduce the time and effort required to make them, researchers have developed algorithms that predict the compatibility of audio elements. Prior work has focused on mixing unaltered excerpts, but advances in source separation enable the creation of mashups from isolated stems (e.g., vocals, drums, bass, etc.). In this work, we take advantage of separated stems not just for creating mashups, but for training a model that predicts the mutual compatibility of groups of excerpts, using self-supervised and semi-supervised methods. Specifically, we first produce a random mashup creation pipeline that combines stem tracks obtained via source separation, with key and tempo automatically adjusted to match, since these are prerequisites for high-quality mashups. To train a model to predict compatibility, we use stem tracks obtained from the same song as positive examples, and random combinations of stems with key and/or tempo unadjusted as negative examples. To improve the model and use more data, we also train on \"average\" examples: random combinations with matching key and tempo, where we treat them as unlabeled data as their true compatibility is unknown. To determine whether the combined signal or the set of stem signals is more indicative of the quality of the result, we experiment on two model architectures and train them using semi-supervised learning technique. Finally, we conduct objective and subjective evaluations of the system, comparing them to a standard rule-based system.",
        "primary_area": "Application Domains",
        "author": "Jiawen Huang; Ju-Chiang Wang; Jordan B. L. Smith; Xuchen Song; Yuxuan Wang",
        "authorids": "",
        "aff": "Queen Mary University of London; ByteDance; ByteDance; ByteDance; ByteDance",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16092/16092-13-19586-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00187-modeling-the-compatibility-of-stem-tracks-to-generate-music-mashups/",
        "doi": "10.1609/aaai.v35i1.16092",
        "pdf_size": 1966646
    },
    {
        "id": "00055",
        "title": "Modeling the Momentum Spillover Effect for Stock Prediction via Attribute-Driven Graph Attention Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "In finance, the momentum spillovers of listed firms is well acknowledged. Only few studies predicted the trend of one firm in terms of its relevant firms. A common strategy of the pilot work is to adopt graph convolution networks (GCNs) with some predefined firm relations. However, momentum spillovers are propagated via a variety of firm relations, of which the bridging importance varies with time. Restricting to several predefined relations inevitably makes noise and thus misleads stock predictions. In addition, traditional GCNs transfer and aggregate the peer influences without considering the states of both connected firms once a connection is built. Such non-attribute sensibility makes traditional GCNs inappropriate to deal with the attribute-sensitive momentum spillovers of listed firms wherein the abnormal price drop of one firm may not spill over if the trade volume of this decreasing price is small or the prices of the linked firms are undervalued. In this study, we propose an attribute-driven graph attention network (AD-GAT) to address both problems in modeling momentum spillovers. This is achieved by element-wisely multiplying the nonlinear transformation of the attributes of the connected firms with the attributes of the source firm to consider its attribute-sensitive momentum spillovers, and applying the unmasked attention mechanism to infer the general dynamic firm relation from observed market signals fused by a novel tensor-based feature extractor. Experiments on the three-year data of the S&P 500 demonstrate the superiority of the proposed framework over stateof-the-art algorithms, including GCN, eLSTM, and TGC.",
        "primary_area": "Application Domains",
        "author": "Rui Cheng; Qing Li",
        "authorids": "",
        "aff": "Fintech Innovation Center School of Economic Information Engineering Southwestern University of Finance and Economics; Fintech Innovation Center School of Economic Information Engineering Southwestern University of Finance and Economics",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16077/16077-13-19571-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00055-modeling-the-momentum-spillover-effect-for-stock-prediction-via-attribute-driven-graph-attention-networks/",
        "doi": "10.1609/aaai.v35i1.16077",
        "pdf_size": 327554
    },
    {
        "id": "01246",
        "title": "Modeling the Probabilistic Distribution of Unlabeled Data for One-shot Medical Image Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "Existing image segmentation networks mainly leverage large-scale labeled datasets to attain high accuracy. However, labeling medical images is very expensive since it requires sophisticated expert knowledge. Thus, it is more desirable to employ only a few labeled data in pursuing high segmentation performance. In this paper, we develop a data augmentation method for one-shot brain magnetic resonance imaging (MRI) image segmentation which exploits only one labeled MRI image (named atlas) and a few unlabeled images. In particular, we propose to learn the probability distributions of deformations (including shapes and intensities) of different unlabeled MRI images with respect to the atlas via 3D variational autoencoders (VAEs). In this manner, our method is able to exploit the learned distributions of image deformations to generate new authentic brain MRI images, and the number of generated samples will be sufficient to train a deep segmentation network. Furthermore, we introduce a new standard segmentation benchmark to evaluate the generalization performance of a segmentation network through a cross-dataset setting (collected from different sources). Extensive experiments demonstrate that our method outperforms the state-of-the-art one-shot medical segmentation methods. Our code has been released at https://github.com/dyh127/Modeling-the-Probabilistic-Distribution-of-Unlabeled-Data.",
        "primary_area": "Computer Vision I",
        "author": "Yuhang Ding; Xin Yu; Yi Yang",
        "authorids": "",
        "aff": "Baidu Research, China; ReLER, University of Technology Sydney, Australia; ReLER, University of Technology Sydney, Australia",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16212/16212-13-19706-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01246-modeling-the-probabilistic-distribution-of-unlabeled-data-for-one-shot-medical-image-segmentation/",
        "doi": "10.1609/aaai.v35i2.16212",
        "pdf_size": 1790193
    },
    {
        "id": "09092",
        "title": "Modular Graph Transformer Networks for Multi-Label Image Classification",
        "track": "main",
        "status": "Poster",
        "abstract": "With the recent advances in graph neural networks, there is a rising number of studies on graph-based multi-label classification with the consideration of object dependencies within visual data. Nevertheless, graph representations can become indistinguishable due to the complex nature of label relationships. We propose a multi-label image classification framework based on graph transformer networks to fully exploit inter-label interactions. The paper presents a modular learning scheme to enhance the classification performance by segregating the computational graph into multiple sub-graphs based on modularity. The proposed approach, named Modular Graph Transformer Networks (MGTN), is capable of employing multiple backbones for better information propagation over different sub-graphs guided by graph transformers and convolutions. We validate our framework on MS-COCO and Fashion550K datasets to demonstrate improvements for multi-label image classification. The source code is available at https://github.com/ReML-AI/MGTN.",
        "primary_area": "Machine Learning III",
        "author": "Hoang D. Nguyen; Xuan-Son Vu; Duc-Trong Le",
        "authorids": "",
        "aff": "University of Glasgow; Ume\u00e5 University; Vietnam National University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17098/17098-13-20592-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09092-modular-graph-transformer-networks-for-multi-label-image-classification/",
        "doi": "10.1609/aaai.v35i10.17098",
        "pdf_size": 2451058
    },
    {
        "id": "08226",
        "title": "MolGrow: A Graph Normalizing Flow for Hierarchical Molecular Generation",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a hierarchical normalizing flow model for generating molecular graphs. The model produces new molecular structures from a single-node graph by recursively splitting every node into two. All operations are invertible and can be used as plug-and-play modules. The hierarchical nature of the latent codes allows for precise changes in the resulting graph: perturbations in the first layer cause global structural changes, while perturbations in the consequent layers change the resulting molecule only marginally. Proposed model outperforms existing generative graph models on the distribution learning task. We also show successful experiments on global and constrained optimization of chemical properties using latent codes of the model.",
        "primary_area": "Machine Learning II",
        "author": "Maksim Kuznetsov; Daniil Polykovskiy",
        "authorids": "",
        "aff": "Insilico Medicine; Insilico Medicine",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17001/17001-13-20495-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08226-molgrow-a-graph-normalizing-flow-for-hierarchical-molecular-generation/",
        "doi": "10.1609/aaai.v35i9.17001",
        "pdf_size": 1307768
    },
    {
        "id": "12821",
        "title": "More the Merrier: Towards Multi-Emotion and Intensity Controllable Response Generation",
        "track": "main",
        "status": "Poster",
        "abstract": "The focus on conversational systems has recently shifted towards creating engaging agents by inculcating emotions into them. Human emotions are highly complex as humans can express multiple emotions with varying intensity in a single utterance, whereas the conversational agents convey only one emotion in their responses. To infuse human-like behaviour in the agents, we introduce the task of multi-emotion controllable response generation with the ability to express different emotions with varying levels of intensity in an open-domain dialogue system. We introduce a Multiple Emotion Intensity aware Multi-party Dialogue (MEIMD) dataset having 34k conversations taken from 8 different TV Series. We finally propose a Multiple Emotion with Intensity-based Dialogue Generation (MEI-DG) framework. The system employs two novel mechanisms: viz. (i) determining the trade-off between the emotion and generic words,  while focusing on the intensity of the desired emotions; and (ii) computing the amount of emotion left to be expressed, thereby regulating the generation accordingly. The detailed evaluation shows that our proposed approach attains superior performance compared to the baseline models.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Mauajama Firdaus; Hardik Chauhan; Asif Ekbal; Pushpak Bhattacharyya",
        "authorids": "",
        "aff": "Indian Institute of Technology Patna; Indian Institute of Technology Patna; Indian Institute of Technology Patna; Indian Institute of Technology Patna",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17517/17517-13-21011-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12821-more-the-merrier-towards-multi-emotion-and-intensity-controllable-response-generation/",
        "doi": "10.1609/aaai.v35i14.17517",
        "pdf_size": 225158
    },
    {
        "id": "00901",
        "title": "Motion-blurred Video Interpolation and Extrapolation",
        "track": "main",
        "status": "Poster",
        "abstract": "Abrupt motion of camera or objects in a scene result in a blurry video, and therefore recovering high quality video requires two types of enhancements: visual enhancement and temporal upsampling. A broad range of research attempted to recover clean frames from blurred image sequences or temporally upsample frames by interpolation, yet there are very limited studies handling both problems jointly. In this work, we present a novel framework for deblurring, interpolating and extrapolating sharp frames from a motion-blurred video in an end-to-end manner. We design our framework by first learning the pixel-level motion that caused the blur from the given inputs via optical flow estimation and then predict multiple clean frames by warping the decoded features with the estimated flows. To ensure temporal coherence across predicted frames and address potential temporal ambiguity, we propose a simple, yet effective flow-based rule. The effectiveness and favorability of our approach are highlighted through extensive qualitative and quantitative evaluations on motion-blurred datasets from high speed videos.",
        "primary_area": "Computer Vision I",
        "author": "Dawit Mureja Argaw; Junsik Kim; Francois Rameau; In So Kweon",
        "authorids": "",
        "aff": "KAIST Robotics and Computer Vision Lab., Daejeon, Korea; KAIST Robotics and Computer Vision Lab., Daejeon, Korea; KAIST Robotics and Computer Vision Lab., Daejeon, Korea; KAIST Robotics and Computer Vision Lab., Daejeon, Korea",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16173/16173-13-19667-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00901-motion-blurred-video-interpolation-and-extrapolation/",
        "doi": "10.1609/aaai.v35i2.16173",
        "pdf_size": 3434861
    },
    {
        "id": "13631",
        "title": "Movie Summarization via Sparse Graph Construction",
        "track": "main",
        "status": "Poster",
        "abstract": "We summarize full-length movies by creating shorter videos containing their most informative scenes. We explore the hypothesis that a summary can be created by assembling scenes which are turning points (TPs), i.e., key events in a movie that describe its storyline. We propose a model that identifies TP scenes by building a sparse movie graph that represents relations between scenes and is constructed using multimodal information. According to human judges, the summaries created by our approach are more informative and complete, and receive higher ratings, than the outputs of sequence-based models and general-purpose summarization algorithms. The induced graphs are interpretable, displaying different topology for different movie genres.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Pinelopi Papalampidi; Frank Keller; Mirella Lapata",
        "authorids": "",
        "aff": "University of Edinburgh; University of Edinburgh; University of Edinburgh",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17607/17607-13-21101-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13631-movie-summarization-via-sparse-graph-construction/",
        "doi": "10.1609/aaai.v35i15.17607",
        "pdf_size": 332592
    },
    {
        "id": "12042",
        "title": "Multi-Decoder Attention Model with Embedding Glimpse for Solving Vehicle Routing Problems",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a novel deep reinforcement learning method to learn construction heuristics for vehicle routing problems. In specific, we propose a Multi-Decoder Attention Model (MDAM) to train multiple diverse policies, which effectively increases the chance of finding good solutions compared with existing methods that train only one policy. A customized beam search strategy is designed to fully exploit the diversity of MDAM. In addition, we propose an Embedding Glimpse layer in MDAM based on the recursive nature of construction, which can improve the quality of each policy by providing more informative embeddings. Extensive experiments on six different routing problems show that our method significantly outperforms the state-of-the-art deep learning based models.",
        "primary_area": "Planning, Routing, and Scheduling",
        "author": "Liang Xin; Wen Song; Zhiguang Cao; Jie Zhang",
        "authorids": "",
        "aff": "Nanyang Technological University, Singapore; Shandong University, China; National University of Singapore, Singapore; Nanyang Technological University, Singapore",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17430/17430-13-20924-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12042-multi-decoder-attention-model-with-embedding-glimpse-for-solving-vehicle-routing-problems/",
        "doi": "10.1609/aaai.v35i13.17430",
        "pdf_size": 316483
    },
    {
        "id": "12507",
        "title": "Multi-Dimensional Explanation of Target Variables from Documents",
        "track": "main",
        "status": "Poster",
        "abstract": "Automated predictions require explanations to be interpretable by humans. Past work used attention and rationale mechanisms to find words that predict the target variable of a document. Often though, they result in a tradeoff between noisy explanations or a drop in accuracy. Furthermore, rationale methods cannot capture the multi-faceted nature of justifications for multiple targets, because of the non-probabilistic nature of the mask. In this paper, we propose the Multi-Target Masker (MTM) to address these shortcomings. The novelty lies in the soft multi-dimensional mask that models a relevance probability distribution over the set of target variables to handle ambiguities. Additionally, two regularizers guide MTM to induce long, meaningful explanations. We evaluate MTM on two datasets and show, using standard metrics and human annotations, that the resulting masks are more accurate and coherent than those generated by the state-of-the-art methods. Moreover, MTM is the first to also achieve the highest F1 scores for all the target variables simultaneously.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Diego Antognini; Claudiu Musat; Boi Faltings",
        "authorids": "",
        "aff": "\u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne; Swisscom; \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17483/17483-13-20977-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12507-multi-dimensional-explanation-of-target-variables-from-documents/",
        "doi": "10.1609/aaai.v35i14.17483",
        "pdf_size": 362715
    },
    {
        "id": "14221",
        "title": "Multi-Document Transformer for Personality Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Personality detection aims to identify the personality traits implied in social media posts. The core of this task is to put together information in multiple scattered posts to depict an overall personality profile for each user. Existing approaches either encode each post individually or assemble posts arbitrarily into a new document that can be encoded sequentially or hierarchically. While the first approach ignores the connection between posts, the second tends to introduce unnecessary post-order bias into posts. In this paper, we propose a multi-document Transformer, namely Transformer-MD, to tackle the above issues. When encoding each post, Transformer-MD allows access to information in the other posts of the user through Transformer-XL\u2019s memory tokens which share the same position embedding.Besides, personality is usually defined along different traits and each trait may need to attend to different post information, which has rarely been touched by existing research. To address this concern, we propose a dimension attention mechanism on top of Transformer-MD to obtain trait-specific representations for multi-trait personality detection. We evaluate the proposed model on the Kaggle and Pandora MBTI datasets and the experimental results show that it compares favorably with baseline methods.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Feifan Yang; Xiaojun Quan; Yunyi Yang; Jianxing Yu",
        "authorids": "",
        "aff": "Sun Yat-sen University; Sun Yat-sen University; Sun Yat-sen University; Sun Yat-sen University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17673/17673-13-21167-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14221-multi-document-transformer-for-personality-detection/",
        "doi": "10.1609/aaai.v35i16.17673",
        "pdf_size": 511666
    },
    {
        "id": "08819",
        "title": "Multi-Domain Multi-Task Rehearsal for Lifelong Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Rehearsal, seeking to remind the model by storing old knowledge in lifelong learning, is one of the most effective ways to mitigate catastrophic forgetting, i.e., biased forgetting of previous knowledge when moving to new tasks. However, the old tasks of the most previous rehearsal-based methods suffer from the unpredictable domain shift when training the new task. This is because these methods always ignore two significant factors. First, the Data Imbalance between the new task and old tasks that makes the domain of old tasks prone to shift. Second, the Task Isolation among all tasks will make the domain shift toward unpredictable directions; To address the unpredictable domain shift, in this paper, we propose Multi-Domain Multi-Task (MDMT) rehearsal to train the old tasks and new task parallelly and equally to break the isolation among tasks. Specifically, a two-level angular margin loss is proposed to encourage the intra-class/task compactness and inter-class/task discrepancy, which keeps the model from domain chaos. In addition, to further address domain shift of the old tasks, we propose an optional episodic distillation loss on the memory to anchor the knowledge for each old task. Experiments on benchmark datasets validate the proposed approach can effectively mitigate the unpredictable domain shift.",
        "primary_area": "Machine Learning III",
        "author": "Fan Lyu; Shuai Wang; Wei Feng; Zihan Ye; Fuyuan Hu; Song Wang",
        "authorids": "",
        "aff": "College of Intelligence and Computing, Tianjin University; College of Intelligence and Computing, Tianjin University; College of Intelligence and Computing, Tianjin University; School of Electronic & Information Engineering, Suzhou University of Science and Technology; School of Electronic & Information Engineering, Suzhou University of Science and Technology; Department of Computer Science and Engineering, University of South Carolina",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17068/17068-13-20562-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08819-multi-domain-multi-task-rehearsal-for-lifelong-learning/",
        "doi": "10.1609/aaai.v35i10.17068",
        "pdf_size": 12276082
    },
    {
        "id": "12409",
        "title": "Multi-Goal Multi-Agent Path Finding via Decoupled and Integrated Goal Vertex Ordering",
        "track": "main",
        "status": "Poster",
        "abstract": "We introduce multi-goal multi agent path finding (MG-MAPF) which generalizes the standard discrete multi-agent path finding (MAPF) problem. While the task in MAPF is to navigate agents in an undirected graph from their starting vertices to one individual goal vertex per agent, MG-MAPF assigns each agent multiple goal vertices and the task is to visit each of them at least once. Solving MG-MAPF not only requires finding collision free paths for individual agents but also determining the order of visiting agent's goal vertices so that common objectives like the sum-of-costs are optimized. We suggest two novel algorithms using different paradigms to address  MG-MAPF: a heuristic search-based algorithm called Hamiltonian-CBS (HCBS) and a compilation-based algorithm built using the satisfiability modulo theories (SMT), called SMT-Hamiltonian-CBS (SMT-HCBS).",
        "primary_area": "Search and Optimization",
        "author": "Pavel Surynek",
        "authorids": "",
        "aff": "Czech Technical University in Prague",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17472/17472-13-20966-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12409-multi-goal-multi-agent-path-finding-via-decoupled-and-integrated-goal-vertex-ordering/",
        "doi": "10.1609/aaai.v35i14.17472",
        "pdf_size": 684073
    },
    {
        "id": "12302",
        "title": "Multi-Objective Submodular Maximization by Regret Ratio Minimization with Theoretical Guarantee",
        "track": "main",
        "status": "Poster",
        "abstract": "Submodular maximization has attracted much attention due to its wide application and attractive property. Previous works mainly considered one single objective function, while there can be multiple ones in practice. As the objectives are usually conflicting, there exists a set of Pareto optimal solutions, attaining different optimal trade-offs among multiple objectives. In this paper, we consider the problem of minimizing the regret ratio in multi-objective submodular maximization, which is to find at most k solutions to approximate the whole Pareto set as well as possible. We propose a new algorithm RRMS by sampling representative weight vectors and solving the corresponding weighted sums of objective functions using some given alpha-approximation algorithm for single-objective submodular maximization. We prove that the regret ratio of the output of RRMS is upper bounded by 1-alpha+O(sqrt{d-1}cdot(frac{d}{k-d})^{frac{1}{d-1}}), where d is the number of objectives. This is the first theoretical guarantee for the situation with more than two objectives. When d=2, it reaches the (1-alpha+O(1/k))-guarantee of the only existing algorithm Polytope. Empirical results on the applications of multi-objective weighted maximum coverage and Max-Cut show the superior performance of RRMS over Polytope.",
        "primary_area": "Search and Optimization",
        "author": "Chao Feng; Chao Qian",
        "authorids": "",
        "aff": "Nanjing University University of Science and Technology of China; Nanjing University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17460/17460-13-20954-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12302-multi-objective-submodular-maximization-by-regret-ratio-minimization-with-theoretical-guarantee/",
        "doi": "10.1609/aaai.v35i14.17460",
        "pdf_size": 1200950
    },
    {
        "id": "05506",
        "title": "Multi-Party Campaigning",
        "track": "main",
        "status": "Poster",
        "abstract": "We study a social choice setting of manipulation in elections and extend the usual model in two major ways: first, instead of considering a single manipulating agent, in our setting there are several, possibly competing ones; second, instead of evaluating an election after the first manipulative action, we allow several back-and-forth rounds to take place. We show that in certain situations, such as in elections with only a few candidates, optimal strategies for each of the manipulating agents can be computed efficiently. Our algorithmic results rely on formulating the problem of finding an optimal strategy as sentences of Presburger arithmetic that are short and only involve small coefficients, which we show is fixed-parameter tractable -- indeed, one of our contributions is a general result regarding fixed-parameter tractability of Presburger arithmetic that might be useful in other settings. Following our general theorem, we design quite general algorithms; in particular, we describe how to design efficient algorithms for various settings, including settings in which we model diffusion of opinions in a social network, complex budgeting schemes available to the manipulating agents, and various realistic restrictions on adversary actions.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Martin Kouteck\u00fd; Nimrod Talmon",
        "authorids": "",
        "aff": "Charles University; Ben-Gurion University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16693/16693-13-20187-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05506-multi-party-campaigning/",
        "doi": "10.1609/aaai.v35i6.16693",
        "pdf_size": 140878
    },
    {
        "id": "08618",
        "title": "Multi-Proxy Wasserstein Classifier for Image Classification",
        "track": "main",
        "status": "Poster",
        "abstract": "Most widely-used convolutional neural networks (CNNs) end up with a global average pooling layer and a fully-connected layer. In this pipeline, a certain class is represented by one template vector preserved in the feature banks of fully-connected layer. Yet, a class may have multiple properties useful for recognition while the above formulation only captures one of them. Therefore, it is desired to represent a class by multiple proxies. However, directly adding multiple linear layers turns out to be a trivial solution as no improvement can be observed. To tackle this problem, we adopt optimal transport theory to calculate a non-uniform matching flow between the elements in the feature map of a sample and the proxies of a class in a closed way. By doing so, the models are enabled to achieve partial matching as both the feature maps and the proxy set can now focus on a subset of elements from the counterpart. Such formulation also enables us to embed the samples into the Wasserstein metric space, which has many advantages over the original Euclidean space. This formulation can be achieved by a lightweight iterative algorithm, which can be easily embedded into the automatic differentiation framework. Empirical studies are performed on two widely-used classification datasets, CIFAR, and ILSVRC2012, and the substantial improvements on these two benchmarks demonstrate the effectiveness of our method.",
        "primary_area": "Machine Learning III",
        "author": "Benlin Liu; Yongming Rao; Jiwen Lu; Jie Zhou; Cho-Jui Hsieh",
        "authorids": "",
        "aff": "UCLA; Tsinghua University; Tsinghua University; Tsinghua University; UCLA",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17045/17045-13-20539-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08618-multi-proxy-wasserstein-classifier-for-image-classification/",
        "doi": "10.1609/aaai.v35i10.17045",
        "pdf_size": 195051
    },
    {
        "id": "05497",
        "title": "Multi-Scale Games: Representing and Solving Games on Networks with Group Structure",
        "track": "main",
        "status": "Poster",
        "abstract": "Network games provide a natural machinery to compactly represent strategic interactions among agents whose payoffs exhibit sparsity in their dependence on the actions of others. Besides encoding interaction sparsity, however, real networks often exhibit a multi-scale structure, in which agents can be grouped into communities, those communities further grouped, and so on, and where interactions among such groups may also exhibit sparsity. We present a general model of multi-scale network games that encodes such multi-level structure. We then develop several algorithmic approaches that leverage this multi-scale structure, and derive sufficient conditions for convergence of these to a Nash equilibrium. Our numerical experiments demonstrate that the proposed approaches enable orders of magnitude improvements in scalability when computing Nash equilibria in such games. For example, we can solve previously intractable instances involving up to 1 million agents in under 15 minutes.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Kun Jin; Yevgeniy Vorobeychik; Mingyan Liu",
        "authorids": "",
        "aff": "University of Michigan, Ann Arbor; Washington University in St. Louis; University of Michigan, Ann Arbor",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16692/16692-13-20186-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05497-multi-scale-games-representing-and-solving-games-on-networks-with-group-structure/",
        "doi": "10.1609/aaai.v35i6.16692",
        "pdf_size": 207410
    },
    {
        "id": "01113",
        "title": "Multi-Scale Spatial Temporal Graph Convolutional Network for Skeleton-Based Action Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "Graph convolutional networks have been widely used for skeleton-based action recognition due to their excellent modeling ability of non-Euclidean data. As the graph convolution is a local operation, it can only utilize the short-range joint dependencies and short-term trajectory but fails to directly model the distant joints relations and long-range temporal information that are vital to distinguishing various actions. To solve this problem, we present a multi-scale spatial graph convolution (MS-GC) module and a multi-scale temporal graph convolution (MT-GC) module to enrich the receptive field of the model in spatial and temporal dimensions.  Concretely, the MS-GC and MT-GC modules decompose the corresponding local graph convolution into a set of sub-graph convolution, forming a hierarchical residual architecture. Without introducing additional parameters, the features will be processed with a series of sub-graph convolutions, and each node could complete multiple spatial and temporal aggregations with its neighborhoods. The final equivalent receptive field is accordingly enlarged, which is capable of capturing both short- and long-range dependencies in spatial and temporal domains. By coupling these two modules as a basic block, we further propose a multi-scale spatial temporal graph convolutional network (MST-GCN), which stacks multiple blocks to learn effective motion representations for action recognition. The proposed MST-GCN achieves remarkable performance on three challenging benchmark datasets, NTU RGB+D, NTU-120 RGB+D and Kinetics-Skeleton, for skeleton-based action recognition.",
        "primary_area": "Computer Vision I",
        "author": "Zhan Chen; Sicheng Li; Bing Yang; Qinghan Li; Hong Liu",
        "authorids": "",
        "aff": "Peking University Shenzhen Graduate School; Zhejiang University; Peking University Shenzhen Graduate School; Syracuse University; Peking University Shenzhen Graduate School",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16197/16197-13-19691-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01113-multi-scale-spatial-temporal-graph-convolutional-network-for-skeleton-based-action-recognition/",
        "doi": "10.1609/aaai.v35i2.16197",
        "pdf_size": 426234
    },
    {
        "id": "13198",
        "title": "Multi-SpectroGAN: High-Diversity and High-Fidelity Spectrogram Generation with Adversarial Style Combination for Speech Synthesis",
        "track": "main",
        "status": "Poster",
        "abstract": "While generative adversarial networks (GANs) based neural text-to-speech (TTS) systems have shown significant improvement in neural speech synthesis, there is no TTS system to learn to synthesize speech from text sequences with only adversarial feedback. Because adversarial feedback alone is not sufficient to train the generator, current models still require the reconstruction loss compared with the ground-truth and the generated mel-spectrogram directly. In this paper, we present Multi-SpectroGAN (MSG), which can train the multi-speaker model with only the adversarial feedback by conditioning a self-supervised hidden representation of the generator to a conditional discriminator. This leads to better guidance for generator training. Moreover, we also propose  adversarial style combination (ASC) for better generalization in the unseen speaking style and transcript, which can learn latent representations of the combined style embedding from multiple mel-spectrograms. Trained with ASC and feature matching, the MSG synthesizes a high-diversity mel-spectrogram by controlling and mixing the individual speaking styles (e.g., duration, pitch, and energy). The result shows that the MSG synthesizes a high-fidelity mel-spectrogram, which has almost the same naturalness MOS score as the ground-truth mel-spectrogram.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Sang-Hoon Lee; Hyun-Wook Yoon; Hyeong-Rae Noh; Ji-Hoon Kim; Seong-Whan Lee",
        "authorids": "",
        "aff": "Korea University; Korea University; Korea University; Korea University; Korea University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17559/17559-13-21053-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13198-multi-spectrogan-high-diversity-and-high-fidelity-spectrogram-generation-with-adversarial-style-combination-for-speech-synthesis/",
        "doi": "10.1609/aaai.v35i14.17559",
        "pdf_size": 779324
    },
    {
        "id": "10496",
        "title": "Multi-Task Recurrent Modular Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider the models of deep multi-task learning with recurrent architectures that exploit regularities across tasks to improve the performance of multiple sequence processing tasks jointly. Most existing architectures are painstakingly customized to learn task relationships for different problems, which is not flexible enough to model the dynamic task relationships and lacks generalization abilities to novel test-time scenarios. We propose multi-task recurrent modular networks (MT-RMN) that can be incorporated in any multi-task recurrent models to address the above drawbacks. MT-RMN consists of a shared encoder and multiple task-specific decoders, and recurrently operates over time. For better flexibility, it modularizes the encoder into multiple layers of sub-networks and dynamically controls the connection between these sub-networks and the decoders at different time steps, which provides the recurrent networks with varying degrees of parameter sharing for tasks with dynamic relatedness. For the generalization ability, MT-RMN aims to discover a set of generalizable sub-networks in the encoder that are assembled in different ways for different tasks. The policy networks augmented with the differentiable routers are utilized to make the binary connection decisions between the sub-networks. The experimental results on three multi-task sequence processing datasets consistently demonstrate the effectiveness of MT-RMN.",
        "primary_area": "Machine Learning V",
        "author": "Dongkuan Xu; Wei Cheng; Xin Dong; Bo Zong; Wenchao Yu; Jingchao Ni; Dongjin Song; Xuchao Zhang; Haifeng Chen; Xiang Zhang",
        "authorids": "",
        "aff": "The Pennsylvania State University; NEC Laboratories America, Inc.; Rutgers University; NEC Laboratories America, Inc.; NEC Laboratories America, Inc.; NEC Laboratories America, Inc.; NEC Laboratories America, Inc.; NEC Laboratories America, Inc.; NEC Laboratories America, Inc.; The Pennsylvania State University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17256/17256-13-20750-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10496-multi-task-recurrent-modular-networks/",
        "doi": "10.1609/aaai.v35i12.17256",
        "pdf_size": 606070
    },
    {
        "id": "12812",
        "title": "Multi-View Feature Representation for Dialogue Generation with Bidirectional Distillation",
        "track": "main",
        "status": "Poster",
        "abstract": "Neural dialogue models suffer from low-quality responses when interacted in practice, demonstrating difficulty in generalization beyond training data. Recently, knowledge distillation has been used to successfully regularize the student by transferring knowledge from the teacher. However, the teacher and the student are trained on the same dataset and tend to learn similar feature representations, whereas the most general knowledge should be found through differences. The finding of general knowledge is further hindered by the unidirectional distillation, as the student should obey the teacher and may discard some knowledge that is truly general but refuted by the teacher. To this end, we propose a novel training framework, where the learning of general knowledge is more in line with the idea of reaching consensus, i.e., finding common knowledge that is beneficial to different yet all datasets through diversified learning partners. Concretely, the training task is divided into a group of subtasks with the same number of students. Each student assigned to one subtask not only is optimized on the allocated subtask but also imitates multi-view feature representation aggregated from other students (i.e., student peers), which induces students to capture common knowledge among different subtasks and alleviates the over-fitting of students on the allocated subtasks. To further enhance generalization, we extend the unidirectional distillation to the bidirectional distillation that encourages the student and its student peers to co-evolve by exchanging complementary knowledge with each other. Empirical results and analysis demonstrate that our training framework effectively improves the model generalization without sacrificing training efficiency.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Shaoxiong Feng; Xuancheng Ren; Kan Li; Xu Sun",
        "authorids": "",
        "aff": "School of Computer Science & Technology, Beijing Institute of Technology; MOE Key Laboratory of Computational Linguistics, School of EECS, Peking University; School of Computer Science & Technology, Beijing Institute of Technology; MOE Key Laboratory of Computational Linguistics, School of EECS, Peking University Center for Data Science, Peking University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17516/17516-13-21010-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12812-multi-view-feature-representation-for-dialogue-generation-with-bidirectional-distillation/",
        "doi": "10.1609/aaai.v35i14.17516",
        "pdf_size": 1097527
    },
    {
        "id": "10085",
        "title": "Multi-View Information-Bottleneck Representation Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "In real-world applications, clustering or classification can usually be improved by fusing information from different views. Therefore, unsupervised representation learning on multi-view data becomes a compelling topic in machine learning. In this paper, we propose a novel and flexible unsupervised multi-view representation learning model termed Collaborative Multi-View Information Bottleneck Networks (CMIB-Nets), which comprehensively explores the common latent structure and the view-specific intrinsic information, and discards the superfluous information in the data significantly improving the generalization capability of the model. Specifically, our proposed model relies on the information bottleneck principle to integrate the shared representation among different views and the view-specific representation of each view, prompting the multi-view complete representation and flexibly balancing the complementarity and consistency among multiple views. We conduct extensive experiments (including clustering analysis, robustness experiment, and ablation study) on real-world datasets, which empirically show promising generalization ability and robustness compared to state-of-the-arts.",
        "primary_area": "Machine Learning IV",
        "author": "Zhibin Wan; Changqing Zhang; Pengfei Zhu; Qinghua Hu",
        "authorids": "",
        "aff": "Tianjin University; Tianjin university Tianjin Key Lab of Machine Learning, Tianjin, China; Tianjin university Tianjin Key Lab of Machine Learning, Tianjin, China; Tianjin University Tianjin Key Lab of Machine Learning, Tianjin, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17210/17210-13-20704-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10085-multi-view-information-bottleneck-representation-learning/",
        "doi": "10.1609/aaai.v35i11.17210",
        "pdf_size": 752764
    },
    {
        "id": "08447",
        "title": "Multi-View Representation Learning with Manifold Smoothness",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-view representation learning attempts to learn a representation from multiple views and most existing methods are unsupervised. However, representation learned only from unlabeled data may not be discriminative enough for further applications (e.g., clustering and classification). For this reason, semi-supervised methods which could use unlabeled data along with the labeled data for multi-view representation learning need to be developed. Manifold information plays an important role in semi-supervised learning, but it has not been considered for multi-view representation learning. In this paper, we introduce the manifold smoothness into multi-view representation learning and propose MvDGAT which learns the representation and the intrinsic manifold simultaneously with graph attention network. Experiments conducted on real-world datasets reveal that our MvDGAT can achieve better performance than state-of-the-art methods.",
        "primary_area": "Machine Learning III",
        "author": "Shu Li; Wei Wang; Wen-Tao Li; Pan Chen",
        "authorids": "",
        "aff": "Nanjing University; Nanjing University; Nanjing University; Nanjing University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17026/17026-13-20520-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08447-multi-view-representation-learning-with-manifold-smoothness/",
        "doi": "10.1609/aaai.v35i10.17026",
        "pdf_size": 676258
    },
    {
        "id": "01827",
        "title": "Multi-level Distance Regularization for Deep Metric Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a novel distance-based regularization method for deep metric learning called Multi-level Distance Regularization (MDR).  MDR explicitly disturbs a learning procedure by regularizing pairwise distances between embedding vectors into multiple levels that represents a degree of similarity between a pair.  In the training stage, the model is trained with both MDR and an existing loss function of deep metric learning, simultaneously; the two losses interfere with the objective of each other, and it makes the learning process difficult.  Moreover, MDR prevents some examples from being ignored or overly influenced in the learning process. These allow the parameters of the embedding network to be settle on a local optima with better generalization. Without bells and whistles, MDR with simple Triplet loss achieves the-state-of-the-art performance in various benchmark datasets: CUB-200-2011, Cars-196, Stanford Online Products, and In-Shop Clothes Retrieval. We extensively perform ablation studies on its behaviors to show the effectiveness of MDR. By easily adopting our MDR, the previous approaches can be improved in performance and generalization ability.",
        "primary_area": "Computer Vision II",
        "author": "Yonghyun Kim; Wonpyo Park",
        "authorids": "",
        "aff": "Kakao Enterprise; Kakao Corporation",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16277/16277-13-19771-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01827-multi-level-distance-regularization-for-deep-metric-learning/",
        "doi": "10.1609/aaai.v35i3.16277",
        "pdf_size": 2872662
    },
    {
        "id": "14347",
        "title": "Multi-modal Graph Fusion for Named Entity Recognition with Targeted Visual Guidance",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-modal named entity recognition (MNER) aims to discover named entities in free text and classify them into pre-defined types with images. However, dominant MNER models do not fully exploit fine-grained semantic correspondences between semantic units of different modalities, which have the potential to refine multi-modal representation learning. To deal with this issue, we propose a unified multi-modal graph fusion (UMGF) approach for MNER. Specifically, we first represent the input sentence and image using a unified multi-modal graph, which captures various semantic relationships between multi-modal semantic units (words and visual objects). Then, we stack multiple graph-based multi-modal fusion layers that iteratively perform semantic interactions to learn node representations. Finally, we achieve an attention-based multi-modal representation for each word and perform entity labeling with a CRF decoder. Experimentation on the two benchmark datasets demonstrates the superiority of our MNER model.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Dong Zhang; Suzhong Wei; Shoushan Li; Hanqian Wu; Qiaoming Zhu; Guodong Zhou",
        "authorids": "",
        "aff": "Soochow University; Southeast University; Soochow University; Southeast University; Soochow University; Soochow University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17687/17687-13-21181-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14347-multi-modal-graph-fusion-for-named-entity-recognition-with-targeted-visual-guidance/",
        "doi": "10.1609/aaai.v35i16.17687",
        "pdf_size": 2756836
    },
    {
        "id": "14338",
        "title": "Multi-modal Multi-label Emotion Recognition with Heterogeneous Hierarchical Message Passing",
        "track": "main",
        "status": "Poster",
        "abstract": "As an important research issue in affective computing community, multi-modal emotion recognition has become a hot topic in the last few years. However, almost all existing studies perform multiple binary classification for each emotion with focus on complete time series data. In this paper, we focus on multi-modal emotion recognition in a multi-label scenario. In this scenario, we consider not only the label-to-label dependency, but also the feature-to-label and modality-to-label dependencies. Particularly, we propose a heterogeneous hierarchical message passing network to effectively model above dependencies. Furthermore, we propose a new multi-modal multi-label emotion dataset based on partial time-series content to show predominant generalization of our model. Detailed evaluation demonstrates the effectiveness of our approach.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Dong Zhang; Xincheng Ju; Wei Zhang; Junhui Li; Shoushan Li; Qiaoming Zhu; Guodong Zhou",
        "authorids": "",
        "aff": "Soochow University; Soochow University; Alibaba Group; Soochow University; Soochow University; Soochow University; Soochow University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17686/17686-13-21180-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14338-multi-modal-multi-label-emotion-recognition-with-heterogeneous-hierarchical-message-passing/",
        "doi": "10.1609/aaai.v35i16.17686",
        "pdf_size": 1036470
    },
    {
        "id": "07789",
        "title": "Multi-scale Graph Fusion for Co-saliency Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "The key challenge of co-saliency detection is to extract discriminative features to distinguish the common salient foregrounds from backgrounds in a group of relevant images. In this paper, we propose a new co-saliency detection framework which includes two strategies to improve the discriminative ability of the features. Specifically, on one hand, we segment each image to semantic superpixel clusters as well as generate different scales/sizes of images for each input image by the VGG-16 model. Different scales capture different patterns of the images. As a result, multi-scale images can capture various patterns among all images by many kinds of perspectives. Second, we propose a new method of Graph Convolutional Network (GCN) to fine-tune the multi-scale features, aiming at capturing the common information among the features from all scales and the private or complementary information for the feature of each scale. Moreover, the proposed GCN method jointly conducts multi-scale feature fine-tune, graph learning, and feature learning in a unified framework. We evaluated our method on three benchmark data sets, compared to state-of-the-art co-saliency detection methods. Experimental results showed that our method outperformed all comparison methods in terms of different evaluation metrics.",
        "primary_area": "Machine Learning II",
        "author": "Rongyao Hu; Zhenyun Deng; Xiaofeng Zhu",
        "authorids": "",
        "aff": "University of Electronic Science and Technology of China Massey University; University of Auckland; University of Electronic Science and Technology of China Massey University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16951/16951-13-20445-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07789-multi-scale-graph-fusion-for-co-saliency-detection/",
        "doi": "10.1609/aaai.v35i9.16951",
        "pdf_size": 1509282
    },
    {
        "id": "11088",
        "title": "Multi-task Learning by Leveraging the Semantic Information",
        "track": "main",
        "status": "Poster",
        "abstract": "One crucial objective of multi-task learning is to align distributions across tasks so that the information between them can be transferred and shared. However, existing approaches only focused on matching the marginal feature distribution while ignoring the semantic information, which may hinder the learning performance. To address this issue, we propose to leverage the label information in multi-task learning by exploring the semantic conditional relations among tasks. We first theoretically analyze the generalization bound of multi-task learning based on the notion of Jensen-Shannon divergence, which provides new insights into the value of label information in multi-task learning. Our analysis also leads to a concrete algorithm that jointly matches the semantic distribution and controls label distribution divergence. To confirm the effectiveness of the proposed method, we first compare the algorithm with several baselines on some benchmarks and then test the algorithms under label space shift conditions. Empirical results demonstrate that the proposed method could outperform most baselines and achieve state-of-the-art performance, particularly showing the benefits under the label shift conditions.",
        "primary_area": "Machine Learning V",
        "author": "Fan Zhou; Brahim Chaib-draa; Boyu Wang",
        "authorids": "",
        "aff": "Laval University; Laval University; University of Western Ontario Vector Institute",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17323/17323-13-20817-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11088-multi-task-learning-by-leveraging-the-semantic-information/",
        "doi": "10.1609/aaai.v35i12.17323",
        "pdf_size": 699486
    },
    {
        "id": "09515",
        "title": "Multi-type Disentanglement without Adversarial Training",
        "track": "main",
        "status": "Poster",
        "abstract": "Controlling the style  of natural language by disentangling the latent space is an important step towards interpretable machine learning. After the latent space is disentangled, the style of a sentence can be transformed by tuning the style representation without affecting other features of the sentence. Previous works usually use adversarial training to guarantee that disentangled vectors do not affect each other.  However, adversarial methods are difficult to train. Especially when there are multiple features (e.g., sentiment, or tense, which we call style types in this paper), each feature requires a separate discriminator  for extracting a disentangled style vector corresponding to that feature. In this paper, we propose a unified distribution-controlling method, which provides each specific style value (the value of style types, e.g., positive sentiment, or past tense) with a unique representation. This method contributes a solid theoretical basis to avoid adversarial training in multi-type disentanglement. We also propose multiple loss functions to achieve a style-content disentanglement as well as a disentanglement among multiple style types. In addition, we observe that if two different style types always have some specific style values    that occur together in the dataset, they will affect each other when transferring the style values. We call this phenomenon  training bias , and we propose a loss function to alleviate such training bias while disentangling multiple types. We conduct experiments on two datasets (Yelp service reviews and Amazon product reviews) to evaluate the style-disentangling effect and the unsupervised style-transfer performance on two style types: sentiment and tense. The experimental results show the effectiveness of our model.",
        "primary_area": "Machine Learning IV",
        "author": "Lei Sha; Thomas Lukasiewicz",
        "authorids": "",
        "aff": "University of Oxford; University of Oxford",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17146/17146-13-20640-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09515-multi-type-disentanglement-without-adversarial-training/",
        "doi": "10.1609/aaai.v35i11.17146",
        "pdf_size": 3463440
    },
    {
        "id": "13234",
        "title": "Multi-view Inference for Relation Extraction with Uncertain Knowledge",
        "track": "main",
        "status": "Poster",
        "abstract": "Knowledge graphs (KGs) are widely used to facilitate relation extraction (RE) tasks. While most previous RE methods focus on leveraging deterministic KGs, uncertain KGs, which assign a confidence score for each relation instance, can provide prior probability distributions of relational facts as valuable external knowledge for RE models. This paper proposes to exploit uncertain knowledge to improve relation extraction. Specifically, we introduce ProBase, an uncertain KG that indicates to what extent a target entity belongs to a concept, into our RE architecture. We then design a novel multi-view inference framework to systematically integrate local context and global knowledge across three views: mention-, entity- and concept-view. The experiment results show that our model achieves competitive performances on both sentence- and document-level relation extraction, which verifies the effectiveness of introducing uncertain knowledge and the multi-view inference framework that we design.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Bo Li; Wei Ye; Canming Huang; Shikun Zhang",
        "authorids": "",
        "aff": "Peking University; Peking University; Beijing University of Posts and Telecommunications; Peking University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17563/17563-13-21057-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13234-multi-view-inference-for-relation-extraction-with-uncertain-knowledge/",
        "doi": "10.1609/aaai.v35i15.17563",
        "pdf_size": 551365
    },
    {
        "id": "12760",
        "title": "MultiTalk: A Highly-Branching Dialog Testbed for Diverse Conversations",
        "track": "main",
        "status": "Poster",
        "abstract": "We study conversational dialog in which there are many possible responses to a given history. We present the MultiTalk Dataset, a corpus of over 320,000 sentences of written conversational dialog that balances a high branching factor (10) with several conversation turns (6) through selective branch continuation. We make multiple contributions to study dialog  generation in the highly branching setting. In order to evaluate a diverse set of generations, we propose a simple scoring algorithm, based on bipartite graph matching, to optimally incorporate a set of diverse references. We study multiple language generation tasks at different levels of predictive conversation depth, using textual attributes induced automatically from pretrained classifiers. Our culminating task is a challenging theory of mind problem, a controllable generation task which requires reasoning about the expected reaction of the listener.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Yao Dou; Maxwell Forbes; Ari Holtzman; Yejin Choi",
        "authorids": "",
        "aff": "University of Washington; University of Washington Allen Institute for AI; University of Washington; University of Washington Allen Institute for AI",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17510/17510-13-21004-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12760-multitalk-a-highly-branching-dialog-testbed-for-diverse-conversations/",
        "doi": "10.1609/aaai.v35i14.17510",
        "pdf_size": 633030
    },
    {
        "id": "07815",
        "title": "Multidimensional Uncertainty-Aware Evidential Neural Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Traditional deep neural networks (NNs) have significantly contributed to the state-of-the-art performance in the task of classification under various application domains.  However, NNs have not considered inherent uncertainty in data associated with the class probabilities where misclassification under uncertainty may easily introduce high risk in decision making in real-world contexts (e.g., misclassification of objects in roads leads to serious accidents).  Unlike Bayesian NN that indirectly infer uncertainty through weight uncertainties, evidential NNs (ENNs) have been recently proposed to explicitly model the uncertainty of class probabilities and use them for classification tasks.  An ENN offers the formulation of the predictions of NNs as subjective opinions and learns the function by collecting an amount of evidence that can form the subjective opinions by a deterministic NN from data.  However, the ENN is trained as a black box without explicitly considering inherent uncertainty in data with their different root causes, such as vacuity (i.e., uncertainty due to a lack of evidence) or dissonance (i.e., uncertainty due to conflicting evidence).  By considering the multidimensional uncertainty, we proposed a novel uncertainty-aware evidential NN called WGAN-ENN (WENN) for solving an out-of-distribution (OOD) detection problem.  We took a hybrid approach that combines Wasserstein Generative Adversarial Network (WGAN) with ENNs to jointly train a model with prior knowledge of a certain class, which has high vacuity for OOD samples.  Via extensive empirical experiments based on both synthetic and real-world datasets, we demonstrated that the estimation of uncertainty by WENN can significantly help distinguish OOD samples from boundary samples. WENN outperformed in OOD detection when compared with other competitive counterparts.",
        "primary_area": "Machine Learning II",
        "author": "Yibo Hu; Yuzhe Ou; Xujiang Zhao; Jin-Hee Cho; Feng Chen",
        "authorids": "",
        "aff": "The University of Texas at Dallas; The University of Texas at Dallas; The University of Texas at Dallas; Virginia Tech; The University of Texas at Dallas",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16954/16954-13-20448-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07815-multidimensional-uncertainty-aware-evidential-neural-networks/",
        "doi": "10.1609/aaai.v35i9.16954",
        "pdf_size": 593253
    },
    {
        "id": "12583",
        "title": "Multilingual Transfer Learning for QA using Translation as Data Augmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "Prior work on multilingual question answering has mostly focused on using large multilingual pre-trained language models (LM) to perform zero-shot language-wise learning: train a QA model on English and test on other languages. In this work, we explore strategies that improve cross-lingual transfer by bringing the multilingual embeddings closer in the semantic space.  Our first strategy augments the original English training data with machine translation-generated data. This results in a corpus of multilingual silver-labeled QA pairs that is 14 times larger than the original training set. In addition, we propose two novel strategies, language adversarial training and language arbitration framework, which significantly improve the (zero-resource) cross-lingual transfer performance and result in LM embeddings that are less language-variant. Empirically, we show that the proposed models outperform the previous zero-shot baseline on the recently introduced multilingual MLQA and TyDiQA datasets.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Mihaela Bornea; Lin Pan; Sara Rosenthal; Radu Florian; Avirup Sil",
        "authorids": "",
        "aff": "IBM Research; IBM Research; IBM Research; IBM Research; IBM Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17491/17491-13-20985-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12583-multilingual-transfer-learning-for-qa-using-translation-as-data-augmentation/",
        "doi": "10.1609/aaai.v35i14.17491",
        "pdf_size": 180782
    },
    {
        "id": "03199",
        "title": "Multimodal Fusion via Teacher-Student Network for Indoor Action Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "Indoor action recognition plays an important role in modern society, such as intelligent healthcare in large mobile cabin hospitals. With the wide usage of depth sensors like Kinect, multimodal information including skeleton and RGB modalities brings a promising way to improve the performance. However, existing methods are either focusing on a single data modality or failed to take the advantage of multiple data modalities. In this paper, we propose a Teacher-Student Multimodal Fusion (TSMF) model that fuses the skeleton and RGB modalities at the model level for indoor action recognition. In our TSMF, we utilize a teacher network to transfer the structural knowledge of the skeleton modality to a student network for the RGB modality. With extensive experiments on two benchmarking datasets: NTU RGB+D and PKU-MMD, results show that the proposed TSMF consistently performs better than state-of-the-art single modal and multimodal methods. It also indicates that our TSMF could not only improve the accuracy of the student network but also significantly improve the ensemble accuracy.",
        "primary_area": "Computer Vision III",
        "author": "Bruce X.B. Yu; Yan Liu; Keith C.C. Chan",
        "authorids": "",
        "aff": "The Hong Kong Polytechnic University; The Hong Kong Polytechnic University; The Hong Kong Polytechnic University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16430/16430-13-19924-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03199-multimodal-fusion-via-teacher-student-network-for-indoor-action-recognition/",
        "doi": "10.1609/aaai.v35i4.16430",
        "pdf_size": 2492836
    },
    {
        "id": "09205",
        "title": "Multinomial Logit Contextual Bandits: Provable Optimality and Practicality",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider a sequential assortment selection problem where the user choice is given by a multinomial logit (MNL) choice model whose parameters are unknown. In each period, the learning agent observes a d-dimensional contextual information about the user and the N available items, and offers an assortment of size K to the user, and observes the bandit feedback of the item chosen from the assortment. We propose upper confidence bound based algorithms for this MNL contextual bandit. The first algorithm is a simple and practical method that achieves an O(d\u221aT) regret over T rounds. Next, we propose a second algorithm which achieves a O(\u221adT) regret. This matches the lower bound for the MNL bandit problem, up to logarithmic terms, and improves on the best-known result by a \u221ad factor. To establish this sharper regret bound, we present a non-asymptotic confidence bound for the maximum likelihood estimator of the MNL model that may be of independent interest as its own theoretical contribution. We then revisit the simpler, significantly more practical, first algorithm and show that a simple variant of the algorithm achieves the optimal regret for a broad class of important applications.",
        "primary_area": "Machine Learning III",
        "author": "Min-hwan Oh; Garud Iyengar",
        "authorids": "",
        "aff": "Seoul National University; Columbia University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17111/17111-13-20605-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09205-multinomial-logit-contextual-bandits-provable-optimality-and-practicality/",
        "doi": "10.1609/aaai.v35i10.17111",
        "pdf_size": 224320
    },
    {
        "id": "09411",
        "title": "Multiple Kernel Clustering with Kernel k-Means Coupled Graph Tensor Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Kernel k-means (KKM) and spectral clustering (SC) are two basic methods used for multiple kernel clustering (MKC), which have both been widely used to identify clusters that are non-linearly separable. However, both of them have their own shortcomings: 1) the KKM-based methods usually focus on learning a discrete clustering indicator matrix via a combined consensus kernel, but cannot exploit the high-order affinities of all pre-defined base kernels; and 2) the SC-based methods require a robust and meaningful affinity graph in kernel space as input in order to form clusters with desired clustering structure. In this paper, a novel method, kernel k-means coupled graph tensor (KCGT), is proposed to graciously couple KKM and SC for seizing their merits and evading their demerits simultaneously. In specific, we innovatively develop a new graph learning paradigm by leveraging an explicit theoretical connection between clustering indicator matrix and affinity graph, such that the affinity graph propagated from KKM enjoys the valuable block diagonal and sparse property. Then, by using this graph learning paradigm, base kernels can produce multiple candidate affinity graphs, which are stacked into a low-rank graph tensor for capturing the high-order affinity of all these graphs. After that, by averaging all the frontal slices of the tensor, a high-quality affinity graph is obtained. Extensive experiments have shown the superiority of KCGT compared with the state-of-the-art MKC methods.",
        "primary_area": "Machine Learning IV",
        "author": "Zhenwen Ren; Quansen Sun; Dong Wei",
        "authorids": "",
        "aff": "Nanjing University of Science and Technology Southwest University of Science and Technology; Nanjing University of Science and Technology; Nanjing University of Science and Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17134/17134-13-20628-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09411-multiple-kernel-clustering-with-kernel-k-means-coupled-graph-tensor-learning/",
        "doi": "10.1609/aaai.v35i11.17134",
        "pdf_size": 2052496
    },
    {
        "id": "07090",
        "title": "NASGEM: Neural Architecture Search via Graph Embedding Method",
        "track": "main",
        "status": "Poster",
        "abstract": "Neural Architecture Search (NAS) automates and prospers the design of neural networks. Estimator-based NAS has been proposed recently to model the relationship between architectures and their performance to enable scalable and flexible search. However, existing estimator-based methods encode the architecture into a latent space without considering graph similarity. Ignoring graph similarity in node-based search space may induce a large inconsistency between similar graphs and their distance in the continuous encoding space, leading to inaccurate encoding representation and/or reduced representation capacity that can yield sub-optimal search results. To preserve graph correlation information in encoding, we propose NASGEM which stands for Neural Architecture Search via Graph Embedding Method. NASGEM is driven by a novel graph embedding method equipped with similarity measures to capture the graph topology information. By precisely estimating the graph distance and using an auxiliary Weisfeiler-Lehman kernel to guide the encoding, NASGEM can utilize additional structural information to get more accurate graph representation to improve the search efficiency. GEMNet, a set of networks discovered by NASGEM, consistently outperforms networks crafted by existing search methods in classification tasks, i.e., with 0.4%-3.6% higher accuracy while having 11%- 21% fewer Multiply-Accumulates. We further transfer GEMNet for COCO object detection. In both one-stage and twostage detectors, our GEMNet surpasses its manually-crafted and automatically-searched counterparts.",
        "primary_area": "Machine Learning I",
        "author": "Hsin-Pai Cheng; Tunhou Zhang; Yixing Zhang; Shiyu Li; Feng Liang; Feng Yan; Meng Li; Vikas Chandra; Hai Li; Yiran Chen",
        "authorids": "",
        "aff": "Duke University; Duke University; Duke University; Duke University; Tsinghua University; University of Nevada, Reno; Facebook Inc.; Facebook Inc.; Duke University; Duke University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16872/16872-13-20366-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07090-nasgem-neural-architecture-search-via-graph-embedding-method/",
        "doi": "10.1609/aaai.v35i8.16872",
        "pdf_size": 2157156
    },
    {
        "id": "09294",
        "title": "NASTransfer: Analyzing Architecture Transferability in Large Scale Neural Architecture Search",
        "track": "main",
        "status": "Poster",
        "abstract": "Neural Architecture Search (NAS) is an open and challenging problem in machine learning. While NAS offers great promise, the prohibitive computational demand of most of the existing NAS methods makes it difficult to directly search the architectures on large-scale tasks. The typical way of conducting large scale NAS is to search for an architectural building block on a small dataset (either using a proxy set from the large dataset or a completely different small scale dataset) and then transfer the block to a larger dataset. Despite a number of recent results that show the promise of transfer from proxy datasets, a comprehensive evaluation of different NAS methods studying the impact of different source datasets has not yet been addressed. In this work, we propose to analyze the architecture transferability of different NAS methods by performing a series of experiments on large scale benchmarks such as ImageNet1K and ImageNet22K. We find that: (i) The size and domain of the  proxy set  does not seem to influence architecture performance on the target dataset. On average, transfer performance of architectures searched using completely different small datasets (e.g., CIFAR10) perform similarly to the architectures searched directly on proxy target datasets. However, design of proxy sets has considerable impact on rankings of different NAS methods. (ii) While different NAS methods show similar performance on a source dataset (e.g., CIFAR10), they significantly differ on the transfer performance to a large dataset (e.g., ImageNet1K). (iii) Even on large datasets, random sampling baseline is very competitive, but the choice of the appropriate combination of proxy set and search strategy can provide significant improvement over it. We believe that our extensive empirical analysis will prove useful for future design of NAS algorithms.",
        "primary_area": "Machine Learning III",
        "author": "Rameswar Panda; Michele Merler; Mayoore S Jaiswal; Hui Wu; Kandan Ramakrishnan; Ulrich Finkler; Chun-Fu Richard Chen; Minsik Cho; Rogerio Feris; David Kung; Bishwaranjan Bhattacharjee",
        "authorids": "",
        "aff": "IBM Research MIT-IBM Watson AI Lab; IBM Research; IBM Research; IBM Research MIT-IBM Watson AI Lab; IBM Research; IBM Research; IBM Research MIT-IBM Watson AI Lab; IBM Research; IBM Research MIT-IBM Watson AI Lab; IBM Research; IBM Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17121/17121-13-20615-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09294-nastransfer-analyzing-architecture-transferability-in-large-scale-neural-architecture-search/",
        "doi": "10.1609/aaai.v35i10.17121",
        "pdf_size": 633256
    },
    {
        "id": "05984",
        "title": "Narrative Plan Generation with Self-Supervised Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Narrative Generation has attracted significant interest as a novel application of Automated Planning techniques. However, the vast amount of narrative material available opens the way to the use of Deep Learning techniques. In this paper, we explore the feasibility of narrative generation through self-supervised learning, using sequence embedding techniques or auto-encoders to produce narrative sequences. We use datasets of well-formed plots generated by a narrative planning approach, using pre-existing, published, narrative planning domains, to train generative models. Our experiments demonstrate the ability of generative sequence models to produce narrative plots with similar structure to those obtained with planning techniques, but with significant plot novelty in comparison with the training set. Most importantly, generated plots share structural properties associated with narrative quality measures used in Planning-based methods. As plan-based structures account for a higher level of causality and narrative consistency, this suggests that our approach is able to extend a set of narratives with novel sequences that display the same high-level narrative properties. Unlike methods developed to extend sets of textual narratives, ours operates at the level of plot structure. Thus, it has the potential to be used across various media for plots of significant complexity, being initially limited to training and generation operating in the same narrative genre.",
        "primary_area": "Humans and AI",
        "author": "Mihai Polceanu; Julie Porteous; Alan Lindsay; Marc Cavazza",
        "authorids": "",
        "aff": "University of Greenwich; RMIT University; Heriot-Watt University; University of Greenwich",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16747/16747-13-20241-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05984-narrative-plan-generation-with-self-supervised-learning/",
        "doi": "10.1609/aaai.v35i7.16747",
        "pdf_size": 1990954
    },
    {
        "id": "13388",
        "title": "Natural Language Inference in Context \u2013 Investigating Contextual Reasoning over Long Texts",
        "track": "main",
        "status": "Poster",
        "abstract": "Natural language inference (NLI) is a fundamental NLP task, investigating the entailment relationship between two texts.\u2028 Popular NLI datasets present the task at sentence-level. While adequate for testing semantic representations, they fall short for testing contextual reasoning over long texts, which is a natural part of the human inference process. We introduce ConTRoL, a new dataset for ConTextual Reasoning over Long texts. Consisting of 8,325 expert-designed \"context-hypothesis\" pairs with gold labels, ConTRoL is a passage-level NLI dataset with a focus on complex contextual reasoning types such as logical reasoning. It is derived from competitive selection and recruitment test (verbal reasoning test) for police recruitment, with expert level quality. Compared with previous NLI benchmarks, the materials in ConTRoL are much more challenging, involving a range of reasoning types. Empirical results show that state-of-the-art language models perform by far worse than educated humans. Our dataset can also serve as a testing-set for downstream tasks like checking the factual correctness of summaries.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Hanmeng Liu; Leyang Cui; Jian Liu; Yue Zhang",
        "authorids": "",
        "aff": "Zhejiang University; Zhejiang University; Fudan University; Westlake University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17580/17580-13-21074-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13388-natural-language-inference-in-context-investigating-contextual-reasoning-over-long-texts/",
        "doi": "10.1609/aaai.v35i15.17580",
        "pdf_size": 1693024
    },
    {
        "id": "14006",
        "title": "NaturalConv: A Chinese Dialogue Dataset Towards Multi-turn Topic-driven Conversation",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a Chinese multi-turn topic-driven conversation dataset, NaturalConv, which allows the participants to chat anything they want as long as any element from the topic is mentioned and the topic shift is smooth. Our corpus contains 19.9K conversations from six domains, and 400K utterances with an average turn number of 20.1. These conversations contain in-depth discussions on related topics or widely natural transition between multiple topics. We believe either way is normal for human conversation. To facilitate the research on this corpus, we provide results of several benchmark models. Comparative results show that for this dataset, our current models are not able to provide significant improvement by introducing background knowledge/topic. Therefore, the proposed dataset should be a good benchmark for further research to evaluate the validity and naturalness of multi-turn conversation systems. Our dataset is available at https://ai.tencent.com/ailab/nlp/dialogue/#datasets.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Xiaoyang Wang; Chen Li; Jianqiao Zhao; Dong Yu",
        "authorids": "",
        "aff": "Tencent; Tencent; Tencent; Tencent",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17649/17649-13-21143-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14006-naturalconv-a-chinese-dialogue-dataset-towards-multi-turn-topic-driven-conversation/",
        "doi": "10.1609/aaai.v35i16.17649",
        "pdf_size": 262856
    },
    {
        "id": "10577",
        "title": "Near Lossless Transfer Learning for Spiking Neural Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Spiking neural networks (SNNs) significantly reduce energy consumption by replacing weight multiplications with additions. This makes SNNs suitable for energy-constrained platforms. However, due to its discrete activation, training of SNNs remains a challenge. A popular approach is to first train an equivalent CNN using traditional backpropagation, and then transfer the weights to the intended SNN. Unfortunately, this often results in significant accuracy loss, especially in deeper networks. In this paper, we propose CQ training (Clamped and Quantized training), an SNN-compatible CNN training algorithm with clamp and quantization that achieves near-zero conversion accuracy loss. Essentially, CNN training in CQ training accounts for certain SNN characteristics. Using a 7 layer VGG-* and a 21 layer VGG-19, running on the CIFAR-10 dataset, we achieved 94.16% and 93.44% accuracy in the respective equivalent SNNs. It outperforms other existing comparable works that we know of. We also demonstrate the low-precision weight compatibility for the VGG-19 structure. Without retraining, an accuracy of 93.43% and 92.82% using quantized 9-bit and 8-bit weights, respectively, was achieved. The framework was developed in PyTorch and is publicly available.",
        "primary_area": "Machine Learning V",
        "author": "Zhanglu Yan; Jun Zhou; Weng-Fai Wong",
        "authorids": "",
        "aff": "National University of Singapore; National University of Singapore; National University of Singapore",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17265/17265-13-20759-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10577-near-lossless-transfer-learning-for-spiking-neural-networks/",
        "doi": "10.1609/aaai.v35i12.17265",
        "pdf_size": 389584
    },
    {
        "id": "10397",
        "title": "Near-Optimal MNL Bandits Under Risk Criteria",
        "track": "main",
        "status": "Poster",
        "abstract": "We study MNL bandits, which is a variant of the traditional multi-armed bandit problem, under risk criteria. Unlike the ordinary expected revenue, risk criteria are more general goals widely used in industries and business. We design algorithms for a broad class of risk criteria, including but not limited to the well-known conditional value-at-risk, Sharpe ratio, and entropy risk, and prove that they suffer a near-optimal regret. As a complement, we also conduct experiments with both synthetic and real data to show the empirical performance of our proposed algorithms.",
        "primary_area": "Machine Learning V",
        "author": "Guangyu Xi; Chao Tao; Yuan Zhou",
        "authorids": "",
        "aff": "University of Maryland, College Park; Indiana University Bloomington; UIUC",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17245/17245-13-20739-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10397-near-optimal-mnl-bandits-under-risk-criteria/",
        "doi": "10.1609/aaai.v35i12.17245",
        "pdf_size": 2383251
    },
    {
        "id": "09791",
        "title": "Near-Optimal Regret Bounds for Contextual Combinatorial Semi-Bandits with Linear Payoff Functions",
        "track": "main",
        "status": "Poster",
        "abstract": "The contextual combinatorial semi-bandit problem with linear payoff functions is a decision-making problem in which a learner chooses a set of arms with the feature vectors in each round under given constraints so as to maximize the sum of rewards of arms. Several existing algorithms have regret bounds that are optimal with respect to the number of rounds T. However, there is a gap of \u00d5(max(\u221ad, \u221ak)) between the current best upper and lower bounds, where d is the dimension of the feature vectors, k is the number of the chosen arms in a round, and \u00d5(\u00b7) ignores the logarithmic factors. The dependence of k and d is of practical importance because k may be larger than T in real-world applications such as recommender systems. In this paper, we fill the gap by improving the upper and lower bounds. More precisely, we show that the C2UCB algorithm proposed by Qin, Chen, and Zhu (2014) has the optimal regret bound \u00d5(d\u221akT + dk) for the partition matroid constraints. For general constraints, we propose an algorithm that modifies the reward estimates of arms in the C2UCB algorithm and demonstrate that it enjoys the optimal regret bound for a more general problem that can take into account other objectives simultaneously. We also show that our technique would be applicable to related problems. Numerical experiments support our theoretical results and considerations.",
        "primary_area": "Machine Learning IV",
        "author": "Kei Takemura; Shinji Ito; Daisuke Hatano; Hanna Sumita; Takuro Fukunaga; Naonori Kakimura; Ken-ichi Kawarabayashi",
        "authorids": "",
        "aff": "NEC Corporation; NEC Corporation; RIKEN AIP; Tokyo Institute of Technology; Chuo University JST PRESTO RIKEN AIP; Keio University; National Institute of Informatics",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17177/17177-13-20671-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09791-near-optimal-regret-bounds-for-contextual-combinatorial-semi-bandits-with-linear-payoff-functions/",
        "doi": "10.1609/aaai.v35i11.17177",
        "pdf_size": 169670
    },
    {
        "id": "10041",
        "title": "Nearest Neighbor Classifier Embedded Network for Active Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep neural networks (DNNs) have been widely applied to active learning. Despite of its effectiveness, the generalization ability of the discriminative classifier (the softmax classifier) is questionable when there is a significant distribution bias between the labeled set and the unlabeled set. In this paper, we attempt to replace the softmax classifier in deep neural network with a nearest neighbor classifier, considering its progressive generalization ability within the unknown sub-space. Our proposed active learning approach, termed nearest Neighbor Classifier Embedded network (NCE-Net), targets at reducing the risk of over-estimating unlabeled samples while improving the opportunity to query informative samples. NCE-Net is conceptually simple but surprisingly powerful, as justified from the perspective of the subset information, which defines a metric to quantify model generalization ability in active learning. Experimental results show that, with simple selection based on rejection or confusion confidence, NCE-Net improves state-of-the-arts on image classification and object detection tasks with significant margins.",
        "primary_area": "Machine Learning IV",
        "author": "Fang Wan; Tianning Yuan; Mengying Fu; Xiangyang Ji; Qingming Huang; Qixiang Ye",
        "authorids": "",
        "aff": "University of Chinese Academy of Sciences; University of Chinese Academy of Sciences; University of Chinese Academy of Sciences; Tsinghua University; University of Chinese Academy of Sciences; University of Chinese Academy of Sciences, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17205/17205-13-20699-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10041-nearest-neighbor-classifier-embedded-network-for-active-learning/",
        "doi": "10.1609/aaai.v35i11.17205",
        "pdf_size": 1276500
    },
    {
        "id": "08200",
        "title": "Nearly Linear-Time, Parallelizable Algorithms for Non-Monotone Submodular Maximization",
        "track": "main",
        "status": "Poster",
        "abstract": "We study combinatorial, parallelizable algorithms for maximization of a submodular function, not necessarily monotone, with respect to a cardinality constraint k. We improve the best approximation factor achieved by an algorithm that has optimal adaptivity and query complexity, up to logarithmic factors in the size of the ground set, from 0.039 to nearly 0.193. Heuristic versions of our algorithms are empirically validated to use a low number of adaptive rounds and total queries while obtaining solutions with high objective value in comparison with state-of-the-art approximation algorithms, including continuous algorithms that use the multilinear extension.",
        "primary_area": "Machine Learning II",
        "author": "Alan Kuhnle",
        "authorids": "",
        "aff": "Florida State University, Tallahassee, Florida",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16998/16998-13-20492-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08200-nearly-linear-time-parallelizable-algorithms-for-non-monotone-submodular-maximization/",
        "doi": "10.1609/aaai.v35i9.16998",
        "pdf_size": 370800
    },
    {
        "id": "05481",
        "title": "Necessarily Optimal One-Sided Matchings",
        "track": "main",
        "status": "Poster",
        "abstract": "We study the classical problem of matching n agents to n objects, where the agents have ranked preferences over the objects. We focus on two popular desiderata from the matching literature: Pareto optimality and rank-maximality. Instead of asking the agents to report their complete preferences, our goal is to learn a desirable matching from partial preferences, specifically a matching that is necessarily Pareto optimal (NPO) or necessarily rank-maximal (NRM) under any completion of the partial preferences. We focus on the top-k model in which agents reveal a prefix of their preference rankings. We design efficient algorithms to check if a given matching is NPO or NRM, and to check whether such a matching exists given top-k partial preferences. We also study online algorithms for eliciting partial preferences adaptively, and prove bounds on their competitive ratio.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Hadi Hosseini; Vijay Menon; Nisarg Shah; Sujoy Sikdar",
        "authorids": "",
        "aff": "Penn State University; University of Waterloo; University of Toronto; Binghamton University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16690/16690-13-20184-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05481-necessarily-optimal-one-sided-matchings/",
        "doi": "10.1609/aaai.v35i6.16690",
        "pdf_size": 156340
    },
    {
        "id": "03688",
        "title": "Necessary and Sufficient Conditions for Avoiding Reopenings in Best First Suboptimal Search with General Bounding Functions",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent work introduced XDP and XUP priority functions for best-first bounded-suboptimal search that do not need to perform state re-expansions as long as the search heuristic is consistent. However, that work had several limitations that are rectified here. This paper analyzes the sufficiency and necessity of the conditions used to formulate XDP and XUP. The analysis presents a simpler proof and generalizes the result in three aspects: (1) the priority function no longer has to be differentiable everywhere, (2) the quality of the solution does not have to be bounded by a constant factor, and (3) directed graphs are handled correctly. These results allow the introduction of more priority functions, such as piecewise linear functions, and more variants of bounded-suboptimal search, such as constant suboptimality. Several new priority functions are presented in this paper that, according to empirical results, can significantly outperform existing approaches including XDP.",
        "primary_area": "Constraint Satisfaction and Optimization",
        "author": "Jingwei Chen; Nathan R. Sturtevant",
        "authorids": "",
        "aff": "University of Alberta; University of Alberta",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16485/16485-13-19979-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03688-necessary-and-sufficient-conditions-for-avoiding-reopenings-in-best-first-suboptimal-search-with-general-bounding-functions/",
        "doi": "10.1609/aaai.v35i5.16485",
        "pdf_size": 378581
    },
    {
        "id": "07099",
        "title": "Neighborhood Consensus Networks for Unsupervised Multi-view Outlier Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-view outlier detection recently attracted rapidly growing attention with the development of multi-view learning. Although promising performance demonstrated, we observe that identifying outliers in multi-view data is still a challenging task due to the complicated characteristics of multi-view data. Specifically, an effective multi-view outlier detection method should be able to handle (1) different types of outliers; (2) two or more views; (3) samples without clusters; (4) high dimensional data. Unfortunately, little is known about how these four issues can be handled simultaneously. In this paper, we propose an unsupervised multi-view outlier detection method to address these issues. Our method is based on the proposed novel neighborhood consensus networks termed NC-Nets, which automatically encodes intrinsic information into a comprehensive latent space for each view (for issue (4)) and uniforms the neighborhood structures among different views (for issue (2)). Accordingly, we propose an outlier score measurement which consists of two parts: the within-view reconstruction score and the cross-view neighborhood consensus score. The measurement is designed based on the characteristics of the different outlier types (for issue (1)) and no cluster assumption is needed (for issue (3)). Experimental results show that our method significantly outperforms state-of-the-art methods. On average, our method achieves 11.2% ~ 96.2% improvement in term of AUC and 33.5% ~ 352.7% improvement in term of F1-Score.",
        "primary_area": "Machine Learning I",
        "author": "Li Cheng; Yijie Wang; Xinwang Liu",
        "authorids": "",
        "aff": "College of Computer, National University of Defense Technology, Changsha, China; College of Computer, National University of Defense Technology, Changsha, China; College of Computer, National University of Defense Technology, Changsha, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16873/16873-13-20367-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07099-neighborhood-consensus-networks-for-unsupervised-multi-view-outlier-detection/",
        "doi": "10.1609/aaai.v35i8.16873",
        "pdf_size": 10246524
    },
    {
        "id": "12839",
        "title": "Nested Named Entity Recognition with Partially-Observed TreeCRFs",
        "track": "main",
        "status": "Poster",
        "abstract": "Named entity recognition (NER) is a well-studied task in natural language processing. However, the widely-used sequence labeling framework is difficult to detect entities with nested structures. In this work, we view nested NER as constituency parsing with partially-observed trees and model it with partially-observed TreeCRFs. Specifically, we view all labeled entity spans as observed nodes in a constituency tree, and other spans as latent nodes. With the TreeCRF we achieve a uniform way to jointly model the observed and the latent nodes. To compute the probability of partial trees with partial marginalization, we propose a variant of the Inside algorithm, the Masked Inside algorithm, that supports different inference operations for different nodes (evaluation for the observed, marginalization for the latent, and rejection for nodes incompatible with the observed) with efficient parallelized implementation, thus significantly speeding up training and inference. Experiments show that our approach achieves the state-of-the-art (SOTA) F1 scores on the ACE2004, ACE2005 dataset, and shows comparable performance to SOTA models on the GENIA dataset. We release the code at https://github.com/FranxYao/Partially-Observed-TreeCRFs.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Yao Fu; Chuanqi Tan; Mosha Chen; Songfang Huang; Fei Huang",
        "authorids": "",
        "aff": "The University of Edinburgh; Alibaba Group; Alibaba Group; Alibaba Group; Alibaba Group",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17519/17519-13-21013-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12839-nested-named-entity-recognition-with-partially-observed-treecrfs/",
        "doi": "10.1609/aaai.v35i14.17519",
        "pdf_size": 215917
    },
    {
        "id": "06218",
        "title": "Network Satisfaction for Symmetric Relation Algebras with a Flexible Atom",
        "track": "main",
        "status": "Poster",
        "abstract": "Robin Hirsch posed in 1996 the Really Big Complexity Problem: classify the computational complexity of  the network satisfaction problem for all finite relation algebras A. We provide a complete classification for the case that A is symmetric and has a flexible atom; the problem is in this case NP-complete or in P. If a finite integral relation algebra has a flexible atom, then it has a normal representation B. We can then study the computational complexity of the network satisfaction problem of A using the universal-algebraic approach, via an analysis of the polymorphisms of B. We also use a Ramsey-type result of  Ne\u0161et\u0159il and R\u00f6dl and a complexity dichotomy result of Bulatov for conservative finite-domain constraint satisfaction problems.",
        "primary_area": "Knowledge Representation and Reasoning",
        "author": "Manuel Bodirsky; Simon Kn\u00e4uer",
        "authorids": "",
        "aff": "TU Dresden; TU Dresden",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16773/16773-13-20267-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06218-network-satisfaction-for-symmetric-relation-algebras-with-a-flexible-atom/",
        "doi": "10.1609/aaai.v35i7.16773",
        "pdf_size": 157732
    },
    {
        "id": "00809",
        "title": "Neural Analogical Matching",
        "track": "main",
        "status": "Poster",
        "abstract": "Analogy is core to human cognition. It allows us to solve problems based on prior experience, it governs the way we conceptualize new information, and it even influences our visual perception. The importance of analogy to humans has made it an active area of research in the broader field of artificial intelligence, resulting in data-efficient models that learn and reason in human-like ways.  While cognitive perspectives of analogy and deep learning have generally been studied independently of one another, the integration of the two lines of research is a promising step towards more robust and efficient learning techniques. As part of a growing body of research on such an integration, we introduce the Analogical Matching Network: a neural architecture that learns to produce analogies between structured, symbolic representations that are largely consistent with the principles of Structure-Mapping Theory.",
        "primary_area": "Cognitive Modeling and Cognitive Systems",
        "author": "Maxwell Crouse; Constantine Nakos; Ibrahim Abdelaziz; Ken Forbus",
        "authorids": "",
        "aff": "Qualitative Reasoning Group, Northwestern University; Qualitative Reasoning Group, Northwestern University; IBM Research, IBM T.J. Watson Research Center; Qualitative Reasoning Group, Northwestern University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16163/16163-13-19657-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00809-neural-analogical-matching/",
        "doi": "10.1609/aaai.v35i1.16163",
        "pdf_size": 384785
    },
    {
        "id": "10379",
        "title": "Neural Architecture Search as Sparse Supernet",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper aims at enlarging the problem of Neural Architecture Search (NAS) from Single-Path and Multi-Path Search to automated Mixed-Path Search. In particular, we model the NAS problem as a sparse supernet using a new continuous architecture representation with a mixture of sparsity constraints. The sparse supernet enables us to automatically achieve sparsely-mixed paths upon a compact set of nodes. To optimize the proposed sparse supernet, we exploit a hierarchical accelerated proximal gradient algorithm within a bi-level optimization framework. Extensive experiments on Convolutional Neural Network and Recurrent Neural Network search demonstrate that the proposed method is capable of searching for compact, general and powerful neural architectures.",
        "primary_area": "Machine Learning V",
        "author": "Yan Wu; Aoming Liu; Zhiwu Huang; Siwei Zhang; Luc Van Gool",
        "authorids": "",
        "aff": "ETH Zurich; ETH Zurich; ETH Zurich; ETH Zurich; ETH Zurich VISICS, KU Leuven",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17243/17243-13-20737-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10379-neural-architecture-search-as-sparse-supernet/",
        "doi": "10.1609/aaai.v35i12.17243",
        "pdf_size": 800876
    },
    {
        "id": "04054",
        "title": "Neural Latent Space Model for Dynamic Networks and Temporal Knowledge Graphs",
        "track": "main",
        "status": "Poster",
        "abstract": "Although static networks have been extensively studied in machine learning, data mining, and AI communities for many decades, the study of dynamic networks has recently taken center stage due to the prominence of social media and its effects on the dynamics of social networks. In this paper, we propose a statistical model for dynamically evolving networks, together with a variational inference approach. Our model, Neural Latent Space Model with Variational Inference, encodes edge dependencies across different time snapshots. It represents nodes via latent vectors and uses interaction matrices to model the presence of edges. These matrices can be used to incorporate multiple relations in heterogeneous networks by having a separate matrix for each of the relations. To capture the temporal dynamics, both node vectors and interaction matrices are allowed to evolve with time. Existing network analysis methods use representation learning techniques for modelling networks. These techniques are different for homogeneous and heterogeneous networks because heterogeneous networks can have multiple types of edges and nodes as opposed to a homogeneous network. Unlike these, we propose a unified model for homogeneous and heterogeneous networks in a variational inference framework. Moreover, the learned node latent vectors and interaction matrices may be interpretable and therefore provide insights on the mechanisms behind network evolution. We experimented with a single step and multi-step link forecasting on real-world networks of homogeneous, bipartite, and heterogeneous nature, and demonstrated that our model significantly outperforms existing models.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Tony Gracious; Shubham Gupta; Arun Kanthali; Rui M. Castro; Ambedkar Dukkipati",
        "authorids": "",
        "aff": "Indian Institute of Science Bangalore; Indian Institute of Science Bangalore; Indian Institute of Science Bangalore; Eindhoven University of Technology; Indian Institute of Science Bangalore",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16526/16526-13-20020-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04054-neural-latent-space-model-for-dynamic-networks-and-temporal-knowledge-graphs/",
        "doi": "10.1609/aaai.v35i5.16526",
        "pdf_size": 160569
    },
    {
        "id": "07055",
        "title": "Neural Relational Inference with Efficient Message Passing Mechanisms",
        "track": "main",
        "status": "Poster",
        "abstract": "Many complex processes can be viewed as dynamical systems of interacting agents. In many cases, only the state sequences of individual agents are observed, while the interacting relations and the dynamical rules are unknown. The neural relational inference (NRI) model adopts graph neural networks that pass messages over a latent graph to jointly learn the relations and the dynamics based on the observed data. However, NRI infers the relations independently and suffers from error accumulation in multi-step prediction at dynamics learning procedure. Besides, relation reconstruction without prior knowledge becomes more difficult in more complex systems. This paper introduces efficient message passing mechanisms to the graph neural networks with structural prior knowledge to address these problems. A relation interaction mechanism is proposed to capture the coexistence of all relations, and a spatio-temporal message passing mechanism is proposed to use historical information to alleviate error accumulation. Additionally, the structural prior knowledge, symmetry as a special case, is introduced for better relation prediction in more complex systems. The experimental results on simulated physics systems show that the proposed method outperforms existing state-of-the-art methods.",
        "primary_area": "Machine Learning I",
        "author": "Siyuan Chen; Jiahai Wang; Guoqing Li",
        "authorids": "",
        "aff": "Sun Yat-sen University; Sun Yat-sen University; Sun Yat-sen University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16868/16868-13-20362-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07055-neural-relational-inference-with-efficient-message-passing-mechanisms/",
        "doi": "10.1609/aaai.v35i8.16868",
        "pdf_size": 1808479
    },
    {
        "id": "14656",
        "title": "Neural Sentence Ordering Based on Constraint Graphs",
        "track": "main",
        "status": "Poster",
        "abstract": "Sentence ordering aims at arranging a list of sentences in the correct order. Based on the observation that sentence order at different distances may rely on different types of information, we devise a new approach based on multi-granular orders between sentences. These orders form multiple constraint graphs, which are then encoded by Graph Isomorphism Networks and fused into sentence representations. Finally, sentence order is determined using the order-enhanced sentence representations. Our experiments on five benchmark datasets show that our method outperforms all existing baselines significantly, achieving a new state-of-the-art performance. The results demonstrate the advantage of considering multiple types of order information and using graph neural networks to integrate sentence content and order information for the task. Our code is available at https://github.com/DaoD/ConstraintGraph4NSO.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Yutao Zhu; Kun Zhou; Jian-Yun Nie; Shengchao Liu; Zhicheng Dou",
        "authorids": "",
        "aff": "Universit\u00e9 de Montr\u00e9al; Renmin University of China; Universit\u00e9 de Montr\u00e9al; Mila Universit\u00e9 de Montr\u00e9al; Remin University, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17722/17722-13-21216-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14656-neural-sentence-ordering-based-on-constraint-graphs/",
        "doi": "10.1609/aaai.v35i16.17722",
        "pdf_size": 1670730
    },
    {
        "id": "13371",
        "title": "Neural Sentence Simplification with Semantic Dependency Information",
        "track": "main",
        "status": "Poster",
        "abstract": "Most previous works on neural sentence simplification exploit seq2seq model to rewrite a sentence without explicitly considering the semantic information of the sentence. This may lead to the semantic deviation of the simplified sentence. In this paper, we leverage semantic dependency graph to aid neural sentence simplification system. We propose a new sentence simplification model with semantic dependency information, called SDISS (as shorthand for Semantic Dependency Information guided Sentence Simplification), which incorporates semantic dependency graph to guide sentence simplification. We evaluate SDISS on three benchmark datasets and it outperforms a number of strong baseline models on the SARI and FKGL metrics. Human evaluation also shows SDISS can produce simplified sentences with better quality.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Zhe Lin; Xiaojun Wan",
        "authorids": "",
        "aff": "Wangxuan Institute of Computer Technology, Peking University Center for Data Science, Peking University The MOE Key Laboratory of Computational Linguistics, Peking University; Wangxuan Institute of Computer Technology, Peking University Center for Data Science, Peking University The MOE Key Laboratory of Computational Linguistics, Peking University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17578/17578-13-21072-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13371-neural-sentence-simplification-with-semantic-dependency-information/",
        "doi": "10.1609/aaai.v35i15.17578",
        "pdf_size": 573784
    },
    {
        "id": "08163",
        "title": "Neural Sequence-to-grid Module for Learning Symbolic Rules",
        "track": "main",
        "status": "Poster",
        "abstract": "Logical reasoning tasks over symbols, such as learning arithmetic operations and computer program evaluations, have become challenges to deep learning. In particular, even state-of-the-art neural networks fail to achieve textit{out-of-distribution} (OOD) generalization of symbolic reasoning tasks, whereas humans can easily extend learned symbolic rules. To resolve this difficulty, we propose a neural sequence-to-grid (seq2grid) module, an input preprocessor that automatically segments and aligns an input sequence into a grid. As our module outputs a grid via a novel differentiable mapping, any neural network structure taking a grid input, such as ResNet or TextCNN, can be jointly trained with our module in an end-to-end fashion. Extensive experiments show that neural networks having our module as an input preprocessor achieve OOD generalization on various arithmetic and algorithmic problems including number sequence prediction problems, algebraic word problems, and computer program evaluation problems while other state-of-the-art sequence transduction models cannot. Moreover, we verify that our module enhances TextCNN to solve the bAbI QA tasks without external memory.",
        "primary_area": "Machine Learning II",
        "author": "Segwang Kim; Hyoungwook Nam; Joonyoung Kim; Kyomin Jung",
        "authorids": "",
        "aff": "Seoul National University; University of Illinois at Urbana-Champaign; Seoul National University; Seoul National University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16994/16994-13-20488-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08163-neural-sequence-to-grid-module-for-learning-symbolic-rules/",
        "doi": "10.1609/aaai.v35i9.16994",
        "pdf_size": 714082
    },
    {
        "id": "07917",
        "title": "Neural Utility Functions",
        "track": "main",
        "status": "Poster",
        "abstract": "Current neural network architectures have no mechanism for explicitly reasoning about item trade-offs. Such trade-offs are important for popular tasks such as recommendation. The main idea of this work is to give neural networks inductive biases that are inspired by economic theories. To this end, we propose Neural Utility Functions, which directly optimize the gradients of a neural network so that they are more consistent with utility theory, a mathematical framework for modeling choice among items. We demonstrate that Neural Utility Functions can recover theoretical item relationships better than vanilla neural networks, analytically show existing neural networks are not quasi-concave and do not inherently reason about trade-offs, and that augmenting existing models with a utility loss function improves recommendation results. The Neural Utility Functions we propose are theoretically motivated, and yield strong empirical results.",
        "primary_area": "Machine Learning II",
        "author": "Porter Jenkins; Ahmad Farag; J. Stockton Jenkins; Huaxiu Yao; Suhang Wang; Zhenhui Li",
        "authorids": "",
        "aff": "Pennsylvania State University; Georgia Tech University; Brigham Young University; Pennsylvania State University; Pennsylvania State University; Pennsylvania State University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16966/16966-13-20460-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07917-neural-utility-functions/",
        "doi": "10.1609/aaai.v35i9.16966",
        "pdf_size": 172809
    },
    {
        "id": "05051",
        "title": "Neural-Symbolic Integration: A Compositional Perspective",
        "track": "main",
        "status": "Poster",
        "abstract": "Despite significant progress in the development of neural-symbolic frameworks, the question of how to integrate a neural and a symbolic system in a compositional manner remains open. Our work seeks to fill this gap by treating these two systems as black boxes to be integrated as modules into a single architecture, without making assumptions on their internal structure and semantics. Instead, we expect only that each module exposes certain methods for accessing the functions that the module implements: the symbolic module exposes a deduction method for computing the function's output on a given input, and an abduction method for computing the function's inputs for a given output; the neural module exposes a deduction method for computing the function's output on a given input, and an induction method for updating the function given input-output training instances. We are, then, able to show that a symbolic module --- with any choice for syntax and semantics, as long as the deduction and abduction methods are exposed --- can be cleanly integrated with a neural module, and facilitate the latter's efficient training, achieving empirical performance that exceeds that of previous work.",
        "primary_area": "Neuro-Symbolic AI",
        "author": "Efthymia Tsamoura; Timothy Hospedales; Loizos Michael",
        "authorids": "",
        "aff": "Samsung AI Research; Samsung AI Research; Open University of Cyprus CYENS Center of Excellence",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16639/16639-13-20133-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05051-neural-symbolic-integration-a-compositional-perspective/",
        "doi": "10.1609/aaai.v35i6.16639",
        "pdf_size": 754296
    },
    {
        "id": "04072",
        "title": "NeuralAC: Learning Cooperation and Competition Effects for Match Outcome Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "Match outcome prediction in group comparison setting is a challenging but important task. Existing works mainly focus on learning individual effects or mining limited interactions between teammates, which is not sufficient for capturing complex interactions between teammates as well as between opponents. Besides, the importance of interacting with different characters is still largely underexplored. To this end, we propose a novel Neural Attentional Cooperation-competition model (NeuralAC), which incorporates weighted-cooperation effects (i.e., intra-team interactions) and weighted-competition effects (i.e., inter-team interactions) for predicting match outcomes. Specifically, we first project individuals to latent vectors and learn complex interactions through deep neural networks. Then, we design two novel attention-based mechanisms to capture the importance of intra-team and inter-team interactions, which enhance NeuralAC with both accuracy and interpretability. Furthermore, we demonstrate NeuralAC can generalize several previous works. To evaluate the performances of NeuralAC, we conduct extensive experiments on four E-sports datasets. The experimental results clearly verify the effectiveness of NeuralAC compared with several state-of-the-art methods.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Yin Gu; Qi Liu; Kai Zhang; Zhenya Huang; Runze Wu; Jianrong Tao",
        "authorids": "",
        "aff": "University of Science and Technology of China; University of Science and Technology of China; University of Science and Technology of China; University of Science and Technology of China; NetEase Fuxi AI Lab; NetEase Fuxi AI Lab",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16528/16528-13-20022-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04072-neuralac-learning-cooperation-and-competition-effects-for-match-outcome-prediction/",
        "doi": "10.1609/aaai.v35i5.16528",
        "pdf_size": 926622
    },
    {
        "id": "03634",
        "title": "New Length Dependent Algorithm for Maximum Satisfiability Problem",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we study the computational complexity of the Maximum Satisfiability problem in terms of the length L of a given formula. We present an algorithm with running time O(1.0927^L), hence, improving the previously known best upper bound O(1.1058^L) developed more than 20 years ago by Bansal and Raman.  Theoretically speaking, our algorithm increases the length of solvable formulas by 13.3% (compare this to the recent breakthrough result for Maximum Satisfiability problem with respect to the number of clauses by Xu et al. in 2019 giving a 7.5% improvement). Besides, we propose a significantly simpler algorithm with running time O(1.1049^L). The algorithm outperforms Bansal's and Raman's algorithm in simplicity and running time.",
        "primary_area": "Constraint Satisfaction and Optimization",
        "author": "Vasily Alferov; Ivan Bliznets",
        "authorids": "",
        "aff": "JetBrains Research; HSE University St. Petersburg Department of Steklov Mathematical Institute of Russian Academy of Sciences",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16479/16479-13-19973-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03634-new-length-dependent-algorithm-for-maximum-satisfiability-problem/",
        "doi": "10.1609/aaai.v35i5.16479",
        "pdf_size": 135949
    },
    {
        "id": "14498",
        "title": "News Content Completion with Location-Aware Image Selection",
        "track": "main",
        "status": "Poster",
        "abstract": "News, as one of the fundamental social media types, typically contains both texts and images. Image selection, which involves choosing appropriate images according to some specified contexts, is crucial for formulating good news. However, it presents two challenges: where to place images and which images to use. The difficulties associated with this where-which problem lie in the fact that news typically contains linguistically rich text that delivers complex information and more than one image. In this paper, we propose a novel end-to-end two-stage framework to address these issues comprehensively. In the first stage, we identify key information in news by using location embeddings, which represent the local contextual information of each candidate location for image insertion. Then, in the second stage, we thoroughly examine the candidate images and select the most context-related ones to insert into each location identified in the first stage. We also introduce three insertion strategies to formulate different scenarios influencing the image selection procedure. Extensive experiments demonstrate the consistent superiority of the proposed framework in image selection.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Zhengkun Zhang; Jun Wang; Adam Jatowt; Zhe Sun; Shao-Ping Lu; Zhenglu Yang",
        "authorids": "",
        "aff": "Nankai University; Ludong University; Kyoto University; RIKEN; Nankai University; Nankai University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17704/17704-13-21198-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14498-news-content-completion-with-location-aware-image-selection/",
        "doi": "10.1609/aaai.v35i16.17704",
        "pdf_size": 543336
    },
    {
        "id": "11325",
        "title": "Newton Optimization on Helmholtz Decomposition for Continuous Games",
        "track": "main",
        "status": "Poster",
        "abstract": "Many learning problems involve multiple agents optimizing different interactive functions. In these problems, the standard policy gradient algorithms fail due to the non-stationarity of the setting and the different interests of each agent. In fact, algorithms must take into account the complex dynamics of these systems to guarantee rapid convergence towards a (local) Nash equilibrium. In this paper, we propose NOHD (Newton Optimization on Helmholtz Decomposition), a Newton-like algorithm for multi-agent learning problems based on the decomposition of the dynamics of the system in its irrotational (Potential) and solenoidal (Hamiltonian) component. This method ensures quadratic convergence in purely irrotational systems and pure solenoidal systems. Furthermore, we show that NOHD is attracted to stable fixed points in general multi-agent systems and repelled by strict saddle ones. Finally, we empirically compare the NOHD's performance with that of state-of-the-art algorithms on some bimatrix games and continuous Gridworlds environment.",
        "primary_area": "Multiagent Systems",
        "author": "Giorgia Ramponi; Marcello Restelli",
        "authorids": "",
        "aff": "Politecnico di Milano; Politecnico di Milano",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17350/17350-13-20844-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11325-newton-optimization-on-helmholtz-decomposition-for-continuous-games/",
        "doi": "10.1609/aaai.v35i13.17350",
        "pdf_size": 820901
    },
    {
        "id": "06644",
        "title": "Noise Estimation Using Density Estimation for Self-Supervised Multimodal Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "One of the key factors of enabling machine learning models to comprehend and solve real-world tasks is to leverage multimodal data. Unfortunately, annotation of multimodal data is challenging and expensive. Recently, self-supervised multimodal methods that combine vision and language were proposed to learn multimodal representations without annotation. However, these methods often choose to ignore the presence of high levels of noise and thus yield sub-optimal results. In this work, we show that the problem of noise estimation for multimodal data can be reduced to a multimodal density estimation task. Using multimodal density estimation, we propose a noise estimation building block for multimodal representation learning that is based strictly on the inherent correlation between different modalities. We demonstrate how our noise estimation can be broadly integrated and achieves comparable results to state-of-the-art performance on five different benchmark datasets for two challenging multimodal tasks: Video Question Answering and Text-To-Video Retrieval. Furthermore, we provide a theoretical probabilistic error bound substantiating our empirical results and analyze failure cases. Code: https://github.com/elad-amrani/ssml.",
        "primary_area": "Machine Learning I",
        "author": "Elad Amrani; Rami Ben-Ari; Daniel Rotman; Alex Bronstein",
        "authorids": "",
        "aff": "IBM Research Technion; IBM Research; IBM Research; Technion",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16822/16822-13-20316-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06644-noise-estimation-using-density-estimation-for-self-supervised-multimodal-learning/",
        "doi": "10.1609/aaai.v35i8.16822",
        "pdf_size": 2553342
    },
    {
        "id": "03119",
        "title": "Non-Autoregressive Coarse-to-Fine Video Captioning",
        "track": "main",
        "status": "Poster",
        "abstract": "It is encouraged to see that progress has been made to bridge videos and natural language. However, mainstream video captioning methods suffer from slow inference speed due to the sequential manner of autoregressive decoding, and prefer generating generic descriptions due to the insufficient training of visual words (e.g., nouns and verbs) and inadequate decoding paradigm. In this paper, we propose a non-autoregressive decoding based model with a coarse-to-fine captioning procedure to alleviate these defects. In implementations, we employ a bi-directional self-attention based network as our language model for achieving inference speedup, based on which we decompose the captioning procedure into two stages, where the model has different focuses. Specifically, given that visual words determine the semantic correctness of captions, we design a mechanism of generating visual words to not only promote the training of scene-related words but also capture relevant details from videos to construct a coarse-grained sentence ``template''. Thereafter, we devise dedicated decoding algorithms that fill in the ``template'' with suitable words and modify inappropriate phrasing via iterative refinement to obtain a fine-grained description. Extensive experiments on two mainstream video captioning benchmarks, i.e., MSVD and MSR-VTT, demonstrate that our approach achieves state-of-the-art performance, generates diverse descriptions, and obtains high inference efficiency.",
        "primary_area": "Computer Vision III",
        "author": "Bang Yang; Yuexian Zou; Fenglin Liu; Can Zhang",
        "authorids": "",
        "aff": "Peking University; Peking University Peng Cheng Laboratory; Peking University; Peking University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16421/16421-13-19915-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03119-non-autoregressive-coarse-to-fine-video-captioning/",
        "doi": "10.1609/aaai.v35i4.16421",
        "pdf_size": 2375781
    },
    {
        "id": "10460",
        "title": "Non-asymptotic Convergence of Adam-type Reinforcement Learning Algorithms under Markovian Sampling",
        "track": "main",
        "status": "Poster",
        "abstract": "Despite the wide applications of Adam in reinforcement learning (RL), the theoretical convergence of Adam-type RL algorithms has not been established. This paper provides the first such convergence analysis for two fundamental RL algorithms of policy gradient (PG) and temporal difference (TD) learning that incorporate AMSGrad updates (a standard alternative of Adam in theoretical analysis), referred to as PG-AMSGrad and TD-AMSGrad, respectively. Moreover, our analysis focuses on Markovian sampling for both algorithms. We show that under general nonlinear function approximation, PG-AMSGrad with a constant stepsize converges to a neighborhood of a stationary point at the rate of O(1/T) (where T denotes the number of iterations), and with a diminishing stepsize converges exactly to a stationary point at the rate of O(log^2 T/\u221aT). Furthermore, under linear function approximation, TD-AMSGrad with a constant stepsize converges to a neighborhood of the global optimum at the rate of O(1/T), and with a diminishing stepsize converges exactly to the global optimum at the rate of O(log T/\u221aT). Our study develops new techniques for analyzing the Adam-type RL algorithms under Markovian sampling.",
        "primary_area": "Machine Learning V",
        "author": "Huaqing Xiong; Tengyu Xu; Yingbin Liang; Wei  Zhang",
        "authorids": "",
        "aff": "Department of Electrical and Computer Engineering, The Ohio State University; Department of Electrical and Computer Engineering, The Ohio State University; Department of Electrical and Computer Engineering, The Ohio State University; Department of Mechanical and Energy Engineering, Southern University of Science and Technology Peng Cheng Laboratory",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17252/17252-13-20746-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10460-non-asymptotic-convergence-of-adam-type-reinforcement-learning-algorithms-under-markovian-sampling/",
        "doi": "10.1609/aaai.v35i12.17252",
        "pdf_size": 166220
    },
    {
        "id": "04249",
        "title": "Noninvasive Self-attention for Side Information Fusion in Sequential Recommendation",
        "track": "main",
        "status": "Poster",
        "abstract": "Sequential recommender systems aim to model users\u2019 evolving interests from their historical behaviors, and hence make customized time-relevant recommendations. Compared with traditional models, deep learning approaches such as CNN and RNN have achieved remarkable advancements in recommendation tasks. Recently, the BERT framework also emerges as a promising method, benefited from its self-attention mechanism in processing sequential data. However, one limitation of the original BERT framework is that it only considers one input source of the natural language tokens. It is still an open question to leverage various types of information under the BERT framework. Nonetheless, it is intuitively appealing to utilize other side information, such as item category or tag, for more comprehensive depictions and better recommendations. In our pilot experiments, we found naive approaches, which directly fuse types of side information into the item embeddings, usually bring very little or even negative effects. Therefore, in this paper, we propose the NOn-inVasive self-Attention mechanism (NOVA) to leverage side information effectively under the BERT framework. NOVA makes use of side information to generate better attention distribution, rather than directly altering the item embeddings, which may cause information overwhelming. We validate the NOVA-BERT model on both public and commercial datasets, and our method can stably outperform the state-of-the-art models with negligible computational overheads.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Chang Liu; Xiaoguang Li; Guohao Cai; Zhenhua Dong; Hong Zhu; Lifeng Shang",
        "authorids": "",
        "aff": "The University of Hong Kong; Huawei Noah's Ark Lab; Huawei Noah's Ark Lab; Huawei Noah's Ark Lab; Huawei Noah's Ark Lab; Huawei Noah's Ark Lab",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16549/16549-13-20043-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04249-noninvasive-self-attention-for-side-information-fusion-in-sequential-recommendation/",
        "doi": "10.1609/aaai.v35i5.16549",
        "pdf_size": 643926
    },
    {
        "id": "08279",
        "title": "Norm-Based Generalisation Bounds for Deep Multi-Class Convolutional Neural Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "We show generalisation error bounds for deep learning with two main improvements over the state of the art. (1) Our bounds have no explicit dependence on the number of classes except for logarithmic factors. This holds even when formulating the bounds in terms of the Frobenius-norm of the weight matrices, where previous bounds exhibit at least a square-root dependence on the number of classes. (2) We adapt the classic Rademacher analysis of DNNs to incorporate weight sharing---a task of fundamental theoretical importance which was previously attempted only under very restrictive assumptions. In our results, each convolutional filter contributes only once to the bound, regardless of how many times it is applied. Further improvements exploiting pooling and sparse connections are provided. The presented bounds scale as the norms of the parameter matrices, rather than the number of parameters. In particular, contrary to bounds based on parameter counting, they are asymptotically tight (up to log factors) when the weights approach initialisation, making them suitable as a basic ingredient in bounds sensitive to the optimisation procedure. We also show how to adapt the recent technique of loss function augmentation to replace spectral norms by empirical analogues whilst maintaining the advantages of our approach.",
        "primary_area": "Machine Learning II",
        "author": "Antoine Ledent; Waleed Mustafa; Yunwen Lei; Marius Kloft",
        "authorids": "",
        "aff": "TU Kaiserslautern; TU Kaiserslautern; TU Kaiserslautern Southern Univ. of Science and Technology; TU Kaiserslautern",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17007/17007-13-20501-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08279-norm-based-generalisation-bounds-for-deep-multi-class-convolutional-neural-networks/",
        "doi": "10.1609/aaai.v35i9.17007",
        "pdf_size": 195253
    },
    {
        "id": "12258",
        "title": "NuQClq: An Effective Local Search Algorithm for Maximum Quasi-Clique Problem",
        "track": "main",
        "status": "Poster",
        "abstract": "The maximum quasi-clique problem (MQCP) is an important extension of maximum clique problem with wide applications. Recent heuristic MQCP algorithms can hardly solve large and hard graphs effectively. This paper develops an efficient local search algorithm named NuQClq for the MQCP, which has two main ideas. First, we propose a novel vertex selection strategy, which utilizes cumulative saturation information to be a selection criterion when the candidate vertices have equal values on the primary scoring function. Second, a variant of configuration checking named BoundedCC is designed by setting an upper bound for the threshold of forbidding strength. When the threshold value of vertex exceeds the upper bound, we reset its threshold value to increase the diversity of search process. Experiments on a broad range of classic benchmarks and sparse instances show that NuQClq significantly outperforms the state-of-the-art MQCP algorithms for most instances.",
        "primary_area": "Search and Optimization",
        "author": "Jiejiang Chen; Shaowei Cai; Shiwei Pan; Yiyuan Wang; Qingwei Lin; Mengyu Zhao; Minghao Yin",
        "authorids": "",
        "aff": "School of Computer Science and Information Technology, Northeast Normal University, China; State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences, China School of Computer Science and Technology, University of Chinese Academy of Sciences, China; School of Computer Science and Information Technology, Northeast Normal University, China; School of Computer Science and Information Technology, Northeast Normal University, China Key Laboratory of Applied Statistics of MOE, Northeast Normal University, Changchun, China; Microsoft Research, China; School of Computer Science and Information Technology, Northeast Normal University, China; School of Computer Science and Information Technology, Northeast Normal University, China Key Laboratory of Applied Statistics of MOE, Northeast Normal University, Changchun, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17455/17455-13-20949-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12258-nuqclq-an-effective-local-search-algorithm-for-maximum-quasi-clique-problem/",
        "doi": "10.1609/aaai.v35i14.17455",
        "pdf_size": 199726
    },
    {
        "id": "13780",
        "title": "Nutri-bullets: Summarizing Health Studies by Composing Segments",
        "track": "main",
        "status": "Poster",
        "abstract": "We introduce Nutri-bullets, a multi-document summarization task for health and nutrition. First, we present two datasets of food and health summaries from multiple scientific studies. Furthermore, we propose a novel extract-compose model to solve the problem in the regime of limited parallel data. We explicitly select key spans from several abstracts using a policy network, followed by composing the selected spans to present a summary via a task specific language model. Compared to state-of-the-art methods, our approach leads to more faithful, relevant and diverse summarization -- properties imperative to this application. For instance, on the BreastCancer dataset our approach gets a more than 50% improvement on relevance and faithfulness.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Darsh J Shah; Lili Yu; Tao Lei; Regina Barzilay",
        "authorids": "",
        "aff": "Massachusetts Institute of Technology; Asapp Inc.; ASAPP Inc.; Massachusetts Institute of Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17624/17624-13-21118-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13780-nutri-bullets-summarizing-health-studies-by-composing-segments/",
        "doi": "10.1609/aaai.v35i15.17624",
        "pdf_size": 737407
    },
    {
        "id": "14138",
        "title": "Nystr\u00f6mformer: A Nystr\u00f6m-based Algorithm for Approximating Self-Attention",
        "track": "main",
        "status": "Poster",
        "abstract": "Transformers have emerged as a powerful tool for a broad range of natural language processing tasks. A key component that drives the impressive performance of Transformers is the self-attention mechanism that encodes the influence or dependence of other tokens on each specific token. While beneficial, the quadratic complexity of self-attention on the input sequence length has limited its application to longer sequences - a topic being actively studied in the community. To address this limitation, we propose Nystr\u00f6mformer - a model that exhibits favorable scalability as a function of sequence length. Our idea is based on adapting the Nystr\u00f6m method to approximate standard self-attention with O(n) complexity. The scalability of Nystr\u00f6mformer enables application to longer sequences with thousands of tokens. We perform evaluations on multiple downstream tasks on the GLUE benchmark and IMDB reviews with standard sequence length, and find that our Nystr\u00f6mformer performs comparably, or in a few cases, even slightly better, than standard self-attention. On longer sequence tasks in the Long Range Arena (LRA) benchmark, Nystr\u00f6mformer performs favorably relative to other efficient self-attention methods. Our code is available at https://github.com/mlpen/Nystromformer.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Yunyang Xiong; Zhanpeng Zeng; Rudrasis Chakraborty; Mingxing Tan; Glenn Fung; Yin Li; Vikas Singh",
        "authorids": "",
        "aff": "University of Wisconsin-Madison; University of Wisconsin-Madison; UC Berkeley; Google Brain; American Family Insurance; University of Wisconsin-Madison; University of Wisconsin-Madison",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17664/17664-13-21158-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14138-nystromformer-a-nystrom-based-algorithm-for-approximating-self-attention/",
        "doi": "10.1609/aaai.v35i16.17664",
        "pdf_size": 1052856
    },
    {
        "id": "07780",
        "title": "OPQ: Compressing Deep Neural Networks with One-shot Pruning-Quantization",
        "track": "main",
        "status": "Poster",
        "abstract": "As Deep Neural Networks (DNNs) usually are overparameterized and have millions of weight parameters, it is challenging to deploy these large DNN models on resource-constrained hardware platforms, e.g., smartphones. Numerous network compression methods such as pruning and quantization are proposed to reduce the model size significantly, of which the key is to find suitable compression allocation (e.g., pruning sparsity and quantization codebook) of each layer.  Existing solutions obtain the compression allocation in an iterative/manual fashion while finetuning the compressed model, thus suffering from the efficiency issue. Different from the prior art, we propose a novel One-shot Pruning-Quantization (OPQ) in this paper, which analytically solves the compression allocation with pre-trained weight parameters only. During finetuning, the compression module is fixed and only weight parameters are updated. To our knowledge, OPQ is the first work that reveals pre-trained model is sufficient for solving pruning and quantization simultaneously, without any complex iterative/manual optimization at the finetuning stage. Furthermore, we propose a unified channel-wise quantization method that enforces all channels of each layer to share a common codebook, which leads to low bit-rate allocation without introducing extra overhead brought by traditional channel-wise quantization. Comprehensive experiments on ImageNet with AlexNet/MobileNet-V1/ResNet-50 show that our method improves accuracy and training efficiency while obtains significantly higher compression rates compared to the state-of-the-art.",
        "primary_area": "Machine Learning II",
        "author": "Peng Hu; Xi Peng; Hongyuan Zhu; Mohamed M. Sabry Aly; Jie Lin",
        "authorids": "",
        "aff": "Institute for Infocomm Research, Agency for Science, Technology and Research, Singapore College of Computer Science, Sichuan University, Chengdu 610065, China; College of Computer Science, Sichuan University, Chengdu 610065, China; Institute for Infocomm Research, Agency for Science, Technology and Research, Singapore; Nanyang Technological University; Institute for Infocomm Research, Agency for Science, Technology and Research, Singapore",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16950/16950-13-20444-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07780-opq-compressing-deep-neural-networks-with-one-shot-pruning-quantization/",
        "doi": "10.1609/aaai.v35i9.16950",
        "pdf_size": 398817
    },
    {
        "id": "09223",
        "title": "OT-Flow: Fast and Accurate Continuous Normalizing Flows via Optimal Transport",
        "track": "main",
        "status": "Poster",
        "abstract": "A normalizing flow is an invertible mapping between an arbitrary probability distribution and a standard normal distribution; it can be used for density estimation and statistical inference. Computing the flow follows the change of variables formula and thus requires invertibility of the mapping and an efficient way to compute the determinant of its Jacobian. To satisfy these requirements, normalizing flows typically consist of carefully chosen components. Continuous normalizing flows (CNFs) are mappings obtained by solving a neural ordinary differential equation (ODE). The neural ODE's dynamics can be chosen almost arbitrarily while ensuring invertibility. Moreover, the log-determinant of the flow's Jacobian can be obtained by integrating the trace of the dynamics' Jacobian along the flow. Our proposed OT-Flow approach tackles two critical computational challenges that limit a more widespread use of CNFs. First, OT-Flow leverages optimal transport (OT) theory to regularize the CNF and enforce straight trajectories that are easier to integrate. Second, OT-Flow features exact trace computation with time complexity equal to trace estimators used in existing CNFs. On five high-dimensional density estimation and generative modeling tasks, OT-Flow performs competitively to state-of-the-art CNFs while on average requiring one-fourth of the number of weights with an 8x speedup in training time and 24x speedup in inference.",
        "primary_area": "Machine Learning III",
        "author": "Derek Onken; Samy Wu Fung; Xingjian Li; Lars Ruthotto",
        "authorids": "",
        "aff": "Emory University; UCLA; Emory University; Emory University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17113/17113-13-20607-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09223-ot-flow-fast-and-accurate-continuous-normalizing-flows-via-optimal-transport/",
        "doi": "10.1609/aaai.v35i10.17113",
        "pdf_size": 2357439
    },
    {
        "id": "03136",
        "title": "Object Relation Attention for Image Paragraph Captioning",
        "track": "main",
        "status": "Poster",
        "abstract": "Image paragraph captioning aims to automatically generate a paragraph from a given image. It is an extension of image captioning in terms of generating multiple sentences instead of a single one, and it is more challenging because paragraphs are longer, more informative, and more linguistically complicated.  Because a paragraph consists of several sentences, an effective image paragraph captioning method should generate consistent sentences rather than contradictory ones. It is still an open question how to achieve this goal, and for it we propose a method to incorporate objects' spatial coherence into a language-generating model.  For every two overlapping objects, the proposed method concatenates their raw visual features to create two directional pair features and learns weights optimizing those pair features as relation-aware object features for a language-generating model. Experimental results show that the proposed network extracts effective object features for image paragraph captioning and achieves promising performance against existing methods.",
        "primary_area": "Computer Vision III",
        "author": "Li-Chuan Yang; Chih-Yuan Yang; Jane Yung-jen Hsu",
        "authorids": "",
        "aff": "National Taiwan University; National Taiwan University; National Taiwan University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16423/16423-13-19917-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03136-object-relation-attention-for-image-paragraph-captioning/",
        "doi": "10.1609/aaai.v35i4.16423",
        "pdf_size": 3146617
    },
    {
        "id": "02647",
        "title": "Object-Centric Image Generation from Layouts",
        "track": "main",
        "status": "Poster",
        "abstract": "We begin with the hypothesis that a model must be able to understand individual objects and relationships between objects in order to generate complex scenes with multiple objects well. Our layout-to-image-generation method, which we call Object-Centric Generative Adversarial Network (or OC-GAN), relies on a novel Scene-Graph Similarity Module (SGSM). The SGSM learns representations of the spatial relationships between objects in the scene, which lead to our model's improved layout-fidelity. We also propose changes to the conditioning mechanism of the generator that enhance its object instance-awareness. Apart from improving image quality, our contributions mitigate two failure modes in previous approaches: (1) spurious objects being generated without corresponding bounding boxes in the layout, and (2) overlapping bounding boxes in the layout leading to merged objects in images. Extensive quantitative evaluation and ablation studies demonstrate the impact of our contributions, with our model outperforming previous state-of-the-art approaches on both the COCO-Stuff and Visual Genome datasets. Finally, we address an important limitation of evaluation metrics used in previous works by introducing SceneFID -- an object-centric adaptation of the popular Fr\u00e9chet Inception Distance metric, that is better suited for multi-object images.",
        "primary_area": "Computer Vision II",
        "author": "Tristan Sylvain; Pengchuan Zhang; Yoshua Bengio; R Devon Hjelm; Shikhar Sharma",
        "authorids": "",
        "aff": "Mila University of Montreal; Microsoft Research AI; Mila University of Montreal CIFAR Senior Fellow; Microsoft Research Mila; Microsoft Turing",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16368/16368-13-19862-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02647-object-centric-image-generation-from-layouts/",
        "doi": "10.1609/aaai.v35i3.16368",
        "pdf_size": 1213848
    },
    {
        "id": "09055",
        "title": "Objective-Based Hierarchical Clustering of Deep Embedding Vectors",
        "track": "main",
        "status": "Poster",
        "abstract": "We initiate a comprehensive experimental study of objective-based hierarchical clustering methods on massive datasets consisting of deep embedding vectors from computer vision and NLP applications. This includes a large variety of image embedding (ImageNet, ImageNetV2, NaBirds), word embedding (Twitter, Wikipedia), and sentence embedding (SST-2) vectors from several popular recent models (e.g. ResNet, ResNext, Inception V3, SBERT). Our study includes datasets with up to 4.5 million data points with embedding dimensions up to 2048.  In order to address the challenge of scaling up hierarchical clustering to such large datasets we propose a new practical hierarchical clustering algorithm B++&C. It gives a 5%/20% improvement on average for the popular Moseley-Wang (MW)/ Cohen-Addad et al. (CKMM) objectives (normalized) compared to a wide range of classic methods and recent heuristics. We also introduce a theoretical algorithm B2SAT&C which achieves a 0.74-approximation for the CKMM objective in polynomial time. This is the first substantial improvement over the trivial 2/3-approximation achieved by a random binary tree. Prior to this work, the best poly-time approximation of \u22482/3 + 0.0004 was due to Charikar et al. (SODA\u201919)",
        "primary_area": "Machine Learning III",
        "author": "Stanislav Naumov; Grigory Yaroslavtsev; Dmitrii Avdiukhin",
        "authorids": "",
        "aff": "ITMO University; Indiana University, Bloomington; Indiana University, Bloomington",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17094/17094-13-20588-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09055-objective-based-hierarchical-clustering-of-deep-embedding-vectors/",
        "doi": "10.1609/aaai.v35i10.17094",
        "pdf_size": 171210
    },
    {
        "id": "03841",
        "title": "On Continuous Local BDD-Based Search for Hybrid SAT Solving",
        "track": "main",
        "status": "Poster",
        "abstract": "We explore the potential of continuous local search (CLS) in SAT solving by proposing a novel approach for finding a solution of a hybrid system of Boolean constraints. The algorithm is based on CLS combined with belief propagation on binary decision diagrams (BDDs). Our framework accepts all Boolean constraints that admit compact BDDs, including symmetric Boolean constraints and small-coefficient pseudo-Boolean constraints as interesting families. We propose a novel algorithm for efficiently computing the gradient needed by CLS. We study the capabilities and limitations of our versatile CLS solver, GradSAT, by applying it on many benchmark instances.  The experimental results indicate that GradSAT can be a useful addition to the portfolio of existing SAT and MaxSAT solvers for solving Boolean satisfiability and optimization problems.",
        "primary_area": "Constraint Satisfaction and Optimization",
        "author": "Anastasios Kyrillidis; Moshe Vardi; Zhiwei Zhang",
        "authorids": "",
        "aff": "Rice University; Rice University; Rice University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16502/16502-13-19996-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03841-on-continuous-local-bdd-based-search-for-hybrid-sat-solving/",
        "doi": "10.1609/aaai.v35i5.16502",
        "pdf_size": 1336308
    },
    {
        "id": "10621",
        "title": "On Convergence of Gradient Expected Sarsa(\u03bb)",
        "track": "main",
        "status": "Poster",
        "abstract": "We study the convergence of Expected Sarsa(\u03bb) with function approximation. We show that with off-line es- timate (multi-step bootstrapping) to ExpectedSarsa(\u03bb) is unstable for off-policy learning. Furthermore, based on convex-concave saddle-point framework, we propose a con- vergent Gradient Expected Sarsa(\u03bb) (GES(\u03bb)) algorithm. The theoretical analysis shows that the proposed GES(\u03bb) converges to the optimal solution at a linear convergence rate under true gradient setting. Furthermore, we develop a Lyapunov function technique to investigate how the step- size influences finite-time performance of GES(\u03bb). Addition- ally, such a technique of Lyapunov function can be poten- tially generalized to other gradient temporal difference algo- rithms. Finally, our experiments verify the effectiveness of our GES(\u03bb). For the details of proof, please refer to https: //arxiv.org/pdf/2012.07199.pdf.",
        "primary_area": "Machine Learning V",
        "author": "Long Yang; Gang Zheng; Yu Zhang; Qian Zheng; Pengfei Li; Gang Pan",
        "authorids": "",
        "aff": "Zhejiang University, China; Zhejiang University, China; Zhejiang University, China; Nanyang Technological University,Singapore; Zhejiang University, China; Zhejiang University, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17270/17270-13-20764-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10621-on-convergence-of-gradient-expected-sarsa-%ce%bb/",
        "doi": "10.1609/aaai.v35i12.17270",
        "pdf_size": 317397
    },
    {
        "id": "04147",
        "title": "On Estimating Recommendation Evaluation Metrics under Sampling",
        "track": "main",
        "status": "Poster",
        "abstract": "Since the recent studies  (KDD'20) done by Krichene and Rendle on the sampling based top-k evaluation metric for recommendation,  there have been a lot of debate on the validity of using sampling for evaluating recommendation algorithms. Though their work and the recent work done by Li et. al. (KDD'20) have proposed some basic approach for mapping the sampling based metrics to their counter-part in the global evaluation which uses the entire dataset, there is still lack of understanding how sampling should be used for recommendation evaluation, and the proposed approaches either are rather ad-hoc or can only work on simple metrics, like Recall/Hit-Ratio. In this paper, we introduce some principled approach to derive the estimators of top-k metric based on sampling. Our approaches utilize the weighted MLE and maximal entropy approach to recover the global rank distribution and then utilize that for estimation. The experimental results shows significant advantages of using our approaches for evaluating recommendation algorithms based on top-k metrics.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Ruoming Jin; Dong Li; Benjamin Mudrak; Jing Gao; Zhi Liu",
        "authorids": "",
        "aff": "Kent State University; Kent State University; Kent State University; iLambda; iLambda",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16537/16537-13-20031-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04147-on-estimating-recommendation-evaluation-metrics-under-sampling/",
        "doi": "10.1609/aaai.v35i5.16537",
        "pdf_size": 454293
    },
    {
        "id": "06514",
        "title": "On Exploiting Hitting Sets for Model Reconciliation",
        "track": "main",
        "status": "Poster",
        "abstract": "In human-aware planning, a planning agent may need to provide an explanation to a human user on why its plan is optimal. A popular approach to do this is called model reconciliation, where the agent tries to reconcile the differences in its model and the human's model such that the plan is also optimal in the human's model. In this paper, we present a logic-based framework for model reconciliation that extends beyond the realm of planning. More specifically, given a knowledge base KB1 entailing a formula phi and a second knowledge base KB2 not entailing it, model reconciliation seeks an explanation, in the form of a cardinality-minimal subset of KB1, whose integration into KB2 makes the entailment possible. Our approach, based on ideas originating in the context of analysis of inconsistencies, exploits the existing hitting set duality between minimal correction sets (MCSes) and minimal unsatisfiable sets (MUSes) in order to identify an appropriate explanation. However, differently from those works targeting inconsistent formulas, which assume a single knowledge base, MCSes and MUSes are computed over two distinct knowledge bases. We conclude our paper with an empirical evaluation of the newly introduced approach on planning instances, where we show how it outperforms an existing state-of-the-art solver, and generic non-planning instances from recent SAT competitions, for which no other solver exists.",
        "primary_area": "Knowledge Representation and Reasoning",
        "author": "Stylianos Loukas Vasileiou; Alessandro Previti; William Yeoh",
        "authorids": "",
        "aff": "Washington University in St Louis; Ericsson Research; Washington University in St. Louis",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16807/16807-13-20301-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06514-on-exploiting-hitting-sets-for-model-reconciliation/",
        "doi": "10.1609/aaai.v35i7.16807",
        "pdf_size": 143335
    },
    {
        "id": "05312",
        "title": "On Fair Division under Heterogeneous Matroid Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "We study fair allocation of indivisible goods among additive agents with feasibility constraints.  In these settings, every agent is restricted to get a bundle among a specified set of feasible bundles. Such scenarios have been of great interest to the AI community due to their applicability to real-world problems. Following some impossibility results, we restrict attention to matroid feasibility constraints that capture natural scenarios, such as the allocation of shifts to medical doctors, and the allocation of conference papers to referees.  We focus on the common fairness notion of envy-freeness up to one good (EF1). Previous algorithms for finding EF1 allocations are either restricted to agents with identical feasibility constraints, or allow free disposal of items. An open problem is the existence of EF1 complete allocations among heterogeneous agents, where the heterogeneity is both in the agents' feasibility constraints and in their valuations. In this work, we make progress on this problem by providing positive and negative results for different matroid and valuation types. Among other results, we devise poly-time algorithms for finding EF1 allocations in the following settings: (i) n agents with heterogeneous partition matroids and heterogeneous binary valuations, (ii) 2 agents with heterogeneous partition matroids and heterogeneous valuations, and (iii) at most 3 agents with heterogeneous binary valuations and identical base-orderable matroids.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Amitay Dror; Michal Feldman; Erel Segal-Halevi",
        "authorids": "",
        "aff": "Tel-Aviv University; Tel-Aviv University Microsoft Research; Ariel University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16670/16670-13-20164-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05312-on-fair-division-under-heterogeneous-matroid-constraints/",
        "doi": "10.1609/aaai.v35i6.16670",
        "pdf_size": 152297
    },
    {
        "id": "05595",
        "title": "On Fair and Efficient Allocations of Indivisible Goods",
        "track": "main",
        "status": "Poster",
        "abstract": "We study the problem of fair and efficient allocation of a set of indivisible goods to agents with additive valuations using the popular fairness notions of envy-freeness up to one good (EF1) and equitability up to one good (EQ1) in conjunction with Pareto-optimality (PO). There exists a pseudo-polynomial time algorithm to compute an EF1+PO allocation, and a non-constructive proof of existence of allocations that are both EF1 and fractionally Pareto-optimal (fPO). We present a pseudo-polynomial time algorithm to compute an EF1+fPO allocation, thereby improving the earlier results. Our techniques also enable us to show that an EQ1+fPO allocation always exists when the values are positive, and that it can be computed in pseudo-polynomial time.  We also consider the class of k-ary instances where k is a constant, i.e., each agent has at most k different values for the goods. We show that for such instances an EF1+fPO allocation can be computed in polynomial time. When all values are positive, we show that an EQ1+fPO allocation for such instances can be computed in polynomial time. Next, we consider instances where the number of agents is constant, and show that an EF1+PO (also EQ1+PO) allocation can be computed in polynomial time. These results significantly extend the polynomial-time computability beyond the known cases of binary or identical valuations.  Further, we show that the problem of computing an EF1+PO allocation polynomial-time reduces to a problem in the complexity class PLS. We also design a polynomial-time algorithm that computes Nash welfare maximizing allocations when there are constantly many agents with constant many different values for the goods.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Aniket Murhekar; Jugal Garg",
        "authorids": "",
        "aff": "University of Illinois, Urbana-Champaign; University of Illinois, Urbana-Champaign",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16703/16703-13-20197-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05595-on-fair-and-efficient-allocations-of-indivisible-goods/",
        "doi": "10.1609/aaai.v35i6.16703",
        "pdf_size": 150818
    },
    {
        "id": "11575",
        "title": "On Generating Plausible Counterfactual and Semi-Factual Explanations for Deep Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "There is a growing concern that the recent progress made in AI, especially regarding the predictive competence of deep learning models, will be undermined by a failure to properly explain their operation and outputs. In response to this disquiet, counterfactual explanations have become very popular in eXplainable AI (XAI) due to their asserted computational, psychological, and legal benefits. In contrast however, semi-factuals (which appear to be equally useful) have surprisingly received no attention. Most counterfactual methods address tabular rather than image data, partly because the non-discrete nature of images makes good counterfactuals difficult to define; indeed, generating plausible counterfactual images which lie on the data manifold is also problematic. This paper advances a novel method for generating plausible counterfactuals and semi-factuals for black-box CNN classifiers doing computer vision. The present method, called PlausIble Exceptionality-based Contrastive Explanations (PIECE), modifies all \u201cexceptional\u201d features in a test image to be \u201cnormal\u201d from the perspective of the counterfactual class, to generate plausible counterfactual images. Two controlled experiments compare this method to others in the literature, showing that PIECE generates highly plausible counterfactuals (and the best semi-factuals) on several benchmark measures.",
        "primary_area": "Philosophy and Ethics of AI",
        "author": "Eoin M. Kenny; Mark T Keane",
        "authorids": "",
        "aff": "University College Dublin, Dublin, Ireland Insight Centre for Data Analytics, UCD, Dublin, Ireland VistaMilk SFI Research Centre; University College Dublin, Dublin, Ireland Insight Centre for Data Analytics, UCD, Dublin, Ireland VistaMilk SFI Research Centre",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17377/17377-13-20871-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11575-on-generating-plausible-counterfactual-and-semi-factual-explanations-for-deep-learning/",
        "doi": "10.1609/aaai.v35i13.17377",
        "pdf_size": 683512
    },
    {
        "id": "06661",
        "title": "On Lipschitz Regularization of Convolutional Layers using Toeplitz Matrix Theory",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper tackles the problem of Lipschitz regularization of Convolutional Neural Networks. Lipschitz regularity is now established as a key property of modern deep learning with implications in training stability, generalization, robustness against adversarial examples, etc. However, computing the exact value of the Lipschitz constant of a neural network is known to be NP-hard. Recent attempts from the literature introduce upper bounds to approximate this constant that are either efficient but loose or accurate but computationally expensive. In this work, by leveraging the theory of Toeplitz matrices, we introduce a new upper bound for convolutional layers that is both tight and easy to compute. Based on this result we devise an algorithm to train Lipschitz regularized Convolutional Neural Networks.",
        "primary_area": "Machine Learning I",
        "author": "Alexandre Araujo; Benjamin Negrevergne; Yann Chevaleyre; Jamal Atif",
        "authorids": "",
        "aff": "Universit\u00e9 Paris-Dauphine; Universit\u00e9 Paris-Dauphine; Universit\u00e9 Paris Dauphine; Universit\u00e9 Paris-Dauphine",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16824/16824-13-20318-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06661-on-lipschitz-regularization-of-convolutional-layers-using-toeplitz-matrix-theory/",
        "doi": "10.1609/aaai.v35i8.16824",
        "pdf_size": 577839
    },
    {
        "id": "06966",
        "title": "On Online Optimization: Dynamic Regret Analysis of Strongly Convex and Smooth Problems",
        "track": "main",
        "status": "Poster",
        "abstract": "The regret bound of dynamic online learning algorithms is often expressed in terms of the variation in the function sequence (V_T) and/or the path-length of the minimizer sequence after T rounds. For strongly convex and smooth functions, Zhang et al. (2017) establish the squared path-length of the minimizer sequence (C*_{2,T}) as a lower bound on regret. They also show that online gradient descent (OGD) achieves this lower bound using multiple gradient queries per round. In this paper, we focus on unconstrained online optimization. We first show that a preconditioned variant of OGD achieves O(min{C*_T,C*_{2,T}}) with one gradient query per round (C*_T refers to the normal path-length). We then propose online optimistic Newton (OON) method for the case when the first and second order information of the function sequence is predictable. The regret bound of OON is captured via the quartic path-length of the minimizer sequence (C*_{4,T}), which can be much smaller than C*_{2,T}. We finally show that by using multiple gradients for OGD, we can achieve an upper bound of O(min{C*_{2,T},V_T}) on regret.",
        "primary_area": "Machine Learning I",
        "author": "Ting-Jui Chang; Shahin Shahrampour",
        "authorids": "",
        "aff": "Texas A&M University; Texas A&M University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16858/16858-13-20352-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06966-on-online-optimization-dynamic-regret-analysis-of-strongly-convex-and-smooth-problems/",
        "doi": "10.1609/aaai.v35i8.16858",
        "pdf_size": 192292
    },
    {
        "id": "14050",
        "title": "On Scalar Embedding of Relative Positions in Attention Models",
        "track": "main",
        "status": "Poster",
        "abstract": "Attention with positional encoding has been demonstrated as a powerful component in modern neural network models, such as transformers. However, why positional encoding works well in attention models remains largely unanswered. In this paper, we study the scalar relative positional encoding (SRPE) proposed in the T5 transformer. Such an encoding method has two features. First, it uses a scalar to embed relative positions. Second, the relative positions are bucketized using a fixed heuristic algorithm, and positions in the same bucket share the same embedding. In this work, we show that SRPE in attention has an elegant probabilistic interpretation. More specifically, the positional encoding serves to produce a prior distribution for the attended positions. The resulting attentive distribution can be viewed as a posterior distribution of the attended position given the observed input sequence. Furthermore, we propose a new SRPE (AT5) that adopts a learnable bucketization protocol and automatically adapts to the dependency range specific to the learning task. Empirical studies show that the AT5 achieves superior performance than the T5's SRPE.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Junshuang Wu; Richong Zhang; Yongyi Mao; Junfan Chen",
        "authorids": "",
        "aff": "Beihang University; Beihang University; University of Ottawa; Beihang University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17654/17654-13-21148-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14050-on-scalar-embedding-of-relative-positions-in-attention-models/",
        "doi": "10.1609/aaai.v35i16.17654",
        "pdf_size": 341275
    },
    {
        "id": "08828",
        "title": "On the Adequacy of Untuned Warmup for Adaptive Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "Adaptive optimization algorithms such as Adam (Kingma and Ba, 2014) are widely used in deep learning. The stability of such algorithms is often improved with a warmup schedule for the learning rate. Motivated by the difficulty of choosing and tuning warmup schedules, recent work proposes automatic variance rectification of Adam's adaptive learning rate, claiming that this rectified approach (\"RAdam\") surpasses the vanilla Adam algorithm and reduces the need for expensive tuning of Adam with warmup. In this work, we refute this analysis and provide an alternative explanation for the necessity of warmup based on the magnitude of the update term, which is of greater relevance to training stability. We then provide some \"rule-of-thumb\" warmup schedules, and we demonstrate that simple untuned warmup of Adam performs more-or-less identically to RAdam in typical practical settings. We conclude by suggesting that practitioners stick to linear warmup with Adam, with a sensible default being linear warmup over 2 / (1 - \u03b2\u2082) training iterations.",
        "primary_area": "Machine Learning III",
        "author": "Jerry Ma; Denis Yarats",
        "authorids": "",
        "aff": "Booth School of Business, University of Chicago U.S. Patent and Trademark Office, Department of Commerce; Courant Institute of Mathematical Sciences, New York University Facebook AI Resesarch",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17069/17069-13-20563-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08828-on-the-adequacy-of-untuned-warmup-for-adaptive-optimization/",
        "doi": "10.1609/aaai.v35i10.17069",
        "pdf_size": 569543
    },
    {
        "id": "05557",
        "title": "On the Approximation of Nash Equilibria in Sparse Win-Lose Multi-player Games",
        "track": "main",
        "status": "Poster",
        "abstract": "A polymatrix game is a multi-player game over n players, where each player chooses a pure strategy from a list of its own pure strategies. The utility of each player is a sum of payoffs it gains from the two player's game from all its neighbors, under its chosen strategy and that of its neighbor. As a natural extension to two-player games (a.k.a. bimatrix games), polymatrix games are widely used for multi-agent games in real world scenarios.    In this paper we show that the problem of approximating a Nash equilibrium in a polymatrix game within the polynomial precision is PPAD-hard, even in sparse and win-lose ones. This result further challenges the predictability of Nash equilibria as a solution concept in the multi-agent setting. We also propose a simple and efficient algorithm, when the game is further restricted. Together, we establish a new dichotomy theorem for this class of games. It is also of independent interest for exploring the computational and structural properties in Nash equilibria.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Zhengyang Liu; Jiawei Li; Xiaotie Deng",
        "authorids": "",
        "aff": "Beijing Institute of Technology; Peking University; Peking University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16699/16699-13-20193-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05557-on-the-approximation-of-nash-equilibria-in-sparse-win-lose-multi-player-games/",
        "doi": "10.1609/aaai.v35i6.16699",
        "pdf_size": 149762
    },
    {
        "id": "05194",
        "title": "On the Complexity of Finding Justifications for Collective Decisions",
        "track": "main",
        "status": "Poster",
        "abstract": "In a collective decision-making process, having the possibility to provide non-expert agents with a justification for why a target outcome is a good compromise given their individual preferences, is an appealing idea. Such questions have recently been addressed in the computational social choice community at large---whether it was to explain the outcomes of a specific rule in voting theory or to seek transparency and accountability in multi-criteria decision making. Ultimately, the development of real-life applications based on these notions depends on their practical feasibility and on the scalability of the approach taken. In this paper, we provide computational complexity results that address the problem of finding and verifying justifications for collective decisions.  In particular, we focus on the recent development of a general notion of justification for outcomes in voting theory. Such a justification consists of a step-by-step explanation, grounded in a normative basis, showing how the selection of the target outcome follows from the normative principles considered. We consider a language in which normative principles can be encoded---either as an explicit list of instances of the principles (by means of quantifier-free sentences), or in a succinct fashion (using quantifiers). We then analyse the computational complexity of identifying and checking justifications. For the case where the normative principles are given in the form of a list of instances, verifying the correctness of a justification is DP-complete and deciding on the existence of such a justification is complete for Sigma 2 P. For the case where the normative principles are given succinctly, deciding whether a justification is correct is in NEXP wedge coNEXP, and NEXP-hard, and deciding whether a justification exists is in EXP with access to an NP oracle  and is NEXP-hard.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Arthur Boixel; Ronald de Haan",
        "authorids": "",
        "aff": "University of Amsterdam; University of Amsterdam",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16656/16656-13-20150-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05194-on-the-complexity-of-finding-justifications-for-collective-decisions/",
        "doi": "10.1609/aaai.v35i6.16656",
        "pdf_size": 156525
    },
    {
        "id": "06304",
        "title": "On the Complexity of Sum-of-Products Problems over Semirings",
        "track": "main",
        "status": "Poster",
        "abstract": "Many important problems in AI, among them SAT, #SAT, and probabilistic inference, amount to Sum-of-Products Problems, i.e. evaluating a sum of products of values from some semiring R. While efficiently solvable cases are known, a systematic study of the complexity of this problem is missing. We characterize the latter by NP(R), a novel generalization of NP over semiring R, and link it to well-known complexity classes. While NP(R) is unlikely to be contained in FPSPACE(poly) in general, for a wide range of commutative (resp. in addition idempotent) semirings, there are reductions to #P (resp. NP) and solutions are thus only mildly harder to compute. We finally discuss NP(R)-complete reasoning problems in well-known semiring formalisms, among them Semiring-based Constraint Satisfaction Problems, obtaining new insights into their computational properties.",
        "primary_area": "Knowledge Representation and Reasoning",
        "author": "Thomas Eiter; Rafael Kiesel",
        "authorids": "",
        "aff": "Vienna University of Technology; Vienna University of Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16783/16783-13-20277-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06304-on-the-complexity-of-sum-of-products-problems-over-semirings/",
        "doi": "10.1609/aaai.v35i7.16783",
        "pdf_size": 163234
    },
    {
        "id": "07510",
        "title": "On the Convergence of Communication-Efficient Local SGD for Federated Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Federated Learning (FL) has attracted increasing attention in recent years. A leading training algorithm in FL is local SGD, which updates the model parameter on each worker and averages model parameters across different workers only once in a while. Although it has fewer communication rounds than the classical parallel SGD, local SGD still has large communication overhead in each communication round for large machine learning models, such as deep neural networks.  To address this issue, we propose a new communication-efficient distributed SGD method,  which can significantly reduce the communication cost by the error-compensated double compression mechanism. Under the non-convex setting, our theoretical results show that our approach has better communication complexity than existing  methods and enjoys the same linear speedup regarding the number of workers as the full-precision local SGD.  Moreover, we  propose a communication-efficient distributed SGD with momentum, which also has better communication complexity than existing methods and enjoys a linear speedup with respect to the number of workers.  At last, extensive experiments are conducted to verify the performance of our proposed two methods. Moreover, we  propose a communication-efficient distributed SGD with momentum to accelerate the convergence, which also has better communication complexity than existing methods and enjoys a linear speedup with respect to the number of workers.  At last, extensive experiments are conducted to verify the performance of our proposed methods.",
        "primary_area": "Machine Learning II",
        "author": "Hongchang Gao; An Xu; Heng Huang",
        "authorids": "",
        "aff": "Temple University; University of Pittsburgh; University of Pittsburgh JD Finance America Corporation",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16920/16920-13-20414-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07510-on-the-convergence-of-communication-efficient-local-sgd-for-federated-learning/",
        "doi": "10.1609/aaai.v35i9.16920",
        "pdf_size": 8772407
    },
    {
        "id": "13461",
        "title": "On the Importance of Word Order Information in Cross-lingual Sequence Labeling",
        "track": "main",
        "status": "Poster",
        "abstract": "Cross-lingual models trained on source language tasks possess the capability to directly transfer to target languages. However, since word order variances generally exist in different languages, cross-lingual models that overfit into the word order of the source language could have sub-optimal performance in target languages. In this paper, we hypothesize that reducing the word order information fitted into the models can improve the adaptation performance in target languages. To verify this hypothesis, we introduce several methods to make models encode less word order information of the source language and test them based on cross-lingual word embeddings and the pre-trained multilingual model. Experimental results on three sequence labeling tasks (i.e., part-of-speech tagging, named entity recognition and slot filling tasks) show that reducing word order information injected into the model can achieve better zero-shot cross-lingual performance. Further analysis illustrates that fitting excessive or insufficient word order information into the model results in inferior cross-lingual performance. Moreover, our proposed methods can also be applied to strong cross-lingual models and further improve their performance.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Zihan Liu; Genta I Winata; Samuel Cahyawijaya; Andrea Madotto; Zhaojiang Lin; Pascale Fung",
        "authorids": "",
        "aff": "The Hong Kong University of Science and Technology; Hong Kong University of Science and Technology; Hong Kong University of Science and Technology; Hong Kong University of Science and Technology; Hong Kong University of Science and Technology; Hong Kong University of Science and Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17588/17588-13-21082-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13461-on-the-importance-of-word-order-information-in-cross-lingual-sequence-labeling/",
        "doi": "10.1609/aaai.v35i15.17588",
        "pdf_size": 5223997
    },
    {
        "id": "12007",
        "title": "On the Optimal Efficiency of A* with Dominance Pruning",
        "track": "main",
        "status": "Poster",
        "abstract": "A well known result is that, given a consistent heuristic and no other source of information, A* does expand a minimal number of nodes up to tie-breaking. We extend this analysis for A* with dominance pruning, which exploits a dominance relation to eliminate some nodes during the search. We show that the expansion order of A* is not necessarily optimally efficient when considering dominance pruning with arbitrary dominance relations, but it remains optimally efficient under certain restrictions for the heuristic and dominance relation.",
        "primary_area": "Planning, Routing, and Scheduling",
        "author": "\u00c1lvaro Torralba",
        "authorids": "",
        "aff": "Aalborg University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17426/17426-13-20920-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12007-on-the-optimal-efficiency-of-a-with-dominance-pruning/",
        "doi": "10.1609/aaai.v35i13.17426",
        "pdf_size": 178728
    },
    {
        "id": "05523",
        "title": "On the PTAS for Maximin Shares in an Indivisible Mixed Manna",
        "track": "main",
        "status": "Poster",
        "abstract": "We study fair allocation of indivisible items, both goods and chores, under the popular fairness notion of maximin share (MMS). The problem is well-studied when there are only goods (or chores), where a PTAS  to compute the MMS values of agents is well-known.   In contrast, for the mixed manna, a recent result showed that finding even an approximate MMS value of an agent up to any approximation factor in (0,1] is NP-hard for general instances. In this paper, we complement the hardness result by obtaining a PTAS to compute the MMS value when its absolute value is at least 1/p times either the total value of all the goods or total cost of all the chores, for some constant p valued at least 1.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Rucha Kulkarni; Ruta Mehta; Setareh Taki",
        "authorids": "",
        "aff": "University of Illinois at Urbana Champaign; UIUC; University of Illinois at Urbana-Champaign",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16695/16695-13-20189-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05523-on-the-ptas-for-maximin-shares-in-an-indivisible-mixed-manna/",
        "doi": "10.1609/aaai.v35i6.16695",
        "pdf_size": 142546
    },
    {
        "id": "13640",
        "title": "On the Softmax Bottleneck of Recurrent Language Models",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent research has pointed to a limitation of word-level neural language models with softmax outputs. This limitation, known as the softmax bottleneck refers to the inability of these models to produce high-rank log probability (log P) matrices. Various solutions have been proposed to break this bottleneck, including Mixture of Softmaxes, SigSoftmax, and Linear Monotonic Softmax with Piecewise Linear Increasing Functions. They were reported to offer better performance in terms of perplexity on test data. A natural perception from these results is a strong positive correlation between the rank of the log P matrix and the model's performance. In this work, we show via an extensive empirical study that such a correlation is fairly weak and that the high-rank of the log P matrix is neither necessary nor sufficient for better test perplexity. Although our results are empirical, they are established in part via the construction of a rich family of models, which we call Generalized SigSoftmax. They are able to create diverse ranks for the log P matrices. We also present an investigation as to why the proposed solutions achieve better performance.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Dwarak Govind  Parthiban; Yongyi Mao; Diana Inkpen",
        "authorids": "",
        "aff": "University of Ottawa; University of Ottawa; University of Ottawa",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17608/17608-13-21102-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13640-on-the-softmax-bottleneck-of-recurrent-language-models/",
        "doi": "10.1609/aaai.v35i15.17608",
        "pdf_size": 2896555
    },
    {
        "id": "06505",
        "title": "On the Tractability of SHAP Explanations",
        "track": "main",
        "status": "Poster",
        "abstract": "SHAP explanations are a popular feature-attribution mechanism for explainable AI. They use game-theoretic notions to measure the influence of individual features on the prediction of a machine learning model. Despite a lot of recent interest from both academia and industry, it is not known whether SHAP explanations of common machine learning models can be computed efficiently. In this paper, we establish the complexity of computing the SHAP explanation in three important settings. First, we consider fully-factorized data distributions, and show that the complexity of computing the SHAP explanation is the same as the complexity of computing the expected value of the model. This fully-factorized setting is often used to simplify the SHAP computation, yet our results show that the computation can be intractable for commonly used models such as logistic regression. Going beyond fully-factorized distributions, we show that computing SHAP explanations is already intractable for a very simple setting: computing SHAP explanations of trivial classifiers over naive Bayes distributions. Finally, we show that even computing SHAP over the empirical distribution is #P-hard.",
        "primary_area": "Knowledge Representation and Reasoning",
        "author": "Guy Van den Broeck; Anton Lykov; Maximilian Schleich; Dan Suciu",
        "authorids": "",
        "aff": "UCLA; UCLA; University of Washington; University of Washington",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16806/16806-13-20300-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06505-on-the-tractability-of-shap-explanations/",
        "doi": "10.1609/aaai.v35i7.16806",
        "pdf_size": 155970
    },
    {
        "id": "11525",
        "title": "On the Verification of Neural ODEs with Stochastic Guarantees",
        "track": "main",
        "status": "Poster",
        "abstract": "We show that Neural ODEs, an emerging class of time-continuous neural networks, can be verified by solving a set of global-optimization problems. For this purpose, we introduce Stochastic Lagrangian Reachability (SLR), an abstraction-based technique for constructing a tight Reachtube (an over-approximation of the set of reachable states over a given time-horizon), and provide stochastic guarantees in the form of confidence intervals for the Reachtube bounds. SLR inherently avoids the infamous wrapping effect (accumulation of over-approximation errors) by performing local optimization steps to expand safe regions instead of repeatedly forward-propagating them as is done by deterministic reachability methods. To enable fast local optimizations, we introduce a novel forward-mode adjoint sensitivity method to compute gradients without the need for backpropagation. Finally, we establish asymptotic and non-asymptotic convergence rates for SLR.",
        "primary_area": "Philosophy and Ethics of AI",
        "author": "Sophie Grunbacher; Ramin Hasani; Mathias Lechner; Jacek Cyranka; Scott A. Smolka; Radu Grosu",
        "authorids": "",
        "aff": "Technische Universit\u00e4t Wien (TU Wien); Massachusetts Institute of Technology (MIT) Technische Universit\u00e4t Wien (TU Wien); Institute of Science and Technology Austria (IST Austria); University of Warsaw; Stony Brook University; Technische Universit\u00e4t Wien (TU Wien)",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17372/17372-13-20866-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11525-on-the-verification-of-neural-odes-with-stochastic-guarantees/",
        "doi": "10.1609/aaai.v35i13.17372",
        "pdf_size": 286906
    },
    {
        "id": "11862",
        "title": "On-line Learning of Planning Domains from Sensor Data in PAL: Scaling up to Large State Spaces",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose an approach to learn an extensional representation of a discrete deterministic planning domain from observations in a continuous space navigated by the agent actions. This is achieved through the use of a perception function providing the likelihood of a real-value observation being in a given state of the planning domain after executing an action. The agent learns an extensional representation of the domain (the set of states, the transitions from states to states caused by actions) and the perception function on-line, while it acts for accomplishing its task. In order to provide a practical approach that can scale up to large state spaces, a \u201cdraft\u201d intensional (PDDL-based) model of the planning domain is used to guide the exploration of the environment and learn the states and state transitions. The proposed approach uses a novel algorithm to (i) construct the extensional representation of the domain by interleaving symbolic planning in the PDDL intensional representation and search in the state transition graph of the extensional representation; (ii) incrementally refine the intensional representation taking into account information about the actions that the agent cannot execute. An experimental analysis shows that the novel approach can scale up to large state spaces, thus overcoming the limits in scalability of the previous work.",
        "primary_area": "Planning, Routing, and Scheduling",
        "author": "Leonardo Lamanna; Alfonso Emilio Gerevini; Alessandro Saetti; Luciano Serafini; Paolo Traverso",
        "authorids": "",
        "aff": "Fondazione Bruno Kessler (FBK) University of Brescia; University of Brescia; University of Brescia; Fondazione Bruno Kessler (FBK); Fondazione Bruno Kessler (FBK)",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17409/17409-13-20903-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11862-on-line-learning-of-planning-domains-from-sensor-data-in-pal-scaling-up-to-large-state-spaces/",
        "doi": "10.1609/aaai.v35i13.17409",
        "pdf_size": 416143
    },
    {
        "id": "06530",
        "title": "On-the-fly Synthesis for LTL over Finite Traces",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a new synthesis framework based on the on-the-fly DFA construction for LTL over finite traces (LTLf ). Extant approaches rely heavily on the construction of the complete DFA w.r.t. the input LTLf formula, whose size can be doubly exponential to the size of the formula in the worst case. Under those approaches, the synthesis cannot be conducted unless the whole DFA is completely constructed, which is not only inefficient but also not scalable in practice. Indeed, the DFA construction is the main bottleneck of LTLf synthesis in prior work. To mitigate this challenge, we follow two steps in this paper: Firstly, we present several light-weight pre-processing techniques such that the synthesis result can be obtained even without DFA construction; Secondly, we propose to achieve the synthesis together with the on-the-fly DFA construction such that the synthesis result can be obtained before constructing the whole DFA. The on-the-fly DFA construction is implemented using the SAT-based techniques for automata generation. We compared our new approach with the traditional ones on extensive LTLf synthesis benchmarks. Experimental results showed that the pre-processing techniques have a significant advantage on the synthesis performance in terms of scalability, and the on-the-fly synthesis is able to complement extant approaches on both realizable and unrealizable cases.",
        "primary_area": "Knowledge Representation and Reasoning",
        "author": "Shengping Xiao; Jianwen Li; Shufang Zhu; Yingying Shi; Geguang Pu; Moshe Vardi",
        "authorids": "",
        "aff": "East China Normal University; East China Normal University; Sapienza Universit`a di Roma Shanghai Trusted Industrial Control Platform Co., Ltd.; East China Normal University; East China Normal University; Rice University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16809/16809-13-20303-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06530-on-the-fly-synthesis-for-ltl-over-finite-traces/",
        "doi": "10.1609/aaai.v35i7.16809",
        "pdf_size": 293050
    },
    {
        "id": "12564",
        "title": "One SPRING to Rule Them Both: Symmetric AMR Semantic Parsing and Generation without a Complex Pipeline",
        "track": "main",
        "status": "Poster",
        "abstract": "In Text-to-AMR parsing, current state-of-the-art semantic parsers use cumbersome pipelines integrating several different modules or components, and exploit graph recategorization, i.e., a set of content-specific heuristics that are developed on the basis of the training set. However, the generalizability of graph recategorization in an out-of-distribution setting is unclear. In contrast, state-of-the-art AMR-to-Text generation, which can be seen as the inverse to parsing, is based on simpler seq2seq. In this paper, we cast Text-to-AMR and AMR-to-Text as a symmetric transduction task and show that by devising a careful graph linearization and extending a pretrained encoder-decoder model, it is possible to obtain state-of-the-art performances in both tasks using the very same seq2seq approach, i.e., SPRING (Symmetric PaRsIng aNd Generation). Our model does not require complex pipelines, nor heuristics built on heavy assumptions. In fact, we drop the need for graph recategorization, showing that this technique is actually harmful outside of the standard benchmark. Finally, we outperform the previous state of the art on the English AMR 2.0 dataset by a large margin: on Text-to-AMR we obtain an improvement of 3.6 Smatch points, while on AMR-to-Text we outperform the state of the art by 11.2 BLEU points.  We release the software at github.com/SapienzaNLP/spring.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Michele Bevilacqua; Rexhina Blloshmi; Roberto Navigli",
        "authorids": "",
        "aff": "Sapienza University of Rome; Sapienza University of Rome; Sapienza University of Rome",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17489/17489-13-20983-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12564-one-spring-to-rule-them-both-symmetric-amr-semantic-parsing-and-generation-without-a-complex-pipeline/",
        "doi": "10.1609/aaai.v35i14.17489",
        "pdf_size": 293021
    },
    {
        "id": "03324",
        "title": "One for More: Selecting Generalizable Samples for Generalizable ReID Model",
        "track": "main",
        "status": "Poster",
        "abstract": "Current training objectives of existing person Re-IDentification (ReID) models only ensure that the loss of the model decreases on selected training batch, with no regards to the performance on samples outside the batch. It will inevitably cause the model to over-fit the data in the dominant position (e.g., head data in imbalanced class, easy samples or noisy samples). The latest resampling methods address the issue by designing specific criterion to select specific samples that trains the model generalize more on certain type of data (e.g., hard samples, tail data),  which is not adaptive to the inconsistent real world ReID data distributions.  Therefore, instead of simply presuming on what samples are generalizable, this paper proposes a one-for-more training objective that directly takes the generalization ability of selected samples as a loss function and learn a sampler to automatically select generalizable samples. More importantly, our proposed one-for-more based sampler can be seamlessly integrated into the ReID training framework which is able to simultaneously train ReID models and the sampler in an end-to-end fashion. The experimental results show that our method can effectively improve the ReID model training and boost the performance of ReID models.",
        "primary_area": "Computer Vision III",
        "author": "Enwei Zhang; Xinyang Jiang; Hao Cheng; Ancong Wu; Fufu Yu; Ke Li; Xiaowei Guo; Feng Zheng; Weishi Zheng; Xing Sun",
        "authorids": "",
        "aff": "Tencent Youtu Lab; Tencent Youtu Lab; Tencent Youtu Lab; Sun Yat-sen University; Tencent Youtu Lab; Tencent Youtu Lab; Tencent Youtu Lab; SUSTech; Sun Yat-sen University, China; Tencent Youtu Lab",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16444/16444-13-19938-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03324-one-for-more-selecting-generalizable-samples-for-generalizable-reid-model/",
        "doi": "10.1609/aaai.v35i4.16444",
        "pdf_size": 1859372
    },
    {
        "id": "03172",
        "title": "One-shot Face Reenactment Using Appearance Adaptive Normalization",
        "track": "main",
        "status": "Poster",
        "abstract": "The paper proposes a novel generative adversarial network for one-shot face reenactment, which can animate a single face image to a different pose-and-expression (provided by a driving image) while keeping its original appearance. The core of our network is a novel mechanism called appearance adaptive normalization, which can effectively integrate the appearance information from the input image into our face generator by modulating the feature maps of the generator using the learned adaptive parameters. Furthermore, we specially design a local net to reenact the local facial components (i.e., eyes, nose and mouth) first, which is a much easier task for the network to learn and can in turn provide explicit anchors to guide our face generator to learn the global appearance and pose-and-expression. Extensive quantitative and qualitative experiments demonstrate the significant efficacy of our model compared with prior one-shot methods.",
        "primary_area": "Computer Vision III",
        "author": "Guangming Yao; Yi Yuan; Tianjia Shao; Shuang Li; Shanqi Liu; Yong Liu; Mengmeng Wang; Kun Zhou",
        "authorids": "",
        "aff": "NetEase Fuxi AI Lab; NetEase Fuxi AI Lab; State Key Lab of CAD&CG, Zhejiang University; School of Computer Science and Technology, Beijing Institute of Technology; Institute of Cyber-Systems and Control, Zhejiang University; Institute of Cyber-Systems and Control, Zhejiang University; Institute of Cyber-Systems and Control, Zhejiang University; State Key Lab of CAD&CG, Zhejiang University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16427/16427-13-19921-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03172-one-shot-face-reenactment-using-appearance-adaptive-normalization/",
        "doi": "10.1609/aaai.v35i4.16427",
        "pdf_size": 16195469
    },
    {
        "id": "08510",
        "title": "One-shot Graph Neural Architecture Search with Dynamic Search Space",
        "track": "main",
        "status": "Poster",
        "abstract": "Relying on the diverse graph convolution operations that have emerged in recent years, graph neural networks (GNNs) are shown to be powerful to deal with high-dimensional non-Euclidean domains, such as social networks or citation networks. Despite the tremendous human efforts been taken to explore new graph convolution operations, there are a few attempts to automatically search operations in GNNs. The search space of GNNs is significantly larger than that of CNNs, because of diverse components in the message-passing of GNNs. This, therefore, prevents the straightforward application of classical NAS methods for GNNs. In this work, we propose a novel dynamic one-shot search space for multi-branch neural architectures of GNNs. The dynamic search space maintains a subset of the large search space along with a set of importance weights for operation candidates in the subset as the architecture parameters. After each iteration, the subset is pruned by removing candidates with low importance weights and is expanded with new operations. The dynamic subsets of operation candidates are not uniform but is individual for each edge in the computation graph of the neural architecture, which can ensure the diversity of operations in the final architecture is as competitive as direct search in the large search space. Our experiments of semi-supervised and supervised node classification on citation networks, including Cora, Citeseer, and Pubmed, demonstrate that our method outperforms the current state-of-the-art manually designed architectures and reaches competitive performance to existing GNN NAS approaches with up to 10 times of speedup.",
        "primary_area": "Machine Learning III",
        "author": "Yanxi Li; Zean Wen; Yunhe Wang; Chang Xu",
        "authorids": "",
        "aff": "University of Sydney; University of Sydney; Huawei Noah's Ark Lab; University of Sydney",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17033/17033-13-20527-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08510-one-shot-graph-neural-architecture-search-with-dynamic-search-space/",
        "doi": "10.1609/aaai.v35i10.17033",
        "pdf_size": 239105
    },
    {
        "id": "00741",
        "title": "Online 3D Bin Packing with Constrained Deep Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "We solve a challenging yet practically useful variant of 3D Bin Packing Problem (3D-BPP). In our problem, the agent has limited information about the items to be packed into a single bin, and an item must be packed immediately after its arrival without buffering or readjusting. The item's placement also subjects to the constraints of order dependence and physical stability. We formulate this online 3D-BPP as a constrained Markov decision process (CMDP). To solve the problem, we propose an effective and easy-to-implement constrained deep reinforcement learning (DRL) method under the actor-critic framework. In particular, we introduce a prediction-and-projection scheme: The agent first predicts a feasibility mask for the placement actions as an auxiliary task and then uses the mask to modulate the action probabilities output by the actor during training. Such supervision and projection facilitate the agent to learn feasible policies very efficiently. Our method can be easily extended to handle lookahead items, multi-bin packing, and item re-orienting. We have conducted extensive evaluation showing that the learned policy significantly outperforms the state-of-the-art methods. A preliminary user study even suggests that our method might attain a human-level performance.",
        "primary_area": "Application Domains",
        "author": "Hang Zhao; Qijin She; Chenyang Zhu; Yin Yang; Kai Xu",
        "authorids": "",
        "aff": "National University of Defense Technology; National University of Defense Technology; National University of Defense Technology; Clemson University; National University of Defense Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16155/16155-13-19649-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00741-online-3d-bin-packing-with-constrained-deep-reinforcement-learning/",
        "doi": "10.1609/aaai.v35i1.16155",
        "pdf_size": 2988281
    },
    {
        "id": "11981",
        "title": "Online Action Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "Recognition in planning seeks to find agent intentions, goals or activities given a set of observations and a knowledge library (e.g. goal states, plans or domain theories). In this work we introduce the problem of Online Action Recognition. It consists in recognizing, in an open world, the planning action that best explains a partially observable state transition from a knowledge library of first-order STRIPS actions, which is initially empty. We frame this as an optimization problem, and propose two algorithms to address it: Action Unification (AU) and Online Action Recognition through Unification (OARU). The former builds on logic unification and generalizes two input actions using weighted partial MaxSAT. The latter looks for an action within the library that explains an observed transition. If there is such action, it generalizes it making use of AU, building in this way an AU hierarchy. Otherwise, OARU inserts a Trivial Grounded Action (TGA) in the library that explains just that transition. We report results on benchmarks from the International Planning Competition and PDDLGym, where OARU recognizes actions accurately with respect to expert knowledge, and shows real-time performance.",
        "primary_area": "Planning, Routing, and Scheduling",
        "author": "Alejandro Su\u00e1rez-Hern\u00e1ndez; Javier Segovia-Aguas; Carme Torras; Guillem Aleny\u00e0",
        "authorids": "",
        "aff": "Institut de Rob\u00f2tica i Inform\u00e0tica Industrial, CSIC-UPC, Barcelona; Institut de Rob\u00f2tica i Inform\u00e0tica Industrial, CSIC-UPC, Barcelona Universitat Pompeu Fabra, Barcelona; Institut de Rob\u00f2tica i Inform\u00e0tica Industrial, CSIC-UPC, Barcelona; Institut de Rob\u00f2tica i Inform\u00e0tica Industrial, CSIC-UPC, Barcelona",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17423/17423-13-20917-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11981-online-action-recognition/",
        "doi": "10.1609/aaai.v35i13.17423",
        "pdf_size": 1057024
    },
    {
        "id": "09630",
        "title": "Online Class-Incremental Continual Learning with Adversarial Shapley Value",
        "track": "main",
        "status": "Poster",
        "abstract": "As image-based deep learning becomes pervasive on every device, from cell phones to smart watches, there is a growing need to develop methods that continually learn from data while minimizing memory footprint and power consumption. While memory replay techniques have shown exceptional promise for this task of continual learning, the best method for selecting which buffered images to replay is still an open question. In this paper, we specifically focus on the online class-incremental setting where a model needs to learn new classes continually from an online data stream. To this end, we contribute a novel Adversarial Shapley value scoring method that scores memory data samples according to their ability to preserve latent decision boundaries for previously observed classes (to maintain learning stability and avoid forgetting) while interfering with latent decision boundaries of current classes being learned (to encourage plasticity and optimal learning of new class boundaries). Overall, we observe that our proposed ASER method provides competitive or improved performance compared to state-of-the-art replay-based continual learning methods on a variety of datasets.",
        "primary_area": "Machine Learning IV",
        "author": "Dongsub Shim; Zheda Mai; Jihwan Jeong; Scott Sanner; Hyunwoo Kim; Jongseong Jang",
        "authorids": "",
        "aff": "University of Toronto; University of Toronto; University of Toronto; University of Toronto; LG AI Research; LG AI Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17159/17159-13-20653-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09630-online-class-incremental-continual-learning-with-adversarial-shapley-value/",
        "doi": "10.1609/aaai.v35i11.17159",
        "pdf_size": 1372176
    },
    {
        "id": "09395",
        "title": "Online DR-Submodular Maximization: Minimizing Regret and Constraint Violation",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we consider online continuous DR-submodular maximization with linear stochastic long-term constraints. Compared to the prior work on online submodular maximization, our setting introduces the extra complication of stochastic linear constraint functions that are i.i.d. generated at each round. In particular, at each time step a DR-submodular utility function and a constraint vector, i.i.d. generated from an unknown distribution, are revealed after committing to an action and we aim to maximize the overall utility while the expected cumulative resource consumption is below a fixed budget. Stochastic long-term constraints arise naturally in applications where there is a limited budget or resource available and resource consumption at each step is governed by stochastically time-varying environments. We propose the Online Lagrangian Frank-Wolfe (OLFW) algorithm to solve this class of online problems. We analyze the performance of the OLFW algorithm and we obtain sub-linear regret bounds as well as sub-linear cumulative constraint violation bounds, both in expectation and with high probability.",
        "primary_area": "Machine Learning IV",
        "author": "Prasanna Raut; Omid Sadeghi; Maryam Fazel",
        "authorids": "",
        "aff": "University of Washington; University of Washington; University of Washington",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17132/17132-13-20626-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09395-online-dr-submodular-maximization-minimizing-regret-and-constraint-violation/",
        "doi": "10.1609/aaai.v35i11.17132",
        "pdf_size": 2272138
    },
    {
        "id": "04106",
        "title": "Online Learning in Variable Feature Spaces under Incomplete Supervision",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper explores a new online learning problem where the input sequence lives in an over-time varying feature space and the ground-truth label of any input point is given only occasionally, making online learners less restrictive and more applicable. The crux in this setting lies in how to exploit the very limited labels to efficiently update the online learners. Plausible ideas such as propagating labels from labeled points to their neighbors through uncovering the point-wise geometric relations face two challenges: (1) distance measurement fails to work as different points may be described by disparate sets of features and (2) storing the geometric shape, which is formed by all arrived points, is unrealistic in an online setting. To address these challenges, we first construct a universal feature space that accumulates all observed features, making distance measurement feasible. Then, we use manifolds to represent the geometric shapes and approximate them in a sparse means, making manifolds computational and memory tractable in online learning. We frame these two building blocks into a regularized risk minimization algorithm. Theoretical analysis and empirical evidence substantiate the viability and effectiveness of our proposal.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Yi He; Xu Yuan; Sheng Chen; Xindong Wu",
        "authorids": "",
        "aff": "University of Louisiana at Lafayette; University of Louisiana at Lafayette; University of Louisiana at Lafayette; HeFei University of Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16532/16532-13-20026-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04106-online-learning-in-variable-feature-spaces-under-incomplete-supervision/",
        "doi": "10.1609/aaai.v35i5.16532",
        "pdf_size": 4679593
    },
    {
        "id": "09868",
        "title": "Online Non-Monotone DR-Submodular Maximization",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we study fundamental problems of maximizing DR-submodular continuous functions that have real-world applications in the domain of machine learning, economics, operations research and communication systems. It captures a subclass of non-convex optimization that provides both theoretical and practical guarantees. Here, we focus on minimizing regret for online arriving non-monotone DR-submodular functions over down-closed and general convex sets. First, we present an online algorithm that achieves a 1/e-approximation ratio with the regret of O(T^{3/4}) for maximizing DR-submodular functions over any down-closed convex set. Note that, the approximation ratio of 1/e matches the best-known guarantee for the offline version of the problem. Next, we give an online algorithm that achieves an approximation guarantee (depending on the search space) for the problem of maximizing non-monotone continuous DR-submodular functions over a general convex set (not necessarily down-closed). To best of our knowledge, no prior algorithm with approximation guarantee was known for non-monotone DR-submodular maximization in the online setting. Finally we run experiments to verify the performance of our algorithms on problems arising in machine learning domain with the real-world datasets.",
        "primary_area": "Machine Learning IV",
        "author": "Nguy\u1ec5n Kim Th\u1eafng; Abhinav Srivastav",
        "authorids": "",
        "aff": "IBISC, Univ. Evry, University Paris-Saclay, France; IBISC, Univ. Evry, University Paris-Saclay, France",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17186/17186-13-20680-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09868-online-non-monotone-dr-submodular-maximization/",
        "doi": "10.1609/aaai.v35i11.17186",
        "pdf_size": 233826
    },
    {
        "id": "08527",
        "title": "Online Optimal Control with Affine Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper considers online optimal control with affine constraints on the states and actions under linear dynamics with bounded random disturbances. The system dynamics and constraints are assumed to be known and time invariant but the convex stage cost functions change adversarially. To solve this problem,  we propose Online Gradient Descent with Buffer Zones (OGD-BZ). Theoretically, we show that OGD-BZ with proper parameters can guarantee the system to satisfy all the constraints despite any admissible disturbances. Further, we investigate the policy regret of OGD-BZ, which compares OGD-BZ's performance with the performance of the optimal linear policy in hindsight. We show that OGD-BZ can achieve a policy regret upper bound that is square root of the horizon length multiplied by some logarithmic terms of the horizon length under proper algorithm parameters.",
        "primary_area": "Machine Learning III",
        "author": "Yingying Li; Subhro Das; Na Li",
        "authorids": "",
        "aff": "John A. Paulson School of Engineering and Applied Sciences, Harvard University; MIT-IBM Watson AI Lab, IBM Research; John A. Paulson School of Engineering and Applied Sciences, Harvard University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17035/17035-13-20529-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08527-online-optimal-control-with-affine-constraints/",
        "doi": "10.1609/aaai.v35i10.17035",
        "pdf_size": 827416
    },
    {
        "id": "05682",
        "title": "Online Posted Pricing with Unknown Time-Discounted Valuations",
        "track": "main",
        "status": "Poster",
        "abstract": "We study the problem of designing posted-price mechanisms in order to sell a single unit of a single item within a finite period of time. Motivated by real-world problems, such as, e.g., long-term rental of rooms and apartments, we assume that customers arrive online according to a Poisson process, and their valuations  are drawn from an unknown distribution and discounted over time. We evaluate our mechanisms in terms of competitive ratio, measuring the worst-case ratio between their revenue and that of an optimal mechanism that knows the distribution of valuations. First, we focus on the identical valuation setting, where all the customers value the item for the same amount. In this setting, we provide a mechanism M_c that achieves the best possible competitive ratio, discussing its dependency on the parameters in the case of linear discount. Then, we switch to the random valuation setting. We show that, if we restrict the attention to distributions of valuations with a monotone hazard rate, then the competitive ratio of M_c is lower bounded by a strictly positive constant that does not depend on the distribution. Moreover, we provide another mechanism, called M_pc, which is defined by a piecewise constant pricing strategy and reaches performances comparable to those obtained with M_c. This mechanism is useful when the seller cannot change the posted price too often. Finally, we empirically evaluate the performances of our mechanisms in a number of experimental settings.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Giulia Romano; Gianluca Tartaglia; Alberto Marchesi; Nicola Gatti",
        "authorids": "",
        "aff": "Politecnico di Milano; Politecnico di Milano; Politecnico di Milano; Politecnico di Milano",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16713/16713-13-20207-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05682-online-posted-pricing-with-unknown-time-discounted-valuations/",
        "doi": "10.1609/aaai.v35i6.16713",
        "pdf_size": 296361
    },
    {
        "id": "03642",
        "title": "Online Search with Maximum Clearance",
        "track": "main",
        "status": "Poster",
        "abstract": "We study the setting in which a mobile searcher must locate a hidden target in a bounded or unbounded search domain, with no information about the hider's position. In particular, we consider online search, in which the performance of the search strategy is evaluated by its worst case competitive ratio. We introduce a multi-criteria search problem in which the searcher has a budget on its allotted search time, and the objective is to design strategies that are competitively efficient, respect the budget, and maximize the total searched ground. We give analytically optimal strategies for the line and the star domains, and efficient heuristics for general networks.",
        "primary_area": "Constraint Satisfaction and Optimization",
        "author": "Spyros Angelopoulos; Malachi Voss",
        "authorids": "",
        "aff": "Centre National de la Recherche Scientifique (CNRS) Sorbonne Universit\u00e9, Laboratoire d'informatique de Paris 6, LIP6, F-75252 Paris, France; \u00c9cole Normale Sup\u00e9rieure Sorbonne Universit\u00e9, Laboratoire d'informatique de Paris 6, LIP6, F-75252 Paris, France",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16480/16480-13-19974-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03642-online-search-with-maximum-clearance/",
        "doi": "10.1609/aaai.v35i5.16480",
        "pdf_size": 633647
    },
    {
        "id": "12320",
        "title": "OpEvo: An Evolutionary Method for Tensor Operator Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "Training and inference efficiency of deep neural networks highly rely on the performance of tensor operators on hardware platforms. Manually optimizing tensor operators has limitations in terms of supporting new operators or hardware platforms. Therefore, automatically optimizing device code configurations of tensor operators is getting increasingly attractive. However, current methods for tensor operator optimization usually suffer from poor sample-efficiency due to the combinatorial search space. In this work, we propose a novel evolutionary method, OpEvo, which efficiently explores the search spaces of tensor operators by introducing a topology-aware mutation operation based on q-random walk to leverage the topological structures over the search spaces. Our comprehensive experiment results show that compared with state-of-the-art(SOTA) methods OpEvo can find the best configuration with the lowest variance and least efforts in the number of trials and wall-clock time. All code of this work is available online.",
        "primary_area": "Search and Optimization",
        "author": "Xiaotian Gao; Wei Cui; Lintao Zhang; Mao Yang",
        "authorids": "",
        "aff": "Microsoft Research Asia; Microsoft Research Asia; Microsoft Research Asia; Microsoft Research Asia",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17462/17462-13-20956-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12320-opevo-an-evolutionary-method-for-tensor-operator-optimization/",
        "doi": "10.1609/aaai.v35i14.17462",
        "pdf_size": 6565545
    },
    {
        "id": "14239",
        "title": "Open Domain Dialogue Generation with Latent Images",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider grounding open domain dialogues with images. Existing work assumes that both an image and a textual context are available, but image-grounded dialogues by nature are more difficult to obtain than textual dialogues. Thus, we propose learning a response generation model with both image-grounded dialogues and textual dialogues by assuming that the visual scene information at the time of a conversation can be represented by an image, and trying to recover the latent images of the textual dialogues through text-to-image generation techniques. The likelihood of the two types of dialogues is then formulated by a response generator and an image reconstructor that are learned within a conditional variational auto-encoding framework. Empirical studies are conducted in both image-grounded conversation and text-based conversation. In the first scenario, image-grounded dialogues, especially under a low-resource setting, can be effectively augmented by textual dialogues with latent images; while in the second scenario, latent images can enrich the content of responses and at the same time keep them relevant to contexts.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Ze Yang; Wei Wu; Huang Hu; Can Xu; Wei Wang; Zhoujun Li",
        "authorids": "",
        "aff": "Beihang University; Meituan; Microsoft; Microsoft; China Resources Group; Beihang University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17675/17675-13-21169-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14239-open-domain-dialogue-generation-with-latent-images/",
        "doi": "10.1609/aaai.v35i16.17675",
        "pdf_size": 856125
    },
    {
        "id": "06877",
        "title": "Open-Set Recognition with Gaussian Mixture Variational Autoencoders",
        "track": "main",
        "status": "Poster",
        "abstract": "In inference, open-set classification is to either classify a sample into a known class from training or reject it as an unknown class. Existing deep open-set classifiers train explicit closed-set classifiers, in some cases disjointly utilizing reconstruction, which we find dilutes the latent representation's ability to distinguish unknown classes. In contrast, we train our model to cooperatively learn reconstruction and perform class-based clustering in the latent space. With this, our Gaussian mixture variational autoencoder (GMVAE) achieves more accurate and robust open-set classification results, with an average F1 increase of 0.26, through extensive experiments aided by analytical results.",
        "primary_area": "Machine Learning I",
        "author": "Alexander Cao; Yuan Luo; Diego Klabjan",
        "authorids": "",
        "aff": "Northwestern University; Northwestern University; Northwestern University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16848/16848-13-20342-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06877-open-set-recognition-with-gaussian-mixture-variational-autoencoders/",
        "doi": "10.1609/aaai.v35i8.16848",
        "pdf_size": 11808765
    },
    {
        "id": "00891",
        "title": "Optical Flow Estimation from a Single Motion-blurred Image",
        "track": "main",
        "status": "Poster",
        "abstract": "In most of computer vision applications, motion blur is regarded as an undesirable artifact. However, it has been shown that motion blur in an image may have practical interests in fundamental computer vision problems. In this work, we propose a novel framework to estimate optical flow from a single motion-blurred image in an end-to-end manner. We design our network with transformer networks to learn globally and locally varying motions from encoded features of a motion-blurred input, and decode left and right frame features without explicit frame supervision. A flow estimator network is then used to estimate optical flow from the decoded features in a coarse-to-fine manner. We qualitatively and quantitatively evaluate our model through a large set of experiments on synthetic and real motion-blur datasets. We also provide in-depth analysis of our model in connection with related approaches to highlight the effectiveness and favorability of our approach. Furthermore, we showcase the applicability of the flow estimated by our method on deblurring and moving object segmentation tasks.",
        "primary_area": "Computer Vision I",
        "author": "Dawit Mureja Argaw; Junsik Kim; Francois Rameau; Jae Won Cho; In So Kweon",
        "authorids": "",
        "aff": "KAIST Robotics and Computer Vision Lab., Daejeon, Korea; KAIST Robotics and Computer Vision Lab., Daejeon, Korea; KAIST Robotics and Computer Vision Lab., Daejeon, Korea; KAIST Robotics and Computer Vision Lab., Daejeon, Korea; KAIST Robotics and Computer Vision Lab., Daejeon, Korea",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16172/16172-13-19666-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00891-optical-flow-estimation-from-a-single-motion-blurred-image/",
        "doi": "10.1609/aaai.v35i2.16172",
        "pdf_size": 5609768
    },
    {
        "id": "03733",
        "title": "Optimal Decision Trees for Nonlinear Metrics",
        "track": "main",
        "status": "Poster",
        "abstract": "Nonlinear metrics, such as the F1-score, Matthews correlation coefficient, and Fowlkes\u2013Mallows index, are often used to evaluate the performance of machine learning models, in particular, when facing imbalanced datasets that contain more samples of one class than the other. Recent optimal decision tree algorithms have shown remarkable progress in producing trees that are optimal with respect to linear criteria, such as accuracy, but unfortunately nonlinear metrics remain a challenge. To address this gap, we propose a novel algorithm based on bi-objective optimisation, which treats misclassifications of each binary class as a separate objective. We show that, for a large class of metrics, the optimal tree lies on the Pareto frontier. Consequently, we obtain the optimal tree by using our method to generate the set of all nondominated trees. To the best of our knowledge, this is the first method to compute provably optimal decision trees for nonlinear metrics. Our approach leads to a trade-off when compared to optimising linear metrics: the resulting trees may be more desirable according to the given nonlinear metric at the expense of higher runtimes. Nevertheless, the experiments illustrate that runtimes are reasonable for majority of the tested datasets.",
        "primary_area": "Constraint Satisfaction and Optimization",
        "author": "Emir Demirovi\u0107; Peter J. Stuckey",
        "authorids": "",
        "aff": "Delft University of Technology; Monash University Data61",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16490/16490-13-19984-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03733-optimal-decision-trees-for-nonlinear-metrics/",
        "doi": "10.1609/aaai.v35i5.16490",
        "pdf_size": 155057
    },
    {
        "id": "00021",
        "title": "Optimal Kidney Exchange with Immunosuppressants",
        "track": "main",
        "status": "Poster",
        "abstract": "Algorithms for exchange of kidneys is one of the key successful applications in market design, artificial intelligence, and operations research. Potent immunosuppressant drugs suppress the body's ability to reject a transplanted organ up to the point that a transplant across blood- or tissue-type incompatibility becomes possible. In contrast to the standard  kidney exchange problem, we consider a setting that also involves the decision about which recipients receive from the limited supply of immunosuppressants that make them compatible with originally incompatible kidneys. We firstly present a general computational framework to model this problem. Our main contribution is a range of efficient algorithms that provide flexibility in terms of meeting meaningful objectives. Motivated by the current reality of kidney exchanges using sophisticated mathematical-programming-based clearing algorithms, we then present a general but scalable approach to optimal clearing with immunosuppression; we validate our approach on realistic data from a large fielded exchange.",
        "primary_area": "Application Domains",
        "author": "Haris Aziz; \u00c1gnes Cseh; John P. Dickerson; Duncan C. McElfresh",
        "authorids": "",
        "aff": "UNSW Sydney Data61 CSIRO; Hasso Plattner Institute, University of Potsdam Institute of Economics, Centre for Economic and Regional Studies; University of Maryland; University of Maryland",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16073/16073-13-19567-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00021-optimal-kidney-exchange-with-immunosuppressants/",
        "doi": "10.1609/aaai.v35i1.16073",
        "pdf_size": 197425
    },
    {
        "id": "03759",
        "title": "Optimising Automatic Calibration of Electric Muscle Stimulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Electrical Muscle Stimulation (EMS) has become a popular interaction technology in Human-Computer Interaction; allowing the computer to take direct control of the user's body. To date, however, the explorations have been limited to coarse, toy examples, due to the low resolution of achievable control. To increase this resolution, the EMS needs to increase significantly in complexity - using large numbers of electrodes in complex patterns. The calibration of such a system remains an unsolved challenge. We present a new SAT-based black-box calibration method, which requires no spatial information about muscular or electrode positioning. The method encodes domain knowledge and observations in a constraint model, and uses these to prune the space of feasible control signals. In a simulated environment we find this method can scale reliably to large arrays while requiring only a modest number of trials, and preliminary tests on real hardware show we can effectively calibrate an electrode array in a few minutes.",
        "primary_area": "Constraint Satisfaction and Optimization",
        "author": "Graeme Gange; Jarrod Knibbe",
        "authorids": "",
        "aff": "Monash University; University of Melbourne",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16493/16493-13-19987-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03759-optimising-automatic-calibration-of-electric-muscle-stimulation/",
        "doi": "10.1609/aaai.v35i5.16493",
        "pdf_size": 1280867
    },
    {
        "id": "03590",
        "title": "Optimizing Information Theory Based Bitwise Bottlenecks for Efficient Mixed-Precision Activation Quantization",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent researches on information theory shed new light on the continuous attempts to open the black box of neural signal encoding. Inspired by the problem of lossy signal compression for wireless communication, this paper presents a Bitwise Bottleneck approach for quantizing and encoding neural network activations. Based on the rate-distortion theory, the Bitwise Bottleneck attempts to determine the most significant bits in activation representation by assigning and approximating the sparse coefficients associated with different bits. Given the constraint of a limited average code rate, the bottleneck minimizes the distortion for optimal activation quantization in a flexible layer-by-layer manner. Experiments over ImageNet and other datasets show that, by minimizing the quantization distortion of each layer, the neural network with bottlenecks achieves the state-of-the-art accuracy with low-precision activation. Meanwhile, by reducing the code rate, the proposed method can improve the memory and computational efficiency by over six times compared with the deep neural network with standard single-precision representation. The source code is available on GitHub: https://github.com/CQUlearningsystemgroup/BitwiseBottleneck.",
        "primary_area": "Computer Vision III",
        "author": "Xichuan Zhou; Kui Liu; Cong Shi; Haijun Liu; Ji Liu",
        "authorids": "",
        "aff": "School of Microelectronics and Communication Engineering, Chongqing University Key Laboratory of Dependable Service Computing in Cyber-Physical-Society, Ministry of Education; School of Microelectronics and Communication Engineering, Chongqing University; School of Microelectronics and Communication Engineering, Chongqing University; School of Microelectronics and Communication Engineering, Chongqing University; AI platform, Kwai Inc.",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16474/16474-13-19968-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03590-optimizing-information-theory-based-bitwise-bottlenecks-for-efficient-mixed-precision-activation-quantization/",
        "doi": "10.1609/aaai.v35i4.16474",
        "pdf_size": 7996177
    },
    {
        "id": "00566",
        "title": "Oral-3D: Reconstructing the 3D Structure of Oral Cavity from Panoramic X-ray",
        "track": "main",
        "status": "Poster",
        "abstract": "Panoramic X-ray (PX) provides a 2D picture of the patient's mouth in a panoramic view to help dentists observe the invisible disease inside the gum. However, it provides limited 2D information compared with cone-beam computed tomography (CBCT), another dental imaging method that generates a 3D picture of the oral cavity but with more radiation dose and a higher price. Consequently, it is of great interest to reconstruct the 3D structure from a 2D X-ray image, which can greatly explore the application of X-ray imaging in dental surgeries. In this paper, we propose a framework, named Oral-3D, to reconstruct the 3D oral cavity from a single PX image and prior information of the dental arch. Specifically, we first train a generative model to learn the cross-dimension transformation from 2D to 3D. Then we restore the shape of the oral cavity with a deformation module with the dental arch curve, which can be obtained simply by taking a photo of the patient's mouth. To be noted, Oral-3D can restore both the density of bony tissues and the curved mandible surface. Experimental results show that Oral-3D can efficiently and effectively reconstruct the 3D oral structure and show critical information in clinical applications, e.g., tooth pulling and dental implants. To the best of our knowledge, we are the first to explore this domain transformation problem between these two imaging methods.",
        "primary_area": "Application Domains",
        "author": "Weinan Song; Yuan Liang; Jiawei Yang; Kun Wang; Lei He",
        "authorids": "",
        "aff": "University of California, Los Angeles; University of California, Los Angeles; University of California, Los Angeles; University of California, Los Angeles; University of California, Los Angeles",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16135/16135-13-19629-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00566-oral-3d-reconstructing-the-3d-structure-of-oral-cavity-from-panoramic-x-ray/",
        "doi": "10.1609/aaai.v35i1.16135",
        "pdf_size": 6954384
    },
    {
        "id": "01496",
        "title": "Order Regularization on Ordinal Loss for Head Pose, Age and Gaze Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Ordinal loss is widely used in solving regression problems with deep learning technologies. Its basic idea is to convert regression to classification while preserving the natural order. However, the order constraint is enforced only by ordinal label implicitly, leading to the real output values not strictly in order. It causes the network to learn separable feature rather than discriminative feature, and possibly overfit on training set. In this paper, we propose order regularization on ordinal loss, which makes the outputs in order by explicitly constraining the ordinal classifiers in order. The proposed method contains two parts, i.e. similar-weights constraint, which reduces the ineffective space between classifiers, and differential-bias constraint, which enforces the decision planes in order and enhances the discrimination power of the classifiers. Experimental results show that our proposed method boosts the performance of original ordinal loss on various regression problems such as head pose, age, and gaze estimation, with significant error reduction of around 5%. Furthermore, our method outperforms the state of the art on all these tasks, with the performance gain of 14.4%, 2.2% and 6.5% on head pose, age and gaze estimation respectively.",
        "primary_area": "Computer Vision I",
        "author": "Tianchu Guo; Hui Zhang; ByungIn Yoo; Yongchao Liu; Youngjun Kwak; Jae-Joon Han",
        "authorids": "",
        "aff": "Artificial Intelligence Center, DAMO Academy, Alibaba Group, Hangzhou, China; Samsung Research China - Beijing (SRC-B); Samsung Advanced Institute of Technology (SAIT), South Korea; Beijing ByteDance Technology Co., Ltd.; Samsung Advanced Institute of Technology (SAIT), South Korea; Samsung Advanced Institute of Technology (SAIT), South Korea",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16240/16240-13-19734-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01496-order-regularization-on-ordinal-loss-for-head-pose-age-and-gaze-estimation/",
        "doi": "10.1609/aaai.v35i2.16240",
        "pdf_size": 892830
    },
    {
        "id": "11564",
        "title": "Ordered Counterfactual Explanation by Mixed-Integer Linear Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "Post-hoc explanation methods for machine learning models have been widely used to support decision-making. One of the popular methods is Counterfactual Explanation (CE), also known as Actionable Recourse, which provides a user with a perturbation vector of features that alters the prediction result. Given a perturbation vector, a user can interpret it as an \"action\" for obtaining one's desired decision result. In practice, however, showing only a perturbation vector is often insufficient for users to execute the action. The reason is that if there is an asymmetric interaction among features, such as causality, the total cost of the action is expected to depend on the order of changing features. Therefore, practical CE methods are required to provide an appropriate order of changing features in addition to a perturbation vector. For this purpose, we propose a new framework called Ordered Counterfactual Explanation (OrdCE). We introduce a new objective function that evaluates a pair of an action and an order based on feature interaction. To extract an optimal pair, we propose a mixed-integer linear optimization approach with our objective function. Numerical experiments on real datasets demonstrated the effectiveness of our OrdCE in comparison with unordered CE methods.",
        "primary_area": "Philosophy and Ethics of AI",
        "author": "Kentaro Kanamori; Takuya Takagi; Ken Kobayashi; Yuichi Ike; Kento Uemura; Hiroki Arimura",
        "authorids": "",
        "aff": "Hokkaido University; Fujitsu Laboratories Ltd.; Fujitsu Laboratories Ltd. Tokyo Institute of Technology; Fujitsu Laboratories Ltd.; Fujitsu Laboratories Ltd.; Hokkaido University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17376/17376-13-20870-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11564-ordered-counterfactual-explanation-by-mixed-integer-linear-optimization/",
        "doi": "10.1609/aaai.v35i13.17376",
        "pdf_size": 194247
    },
    {
        "id": "06759",
        "title": "Ordinal Historical Dependence in Graphical Event Models with Tree Representations",
        "track": "main",
        "status": "Poster",
        "abstract": "Graphical event models are representations that capture process independence between different types of events in multivariate temporal point processes. The literature consists of various parametric models and approaches to learn them from multivariate event stream data. Since these models are interpretable, they are often able to provide beneficial insights about event dynamics. In this paper, we show how to compactly model the situation where the order of occurrences of an event\u2019s causes in some recent historical time interval impacts its occurrence rate; this sort of historical dependence is common in several real-world applications. To overcome the practical challenge of parameter explosion due to the number of potential orders that is super-exponential in the number of parents, we introduce a novel graphical event model based on a parametric tree representation for capturing ordinal historical dependence. We present an approach to learn such a model from data, demonstrating that the proposed model fits several real-world datasets better than relevant baselines. We also showcase the potential advantages of such a model to an analyst during the process of knowledge discovery.",
        "primary_area": "Machine Learning I",
        "author": "Debarun Bhattacharjya; Tian Gao; Dharmashankar Subramanian",
        "authorids": "",
        "aff": "IBM Research; IBM Research; IBM Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16835/16835-13-20329-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06759-ordinal-historical-dependence-in-graphical-event-models-with-tree-representations/",
        "doi": "10.1609/aaai.v35i8.16835",
        "pdf_size": 248240
    },
    {
        "id": "04529",
        "title": "Out-of-Town Recommendation with Travel Intention Modeling",
        "track": "main",
        "status": "Poster",
        "abstract": "Out-of-town recommendation is designed for those users who leave their home-town areas and visit the areas they have never been to before. It is challenging to recommend Point-of-Interests (POIs) for out-of-town users since the out-of-town check-in behavior is determined by not only the user\u2019s home-town preference but also the user\u2019s travel intention. Besides, the user\u2019s travel intentions are complex and dynamic, which leads to big difficulties in understanding such intentions precisely. In this paper, we propose a TRAvel-INtention-aware Out-of-town Recommendation framework, named TRAINOR. The proposed TRAINOR framework distinguishes itself from existing out-of-town recommenders in three aspects. First, graph neural networks are explored to represent users\u2019 home-town check-in preference and geographical constraints in out-of-town check-in behaviors. Second, a user-specific travel intention is formulated as an aggregation combining home-town preference and generic travel intention together, where the generic travel intention is regarded as a mixture of inherent intentions that can be learned by Neural Topic Model (NTM). Third, a non-linear mapping function, as well as a matrix factorization method, are employed to transfer users\u2019 home-town preference and estimate out-of-town POI\u2019s representation, respectively. Extensive experiments on real-world data sets validate the effectiveness of the TRAINOR framework. Moreover, the learned travel intention can deliver meaningful explanations for understanding a user\u2019s travel purposes.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Haoran Xin; Xinjiang Lu; Tong Xu; Hao Liu; Jingjing Gu; Dejing Dou; Hui Xiong",
        "authorids": "",
        "aff": "University of Science and Technology of China Business Intelligence Lab, Baidu Research; Business Intelligence Lab, Baidu Research National Engineering Laboratory of Deep Learning Technology and Application, China; University of Science and Technology of China; Business Intelligence Lab, Baidu Research National Engineering Laboratory of Deep Learning Technology and Application, China; Nanjing University of Aeronautics and Astronautics; Business Intelligence Lab, Baidu Research National Engineering Laboratory of Deep Learning Technology and Application, China; Rutgers University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16581/16581-13-20075-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04529-out-of-town-recommendation-with-travel-intention-modeling/",
        "doi": "10.1609/aaai.v35i5.16581",
        "pdf_size": 935949
    },
    {
        "id": "11595",
        "title": "Outlier Impact Characterization for Time Series Data",
        "track": "main",
        "status": "Poster",
        "abstract": "For time series data, certain types of outliers are intrinsically more harmful for parameter estimation and future predictions than others, irrespective of their frequency. In this paper, for the first time, we study the characteristics of such outliers through the lens of the influence functional from robust statistics. In particular, we consider the input time series as a contaminated process, with the recurring outliers generated from an unknown contaminating process. Then we leverage the influence functional to understand the impact of the contaminating process on parameter estimation. The influence functional results in a multi-dimensional vector that measures the sensitivity of the predictive model to the contaminating process, which can be challenging to interpret especially for models with a large number of parameters. To this end, we further propose a comprehensive single-valued metric (the SIF) to measure outlier impacts on future predictions. It provides a quantitative measure regarding the outlier impacts, which can be used in a variety of scenarios, such as the evaluation of outlier detection methods, the creation of more harmful outliers, etc. The empirical results on multiple real data sets demonstrate the effectivenss of the proposed SIF metric.",
        "primary_area": "Philosophy and Ethics of AI",
        "author": "Jianbo Li; Lecheng Zheng; Yada Zhu; Jingrui He",
        "authorids": "",
        "aff": "Three Bridges Capital; University of Illinois at Urbana-Champaign; IBM Research; University of Illinois at Urbana-Champaign",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17379/17379-13-20873-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11595-outlier-impact-characterization-for-time-series-data/",
        "doi": "10.1609/aaai.v35i13.17379",
        "pdf_size": 1260355
    },
    {
        "id": "08653",
        "title": "Overcoming Catastrophic Forgetting in Graph Neural Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Catastrophic forgetting refers to the tendency that a neural network ``forgets'' the previous learned knowledge upon learning new tasks. Prior methods have been focused on overcoming this problem on convolutional neural networks (CNNs), where the input samples like images lie in a grid domain, but have largely overlooked graph neural networks (GNNs) that handle non-grid data. In this paper, we propose a novel scheme dedicated to overcoming catastrophic forgetting problem and hence strengthen continual learning in GNNs. At the heart of our approach is a generic module, termed as topology-aware weight preserving (TWP), applicable to arbitrary form of GNNs in a plug-and-play fashion. Unlike the main stream of CNN-based continual learning methods that rely on solely slowing down the updates of parameters important to the downstream task, TWP explicitly explores the local structures of the input graph, and attempts to stabilize the parameters playing pivotal roles in the topological aggregation. We evaluate TWP on different GNN backbones over several datasets, and demonstrate that it yields performances superior to the state of the art. Code is publicly available at https://github.com/hhliu79/TWP.",
        "primary_area": "Machine Learning III",
        "author": "Huihui Liu; Yiding Yang; Xinchao Wang",
        "authorids": "",
        "aff": "Stevens Institute of Technology; Stevens Institute of Technology; Stevens Institute of Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17049/17049-13-20543-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08653-overcoming-catastrophic-forgetting-in-graph-neural-networks/",
        "doi": "10.1609/aaai.v35i10.17049",
        "pdf_size": 1887318
    },
    {
        "id": "04714",
        "title": "Overcoming Catastrophic Forgetting in Graph Neural Networks with Experience Replay",
        "track": "main",
        "status": "Poster",
        "abstract": "Graph Neural Networks (GNNs) have recently received significant research attention due to their superior performance on a variety of graph-related learning tasks. Most of the current works focus on either static or dynamic graph settings, addressing a single particular task, e.g., node/graph classification, link prediction. In this work, we investigate the question: can GNNs be applied to continuously learning a sequence of tasks? Towards that, we explore the Continual Graph Learning (CGL) paradigm and present the Experience Replay based framework ER-GNN for CGL to alleviate the catastrophic forgetting problem in existing GNNs. ER-GNN stores knowledge from previous tasks as experiences and replays them when learning new tasks to mitigate the catastrophic forgetting issue. We propose three experience node selection strategies: mean of feature, coverage maximization, and influence maximization, to guide the process of selecting experience nodes. Extensive experiments on three benchmark datasets demonstrate the effectiveness of our ER-GNN and shed light on the incremental graph (non-Euclidean) structure learning.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Fan Zhou; Chengtai Cao",
        "authorids": "",
        "aff": "University of Electronic Science and Technology of China; University of Electronic Science and Technology of China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16602/16602-13-20096-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04714-overcoming-catastrophic-forgetting-in-graph-neural-networks-with-experience-replay/",
        "doi": "10.1609/aaai.v35i5.16602",
        "pdf_size": 3008273
    },
    {
        "id": "09774",
        "title": "PAC Learning of Causal Trees with Latent Variables",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning causal models with latent variables from observational and experimental data is an important problem. In this paper we present a polynomial-time algorithm that PAC learns the structure and parameters of a rooted  tree-structured causal network of bounded degree where the internal nodes of the tree cannot be observed or manipulated. Our algorithm is the first of its kind to provably learn the structure and parameters of tree-structured causal models with latent internal variables from random examples and active experiments.",
        "primary_area": "Machine Learning IV",
        "author": "Prasad Tadepalli; Stuart J. Russell",
        "authorids": "",
        "aff": "Oregon State University; University of California at Berkeley",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17175/17175-13-20669-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09774-pac-learning-of-causal-trees-with-latent-variables/",
        "doi": "10.1609/aaai.v35i11.17175",
        "pdf_size": 176964
    },
    {
        "id": "00371",
        "title": "PANTHER: Pathway Augmented Nonnegative Tensor Factorization for HighER-order Feature Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Genetic pathways usually encode molecular mechanisms that can inform targeted interventions. It is often challenging for existing machine learning approaches to jointly model genetic pathways (higher-order features) and variants (atomic features), and present to clinicians interpretable models. In order to build more accurate and better interpretable machine learning models for genetic medicine, we introduce Pathway Augmented Nonnegative Tensor factorization for HighER-order feature learning (PANTHER). PANTHER selects informative genetic pathways that directly encode molecular mechanisms. We apply genetically motivated constrained tensor factorization to group pathways in a way that reflects molecular mechanism interactions. We then train a softmax classifier for disease types using the identified pathway groups. We evaluated PANTHER against multiple state-of-the-art constrained tensor/matrix factorization models, as well as group guided and Bayesian hierarchical models. PANTHER outperforms all state-of-the-art comparison models significantly (p",
        "primary_area": "Application Domains",
        "author": "Yuan Luo; Chengsheng Mao",
        "authorids": "",
        "aff": "Northwestern University; Northwestern University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16113/16113-13-19607-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00371-panther-pathway-augmented-nonnegative-tensor-factorization-for-higher-order-feature-learning/",
        "doi": "10.1609/aaai.v35i1.16113",
        "pdf_size": 479122
    },
    {
        "id": "04019",
        "title": "PASSLEAF: A Pool-bAsed Semi-Supervised LEArning Framework for Uncertain Knowledge Graph Embedding",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we study the problem of embedding uncertain knowledge graphs, where each relation between entities is associated with a confidence score. Observing the existing embedding methods may discard the uncertainty information, only incorporate a specific type of score function, or cause many false-negative samples in the training, we propose the PASSLEAF framework to solve the above issues. PASSLEAF consists of two parts, one is a model that can incorporate different types of scoring functions to predict the relation confidence scores and the other is the semi-supervised learning model by exploiting both positive and negative samples associated with the estimated confidence scores. Furthermore, PASSLEAF leverages a sample pool as a relay of generated samples to further augment the semi-supervised learning. Experiment results show that our proposed framework can learn better embedding in terms of having higher accuracy in both the confidence score prediction and tail entity prediction.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Zhu-Mu Chen; Mi-Yen Yeh; Tei-Wei Kuo",
        "authorids": "",
        "aff": "Department of Computer Science and Information Engineering, National Taiwan University, Taipei, Taiwan; Institute of Information Science, Academia Sinica, Taipei, Taiwan; Department of Computer Science, City University of Hong Kong, Hong Kong Department of Computer Science and Information Engineering, National Taiwan University, Taipei, Taiwan Graduate Institute of Networking and Multimedia, National Taiwan University, Taiwan",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16522/16522-13-20016-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04019-passleaf-a-pool-based-semi-supervised-learning-framework-for-uncertain-knowledge-graph-embedding/",
        "doi": "10.1609/aaai.v35i5.16522",
        "pdf_size": 1271498
    },
    {
        "id": "02269",
        "title": "PC-HMR: Pose Calibration for 3D Human Mesh Recovery from 2D Images/Videos",
        "track": "main",
        "status": "Poster",
        "abstract": "The end-to-end Human Mesh Recovery (HMR) approach has been successfully used for 3D body reconstruction. However, most HMR-based frameworks reconstruct human body by directly learning mesh parameters from images or videos, while lacking explicit guidance of 3D human pose in visual data. As a result, the generated mesh often exhibits incorrect pose for complex activities. To tackle this problem, we propose to exploit 3D pose to calibrate human mesh. Specifically, we develop two novel Pose Calibration frameworks, i.e., Serial PC-HMR and Parallel PC-HMR. By coupling advanced 3D pose estimators and HMR in a serial or parallel manner, these two frameworks can effectively correct human mesh with guidance of a concise pose calibration module. Furthermore, since the calibration module is designed via non-rigid pose transformation, our PC-HMR frameworks can flexibly tackle bone length variations to alleviate misplacement in the calibrated mesh. Finally, our frameworks are based on generic and complementary integration of data-driven learning and geometrical modeling. Via plug-and-play modules, they can be efficiently adapted for both image/video-based human mesh recovery. Additionally, they have no requirement of extra 3D pose annotations in the testing phase, which releases inference difficulties in practice. We perform extensive experiments on the popular benchmarks, i.e., Human3.6M, 3DPW and SURREAL, where our PC-HMR frameworks achieve the SOTA results.",
        "primary_area": "Computer Vision II",
        "author": "Tianyu Luan; Yali Wang; Junhao Zhang; Zhe Wang; Zhipeng Zhou; Yu Qiao",
        "authorids": "",
        "aff": "Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, China; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, China; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, China; University of California, Irvine; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, China; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, China SIAT Branch, Shenzhen Institute of Artificial Intelligence and Robotics for Society",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16326/16326-13-19820-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02269-pc-hmr-pose-calibration-for-3d-human-mesh-recovery-from-2d-images-videos/",
        "doi": "10.1609/aaai.v35i3.16326",
        "pdf_size": 11627958
    },
    {
        "id": "03430",
        "title": "PC-RGNN: Point Cloud Completion and Graph Neural Network for 3D Object Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "LiDAR-based 3D object detection is an important task for autonomous driving and current approaches suffer from sparse and partial point clouds caused by distant and occluded objects. In this paper, we propose a novel two-stage framework, namely PC-RGNN, which deals with these challenges by two specific solutions. On the one hand, we introduce a point cloud completion module to recover high-quality proposals of dense points and entire view with original structures preserved. On the other hand, a graph neural network module, is designed, which comprehensively captures relations among points by the local-global attention mechanism as well as the multi-scale graph based context aggregation and substantially strengthens encoded features. Extensive experiments on the KITTI benchmark show that the proposed approach outperforms the previous state-of-the-art baselines by remarkable margins, highlighting its effectiveness.",
        "primary_area": "Computer Vision III",
        "author": "Yanan Zhang; Di Huang; Yunhong Wang",
        "authorids": "",
        "aff": "Beihang University; Beihang University; Beihang University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16456/16456-13-19950-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03430-pc-rgnn-point-cloud-completion-and-graph-neural-network-for-3d-object-detection/",
        "doi": "10.1609/aaai.v35i4.16456",
        "pdf_size": 4244758
    },
    {
        "id": "09585",
        "title": "PDO-eS2CNNs: Partial Differential Operator Based Equivariant Spherical CNNs",
        "track": "main",
        "status": "Poster",
        "abstract": "Spherical signals exist in many applications, e.g., planetary data, LiDAR scans and digitalization of 3D objects, calling for models that can process spherical data effectively. It does not perform well when simply projecting spherical data into the 2D plane and then using planar convolution neural networks (CNNs), because of the distortion from projection and ineffective translation equivariance.  Actually, good principles of designing spherical CNNs are avoiding distortions and converting the shift equivariance property in planar CNNs to rotation equivariance in the spherical domain. In this work, we use partial differential operators (PDOs) to design a spherical equivariant CNN, PDO-eS2CNN, which is exactly rotation equivariant in the continuous domain. We then discretize PDO-eS2CNNs, and analyze the equivariance error resulted from discretization. This is the first time that the equivariance error is theoretically analyzed in the spherical domain.  In experiments, PDO-eS2CNNs show greater parameter efficiency and outperform other spherical CNNs significantly on several tasks.",
        "primary_area": "Machine Learning IV",
        "author": "Zhengyang Shen; Tiancheng Shen; Zhouchen Lin; Jinwen Ma",
        "authorids": "",
        "aff": "School of Mathematical Sciences and LMAM, Peking University; Center for Data Science, Peking University The Chinese University of Hong Kong; Key Lab. of Machine Perception (MoE), School of EECS, Peking University Pazhou Lab, Guangzhou, China; School of Mathematical Sciences and LMAM, Peking University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17154/17154-13-20648-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09585-pdo-es2cnns-partial-differential-operator-based-equivariant-spherical-cnns/",
        "doi": "10.1609/aaai.v35i11.17154",
        "pdf_size": 2578021
    },
    {
        "id": "02782",
        "title": "PGNet: Real-time Arbitrarily-Shaped Text Spotting with Point Gathering Network",
        "track": "main",
        "status": "Poster",
        "abstract": "The reading of arbitrarily-shaped text has received increasing research attention. However, existing text spotters are mostly built on two-stage frameworks or character-based methods, which suffer from either Non-Maximum Suppression (NMS), Region-of-Interest (RoI) operations, or character-level annotations. In this paper, to address the above problems, we propose a novel fully convolutional Point Gathering Network (PGNet) for reading arbitrarily-shaped text in real-time. The PGNet is a single-shot text spotter, where the pixel-level character classification map is learned with proposed PG-CTC loss avoiding the usage of character-level annotations. With a PG-CTC decoder, we gather high-level character classification vectors from two-dimensional space and decode them into text symbols without NMS and RoI operations involved, which guarantees high efficiency. Additionally, reasoning the relations between each character and its neighbors, a graph refinement module (GRM) is proposed to optimize the coarse recognition and improve the end-to-end performance. Experiments prove that the proposed method achieves competitive accuracy, meanwhile significantly improving the running speed. In particular, in Total-Text, it runs at 46.7 FPS, surpassing the previous spotters with a large margin.",
        "primary_area": "Computer Vision III",
        "author": "Pengfei Wang; Chengquan Zhang; Fei Qi; Shanshan Liu; Xiaoqiang Zhang; Pengyuan Lyu; Junyu Han; Jingtuo Liu; Errui Ding; Guangming Shi",
        "authorids": "",
        "aff": "Xidian University; Baidu Inc.; Xidian University; Baidu Inc.; Baidu Inc.; Baidu Inc.; Baidu Inc.; Baidu Inc.; Baidu Inc.; Xidian University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16383/16383-13-19877-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02782-pgnet-real-time-arbitrarily-shaped-text-spotting-with-point-gathering-network/",
        "doi": "10.1609/aaai.v35i4.16383",
        "pdf_size": 3584171
    },
    {
        "id": "00845",
        "title": "PHASE: PHysically-grounded Abstract Social Events for Machine Social Perception",
        "track": "main",
        "status": "Poster",
        "abstract": "The ability to perceive and reason about social interactions in the context of physical environments is core to human social intelligence and human-machine cooperation. However, no prior dataset or benchmark has systematically evaluated physically grounded perception of complex social interactions that go beyond short actions, such as high-fiving, or simple group activities, such as gathering. In this work, we create a dataset of physically-grounded abstract social events, PHASE, that resemble a wide range of real-life social interactions by including social concepts such as helping another agent. PHASE consists of 2D animations of pairs of agents moving in a continuous space generated procedurally using a physics engine and a hierarchical planner. Agents have a limited field of view, and can interact with multiple objects, in an environment that has multiple landmarks and obstacles. Using PHASE, we design a social recognition task and a social prediction task. PHASE is validated with human experiments demonstrating that humans perceive rich interactions in the social events, and that the simulated agents behave similarly to humans. As a baseline model, we introduce a Bayesian inverse planning approach, SIMPLE (SIMulation, Planning and Local Estimation), which outperforms state-of-the-art feed-forward neural networks. We hope that PHASE can serve as a difficult new challenge for developing new models that can recognize complex social interactions.",
        "primary_area": "Cognitive Modeling and Cognitive Systems",
        "author": "Aviv Netanyahu; Tianmin Shu; Boris Katz; Andrei Barbu; Joshua B. Tenenbaum",
        "authorids": "",
        "aff": "Massachusetts Institute of Technology; Massachusetts Institute of Technology; Massachusetts Institute of Technology; Massachusetts Institute of Technology; Massachusetts Institute of Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16167/16167-13-19661-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00845-phase-physically-grounded-abstract-social-events-for-machine-social-perception/",
        "doi": "10.1609/aaai.v35i1.16167",
        "pdf_size": 1595800
    },
    {
        "id": "10033",
        "title": "PID-Based Approach to Adversarial Attacks",
        "track": "main",
        "status": "Poster",
        "abstract": "Adversarial attack can misguide the deep neural networks (DNNs) with adding small-magnitude perturbations to normal examples, which is mainly determined by the gradient of the loss function with respect to inputs. Previously, various strategies have been proposed to enhance the performance of adversarial attacks. However, all these methods only  utilize the gradients in the present and past to generate adversarial examples. Until now, the trend of gradient change in the future (i.e., the derivative of gradient) has not been considered yet. Inspired by the classic proportional-integral-derivative (PID) controller in the field of automatic control, we propose a new PID-based approach for generating adversarial examples. The gradients in the present and past, and the derivative of gradient are considered in our method, which correspond to the components of P, I and D in the PID controller, respectively.  Extensive experiments consistently demonstrate that our method can achieve higher attack success rates and exhibit better transferability compared with the state-of-the-art gradient-based adversarial attacks. Furthermore, our method possesses good extensibility and can be applied to almost all available gradient-based adversarial attacks.",
        "primary_area": "Machine Learning IV",
        "author": "Chen Wan; Biaohua Ye; Fangjun  Huang",
        "authorids": "",
        "aff": "School of Computer Science and Engineering, Sun Yat-Sen University, Guangzhou 510006, China Guangdong Provincial Key Laboratory of Information Security Technology, Guangzhou 510006, China; School of Computer Science and Engineering, Sun Yat-Sen University, Guangzhou 510006, China Guangdong Provincial Key Laboratory of Information Security Technology, Guangzhou 510006, China; School of Computer Science and Engineering, Sun Yat-Sen University, Guangzhou 510006, China Guangdong Provincial Key Laboratory of Information Security Technology, Guangzhou 510006, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17204/17204-13-20698-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10033-pid-based-approach-to-adversarial-attacks/",
        "doi": "10.1609/aaai.v35i11.17204",
        "pdf_size": 2195012
    },
    {
        "id": "04164",
        "title": "PREMERE: Meta-Reweighting via Self-Ensembling for Point-of-Interest Recommendation",
        "track": "main",
        "status": "Poster",
        "abstract": "Point-of-interest (POI) recommendation has become an important research topic in these days. The user check-in history used as the input to POI recommendation is very imbalanced and noisy because of sparse and missing check-ins. Although sample reweighting is commonly adopted for addressing this challenge with the input data, its fixed weighting scheme is often inappropriate to deal with different characteristics of users or POIs. Thus, in this paper, we propose PREMERE, an adaptive weighting scheme based on meta-learning. Because meta-data is typically required by meta-learning but is inherently hard to obtain in POI recommendation, we self-generate the meta-data via self-ensembling. Furthermore, the meta-model architecture is extended to deal with the scarcity of check-ins. Thorough experiments show that replacing a weighting scheme with PREMERE boosts the performance of the state-of-the-art recommender algorithms by 2.36\u201326.9% on three benchmark datasets.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Minseok Kim; Hwanjun Song; Doyoung Kim; Kijung Shin; Jae-Gil Lee",
        "authorids": "",
        "aff": "KAIST; KAIST; KAIST; KAIST; KAIST",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16539/16539-13-20033-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04164-premere-meta-reweighting-via-self-ensembling-for-point-of-interest-recommendation/",
        "doi": "10.1609/aaai.v35i5.16539",
        "pdf_size": 340284
    },
    {
        "id": "00617",
        "title": "PSSM-Distil: Protein Secondary Structure Prediction (PSSP) on Low-Quality PSSM by Knowledge Distillation with Contrastive Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "",
        "primary_area": "Application Domains",
        "author": "Qin Wang; Boyuan Wang; Zhenlei Xu; Jiaxiang Wu; Peilin Zhao; Zhen Li; Sheng Wang; Junzhou Huang; Shuguang Cui",
        "authorids": "",
        "aff": "",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16141/16141-13-19635-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00617-pssm-distil-protein-secondary-structure-prediction-pssp-on-low-quality-pssm-by-knowledge-distillation-with-contrastive-learning/",
        "doi": "",
        "pdf_size": 581024
    },
    {
        "id": "01602",
        "title": "PTN: A Poisson Transfer Network for Semi-supervised Few-shot Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "The predicament in semi-supervised few-shot learning (SSFSL) is to maximize the value of the extra unlabeled data to boost the few-shot learner. In this paper, we propose a Poisson Transfer Network (PTN) to mine the unlabeled information for SSFSL from two aspects. First, the Poisson Merriman\u2013Bence\u2013Osher (MBO) model builds a bridge for the communications between labeled and unlabeled examples. This model serves as a more stable and informative classifier than traditional graph-based SSFSL methods in the message-passing process of the labels. Second, the extra unlabeled samples are employed to transfer the knowledge from base classes to novel classes through contrastive learning. Specifically, we force the augmented positive pairs close while push the negative ones distant. Our contrastive transfer scheme implicitly learns the novel-class embeddings to alleviate the over-fitting problem on the few labeled data. Thus, we can mitigate the degeneration of embedding generality in novel classes. Extensive experiments indicate that PTN outperforms the state-of-the-art few-shot and SSFSL models on miniImageNet and tieredImageNet benchmark datasets.",
        "primary_area": "Computer Vision I",
        "author": "Huaxi Huang; Junjie Zhang; Jian Zhang; Qiang Wu; Chang Xu",
        "authorids": "",
        "aff": "University of Technology Sydney; Shanghai University; University of Technology Sydney; University of Technology Sydney; The University of Sydney",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16252/16252-13-19746-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01602-ptn-a-poisson-transfer-network-for-semi-supervised-few-shot-learning/",
        "doi": "10.1609/aaai.v35i2.16252",
        "pdf_size": 410931
    },
    {
        "id": "08784",
        "title": "PULNS: Positive-Unlabeled Learning with Effective Negative Sample Selector",
        "track": "main",
        "status": "Poster",
        "abstract": "Positive-unlabeled learning (PU learning) is an important case of binary classification where the training data only contains positive and unlabeled samples. The current state-of-the-art approach for PU learning is the cost-sensitive approach, which casts PU learning as a cost-sensitive classification problem and relies on unbiased risk estimator for correcting the bias introduced by the unlabeled samples. However, this approach requires the knowledge of class prior and is subject to the potential label noise. In this paper, we propose a novel PU learning approach dubbed PULNS, equipped with an effective negative sample selector, which is optimized by reinforcement learning. Our PULNS approach employs an effective negative sample selector as the agent responsible for selecting negative samples from the unlabeled data. While the selected, likely negative samples can be used to improve the classifier, the performance of classifier is also used as the reward to improve the selector through the REINFORCE algorithm. By alternating the updates of the selector and the classifier, the performance of both is improved. Extensive experimental studies on 7 real-world application benchmarks demonstrate that PULNS consistently outperforms the current state-of-the-art methods in PU learning, and our experimental results also confirm the effectiveness of the negative sample selector underlying PULNS.",
        "primary_area": "Machine Learning III",
        "author": "Chuan Luo; Pu Zhao; Chen Chen; Bo Qiao; Chao Du; Hongyu Zhang; Wei Wu; Shaowei Cai; Bing He; Saravanakumar Rajmohan; Qingwei Lin",
        "authorids": "",
        "aff": "Microsoft Research, China; Microsoft Research, China; Microsoft Research, China Microsoft 365, United States; Microsoft Research, China; Microsoft Research, China; The University of Newcastle, Australia; L3S Research Center, Leibniz University Hannover, Germany; State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences, China School of Computer Science and Technology, University of Chinese Academy of Sciences, China; State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences, China School of Computer Science and Technology, University of Chinese Academy of Sciences, China; Microsoft 365, United States; Microsoft Research, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17064/17064-13-20558-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08784-pulns-positive-unlabeled-learning-with-effective-negative-sample-selector/",
        "doi": "10.1609/aaai.v35i10.17064",
        "pdf_size": 324629
    },
    {
        "id": "12857",
        "title": "Paragraph-level Commonsense Transformers with Recurrent Memory",
        "track": "main",
        "status": "Poster",
        "abstract": "Human understanding of narrative texts requires making commonsense inferences beyond what is stated in the text explicitly. A recent model, COMET, can generate such inferences along several dimensions such as pre- and post-conditions, motivations, and mental states of the participants. However, COMET was trained on short phrases, and is therefore discourse-agnostic. When presented with each sentence of a multi-sentence narrative, it might generate inferences that are inconsistent with the rest of the narrative.   We present the task of discourse-aware commonsense inference. Given a sentence within a narrative, the goal is to generate commonsense inferences along predefined dimensions, while maintaining coherence with the rest of the narrative. Such large-scale paragraph-level annotation is hard to get and costly, so we use available sentence-level annotations to efficiently and automatically construct a distantly supervised corpus.   Using this corpus, we train PARA-COMET, a discourse-aware model that incorporates paragraph-level information to generate coherent commonsense inferences from narratives. PARA-COMET captures both semantic knowledge pertaining to prior world knowledge, and episodic knowledge involving how current events relate to prior and future events in a narrative. Our results confirm that PARA-COMET outperforms the sentence-level baselines, particularly in generating inferences that are both coherent and novel.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Saadia Gabriel; Chandra Bhagavatula; Vered Shwartz; Ronan Le Bras; Maxwell Forbes; Yejin Choi",
        "authorids": "",
        "aff": "University of Washington Allen Institute for Artificial Intelligence; Allen Institute for Artificial Intelligence; University of Washington Allen Institute for Artificial Intelligence; Allen Institute for Artificial Intelligence; University of Washington Allen Institute for Artificial Intelligence; University of Washington Allen Institute for Artificial Intelligence",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17521/17521-13-21015-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12857-paragraph-level-commonsense-transformers-with-recurrent-memory/",
        "doi": "10.1609/aaai.v35i14.17521",
        "pdf_size": 1583266
    },
    {
        "id": "03860",
        "title": "Parallel Constraint Acquisition",
        "track": "main",
        "status": "Poster",
        "abstract": "Constraint acquisition systems assist the non-expert user in modelling her problem as a constraint network. QUACQ is a sequential constraint acquisition algorithm that generates queries as (partial) examples to be classified as positive or negative. The drawbacks are that the user may need to answer a great number of such examples, within a significant waiting time between two examples, to learn all the constraints. In this paper, we propose PACQ, a portfolio-based parallel constraint acquisition system. The design of PACQ benefits from having several users sharing the same target problem. Moreover, each user is involved in a particular acquisition session, opened in parallel to improve the overall performance of the whole system.We prove the correctness of PACQ and we give an experimental evaluation that shows that our approach improves on QUACQ.",
        "primary_area": "Constraint Satisfaction and Optimization",
        "author": "Nadjib Lazaar",
        "authorids": "",
        "aff": "LIRMM University of Montpellier CNRS",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16504/16504-13-19998-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03860-parallel-constraint-acquisition/",
        "doi": "10.1609/aaai.v35i5.16504",
        "pdf_size": 1846528
    },
    {
        "id": "12249",
        "title": "Parameterized Algorithms for MILPs with Small Treedepth",
        "track": "main",
        "status": "Poster",
        "abstract": "Solving (mixed) integer (linear) programs, (M)I(L)Ps for short, is a fundamental optimisation task with a wide range of applications in artificial intelligence and computer science in general. While hard in general, recent years have brought about vast progress for solving structurally restricted, (non-mixed) ILPs: n-fold, tree-fold, 2-stage stochastic and multi-stage stochastic programs admit efficient algorithms, and all of these special cases are subsumed by the class of ILPs of small treedepth.  In this paper, we extend this line of work to the mixed case, by showing an algorithm solving MILP in time f(a,d)poly(n), where a is the largest coefficient of the constraint matrix, d is its treedepth, and n is the number of variables.  This is enabled by proving bounds on the denominators (fractionality) of the vertices of bounded-treedepth (non-integer) linear programs. We do so by carefully analysing the inverses of invertible sub-matrices of the constraint matrix. This allows us to afford scaling up the mixed program to the integer grid, and applying the known methods for integer programs.  We then trace the limiting boundary of our \"bounded fractionality\" approach both in terms of going beyond MILP (by allowing non-linear objectives) as well as its usefulness for generalising other important known tractable classes of ILP.  On the positive side, we show that our result can be generalised from MILP to MIP with piece-wise linear separable convex objectives with integer breakpoints. On the negative side, we show that going even slightly beyond such objectives or considering other natural related tractable classes of ILP leads to unbounded fractionality.  Finally, we show that restricting the structure of only the integral variables in the constraint matrix does not yield tractable special cases.",
        "primary_area": "Search and Optimization",
        "author": "Cornelius Brand; Martin Kouteck\u00fd; Sebastian Ordyniak",
        "authorids": "",
        "aff": "Charles University, Prague; Charles University, Prague; University of Leeds",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17454/17454-13-20948-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12249-parameterized-algorithms-for-milps-with-small-treedepth/",
        "doi": "10.1609/aaai.v35i14.17454",
        "pdf_size": 167658
    },
    {
        "id": "06426",
        "title": "Parameterized Complexity of Logic-Based Argumentation in Schaefer\u2019s Framework",
        "track": "main",
        "status": "Poster",
        "abstract": "Logic-based argumentation is a well-established formalism modeling nonmonotonic reasoning. It has been playing a major role in AI for decades, now.  Informally, a set of formulas is the support for a given claim if it is consistent, subset-minimal, and implies the claim. In such a case, the pair of the support and the claim together is called an argument. In this paper, we study the propositional variants of the following three computational tasks studied in argumentation: ARG (exists a support for a given claim with respect to a given set of formulas), ARG-Check (is a given set a support for a given claim), and ARG-Rel (similarly as ARG plus requiring an additionally given formula to be contained in the support). ARG-Check is complete for the complexity class DP, and the other two problems are known to be complete for the second level of the polynomial hierarchy and, accordingly, are highly intractable. Analyzing the reason for this intractability, we perform a two-dimensional classification: first, we consider all possible propositional fragments of the problem within Schaefer's framework, and then study different parameterizations for each of the fragment. We identify a list of reasonable structural parameters (size of the claim, support, knowledge-base) that are connected to the aforementioned decision problems. Eventually, we thoroughly draw a fine border of parameterized intractability for each of the problems showing where the problems are fixed-parameter tractable and when this exactly stops. Surprisingly, several cases are of very high intractability (paraNP and beyond).",
        "primary_area": "Knowledge Representation and Reasoning",
        "author": "Yasir Mahmood; Arne Meier; Johannes Schmidt",
        "authorids": "",
        "aff": "Leibniz Universit\u00e4t Hannover; Leibniz Universit\u00e4t Hannover; J\u00f6nk\u00f6ping University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16797/16797-13-20291-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06426-parameterized-complexity-of-logic-based-argumentation-in-schaefer-s-framework/",
        "doi": "10.1609/aaai.v35i7.16797",
        "pdf_size": 157975
    },
    {
        "id": "06454",
        "title": "Parameterized Complexity of Small Decision Tree Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "We study the NP-hard problem of learning a decision tree (DT) of smallest depth or size from data. We provide the first parameterized complexity analysis of the problem and draw a detailed parameterized complexity map for the natural parameters: size or depth of the DT, maximum domain size of all features, and the maximum Hamming distance between any two examples.  Our main result shows that learning DTs of smallest depth or size is fixed-parameter tractable (FPT) parameterized by the combination of all three of these parameters. We contrast this FPT-result by various hardness results that underline the algorithmic significance of the considered parameters.",
        "primary_area": "Knowledge Representation and Reasoning",
        "author": "Sebastian Ordyniak; Stefan Szeider",
        "authorids": "",
        "aff": "University of Leeds; TU Wien",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16800/16800-13-20294-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06454-parameterized-complexity-of-small-decision-tree-learning/",
        "doi": "10.1609/aaai.v35i7.16800",
        "pdf_size": 167603
    },
    {
        "id": "06402",
        "title": "Parameterized Logical Theories",
        "track": "main",
        "status": "Poster",
        "abstract": "A theory in first-order logic is a set of sentences. A parameterized theory is a first-order theory with some of its predicates and functions identified as parameters, together with some import statements that call other parameterized theories. A KB is then a collection of these interconnected parameterised theories, similar to how a computer program is constructed as a set of functions in a modern programming language. In this paper, we provide a translational semantics for these parameterized theories in first-order logic using the situation calculus. We also discuss their potential uses in areas such as multi-context reasoning and logical formalization of computer programs.",
        "primary_area": "Knowledge Representation and Reasoning",
        "author": "Fangzhen Lin",
        "authorids": "",
        "aff": "Hong Kong University of Science and Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16794/16794-13-20288-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06402-parameterized-logical-theories/",
        "doi": "10.1609/aaai.v35i7.16794",
        "pdf_size": 134818
    },
    {
        "id": "03931",
        "title": "Parameterizing Branch-and-Bound Search Trees to Learn Branching Policies",
        "track": "main",
        "status": "Poster",
        "abstract": "Branch and Bound (B&B) is the exact tree search method typically used to solve Mixed-Integer Linear Programming problems (MILPs). Learning branching policies for MILP has become an active research area, with most works proposing to imitate the strong branching rule and specialize it to distinct classes of problems. We aim instead at learning a policy that generalizes across heterogeneous MILPs: our main hypothesis is that parameterizing the state of the B&B search tree can aid this type of generalization. We propose a novel imitation learning framework, and introduce new input features and architectures to represent branching. Experiments on MILP benchmark instances clearly show the advantages of incorporating an explicit parameterization of the state of the search tree to modulate the branching decisions, in terms of both higher accuracy and smaller B&B trees. The resulting policies significantly outperform the current state-of-the-art method for \"learning to branch\" by effectively allowing generalization to generic unseen instances.",
        "primary_area": "Constraint Satisfaction and Optimization",
        "author": "Giulia Zarpellon; Jason Jo; Andrea Lodi; Yoshua Bengio",
        "authorids": "",
        "aff": "Polytechnique Montr\u00e9al; Mila Universit\u00e9 de Montr\u00e9al; Polytechnique Montr\u00e9al; Mila Universit\u00e9 de Montr\u00e9al",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16512/16512-13-20006-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03931-parameterizing-branch-and-bound-search-trees-to-learn-branching-policies/",
        "doi": "10.1609/aaai.v35i5.16512",
        "pdf_size": 317832
    },
    {
        "id": "12284",
        "title": "Pareto Optimization for Subset Selection with Dynamic Partition Matroid Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "In this study, we consider the subset selection problems with submodular or monotone discrete objective functions under partition matroid constraints where the thresholds are dynamic. We focus on POMC, a simple Pareto optimization approach that has been shown to be effective on such problems. Our analysis departs from singular constraint problems and extends to problems of multiple constraints. We show that previous results of POMC's performance also hold for multiple constraints. Our experimental investigations on random undirected maxcut problems demonstrate POMC's competitiveness against the classical GREEDY algorithm with restart strategy.",
        "primary_area": "Search and Optimization",
        "author": "Anh Viet Do; Frank Neumann",
        "authorids": "",
        "aff": "Optimisation and Logistics, School of Computer Science, The University of Adelaide, Adelaide, Australia; Optimisation and Logistics, School of Computer Science, The University of Adelaide, Adelaide, Australia",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17458/17458-13-20952-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12284-pareto-optimization-for-subset-selection-with-dynamic-partition-matroid-constraints/",
        "doi": "10.1609/aaai.v35i14.17458",
        "pdf_size": 283343
    },
    {
        "id": "09594",
        "title": "Partial Is Better Than All: Revisiting Fine-tuning Strategy for Few-shot Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "The goal of few-shot learning is to learn a classifier that can recognize unseen classes from limited support data with labels. A common practice for this task is to train a model on the base set first and then transfer to novel classes through fine-tuning or meta-learning. However, as the base classes have no overlap to the novel set, simply transferring whole knowledge from base data is not an optimal solution since some knowledge in the base model may be biased or even harmful to the novel class. In this paper, we propose to transfer partial knowledge by freezing or fine-tuning particular layer(s) in the base model. Specifically, layers will be imposed different learning rates if they are chosen to be fine-tuned, to control the extent of preserved transferability. To determine which layers to be recast and what values of learning rates for them, we introduce an evolutionary search based method that is efficient to simultaneously locate the target layers and determine their individual learning rates. We conduct extensive experiments on CUB and mini-ImageNet to demonstrate the effectiveness of our proposed method. It achieves the state-of-the-art performance on both meta-learning and non-meta based frameworks. Furthermore, we extend our method to the conventional pre-training + fine-tuning paradigm and obtain consistent improvement.",
        "primary_area": "Machine Learning IV",
        "author": "Zhiqiang Shen; Zechun Liu; Jie Qin; Marios Savvides; Kwang-Ting Cheng",
        "authorids": "",
        "aff": "Carnegie Mellon University; Hong Kong University of Science and Technology; Inception Institute of Artificial Intelligence; Carnegie Mellon University; Hong Kong University of Science and Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17155/17155-13-20649-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09594-partial-is-better-than-all-revisiting-fine-tuning-strategy-for-few-shot-learning/",
        "doi": "10.1609/aaai.v35i11.17155",
        "pdf_size": 2846021
    },
    {
        "id": "10948",
        "title": "Partial-Label and Structure-constrained Deep Coupled Factorization Network",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we technically propose an enriched prior guided framework, called Dual-constrained Deep Semi-Supervised Coupled Factorization Network (DS2CF-Net), for discovering hierarchical coupled data representation. To extract hidden deep features, DS2CF-Net is formulated as a partial-label and geometrical structure-constrained framework. Specifically, DS2CF-Net designs a deep factorization architecture using multilayers of linear transformations, which can coupled update both the basis vectors and new representations in each layer. To enable learned deep representations and coefficients to be discriminative, we also consider enriching the supervised prior by joint deep coefficients-based label prediction and then incorporate the enriched prior information as additional label and structure constraints. The label constraint can enable the intra-class samples to have same coordinate in feature space, and the structure constraint forces the coefficients in each layer to be block-diagonal so that the enriched prior using the self-expressive label propagation are more accurate. Our network also integrates the adaptive dual-graph learning to retain the local structures of both data and feature manifolds in each layer. Extensive experiments on image datasets demonstrate the effectiveness of DS2CF-Net for representation learning and clustering.",
        "primary_area": "Machine Learning V",
        "author": "Yan Zhang; Zhao Zhang; Yang Wang; Zheng Zhang; Li Zhang; Shuicheng Yan; Meng Wang",
        "authorids": "",
        "aff": "School of Computer Science and Technology, Soochow University, Suzhou 215006, China; School of Computer Science and Technology, Soochow University, Suzhou 215006, China School of Computer Science and Information Engineering, Hefei University of Technology, Hefei, China; School of Computer Science and Information Engineering, Hefei University of Technology, Hefei, China; Harbin Institute of Technology & Peng Cheng Laboratory, Shenzhen, China; School of Computer Science and Technology, Soochow University, Suzhou 215006, China; YITU Technology; School of Computer Science and Information Engineering, Hefei University of Technology, Hefei, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17307/17307-13-20801-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10948-partial-label-and-structure-constrained-deep-coupled-factorization-network/",
        "doi": "10.1609/aaai.v35i12.17307",
        "pdf_size": 2071027
    },
    {
        "id": "01309",
        "title": "Partially Non-Autoregressive Image Captioning",
        "track": "main",
        "status": "Poster",
        "abstract": "Current state-of-the-art image captioning systems usually generated descriptions autoregressively, i.e., every forward step conditions on the given image and previously produced words. The sequential attribution causes a unavoidable decoding latency. Non-autoregressive image captioning, on the other hand, predicts the entire sentence simultaneously and accelerates the inference process significantly. However, it removes the dependence in a caption and commonly suffers from repetition or missing issues. To make a better trade-off between speed and quality, we introduce a partially non-autoregressive model, named PNAIC, which considers a caption as a series of concatenated word groups. The groups are generated parallelly in global while each word in group is predicted from left to right, and thus the captioner can create multiple discontinuous words concurrently at each time step. More importantly, by incorporating curriculum learning-based training tasks of group length prediction and invalid group deletion, our model is capable of generating accurate captions as well as preventing common incoherent errors. Extensive experiments on MS COCO benchmark demonstrate that our proposed method achieves more than 3.5\u00d7 speedup while maintaining competitive performance.",
        "primary_area": "Computer Vision I",
        "author": "Zhengcong Fei",
        "authorids": "",
        "aff": "Key Lab of Intelligent Information Processing of Chinese Academy of Sciences (CAS), Institute of Computing Technology, CAS, Beijing 100190, China University of Chinese Academy of Sciences, Beijing 100049, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16219/16219-13-19713-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01309-partially-non-autoregressive-image-captioning/",
        "doi": "10.1609/aaai.v35i2.16219",
        "pdf_size": 900159
    },
    {
        "id": "01873",
        "title": "Patch-Wise Attention Network for Monocular Depth Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "In computer vision, monocular depth estimation is the problem of obtaining a high-quality depth map from a two-dimensional image. This map provides information on three-dimensional scene geometry, which is necessary for various applications in academia and industry, such as robotics and autonomous driving. Recent studies based on convolutional neural networks achieved impressive results for this task. However, most previous studies did not consider the relationships between the neighboring pixels in a local area of the scene. To overcome the drawbacks of existing methods, we propose a patch-wise attention method for focusing on each local area. After extracting patches from an input feature map, our module generates attention maps for each local patch, using two attention modules for each patch along the channel and spatial dimensions. Subsequently, the attention maps return to their initial positions and merge into one attention feature. Our method is straightforward but effective. The experimental results on two challenging datasets, KITTI and NYU Depth V2, demonstrate that the proposed method achieves significant performance. Furthermore, our method outperforms other state-of-the-art methods on the KITTI depth estimation benchmark.",
        "primary_area": "Computer Vision II",
        "author": "Sihaeng Lee; Janghyeon Lee; Byungju Kim; Eojindl Yi; Junmo Kim",
        "authorids": "",
        "aff": "KAIST; KAIST; KAIST Mathpresso Inc; KAIST; KAIST",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16282/16282-13-19776-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01873-patch-wise-attention-network-for-monocular-depth-estimation/",
        "doi": "10.1609/aaai.v35i3.16282",
        "pdf_size": 4173990
    },
    {
        "id": "10302",
        "title": "Peer Collaborative Learning for Online Knowledge Distillation",
        "track": "main",
        "status": "Poster",
        "abstract": "Traditional knowledge distillation uses a two-stage training strategy to transfer knowledge from a high-capacity teacher model to a compact student model, which relies heavily on the pre-trained teacher. Recent online knowledge distillation alleviates this limitation by collaborative learning, mutual learning and online ensembling, following a one-stage end-to-end training fashion. However, collaborative learning and mutual learning fail to construct an online high-capacity teacher, whilst online ensembling ignores the collaboration among branches and its logit summation impedes the further optimisation of the ensemble teacher. In this work, we propose a novel Peer Collaborative Learning method for online knowledge distillation, which integrates online ensembling and network collaboration into a unified framework. Specifically, given a target network, we construct a multi-branch network for training, in which each branch is called a peer. We perform random augmentation multiple times on the inputs to peers and assemble feature representations outputted from peers with an additional classifier as the peer ensemble teacher. This helps to transfer knowledge from a high-capacity teacher to peers, and in turn further optimises the ensemble teacher. Meanwhile, we employ the temporal mean model of each peer as the peer mean teacher to collaboratively transfer knowledge among peers, which helps each peer to learn richer knowledge and facilitates to optimise a more stable model with better generalisation. Extensive experiments on CIFAR-10, CIFAR-100 and ImageNet show that the proposed method significantly improves the generalisation of various backbone networks and outperforms the state-of-the-art methods.",
        "primary_area": "Machine Learning V",
        "author": "Guile Wu; Shaogang Gong",
        "authorids": "",
        "aff": "Queen Mary University of London; Queen Mary University of London",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17234/17234-13-20728-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10302-peer-collaborative-learning-for-online-knowledge-distillation/",
        "doi": "10.1609/aaai.v35i12.17234",
        "pdf_size": 264646
    },
    {
        "id": "11536",
        "title": "PenDer: Incorporating Shape Constraints via Penalized Derivatives",
        "track": "main",
        "status": "Poster",
        "abstract": "When deploying machine learning models in the real-world, system designers may wish that models exhibit certain shape behavior, i.e., model outputs follow a particular shape with respect to input features. Trends such as monotonicity, convexity, diminishing or accelerating returns are some of the desired shapes. Presence of these shapes makes the model more interpretable for the system designers, and adequately fair for the customers. We notice that many such common shapes are related to derivatives, and propose a new approach, PenDer (Penalizing Derivatives), which incorporates these shape constraints by penalizing the derivatives. We further present an Augmented Lagrangian Method (ALM) to solve this constrained optimization problem. Experiments on three real-world datasets illustrate that even though both PenDer and state-of-the-art Lattice models achieve similar conformance to shape, PenDer captures better sensitivity of prediction with respect to intended features. We also demonstrate that PenDer achieves better test performance than Lattice while enforcing more desirable shape behavior.",
        "primary_area": "Philosophy and Ethics of AI",
        "author": "Akhil Gupta; Lavanya Marla; Ruoyu Sun; Naman Shukla; Arinbj\u00f6rn Kolbeinsson",
        "authorids": "",
        "aff": "University of Illinois, Urbana-Champaign; University of Illinois, Urbana-Champaign; University of Illinois, Urbana-Champaign; Deepair LLC; Imperial College London",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17373/17373-13-20867-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11536-pender-incorporating-shape-constraints-via-penalized-derivatives/",
        "doi": "10.1609/aaai.v35i13.17373",
        "pdf_size": 1576963
    },
    {
        "id": "12902",
        "title": "Perception Score: A Learned Metric for Open-ended Text Generation Evaluation",
        "track": "main",
        "status": "Poster",
        "abstract": "Automatic evaluation for open-ended natural language generation tasks remains a challenge. We propose a learned evaluation metric: Perception Score. It utilizes a pre-trained model and considers context information for conditional generation. Perception Score assigns a holistic score along with the uncertainty measurement. We conduct experiments on three open-ended conditional generation tasks and two open-ended unconditional generation tasks. Perception Score achieves state-of-the-art results on all the tasks consistently in terms of correlation with human evaluation scores.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Jing Gu; Qingyang Wu; Zhou Yu",
        "authorids": "",
        "aff": "University of California, Davis; University of California, Davis; Columbia University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17526/17526-13-21020-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12902-perception-score-a-learned-metric-for-open-ended-text-generation-evaluation/",
        "doi": "10.1609/aaai.v35i14.17526",
        "pdf_size": 376031
    },
    {
        "id": "04812",
        "title": "Persistence of Anti-vaccine Sentiment in Social Networks Through Strategic Interactions",
        "track": "main",
        "status": "Poster",
        "abstract": "Vaccination is the primary intervention for controlling the spread of infectious diseases. A certain level of vaccination rate (referred to as \"herd immunity'') is needed for this intervention to be effective. However, there are concerns that herd immunity might not be achieved due to an increasing level of hesitancy and opposition to vaccines. One of the primary reasons for this is the cost of non-conformance with one's peers. We use the framework of network coordination games to study the persistence of anti-vaccine sentiment in a population. We extend it to incorporate the opposing forces of the pressure of conforming to peers, herd-immunity and vaccination benefits. We study the structure of the equilibria in such games, and the characteristics of unvaccinated nodes. We also study Stackelberg strategies to reduce the number of nodes with anti-vaccine sentiment. Finally, we evaluate our results on different kinds of real world social networks.",
        "primary_area": "AI Responses to the COVID-19 Pandemic",
        "author": "A S M Ahsan-Ul Haque; Mugdha Thakur; Matthew Bielskas; Achla Marathe; Anil Vullikanti",
        "authorids": "",
        "aff": "Biocomplexity Institute, University of Virginia Department of Computer Science, University of Virginia; Biocomplexity Institute, University of Virginia; Biocomplexity Institute, University of Virginia Department of Computer Science, University of Virginia; Biocomplexity Institute, University of Virginia Department of Public Health Sciences, University of Virginia; Biocomplexity Institute, University of Virginia Department of Computer Science, University of Virginia",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16613/16613-13-20107-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04812-persistence-of-anti-vaccine-sentiment-in-social-networks-through-strategic-interactions/",
        "doi": "10.1609/aaai.v35i6.16613",
        "pdf_size": 253327
    },
    {
        "id": "10772",
        "title": "Personalized Adaptive Meta Learning for Cold-start User Preference Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "A common challenge in personalized user preference prediction is the cold-start problem. Due to the lack of user-item interactions, directly learning from the new users' log data causes serious over-fitting problem. Recently, many existing studies regard the cold-start personalized preference prediction as a few-shot learning problem, where each user is the task and recommended items are the classes, and the gradient-based meta learning method (MAML) is leveraged to address this challenge. However, in real-world application, the users are not uniformly distributed (i.e., different users may have different browsing history, recommended items, and user profiles. We define the major users as the users in the groups with large numbers of users sharing similar user information, and other users are the minor users), existing MAML approaches tend to fit the major users and ignore the minor users. To address the task-overfitting problem, we propose a novel personalized adaptive meta learning approach to consider both the major and the minor users with three key contributions: 1) We are the first to present a personalized adaptive learning rate meta-learning approach to improve the performance of MAML by focusing on both the major and minor users. 2) To provide better personalized learning rates for each user, we introduce a similarity-based method to find similar users as a reference and a tree-based method to store users' features for fast search. 3) To reduce the memory usage, we design a memory agnostic regularizer to further reduce the space complexity to constant while maintain the performance. Experiments on MovieLens, BookCrossing, and real-world production datasets reveal that our method outperforms the state-of-the-art methods dramatically for both the minor and major users.",
        "primary_area": "Machine Learning V",
        "author": "Runsheng Yu; Yu Gong; Xu He; Yu Zhu; Qingwen Liu; Wenwu Ou; Bo An",
        "authorids": "",
        "aff": "Nanyang Technological University; Alibaba Group; Nanyang Technological University; Alibaba Group; Alibaba Group; Alibaba Group; Nanyang Technological University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17287/17287-13-20781-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10772-personalized-adaptive-meta-learning-for-cold-start-user-preference-prediction/",
        "doi": "10.1609/aaai.v35i12.17287",
        "pdf_size": 484625
    },
    {
        "id": "07865",
        "title": "Personalized Cross-Silo Federated Learning on Non-IID Data",
        "track": "main",
        "status": "Poster",
        "abstract": "Non-IID data present a tough challenge for federated learning. In this paper, we explore a novel idea of facilitating pairwise collaborations between clients with similar data. We propose FedAMP, a new method employing federated attentive message passing to facilitate similar clients to collaborate more. We establish the convergence of FedAMP for both convex and non-convex models, and propose a heuristic method to further improve the performance of FedAMP when clients adopt deep neural networks as personalized models. Our extensive experiments on benchmark data sets demonstrate the superior performance of the proposed methods.",
        "primary_area": "Machine Learning II",
        "author": "Yutao Huang; Lingyang Chu; Zirui Zhou; Lanjun Wang; Jiangchuan Liu; Jian Pei; Yong Zhang",
        "authorids": "",
        "aff": "Simon Fraser University, Burnaby, Canada; McMaster University, Hamilton, Canada; Huawei Technologies Canada, Burnaby, Canada; Huawei Technologies Canada, Burnaby, Canada; Simon Fraser University, Burnaby, Canada; Simon Fraser University, Burnaby, Canada; Huawei Technologies Canada, Burnaby, Canada",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16960/16960-13-20454-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07865-personalized-cross-silo-federated-learning-on-non-iid-data/",
        "doi": "10.1609/aaai.v35i9.16960",
        "pdf_size": 344208
    },
    {
        "id": "05244",
        "title": "Persuading Voters in District-based Elections",
        "track": "main",
        "status": "Poster",
        "abstract": "We focus on the scenario in which an agent can exploit his information advantage to manipulate the outcome of an election. In particular, we study district-based elections with two candidates, in which the winner of the election is the candidate that wins in the majority of the districts. District-based elections are adopted worldwide (e.g., UK and USA) and are a natural extension of widely studied voting mechanisms (e.g., k-voting and plurality voting). We resort to the Bayesian persuasion framework, where the manipulator (sender) strategically discloses information to the voters (receivers) that update their beliefs rationally. We study both private signaling in which the sender can use a private communication channel per receiver and public signaling in which the sender can use a single communication channel for all the receivers. Furthermore, for the first time, we introduce semi-public signaling in which the sender can use a single communication channel per district. We show that there is a sharp distinction between private and (semi-)public signaling. In particular, optimal private signaling schemes can provide an arbitrarily better probability of victory than (semi-)public ones and can be computed efficiently, while optimal (semi-)public signaling schemes cannot be approximated to within any factor in polynomial time unless P=NP. However, we show that reasonable relaxations allow the design of multi-criteria PTASs for optimal (semi-)public signaling schemes. In doing so, we introduce a novel property, namely comparative stability, and we design a bi-criteria PTAS for public signaling in general Bayesian persuasion problems beyond elections when the sender's utility function is state-dependent.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Matteo Castiglioni; Nicola Gatti",
        "authorids": "",
        "aff": "Politecnico di Milano; Politecnico di Milano",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16662/16662-13-20156-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05244-persuading-voters-in-district-based-elections/",
        "doi": "10.1609/aaai.v35i6.16662",
        "pdf_size": 180052
    },
    {
        "id": "08939",
        "title": "Physarum Powered Differentiable Linear Programming Layers and Applications",
        "track": "main",
        "status": "Poster",
        "abstract": "Consider a learning algorithm, which involves an internal call to an optimization routine such as a generalized eigenvalue problem, a cone programming problem or even sorting. Integrating such a method as layers within a trainable deep network in a numerically stable way is not simple \u2013 for instance, only recently, strategies have emerged for eigendecomposition and differentiable sorting. We propose an efficient and differentiable solver for general linear programming problems which can be used in a plug and play manner within deep neural networks as a layer. Our development is inspired by a fascinating but not widely used link between dynamics of slime mold (physarum) and mathematical optimization schemes such as steepest descent. We describe our development and demonstrate the use of our solver in a video object segmentation task and meta-learning for few-shot learning. We review the relevant known results and provide a technical analysis describing its applicability for our use cases. Our solver performs comparably with a customized projected gradient descent method on the first task and outperforms the very recently proposed differentiable CVXPY solver on the second task. Experiments show that our solver converges quickly without the need for a feasible initial point. Interestingly, our scheme is easy to implement and can easily serve as layers whenever a learning procedure needs a fast approximate solution to a LP, within a larger network.",
        "primary_area": "Machine Learning III",
        "author": "Zihang Meng; Sathya N. Ravi; Vikas Singh",
        "authorids": "",
        "aff": "University of Wisconsin Madison; University of Illinois at Chicago; University of Wisconsin Madison",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17081/17081-13-20575-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08939-physarum-powered-differentiable-linear-programming-layers-and-applications/",
        "doi": "10.1609/aaai.v35i10.17081",
        "pdf_size": 1131685
    },
    {
        "id": "00540",
        "title": "Physics-Informed Deep Learning for Traffic State Estimation: A Hybrid Paradigm Informed By Second-Order Traffic Models",
        "track": "main",
        "status": "Poster",
        "abstract": "Traffic state estimation (TSE) reconstructs the traffic variables (e.g., density or average velocity) on road segments using partially observed data, which is important for traffic managements. Traditional TSE approaches mainly bifurcate into two categories: model-driven and data-driven, and each of them has shortcomings. To mitigate these limitations, hybrid TSE methods, which combine both model-driven and data-driven, are becoming a promising solution. This paper introduces a hybrid framework, physics-informed deep learning (PIDL), to combine second-order traffic flow models and neural networks to solve the TSE problem. PIDL can encode traffic flow models into deep neural networks to regularize the learning process to achieve improved data efficiency and estimation accuracy. We focus on highway TSE with observed data from loop detectors and probe vehicles, using both density and average velocity as the traffic variables. With numerical examples, we show the use of PIDL to solve a popular second-order traffic flow model, i.e., a Greenshields-based Aw-Rascle-Zhang (ARZ) model, and discover the model parameters. We then evaluate the PIDL-based TSE method using the Next Generation SIMulation (NGSIM) dataset. Experimental results demonstrate the proposed PIDL-based approach to outperform advanced baseline methods in terms of data efficiency and estimation accuracy.",
        "primary_area": "Application Domains",
        "author": "Rongye Shi; Zhaobin Mo; Xuan Di",
        "authorids": "",
        "aff": "Columbia University; Columbia University; Columbia University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16132/16132-13-19626-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00540-physics-informed-deep-learning-for-traffic-state-estimation-a-hybrid-paradigm-informed-by-second-order-traffic-models/",
        "doi": "10.1609/aaai.v35i1.16132",
        "pdf_size": 827590
    },
    {
        "id": "10414",
        "title": "Physics-constrained Automatic Feature Engineering for Predictive Modeling in Materials Science",
        "track": "main",
        "status": "Poster",
        "abstract": "Automatic Feature Engineering (AFE) aims to extract useful knowledge for interpretable predictions given data for the machine learning tasks. Here, we develop AFE to extract dependency relationships that can be interpreted with functional formulas to discover physics meaning or new hypotheses for the problems of interest. We focus on materials science applications, where interpretable predictive modeling may provide principled understanding of materials systems and guide new materials discovery. It is often computationally prohibitive to exhaust all the potential relationships to construct and search the whole feature space to identify interpretable and predictive features. We develop and evaluate new AFE strategies by exploring a feature generation tree (FGT) with deep Q-network (DQN) for scalable and efficient exploration policies. The developed DQN-based AFE strategies are benchmarked with the existing AFE methods on several materials science datasets.",
        "primary_area": "Machine Learning V",
        "author": "Ziyu Xiang; Mingzhou Fan; Guillermo V\u00e1zquez Tovar; William Trehern; Byung-Jun Yoon; Xiaofeng Qian; Raymundo Arroyave; Xiaoning Qian",
        "authorids": "",
        "aff": "Texas A&M University; Texas A&M University; Texas A&M University; Texas A&M University; Texas A&M University Brookhaven National Laboratory; Texas A&M University; Texas A&M University; Texas A&M University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17247/17247-13-20741-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10414-physics-constrained-automatic-feature-engineering-for-predictive-modeling-in-materials-science/",
        "doi": "10.1609/aaai.v35i12.17247",
        "pdf_size": 172110
    },
    {
        "id": "04941",
        "title": "Planning from Pixels in Atari with Learned Symbolic Representations",
        "track": "main",
        "status": "Poster",
        "abstract": "Width-based planning methods have been shown to yield state-of-the-art performance in the Atari 2600 domain using pixel input. One successful approach, RolloutIW, represents states with the B-PROST boolean feature set. An augmented version of RolloutIW, pi-IW, shows that learned features can be competitive with handcrafted ones for width-based search. In this paper, we leverage variational autoencoders (VAEs) to learn features directly from pixels in a principled manner, and without supervision. The inference model of the trained VAEs extracts boolean features from pixels, and RolloutIW plans with these features. The resulting combination outperforms the original RolloutIW and human professional play on Atari 2600 and drastically reduces the size of the feature set.",
        "primary_area": "Neuro-Symbolic AI",
        "author": "Andrea Dittadi; Frederik K. Drachmann; Thomas Bolander",
        "authorids": "",
        "aff": "Technical University of Denmark; Technical University of Denmark; Technical University of Denmark",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16627/16627-13-20121-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04941-planning-from-pixels-in-atari-with-learned-symbolic-representations/",
        "doi": "10.1609/aaai.v35i6.16627",
        "pdf_size": 816425
    },
    {
        "id": "11962",
        "title": "Planning with Learned Object Importance in Large Problem Instances using Graph Neural Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Real-world planning problems often involve hundreds or even thousands of objects, straining the limits of modern planners. In this work, we address this challenge by learning to predict a small set of objects that, taken together, would be sufficient for finding a plan. We propose a graph neural network architecture for predicting object importance in a single inference pass, thus incurring little overhead while greatly reducing the number of objects that must be considered by the planner. Our approach treats the planner and transition model as black boxes, and can be used with any off-the-shelf planner. Empirically, across classical planning, probabilistic planning, and robotic task and motion planning, we find that our method results in planning that is significantly faster than several baselines, including other partial grounding strategies and lifted planners. We conclude that learning to predict a sufficient set of objects for a planning problem is a simple, powerful, and general mechanism for planning in large instances. Video: https://youtu.be/FWsVJc2fvCE Code: https://git.io/JIsqX",
        "primary_area": "Planning, Routing, and Scheduling",
        "author": "Tom Silver; Rohan Chitnis; Aidan Curtis; Joshua B. Tenenbaum; Tom\u00e1s Lozano-P\u00e9rez; Leslie Pack Kaelbling",
        "authorids": "",
        "aff": "Massachusetts Institute of Technology; Massachusetts Institute of Technology; Massachusetts Institute of Technology; Massachusetts Institute of Technology; Massachusetts Institute of Technology; Massachusetts Institute of Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17421/17421-13-20915-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11962-planning-with-learned-object-importance-in-large-problem-instances-using-graph-neural-networks/",
        "doi": "10.1609/aaai.v35i13.17421",
        "pdf_size": 1792119
    },
    {
        "id": "00863",
        "title": "Plug-and-Play Domain Adaptation for Cross-Subject EEG-based Emotion Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "Human emotion decoding in affective brain-computer interfaces suffers a major setback due to the inter-subject variability of electroencephalography (EEG) signals. Existing approaches usually require amassing extensive EEG data of each new subject, which is prohibitively time-consuming along with poor user experience. To tackle this issue, we divide EEG representations into private components specific to each subject and shared emotional components that are universal to all subjects. According to this representation partition, we propose a plug-and-play domain adaptation method for dealing with the inter-subject variability. In the training phase, subject-invariant emotional representations and private components of source subjects are separately captured by a shared encoder and private encoders. Furthermore, we build one emotion classifier on the shared partition and subjects' individual classifiers on the combination of these two partitions. In the calibration phase, the model only requires few unlabeled EEG data from incoming target subjects to model their private components. Therefore, besides the shared emotion classifier, we have another pipeline to use the knowledge of source subjects through the similarity of private components. In the test phase, we integrate predictions of the shared emotion classifier with those of individual classifiers ensemble after modulation by similarity weights. Experimental results on the SEED dataset show that our model greatly shortens the calibration time within a minute while maintaining the recognition accuracy, all of which make emotion decoding more generalizable and practicable.",
        "primary_area": "Cognitive Modeling and Cognitive Systems",
        "author": "Li-Ming Zhao; Xu Yan; Bao-Liang Lu",
        "authorids": "",
        "aff": "Shanghai Jiao Tong University; University of Washington; Shanghai Jiao Tong University Ruijin Hospital, Shanghai Jiao Tong University School of Medicine",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16169/16169-13-19663-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00863-plug-and-play-domain-adaptation-for-cross-subject-eeg-based-emotion-recognition/",
        "doi": "10.1609/aaai.v35i1.16169",
        "pdf_size": 1320667
    },
    {
        "id": "05321",
        "title": "PoA of Simple Auctions with Interdependent Values",
        "track": "main",
        "status": "Poster",
        "abstract": "We expand the literature on the price of anarchy (PoA) of simultaneous item auctions by considering settings with correlated values; we do this via the fundamental economic model of interdependent values (IDV).  It is well-known that in multi-item settings with private values, correlated values can lead to bad PoA, which can be polynomially large in the number of agents~n.  In the more general model of IDV, we show that the PoA can be polynomially large even in single-item settings.  On the positive side, we identify a natural condition on information dispersion in the market, which enables good PoA guarantees.   Under this condition, we show that for single-item settings, the PoA of standard mechanisms degrades gracefully.  For settings with multiple items we show a separation between two domains:   If there are more buyers, we devise a new simultaneous item auction with good PoA, under limited information asymmetry.  To the best of our knowledge, this is the first positive PoA result for correlated values in multi-item settings.  The main technical difficulty in establishing this result is that the standard tool for establishing PoA results --- the smoothness framework --- is unsuitable for IDV settings, and so we must introduce new techniques to address the unique challenges imposed by such settings.  In the domain of more items, we establish impossibility results even for surprisingly simple scenarios.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Alon Eden; Michal Feldman; Inbal Talgam-Cohen; Ori Zviran",
        "authorids": "",
        "aff": "Harvard University; Tel-Aviv University; Technion; Tel Aviv University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16671/16671-13-20165-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05321-poa-of-simple-auctions-with-interdependent-values/",
        "doi": "10.1609/aaai.v35i6.16671",
        "pdf_size": 183002
    },
    {
        "id": "03385",
        "title": "Point Cloud Semantic Scene Completion from RGB-D Images",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we devise a novel semantic completion network, called point cloud semantic scene completion network (PCSSC-Net), for indoor scenes solely based on point clouds. Existing point cloud completion networks still suffer from their inability of fully recovering complex structures and contents from global geometric descriptions neglecting semantic hints. To extract and infer comprehensive information from partial input, we design a patch-based contextual encoder to hierarchically learn point-level, patch-level, and scene-level geometric and contextual semantic information with a divide-and-conquer strategy. Consider that the scene semantics afford a high-level clue of constituting geometry for an indoor scene environment, we articulate a semantics-guided completion decoder where semantics could help cluster isolated points in the latent space and infer complicated scene geometry. Given the fact that real-world scans tend to be incomplete as ground truth, we choose to synthesize scene dataset with RGB-D images and annotate complete point clouds as ground truth for the supervised training purpose. Extensive experiments validate that our new method achieves the state-of-the-art performance, in contrast with the current methods applied to our dataset.",
        "primary_area": "Computer Vision III",
        "author": "Shoulong Zhang; Shuai Li; Aimin Hao; Hong Qin",
        "authorids": "",
        "aff": "Beihang University, Beijing, China; Beihang University, Beijing, China Peng Cheng Laboratory, Shenzhen, China; Beihang University, Beijing, China Peng Cheng Laboratory, Shenzhen, China; Stony Brook University (SUNY), Stony Brook, USA",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16451/16451-13-19945-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03385-point-cloud-semantic-scene-completion-from-rgb-d-images/",
        "doi": "10.1609/aaai.v35i4.16451",
        "pdf_size": 3449539
    },
    {
        "id": "02251",
        "title": "PointINet: Point Cloud Frame Interpolation Network",
        "track": "main",
        "status": "Poster",
        "abstract": "LiDAR point cloud streams are usually sparse in time dimension, which is limited by hardware performance. Generally, the frame rates of  mechanical LiDAR sensors are 10 to 20 Hz, which is much lower than other commonly used sensors like cameras. To overcome the temporal limitations of LiDAR sensors, a novel task named Point Cloud Frame Interpolation is studied in this paper. Given two consecutive point cloud frames, Point Cloud Frame Interpolation aims to generate intermediate frame(s) between them. To achieve that, we propose a novel framework, namely Point Cloud Frame Interpolation Network (PointINet). Based on the proposed method, the low frame rate point cloud streams can be upsampled to higher frame rates. We start by estimating bi-directional 3D scene flow between the two point clouds and then warp them to the given time step based on the 3D scene flow. To fuse the two warped frames and generate intermediate point cloud(s), we propose a novel learning-based points fusion module, which simultaneously takes two warped point clouds into consideration. We design both quantitative and qualitative experiments to evaluate the performance of the point cloud frame interpolation method and extensive experiments on two large scale outdoor LiDAR datasets demonstrate the effectiveness of the proposed PointINet. Our code is available at https://github.com/ispc-lab/PointINet.git.",
        "primary_area": "Computer Vision II",
        "author": "Fan Lu; Guang Chen; Sanqing Qu; Zhijun Li; Yinlong Liu; Alois Knoll",
        "authorids": "",
        "aff": "Tongji University; Tongji University; Tongji University; University of Science and Technology of China; Technische Universit\u00e4t M\u00fcnchen; Technische Universit\u00e4t M\u00fcnchen",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16324/16324-13-19818-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02251-pointinet-point-cloud-frame-interpolation-network/",
        "doi": "10.1609/aaai.v35i3.16324",
        "pdf_size": 1510661
    },
    {
        "id": "08958",
        "title": "Policy Optimization as Online Learning with Mediator Feedback",
        "track": "main",
        "status": "Poster",
        "abstract": "Policy Optimization (PO) is a widely used approach to address continuous control tasks. In this paper, we introduce the notion of mediator feedback that frames PO as an online learning problem over the policy space. The additional available information, compared to the standard bandit feedback, allows reusing samples generated by one policy to estimate the performance of other policies. Based on this observation, we propose an algorithm, RANDomized-exploration policy Optimization via Multiple Importance Sampling with Truncation (RANDOMIST), for regret minimization in PO, that employs a randomized exploration strategy, differently from the existing optimistic approaches. When the policy space is finite, we show that under certain circumstances, it is possible to achieve constant regret, while always enjoying logarithmic regret. We also derive problem-dependent regret lower bounds. Then, we extend RANDOMIST to compact policy spaces. Finally, we provide numerical simulations on finite and compact policy spaces, in comparison with PO and bandit baselines.",
        "primary_area": "Machine Learning III",
        "author": "Alberto Maria Metelli; Matteo Papini; Pierluca D'Oro; Marcello Restelli",
        "authorids": "",
        "aff": "Politecnico di Milano; Politecnico di Milano; Politecnico di Milano; Politecnico di Milano",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17083/17083-13-20577-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08958-policy-optimization-as-online-learning-with-mediator-feedback/",
        "doi": "10.1609/aaai.v35i10.17083",
        "pdf_size": 360724
    },
    {
        "id": "12382",
        "title": "Policy-Guided Heuristic Search with Guarantees",
        "track": "main",
        "status": "Poster",
        "abstract": "The use of a policy and a heuristic function for guiding search can be quite effective in adversarial problems, as demonstrated by AlphaGo and its successors, which are  based on the PUCT search algorithm.  While PUCT can also be used to solve single-agent deterministic problems,  it lacks guarantees on its search effort and it can be computationally inefficient in practice.   Combining the A* algorithm with a learned heuristic function  tends to work better in these domains, but A* and its variants do not use a policy. Moreover, the purpose of using A* is to find solutions of minimum cost,  while we seek instead to minimize the search loss (e.g., the number of search steps). LevinTS is guided by a policy and provides guarantees on the number of search steps that relate to the quality of the policy, but it does not make use of a heuristic function. In this work we introduce Policy-guided Heuristic Search (PHS), a novel search algorithm that uses both a heuristic function and a policy and has theoretical guarantees on the search loss that relates to both the quality of the heuristic and of the policy. We show empirically on the sliding-tile puzzle, Sokoban, and a puzzle from the commercial game `The Witness' that PHS enables the rapid learning of both a policy and a heuristic function and compares favorably with A*, Weighted A*, Greedy Best-First Search, LevinTS, and PUCT in terms of number of problems solved and search time in all three domains tested.",
        "primary_area": "Search and Optimization",
        "author": "Laurent Orseau; Levi H. S. Lelis",
        "authorids": "",
        "aff": "DeepMind; University of Alberta",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17469/17469-13-20963-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12382-policy-guided-heuristic-search-with-guarantees/",
        "doi": "10.1609/aaai.v35i14.17469",
        "pdf_size": 289913
    },
    {
        "id": "12198",
        "title": "Polynomial-Time Algorithms for Counting and Sampling Markov Equivalent DAGs",
        "track": "main",
        "status": "Poster",
        "abstract": "Counting and uniform sampling of directed acyclic graphs (DAGs) from a Markov equivalence class are fundamental tasks in graphical causal analysis. In this paper, we show that these tasks can be performed in polynomial time, solving a long-standing open problem in this area. Our algorithms are effective and easily implementable. Experimental results show that the algorithms significantly outperform state-of-the-art methods.",
        "primary_area": "Reasoning under Uncertainty",
        "author": "Marcel Wien\u00f6bst; Max Bannach; Maciej Liskiewicz",
        "authorids": "",
        "aff": "Universit\u00e4t of L\u00fcbeck; Universit\u00e4t of L\u00fcbeck; Universit\u00e4t of L\u00fcbeck",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17448/17448-13-20942-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12198-polynomial-time-algorithms-for-counting-and-sampling-markov-equivalent-dags/",
        "doi": "10.1609/aaai.v35i13.17448",
        "pdf_size": 228382
    },
    {
        "id": "08217",
        "title": "Positions, Channels, and Layers: Fully Generalized Non-Local Network for Singer Identification",
        "track": "main",
        "status": "Poster",
        "abstract": "Recently, a non-local (NL) operation has been designed as the central building block for deep-net models to capture long-range dependencies (Wang et al. 2018). Despite its excellent performance, it does not consider the interaction between positions across channels and layers, which is crucial in fine-grained classification tasks. To address the limitation, we target at singer identification (SID) task and present a fully generalized non-local (FGNL) module to help identify fine-grained vocals. Specifically, we first propose a FGNL operation, which extends the NL operation to explore the correlations between positions across channels and layers. Secondly, we further apply a depth-wise convolution with Gaussian kernel in the FGNL operation to smooth feature maps for better generalization. More, we modify the squeeze-and-excitation (SE) scheme into the FGNL module to adaptively emphasize correlated feature channels to help uncover relevant feature responses and eventually the target singer. Evaluating results on the benchmark artist20 dataset shows that the FGNL module significantly improves the accuracy of the deep-net models in SID. Codes are available at https://github.com/ian-k-1217/Fully-Generalized-Non-Local-Network.",
        "primary_area": "Machine Learning II",
        "author": "I-Yuan Kuo; Wen-Li Wei; Jen-Chun  Lin",
        "authorids": "",
        "aff": "Academia Sinica, Taiwan; Academia Sinica, Taiwan; Academia Sinica, Taiwan",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17000/17000-13-20494-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08217-positions-channels-and-layers-fully-generalized-non-local-network-for-singer-identification/",
        "doi": "10.1609/aaai.v35i9.17000",
        "pdf_size": 3432399
    },
    {
        "id": "08697",
        "title": "Post-training Quantization with Multiple Points: Mixed Precision without Mixed Precision",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider the post-training quantization problem, which discretizes the weights of pre-trained deep neural networks without re-training the model. We propose multipoint quantization, a quantization method that approximates a full-precision weight vector using a linear combination of multiple vectors of low-bit numbers;  this is in contrast to typical quantization methods that approximate each weight using a single low precision number.  Computationally, we construct the multipoint quantization with an efficient greedy selection procedure, and adaptively decides the number of low precision points on each quantized weight vector based on the error of its output.   This allows us to achieve higher precision levels for important weights that greatly influence the outputs, yielding an ``effect of mixed precision'' but without physical mixed precision implementations  (which requires specialized hardware accelerators).  Empirically, our method can be implemented by common operands, bringing almost no memory and computation overhead. We show that our method outperforms a range of state-of-the-art methods on ImageNet classification and it can be generalized to more challenging tasks like PASCAL VOC object detection.",
        "primary_area": "Machine Learning III",
        "author": "Xingchao Liu; Mao Ye; Dengyong Zhou; Qiang Liu",
        "authorids": "",
        "aff": "University of Texas at Austin; University of Texas at Austin; Google Brain; University of Texas at Austin",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17054/17054-13-20548-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08697-post-training-quantization-with-multiple-points-mixed-precision-without-mixed-precision/",
        "doi": "10.1609/aaai.v35i10.17054",
        "pdf_size": 218768
    },
    {
        "id": "05822",
        "title": "Power in Liquid Democracy",
        "track": "main",
        "status": "Poster",
        "abstract": "The paper develops a theory of power for delegable proxy voting systems. We define a power index able to measure the influence of both voters and delegators. Using this index, which we characterize axiomatically, we extend an earlier game-theoretic model by incorporating power-seeking behavior by agents. We analytically study the existence of pure strategy Nash equilibria in such a model. Finally, by means of simulations, we study the effect of several parameters on the emergence of power inequalities in the model.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Yuzhe Zhang; Davide Grossi",
        "authorids": "",
        "aff": "University of Groningen; University of Groningen University of Amsterdam",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16729/16729-13-20223-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05822-power-in-liquid-democracy/",
        "doi": "10.1609/aaai.v35i6.16729",
        "pdf_size": 281609
    },
    {
        "id": "08004",
        "title": "Power up! Robust Graph Convolutional Network via Graph Powering",
        "track": "main",
        "status": "Poster",
        "abstract": "Graph convolutional networks (GCNs) are powerful tools for graph-structured data. However, they have been recently shown to be vulnerable to topological attacks. To enhance adversarial robustness, we go beyond spectral graph theory to robust graph theory. By challenging the classical graph Laplacian, we propose a new convolution operator that is provably robust in the spectral domain and is incorporated in the GCN architecture to improve expressivity and interpretability. By extending the original graph to a sequence of graphs, we also propose a robust training paradigm that encourages transferability across graphs that span a range of spatial and spectral characteristics. The proposed approaches are demonstrated in extensive experiments to simultaneously improve performance  in both benign and adversarial situations.",
        "primary_area": "Machine Learning II",
        "author": "Ming Jin; Heng Chang; Wenwu Zhu; Somayeh Sojoudi",
        "authorids": "",
        "aff": "Virginia Tech; Tsinghua University; Tsinghua University; University of California at Berkeley",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16976/16976-13-20470-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08004-power-up-robust-graph-convolutional-network-via-graph-powering/",
        "doi": "10.1609/aaai.v35i9.16976",
        "pdf_size": 470365
    },
    {
        "id": "07439",
        "title": "Practical and Rigorous Uncertainty Bounds for Gaussian Process Regression",
        "track": "main",
        "status": "Poster",
        "abstract": "Gaussian Process regression is a popular nonparametric regression method based on Bayesian principles that provides uncertainty estimates for its predictions. However, these estimates are of a Bayesian nature, whereas for some important applications, like learning-based control with safety guarantees, frequentist uncertainty bounds are required. Although such rigorous bounds are available for Gaussian Processes, they are too conservative to be useful in applications. This often leads practitioners to replacing these bounds by heuristics, thus breaking all theoretical guarantees. To address this problem, we introduce new uncertainty bounds that are rigorous, yet practically useful at the same time. In particular, the bounds can be explicitly evaluated and are much less conservative than state of the art results. Furthermore, we show that certain model misspecifications lead to only graceful degradation. We demonstrate these advantages and the usefulness of our results for learning-based control with numerical examples.",
        "primary_area": "Machine Learning I",
        "author": "Christian Fiedler; Carsten W. Scherer; Sebastian Trimpe",
        "authorids": "",
        "aff": "Institute for Data Science in Mechanical Engineering, RWTH Aachen University Intelligent Control Systems Group, Max Planck Institute for Intelligent Systems Department of Mathematics, University of Stuttgart; Department of Mathematics, University of Stuttgart; Institute for Data Science in Mechanical Engineering, RWTH Aachen University Intelligent Control Systems Group, Max Planck Institute for Intelligent Systems",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16912/16912-13-20406-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07439-practical-and-rigorous-uncertainty-bounds-for-gaussian-process-regression/",
        "doi": "10.1609/aaai.v35i8.16912",
        "pdf_size": 2932576
    },
    {
        "id": "00445",
        "title": "Pragmatic Code Autocomplete",
        "track": "main",
        "status": "Poster",
        "abstract": "Human language is ambiguous, with intended meanings recovered via pragmatic reasoning in context. Such reliance on context is essential for the efficiency of human communication. Programming languages, in stark contrast, are defined by unambiguous grammars. In this work, we aim to make programming languages more concise by allowing programmers to utilize a controlled level of ambiguity. Specifically, we allow single-character abbreviations for common keywords and identifiers. Our system first proposes a set of strings that can be abbreviated by the user. Using only 100 abbreviations, we observe that a large dataset of Python code can be compressed by 15%, a number that can be improved even further by specializing the abbreviations to a particular code base. We then use a contextualized sequence-to-sequence model to rank potential expansions of inputs that include abbreviations. In an offline reconstruction task our model achieves accuracies ranging from 93% to 99%, depending on the programming language and user settings. The model is small enough to run on a commodity CPU in real-time. We evaluate the usability of our system in a user study, integrating it in Microsoft VSCode, a popular code text editor. We observe that our system performs well and is complementary to traditional autocomplete features.",
        "primary_area": "Application Domains",
        "author": "Gabriel Poesia; Noah Goodman",
        "authorids": "",
        "aff": "Stanford University; Stanford University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16121/16121-13-19615-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00445-pragmatic-code-autocomplete/",
        "doi": "10.1609/aaai.v35i1.16121",
        "pdf_size": 427341
    },
    {
        "id": "04241",
        "title": "Pre-training Context and Time Aware Location Embeddings from Spatial-Temporal Trajectories for User Next Location Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "Pre-training location embeddings from spatial-temporal trajectories is a fundamental procedure and very beneficial for user next location prediction. In the real world, a location usually has variable functionalities under different contextual environments. If the exact functions of a location in the trajectory can be reflected in its embedding, the accuracy of user next location prediction should be improved. Yet, existing location embeddings pre-trained on trajectories are mostly based on distributed word representations, which mix a location's various functionalities into one latent representation vector. To address this problem, we propose a Context and Time aware Location Embedding (CTLE) model, which calculates a location's representation vector with consideration of its specific contextual neighbors in trajectories. In this way, the multi-functional properties of locations can be properly tackled. Furthermore, in order to incorporate temporal information in trajectories into location embeddings, we propose a subtle temporal encoding module and a novel pre-training objective, which further improve the quality of location embeddings. We evaluate our proposed model on two real-world mobile user trajectory datasets. The experimental results demonstrate that, compared with the existing embedding methods, our CTLE model can pre-train higher quality location embeddings and significantly improve the performance of downstream user location prediction models.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Yan Lin; Huaiyu Wan; Shengnan Guo; Youfang Lin",
        "authorids": "",
        "aff": "School of Computer and Information Technology, Beijing Jiaotong University, Beijing, China Beijing Key Laboratory of Traffic Data Analysis and Mining, Beijing, China; School of Computer and Information Technology, Beijing Jiaotong University, Beijing, China Beijing Key Laboratory of Traffic Data Analysis and Mining, Beijing, China CAAC Key Laboratory of Intelligent Passenger Service of Civil Aviation, Beijing, China; School of Computer and Information Technology, Beijing Jiaotong University, Beijing, China Beijing Key Laboratory of Traffic Data Analysis and Mining, Beijing, China Key Laboratory of Transport Industry of Big Data Appalication Technologies for Comprehensive Transport, Beijing, China; School of Computer and Information Technology, Beijing Jiaotong University, Beijing, China Beijing Key Laboratory of Traffic Data Analysis and Mining, Beijing, China CAAC Key Laboratory of Intelligent Passenger Service of Civil Aviation, Beijing, China Key Laboratory of Transport Industry of Big Data Appalication Technologies for Comprehensive Transport, Beijing, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16548/16548-13-20042-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04241-pre-training-context-and-time-aware-location-embeddings-from-spatial-temporal-trajectories-for-user-next-location-prediction/",
        "doi": "10.1609/aaai.v35i5.16548",
        "pdf_size": 351095
    },
    {
        "id": "02916",
        "title": "Precise Yet Efficient Semantic Calibration and Refinement in ConvNets for Real-time Polyp Segmentation from Colonoscopy Videos",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a novel convolutional neural network (ConvNet) equipped with two new semantic calibration and refinement approaches for automatic polyp segmentation from colonoscopy videos. While ConvNets set state-of-the-are performance for this task, it is still difficult to achieve satisfactory results in a real-time manner, which is a necessity in clinical practice. The main obstacle is the huge semantic gap between high-level features and low-level features, making it difficult to take full advantage of complementary semantic information contained in these hierarchical features. Compared with existing solutions, which either directly aggregate these features without considering the semantic gap or employ sophisticated non-local modeling techniques to refine semantic information by introduce many extra computational costs, the proposed ConvNet is able to more precisely yet efficiently calibrate and refine semantic information for better segmentation performance without increasing model complexity; we call the proposed ConvNet as SCR-Net, which has two key modules. We first propose a semantic calibration module (SCM) to effectively transmit the semantic information from high-level layers to low-level layers by learning the semantic-spatial relations during the training procedure. We then propose a semantic refinement module (SRM) to, based on the features calibrated by SCM, enhance the discrimination capability of the features for targeting objects. Extensive experiments on the Kvasir-SEG dataset demonstrate that the proposed SCR-Net is capable of achieving better segmentation accuracy than state-of-the-art approaches with a faster speed. The proposed techniques are general enough to be applied to similar applications where precise and efficient multi-level feature fusion is critical. The code is available at https://github.com/jiafuz/SCR-Net.",
        "primary_area": "Computer Vision III",
        "author": "Huisi Wu; Jiafu Zhong; Wei Wang; Zhenkun Wen; Jing Qin",
        "authorids": "",
        "aff": "Shenzhen University; Shenzhen University; Shenzhen University; Shenzhen University; The Hong Kong Polytechnic University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16398/16398-13-19892-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02916-precise-yet-efficient-semantic-calibration-and-refinement-in-convnets-for-real-time-polyp-segmentation-from-colonoscopy-videos/",
        "doi": "10.1609/aaai.v35i4.16398",
        "pdf_size": 2423254
    },
    {
        "id": "09153",
        "title": "Precision-based Boosting",
        "track": "main",
        "status": "Poster",
        "abstract": "AdaBoost is a highly popular ensemble classification method for which many variants have been published. This paper proposes a generic refinement of all of these AdaBoost variants. Instead of assigning weights based on the total error of the base classifiers (as in AdaBoost), our method uses class-specific error rates. On instance x it assigns a higher weight to a classifier predicting label y on x, if that classifier is less likely to make a mistake when it predicts class y. Like AdaBoost, our method is guaranteed to boost weak learners into strong learners. An empirical study on AdaBoost and one of its multi-class versions, SAMME, demonstrates the superiority of our method on datasets with more than 1,000 instances as well as on datasets with more than three classes.",
        "primary_area": "Machine Learning III",
        "author": "Mohammad Hossein Nikravan; Marjan Movahedan; Sandra Zilles",
        "authorids": "",
        "aff": "University of Regina; University of Regina; University of Regina",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17105/17105-13-20599-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09153-precision-based-boosting/",
        "doi": "10.1609/aaai.v35i10.17105",
        "pdf_size": 137617
    },
    {
        "id": "00268",
        "title": "Predicting Livelihood Indicators from Community-Generated Street-Level Imagery",
        "track": "main",
        "status": "Poster",
        "abstract": "Major decisions from governments and other large organizations rely on measurements of the populace's well-being, but making such measurements at a broad scale is expensive and thus infrequent in much of the developing world. We propose an inexpensive, scalable, and interpretable approach to predict key livelihood indicators from public crowd-sourced street-level imagery. Such imagery can be cheaply collected and more frequently updated compared to traditional surveying methods, while containing plausibly relevant information for a range of livelihood indicators. We propose two approaches to learn from the street-level imagery: (1) a method that creates multi-household cluster representations by detecting informative objects and (2) a graph-based approach that captures the relationships between images. By visualizing what features are important to a model and how they are used, we can help end-user organizations understand the models and offer an alternate approach for index estimation that uses cheaply obtained roadway features. By comparing our results against ground data collected in nationally-representative household surveys, we demonstrate the performance of our approach in accurately predicting indicators of poverty, population, and health and its scalability by testing in two different countries, India and Kenya.  Our code is available at https://github.com/sustainlab-group/mapillarygcn.",
        "primary_area": "Application Domains",
        "author": "Jihyeon Lee; Dylan Grosz; Burak Uzkent; Sicheng Zeng; Marshall Burke; David Lobell; Stefano Ermon",
        "authorids": "",
        "aff": "Department of Computer Science, Stanford University; Department of Computer Science, Stanford University; Department of Computer Science, Stanford University; Department of Computer Science, Stanford University; Department of Earth Science, Stanford University; Department of Earth Science, Stanford University; Department of Computer Science, Stanford University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16101/16101-13-19595-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00268-predicting-livelihood-indicators-from-community-generated-street-level-imagery/",
        "doi": "10.1609/aaai.v35i1.16101",
        "pdf_size": 9244750
    },
    {
        "id": "07806",
        "title": "Predictive Adversarial Learning from Positive and Unlabeled Data",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper studies learning from positive and unlabeled examples, known as PU learning. It proposes a novel PU learning method called Predictive Adversarial Networks (PAN) based on GAN (Generative Adversarial Networks). GAN learns a generator to generate data (e.g., images) to fool a discriminator which tries to determine whether the generated data belong to a (positive) training class. PU learning can be casted as trying to identify (not generate) likely positive instances from the unlabeled set to fool a discriminator that determines whether the identified likely positive instances from the unlabeled set are indeed positive. However, directly applying GAN is problematic because GAN focuses on only the positive data. The resulting PU learning method will have high precision but low recall. We propose a new objective function based on KL-divergence. Evaluation using both image and text data shows that PAN outperforms state-of-the-art PU learning methods and also a direct adaptation of GAN for PU learning.",
        "primary_area": "Machine Learning II",
        "author": "Wenpeng Hu; Ran Le; Bing Liu; Feng Ji; Jinwen Ma; Dongyan Zhao; Rui Yan",
        "authorids": "",
        "aff": "Peking University; Peking University; UIC; Alibaba Inc.; Peking University; Peking University; Peking University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16953/16953-13-20447-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07806-predictive-adversarial-learning-from-positive-and-unlabeled-data/",
        "doi": "10.1609/aaai.v35i9.16953",
        "pdf_size": 332201
    },
    {
        "id": "05647",
        "title": "Preference Elicitation as Average-Case Sorting",
        "track": "main",
        "status": "Poster",
        "abstract": "Many decision making systems require users to indicate their preferences via a ranking. It is common to elicit such rankings through pairwise comparison queries. By using sorting algorithms, this can be achieved by asking at most O(m log m) adaptive comparison queries. However, in many cases we have some advance (probabilistic) information about the user's preferences, for instance if we have a learnt model of the user's preferences or if we expect the user's preferences to be correlated with those of previous users. For these cases, we design elicitation algorithms that ask fewer questions in expectation, by building on results for average-case sorting. If the user's preferences are drawn from a Mallows phi model, O(m) queries are enough; for a mixture of k Mallows models, log k + O(m) queries are enough; for Plackett-Luce models, the answer varies with the alternative weights. Our results match information-theoretic lower bounds. We also provide empirical evidence for the benefits of our approach.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Dominik Peters; Ariel D. Procaccia",
        "authorids": "",
        "aff": "Harvard University; Harvard University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16709/16709-13-20203-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05647-preference-elicitation-as-average-case-sorting/",
        "doi": "10.1609/aaai.v35i6.16709",
        "pdf_size": 206967
    },
    {
        "id": "06262",
        "title": "Preferred Explanations for Ontology-Mediated Queries under Existential Rules",
        "track": "main",
        "status": "Poster",
        "abstract": "Recently, explanations for query answers under existential rules have been investigated, where an explanation is an inclusion-minimal subset of a given database that, together with the ontology, entails the query. In this paper, we take a step further and study explanations under different minimality criteria. In particular, we first study cardinality-minimal explanations and hence focus on deriving explanations of minimum size. We then study a more general preference order induced by a weight distribution. We assume that every database fact is annotated with a (penalization) weight, and we are interested in explanations with minimum overall weight. For both preference orders, we study a variety of explanation problems, such as recognizing a preferred explanation, all preferred explanations, a relevant or necessary fact, and the existence of a  preferred explanation not containing forbidden sets of facts. We provide a detailed complexity analysis for all the aforementioned problems, thereby providing a more complete picture for explaining query answers under existential rules.",
        "primary_area": "Knowledge Representation and Reasoning",
        "author": "\u0130smail \u0130lkan Ceylan; Thomas Lukasiewicz; Enrico Malizia; Cristian Molinaro; Andrius Vaicenavi\u010dius",
        "authorids": "",
        "aff": "University of Oxford; University of Oxford; University of Bologna; University of Calabria; University of Oxford",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16778/16778-13-20272-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06262-preferred-explanations-for-ontology-mediated-queries-under-existential-rules/",
        "doi": "10.1609/aaai.v35i7.16778",
        "pdf_size": 165793
    },
    {
        "id": "05415",
        "title": "Present-Biased Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper explores the behavior of present-biased agents, that is, agents who erroneously anticipate the costs of future actions compared to their real costs. Specifically, the paper extends the origi- nal framework proposed by Akerlof (1991) for studying various aspects of human behavior related to time-inconsistent planning, including pro- crastination, and abandonment, as well as the elegant graph-theoretic model encapsulating this framework recently proposed by Kleinberg and Oren (2014). The benefit of this extension is twofold. First, it enables to perform fine grained analysis of the behavior of present-biased agents depending on the optimisation task they have to perform. In particular, we study covering tasks vs. hitting tasks, and show that the ratio be- tween the cost of the solutions computed by present-biased agents and the cost of the optimal solutions may differ significantly depending on the problem constraints. Second, our extension enables to study not only un- derestimation of future costs, coupled with minimization problems, but also all combinations of minimization/maximization, and underestima- tion/overestimation. We study the four scenarios, and we establish upper bounds on the cost ratio for three of them (the cost ratio for the origi- nal scenario was known to be unbounded), providing a complete global picture of the behavior of present-biased agents, as far as optimisation tasks are concerned.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Fedor V. Fomin; Pierre Fraigniaud; Petr A. Golovach",
        "authorids": "",
        "aff": "University of Bergen; CNRS and Universit\u00e9 de Paris; University of Bergen",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16682/16682-13-20176-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05415-present-biased-optimization/",
        "doi": "10.1609/aaai.v35i6.16682",
        "pdf_size": 184274
    },
    {
        "id": "05202",
        "title": "Preserving Condorcet Winners under Strategic Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Condorcet extensions have long held a prominent place in social choice theory. A Condorcet extension will return the Condorcet winner as the unique winner whenever such an alternative exists. However, the definition of a Condorcet extension does not take into account possible manipulation by the voters. A profile where all agents vote truthfully may have a Condorcet winner, but this alternative may not end up in the set of winners if agents are acting strategically. Focusing on the class of tournament solutions, we show that many natural social choice functions in this class, such as the well-known Copeland and Slater rules, cannot guarantee the preservation of Condorcet winners when agents behave strategically. Our main result in this respect is an impossibility theorem that establishes that no tournament solution satisfying a very weak decisiveness requirement can provide such a guarantee. On the bright side, we identify several indecisive but otherwise attractive tournament solutions that do guarantee the preservation of Condorcet winners under strategic manipulation for a large class of preference extensions.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Sirin Botan; Ulle Endriss",
        "authorids": "",
        "aff": "University of Amsterdam; University of Amsterdam",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16657/16657-13-20151-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05202-preserving-condorcet-winners-under-strategic-manipulation/",
        "doi": "10.1609/aaai.v35i6.16657",
        "pdf_size": 150624
    },
    {
        "id": "03369",
        "title": "Proactive Privacy-preserving Learning for Retrieval",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep Neural Networks (DNNs) have recently achieved remarkable performance in image retrieval, yet posing great threats to data privacy. On the one hand, one may misuse a deployed DNNs based system to look up data without consent. On the other hand, organizations or individuals would legally or illegally collect data to train high-performance models outside the scope of legitimate purposes. Unfortunately, less effort has been made to safeguard data privacy against malicious uses of DNNs. In this paper, we propose a data-centric Proactive Privacy-preserving Learning (PPL) algorithm for hashing based retrieval, which achieves the protection purpose by employing a generator to transfer the original data into the adversarial data with quasi-imperceptible perturbations before releasing them. When the data source is infiltrated, the adversarial data can confuse menacing retrieval models to make erroneous predictions. Given that the prior knowledge of malicious models is not available, a surrogate retrieval model is instead introduced acting as a fooling target. The framework is trained by a two-player game conducted between the generator and the surrogate model. More specifically, the generator is updated to enlarge the gap between the adversarial data and the original data, aiming to lower the search accuracy of the surrogate model. On the contrary, the surrogate model is trained with the opposing objective that is to maintain the search performance. As a result, an effective and robust adversarial generator is encouraged. Furthermore, to facilitate an effective optimization, a Gradient Reversal Layer (GRL) module is inserted to connect two models, enabling the two-player game in a one-step learning. Extensive experiments on three widely-used realistic datasets prove the effectiveness of the proposed method.",
        "primary_area": "Computer Vision III",
        "author": "Peng-Fei Zhang; Zi Huang; Xin-Shun Xu",
        "authorids": "",
        "aff": "University of Queensland; University of Queensland; Shandong University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16449/16449-13-19943-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03369-proactive-privacy-preserving-learning-for-retrieval/",
        "doi": "10.1609/aaai.v35i4.16449",
        "pdf_size": 8070058
    },
    {
        "id": "12174",
        "title": "Probabilistic Dependency Graphs",
        "track": "main",
        "status": "Poster",
        "abstract": "We introduce Probabilistic Dependency Graphs (PDGs), a new class of directed graphical models.   PDGs can capture inconsistent beliefs in a natural way and are more modular than Bayesian Networks (BNs), in that they make it easier to incorporate new information and restructure the representation.    We show by example how PDGs are an especially natural modeling tool. We provide three semantics for PDGs, each of which can be derived from a scoring function (on joint distributions over the variables in the network) that can be viewed as representing a distribution's incompatibility with the PDG. For the PDG corresponding to a BN, this function is uniquely minimized by the distribution the BN represents, showing that PDG semantics extend BN semantics. We show further that factor graphs and their exponential families can also be faithfully represented as PDGs, while there are significant barriers to modeling a PDG with a factor graph.",
        "primary_area": "Reasoning under Uncertainty",
        "author": "Oliver Richardson; Joseph Y Halpern",
        "authorids": "",
        "aff": "Cornell University; Cornell University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17445/17445-13-20939-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12174-probabilistic-dependency-graphs/",
        "doi": "10.1609/aaai.v35i13.17445",
        "pdf_size": 203924
    },
    {
        "id": "00778",
        "title": "Probabilistic Programming Bots in Intuitive Physics Game Play",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent findings suggest that humans deploy cognitive mechanism of physics simulation engines to simulate the physics of objects. We propose a framework for bots to deploy probabilistic programming tools for interacting with intuitive physics environments. The framework employs a physics simulation in a probabilistic way to infer about moves performed by an agent in a setting governed by Newtonian laws of motion. However, methods of probabilistic programs can be slow in such setting due to their need to generate many samples. We complement the model with a model-free approach to aid the sampling procedures in becoming more efficient through learning from experience during game playing. We present an approach where combining model-free approaches (a convolutional neural network in our model) and model-based approaches (probabilistic physics simulation) is able to achieve what neither could alone. This way the model outperforms an all model-free or all model-based approach. We discuss a case study showing empirical results of the performance of the model on the game of Flappy Bird.",
        "primary_area": "Cognitive Modeling and Cognitive Systems",
        "author": "Fahad Alhasoun; Sarah Alneghiemish",
        "authorids": "",
        "aff": "Massachusetts Institute of Technology; Massachusetts Institute of Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16159/16159-13-19653-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00778-probabilistic-programming-bots-in-intuitive-physics-game-play/",
        "doi": "10.1609/aaai.v35i1.16159",
        "pdf_size": 359975
    },
    {
        "id": "14301",
        "title": "Probing Product Description Generation via Posterior Distillation",
        "track": "main",
        "status": "Poster",
        "abstract": "In product description generation (PDG), the user-cared aspect is critical for the recommendation system, which can not only improve user's experiences but also obtain more clicks. High-quality customer reviews can be considered as an ideal source to mine user-cared aspects. However, in reality, a large number of new products (known as long-tailed commodities) cannot gather sufficient amount of customer reviews, which brings a big challenge in the product description generation task. Existing works tend to generate the product description solely based on item information, i.e., product attributes or title words, which leads to tedious contents and cannot attract customers effectively. To tackle this problem, we propose an adaptive posterior network based on Transformer architecture that can utilize user-cared information from customer reviews. Specifically, we first extend the self-attentive Transformer encoder to encode product titles and attributes. Then, we apply an adaptive posterior distillation module to utilize useful review information, which integrates user-cared aspects to the generation process. Finally, we apply a Transformer-based decoding phase with copy mechanism to automatically generate the product description. Besides, we also collect a large-scare Chinese product description dataset to support our work and further research in this field. Experimental results show that our model is superior to traditional generative models in both automatic indicators and human evaluation.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Haolan Zhan; Hainan Zhang; Hongshen Chen; Lei Shen; Zhuoye Ding; Yongjun Bao; Weipeng Yan; Yanyan Lan",
        "authorids": "",
        "aff": "Institute of Software, Chinese Academy of Sciences; JD.com; JD.com; Institute of Computing Technology, Chinese Academy of Sciences; JD.com; JD.com; JD.com; Institute of Computing Technology, Chinese Academy of Sciences",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17682/17682-13-21176-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14301-probing-product-description-generation-via-posterior-distillation/",
        "doi": "10.1609/aaai.v35i16.17682",
        "pdf_size": 1317078
    },
    {
        "id": "00381",
        "title": "Programmatic Strategies for Real-Time Strategy Games",
        "track": "main",
        "status": "Poster",
        "abstract": "Search-based systems have shown to be effective for planning in zero-sum games. However, search-based approaches have important disadvantages. First, the decisions of search algorithms are mostly non-interpretable, which is problematic in domains where predictability and trust are desired such as commercial games. Second, the computational complexity of search-based algorithms might limit their applicability, especially in contexts where resources are shared among other tasks such as graphic rendering. In this work we introduce a system for synthesizing programmatic strategies for a real-time strategy (RTS) game. In contrast with search algorithms, programmatic strategies are more amenable to explanations and tend to be efficient, once the program is synthesized. Our system uses a novel algorithm for simplifying domain-specific languages (DSLs) and a local search algorithm that synthesizes programs with self play. We performed a user study where we enlisted four professional programmers to develop programmatic strategies for mRTS, a minimalist RTS game. Our results show that the programs synthesized by our approach can outperform search algorithms and be competitive with programs written by the programmers.",
        "primary_area": "Application Domains",
        "author": "Julian R. H. Mari\u00f1o; Rubens O. Moraes; Tassiana C. Oliveira; Claudio Toledo; Levi H. S. Lelis",
        "authorids": "",
        "aff": "Universidade de S\u00e3o Paulo; Universidade Federal de Vi\u00e7osa; Universidade Federal de Vi\u00e7osa; Universidade de S\u00e3o Paulo; University of Alberta",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16114/16114-13-19608-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00381-programmatic-strategies-for-real-time-strategy-games/",
        "doi": "10.1609/aaai.v35i1.16114",
        "pdf_size": 166803
    },
    {
        "id": "11870",
        "title": "Progression Heuristics for Planning with Probabilistic LTL Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "Probabilistic planning subject to multi-objective probabilistic temporal logic (PLTL) constraints models the problem of computing safe and robust behaviours for agents in stochastic environments.  We present novel admissible heuristics to guide the search for cost-optimal policies for these problems.  These heuristics project and decompose LTL formulae obtained by progression to estimate the probability that an extension of a partial policy satisfies the constraints.  Their computation with linear programming is integrated with the recent PLTL-dual heuristic search algorithm, enabling more aggressive pruning of regions violating the constraints.  Our experiments show that they further widen the scalability gap between heuristic search and verification approaches to these planning problems.",
        "primary_area": "Planning, Routing, and Scheduling",
        "author": "Ian Mallett; Sylvie Thiebaux; Felipe Trevizan",
        "authorids": "",
        "aff": "The Australian National University; The Australian National University; The Australian National University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17410/17410-13-20904-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11870-progression-heuristics-for-planning-with-probabilistic-ltl-constraints/",
        "doi": "10.1609/aaai.v35i13.17410",
        "pdf_size": 620352
    },
    {
        "id": "13851",
        "title": "Progressive Multi-task Learning with Controlled Information Flow for Joint Entity and Relation Extraction",
        "track": "main",
        "status": "Poster",
        "abstract": "Multitask learning has shown promising performance in learning multiple related tasks simultaneously, and variants of model architectures have been proposed, especially for supervised classification problems. One goal of multitask learning is to extract a good representation that sufficiently captures the relevant part of the input about the output for each learning task. To achieve this objective, in this paper we design a multitask learning architecture based on the observation that correlations exist between outputs of some related tasks (e.g. entity recognition and relation extraction tasks), and they reflect the relevant features that need to be extracted from the input. As outputs are unobserved, our proposed model exploits task predictions in lower layers of the neural model, also referred to as early predictions in this work. But we control the injection of early predictions to ensure that we extract good task-specific representations for classification. We refer to this model as a Progressive Multitask learning model with Explicit Interactions (PMEI). Extensive experiments on multiple benchmark datasets produce state-of-the-art results on the joint entity and relation extraction task.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Kai Sun; Richong Zhang; Samuel Mensah; Yongyi Mao; Xudong Liu",
        "authorids": "",
        "aff": "Beihang University; Beihang University; Beihang University; University of Ottawa; Beihang University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17632/17632-13-21126-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13851-progressive-multi-task-learning-with-controlled-information-flow-for-joint-entity-and-relation-extraction/",
        "doi": "10.1609/aaai.v35i15.17632",
        "pdf_size": 346647
    },
    {
        "id": "02541",
        "title": "Progressive Network Grafting for Few-Shot Knowledge Distillation",
        "track": "main",
        "status": "Poster",
        "abstract": "Knowledge distillation has demonstrated encouraging performances in deep model compression. Most existing approaches, however, require massive labeled data to accomplish the knowledge transfer,  making the model compression a cumbersome and costly process. In this paper, we investigate the practical few-shot knowledge distillation scenario, where we assume only a few samples without human annotations are available for each category. To this end, we introduce a principled dual-stage distillation scheme tailored for few-shot data. In the first step, we graft the student blocks one by one onto the teacher, and learn the parameters of the grafted block intertwined with those of the other teacher blocks. In the second step, the trained student blocks are progressively connected and then together grafted onto the teacher network, allowing the learned student blocks to adapt themselves to each other and eventually replace the teacher network. Experiments demonstrate that our approach, with only a few unlabeled samples, achieves gratifying results on CIFAR10,CIFAR100, and ILSVRC-2012. On CIFAR10 and CIFAR100, our performances are even on par with those of knowledge distillation schemes that utilize the full datasets. The source code is available at https://github.com/zju-vipa/NetGraft.",
        "primary_area": "Computer Vision II",
        "author": "Chengchao Shen; Xinchao Wang; Youtan Yin; Jie Song; Sihui Luo; Mingli Song",
        "authorids": "",
        "aff": "Zhejiang University; Stevens Institute of Technology; Zhejiang University; Zhejiang University; Zhejiang University; Zhejiang University Alibaba-Zhejiang University Joint Research Institute of Frontier Technologies",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16356/16356-13-19850-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02541-progressive-network-grafting-for-few-shot-knowledge-distillation/",
        "doi": "10.1609/aaai.v35i3.16356",
        "pdf_size": 599823
    },
    {
        "id": "01522",
        "title": "Progressive One-shot Human Parsing",
        "track": "main",
        "status": "Poster",
        "abstract": "Prior human parsing models are limited to parsing humans into classes pre-defined in the training data, which is not flexible to generalize to unseen classes, e.g., new clothing in fashion analysis. In this paper, we propose a new problem named one-shot human parsing (OSHP) that requires to parse human into an open set of reference classes defined by any single reference example. During training, only base classes defined in the training set are exposed, which can overlap with part of reference classes. In this paper, we devise a novel Progressive One-shot Parsing network (POPNet) to address two critical challenges , i.e., testing bias and small sizes. POPNet consists of two collaborative metric learning modules named Attention Guidance Module and Nearest Centroid Module, which can learn representative prototypes for base classes and quickly transfer the ability to unseen classes during testing, thereby reducing testing bias. Moreover, POPNet adopts a progressive human parsing framework that can incorporate the learned knowledge of parent classes at the coarse granularity to help recognize the descendant classes at the fine granularity, thereby handling the small sizes issue. Experiments on the ATR-OS benchmark tailored for OSHP demonstrate POPNet outperforms other representative one-shot segmentation models by large margins and establishes a strong baseline. Source code can be found at https://github.com/Charleshhy/One-shot-Human-Parsing.",
        "primary_area": "Computer Vision I",
        "author": "Haoyu He; Jing Zhang; Bhavani Thuraisingham; Dacheng Tao",
        "authorids": "",
        "aff": "The University of Sydney; The University of Sydney; The University of Texas at Dallas; The University of Sydney",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16243/16243-13-19737-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01522-progressive-one-shot-human-parsing/",
        "doi": "10.1609/aaai.v35i2.16243",
        "pdf_size": 1522354
    },
    {
        "id": "07322",
        "title": "Projection-Free Bandit Optimization with Privacy Guarantees",
        "track": "main",
        "status": "Poster",
        "abstract": "We design differentially private algorithms for the bandit convex optimization problem in the projection-free setting.  This setting is important whenever the decision set has a complex geometry, and access to it is done efficiently only through a linear optimization oracle, hence Euclidean projections are unavailable (e.g. matroid polytope, submodular base polytope). This is the first differentially-private algorithm for projection-free bandit optimization, and in fact our bound matches the best known non-private projection-free algorithm and the best known private algorithm, even for the weaker setting when projections are available.",
        "primary_area": "Machine Learning I",
        "author": "Alina Ene; Huy L. Nguyen; Adrian Vladu",
        "authorids": "",
        "aff": "Boston University; Northeastern University; CNRS & IRIF, Universit\u00e9 de Paris",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16899/16899-13-20393-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07322-projection-free-bandit-optimization-with-privacy-guarantees/",
        "doi": "10.1609/aaai.v35i8.16899",
        "pdf_size": 154343
    },
    {
        "id": "10067",
        "title": "Projection-free Online Learning in Dynamic Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "To efficiently solve high-dimensional problems with complicated constraints, projection-free online learning has received ever-increasing research interest. However, previous studies either focused on static regret that is not suitable for dynamic environments, or only established the dynamic regret bound under the smoothness of losses. In this paper, without the condition of the smoothness, we propose a novel projection-free online algorithm, and achieve an O(max{T^{2/3}V_T^{1/3},T^{1/2}}) dynamic regret bound for convex functions and an O(max{(TV_Tlog T)^{1/2},log T}) dynamic regret bound for strongly convex functions, where T is the time horizon and V_T denotes the variation of loss functions. Specifically, we first improve an existing projection-free algorithm called online conditional gradient (OCG) to enjoy small dynamic regret bounds with the prior knowledge of V_T. To work with unknowable V_T, we maintain multiple instances of the improved OCG that can handle different functional variations, and combine them with a meta-algorithm that can track the best one. Experimental results validate the efficiency and effectiveness of our algorithm.",
        "primary_area": "Machine Learning IV",
        "author": "Yuanyu Wan; Bo Xue; Lijun Zhang",
        "authorids": "",
        "aff": "Nanjing University; Nanjing University; Nanjing University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17208/17208-13-20702-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10067-projection-free-online-learning-in-dynamic-environments/",
        "doi": "10.1609/aaai.v35i11.17208",
        "pdf_size": 332134
    },
    {
        "id": "10076",
        "title": "Projection-free Online Learning over Strongly Convex Sets",
        "track": "main",
        "status": "Poster",
        "abstract": "To efficiently solve online problems with complicated constraints, projection-free algorithms including online frank-wolfe (OFW) and its variants have received significant interest recently. However, in the general case, existing efficient projection-free algorithms only achieved the regret bound of O(T^{3/4}), which is worse than the regret of projection-based algorithms, where T is the number of decision rounds. In this paper, we study the special case of online learning over strongly convex sets, for which we first prove that OFW can enjoy a better regret bound of O(T^{2/3}) for general convex losses. The key idea is to refine the decaying step-size in the original OFW by a simple line search rule. Furthermore, for strongly convex losses, we propose a strongly convex variant of OFW by redefining the surrogate loss function in OFW. We show that it achieves a regret bound of O(T^{2/3}) over general convex sets and a better regret bound of O(T^{1/2}) over strongly convex sets.",
        "primary_area": "Machine Learning IV",
        "author": "Yuanyu Wan; Lijun Zhang",
        "authorids": "",
        "aff": "Nanjing University; Nanjing University Pazhou Lab",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17209/17209-13-20703-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10076-projection-free-online-learning-over-strongly-convex-sets/",
        "doi": "10.1609/aaai.v35i11.17209",
        "pdf_size": 160411
    },
    {
        "id": "05286",
        "title": "Proportional Representation under Single-Crossing Preferences Revisited",
        "track": "main",
        "status": "Poster",
        "abstract": "We study the complexity of determining a winning committee under the Chamberlin-Courant voting rule when voters' preferences are single-crossing on a line, or, more generally, on a tree. For the line, Skowron et al. (2015) describe an O(n^2mk) algorithm (where n, m, k are the number of voters, the number of candidates and the committee size, respectively); we show that a simple tweak improves the time complexity to O(nmk). We then improve this bound for k=\u03a9(log n) by reducing our problem to the k-link path problem for DAGs with concave Monge weights, obtaining a nm2^O(\u221a(log k log log n)) algorithm for the general case and a nearly linear algorithm for the Borda misrepresentation function. For trees, we point out an issue with the algorithm proposed by Clearwater, Puppe and Slinko (2015), and develop a O(nmk) algorithm for this case as well.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Andrei Costin Constantinescu; Edith Elkind",
        "authorids": "",
        "aff": "University of Oxford; University of Oxford",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16667/16667-13-20161-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05286-proportional-representation-under-single-crossing-preferences-revisited/",
        "doi": "10.1609/aaai.v35i6.16667",
        "pdf_size": 160053
    },
    {
        "id": "05110",
        "title": "Proportionally Representative Participatory Budgeting with Ordinal Preferences",
        "track": "main",
        "status": "Poster",
        "abstract": "Participatory budgeting (PB) is a democratic paradigm whereby voters decide on a set of projects to fund with  a limited budget. We consider PB in a setting where voters report ordinal preferences over projects and have (possibly) asymmetric weights. We propose proportional representation axioms and clarify how they fit into other preference aggregation settings, such as multi-winner voting and approval-based multi-winner voting. As a result of our study, we also discover a new solution concept for approval-based multi-winner voting, which we call Inclusion PSC (IPSC). IPSC is stronger than proportional justified representation (PJR), incomparable to extended justified representation (EJR), and yet compatible with EJR. The well-studied Proportional Approval Voting (PAV)  rule produces a committee that satisfies both EJR and IPSC; however, both these axioms can also be satisfied by an algorithm that runs in polynomial-time.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Haris Aziz; Barton E. Lee",
        "authorids": "",
        "aff": "UNSW Sydney; UNSW Sydney",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16646/16646-13-20140-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05110-proportionally-representative-participatory-budgeting-with-ordinal-preferences/",
        "doi": "10.1609/aaai.v35i6.16646",
        "pdf_size": 139828
    },
    {
        "id": "01902",
        "title": "Proposal-Free Video Grounding with Contextual Pyramid Network",
        "track": "main",
        "status": "Poster",
        "abstract": "The challenge of video grounding - localizing activities in an untrimmed video via a natural language query - is to tackle the semantics of vision and language consistently along the temporal dimension. Most existing proposal-based methods are trapped by computational cost with extensive candidate proposals. In this paper, we propose a novel proposal-free framework named Contextual Pyramid Network (CPNet) to investigate multi-scale temporal correlation in the video. Specifically, we propose a pyramid network to extract 2D contextual correlation maps at different temporal scales (T*T, T/2*T/2, T/4*T/4), where the 2D correlation map (past to current & future to current) is designed to model all the relations of any two moments in the video. In other words, CPNet progressively replenishes the temporal contexts and refines the location of queried activity by enlarging the temporal receptive fields. Finally, we implement a temporal self-attentive regression (i.e., proposal-free regression) to predict the activity boundary from the above hierarchical context-aware 2D correlation maps. Extensive experiments on ActivityNet Captions, Charades-STA, and TACoS datasets demonstrate that our approach outperforms state-of-the-art methods.",
        "primary_area": "Computer Vision II",
        "author": "Kun Li; Dan Guo; Meng Wang",
        "authorids": "",
        "aff": "Hefei University of Technology; Hefei University of Technology; Hefei University of Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16285/16285-13-19779-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01902-proposal-free-video-grounding-with-contextual-pyramid-network/",
        "doi": "10.1609/aaai.v35i3.16285",
        "pdf_size": 1504493
    },
    {
        "id": "05176",
        "title": "Protecting the Protected Group: Circumventing Harmful Fairness",
        "track": "main",
        "status": "Poster",
        "abstract": "The recent literature on fair Machine Learning manifests that the choice of fairness constraints must be driven by the utilities of the population. However, virtually all previous work makes the unrealistic assumption that the exact underlying utilities of the population (representing private tastes of individuals) are known to the regulator that imposes the fairness constraint. In this paper we initiate the discussion of the emph{mismatch}, the unavoidable difference between the underlying utilities of the population and the utilities assumed by the regulator. We demonstrate that the mismatch can make the disadvantaged protected group worse off after imposing the fairness constraint and provide tools to design fairness constraints that help the disadvantaged group despite the mismatch.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Omer Ben-Porat; Fedor Sandomirskiy; Moshe Tennenholtz",
        "authorids": "",
        "aff": "Tel-Aviv University; Technion \u2013 Israel Institute of Technology Higher School of Economics, St. Petersburg, Russia; Technion \u2013 Israel Institute of Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16654/16654-13-20148-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05176-protecting-the-protected-group-circumventing-harmful-fairness/",
        "doi": "10.1609/aaai.v35i6.16654",
        "pdf_size": 191367
    },
    {
        "id": "06974",
        "title": "Provable Benefits of Overparameterization in Model Compression: From Double Descent to Pruning Neural Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep networks are typically trained with many more parameters than the size of the training dataset. Recent empirical evidence indicates that the practice of overparameterization not only benefits training large models, but also assists \u2013 perhaps counterintuitively \u2013 building lightweight models. Specifically, it suggests that overparameterization benefits model pruning / sparsification. This paper sheds light on these empirical findings by theoretically characterizing the high-dimensional asymptotics of model pruning in the overparameterized regime. The theory presented addresses the following core question: ``should one train a small model from the beginning, or first train a large model and then prune?''. We analytically identify regimes in which, even if the location of the most informative features is known, we are better off fitting a large model and then pruning rather than simply training with the known informative features. This leads to a new double descent in the training of sparse models: growing the original model, while preserving the target sparsity, improves the test accuracy as one moves beyond the overparameterization threshold. Our analysis further reveals the benefit of retraining by relating it to feature correlations. We find that the above phenomena are already present in linear and random-features models. Our technical approach advances the toolset of high-dimensional analysis and precisely characterizes the asymptotic distribution of over-parameterized least-squares. The intuition gained by analytically studying simpler models is numerically verified on neural networks.",
        "primary_area": "Machine Learning I",
        "author": "Xiangyu Chang; Yingcong Li; Samet Oymak; Christos Thrampoulidis",
        "authorids": "",
        "aff": "University of Calinfornia, Riverside; University of California, Riverside; University of California, Riverside; University of British Columbia",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16859/16859-13-20353-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06974-provable-benefits-of-overparameterization-in-model-compression-from-double-descent-to-pruning-neural-networks/",
        "doi": "10.1609/aaai.v35i8.16859",
        "pdf_size": 981358
    },
    {
        "id": "07685",
        "title": "Provably Good Solutions to the Knapsack Problem via Neural Networks of Bounded Size",
        "track": "main",
        "status": "Poster",
        "abstract": "The development of a satisfying and rigorous mathematical understanding of the performance of neural networks is a major challenge in artificial intelligence. Against this background, we study the expressive power of neural networks through the example of the classical NP-hard Knapsack Problem. Our main contribution is a class of recurrent neural networks (RNNs) with rectified linear units that are iteratively applied to each item of a Knapsack instance and thereby compute optimal or provably good solution values. We show that an RNN of depth four and width depending quadratically on the profit of an optimum Knapsack solution is sufficient to find optimum Knapsack solutions. We also prove the following tradeoff between the size of an RNN and the quality of the computed Knapsack solution: for Knapsack instances consisting of n items, an RNN of depth five and width w computes a solution of value at least 1 - O(n^2 sqrt(w)) times the optimum solution value. Our results build upon a classical dynamic programming formulation of the Knapsack Problem as well as a careful rounding of profit values that are also at the core of the well-known fully polynomial-time approximation scheme for the Knapsack Problem. Finally, we point out that our results can be generalized to many other combinatorial optimization problems that admit dynamic programming solution methods, such as various Shortest Path Problems, the Longest Common Subsequence Problem, and the Traveling Salesperson Problem.",
        "primary_area": "Machine Learning II",
        "author": "Christoph Hertrich; Martin Skutella",
        "authorids": "",
        "aff": "Institute of Mathematics Technische Universit\u00e4t Berlin; Institute of Mathematics Technische Universit\u00e4t Berlin",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16939/16939-13-20433-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07685-provably-good-solutions-to-the-knapsack-problem-via-neural-networks-of-bounded-size/",
        "doi": "10.1609/aaai.v35i9.16939",
        "pdf_size": 179444
    },
    {
        "id": "06885",
        "title": "Provably Secure Federated Learning against Malicious Clients",
        "track": "main",
        "status": "Poster",
        "abstract": "Federated learning enables clients to collaboratively learn a shared global model without sharing their local training data with a cloud server. However, malicious clients can corrupt the  global  model  to  predict  incorrect  labels  for  testing  examples. Existing defenses against malicious clients leverage Byzantine-robust federated learning methods. However, these methods cannot provably guarantee that the predicted label for  a  testing  example  is  not  affected  by  malicious  clients. We bridge this gap via ensemble federated learning. In particular, given any base federated learning algorithm, we use the algorithm to learn multiple global models, each of which is learnt using a randomly selected subset of clients. When predicting  the  label  of  a  testing  example,  we  take  majority vote  among  the  global  models.  We  show  that  our  ensemble  federated  learning  with  any  base  federated  learning  algorithm is provably secure against malicious clients. Specifically, the label predicted by our ensemble global model for a testing example is provably not affected by a bounded number of malicious clients. Moreover, we show that our derived bound is tight. We evaluate our method on MNIST and Human Activity Recognition datasets. For instance, our method can achieve a certified accuracy of 88% on MNIST when 20 out of 1,000 clients are malicious.",
        "primary_area": "Machine Learning I",
        "author": "Xiaoyu Cao; Jinyuan Jia; Neil Zhenqiang Gong",
        "authorids": "",
        "aff": "Duke University; Duke University; Duke University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16849/16849-13-20343-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06885-provably-secure-federated-learning-against-malicious-clients/",
        "doi": "10.1609/aaai.v35i8.16849",
        "pdf_size": 9891819
    },
    {
        "id": "09808",
        "title": "Proxy Graph Matching with Proximal Matching Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Estimating feature point correspondence is a common technique in computer vision. A line of recent data-driven approaches utilizing the graph neural networks improved the matching accuracy by a large margin. However, these learning-based methods require a lot of labeled training data, which are expensive to collect. Moreover, we find most methods are sensitive to global transforms, for example, a random rotation. On the contrary, classical geometric approaches are immune to rotational transformation though their performance is generally inferior. To tackle these issues, we propose a new learning-based matching framework, which is designed to be rotationally invariant. The model only takes geometric information as input. It consists of three parts: a graph neural network to generate a high-level local feature, an attention-based module to normalize the rotational transform, and a global feature matching module based on proximal optimization. To justify our approach, we provide a convergence guarantee for the proximal method for graph matching. The overall performance is validated by numerical experiments. In particular, our approach is trained on the synthetic random graphs and then applied to several real-world datasets. The experimental results demonstrate that our method is robust to rotational transform and highlights its strong performance of matching accuracy.",
        "primary_area": "Machine Learning IV",
        "author": "Hao-Ru Tan; Chuang Wang; Si-Tong Wu; Tie-Qiang Wang; Xu-Yao Zhang; Cheng-Lin Liu",
        "authorids": "",
        "aff": "National Laboratory of Pattern Recognition, Institute of Automation of Chinese Academy of Sciences School of Artificial Intelligence, University of Chinese Academy of Sciences; National Laboratory of Pattern Recognition, Institute of Automation of Chinese Academy of Sciences School of Artificial Intelligence, University of Chinese Academy of Sciences; School of Artificial Intelligence, University of Chinese Academy of Sciences; National Laboratory of Pattern Recognition, Institute of Automation of Chinese Academy of Sciences School of Artificial Intelligence, University of Chinese Academy of Sciences; National Laboratory of Pattern Recognition, Institute of Automation of Chinese Academy of Sciences School of Artificial Intelligence, University of Chinese Academy of Sciences; National Laboratory of Pattern Recognition, Institute of Automation of Chinese Academy of Sciences School of Artificial Intelligence, University of Chinese Academy of Sciences CAS Center for Excellence of Brain Science and Intelligence Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17179/17179-13-20673-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09808-proxy-graph-matching-with-proximal-matching-networks/",
        "doi": "10.1609/aaai.v35i11.17179",
        "pdf_size": 337187
    },
    {
        "id": "01460",
        "title": "Proxy Synthesis: Learning with Synthetic Classes for Deep Metric Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "One of the main purposes of deep metric learning is to construct an embedding space that has well-generalized embeddings on both seen (training) classes and unseen (test) classes. Most existing works have tried to achieve this using different types of metric objectives and hard sample mining strategies with given training data. However, learning with only the training data can be overfitted to the seen classes, leading to the lack of generalization capability on unseen classes. To address this problem, we propose a simple regularizer called Proxy Synthesis that exploits synthetic classes for stronger generalization in deep metric learning. The proposed method generates synthetic embeddings and proxies that work as synthetic classes, and they mimic unseen classes when computing proxy-based losses. Proxy Synthesis derives an embedding space considering class relations and smooth decision boundaries for robustness on unseen classes. Our method is applicable to any proxy-based losses, including softmax and its variants. Extensive experiments on four famous benchmarks in image retrieval tasks demonstrate that Proxy Synthesis significantly boosts the performance of proxy-based losses and achieves state-of-the-art performance. Our implementation is available at github.com/navervision/proxy-synthesis.",
        "primary_area": "Computer Vision I",
        "author": "Geonmo Gu; Byungsoo Ko; Han-Gyu Kim",
        "authorids": "",
        "aff": "NAVER/LINE Vision; NAVER/LINE Vision; NAVER Clova Speech",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16236/16236-13-19730-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01460-proxy-synthesis-learning-with-synthetic-classes-for-deep-metric-learning/",
        "doi": "10.1609/aaai.v35i2.16236",
        "pdf_size": 1833561
    },
    {
        "id": "02311",
        "title": "Pyramidal Feature Shrinking for Salient Object Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Recently, we have witnessed the great progress of salient object detection (SOD),  which benefits from the effectiveness of various feature aggregation strategies. However, existing methods usually aggregate the low-level features containing details and the high-level features containing semantics over a large span, which introduces noise into the aggregated features and generate inaccurate saliency map. To address this issue, we propose pyramidal feature shrinking network (PFSNet), which aims to aggregate adjacent feature nodes in pairs with layer-by-layer shrinkage, so that the aggregated features fuse effective details and semantics together and discard interference information. Specifically, pyramidal shrinking decoder (PSD) is proposed to aggregate adjacent features hierarchically in an asymptotic manner. Unlike other methods that aggregate features with significantly different information, this method only focuses on adjacent feature nodes in each layer and shrinks them to a final unique feature node. Besides, we propose adjacent fusion module (AFM) to perform mutual spatial enhancement between the adjacent features so as to dynamically weight the features and adaptively fuse the appropriate information. In addition, scale-aware enrichment module (SEM) based on the features extracted from backbone is utilized to obtain rich scale information and generate diverse initial features with dilated convolutions. Extensive quantitative and qualitative experiments demonstrate that the proposed intuitive framework outperforms 14 state-of-the-art approaches on 5 public datasets.",
        "primary_area": "Computer Vision II",
        "author": "Mingcan Ma; Changqun Xia; Jia Li",
        "authorids": "",
        "aff": "State Key Laboratory of Virtual Reality Technology and Systems, SCSE, Beihang University, Beijing, China Pengcheng Laboratory, Shenzhen, China; Pengcheng Laboratory, Shenzhen, China; State Key Laboratory of Virtual Reality Technology and Systems, SCSE, Beihang University, Beijing, China Pengcheng Laboratory, Shenzhen, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16331/16331-13-19825-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02311-pyramidal-feature-shrinking-for-salient-object-detection/",
        "doi": "10.1609/aaai.v35i3.16331",
        "pdf_size": 1091621
    },
    {
        "id": "06480",
        "title": "Quantification of Resource Production Incompleteness",
        "track": "main",
        "status": "Poster",
        "abstract": "In a situation where an agent has to produce specific resources using the available ones, it may not be possible to achieve the complete goal, but only obtaining some of its parts.This incompleteness problem calls for reasoning models to make rational decisions. In this paper, we introduce a logic-based framework for measuring resource production incompleteness: the greater the value returned by a measure, the greater is the intensity of incompleteness. After motivating our work  by describing situations where the incompleteness measures can be applied, we introduce our framework by  using a postulate-based approach. To some extent, the incompleteness measures can be seen as a counterpart  of inconsistency measures in resource logics.  Here, intuitionistic affine logic is used  for representing and reasoning about resource consummation and production. Besides,  we propose different  notions that are useful for defining different types of incompleteness measures. We also present several  measures to illustrate the  introduced concepts and notions.",
        "primary_area": "Knowledge Representation and Reasoning",
        "author": "Yakoub Salhi",
        "authorids": "",
        "aff": "CRIL, U. Artois & CNRS, Lens, France",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16803/16803-13-20297-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06480-quantification-of-resource-production-incompleteness/",
        "doi": "10.1609/aaai.v35i7.16803",
        "pdf_size": 166905
    },
    {
        "id": "00827",
        "title": "Quantum Cognitively Motivated Decision Fusion for Video Sentiment Analysis",
        "track": "main",
        "status": "Poster",
        "abstract": "Video sentiment analysis as a decision-making process is inherently complex, involving the fusion of decisions from multiple modalities and the so-caused cognitive biases. Inspired by recent advances in quantum cognition, we show that the sentiment judgment from one modality could be incompatible with the judgment from another, i.e., the order matters and they cannot be jointly measured to produce a final decision. Thus the cognitive process exhibits ``quantum-like'' biases that cannot be captured by classical probability theories. Accordingly, we propose a fundamentally new, quantum cognitively motivated fusion strategy for predicting sentiment judgments. In particular, we formulate utterances as quantum superposition states of positive and negative sentiment judgments, and uni-modal classifiers as mutually incompatible observables, on a complex-valued Hilbert space with positive-operator valued measures. Experiments on two benchmarking datasets illustrate that our model significantly outperforms various existing decision level and a range of state-of-the-art content-level fusion approaches. The results also show that the concept of incompatibility allows effective handling of all combination patterns, including those extreme cases that are wrongly predicted by all uni-modal classifiers.",
        "primary_area": "Cognitive Modeling and Cognitive Systems",
        "author": "Dimitris Gkoumas; Qiuchi Li; Shahram Dehdashti; Massimo Melucci; Yijun Yu; Dawei Song",
        "authorids": "",
        "aff": "The Open University, Milton Keynes, UK; University of Padua, Padua, Italy; Queensland University of Technology, Brisbane, Australia; University of Padua, Padua, Italy; The Open University, Milton Keynes, UK; The Open University, Milton Keynes, UK",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16165/16165-13-19659-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00827-quantum-cognitively-motivated-decision-fusion-for-video-sentiment-analysis/",
        "doi": "10.1609/aaai.v35i1.16165",
        "pdf_size": 238412
    },
    {
        "id": "10102",
        "title": "Quantum Exploration Algorithms for Multi-Armed Bandits",
        "track": "main",
        "status": "Poster",
        "abstract": "Identifying the best arm of a multi-armed bandit is a central problem in bandit optimization. We study a quantum computational version of this problem with coherent oracle access to states encoding the reward probabilities of each arm as quantum amplitudes. Specifically, we provide an algorithm to find the best arm with fixed confidence based on variable-time amplitude amplification and estimation. This algorithm gives a quadratic speedup compared to the best possible classical result in terms of query complexity. We also prove a matching quantum lower bound (up to poly-logarithmic factors).",
        "primary_area": "Machine Learning IV",
        "author": "Daochen Wang; Xuchen You; Tongyang Li; Andrew M. Childs",
        "authorids": "",
        "aff": "University of Maryland; University of Maryland; University of Maryland Massachusetts Institute of Technology; University of Maryland",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17212/17212-13-20706-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10102-quantum-exploration-algorithms-for-multi-armed-bandits/",
        "doi": "10.1609/aaai.v35i11.17212",
        "pdf_size": 171590
    },
    {
        "id": "13270",
        "title": "Quantum-inspired Neural Network for Conversational Emotion Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "We provide a novel perspective on conversational emotion recognition by drawing an analogy between the task and a complete span of quantum measurement. We characterize different steps of quantum measurement in the process of recognizing speakers' emotions in conversation, and stitch them up with a quantum-like neural network. The quantum-like layers are implemented by complex-valued operations to ensure an authentic adoption of quantum concepts, which naturally enables conversational context modeling and multimodal fusion. We borrow an existing algorithm to learn the complex-valued network weights, so that the quantum-like procedure is conducted in a data-driven manner. Our model is comparable to state-of-the-art approaches on two benchmarking datasets, and provide a quantum view to understand conversational emotion recognition.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Qiuchi Li; Dimitris Gkoumas; Alessandro Sordoni; Jian-Yun Nie; Massimo Melucci",
        "authorids": "",
        "aff": "University of Padua; The Open University; Microsoft Research; Universit\u00e9 de Montr\u00e9al; University of Padua",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17567/17567-13-21061-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13270-quantum-inspired-neural-network-for-conversational-emotion-recognition/",
        "doi": "10.1609/aaai.v35i15.17567",
        "pdf_size": 395327
    },
    {
        "id": "08252",
        "title": "Query Training: Learning a Worse Model to Infer Better Marginals in Undirected Graphical Models with Hidden Variables",
        "track": "main",
        "status": "Poster",
        "abstract": "Probabilistic graphical models (PGMs) provide a compact representation of knowledge that can be queried in a flexible way: after learning the parameters of a graphical model once, new probabilistic queries can be answered at test time without retraining. However, when using undirected PGMS with hidden variables, two sources of error typically compound in all but the simplest models (a) learning error (both computing the partition function and integrating out the hidden variables is intractable); and (b) prediction error (exact inference is also intractable). Here we introduce query training (QT), a mechanism to learn a PGM that is optimized for the approximate inference algorithm that will be paired with it. The resulting PGM is a worse model of the data (as measured by the likelihood), but it is tuned to produce better marginals for a given inference algorithm. Unlike prior works, our approach preserves the querying flexibility of the original PGM: at test time, we can estimate the marginal of any variable given any partial evidence. We demonstrate experimentally that QT can be used to learn a challenging 8-connected grid Markov random field with hidden variables and that it consistently outperforms the state-of-the-art AdVIL when tested on three undirected models across multiple datasets.",
        "primary_area": "Machine Learning II",
        "author": "Miguel L\u00e1zaro-Gredilla; Wolfgang Lehrach; Nishad Gothoskar; Guangyao Zhou; Antoine Dedieu; Dileep George",
        "authorids": "",
        "aff": "Vicarious AI; Vicarious AI; MIT; Vicarious AI; Vicarious AI; Vicarious AI",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17004/17004-13-20498-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08252-query-training-learning-a-worse-model-to-infer-better-marginals-in-undirected-graphical-models-with-hidden-variables/",
        "doi": "10.1609/aaai.v35i9.17004",
        "pdf_size": 423420
    },
    {
        "id": "02038",
        "title": "Query-Memory Re-Aggregation for Weakly-supervised Video Object Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "Weakly-supervised video object segmentation (WVOS) is an emerging video task that can track and segment the target given a simple bounding box label. However, existing WVOS methods are still unsatisfied in either speed or accuracy, since they only use the exemplar frame to guide the prediction while they neglect the reference from other frames. To solve the problem, we propose a novel Re-Aggregation based framework, which uses feature matching to efficiently find the target and capture the temporal dependencies from multiple frames to guide the segmentation. Based on a two-stage structure, our framework builds an information-symmetric matching process to achieve robust aggregation. In each stage, we design a Query-Memory Aggregation (QMA) module to gather features from the past frames and make bidirectional aggregation to adaptively weight the aggregated features, which relieves the latent misguidance in unidirectional aggregation. To further exploit the information from different aggregation stages, we propose a novel coarse-fine constraint by using the Cascaded Refinement Module (CRM) to combine the predictions from different stages and further boosts the performance. Experimental results on three benchmarks show that our method achieves the state-of-the-art performance in WVOS (e.g., an overall score of 84.7% on the DAVIS 2016 validation set).",
        "primary_area": "Computer Vision II",
        "author": "Fanchao Lin; Hongtao Xie; Yan Li; Yongdong Zhang",
        "authorids": "",
        "aff": "School of Information Science and Technology, University of Science and Technology of China, Hefei, China; School of Information Science and Technology, University of Science and Technology of China, Hefei, China; Beijing Kuaishou Technology Co., Ltd., Beijing, China School of Information Science and Technology, University of Science and Technology of China, Hefei, China; School of Information Science and Technology, University of Science and Technology of China, Hefei, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16300/16300-13-19794-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02038-query-memory-re-aggregation-for-weakly-supervised-video-object-segmentation/",
        "doi": "10.1609/aaai.v35i3.16300",
        "pdf_size": 6629983
    },
    {
        "id": "12875",
        "title": "Question-Driven Span Labeling Model for Aspect\u2013Opinion Pair Extraction",
        "track": "main",
        "status": "Poster",
        "abstract": "Aspect term extraction and opinion word extraction are two fundamental subtasks of aspect-based sentiment analysis. The internal relationship between aspect terms and opinion words is typically ignored, and information for the decision-making of buyers and sellers is insufficient. In this paper, we explore an aspect\u2013opinion pair extraction (AOPE) task and propose a Question-Driven Span Labeling (QDSL) model to extract all the aspect\u2013opinion pairs from user-generated reviews. Specifically, we divide the AOPE task into aspect term extraction (ATE) and aspect-specified opinion extraction (ASOE) subtasks; we first extract all the candidate aspect terms and then the corresponding opinion words given the aspect term. Unlike existing approaches that use the BIO-based tagging scheme for extraction, the QDSL model adopts a span-based tagging scheme and builds a question\u2013answer-based machine-reading comprehension task for an effective aspect\u2013opinion pair extraction. Extensive experiments conducted on three tasks (ATE, ASOE, and AOPE) on four benchmark datasets demonstrate that the proposed method significantly outperforms state-of-the-art approaches.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Lei Gao; Yulong Wang; Tongcun Liu; Jingyu Wang; Lei Zhang; Jianxin Liao",
        "authorids": "",
        "aff": "State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications EBUPT Information Technology Co., Ltd.; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications EBUPT Information Technology Co., Ltd.; School of Information Engineering, Zhejiang A&F University EBUPT Information Technology Co., Ltd.; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications EBUPT Information Technology Co., Ltd.; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications EBUPT Information Technology Co., Ltd.; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications EBUPT Information Technology Co., Ltd.",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17523/17523-13-21017-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12875-question-driven-span-labeling-model-for-aspect-opinion-pair-extraction/",
        "doi": "10.1609/aaai.v35i14.17523",
        "pdf_size": 729330
    },
    {
        "id": "00461",
        "title": "Queue-Learning: A Reinforcement Learning Approach for Providing Quality of Service",
        "track": "main",
        "status": "Poster",
        "abstract": "End-to-end delay is a critical attribute of quality of service (QoS) in application domains such as cloud computing and computer networks. This metric is particularly important in tandem service systems, where the end-to-end service is provided through a chain of services. Service-rate control is a common mechanism for providing QoS guarantees in service systems. In this paper, we introduce a reinforcement learning-based (RL-based) service-rate controller that provides probabilistic upper-bounds on the end-to-end delay of the system, while preventing the overuse of service resources. In order to have a general framework, we use queueing theory to model the service systems. However, we adopt an RL-based approach to avoid the limitations of queueing-theoretic methods. In particular, we use Deep Deterministic Policy Gradient (DDPG) to learn the service rates (action) as a function of the queue lengths (state) in tandem service systems. In contrast to existing RL-based methods that quantify their performance by the achieved overall reward, which could be hard to interpret or even misleading, our proposed controller provides explicit probabilistic guarantees on the end-to-end delay of the system. The evaluations are presented for a tandem queueing system with non-exponential inter-arrival and service times, the results of which validate our controller's capability in meeting QoS constraints.",
        "primary_area": "Application Domains",
        "author": "Majid Raeis; Ali Tizghadam; Alberto Leon-Garcia",
        "authorids": "",
        "aff": "University of Toronto, Canada; University of Toronto, Canada; University of Toronto, Canada",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16123/16123-13-19617-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00461-queue-learning-a-reinforcement-learning-approach-for-providing-quality-of-service/",
        "doi": "10.1609/aaai.v35i1.16123",
        "pdf_size": 370085
    },
    {
        "id": "03163",
        "title": "R3Det: Refined Single-Stage Detector with Feature Refinement for Rotating Object",
        "track": "main",
        "status": "Poster",
        "abstract": "Rotation detection is a challenging task due to the difficulties of locating the multi-angle objects and separating them effectively from the background. Though considerable progress has been made, for practical settings, there still exist challenges for rotating objects with large aspect ratio, dense distribution and category extremely imbalance. In this paper, we propose an end-to-end refined single-stage rotation detector for fast and accurate object detection by using a progressive regression approach from coarse to fine granularity. Considering the shortcoming of feature misalignment in existing refined single-stage detector, we design a feature refinement module to improve detection performance by getting more accurate features. The key idea of feature refinement module is to re-encode the position information of the current refined bounding box to the corresponding feature points through pixel-wise feature interpolation to realize feature reconstruction and alignment. For more accurate rotation estimation, an approximate SkewIoU loss is proposed to solve the problem that the calculation of SkewIoU is not derivable. Experiments on three popular remote sensing public datasets DOTA, HRSC2016, UCAS-AOD as well as one scene text dataset ICDAR2015 show the effectiveness of our approach. The source code is available at https://github.com/Thinklab-SJTU/R3Det_Tensorflow and is also integrated in our open source rotation detection benchmark: https://github.com/yangxue0827/RotationDetection.",
        "primary_area": "Computer Vision III",
        "author": "Xue Yang; Junchi Yan; Ziming Feng; Tao He",
        "authorids": "",
        "aff": "Department of Computer Science and Engineering, Shanghai Jiao Tong University MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University; Department of Computer Science and Engineering, Shanghai Jiao Tong University MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University; China Merchants Bank Credit Card Center; Anhui COWAROBOT CO., Ltd. Anhui Provincial Key Laboratory of Multimodal Cognitive Computation",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16426/16426-13-19920-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03163-r3det-refined-single-stage-detector-with-feature-refinement-for-rotating-object/",
        "doi": "10.1609/aaai.v35i4.16426",
        "pdf_size": 5830186
    },
    {
        "id": "02477",
        "title": "REFINE: Prediction Fusion Network for Panoptic Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "Panoptic segmentation aims at generating pixel-wise class and instance predictions for each pixel in the input image, which is a challenging task and far more complicated than naively fusing the semantic and instance segmentation results. Prediction fusion is therefore important to achieve accurate panoptic segmentation. In this paper, we present REFINE, pREdiction FusIon NEtwork for panoptic segmentation, to achieve high-quality panoptic segmentation by improving cross-task prediction fusion, and within-task prediction fusion. Our single-model ResNeXt-101 with DCN achieves PQ=51.5 on the COCO dataset, surpassing state-of-the-art performance by a convincing margin and is comparable with ensembled models. Our smaller model with a ResNet-50 backbone achieves PQ=44.9, which is comparable with state-of-the-art methods with larger backbones.",
        "primary_area": "Computer Vision II",
        "author": "Jiawei Ren; Cunjun Yu; Zhongang Cai; Mingyuan Zhang; Chongsong Chen; Haiyu Zhao; Shuai Yi; Hongsheng Li",
        "authorids": "",
        "aff": "SenseTime Research; SenseTime Research; SenseTime Research; SenseTime Research; SenseTime Research Nanyang Technological University; SenseTime Research; SenseTime Research; Multimedia Laboratory, The Chinese University of Hong Kong",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16349/16349-13-19843-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02477-refine-prediction-fusion-network-for-panoptic-segmentation/",
        "doi": "10.1609/aaai.v35i3.16349",
        "pdf_size": 1597585
    },
    {
        "id": "06375",
        "title": "REM-Net: Recursive Erasure Memory Network for Commonsense Evidence Refinement",
        "track": "main",
        "status": "Poster",
        "abstract": "When answering a question, people often draw upon their rich world knowledge in addition to the particular context. While recent works retrieve supporting facts/evidence from commonsense knowledge bases to supply additional information to each question, there is still ample opportunity to advance it on the quality of the evidence. It is crucial since the quality of the evidence is the key to answering common- sense questions, and even determines the upper bound on the QA systems\u2019 performance. In this paper, we propose a recursive erasure memory network (REM-Net) to cope with the quality improvement of evidence. To address this, REM-Net is equipped with a module to refine the evidence by recursively erasing the low-quality evidence that does not explain the question answering. Besides, instead of retrieving evidence from existing knowledge bases, REM-Net leverages a pre-trained generative model to generate candidate evidence customized for the question. We conduct experiments on two commonsense question answering datasets, WIQA and CosmosQA. The results demonstrate the performance of REM- Net and show that the refined evidence is explainable.",
        "primary_area": "Knowledge Representation and Reasoning",
        "author": "Yinya Huang; Meng Fang; Xunlin Zhan; Qingxing Cao; Xiaodan Liang",
        "authorids": "",
        "aff": "Sun Yat-Sen University; Tencent; Sun Yat-Sen University; Sun Yat-Sen University; Sun Yat-sen University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16791/16791-13-20285-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06375-rem-net-recursive-erasure-memory-network-for-commonsense-evidence-refinement/",
        "doi": "10.1609/aaai.v35i7.16791",
        "pdf_size": 748460
    },
    {
        "id": "03547",
        "title": "RESA: Recurrent Feature-Shift Aggregator for Lane Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Lane detection is one of the most important tasks in self-driving. Due to various complex scenarios (e.g., severe occlusion, ambiguous lanes, etc.) and the sparse supervisory signals inherent in lane annotations, lane detection task is still challenging. Thus, it is difficult for the ordinary convolutional neural network (CNN) to train in general scenes to catch subtle lane feature from the raw image. In this paper, we present a novel module named REcurrent Feature-Shift Aggregator (RESA) to enrich lane feature after preliminary feature extraction with an ordinary CNN. RESA takes advantage of strong shape priors of lanes and captures spatial relationships of pixels across rows and columns. It shifts sliced feature map recurrently in vertical and horizontal directions and enables each pixel to gather global information. RESA can conjecture lanes accurately in challenging scenarios with weak appearance clues by aggregating sliced feature map. Moreover, we propose a Bilateral Up-Sampling Decoder that combines coarse-grained and fine-detailed features in the up-sampling stage. It can recover the low-resolution feature map into pixel-wise prediction meticulously. Our method achieves state-of-the-art results on two popular lane detection benchmarks (CULane and Tusimple). Code has been made available at: https://github.com/ZJULearning/resa.",
        "primary_area": "Computer Vision III",
        "author": "Tu Zheng; Hao Fang; Yi Zhang; Wenjian Tang; Zheng Yang; Haifeng Liu; Deng Cai",
        "authorids": "",
        "aff": "Zhejiang University Fabu Inc., Hangzhou, China; Zhejiang University; Zhejiang University; Fabu Inc., Hangzhou, China; Fabu Inc., Hangzhou, China; Zhejiang University; Zhejiang University Fabu Inc., Hangzhou, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16469/16469-13-19963-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03547-resa-recurrent-feature-shift-aggregator-for-lane-detection/",
        "doi": "10.1609/aaai.v35i4.16469",
        "pdf_size": 416750
    },
    {
        "id": "01063",
        "title": "RGB-D Salient Object Detection via 3D Convolutional Neural Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "RGB-D salient object detection (SOD) recently has attracted increasing research interest and many deep learning methods based on encoder-decoder architectures have emerged. However, most existing RGB-D SOD models conduct feature fusion either in the single encoder or the decoder stage, which hardly guarantees sufficient cross-modal fusion ability. In this paper, we make the first attempt in addressing RGB-D SOD through 3D convolutional neural networks. The proposed model, named RD3D, aims at pre-fusion in the encoder stage and in-depth fusion in the decoder stage to effectively promote the full integration of RGB and depth streams. Specifically, RD3D first conducts pre-fusion across RGB and depth modalities through an inflated 3D encoder, and later provides in-depth feature fusion by designing a 3D decoder equipped with rich back-projection paths (RBPP) for leveraging the extensive aggregation ability of 3D convolutions. With such a progressive fusion strategy involving both the encoder and decoder, effective and thorough interaction between the two modalities can be exploited and boost the detection accuracy. Extensive experiments on six widely used benchmark datasets demonstrate that RD3D performs favorably against 14 state-of-the-art RGB-D SOD approaches in terms of four key evaluation metrics. Our code will be made publicly available: https://github.com/PPOLYpubki/RD3D.",
        "primary_area": "Computer Vision I",
        "author": "Qian Chen; Ze Liu; Yi Zhang; Keren Fu; Qijun Zhao; Hongwei Du",
        "authorids": "",
        "aff": "University of Science and Technology of China; University of Science and Technology of China; INSA Rennes; Sichuan University; Sichuan University; University of Science and Technology of China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16191/16191-13-19685-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01063-rgb-d-salient-object-detection-via-3d-convolutional-neural-networks/",
        "doi": "10.1609/aaai.v35i2.16191",
        "pdf_size": 788606
    },
    {
        "id": "00362",
        "title": "RNA Secondary Structure Representation Network for RNA-proteins Binding Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "RNA-binding proteins (RBPs) play a significant part in several biological processes in the living cell, such as gene regulation and mRNA localization. Several deep learning methods, especially the model based on convolutional neural network(CNN), have been used to predict the binding sites. However, previous methods fail to represent RNA secondary structure features. The traditional deep learning methods generally transform the RNA secondary structure to a regular matrix that cannot reveal the topological structure information of RNA. To effectively extract the structure features of RNA, we propose an RNA secondary structure representation network (RNASSR-Net) based on graph convolutional neural network (GCN) and convolution neural network (CNN) for RBP binding prediction. RNASSR-Net constructs the graph model derived from the RNA secondary structure to learn the topological properties of RNA. Then, it obtains the spatial importance of each base in RNA with CNN to guide the representation of the RNA secondary structure. Finally, RNASSR-Net combines the structure and sequence features to predict the binding sites. Experimental results demonstrate the proposed method outperforms a few state-of-the-art methods on the benchmark datasets and gets a higher improvement on the small-size data. Besides, the proposed RNASSR-Net is also used to detect the accurate motifs compared with the experimentally verified motifs, which reveals the binding region location and RNA structure interpretation for some biological guidance in the future.",
        "primary_area": "Application Domains",
        "author": "Ziyi Liu; Fulin Luo; Bo Du",
        "authorids": "",
        "aff": "Wuhan University; Wuhan University; Wuhan University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16112/16112-13-19606-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00362-rna-secondary-structure-representation-network-for-rna-proteins-binding-prediction/",
        "doi": "10.1609/aaai.v35i1.16112",
        "pdf_size": 3276283
    },
    {
        "id": "08715",
        "title": "ROSITA: Refined BERT cOmpreSsion with InTegrAted techniques",
        "track": "main",
        "status": "Poster",
        "abstract": "Pre-trained language models of the BERT family have defined the state-of-the-arts in a wide range of NLP tasks. However, the performance of BERT-based models is mainly driven by the enormous amount of parameters, which hinders their application to resource-limited scenarios. Faced with this problem, recent studies have been attempting to compress BERT into a small-scale model. However, most previous work primarily focuses on a single kind of compression technique, and few attention has been paid to the combination of different methods. When BERT is compressed with integrated techniques, a critical question is how to design the entire compression framework to obtain the optimal performance. In response to this question, we integrate three kinds of compression methods (weight pruning, low-rank factorization and knowledge distillation (KD)) and explore a range of designs concerning model architecture, KD strategy, pruning frequency and learning rate schedule. We find that a careful choice of the designs is crucial to the performance of the compressed model. Based on the empirical findings, our best compressed model, dubbed Refined BERT cOmpreSsion with InTegrAted techniques (ROSITA), is 7.5x smaller than BERT while maintains 98.5% of the performance on five tasks of the GLUE benchmark, outperforming the previous BERT compression methods with similar parameter budget.",
        "primary_area": "Machine Learning III",
        "author": "Yuanxin Liu; Zheng Lin; Fengcheng Yuan",
        "authorids": "",
        "aff": "Institute of Information Engineering, Chinese Academy of Sciences; School of Cyber Security, University of Chinese Academy of Sciences; Institute of Information Engineering, Chinese Academy of Sciences; Meituan Inc",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17056/17056-13-20550-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08715-rosita-refined-bert-compression-with-integrated-techniques/",
        "doi": "10.1609/aaai.v35i10.17056",
        "pdf_size": 873631
    },
    {
        "id": "01193",
        "title": "RSGNet: Relation based Skeleton Graph Network for Crowded Scenes Pose Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Despite of the recent great progress on multi-person pose estimation, existing solutions still remain challenging under the condition of  \"crowded scenes'', where RGB images capture complex real-world scenes with highly-overlapped people, severe occlusions and diverse postures. In this work, we focus on two main problems: 1) how to design an effective pipeline for crowded scenes pose estimation; and 2) how to equip this pipeline with the ability of relation modeling for interference resolving. To tackle these problems, we propose a new pipeline named Relation based Skeleton Graph Network (RSGNet). Unlike existing works that directly predict joints-of-target by labeling joints-of-interference as false positive, we first encourage all joints to be predicted. And then, a Target-aware Relation Parser (TRP) is designed to model the relation over all predicted joints, resulting in a target-aware encoding. This new pipeline will largely relieve the confusion of the joints estimation model when seeing identical joints with totally distinct labels (e.g., the identical hand exists in two bounding boxes). Furthermore, we introduce a Skeleton Graph Machine (SGM) to model the skeleton-based commonsense knowledge, aiming to estimate the target pose with the constraint of human body structure. Such skeleton-based constraint can help to deal with the challenges in crowded scenes from a reasoning perspective. Solid experiments on pose estimation benchmarks demonstrate that our method outperforms existing state-of-the-art methods.",
        "primary_area": "Computer Vision I",
        "author": "Yan Dai; Xuanhan Wang; Lianli Gao; Jingkuan Song; Heng Tao Shen",
        "authorids": "",
        "aff": "University of Electronic Science and Technology of China; University of Electronic Science and Technology of China; University of Electronic Science and Technology of China; University of Electronic Science and Technology of China, Key Laboratory of Artificial Intelligence, Ministry of Education; University of Electronic Science and Technology of China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16206/16206-13-19700-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01193-rsgnet-relation-based-skeleton-graph-network-for-crowded-scenes-pose-estimation/",
        "doi": "10.1609/aaai.v35i2.16206",
        "pdf_size": 1089770
    },
    {
        "id": "01045",
        "title": "RSPNet: Relative Speed Perception for Unsupervised Video Representation Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "We study unsupervised video representation learning that seeks to learn both motion and appearance features from unlabeled video only, which can be reused for downstream tasks such as action recognition. This task, however, is extremely challenging due to 1) the highly complex spatial-temporal information in videos and 2) the lack of labeled data for training. Unlike representation learning for static images, it is difficult to construct a suitable self-supervised task to effectively model both motion and appearance features. More recently, several attempts have been made to learn video representation through video playback speed prediction. However, it is non-trivial to obtain precise speed labels for the videos. More critically, the learned models may tend to focus on motion patterns and thus may not learn appearance features well. In this paper, we observe that the relative playback speed is more consistent with motion patterns and thus provides more effective and stable supervision for representation learning. Therefore, we propose a new way to perceive the playback speed and exploit the relative speed between two video clips as labels. In this way, we are able to effectively perceive speed and learn better motion features. Moreover, to ensure the learning of appearance features, we further propose an appearance-focused task, where we enforce the model to perceive the appearance difference between two video clips. We show that jointly optimizing the two tasks consistently improves the performance on two downstream tasks (namely, action recognition and video retrieval) w.r.t the increasing pre-training epochs. Remarkably, for action recognition on the UCF101 dataset, we achieve 93.7% accuracy without the use of labeled data for pre-training, which outperforms the ImageNet supervised pre-trained model. Our code, pre-trained models, and supplementary materials can be found at https://github.com/PeihaoChen/RSPNet.",
        "primary_area": "Computer Vision I",
        "author": "Peihao Chen; Deng Huang; Dongliang He; Xiang Long; Runhao Zeng; Shilei Wen; Mingkui Tan; Chuang Gan",
        "authorids": "",
        "aff": "School of Software Engineering, South China University of Technology Pazhou Laboratory; School of Software Engineering, South China University of Technology; Baidu Inc.; Baidu Inc.; School of Software Engineering, South China University of Technology; Baidu Inc.; School of Software Engineering, South China University of Technology Key Laboratory of Big Data and Intelligent Robot, Ministry of Education; MIT-IBM Watson AI Lab",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16189/16189-13-19683-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01045-rspnet-relative-speed-perception-for-unsupervised-video-representation-learning/",
        "doi": "10.1609/aaai.v35i2.16189",
        "pdf_size": 1490171
    },
    {
        "id": "09179",
        "title": "RT3D: Achieving Real-Time Execution of 3D Convolutional Neural Networks on Mobile Devices",
        "track": "main",
        "status": "Poster",
        "abstract": "Mobile devices are becoming an important carrier for deep learning tasks, as they are being equipped with powerful, high-end mobile CPUs and GPUs. However, it is still a challenging task to execute 3D Convolutional Neural Networks (CNNs) targeting for real-time performance, besides high inference accuracy. The reason is more complex model structure and higher model dimensionality overwhelm the available computation/storage resources on mobile devices. A natural way may be turning to deep learning weight pruning techniques. However, the direct generalization of existing 2D CNN weight pruning methods to 3D CNNs is not ideal for fully exploiting mobile parallelism while achieving high inference accuracy.  This paper proposes RT3D, a model compression and mobile acceleration framework for 3D CNNs, seamlessly integrating neural network weight pruning and compiler code generation techniques. We propose and investigate two structured sparsity schemes i.e., the vanilla structured sparsity and kernel group structured (KGS) sparsity that are mobile acceleration friendly. The vanilla sparsity removes whole kernel groups, while KGS sparsity is a more fine-grained structured sparsity that enjoys higher flexibility while exploiting full on-device parallelism. We propose a reweighted regularization pruning algorithm to achieve the proposed sparsity schemes. The inference time speedup due to sparsity is approaching the pruning rate of the whole model FLOPs (floating point operations). RT3D demonstrates up to 29.1x speedup in end-to-end inference time comparing with current mobile frameworks supporting 3D CNNs, with moderate 1%~1.5% accuracy loss. The end-to-end inference time for 16 video frames could be within 150 ms, when executing representative C3D and R(2+1)D models on a cellphone. For the first time, real-time execution of 3D CNNs is achieved on off-the-shelf mobiles.",
        "primary_area": "Machine Learning III",
        "author": "Wei Niu; Mengshu Sun; Zhengang Li; Jou-An Chen; Jiexiong Guan; Xipeng Shen; Yanzhi Wang; Sijia Liu; Xue Lin; Bin Ren",
        "authorids": "",
        "aff": "William & Mary; Northeastern University; Northeastern University; North Carolina State University; William & Mary; North Carolina State University; Northeastern University; Michigan State University; Northeastern University; William & Mary",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17108/17108-13-20602-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09179-rt3d-achieving-real-time-execution-of-3d-convolutional-neural-networks-on-mobile-devices/",
        "doi": "10.1609/aaai.v35i10.17108",
        "pdf_size": 469585
    },
    {
        "id": "01930",
        "title": "RTS3D: Real-time Stereo 3D Detection from 4D Feature-Consistency Embedding Space for Autonomous Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "Although the recent image-based 3D object detection methods using Pseudo-LiDAR representation have shown great capabilities, a notable gap in efficiency and accuracy still exist compared with LiDAR-based methods. Besides, over-reliance on the stand-alone depth estimator, requiring a large number of pixel-wise annotations in the training stage and more computation in the inferencing stage, limits the scaling application in the real world. In this paper, we propose an efficient and accurate 3D object detection method from stereo images, named RTS3D. Different from the 3D occupancy space in the Pseudo-LiDAR similar methods, we design a novel 4D feature-consistent embedding (FCE) space as the intermediate representation of the 3D scene without depth supervision. The FCE space encodes the object's structural and semantic information by exploring the multi-scale feature consistency warped from stereo pair. Furthermore, a semantic-guided RBF (Radial Basis Function) and a structure-aware attention module are devised to reduce the influence of FCE space noise without instance mask supervision. Experiments on KITTI benchmark show that RTS3D is the first true real-time system (FPS>24) for stereo image 3D detection meanwhile achieves 10% improvement in average precision comparing with the previous state-of-the-art method.",
        "primary_area": "Computer Vision II",
        "author": "Peixuan Li; Shun Su; Huaici Zhao",
        "authorids": "",
        "aff": "Shenyang Institute of Automation,Chinese Academy of Sciences,Shenyang 11016, China; Institutes for Robotics and Intelligent Manufacturing, Chinese Academy of Sciences, Shenyang 110169, China; University of Chinese Academy of Sciences, Beijing 100049, China; Key Laboratory of Opto-Electronic Information Processing, Chinese Academy of Sciences; Key Lab of Image Understanding and Computer Vision, Liaoning Province; Shenyang Institute of Automation,Chinese Academy of Sciences,Shenyang 11016, China; Institutes for Robotics and Intelligent Manufacturing, Chinese Academy of Sciences, Shenyang 110169, China; University of Chinese Academy of Sciences, Beijing 100049, China; State Key Laboratory of Robotics, Shenyang Institute of Automation, Chinese Academy of Sciences, Shenyang 110016, China; Shenyang Institute of Automation,Chinese Academy of Sciences,Shenyang 11016, China; Institutes for Robotics and Intelligent Manufacturing, Chinese Academy of Sciences, Shenyang 110169, China; Key Laboratory of Opto-Electronic Information Processing, Chinese Academy of Sciences; Key Lab of Image Understanding and Computer Vision, Liaoning Province",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16288/16288-13-19782-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01930-rts3d-real-time-stereo-3d-detection-from-4d-feature-consistency-embedding-space-for-autonomous-driving/",
        "doi": "10.1609/aaai.v35i3.16288",
        "pdf_size": 2266664
    },
    {
        "id": "01352",
        "title": "Rain Streak Removal via Dual Graph Convolutional Network",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep convolutional neural networks (CNNs) have become dominant in the single image de-raining area. However, most deep CNNs-based de-raining methods are designed by stacking vanilla convolutional layers, which can only be used to model local relations. Therefore, long-range contextual information is rarely considered for this specific task. To address the above problem, we propose a simple yet effective dual graph convolutional network (GCN) for single image rain removal. Specifically, we design two graphs to perform global relational modeling and reasoning. The first GCN is used to explore global spatial relations among pixels in feature maps, while the second GCN models the global relations across the channels. Compared to standard convolutional operations, the proposed two graphs enable the network to extract representations from new dimensions. To achieve the image rain removal, we further embed these two graphs and multi-scale dilated convolution into a symmetrically skip-connected network architecture. Therefore, our dual graph convolutional network is able to well handle complex and spatially long rain streaks by exploring multiple representations, e.g., multi-scale local feature, global spatial coherence and cross-channel correlation. Meanwhile, our model is easy to implement, end-to-end trainable and computationally efficient. Extensive experiments on synthetic and real data demonstrate that our method achieves significant improvements over the recent state-of-the-art methods.",
        "primary_area": "Computer Vision I",
        "author": "Xueyang Fu; Qi Qi; Zheng-Jun Zha; Yurui Zhu; Xinghao Ding",
        "authorids": "",
        "aff": "University of Science and Technology of China; Xiamen University; University of Science and Technology of China; University of Science and Technology of China; Xiamen University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16224/16224-13-19718-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01352-rain-streak-removal-via-dual-graph-convolutional-network/",
        "doi": "10.1609/aaai.v35i2.16224",
        "pdf_size": 12256693
    },
    {
        "id": "04155",
        "title": "Randomized Generation of Adversary-aware Fake Knowledge Graphs to Combat Intellectual Property Theft",
        "track": "main",
        "status": "Poster",
        "abstract": "Knowledge Graphs (KGs) can be used to store information about software design, biomedical designs, and financial information---all domains where intellectual property and/or specialized knowledge must be kept confidential. Moreover, KGs can also be used to represent the content of technical documents. In order to deter theft of intellectual property via cyber-attacks, we consider the following problem: given a KG K0 (e.g., representing a software or biomedical device design or the content of a technical document), can we automatically generate a set of KGs that are similar enough to K0 (so they are hard to discern as synthetic) but sufficiently different (so as to be wrong)? If this is possible, then we will be one step closer to automatically generating fake KGs that an adversary has difficulty distinguishing from the original. We will also be closer to automatically generating documents corresponding to fake KGs so that an adversary who steals such documents has difficulty distinguishing the real from the fakes. We formally define this problem and prove that it is NP-hard. We show that obvious approaches to solving this problem do not satisfy a novel concept of \"adversary-awareness\" that we define. We provide a graph-theoretic characterization of the problem and leverage it to devise an \"adversary-aware\" algorithm. We validate the efficacy of our algorithm on 3 diverse real-world datasets, showing that it achieves high levels of deception.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Snow Kang; Cristian Molinaro; Andrea Pugliese; V. S. Subrahmanian",
        "authorids": "",
        "aff": "Dartmouth College; University of Calabria; University of Calabria; Dartmouth College",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16538/16538-13-20032-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04155-randomized-generation-of-adversary-aware-fake-knowledge-graphs-to-combat-intellectual-property-theft/",
        "doi": "10.1609/aaai.v35i5.16538",
        "pdf_size": 258346
    },
    {
        "id": "06435",
        "title": "Ranking Sets of Defeasible Elements in Preferential Approaches to Structured Argumentation: Postulates, Relations, and Characterizations",
        "track": "main",
        "status": "Poster",
        "abstract": "Preferences play a key role in computational argumentation in AI, as they reflect various notions of argument strength vital for the representation of argumentation. Within central formal approaches to structured argumentation, preferential approaches are applied by lifting preferences over defeasible elements to rankings over sets of defeasible elements, in order to be able to compare the relative strength of two arguments and their respective defeasible constituents. To overcome the current gap in the scientific landscape, we give in this paper a general study of the critical component of lifting operators in structured argumentation. We survey existing lifting operators scattered in the literature of argumentation theory, social choice, and utility theory, and show fundamental relations and properties of these operators. Extending existing works from argumentation and social choice, we propose a list of postulates for lifting operations, and give a complete picture of (non-)satisfaction for the considered operators. Based on our postulates, we present impossibility results, stating for which sets of postulates there is no hope of satisfaction, and for two main lifting operators presented in structured argumentation, Elitist and Democratic, we give a full characterization in terms of our postulates.",
        "primary_area": "Knowledge Representation and Reasoning",
        "author": "Jan Maly; Johannes P. Wallner",
        "authorids": "",
        "aff": "Institute of Logic and Computation, TU Wien; Institute of Software Technology, Graz University of Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16798/16798-13-20292-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06435-ranking-sets-of-defeasible-elements-in-preferential-approaches-to-structured-argumentation-postulates-relations-and-characterizations/",
        "doi": "10.1609/aaai.v35i7.16798",
        "pdf_size": 138849
    },
    {
        "id": "00453",
        "title": "RareBERT: Transformer Architecture for Rare Disease Patient Identification using Administrative Claims",
        "track": "main",
        "status": "Poster",
        "abstract": "A rare disease is any disease that affects a very small percentage (1 in 1,500) of population. It is estimated that there are nearly 7,000 rare disease affecting 30 million patients in the U. S. alone. Most of the patients suffering from rare diseases experience multiple misdiagnoses and may never be diagnosed correctly. This is largely driven by the low prevalence of the disease that results in a lack of awareness among healthcare providers. There have been efforts from machine learning researchers to develop predictive models to help diagnose patients using healthcare datasets such as electronic health records and administrative claims. Most recently, transformer models have been applied to predict diseases BEHRT, G-BERT and Med-BERT. However, these have been developed specifically for electronic health records (EHR) and have not been designed to address rare disease challenges such as class imbalance, partial longitudinal data capture, and noisy labels. As a result, they deliver poor performance in predicting rare diseases compared with baselines. Besides, EHR datasets are generally confined to the hospital systems using them and do not capture a wider sample of patients thus limiting the availability of sufficient rare dis-ease patients in the dataset. To address these challenges, we introduced an extension of the BERT model tailored for rare disease diagnosis called RareBERT which has been trained on administrative claims datasets. RareBERT extends Med-BERT by including context embedding and temporal reference embedding. Moreover, we introduced a novel adaptive loss function to handle the class imbal-ance. In this paper, we show our experiments on diagnosing X-Linked Hypophosphatemia (XLH), a genetic rare disease. While RareBERT performs significantly better than the baseline models (79.9% AUPRC versus 30% AUPRC for Med-BERT), owing to the transformer architecture, it also shows its robustness in partial longitudinal data capture caused by poor capture of claims with a drop in performance of only 1.35% AUPRC, compared with 12% for Med-BERT and 33.0% for LSTM and 67.4% for boosting trees based baseline.",
        "primary_area": "Application Domains",
        "author": "PKS Prakash; Srinivas Chilukuri; Nikhil Ranade; Shankar Viswanathan",
        "authorids": "",
        "aff": "ZS Associates, Bengaluru 560052, Karnataka, India; ZS Associates, Evanston, IL 60201, US; ZS Associates, Bengaluru 560052, Karnataka, India; ZS Associates, Bengaluru 560052, Karnataka, India",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16122/16122-13-19616-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00453-rarebert-transformer-architecture-for-rare-disease-patient-identification-using-administrative-claims/",
        "doi": "10.1609/aaai.v35i1.16122",
        "pdf_size": 783569
    },
    {
        "id": "09612",
        "title": "Raven\u2019s Progressive Matrices Completion with Latent Gaussian Process Priors",
        "track": "main",
        "status": "Poster",
        "abstract": "Abstract reasoning ability is fundamental to human intelligence. It enables humans to uncover relations among abstract concepts and further deduce implicit rules from the relations. As a well-known abstract visual reasoning task, Raven's Progressive Matrices (RPM) are widely used in human IQ tests. Although extensive research has been conducted on RPM solvers with machine intelligence, few studies have considered further advancing the standard answer-selection (classification) problem to a more challenging answer-painting (generating) problem, which can verify whether the model has indeed understood the implicit rules. In this paper we aim to solve the latter one by proposing a deep latent variable model, in which multiple Gaussian processes are employed as priors of latent variables to separately learn underlying abstract concepts from RPMs; thus the proposed model is interpretable in terms of concept-specific latent variables. The latent Gaussian process also provides an effective way of extrapolation for answer painting based on the learned concept-changing rules. We evaluate the proposed model on RPM-like datasets with multiple continuously-changing visual concepts. Experimental results demonstrate that our model requires only few training samples to paint high-quality answers, generate novel RPM panels, and achieve interpretability through concept-specific latent variables.",
        "primary_area": "Machine Learning IV",
        "author": "Fan Shi; Bin Li; Xiangyang Xue",
        "authorids": "",
        "aff": "Fudan University; Fudan University; Fudan University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17157/17157-13-20651-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09612-raven-s-progressive-matrices-completion-with-latent-gaussian-process-priors/",
        "doi": "10.1609/aaai.v35i11.17157",
        "pdf_size": 1809865
    },
    {
        "id": "13843",
        "title": "Re-TACRED: Addressing Shortcomings of the TACRED Dataset",
        "track": "main",
        "status": "Poster",
        "abstract": "TACRED is one of the largest and most widely used sentence-level relation extraction datasets. Proposed models that are evaluated using this dataset consistently set new state-of-the-art performance. However, they still exhibit large error rates despite leveraging external knowledge and unsupervised pretraining on large text corpora. A recent study suggested that this may be due to poor dataset quality. The study observed that over 50% of the most challenging sentences from the development and test sets are incorrectly labeled and account for an average drop of 8% f1-score in model performance. However, this study was limited to a small biased sample of 5k (out of a total of 106k) sentences, substantially restricting the generalizability and broader implications of its findings. In this paper, we address these shortcomings by: (i) performing a comprehensive study over the whole TACRED dataset, (ii) proposing an improved crowdsourcing strategy and deploying it to re-annotate the whole dataset, and (iii) performing a thorough analysis to understand how correcting the TACRED annotations affects previously published results. After verification, we observed that 23.9% of TACRED labels are incorrect. Moreover, evaluating several models on our revised dataset yields an average f1-score improvement of 14.3% and helps uncover significant relationships between the different models (rather than simply offsetting or scaling their scores by a constant factor). Finally, aside from our analysis we also release Re-TACRED, a new completely re-annotated version of the TACRED dataset that can be used to perform reliable evaluation of relation extraction models.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "George Stoica; Emmanouil Antonios Platanios; Barnabas Poczos",
        "authorids": "",
        "aff": "Carnegie Mellon University; Microsoft Semantic Machines; Carnegie Mellon University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17631/17631-13-21125-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13843-re-tacred-addressing-shortcomings-of-the-tacred-dataset/",
        "doi": "10.1609/aaai.v35i15.17631",
        "pdf_size": 138761
    },
    {
        "id": "05211",
        "title": "Reaching Individually Stable Coalition Structures in Hedonic Games",
        "track": "main",
        "status": "Poster",
        "abstract": "The formal study of coalition formation in multiagent systems is typically realized using so-called hedonic games, which originate from economic theory. The main focus of this branch of research has been on the existence and the computational complexity of deciding the existence of coalition structures that satisfy various stability criteria. The actual process of forming coalitions based on individual behavior has received little attention. In this paper, we study the convergence of simple dynamics leading to stable partitions in a variety of classes of hedonic games, including anonymous, dichotomous, fractional, and hedonic diversity games. The dynamics we consider is based on individual stability: an agent will join another coalition if she is better off and no member of the welcoming coalition is worse off. We identify conditions for convergence, provide elaborate counterexamples of existence of individually stable partitions, and study the computational complexity of problems related to the coalition formation dynamics. In particular, we settle open problems suggested by Bogomolnaia and Jackson (2002), Brandl, Brandt, and Strobel (2015), and Boehmer and Elkind (2020).",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Felix Brandt; Martin Bullinger; Ana\u00eblle Wilczynski",
        "authorids": "",
        "aff": "Technische Universit\u00e4t M\u00fcnchen; Technische Universit\u00e4t M\u00fcnchen; CentraleSup\u00e9lec, Universit\u00e9 Paris-Saclay",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16658/16658-13-20152-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05211-reaching-individually-stable-coalition-structures-in-hedonic-games/",
        "doi": "10.1609/aaai.v35i6.16658",
        "pdf_size": 163461
    },
    {
        "id": "12920",
        "title": "Read, Retrospect, Select: An MRC Framework to Short Text Entity Linking",
        "track": "main",
        "status": "Poster",
        "abstract": "Entity linking (EL) for the rapidly growing short text (e.g. search queries and news titles) is critical to industrial applications. Most existing approaches relying on adequate context for long text EL are not effective for the concise and sparse short text. In this paper, we propose a novel framework called Multi-turn Multiple-choice Machine reading comprehension (M3) to solve the short text EL from a new perspective: a query is generated for each ambiguous mention exploiting its surrounding context, and an option selection module is employed to identify the golden entity from candidates using the query. In this way, M3 framework sufficiently interacts limited context with candidate entities during the encoding process, as well as implicitly considers the dissimilarities inside the candidate bunch in the selection stage. In addition, we design a two-stage verifier incorporated into M3 to address the commonly existed unlinkable problem in short text. To further consider the topical coherence and interdependence among referred entities, M3 leverages a multi-turn fashion to deal with mentions in a sequence manner by retrospecting historical cues. Evaluation shows that our M3 framework achieves the state-of-the-art performance on five Chinese and English datasets for the real-world short text EL.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Yingjie Gu; Xiaoye Qu; Zhefeng Wang; Baoxing Huai; Nicholas Jing Yuan; Xiaolin Gui",
        "authorids": "",
        "aff": "Faculty of Electronics and Information Engineering, Xi\u2019an Jiaotong University; Huawei Cloud & AI; Huawei Cloud & AI; Huawei Cloud & AI; Huawei Cloud & AI; Faculty of Electronics and Information Engineering, Xi\u2019an Jiaotong University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17528/17528-13-21022-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12920-read-retrospect-select-an-mrc-framework-to-short-text-entity-linking/",
        "doi": "10.1609/aaai.v35i14.17528",
        "pdf_size": 442715
    },
    {
        "id": "12683",
        "title": "Reasoning in Dialog: Improving Response Generation by Context Reading Comprehension",
        "track": "main",
        "status": "Poster",
        "abstract": "In multi-turn dialog, utterances do not always take the full form of sentences (Carbonell 1983), which naturally makes understanding the dialog context more difficult. However, it is essential to fully grasp the dialog context to generate a reasonable response. Hence, in this paper, we propose to improve the response generation performance by examining the model's ability to answer a reading comprehension question, where the question is focused on the omitted information in the dialog. Enlightened by the multi-task learning scheme, we propose a joint framework that unifies these two tasks, sharing the same encoder to extract the common and task-invariant features with different decoders to learn task-specific features. To better fusing information from the question and the dialog history in the encoding part, we propose to augment the Transformer architecture with a memory updater, which is designed to selectively store and update the history dialog information so as to support downstream tasks. For the experiment, we employ human annotators to write and examine a large-scale dialog reading comprehension dataset. Extensive experiments are conducted on this dataset, and the results show that the proposed model brings substantial improvements over several strong baselines on both tasks. In this way, we demonstrate that reasoning can indeed help better response generation and vice versa. We release our large-scale dataset for further research.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Xiuying Chen; Zhi Cui; Jiayi Zhang; Chen Wei; Jianwei Cui; Bin Wang; Dongyan Zhao; Rui Yan",
        "authorids": "",
        "aff": "Wangxuan Institute of Computer Technology, Peking University,Beijing,China Center for Data Science, AAIS, Peking University,Beijing,China; Xiaomi AI Lab; Xiaomi AI Lab; Xiaomi AI Lab; Xiaomi AI Lab.; Xiaomi AI Lab; Wangxuan Institute of Computer Technology, Peking University,Beijing,China Center for Data Science, AAIS, Peking University,Beijing,China; Gaoling School of Artificial Intelligence, Renmin University of China Beijing Academy of Artificial Intelligence",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17502/17502-13-20996-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12683-reasoning-in-dialog-improving-response-generation-by-context-reading-comprehension/",
        "doi": "10.1609/aaai.v35i14.17502",
        "pdf_size": 360187
    },
    {
        "id": "05006",
        "title": "Recognizing and Verifying Mathematical Equations using Multiplicative Differential Neural Units",
        "track": "main",
        "status": "Poster",
        "abstract": "Automated mathematical reasoning is a challenging problem that requires an agent to learn algebraic patterns that contain long-range dependencies. Two particular tasks that test this type of reasoning are (1)mathematical equation verification,which requires determining whether trigonometric and linear algebraic statements are valid identities or not, and (2)equation completion, which entails filling in a blank within an expression to make it true. Solving these tasks with deep learning requires that the neural model learn how to manipulate and compose various algebraic symbols, carrying this ability over to previously unseen expressions. Artificial neural net-works, including recurrent networks and transformers, struggle  to  generalize  on  these  kinds  of  difficult  compositional problems,  often  exhibiting  poor  extrapolation  performance.In  contrast,  recursive  neural  networks  (recursive-NNs)  are,theoretically, capable of achieving better extrapolation due to their tree-like design but are very difficult to optimize as the depth  of  their  underlying  tree  structure  increases.  To  over-come this, we extend recursive-NNs to utilize multiplicative,higher-order synaptic connections and, furthermore, to learn to dynamically control and manipulate an external memory.We argue that this key modification gives the neural system the ability to capture powerful transition functions for each possible input. We demonstrate the effectiveness of our pro-posed higher-order, memory-augmented recursive-NN models on two challenging mathematical equation tasks, showing improved extrapolation, stable performance, and faster convergence. We show that our models achieve 1.53% average improvement over current state-of-the-art methods in equation verification and achieve 2.22% top-1 average accuracy and 2.96% top-5 average accuracy for equation completion.",
        "primary_area": "Neuro-Symbolic AI",
        "author": "Ankur Mali; Alexander G. Ororbia; Daniel Kifer; C. Lee Giles",
        "authorids": "",
        "aff": "The Pennsylvania State University, PA, USA; Rochester Institute of Techonology, NY, USA; The Pennsylvania State University, PA, USA; The Pennsylvania State University, PA, USA",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16634/16634-13-20128-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05006-recognizing-and-verifying-mathematical-equations-using-multiplicative-differential-neural-units/",
        "doi": "10.1609/aaai.v35i6.16634",
        "pdf_size": 319676
    },
    {
        "id": "06288",
        "title": "Recursion in Abstract Argumentation is Hard \u2014 On the Complexity of Semantics Based on Weak Admissibility",
        "track": "main",
        "status": "Poster",
        "abstract": "We study the computational complexity of abstract argumentation semantics based on weak admissibility, a recently introduced concept  to deal with arguments of self-defeating nature. Our results reveal that semantics based on weak admissibility are of much higher complexity (under typical assumptions) compared to all argumentation semantics which have been analysed in  terms of complexity so far. In fact, we show  PSPACE-completeness of all non-trivial standard decision problems for weak-admissible based semantics. We then investigate potential tractable fragments and show that restricting the frameworks under consideration to certain graph-classes  significantly reduces the complexity.             As a strategy for implementation we also provide a polynomial-time reduction  to DATALOG with stratified negation.",
        "primary_area": "Knowledge Representation and Reasoning",
        "author": "Wolfgang Dvo\u0159\u00e1k; Markus Ulbricht; Stefan Woltran",
        "authorids": "",
        "aff": "TU Wien; University of Leipzig; TU Wien",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16781/16781-13-20275-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06288-recursion-in-abstract-argumentation-is-hard-on-the-complexity-of-semantics-based-on-weak-admissibility/",
        "doi": "10.1609/aaai.v35i7.16781",
        "pdf_size": 180704
    },
    {
        "id": "01036",
        "title": "Ref-NMS: Breaking Proposal Bottlenecks in Two-Stage Referring Expression Grounding",
        "track": "main",
        "status": "Poster",
        "abstract": "The prevailing framework for solving referring expression grounding is based on a two-stage process: 1) detecting proposals with an object detector and 2) grounding the referent to one of the proposals. Existing two-stage solutions mostly focus on the grounding step, which aims to align the expressions with the proposals. In this paper, we argue that these methods overlook an obvious mismatch between the roles of proposals in the two stages: they generate proposals solely based on the detection confidence (i.e., expression-agnostic), hoping that the proposals contain all right instances in the expression (i.e., expression-aware). Due to this mismatch, current two-stage methods suffer from a severe performance drop between detected and ground-truth proposals. To this end, we propose Ref-NMS, which is the first method to yield expression-aware proposals at the first stage. Ref-NMS regards all nouns in the expression as critical objects, and introduces a lightweight module to predict a score for aligning each box with a critical object. These scores can guide the NMS operation to filter out the boxes irrelevant to the expression, increasing the recall of critical objects, resulting in a significantly improved grounding performance. Since Ref- NMS is agnostic to the grounding step, it can be easily integrated into any state-of-the-art two-stage method. Extensive ablation studies on several backbones, benchmarks, and tasks consistently demonstrate the superiority of Ref-NMS. Codes are available at: https://github.com/ChopinSharp/ref-nms.",
        "primary_area": "Computer Vision I",
        "author": "Long Chen; Wenbo Ma; Jun Xiao; Hanwang Zhang; Shih-Fu Chang",
        "authorids": "",
        "aff": "Tencent AI Lab, Shenzhen; Zhejiang University, Hangzhou; Zhejiang University, Hangzhou; Nanyang Technological University, Singapore; Columbia University, New York",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16188/16188-13-19682-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01036-ref-nms-breaking-proposal-bottlenecks-in-two-stage-referring-expression-grounding/",
        "doi": "10.1609/aaai.v35i2.16188",
        "pdf_size": 19908167
    },
    {
        "id": "02907",
        "title": "Region-aware Global Context Modeling for Automatic Nerve Segmentation from Ultrasound Images",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a novel deep learning model equipped with a new region-aware global context modeling technique for automatic nerve segmentation from ultrasound images, which is a challenging task due to (1) the large variation and blurred boundaries of targets, (2) the large amount of speckle noise in ultrasound images, and (3) the inherent real-time requirement of this task. It is essential to efficiently capture long-range dependencies by global context modeling for a segmentation network to overcome these challenges. Traditional global context modeling techniques usually explore pixel-aware correlations to establish long-range dependencies, which are usually computation-intensive and greatly degrade time performance. In addition, in this application, pixel-aware modeling may inevitably introduce much speckle noise in the computation and potentially degrade segmentation performance. In this paper, we propose a novel region-aware modeling technique to establish long-range dependencies based on different regions to improve segmentation accuracy while maintaining real-time performance; we call it region-aware pyramid aggregation (RPA) module. In order to adaptively divide the feature maps into a set of semantic-independent regions, we develop an attention mechanism and integrate it into the spatial pyramid network to evaluate the semantic similarity of different regions. We further develop an adaptive pyramid fusion (APF) module to dynamically fuse the multi-level features generated from the decoder to refining the segmentation results. We conducted extensive experiments on a famous public ultrasound nerve image segmentation dataset. Experimental results demonstrate that our method consistently outperforms our rivals in terms of segmentation accuracy. The code is available at https://github.com/jsonliu-szu/RAGCM.",
        "primary_area": "Computer Vision III",
        "author": "Huisi Wu; Jiasheng Liu; Wei Wang; Zhenkun Wen; Jing Qin",
        "authorids": "",
        "aff": "Shenzhen University; Shenzhen University; Shenzhen University; Shenzhen University; The Hong Kong Polytechnic University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16397/16397-13-19891-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02907-region-aware-global-context-modeling-for-automatic-nerve-segmentation-from-ultrasound-images/",
        "doi": "10.1609/aaai.v35i4.16397",
        "pdf_size": 1221939
    },
    {
        "id": "03563",
        "title": "Regional Attention with Architecture-Rebuilt 3D Network for RGB-D  Gesture Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "Human gesture recognition has drawn much attention in the area of computer vision. However, the performance of gesture recognition is always influenced by some gesture-irrelevant factors like the background and the clothes of performers. Therefore, focusing on the regions of hand/arm is important to the gesture recognition. Meanwhile, a more adaptive architecture-searched network structure can also perform better than the block-fixed ones like ResNet since it increases the diversity of features in different stages of the network better. In this paper, we propose a regional attention with architecture-rebuilt 3D network (RAAR3DNet) for gesture recognition. We replace the fixed Inception modules with the automatically rebuilt structure through the network via Neural Architecture Search (NAS), owing to the different shape and representation ability of features in the early, middle, and late stage of the network.  It enables the network to capture different levels of feature representations at different layers more adaptively. Meanwhile, we also design a stackable regional attention module called Dynamic-Static Attention (DSA), which derives a Gaussian guidance heatmap and dynamic motion map to highlight the hand/arm regions and the motion information in the spatial and temporal domains, respectively. Extensive experiments on two recent large-scale RGB-D gesture datasets validate the effectiveness of the proposed method and show it outperforms state-of-the-art methods. The codes of our method are available at:  https://github.com/zhoubenjia/RAAR3DNet.",
        "primary_area": "Computer Vision III",
        "author": "Benjia Zhou; Yunan Li; Jun Wan",
        "authorids": "",
        "aff": "Macau University of Science and Technology; Xidian University Xi\u2019an Key Laboratory of Big Data and Intelligent Vision, China; NLPR, CASIA School of Artificial Intelligence, University of Chinese Academy of Sciences, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16471/16471-13-19965-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03563-regional-attention-with-architecture-rebuilt-3d-network-for-rgb-d-gesture-recognition/",
        "doi": "10.1609/aaai.v35i4.16471",
        "pdf_size": 615955
    },
    {
        "id": "07340",
        "title": "Regret Bounds for Batched Bandits",
        "track": "main",
        "status": "Poster",
        "abstract": "We present simple algorithms for batched stochastic multi-armed bandit and batched stochastic linear bandit problems. We prove bounds for their expected regrets that improve and extend the best known regret bounds of Gao, Han, Ren, and Zhou (NeurIPS 2019), for any number of batches. In particular, our algorithms in both settings achieve the optimal expected regrets by using only a logarithmic number of batches.  We also study the batched adversarial multi-armed bandit problem for the first time and provide the optimal regret, up to logarithmic factors, of any algorithm with predetermined batch sizes.",
        "primary_area": "Machine Learning I",
        "author": "Hossein Esfandiari; Amin Karbasi; Abbas Mehrabian; Vahab Mirrokni",
        "authorids": "",
        "aff": "Google Research, New York; Yale University; McGill University; Google Research, New York",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16901/16901-13-20395-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07340-regret-bounds-for-batched-bandits/",
        "doi": "10.1609/aaai.v35i8.16901",
        "pdf_size": 162149
    },
    {
        "id": "10931",
        "title": "Regret Bounds for Online Kernel Selection in Continuous Kernel Space",
        "track": "main",
        "status": "Poster",
        "abstract": "Regret bounds of online kernel selection in a finite kernel set have been well studied, having at least an order O( \u221a NT) of magnitude after T rounds, where N is the number of candidate kernels. But it is still an unsolved problem to achieve sublinear regret bounds of online kernel selection in a continuous kernel space under different learning frameworks. In this paper, to represent different learning frameworks of online kernel selection, we divide online kernel selection approaches in a continuous kernel space into two categories according to the order of selection and training at each round. Then we construct a surrogate hypothesis space that contains all the candidate kernels with bounded norms and inner products, representing the continuously varying hypothesis space. Finally, we decompose the regrets of the proposed online kernel selection categories into different types of instantaneous regrets in the surrogate hypothesis space, and derive optimal regret bounds of order O( \u221a T) of magnitude under mild assumptions, independent of the cardinality of the continuous kernel space. Empirical studies verified the correctness of the theoretical regret analyses.",
        "primary_area": "Machine Learning V",
        "author": "Xiao Zhang; Shizhong Liao; Jun Xu; Ji-Rong Wen",
        "authorids": "",
        "aff": "Gaoling School of Artificial Intelligence, Renmin University of China Beijing Key Laboratory of Big Data Management and Analysis Methods; College of Intelligence and Computing, Tianjin University; Gaoling School of Artificial Intelligence, Renmin University of China Beijing Key Laboratory of Big Data Management and Analysis Methods; Gaoling School of Artificial Intelligence, Renmin University of China Beijing Key Laboratory of Big Data Management and Analysis Methods",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17305/17305-13-20799-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10931-regret-bounds-for-online-kernel-selection-in-continuous-kernel-space/",
        "doi": "10.1609/aaai.v35i12.17305",
        "pdf_size": 275658
    },
    {
        "id": "01845",
        "title": "Regularizing Attention Networks for Anomaly Detection in Visual Question Answering",
        "track": "main",
        "status": "Poster",
        "abstract": "For stability and reliability of real-world applications, the robustness of DNNs in unimodal tasks has been evaluated. However, few studies consider abnormal situations that a visual question answering (VQA) model might encounter at test time after deployment in the real-world. In this study, we evaluate the robustness of state-of-the-art VQA models to five different anomalies, including worst-case scenarios, the most frequent scenarios, and the current limitation of VQA models. Different from the results in unimodal tasks, the maximum confidence of answers in VQA models cannot detect anomalous inputs, and post-training of the outputs, such as outlier exposure, is ineffective for VQA models. Thus, we propose an attention-based method, which uses confidence of reasoning between input images and questions and shows much more promising results than the previous methods in unimodal tasks. In addition, we show that a maximum entropy regularization of attention networks can significantly improve the attention-based anomaly detection of the VQA models. Thanks to the simplicity, attention-based anomaly detection and the regularization are model-agnostic methods, which can be used for various cross-modal attentions in the state-of-the-art VQA models. The results imply that cross-modal attention in VQA is important to improve not only VQA accuracy, but also the robustness to various anomalies.",
        "primary_area": "Computer Vision II",
        "author": "Doyup Lee; Yeongjae Cheon; Wook-Shin Han",
        "authorids": "",
        "aff": "POSTECH; Kakaobrain; POSTECH",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16279/16279-13-19773-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01845-regularizing-attention-networks-for-anomaly-detection-in-visual-question-answering/",
        "doi": "10.1609/aaai.v35i3.16279",
        "pdf_size": 2032653
    },
    {
        "id": "13718",
        "title": "Reinforced History Backtracking for Conversational Question Answering",
        "track": "main",
        "status": "Poster",
        "abstract": "To model the context history in multi-turn conversations has become a critical step towards a better understanding of the user query in question answering systems. To utilize the context history, most existing studies treat the whole context as input, which will inevitably face the following two challenges. First, modeling a long history can be costly as it requires more computation resources. Second, the long context history consists of a lot of irrelevant information that makes it difficult to model appropriate information relevant to the user query. To alleviate these problems, we propose a reinforcement learning based method to capture and backtrack the related conversation history to boost model performance in this paper. Our method seeks to automatically backtrack the history information with the implicit feedback from the model performance. We further consider both immediate and delayed rewards to guide the reinforced backtracking policy. Extensive experiments on a large conversational question answering dataset show that the proposed method can help to alleviate the problems arising from longer context history. Meanwhile, experiments show that the method yields better performance than other strong baselines, and the actions made by the method are insightful.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Minghui Qiu; Xinjing Huang; Cen Chen; Feng Ji; Chen Qu; Wei Wei; Jun Huang; Yin Zhang",
        "authorids": "",
        "aff": "Alibaba Group; Zhejiang University; Alibaba Group; Alibaba Group; Alibaba Group; Huazhong University of Science and Technology; Alibaba Group; Zhejiang University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17617/17617-13-21111-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13718-reinforced-history-backtracking-for-conversational-question-answering/",
        "doi": "10.1609/aaai.v35i15.17617",
        "pdf_size": 186688
    },
    {
        "id": "04410",
        "title": "Reinforced Imitative Graph Representation Learning for Mobile User Profiling: An Adversarial Training Perspective",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we study the problem of mobile user profiling, which is a critical component for quantifying users' characteristics in the human mobility modeling pipeline. Human mobility is a sequential decision-making process dependent on the users' dynamic interests. With accurate user profiles, the predictive model can perfectly reproduce users' mobility trajectories. In the reverse direction, once the predictive model can imitate users' mobility patterns, the learned user profiles are also optimal. Such intuition motivates us to propose an imitation-based mobile user profiling framework by exploiting reinforcement learning, in which the agent is trained to precisely imitate users' mobility patterns for optimal user profiles. Specifically, the proposed framework includes two modules: (1) representation module, that produces state combining user profiles and spatio-temporal context in real-time; (2) imitation module, where Deep Q-network (DQN) imitates the user behavior (action) based on the state that is produced by the representation module. However, there are two challenges in running the framework effectively. First, epsilon-greedy strategy in DQN makes use of the exploration-exploitation trade-off by randomly pick actions with the epsilon probability. Such randomness feeds back to the representation module, causing the learned user profiles unstable. To solve the problem, we propose an adversarial training strategy to guarantee the robustness of the representation module. Second, the representation module updates users' profiles in an incremental manner, requiring integrating the temporal effects of user profiles. Inspired by Long-short Term Memory (LSTM), we introduce a gated mechanism to incorporate new and old user characteristics into the user profile. In the experiment, we evaluate our proposed framework on real-world datasets. The extensive experimental results validate the superiority of our method comparing to baseline algorithms.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Dongjie Wang; Pengyang Wang; Kunpeng Liu; Yuanchun Zhou; Charles E Hughes; Yanjie Fu",
        "authorids": "",
        "aff": "University of Central Florida; University of Central Florida; University of Central Florida; Computer Network Information Center, Chinese Academy of Sciences; University of Central Florida; University of Central Florida",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16567/16567-13-20061-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04410-reinforced-imitative-graph-representation-learning-for-mobile-user-profiling-an-adversarial-training-perspective/",
        "doi": "10.1609/aaai.v35i5.16567",
        "pdf_size": 515274
    },
    {
        "id": "14284",
        "title": "Reinforced Multi-Teacher Selection for Knowledge Distillation",
        "track": "main",
        "status": "Poster",
        "abstract": "In natural language processing (NLP) tasks, slow inference speed and huge footprints in GPU usage remain the bottleneck of applying pre-trained deep models in production. As a popular method for model compression, knowledge distillation transfers knowledge from one or multiple large (teacher) models to a small (student) model. When multiple teacher models are available in distillation, the state-of-the-art methods assign a fixed weight to a teacher model in the whole distillation. Furthermore, most of the existing methods allocate an equal weight to every teacher model.  In this paper, we observe that, due to the complexity of training examples and the differences in student model capability, learning differentially from teacher models can lead to better performance of student models distilled. We systematically develop a reinforced method to dynamically assign weights to teacher models for different training instances and optimize the performance of student model. Our extensive experimental results on several NLP tasks clearly verify the feasibility and effectiveness of our approach.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Fei Yuan; Linjun Shou; Jian Pei; Wutao Lin; Ming Gong; Yan Fu; Daxin Jiang",
        "authorids": "",
        "aff": "University of Electronic Science and Technology of China; Microsoft STCA NLP Group; School of Computing Science, Simon Fraser University; Microsoft STCA NLP Group; Microsoft STCA NLP Group; University of Electronic Science and Technology of China; Microsoft STCA NLP Group",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17680/17680-13-21174-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14284-reinforced-multi-teacher-selection-for-knowledge-distillation/",
        "doi": "10.1609/aaai.v35i16.17680",
        "pdf_size": 270905
    },
    {
        "id": "07737",
        "title": "Reinforcement Learning Based Multi-Agent Resilient Control: From Deep Neural Networks to an Adaptive Law",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent advances in Multi-agent Reinforcement Learning (MARL) have made it possible to implement various tasks in cooperative as well as competitive scenarios through trial and error, and deep neural networks. These successes motivate us to bring the mechanism of MARL into  the Multi-agent Resilient Consensus (MARC) problem  that studies the consensus problem in a network of agents with faulty ones. Relying on the natural characteristics of the system goal, the key component in MARL, reward function, can thus be directly constructed via the relative distance among agents. Firstly, we apply Deep Deterministic Policy Gradient (DDPG) on each single agent to train and learn adjacent weights of neighboring agents in a distributed manner, that we call Distributed-DDPG (D-DDPG), so as to minimize the weights from suspicious agents and eliminate the corresponding influences. Secondly, to get rid of neural networks and their time-consuming training process, a Q-learning based algorithm, called Q-consensus, is further presented by building a proper reward function and a credibility function for each pair of neighboring agents so that the adjacent weights  can update in an adaptive way. The experimental results indicate that both algorithms perform well with appearance of constant and/or random faulty agents, yet the Q-consensus algorithm outperforms the faulty ones running D-DDPG. Compared to the traditional resilient consensus strategies, e.g., Weighted-Mean-Subsequence-Reduced (W-MSR) or trustworthiness analysis, the proposed Q-consensus algorithm has greatly relaxed the topology requirements, as well as reduced the storage and computation loads. Finally, a smart-car hardware platform consisting of six vehicles is used to verify the effectiveness of the Q-consensus algorithm by achieving resilient velocity synchronization.",
        "primary_area": "Machine Learning II",
        "author": "Jian Hou; Fangyuan Wang; Lili Wang; Zhiyong Chen",
        "authorids": "",
        "aff": "Zhejiang Sci-Tech University; Zhejiang Sci-Tech University; Boston University; University of Newcastle",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16945/16945-13-20439-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07737-reinforcement-learning-based-multi-agent-resilient-control-from-deep-neural-networks-to-an-adaptive-law/",
        "doi": "10.1609/aaai.v35i9.16945",
        "pdf_size": 2373634
    },
    {
        "id": "05219",
        "title": "Reinforcement Learning of Sequential Price Mechanisms",
        "track": "main",
        "status": "Poster",
        "abstract": "We introduce the use of reinforcement learning for indirect mechanisms, working with the existing class of sequential price mechanisms, which generalizes both serial dictatorship and posted price mechanisms and essentially characterizes all strongly obviously strategyproof mechanisms. Learning an optimal mechanism within this class forms a partially-observable Markov decision process. We provide rigorous conditions for when this class of mechanisms is more powerful than simpler static mechanisms, for sufficiency or insufficiency of observation statistics for learning, and for the necessity of complex (deep) policies. We show that our approach can learn optimal or near-optimal mechanisms in several experimental settings.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Gianluca Brero; Alon Eden; Matthias Gerstgrasser; David Parkes; Duncan Rheingans-Yoo",
        "authorids": "",
        "aff": "Harvard University; Harvard University; Harvard University; Harvard University; Harvard University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16659/16659-13-20153-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05219-reinforcement-learning-of-sequential-price-mechanisms/",
        "doi": "10.1609/aaai.v35i6.16659",
        "pdf_size": 731743
    },
    {
        "id": "07288",
        "title": "Reinforcement Learning with Trajectory Feedback",
        "track": "main",
        "status": "Poster",
        "abstract": "The standard feedback model of reinforcement learning requires revealing the reward of every visited state-action pair. However, in practice, it is often the case that such frequent feedback is not available. In this work, we take a first step towards relaxing this assumption and require a weaker form of feedback, which we refer to as emph{trajectory feedback}. Instead of observing the reward obtained after every action, we assume we only receive a score that represents the quality of the whole trajectory observed by the agent, namely, the sum of all rewards obtained over this trajectory. We extend reinforcement learning algorithms to this setting, based on least-squares estimation of the unknown reward, for both the known and unknown transition model cases, and study the performance of these algorithms by analyzing their regret. For cases where the transition model is unknown, we offer a hybrid optimistic-Thompson Sampling approach that results in a tractable algorithm.",
        "primary_area": "Machine Learning I",
        "author": "Yonathan Efroni; Nadav Merlis; Shie Mannor",
        "authorids": "",
        "aff": "Microsoft Research, New York Technion, Israel Institute of Technology; Technion, Israel Institute of Technology; Technion, Israel Institute of Technology Nvidia Research, Israel",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16895/16895-13-20389-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07288-reinforcement-learning-with-trajectory-feedback/",
        "doi": "10.1609/aaai.v35i8.16895",
        "pdf_size": 171101
    },
    {
        "id": "04427",
        "title": "Reinforcement Learning with a Disentangled Universal Value Function for Item Recommendation",
        "track": "main",
        "status": "Poster",
        "abstract": "In recent years, there are great interests as well as many challenges in applying reinforcement learning (RL) to recommendation systems (RS). In this paper, we summarize three key practical challenges of large-scale RL-based recommender systems: massive state and action spaces, high-variance environment, and the unspecific reward setting in recommendation. All these problems remain largely unexplored in the existing literature and make the application of RL challenging. We develop a model-based reinforcement learning framework, called GoalRec. Inspired by the ideas of world model (model-based), value function estimation (model-free), and goal-based RL, a novel disentangled universal value function designed for item recommendation is proposed. It can generalize to various goals that the recommender may have, and disentangle the stochastic environmental dynamics and high-variance reward signals accordingly. As a part of the value function, free from the sparse and high-variance reward signals, a high-capacity reward-independent world model is trained to simulate complex environmental dynamics under a certain goal. Based on the predicted environmental dynamics, the disentangled universal value function is related to the user's future trajectory instead of a monolithic state and a scalar reward. We demonstrate the superiority of GoalRec over previous approaches in terms of the above three practical challenges in a series of simulations and a real application.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Kai Wang; Zhene Zou; Qilin Deng; Jianrong Tao; Runze Wu; Changjie Fan; Liang Chen; Peng Cui",
        "authorids": "",
        "aff": "NetEase Fuxi AI Lab; NetEase Fuxi AI Lab; NetEase Fuxi AI Lab; NetEase Fuxi AI Lab; NetEase Fuxi AI Lab; NetEase Fuxi AI Lab; Sun Yat-sen University; Tsinghua University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16569/16569-13-20063-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04427-reinforcement-learning-with-a-disentangled-universal-value-function-for-item-recommendation/",
        "doi": "10.1609/aaai.v35i5.16569",
        "pdf_size": 3137328
    },
    {
        "id": "04197",
        "title": "Rejection Sampling for Weighted Jaccard Similarity Revisited",
        "track": "main",
        "status": "Poster",
        "abstract": "Efficiently computing the weighted Jaccard similarity has become an active research topic in machine learning and theory. For sparse data, the standard technique is based on the consistent weighed sampling (CWS). For dense data, however, methods based on rejection sampling (RS) can be much more efficient. Nevertheless, existing RS methods are still slow for practical purposes. In this paper, we propose to improve RS by  a strategy, which we call  efficient rejection sampling (ERS), based on ``early stopping + densification''.  We analyze the statistical property of  ERS and provide experimental results to compare ERS with RS and other algorithms for hashing weighted Jaccard. The results demonstrate that ERS significantly improves the existing methods for estimating the weighted Jaccard similarity in relatively dense data.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Xiaoyun Li; Ping Li",
        "authorids": "",
        "aff": "Baidu Research; Baidu Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16543/16543-13-20037-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04197-rejection-sampling-for-weighted-jaccard-similarity-revisited/",
        "doi": "10.1609/aaai.v35i5.16543",
        "pdf_size": 460870
    },
    {
        "id": "04749",
        "title": "Relation-Aware Neighborhood Matching Model for Entity Alignment",
        "track": "main",
        "status": "Poster",
        "abstract": "Entity alignment which aims at linking entities with the same meaning from different knowledge graphs (KGs) is a vital step for knowledge fusion. Existing research focused on learning embeddings of entities by utilizing structural information of KGs for entity alignment. These methods can aggregate information from neighboring nodes but may also bring noise from neighbors. Most recently, several researchers attempted to compare neighboring nodes in pairs to enhance the entity alignment. However, they ignored the relations between entities which are also important for neighborhood matching. In addition, existing methods paid less attention to the positive interactions between the entity alignment and the relation alignment. To deal with these issues, we propose a novel Relation-aware Neighborhood Matching model named RNM for entity alignment. Specifically, we propose to utilize the neighborhood matching to enhance the entity alignment. Besides comparing neighbor nodes when matching neighborhood, we also try to explore useful information from the connected relations. Moreover, an iterative framework is designed to leverage the positive interactions between the entity alignment and the relation alignment in a semi-supervised manner. Experimental results on three real-world datasets demonstrate that the proposed model RNM performs better than state-of-the-art methods.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Yao Zhu; Hongzhi Liu; Zhonghai Wu; Yingpeng Du",
        "authorids": "",
        "aff": "Center for Data Science, Peking University; School of Software and Microelectronics, Peking University; National Engineering Center of Software Engineering, Peking University Key Lab of High Confidence Software Technologies (MOE), Peking University; School of Software and Microelectronics, Peking University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16606/16606-13-20100-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04749-relation-aware-neighborhood-matching-model-for-entity-alignment/",
        "doi": "10.1609/aaai.v35i5.16606",
        "pdf_size": 677144
    },
    {
        "id": "09368",
        "title": "Relation-aware Graph Attention Model with Adaptive Self-adversarial Training",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper describes an end-to-end solution for the relationship prediction task in heterogeneous, multi-relational graphs. We particularly address two building blocks in the pipeline, namely heterogeneous graph representation learning and negative sampling. Existing message passing-based graph neural networks use edges either for graph traversal and/or selection of message encoding functions. Ignoring the edge semantics could have severe repercussions on the quality of embeddings, especially when dealing with two nodes having multiple relations. Furthermore, the expressivity of the learned representation depends on the quality of negative samples used during training. Although existing hard negative sampling techniques can identify challenging negative relationships for optimization, new techniques are required to control false negatives during training as false negatives could corrupt the learning process. To address these issues, first, we propose RelGNN -- a message passing-based heterogeneous graph attention model. In particular, RelGNN generates the states of different relations and leverages them along with the node states to weigh the messages. RelGNN also adopts a self-attention mechanism to balance the importance of attribute features and topological features for generating the final entity embeddings. Second, we introduce a parameter free negative sampling technique -- adaptive self-adversarial (ASA) negative sampling. ASA reduces the false negative rate by leveraging positive relationships to effectively guide the identification of true negative samples. Our experimental evaluation demonstrates that RelGNN optimized by ASA for relationship prediction improves state-of-the-art performance across established benchmarks as well as on a real industrial dataset.",
        "primary_area": "Machine Learning IV",
        "author": "Xiao Qin; Nasrullah Sheikh; Berthold Reinwald; Lingfei Wu",
        "authorids": "",
        "aff": "IBM Almaden Research Center; IBM Almaden Research Center; IBM Almaden Research Center; IBM Thomas J. Watson Research Center",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17129/17129-13-20623-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09368-relation-aware-graph-attention-model-with-adaptive-self-adversarial-training/",
        "doi": "10.1609/aaai.v35i11.17129",
        "pdf_size": 432226
    },
    {
        "id": "12123",
        "title": "Relational Boosted Bandits",
        "track": "main",
        "status": "Poster",
        "abstract": "Contextual bandits algorithms have become essential in real-world user interaction problems in recent years. However, these algorithms represent context as attribute value representation, which makes them infeasible for real world domains like social networks, which are inherently relational. We propose Relational Boosted Bandits  (RB2), a contextual bandits algorithm for relational domains based on (relational) boosted trees. RB2 enables us to learn interpretable and explainable models due to the more descriptive nature of the relational representation. We empirically demonstrate the effectiveness and interpretability of RB2 on tasks such as link prediction, relational classification, and recommendation.",
        "primary_area": "Reasoning under Uncertainty",
        "author": "Ashutosh Kakadiya; Sriraam Natarajan; Balaraman Ravindran",
        "authorids": "",
        "aff": "Robert Bosch Centre for Data Science and Artificial Intelligence, Indian Institute of Technology Madras; The University of Texas at Dallas; Robert Bosch Centre for Data Science and Artificial Intelligence, Indian Institute of Technology Madras",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17439/17439-13-20933-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12123-relational-boosted-bandits/",
        "doi": "10.1609/aaai.v35i13.17439",
        "pdf_size": 650155
    },
    {
        "id": "00344",
        "title": "Relational Classification of Biological Cells in Microscopy Images",
        "track": "main",
        "status": "Poster",
        "abstract": "We investigate the relational classification of biological cells in 2D microscopy images. Rather than treating each cell image independently, we investigate whether and how the neighborhood information of a cell can be informative for its prediction.  We propose a Relational Long Short-Term Memory (R-LSTM) algorithm, coupled with auto-encoders and convolutional neural networks, that can learn from both annotated and unlabeled microscopy images and that can utilize both the local and neighborhood information to perform an improved classification of biological cells. Experimental results on both synthetic and real datasets show that R-LSTM performs comparable to or better than six baselines.",
        "primary_area": "Application Domains",
        "author": "Ping Liu; Mustafa Bilgic",
        "authorids": "",
        "aff": "Illinois Institute of Technology; Illinois Institute of Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16110/16110-13-19604-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00344-relational-classification-of-biological-cells-in-microscopy-images/",
        "doi": "10.1609/aaai.v35i1.16110",
        "pdf_size": 802569
    },
    {
        "id": "06732",
        "title": "Relative Variational Intrinsic Control",
        "track": "main",
        "status": "Poster",
        "abstract": "In the absence of external rewards, agents can still learn useful behaviors by identifying and mastering a set of diverse skills within their environment. Existing skill learning methods use mutual information objectives to incentivize each skill to be diverse and distinguishable from the rest. However, if care is not taken to constrain the ways in which the skills are diverse, trivially diverse skill sets can arise. To ensure useful skill diversity, we propose a novel skill learning objective, Relative Variational Intrinsic Control (RVIC), which incentivizes learning skills that are distinguishable in how they change the agent's relationship to its environment. The resulting set of skills tiles the space of affordances available to the agent. We qualitatively analyze skill behaviors on multiple environments and show how RVIC skills are more useful than skills discovered by existing methods in hierarchical reinforcement learning.",
        "primary_area": "Machine Learning I",
        "author": "Kate Baumli; David Warde-Farley; Steven Hansen; Volodymyr Mnih",
        "authorids": "",
        "aff": "DeepMind; DeepMind; DeepMind; DeepMind",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16832/16832-13-20326-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06732-relative-variational-intrinsic-control/",
        "doi": "10.1609/aaai.v35i8.16832",
        "pdf_size": 3184852
    },
    {
        "id": "04267",
        "title": "Relative and Absolute Location Embedding for Few-Shot Node Classification on Graph",
        "track": "main",
        "status": "Poster",
        "abstract": "Node classification is an important problem on graphs. While recent advances in graph neural networks achieve promising performance, they require abundant labeled nodes for training. However, in many practical scenarios, there often exist novel classes in which only one or a few labeled nodes are available as supervision, known as few-shot node classification. Although meta-learning has been widely used in vision and language domains to address few-shot learning, its adoption on graphs has been limited. In particular, graph nodes in a few-shot task are not independent and relate to each other. To deal with this, we propose a novel model called Relative and Absolute Location Embedding (RALE) hinged on the concept of hub nodes. Specifically, RALE captures the task-level dependency by assigning each node a relative location within a task, as well as the graph-level dependency by assigning each node an absolute location on the graph to further align different tasks toward learning a transferable prior. Finally, extensive experiments on three public datasets demonstrate the state-of-the-art performance of RALE.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Zemin Liu; Yuan Fang; Chenghao Liu; Steven C.H. Hoi",
        "authorids": "",
        "aff": "Singapore Management University, Singapore; Singapore Management University, Singapore; Singapore Management University, Singapore Salesforce Research Asia, Singapore; Singapore Management University, Singapore Salesforce Research Asia, Singapore",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16551/16551-13-20045-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04267-relative-and-absolute-location-embedding-for-few-shot-node-classification-on-graph/",
        "doi": "10.1609/aaai.v35i5.16551",
        "pdf_size": 619192
    },
    {
        "id": "04599",
        "title": "Relaxed Clustered Hawkes Process for Student Procrastination Modeling in MOOCs",
        "track": "main",
        "status": "Poster",
        "abstract": "Hawkes processes have been shown to be efficient in modeling bursty sequences in a variety of applications, such as finance and social network activity analysis. Traditionally, these models parameterize each process independently and assume that the history of each point process can be fully observed. Such models could however be inefficient or even prohibited in certain real-world applications, such as in the field of education, where such assumptions are violated.     Motivated by the problem of detecting and predicting student procrastination in students Massive Open Online Courses (MOOCs) with missing and partially observed data, in this work, we propose a novel personalized Hawkes process model (RCHawkes-Gamma) that discovers meaningful student behavior clusters by jointly learning all partially observed processes simultaneously, without relying on auxiliary features. Our experiments on both synthetic and real-world education datasets show that RCHawkes-Gamma can effectively recover student clusters and their temporal procrastination dynamics, resulting in better predictive performance of future student activities. Our further analyses of the learned parameters and their association with student delays show that the discovered student clusters unveil meaningful representations of various procrastination behaviors in students.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Mengfan Yao; Siqian Zhao; Shaghayegh Sahebi; Reza Feyzi Behnagh",
        "authorids": "",
        "aff": "University at Albany, SUNY; University at Albany, SUNY; University at Albany - SUNY; University at Albany, SUNY",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16589/16589-13-20083-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04599-relaxed-clustered-hawkes-process-for-student-procrastination-modeling-in-moocs/",
        "doi": "10.1609/aaai.v35i5.16589",
        "pdf_size": 878387
    },
    {
        "id": "05086",
        "title": "Representative Proxy Voting",
        "track": "main",
        "status": "Poster",
        "abstract": "We study a model of proxy voting where the candidates, voters, and proxies are all located on the real line, and instead of voting directly, each voter delegates its vote to the closest proxy. The goal is to find a set of proxies that is theta-representative, which entails that for any voter located anywhere on the line, its favorite candidate is within a distance theta of the favorite candidate of its closest proxy. This property guarantees a strong form of representation as the set of voters is not required to be fixed in advance, or even be finite. We show that for candidates located on a line, an optimal proxy arrangement can be computed in polynomial time. Moreover, we provide upper and lower bounds on the number of proxies required to form a theta-representative set, thus showing that a relatively small number of proxies is enough to capture the preferences of any set of voters. An additional beneficial property of a theta-representative proxy arrangement is that for strict-Condorcet voting rules, the outcome of proxy voting is similarly close to the outcome of direct voting.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Elliot Anshelevich; Zack Fitzsimmons; Rohit Vaish; Lirong Xia",
        "authorids": "",
        "aff": "Rensselaer Polytechnic Institute; College of the Holy Cross; Tata Institute of Fundamental Research; Rensselaer Polytechnic Institute",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16643/16643-13-20137-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05086-representative-proxy-voting/",
        "doi": "10.1609/aaai.v35i6.16643",
        "pdf_size": 234768
    },
    {
        "id": "00469",
        "title": "Research Reproducibility as a Survival Analysis",
        "track": "main",
        "status": "Poster",
        "abstract": "There has been increasing concern within the machine learning community that we are in a reproducibility crisis. As many have begun to work on this problem, all work we are aware of treat the issue of reproducibility as an intrinsic binary property: a paper is or is not reproducible. Instead, we consider modeling the reproducibility of a paper as a survival analysis problem. We argue that this perspective represents a more accurate model of the underlying meta-science question of reproducible research, and we show how a survival analysis allows us to draw new insights that better explain prior longitudinal data. The data and code can be found at https://github.com/EdwardRaff/Research-Reproducibility-Survival-Analysis",
        "primary_area": "Application Domains",
        "author": "Edward Raff",
        "authorids": "",
        "aff": "Booz Allen Hamilton University of Maryland, Baltimore County",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16124/16124-13-19618-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00469-research-reproducibility-as-a-survival-analysis/",
        "doi": "10.1609/aaai.v35i1.16124",
        "pdf_size": 1585910
    },
    {
        "id": "07245",
        "title": "Residual Shuffle-Exchange Networks for Fast Processing of Long Sequences",
        "track": "main",
        "status": "Poster",
        "abstract": "Attention is a commonly used mechanism in sequence processing, but it is of O(n^2) complexity which prevents its application to long sequences. The recently introduced neural Shuffle-Exchange network offers a computation-efficient alternative, enabling the modelling of long-range dependencies in O(n log n) time. The model, however, is quite complex, involving a sophisticated gating mechanism derived from the Gated Recurrent Unit. In this paper, we present a simple and lightweight variant of the Shuffle-Exchange network, which is based on a residual network employing GELU and Layer Normalization. The proposed architecture not only scales to longer sequences but also converges faster and provides better accuracy. It surpasses the Shuffle-Exchange network on the LAMBADA language modelling task and achieves state-of-the-art performance on the MusicNet dataset for music transcription while being efficient in the number of parameters. We show how to combine the improved Shuffle-Exchange network with convolutional layers, establishing it as a useful building block in long sequence processing applications.",
        "primary_area": "Machine Learning I",
        "author": "Andis Draguns; Em\u012bls Ozoli\u0146\u0161; Agris \u0160ostaks; Mat\u012bss Apinis; Karlis Freivalds",
        "authorids": "",
        "aff": "Institute of Mathematics and Computer Science, University of Latvia; Institute of Mathematics and Computer Science, University of Latvia; Institute of Mathematics and Computer Science, University of Latvia; Institute of Mathematics and Computer Science, University of Latvia; Institute of Mathematics and Computer Science, University of Latvia",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16890/16890-13-20384-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07245-residual-shuffle-exchange-networks-for-fast-processing-of-long-sequences/",
        "doi": "10.1609/aaai.v35i8.16890",
        "pdf_size": 258709
    },
    {
        "id": "11308",
        "title": "Resilient Multi-Agent Reinforcement Learning with Adversarial Value Decomposition",
        "track": "main",
        "status": "Poster",
        "abstract": "We focus on resilience in cooperative multi-agent systems, where agents can change their behavior due to udpates or failures of hardware and software components. Current state-of-the-art approaches to cooperative multi-agent reinforcement learning (MARL) have either focused on idealized settings without any changes or on very specialized scenarios, where the number of changing agents is fixed, e.g., in extreme cases with only one productive agent. Therefore, we propose Resilient Adversarial value Decomposition with Antagonist-Ratios (RADAR). RADAR offers a value decomposition scheme to train competing teams of varying size for improved resilience against arbitrary agent changes. We evaluate RADAR in two cooperative multi-agent domains and show that RADAR achieves better worst case performance w.r.t. arbitrary agent changes than state-of-the-art MARL.",
        "primary_area": "Multiagent Systems",
        "author": "Thomy Phan; Lenz Belzner; Thomas Gabor; Andreas Sedlmeier; Fabian Ritz; Claudia Linnhoff-Popien",
        "authorids": "",
        "aff": "LMU Munich; MaibornWolff; LMU Munich; LMU Munich; LMU Munich; LMU Munich",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17348/17348-13-20842-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11308-resilient-multi-agent-reinforcement-learning-with-adversarial-value-decomposition/",
        "doi": "10.1609/aaai.v35i13.17348",
        "pdf_size": 2600754
    },
    {
        "id": "11734",
        "title": "Responsibility Attribution in Parameterized Markovian Models",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider the problem of responsibility attribution in the setting of parametric Markov chains. Given a family of Markov chains over a set of parameters, and a property, responsibility attribution asks how the difference in the value of the property should be attributed to the parameters when they change from one point in the parameter space to another.   We formalize responsibility as path-based attribution schemes studied in cooperative game theory. An attribution scheme in a game determines how a value (a surplus or a cost) is distributed among a set of participants. Path-based attribution schemes include the well-studied Aumann-Shapley and the Shapley-Shubik schemes. In our context, an attribution scheme measures the responsibility of each parameter on the value function of the parametric Markov chain.   We study the decision problem for path-based attribution schemes. Our main technical result is an algorithm for deciding if a path-based attribution scheme for a rational (ratios of polynomials) cost function is over a rational threshold. In particular, it is decidable if the Aumann-Shapley value for a player is at least a given rational number. As a consequence, we show that responsibility attribution is decidable for parametric Markov chains and for a general class of properties that include expectation and variance of discounted sum and long-run average rewards, as well as specifications in temporal logic.",
        "primary_area": "Planning, Routing, and Scheduling",
        "author": "Christel Baier; Florian Funke; Rupak Majumdar",
        "authorids": "",
        "aff": "Technische Universit\u00e4t Dresden; Technische Universit\u00e4t Dresden; Max Planck Institute for Software Systems",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17395/17395-13-20889-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11734-responsibility-attribution-in-parameterized-markovian-models/",
        "doi": "10.1609/aaai.v35i13.17395",
        "pdf_size": 170701
    },
    {
        "id": "05726",
        "title": "Restricted Domains of Dichotomous Preferences with Possibly Incomplete Information",
        "track": "main",
        "status": "Poster",
        "abstract": "Restricted domains over voter preferences have been extensively studied within the area of computational social choice, initially for preferences that are total orders over the set of alternatives and subsequently for preferences that are dichotomous\u2014i.e., that correspond to approved and disapproved alternatives. This paper contributes to the latter stream of work in a twofold manner. First, we obtain forbidden subprofile characterisations for various important dichotomous domains. Then, we are concerned with incomplete profiles that may arise in many real-world scenarios, where we have partial information about the voters\u2019 preferences. We tackle the problem of determining whether an incomplete profile admits a completion within a certain restricted domain and design constructive, polynomial algorithms to that effect.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Zoi Terzopoulou; Alexander Karpov; Svetlana Obraztsova",
        "authorids": "",
        "aff": "University of Amsterdam, The Netherlands; HSE University Institute of Control Sciences of Russian Academy of Sciences, Russia; Nanyang Technological University, Singapore",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16718/16718-13-20212-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05726-restricted-domains-of-dichotomous-preferences-with-possibly-incomplete-information/",
        "doi": "10.1609/aaai.v35i6.16718",
        "pdf_size": 151283
    },
    {
        "id": "10551",
        "title": "Rethinking Bi-Level Optimization in Neural Architecture Search: A Gibbs Sampling Perspective",
        "track": "main",
        "status": "Poster",
        "abstract": "One-Shot architecture search, which aims to explore all possible operations jointly based on a single model, has been an active direction of Neural Architecture Search (NAS). As a well-known one-shot solution, Differentiable Architecture Search (DARTS) performs continuous relaxation on the architecture's importance and results in a bi-level optimization problem. However, as many recent studies have shown, DARTS cannot always work robustly for new tasks, which is mainly due to the approximate solution of the bi-level optimization. In this paper, one-shot neural architecture search is addressed by adopting a directed probabilistic graphical model to represent the joint probability distribution over data and model. Then, neural architectures are searched for and optimized by Gibbs sampling. We rethink the bi-level optimization problem as the task of Gibbs sampling from the posterior distribution, which expresses the preferences for different models given the observed dataset. We evaluate our proposed NAS method -- GibbsNAS on the search space used in DARTS/ENAS and the search space of NAS-Bench-201. Experimental results on multiple search space show the efficacy and stability of our approach.",
        "primary_area": "Machine Learning V",
        "author": "Chao Xue; Xiaoxing Wang; Junchi Yan; Yonggang Hu; Xiaokang Yang; Kewei Sun",
        "authorids": "",
        "aff": "IBM Research; Shanghai Jiao Tong University; Shanghai Jiao Tong University; IBM System; Shanghai Jiao Tong University; IBM Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17262/17262-13-20756-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10551-rethinking-bi-level-optimization-in-neural-architecture-search-a-gibbs-sampling-perspective/",
        "doi": "10.1609/aaai.v35i12.17262",
        "pdf_size": 218703
    },
    {
        "id": "12785",
        "title": "Rethinking Boundaries: End-To-End Recognition of Discontinuous Mentions with Pointer Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "A majority of research interests in irregular (e.g., nested or discontinuous) named entity recognition (NER) have been paid on nested entities, while discontinuous entities received limited attention. Existing work for discontinuous NER, however, either suffers from decoding ambiguity or predicting using token-level local features. In this work, we present an innovative model for discontinuous NER based on pointer networks, where the pointer simultaneously decides whether a token at each decoding frame constitutes an entity mention and where the next constituent token is. Our model has three major merits compared with previous work: (1) The pointer mechanism is memory-augmented, which enhances the mention boundary detection and interactions between the current decision and prior recognized mentions. (2) The encoder-decoder architecture can linearize the complexity of structure prediction, and thus reduce search costs. (3) The model makes every decision using global information, i.e., by consulting all the input, encoder and previous decoder output in a global view. Experimental results on the CADEC and ShARe13 datasets show that our model outperforms flat and hypergraph models as well as a state-of-the-art transition-based model for discontinuous NER. Further in-depth analysis demonstrates that our model performs well in recognizing various entities including flat, overlapping and discontinuous ones. More crucially, our model is effective on boundary detection, which is the kernel source to NER.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Hao Fei; Donghong Ji; Bobo Li; Yijiang Liu; Yafeng Ren; Fei Li",
        "authorids": "",
        "aff": "Wuhan University; Wuhan University; Wuhan University; Wuhan University; Guangdong University of Foreigh Studies; Wuhan University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17513/17513-13-21007-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12785-rethinking-boundaries-end-to-end-recognition-of-discontinuous-mentions-with-pointer-networks/",
        "doi": "10.1609/aaai.v35i14.17513",
        "pdf_size": 380580
    },
    {
        "id": "04573",
        "title": "Rethinking Graph Regularization for Graph Neural Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "The graph Laplacian regularization term is usually used in semi-supervised representation learning to provide graph structure information for a model f(X). However, with the recent popularity of graph neural networks (GNNs), directly encoding graph structure A into a model, i.e., f(A, X), has become the more common approach. While we show that graph Laplacian regularization brings little-to-no benefit to existing GNNs, and propose a simple but non-trivial variant of graph Laplacian regularization, called Propagation-regularization (P-reg), to boost the performance of existing GNN models. We provide formal analyses to show that P-reg not only infuses extra information (that is not captured by the traditional graph Laplacian regularization) into GNNs, but also has the capacity equivalent to an infinite-depth graph convolutional network. We demonstrate that P-reg can effectively boost the performance of existing GNN models on both node-level and graph-level tasks across many different datasets.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Han Yang; Kaili Ma; James Cheng",
        "authorids": "",
        "aff": "The Chinese University of Hong Kong; The Chinese University of Hong Kong; The Chinese University of Hong Kong",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16586/16586-13-20080-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04573-rethinking-graph-regularization-for-graph-neural-networks/",
        "doi": "10.1609/aaai.v35i5.16586",
        "pdf_size": 1264806
    },
    {
        "id": "00947",
        "title": "Rethinking Object Detection in Retail Stores",
        "track": "main",
        "status": "Poster",
        "abstract": "The conventional standard for object detection uses a bounding box to represent each individual object instance. However, it is not practical in the industry-relevant applications in the context of warehouses due to severe occlusions among groups of instances of the same categories. In this paper, we propose a new task, i.e., simultaneously object localization and counting, abbreviated as Locount, which requires algorithms to localize groups of objects of interest with the number of instances. However, there does not exist a dataset or benchmark designed for such a task. To this end, we collect a large-scale object localization and counting dataset with rich annotations in retail stores, which consists of 50,394 images with more than 1.9 million object instances in 140 categories. Together with this dataset, we provide a new evaluation protocol and divide the training and testing subsets to fairly evaluate the performance of algorithms for Locount, developing a new benchmark for the Locount task. Moreover, we present a cascaded localization and counting network as a strong baseline, which gradually classifies and regresses the bounding boxes of objects with the predicted numbers of instances enclosed in the bounding boxes, trained in an end-to-end manner. Extensive experiments are conducted on the proposed dataset to demonstrate its significance and the analysis is provided to indicate future directions. Dataset is available at https://isrc.iscas.ac.cn/gitlab/research/locount-dataset.",
        "primary_area": "Computer Vision I",
        "author": "Yuanqiang Cai; Longyin Wen; Libo Zhang; Dawei Du; Weiqiang Wang",
        "authorids": "",
        "aff": "State Key Laboratory of Computer Science, ISCAS University of Chinese Academy of Sciences; Bytedance Inc.; State Key Laboratory of Computer Science, ISCAS University of Chinese Academy of Sciences; University at Albany, SUNY; University of Chinese Academy of Sciences",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16178/16178-13-19672-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00947-rethinking-object-detection-in-retail-stores/",
        "doi": "10.1609/aaai.v35i2.16178",
        "pdf_size": 2242193
    },
    {
        "id": "14506",
        "title": "Retrospective Reader for Machine Reading Comprehension",
        "track": "main",
        "status": "Poster",
        "abstract": "Machine reading comprehension (MRC) is an AI challenge that requires machines to determine the correct answers to questions based on a given passage. MRC systems must not only answer questions when necessary but also tactfully abstain from answering when no answer is available according to the given passage. When unanswerable questions are involved in the MRC task, an essential verification module called verifier is especially required in addition to the encoder, though the latest practice on MRC modeling still mostly benefits from adopting well pre-trained language models as the encoder block by only focusing on the \"reading\". This paper devotes itself to exploring better verifier design for the MRC task with unanswerable questions. Inspired by how humans solve reading comprehension questions, we proposed a retrospective reader (Retro-Reader) that integrates two stages of reading and verification strategies: 1) sketchy reading that briefly investigates the overall interactions of passage and question, and yields an initial judgment; 2) intensive reading that verifies the answer and gives the final prediction. The proposed reader is evaluated on two benchmark MRC challenge datasets SQuAD2.0 and NewsQA, achieving new state-of-the-art results. Significance tests show that our model is significantly better than strong baselines.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Zhuosheng Zhang; Junjie Yang; Hai Zhao",
        "authorids": "",
        "aff": "Shanghai Jiao Tong University; Shanghai Jiao Tong University; Shanghai Jiao Tong University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17705/17705-13-21199-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14506-retrospective-reader-for-machine-reading-comprehension/",
        "doi": "10.1609/aaai.v35i16.17705",
        "pdf_size": 456838
    },
    {
        "id": "00303",
        "title": "RevMan: Revenue-aware Multi-task Online Insurance Recommendation",
        "track": "main",
        "status": "Poster",
        "abstract": "Online insurance is a new type of e-commerce with exponential growth. An effective recommendation model that maximizes the total revenue of insurance products listed in multiple customized sales scenarios is crucial for the success of online insurance business. Prior recommendation models are ineffective because they fail to characterize the complex relatedness of insurance products in multiple sales scenarios and maximize the overall conversion rate rather than the total revenue. Even worse, it is impractical to collect training data online for total revenue maximization due to the business logic of online insurance. We propose RevMan, a Revenue-aware Multi-task Network for online insurance recommendation. RevMan adopts an adaptive attention mechanism to allow effective feature sharing among complex insurance products and sales scenarios. It also designs an efficient offline learning mechanism to learn the rank that maximizes the expected total revenue, by reusing training data and model for conversion rate maximization. Extensive offline and online evaluations show that RevMan outperforms the state-of-the-art recommendation systems for e-commerce.",
        "primary_area": "Application Domains",
        "author": "Yu Li; Yi Zhang; Lu Gan; Gengwei Hong; Zimu Zhou; Qiang Li",
        "authorids": "",
        "aff": "Jilin University; Wesure Inc.; Wesure Inc.; WeSure Inc.; Singapore Management University; Jilin University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16105/16105-13-19599-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00303-revman-revenue-aware-multi-task-online-insurance-recommendation/",
        "doi": "10.1609/aaai.v35i1.16105",
        "pdf_size": 999649
    },
    {
        "id": "11903",
        "title": "Revealing Hidden Preconditions and Effects of Compound HTN Planning Tasks \u2013 A Complexity Analysis",
        "track": "main",
        "status": "Poster",
        "abstract": "In Hierarchical Task Network (HTN) planning, compound tasks need to be refined into executable (primitive) action sequences. In contrast to their primitive counterparts, compound tasks do not specify preconditions or effects. Thus, their implications on the states in which they are applied are not explicitly known: they are \"hidden\" in and depending on the decomposition structure. We formalize several kinds of preconditions and effects that can be inferred for compound tasks in totally ordered HTN domains. As relevant special case we introduce a problem relaxation which admits reasoning about preconditions and effects in polynomial time. We provide procedures for doing so, thereby extending previous work, which could only deal with acyclic models. We prove our procedures to be correct and complete for any totally ordered input domain. These results are embedded into an encompassing complexity analysis of the inference of preconditions and effects of compound tasks, an investigation that has not been made so far.",
        "primary_area": "Planning, Routing, and Scheduling",
        "author": "Conny Olz; Susanne Biundo; Pascal Bercher",
        "authorids": "",
        "aff": "Ulm University; Ulm University; The Australian National University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17414/17414-13-20908-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11903-revealing-hidden-preconditions-and-effects-of-compound-htn-planning-tasks-a-complexity-analysis/",
        "doi": "10.1609/aaai.v35i13.17414",
        "pdf_size": 236238
    },
    {
        "id": "08793",
        "title": "Revisiting Co-Occurring Directions: Sharper Analysis and Efficient Algorithm for Sparse Matrices",
        "track": "main",
        "status": "Poster",
        "abstract": "We study the streaming model for approximate matrix multiplication (AMM). We are interested in the scenario that the algorithm can only take one pass over the data with limited memory. The state-of-the-art deterministic sketching algorithm for streaming AMM is the co-occurring directions (COD), which has much smaller approximation errors than randomized algorithms and outperforms other deterministic sketching methods empirically. In this paper, we provide a tighter error bound for COD whose leading term considers the potential approximate low-rank structure and the correlation of input matrices.  We prove COD is space optimal with respect to our improved error bound. We also propose a variant of COD for sparse matrices with theoretical guarantees. The experiments on real-world sparse datasets show that the proposed algorithm is more efficient than baseline methods.",
        "primary_area": "Machine Learning III",
        "author": "Luo Luo; Cheng Chen; Guangzeng Xie; Haishan Ye",
        "authorids": "",
        "aff": "Department of Mathematics, The Hong Kong University of Science and Technology; Department of Computer Science and Engineering, Shanghai Jiao Tong University; Academy for Advanced Interdisciplinary Studies, Peking University; School of Management, Xi'an Jiaotong University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17065/17065-13-20559-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08793-revisiting-co-occurring-directions-sharper-analysis-and-efficient-algorithm-for-sparse-matrices/",
        "doi": "10.1609/aaai.v35i10.17065",
        "pdf_size": 214853
    },
    {
        "id": "03976",
        "title": "Revisiting Consistent Hashing with Bounded Loads",
        "track": "main",
        "status": "Poster",
        "abstract": "Dynamic load balancing lies at the heart of distributed caching. Here, the goal is to assign objects (load) to servers (computing nodes) in a way that provides load balancing while at the same time dynamically adjusts to the addition or removal of servers. Load balancing is a critical topic in many areas including cloud systems, distributed databases, and distributed and data-parallel machine learning. A popular and widely adopted solution to dynamic load balancing is the two-decade-old Consistent Hashing (CH). Recently, an elegant extension was provided to account for server bounds. In this paper, we identify that existing methodologies for CH and its variants suffer from cascaded overflow, leading to poor load balancing. This cascading effect leads to decreasing performance of the hashing procedure with increasing load. To overcome the cascading effect, we propose a simple solution to CH based on recent advances in fast minwise hashing. We show, both theoretically and empirically, that our proposed solution is significantly superior for load balancing and is optimal in many senses. On the AOL search dataset and Indiana University Clicks dataset with real user activity, our proposed solution reduces cache misses by several magnitudes.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "John Chen; Benjamin Coleman; Anshumali Shrivastava",
        "authorids": "",
        "aff": "Rice University; Rice University; Rice University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16517/16517-13-20011-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03976-revisiting-consistent-hashing-with-bounded-loads/",
        "doi": "10.1609/aaai.v35i5.16517",
        "pdf_size": 592104
    },
    {
        "id": "11809",
        "title": "Revisiting Dominance Pruning in Decoupled Search",
        "track": "main",
        "status": "Poster",
        "abstract": "In classical planning as search, duplicate state pruning is a standard method to avoid unnecessarily handling the same state multiple times. In decoupled search, similar to symbolic search approaches, search nodes, called decoupled states, do not correspond to individual states, but to sets of states. Therefore, duplicate state pruning is less effective in decoupled search, and dominance pruning is employed, taking into account the state sets. We observe that the time required for dominance checking dominates the overall runtime, and propose two ways to tackle this issue. Our main contribution is a stronger variant of dominance checking for optimal planning, where efficiency and pruning power are most crucial. The new variant greatly improves the latter, without incurring a computational overhead. Moreover, we develop three methods that make the dominance check more efficient: exact duplicate checking, which, albeit resulting in weaker pruning, can pay off due to the use of hashing; avoiding the dominance check in non-optimal planning if leaf state spaces are invertible; and exploiting the transitivity of the dominance relation to only check against the relevant subset of visited decoupled states. We show empirically that all our improvements are indeed beneficial in many standard benchmarks.",
        "primary_area": "Planning, Routing, and Scheduling",
        "author": "Daniel Gnad",
        "authorids": "",
        "aff": "Saarland University Saarland Informatics Campus",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17403/17403-13-20897-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11809-revisiting-dominance-pruning-in-decoupled-search/",
        "doi": "10.1609/aaai.v35i13.17403",
        "pdf_size": 226464
    },
    {
        "id": "07601",
        "title": "Revisiting Iterative Back-Translation from the Perspective of Compositional Generalization",
        "track": "main",
        "status": "Poster",
        "abstract": "Human intelligence exhibits compositional generalization (i.e., the capacity to understand and produce unseen combinations of seen components), but current neural seq2seq models lack such ability. In this paper, we revisit iterative back-translation, a simple yet effective semi-supervised method, to investigate whether and how it can improve compositional generalization. In this work: (1) We first empirically show that iterative back-translation substantially improves the performance on compositional generalization benchmarks (CFQ and SCAN). (2) To understand why iterative back-translation is useful, we carefully examine the performance gains and find that iterative back-translation can increasingly correct errors in pseudo-parallel data. (3) To further encourage this mechanism, we propose curriculum iterative back-translation, which better improves the quality of pseudo-parallel data, thus further improving the performance.",
        "primary_area": "Machine Learning II",
        "author": "Yinuo Guo; Hualei Zhu; Zeqi Lin; Bei Chen; Jian-Guang Lou; Dongmei Zhang",
        "authorids": "",
        "aff": "Peking University; Beihang University; Microsoft Research Asia; Microsoft Research Asia; Microsoft Research Asia; Microsoft Research Asia",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16930/16930-13-20424-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07601-revisiting-iterative-back-translation-from-the-perspective-of-compositional-generalization/",
        "doi": "10.1609/aaai.v35i9.16930",
        "pdf_size": 2713455
    },
    {
        "id": "13675",
        "title": "Revisiting Mahalanobis Distance for Transformer-Based Out-of-Domain Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Real-life applications, heavily relying on machine learning, such as dialog systems, demand for out-of-domain detection methods. Intent classification models should be equipped with a mechanism to distinguish seen intents from unseen ones so that the dialog agent is capable of rejecting the latter and avoiding undesired behavior. However, despite increasing attention paid to the task, the best practices for out-of-domain intent detection have not yet been fully established.   This paper conducts a thorough comparison of out-of-domain intent detection methods. We prioritize the methods, not requiring access to out-of-domain data during training, gathering of which is extremely time- and labor-consuming due to lexical and stylistic variation of user utterances. We evaluate multiple contextual encoders and methods, proven to be efficient, on three common datasets for intent classification, expanded with out-of-domain utterances. Our main findings show that fine-tuning Transformer-based encoders on in-domain data leads to superior results. Mahalanobis distance, together with utterance representations, derived from Transformer-based encoders, outperform other methods by a wide margin(1-5% in terms of AUROC) and establish new state-of-the-art results for all datasets.   The broader analysis shows that the reason for success lies in the fact that the fine-tuned Transformer is capable of constructing homogeneous representations of in-domain utterances, revealing geometrical disparity to out of domain utterances. In turn, the Mahalanobis distance captures this disparity easily.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Alexander Podolskiy; Dmitry Lipin; Andrey Bout; Ekaterina Artemova; Irina Piontkovskaya",
        "authorids": "",
        "aff": "Huawei Noah\u2019s Ark Lab, Moscow, Russia; Huawei Noah\u2019s Ark Lab, Moscow, Russia; Huawei Noah\u2019s Ark Lab, Moscow, Russia; Huawei Noah\u2019s Ark Lab, Moscow, Russia HSE University, Moscow, Russia; Huawei Noah\u2019s Ark Lab, Moscow, Russia",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17612/17612-13-21106-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13675-revisiting-mahalanobis-distance-for-transformer-based-out-of-domain-detection/",
        "doi": "10.1609/aaai.v35i15.17612",
        "pdf_size": 433382
    },
    {
        "id": "07874",
        "title": "Reward-Biased Maximum Likelihood Estimation for Linear Stochastic Bandits",
        "track": "main",
        "status": "Poster",
        "abstract": "Modifying the reward-biased maximum likelihood method originally proposed in the adaptive control literature, we propose novel learning algorithms to handle the explore-exploit trade-off in linear bandits problems as well as generalized linear bandits problems. We develop novel index policies that we prove achieve order-optimality, and show that they achieve empirical performance competitive with the state-of-the-art benchmark methods in extensive experiments. The new policies achieve this with low computation time per pull for linear bandits, and thereby resulting in both favorable regret as well as computational efficiency.",
        "primary_area": "Machine Learning II",
        "author": "Yu-Heng Hung; Ping-Chun Hsieh; Xi Liu; P. R. Kumar",
        "authorids": "",
        "aff": "National Chiao Tung University National Yang Ming Chiao Tung University; National Chiao Tung University National Yang Ming Chiao Tung University; Texas A&M University; Texas A&M University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16961/16961-13-20455-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07874-reward-biased-maximum-likelihood-estimation-for-linear-stochastic-bandits/",
        "doi": "10.1609/aaai.v35i9.16961",
        "pdf_size": 737702
    },
    {
        "id": "00854",
        "title": "Riemannian Embedding Banks for Common Spatial Patterns with EEG-based SPD Neural Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Modeling non-linear data as symmetric positive definite (SPD) matrices on Riemannian manifolds has attracted much attention for various classification tasks. In the context of deep learning, SPD matrix-based Riemannian networks have been shown to be a promising solution for classifying electroencephalogram (EEG) signals, capturing the Riemannian geometry within their structured 2D feature representation. However, existing approaches usually learn spatial-temporal structures in an embedding space for all available EEG signals, and their optimization procedures rely on computationally expensive iterations. Furthermore, these approaches often struggle to encode all of the various types of relationships into a single distance metric, resulting in a loss of generality. To address the above limitations, we propose a Riemannian Embedding Banks method, which divides the problem of common spatial patterns learning in an entire embedding space into K-subproblems and builds one model for each subproblem, to be combined with SPD neural networks. By leveraging the concept of the \"separate to learn\" technology on a Riemannian manifold, REB divides the data and the embedding space into K non-overlapping subsets and learns K separate distance metrics in a Riemannian geometric space instead of the vector space. Then, the learned K non-overlapping subsets are grouped into neurons in the SPD neural network's embedding layer. Experimental results on public EEG datasets demonstrate the superiority of the proposed approach for learning common spatial patterns of EEG signals despite their non-stationary nature, increasing the convergence speed while maintaining generalization.",
        "primary_area": "Cognitive Modeling and Cognitive Systems",
        "author": "Yoon-Je Suh; Byung Hyung Kim",
        "authorids": "",
        "aff": "KAIST; KAIST",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16168/16168-13-19662-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00854-riemannian-embedding-banks-for-common-spatial-patterns-with-eeg-based-spd-neural-networks/",
        "doi": "10.1609/aaai.v35i1.16168",
        "pdf_size": 2525692
    },
    {
        "id": "09533",
        "title": "Right for Better Reasons: Training Differentiable Models by Constraining their Influence Functions",
        "track": "main",
        "status": "Poster",
        "abstract": "Explaining black-box models such as deep neural networks is becoming increasingly important as it helps to boost trust and debugging. Popular forms of explanations map the features to a vector indicating their individual importance to a decision on the instance-level. They can then be used to prevent the model from learning the wrong bias in data possibly due to ambiguity. For instance, Ross et al.'s ``right for the right reasons'' propagates user explanations backwards to the network by formulating differentiable constraints based on input gradients.   Unfortunately, input gradients as well as many other widely used explanation methods form an approximation of the decision boundary and assume the underlying model to be fixed. Here, we demonstrate how to make use of influence functions---a well known robust statistic---in the constraints to correct the model\u2019s behaviour more effectively. Our empirical evidence demonstrates that this ``right for better reasons''(RBR) considerably reduces the time to correct the classifier at training time and boosts the quality of explanations at inference time compared to input gradients. Besides, we also showcase the effectiveness of RBR in correcting \"Clever Hans\"-like behaviour in real, high-dimensional domain.",
        "primary_area": "Machine Learning IV",
        "author": "Xiaoting Shao; Arseny Skryagin; Wolfgang Stammer; Patrick Schramowski; Kristian Kersting",
        "authorids": "",
        "aff": "TU Darmstadt; TU Darmstadt; TU Darmstadt; TU Darmstadt; TU Darmstadt",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17148/17148-13-20642-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09533-right-for-better-reasons-training-differentiable-models-by-constraining-their-influence-functions/",
        "doi": "10.1609/aaai.v35i11.17148",
        "pdf_size": 12115514
    },
    {
        "id": "10594",
        "title": "Robust Bandit Learning with Imperfect Context",
        "track": "main",
        "status": "Poster",
        "abstract": "A standard assumption in contextual multi-arm bandit is that the true context is perfectly known before arm selection. Nonetheless, in many practical applications (e.g., cloud resource management), prior to arm selection, the context information can only be acquired by prediction subject to errors or adversarial modification. In this paper, we study a novel contextual bandit setting in which only imperfect context is available for arm selection while the true context is revealed at the end of each round. We propose two robust arm selection algorithms: MaxMinUCB (Maximize Minimum UCB) which maximizes the worst-case reward, and MinWD (Minimize Worst-case Degradation) which minimizes the worst-case regret. Importantly, we analyze the robustness of MaxMinUCB and MinWD by deriving both regret and reward bounds compared to an oracle that knows the true context. Our results show that as time goes on, MaxMinUCB and MinWD both perform as asymptotically well as their optimal counterparts that know the reward function. Finally, we apply MaxMinUCB and MinWD to online edge datacenter selection, and run synthetic simulations to validate our theoretical analysis.",
        "primary_area": "Machine Learning V",
        "author": "Jianyi Yang; Shaolei Ren",
        "authorids": "",
        "aff": "UC Riverside; UC Riverside",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17267/17267-13-20761-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10594-robust-bandit-learning-with-imperfect-context/",
        "doi": "10.1609/aaai.v35i12.17267",
        "pdf_size": 5348551
    },
    {
        "id": "12182",
        "title": "Robust Contextual Bandits via Bootstrapping",
        "track": "main",
        "status": "Poster",
        "abstract": "Upper confidence bound (UCB) based contextual bandit algorithms require one to know the tail property of the reward distribution. Unfortunately, such tail property is usually unknown or difficult to specify in real-world applications. Using a tail property heavier than the ground truth leads to a slow learning speed of the contextual bandit algorithm, while using a lighter one may cause the algorithm to diverge. To address this fundamental problem, we develop an estimator (evaluated from historical rewards) for the contextual bandit UCB based on the multiplier bootstrapping technique. We first establish sufficient conditions under which our estimator converges asymptotically to the ground truth of contextual bandit UCB. We further derive a second order correction for our estimator so as to obtain its confidence level with a finite number of rounds. To demonstrate the versatility of the estimator, we apply it to design a BootLinUCB algorithm for the contextual bandit. We prove that the BootLinUCB has a sub-linear regret upper bound and also conduct extensive experiments to validate its superior performance.",
        "primary_area": "Reasoning under Uncertainty",
        "author": "Qiao Tang; Hong Xie; Yunni Xia; Jia Lee; Qingsheng Zhu",
        "authorids": "",
        "aff": "Chongqing Key Laboratory of Software Theory and Technology, Chongqing University; Chongqing Key Laboratory of Software Theory and Technology, Chongqing University; Chongqing Key Laboratory of Software Theory and Technology, Chongqing University; Chongqing Key Laboratory of Software Theory and Technology, Chongqing University; Chongqing Key Laboratory of Software Theory and Technology, Chongqing University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17446/17446-13-20940-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12182-robust-contextual-bandits-via-bootstrapping/",
        "doi": "10.1609/aaai.v35i13.17446",
        "pdf_size": 408859
    },
    {
        "id": "09419",
        "title": "Robust Fairness Under Covariate Shift",
        "track": "main",
        "status": "Poster",
        "abstract": "Making predictions that are fair with regard to protected attributes (race, gender, age, etc.) has become an important requirement for classification algorithms. Existing techniques derive a fair model from sampled labeled data relying on the assumption that training and testing data are identically and independently drawn (iid) from the same distribution. In practice, distribution shift can and does occur between training and testing datasets as the characteristics of individuals interacting with the machine learning system change. We investigate fairness under covariate shift, a relaxation of the iid assumption in which the inputs or covariates change while the conditional label distribution remains the same. We seek fair decisions under these assumptions on target data with unknown labels. We propose an approach that obtains the predictor that is robust to the worst-case testing performance while satisfying target fairness requirements and matching statistical properties of the source data. We demonstrate the benefits of our approach on benchmark prediction tasks.",
        "primary_area": "Machine Learning IV",
        "author": "Ashkan Rezaei; Anqi Liu; Omid Memarrast; Brian D. Ziebart",
        "authorids": "",
        "aff": "University of Illinois at Chicago; California Institute of Technology; University of Illinois at Chicago; University of Illinois at Chicago",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17135/17135-13-20629-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09419-robust-fairness-under-covariate-shift/",
        "doi": "10.1609/aaai.v35i11.17135",
        "pdf_size": 2944618
    },
    {
        "id": "11792",
        "title": "Robust Finite-State Controllers for Uncertain POMDPs",
        "track": "main",
        "status": "Poster",
        "abstract": "Uncertain partially observable Markov decision processes (uPOMDPs) allow the probabilistic transition and observation functions of standard POMDPs to belong to a so-called uncertainty set. Such uncertainty, referred to as epistemic uncertainty, captures uncountable sets of probability distributions caused by, for instance, a lack of data available. We develop an algorithm to compute finite-memory policies for uPOMDPs that robustly satisfy specifications against any admissible distribution. In general, computing such policies is theoretically and practically intractable.  We provide an efficient solution to this problem in four steps. (1) We state the underlying problem as a nonconvex optimization problem with infinitely many constraints.  (2) A dedicated dualization scheme yields a dual problem that is still nonconvex but has finitely many constraints.  (3) We linearize this dual problem and (4) solve the resulting finite linear program to obtain locally optimal solutions to the original problem. The resulting problem formulation is exponentially smaller than those resulting from existing methods. We demonstrate the applicability of our algorithm using large instances of an aircraft collision-avoidance scenario and a novel spacecraft motion planning case study.",
        "primary_area": "Planning, Routing, and Scheduling",
        "author": "Murat Cubuktepe; Nils Jansen; Sebastian Junges; Ahmadreza Marandi; Marnix Suilen; Ufuk Topcu",
        "authorids": "",
        "aff": "The University of Texas at Austin; Radboud University Nijmegen; University of California, Berkeley; Eindhoven University of Technology; Radboud University Nijmegen; University of Texas at Austin",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17401/17401-13-20895-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11792-robust-finite-state-controllers-for-uncertain-pomdps/",
        "doi": "10.1609/aaai.v35i13.17401",
        "pdf_size": 482490
    },
    {
        "id": "02558",
        "title": "Robust Knowledge Transfer via Hybrid Forward on the Teacher-Student Model",
        "track": "main",
        "status": "Poster",
        "abstract": "When adopting deep neural networks for a new vision task, a common practice is to start with fine-tuning some off-the-shelf well-trained network models from the community. Since a new task may require training a different network architecture with new domain data, taking advantage of off-the-shelf models is not trivial and generally requires considerable try-and-error and parameter tuning. In this paper, we denote a well-trained model as a teacher network and a model for the new task as a student network. We aim to ease the efforts of transferring knowledge from the teacher to the student network, robust to the gaps between their network architectures, domain data, and task definitions. Specifically, we propose a hybrid forward scheme in training the teacher-student models, alternately updating layer weights of the student model. The key merit of our hybrid forward scheme is on the dynamical balance between the knowledge transfer loss and task specific loss in training. We demonstrate the effectiveness of our method on a variety of tasks, e.g., model compression, segmentation, and detection, under a variety of knowledge transfer settings.",
        "primary_area": "Computer Vision II",
        "author": "Liangchen Song; Jialian Wu; Ming Yang; Qian Zhang; Yuan Li; Junsong Yuan",
        "authorids": "",
        "aff": "University at Buffalo; University at Buffalo; Horizon Robotics; Horizon Robotics; Google; University at Buffalo",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16358/16358-13-19852-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02558-robust-knowledge-transfer-via-hybrid-forward-on-the-teacher-student-model/",
        "doi": "10.1609/aaai.v35i3.16358",
        "pdf_size": 1716997
    },
    {
        "id": "03510",
        "title": "Robust Lightweight Facial Expression Recognition Network with Label Distribution Training",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents an efficiently robust facial expression recognition (FER) network, named EfficientFace, which holds much fewer parameters but more robust to the FER in the wild. Firstly, to improve the robustness of the lightweight network, a local-feature extractor and a channel-spatial modulator are designed, in which the depthwise convolution is employed. As a result, the network is aware of local and global-salient facial features. Then, considering the fact that most emotions occur as combinations, mixtures, or compounds of the basic emotions, we introduce a simple but efficient label distribution learning (LDL) method as a novel training strategy. Experiments conducted on realistic occlusion and pose variation datasets demonstrate that the proposed EfficientFace is robust under occlusion and pose variation conditions. Moreover, the proposed method achieves state-of-the-art results on RAF-DB, CAER-S, and AffectNet-7 datasets with accuracies of 88.36%, 85.87%, and 63.70%, respectively, and a comparable result on the AffectNet-8 dataset with an accuracy of 59.89%. The code is public available at https://github.com/zengqunzhao/EfficientFace.",
        "primary_area": "Computer Vision III",
        "author": "Zengqun Zhao; Qingshan Liu; Feng Zhou",
        "authorids": "",
        "aff": "Nanjing University of Information Science & Technology, Nanjing, China; Nanjing University of Information Science & Technology, Nanjing, China; Nanjing University of Information Science & Technology, Nanjing, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16465/16465-13-19959-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03510-robust-lightweight-facial-expression-recognition-network-with-label-distribution-training/",
        "doi": "10.1609/aaai.v35i4.16465",
        "pdf_size": 526261
    },
    {
        "id": "06688",
        "title": "Robust Model Compression Using Deep Hypotheses",
        "track": "main",
        "status": "Poster",
        "abstract": "Machine Learning models should ideally be compact and robust. Compactness provides efficiency and comprehensibility whereas robustness provides stability. Both topics have been studied in recent years but in isolation. Here we present a robust model compression scheme which is independent of model types: it can compress ensembles, neural networks and other types of models into diverse types of small models.  The main building block is the notion of depth derived from robust statistics.  Originally, depth was introduced as a measure of the centrality of a point in a sample such that the median is the deepest point. This concept was extended to classification functions which makes it possible to define the depth of a hypothesis and the median hypothesis. Algorithms have been suggested to approximate the median but they have been limited to binary classification. In this study, we present a new algorithm, the Multiclass Empirical Median Optimization (MEMO) algorithm that finds a deep hypothesis in multi-class tasks, and prove its correctness. This led to our Compact Robust Estimated Median Belief Optimization (CREMBO) algorithm for robust model compression. We demonstrate the success of this algorithm empirically by compressing neural networks and random forests into small decision trees, which are interpretable models, and show that they are more accurate and robust than other comparable methods. In addition, our empirical study shows that our method outperforms Knowledge Distillation on DNN to DNN compression.",
        "primary_area": "Machine Learning I",
        "author": "Omri Armstrong; Ran Gilad-Bachrach",
        "authorids": "",
        "aff": "Tel Aviv University; Tel-Aviv University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16827/16827-13-20321-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06688-robust-model-compression-using-deep-hypotheses/",
        "doi": "10.1609/aaai.v35i8.16827",
        "pdf_size": 138496
    },
    {
        "id": "03529",
        "title": "Robust Multi-Modality Person Re-identification",
        "track": "main",
        "status": "Poster",
        "abstract": "To avoid the illumination limitation in visible person re-identification (Re-ID) and the heterogeneous issue in cross-modality Re-ID, we propose to utilize complementary advantages of multiple modalities including visible (RGB), near infrared (NI) and thermal infrared (TI) ones for robust person Re-ID. A novel progressive fusion network is designed to learn effective multi-modal features from single to multiple modalities and from local to global views. Our method works well in diversely challenging scenarios even in the presence of missing modalities. Moreover, we contribute a comprehensive benchmark dataset, RGBNT201, including 201 identities captured from various challenging conditions, to facilitate the research of RGB-NI-TI multi-modality person Re-ID. Comprehensive experiments on RGBNT201 dataset comparing to the state-of-the-art methods demonstrate the contribution of multi-modality person Re-ID and the effectiveness of the proposed approach, which launch a new benchmark and a new baseline for multi-modality person Re-ID.",
        "primary_area": "Computer Vision III",
        "author": "Aihua Zheng; Zi Wang; Zihan Chen; Chenglong Li; Jin Tang",
        "authorids": "",
        "aff": "Anhui University; Anhui University; Anhui University; Anhui University; Anhui University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16467/16467-13-19961-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03529-robust-multi-modality-person-re-identification/",
        "doi": "10.1609/aaai.v35i4.16467",
        "pdf_size": 2833625
    },
    {
        "id": "09303",
        "title": "Robust Reinforcement Learning: A Case Study in Linear Quadratic Regulation",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper studies the robustness of reinforcement learning algorithms to errors in the learning process. Specifically, we revisit the benchmark problem of discrete-time linear quadratic regulation (LQR) and study the long-standing open question: Under what conditions is the policy iteration method robustly stable from a dynamical systems perspective? Using advanced stability results in control theory, it is shown that policy iteration for LQR is inherently robust to small errors in the learning process and enjoys small-disturbance input-to-state stability: whenever the error in each iteration is bounded and small, the solutions of the policy iteration algorithm are also bounded, and, moreover, enter and stay in a small neighborhood of the optimal LQR solution. As an application, a novel off-policy optimistic least-squares policy iteration for the LQR problem is proposed, when the system dynamics are subjected to additive stochastic disturbances. The proposed new results in robust reinforcement learning are validated by a numerical example.",
        "primary_area": "Machine Learning III",
        "author": "Bo Pang; Zhong-Ping Jiang",
        "authorids": "",
        "aff": "New York University; New York University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17122/17122-13-20616-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09303-robust-reinforcement-learning-a-case-study-in-linear-quadratic-regulation/",
        "doi": "10.1609/aaai.v35i10.17122",
        "pdf_size": 303038
    },
    {
        "id": "04312",
        "title": "Robust Spatio-Temporal Purchase Prediction via Deep Meta Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Purchase prediction is an essential task in both online and offline retail industry, especially during major shopping festivals, when strong promotion boosts consumption dramatically. It is important for merchants to forecast such surge of sales and have better preparation. This is a challenging problem, as the purchase patterns during shopping festivals are significantly different from usual cases and also rare in historical data. Most existing methods fail at this problem due to the extremely scarce data samples as well as the inability to capture the complex macroscopic spatio-temporal dependencies in a city. To address this problem, we propose the Spatio-Temporal Meta-learning Prediction (STMP) model for purchase prediction during shopping festivals. STMP is a meta-learning based spatio-temporal multi-task deep generative model. It adopts a meta-learning framework with few-shot learning capability to capture both spatial and temporal data representations. A generative component then uses the extracted spatio-temporal representation and input data to infer the prediction results. Extensive experiments demonstrate the meta-learning generalization ability of STMP. STMP outperforms baselines in all cases, which shows the effectiveness of our model.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Huiling Qin; Songyu Ke; Xiaodu Yang; Haoran Xu; Xianyuan Zhan; Yu Zheng",
        "authorids": "",
        "aff": "Xidian University JD Intelligent Cities Research JD iCity, JD Technology; Shanghai Jiao Tong University JD Intelligent Cities Research JD iCity, JD Technology; Southwest Jiaotong University JD Intelligent Cities Research JD iCity, JD Technology; Xidian University JD Intelligent Cities Research JD iCity, JD Technology; JD Intelligent Cities Research JD iCity, JD Technology; Xidian University JD Intelligent Cities Research JD iCity, JD Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16556/16556-13-20050-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04312-robust-spatio-temporal-purchase-prediction-via-deep-meta-learning/",
        "doi": "10.1609/aaai.v35i5.16556",
        "pdf_size": 4044720
    },
    {
        "id": "09277",
        "title": "Robustness Guarantees for Mode Estimation with an Application to Bandits",
        "track": "main",
        "status": "Poster",
        "abstract": "Mode estimation is a classical problem in statistics with a wide range of applications in machine learning. Despite this, there is little understanding in its robustness properties under possibly adversarial data contamination. In this paper, we give precise robustness guarantees as well as privacy guarantees under simple randomization. We then introduce a theory for multi-armed bandits where the values are the modes of the reward distributions instead of the mean. We prove regret guarantees for the problems of top arm identification, top m-arms identification, contextual modal bandits, and infinite continuous arms top arm recovery. We show in simulations that our algorithms are robust to perturbation of the arms by adversarial noise sequences, thus rendering modal bandits an attractive choice in situations where the rewards may have outliers or adversarial corruptions.",
        "primary_area": "Machine Learning III",
        "author": "Aldo Pacchiano; Heinrich Jiang; Michael I. Jordan",
        "authorids": "",
        "aff": "UC Berkeley; Google Research; UC Berkeley",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17119/17119-13-20613-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09277-robustness-guarantees-for-mode-estimation-with-an-application-to-bandits/",
        "doi": "10.1609/aaai.v35i10.17119",
        "pdf_size": 348064
    },
    {
        "id": "11451",
        "title": "Robustness of Accuracy Metric and its Inspirations in Learning with Noisy Labels",
        "track": "main",
        "status": "Poster",
        "abstract": "For multi-class classification under class-conditional label noise, we prove that the accuracy metric itself can be robust. We concretize this finding's inspiration in two essential aspects: training and validation, with which we address critical issues in learning with noisy labels. For training, we show that maximizing training accuracy on sufficiently many noisy samples yields an approximately optimal classifier. For validation, we prove that a noisy validation set is reliable, addressing the critical demand of model selection in scenarios like hyperparameter-tuning and early stopping. Previously, model selection using noisy validation samples has not been theoretically justified. We verify our theoretical results and additional claims with extensive experiments. We show characterizations of models trained with noisy labels, motivated by our theoretical results, and verify the utility of a noisy validation set by showing the impressive performance of a framework termed noisy best teacher and student (NTS). Our code is released.",
        "primary_area": "Philosophy and Ethics of AI",
        "author": "Pengfei Chen; Junjie Ye; Guangyong Chen; Jingwei Zhao; Pheng-Ann Heng",
        "authorids": "",
        "aff": "The Chinese University of Hong Kong; VIVO AI Lab; Guangdong Provincial Key Laboratory of Computer Vision and Virtual Reality Technology, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences; VIVO AI Lab; The Chinese University of Hong Kong Guangdong Provincial Key Laboratory of Computer Vision and Virtual Reality Technology, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17364/17364-13-20858-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11451-robustness-of-accuracy-metric-and-its-inspirations-in-learning-with-noisy-labels/",
        "doi": "10.1609/aaai.v35i13.17364",
        "pdf_size": 776019
    },
    {
        "id": "14024",
        "title": "Robustness to Spurious Correlations in Text Classification via Automatically Generated Counterfactuals",
        "track": "main",
        "status": "Poster",
        "abstract": "Spurious correlations threaten the validity of statistical classifiers. While model accuracy may appear high when the test data is from the same distribution as the training data, it can quickly degrade when the test distribution changes. For example, it has been shown that classifiers perform poorly when humans make minor modifications to change the label of an example. One solution to increase model reliability and generalizability is to identify causal associations between features and classes. In this paper, we propose to train a robust text classifier by augmenting the training data with automatically generated counterfactual data. We first identify likely causal features using a statistical matching approach. Next, we generate counterfactual samples for the original training data by substituting causal features with their antonyms and then assigning opposite labels to the counterfactual samples. Finally, we combine the original data and counterfactual data to train a robust classifier. Experiments on two classification tasks show that a traditional classifier trained on the original data does very poorly on human-generated counterfactual samples (e.g., 10%-37% drop in accuracy). However, the classifier trained on the combined data is more robust and performs well on both the original test data and the counterfactual test data (e.g., 12%-25% increase in accuracy compared with the traditional classifier). Detailed analysis shows that the robust classifier makes meaningful and trustworthy predictions by emphasizing causal features and de-emphasizing non-causal features.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Zhao Wang; Aron Culotta",
        "authorids": "",
        "aff": "Illinois Institute of Technology; Tulane University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17651/17651-13-21145-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14024-robustness-to-spurious-correlations-in-text-classification-via-automatically-generated-counterfactuals/",
        "doi": "10.1609/aaai.v35i16.17651",
        "pdf_size": 235475
    },
    {
        "id": "13860",
        "title": "RpBERT: A Text-image Relation Propagation-based BERT Model for Multimodal NER",
        "track": "main",
        "status": "Poster",
        "abstract": "Recently multimodal named entity recognition (MNER) has utilized images to improve the accuracy of NER in tweets. However, most of the multimodal methods use attention mechanisms to extract visual clues regardless of whether the text and image are relevant. Practically, the irrelevant text-image pairs account for a large proportion in tweets. The visual clues that are unrelated to the texts will exert uncertain or even negative effects on multimodal model learning. In this paper, we introduce a method of text-image relation propagation into the multimodal BERT model. We integrate soft or hard gates to select visual clues and propose a multitask algorithm to train and validate the effects of relation propagation on the MNER datasets. In the experiments, we deeply analyze the changes in visual attention before and after the use of relation propagation. Our model achieves state-of-the-art performance on the MNER datasets.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Lin  Sun; Jiquan Wang; Kai Zhang; Yindu Su; Fangsheng Weng",
        "authorids": "",
        "aff": "Zhejiang University City College; Zhejiang University Zhejiang University City College; Tsinghua University; Zhejiang University Zhejiang University City College; Zhejiang University City College",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17633/17633-13-21127-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13860-rpbert-a-text-image-relation-propagation-based-bert-model-for-multimodal-ner/",
        "doi": "10.1609/aaai.v35i15.17633",
        "pdf_size": 1322186
    },
    {
        "id": "02091",
        "title": "SA-BNN: State-Aware Binary Neural Network",
        "track": "main",
        "status": "Poster",
        "abstract": "Binary Neural Networks (BNNs) have received significant attention due to the memory and computation efficiency recently. However, the considerable accuracy gap between BNNs and their full-precision counterparts hinders BNNs to be deployed to resource-constrained platforms. One of the main reasons for the performance gap can be attributed to the frequent weight flip, which is caused by the misleading weight update in BNNs. To address this issue, we propose a state-aware binary neural network (SA-BNN) equipped with the well designed state-aware gradient. Our SA-BNN is inspired by the observation that the frequent weight flip is more likely to occur, when the gradient magnitude for all quantization states {-1,1} is identical. Accordingly, we propose to employ independent gradient coefficients for different states when updating the weights. Furthermore, we also analyze the effectiveness of the state-aware gradient on suppressing the frequent weight flip problem. Experiments on ImageNet show that the proposed SA-BNN outperforms the current state-of-the-arts (e.g., Bi-Real Net) by more than 3% when using a ResNet architecture. Specifically, we achieve 61.7%, 65.5% and 68.7% Top-1 accuracy with ResNet-18, ResNet-34 and ResNet-50 on ImageNet, respectively.",
        "primary_area": "Computer Vision II",
        "author": "Chunlei Liu; Peng Chen; Bohan Zhuang; Chunhua Shen; Baochang Zhang; Wenrui Ding",
        "authorids": "",
        "aff": "Beihang University The University of Adelaide; The University of Adelaide; Monash University; The University of Adelaide; Beihang University; Beihang University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16306/16306-13-19800-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02091-sa-bnn-state-aware-binary-neural-network/",
        "doi": "10.1609/aaai.v35i3.16306",
        "pdf_size": 1129268
    },
    {
        "id": "13189",
        "title": "SALNet: Semi-supervised Few-Shot Text Classification with Attention-based Lexicon Construction",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a semi-supervised bootstrap learning framework for few-shot text classification. From a small amount of the initial dataset, our framework obtains a larger set of reliable training data by using the attention weights from an LSTM-based trained classifier. We first train an LSTM-based text classifier from a given labeled dataset using the attention mechanism. Then, we collect a set of words for each class called a lexicon, which is supposed to be a representative set of words for each class based on the attention weights calculated for the classification task. We bootstrap the classifier using the new data that are labeled by the combination of the classifier and the constructed lexicons to improve the prediction accuracy. As a result, our approach outperforms the previous state-of-the-art methods including semi-supervised learning algorithms and pretraining algorithms for  few-shot text classification task on four publicly available benchmark datasets. Moreover, we empirically confirm that the constructed lexicons are reliable enough and substantially improve the performance of the original classifier.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Ju-Hyoung Lee; Sang-Ki Ko; Yo-Sub Han",
        "authorids": "",
        "aff": "Yonsei University; Kangwon National University; Yonsei University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17558/17558-13-21052-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13189-salnet-semi-supervised-few-shot-text-classification-with-attention-based-lexicon-construction/",
        "doi": "10.1609/aaai.v35i14.17558",
        "pdf_size": 207926
    },
    {
        "id": "13055",
        "title": "SARG: A Novel Semi Autoregressive Generator for Multi-turn Incomplete Utterance Restoration",
        "track": "main",
        "status": "Poster",
        "abstract": "Dialogue systems in open domain have achieved great success due to the easily obtained single-turn corpus and the development of deep learning, but the multi-turn scenario is still a challenge because of the frequent coreference and information omission. In this paper, we investigate the incomplete utterance restoration which has brought general improvement over multi-turn dialogue systems in recent studies. Meanwhile, inspired by the autoregression for text generation and the sequence labeling for text editing, we propose a novel semi autoregressive generator (SARG) with the high efficiency and flexibility. Moreover, experiments on Restoration-200k show that our proposed model significantly outperforms the state-of-the-art models in terms of quality and inference speed.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Mengzuo Huang; Feng Li; Wuhe Zou; Weidong Zhang",
        "authorids": "",
        "aff": "Dalian University of Technology Netease Games AI Lab; Netease Games AI Lab; Netease Games AI Lab; Netease Games AI Lab",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17543/17543-13-21037-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13055-sarg-a-novel-semi-autoregressive-generator-for-multi-turn-incomplete-utterance-restoration/",
        "doi": "10.1609/aaai.v35i14.17543",
        "pdf_size": 361816
    },
    {
        "id": "03904",
        "title": "SAT-based Decision Tree Learning for Large Data Sets",
        "track": "main",
        "status": "Poster",
        "abstract": "Decision trees of low depth are beneficial for understanding and interpreting the data they represent.  Unfortunately, finding a decision tree of lowest depth that correctly represents given data is NP-hard.  Hence known algorithms either (i) utilize heuristics that do not optimize the depth or (ii) are exact but scale only to small or medium-sized instances.  We propose a new hybrid approach to decision tree learning, combining heuristic and exact methods in a novel way.  More specifically, we employ SAT encodings repeatedly to local parts of a decision tree provided by a standard heuristic, leading to a global depth improvement.  This allows us to scale the power of exact SAT-based methods to almost arbitrarily large data sets.  We evaluate our new approach experimentally on a range of real-world instances that contain up to several thousand samples.  In almost all cases, our method successfully decreases the depth of the initial decision tree; often, the decrease is significant.",
        "primary_area": "Constraint Satisfaction and Optimization",
        "author": "Andre Schidler; Stefan Szeider",
        "authorids": "",
        "aff": "TU Wien, Vienna, Austria; TU Wien, Vienna, Austria",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16509/16509-13-20003-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03904-sat-based-decision-tree-learning-for-large-data-sets/",
        "doi": "10.1609/aaai.v35i5.16509",
        "pdf_size": 159298
    },
    {
        "id": "06119",
        "title": "SCAN: A Spatial Context Attentive Network for Joint Multi-Agent Intent Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "Safe navigation of autonomous agents in human centric environments requires the ability to understand and predict motion of neighboring pedestrians. However, predicting pedestrian intent is a complex problem. Pedestrian motion is governed by complex social navigation norms, is dependent on neighbors' trajectories and is multimodal in nature. In this work, we propose SCAN, a Spatial Context Attentive Network that can jointly predict socially-acceptable multiple future trajectories for all pedestrians in a scene. SCAN encodes the influence of spatially close neighbors using a novel spatial attention mechanism in a manner that relies on fewer assumptions, is parameter efficient, and is more interpretable compared to state-of-the-art spatial attention approaches. Through experiments on several datasets we demonstrate that our approach can also quantitatively outperform state of the art trajectory prediction methods in terms of accuracy of predicted intent.",
        "primary_area": "Intelligent Robots",
        "author": "Jasmine  Sekhon; Cody Fleming",
        "authorids": "",
        "aff": "University of Virginia; University of Virginia Iowa State University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16762/16762-13-20256-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06119-scan-a-spatial-context-attentive-network-for-joint-multi-agent-intent-prediction/",
        "doi": "10.1609/aaai.v35i7.16762",
        "pdf_size": 2339264
    },
    {
        "id": "02701",
        "title": "SCNet: Training Inference Sample Consistency for Instance Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "Cascaded architectures have brought significant performance improvement in object detection and instance segmentation. However, there are lingering issues regarding the disparity in the Intersection-over-Union (IoU) distribution of the samples between training and inference. This disparity can potentially exacerbate detection accuracy. This paper proposes an architecture referred to as Sample Consistency Network (SCNet) to ensure that the IoU distribution of the samples at training time is close to that at inference time. Furthermore, SCNet incorporates feature relay and utilizes global contextual information to further reinforce the reciprocal relationships among classifying, detecting, and segmenting sub-tasks. Extensive experiments on the standard COCO dataset reveal the effectiveness of the proposed method over multiple evaluation metrics, including box AP, mask AP, and inference speed. In particular, while running 38% faster, the proposed SCNet improves the AP of the box and mask predictions by respectively 1.3 and 2.3 points compared to the strong Cascade Mask R-CNN baseline. Code is available at https://github.com/thangvubk/SCNet.",
        "primary_area": "Computer Vision II",
        "author": "Thang Vu; Haeyong Kang; Chang D. Yoo",
        "authorids": "",
        "aff": "KAIST, Korea; KAIST, Korea; KAIST, Korea",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16374/16374-13-19868-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02701-scnet-training-inference-sample-consistency-for-instance-segmentation/",
        "doi": "10.1609/aaai.v35i3.16374",
        "pdf_size": 7419368
    },
    {
        "id": "13470",
        "title": "SCRUPLES: A Corpus of Community Ethical Judgments on 32,000 Real-Life Anecdotes",
        "track": "main",
        "status": "Poster",
        "abstract": "As AI systems become an increasing part of people's everyday lives, it becomes ever more important that they understand people's ethical norms. Motivated by descriptive ethics, a field of study that focuses on people's descriptive judgments rather than theoretical prescriptions on morality, we investigate a novel, data-driven approach to machine ethics.  We introduce SCRUPLES, the first large-scale dataset with 625,000 ethical judgments over 32,000 real-life anecdotes. Each anecdote recounts a complex ethical situation, often posing moral dilemmas, paired with a distribution of judgments contributed by the community members. Our dataset presents a major challenge to state-of-the-art neural language models, leaving significant room for improvement. However, when presented with simplified moral situations, the results are considerably more promising, suggesting that neural models can effectively learn simpler ethical building blocks.  A key take-away of our empirical analysis is that norms are not always clean-cut; many situations are naturally divisive. We present a new method to estimate the best possible performance on such tasks with inherently diverse label distributions, and explore likelihood functions that separate intrinsic from model uncertainty. Data and code are available at https://github.com/allenai/scruples.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Nicholas Lourie; Ronan Le Bras; Yejin Choi",
        "authorids": "",
        "aff": "Allen Institute for AI; Allen Institute for AI; Paul G. Allen School of Computer Science & Engineering, University of Washington Allen Institute for AI",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17589/17589-13-21083-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13470-scruples-a-corpus-of-community-ethical-judgments-on-32-000-real-life-anecdotes/",
        "doi": "10.1609/aaai.v35i15.17589",
        "pdf_size": 187343
    },
    {
        "id": "02020",
        "title": "SD-Pose: Semantic Decomposition for Cross-Domain 6D Object Pose Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "The current leading 6D object pose estimation methods rely heavily on annotated real data, which is highly costly to acquire. To overcome this, many works have proposed to introduce computer-generated synthetic data. However, bridging the gap between the synthetic and real data remains a severe problem. Images depicting different levels of realism/semantics usually have different transferability between the synthetic and real domains. Inspired by this observation, we introduce an approach, SD-Pose, that explicitly decomposes the input image into multi-level semantic representations and then combines the merits of each representation to bridge the domain gap. Our comprehensive analyses and experiments show that our semantic decomposition strategy can fully utilize the different domain similarities of different representations, thus allowing us to outperform the state of the art on modern 6D object pose datasets without accessing any real data during training.",
        "primary_area": "Computer Vision II",
        "author": "Zhigang Li; Yinlin Hu; Mathieu Salzmann; Xiangyang Ji",
        "authorids": "",
        "aff": "Tsinghua University; EPFL; EPFL ClearSpace SA; Tsinghua University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16298/16298-13-19792-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02020-sd-pose-semantic-decomposition-for-cross-domain-6d-object-pose-estimation/",
        "doi": "10.1609/aaai.v35i3.16298",
        "pdf_size": 1549375
    },
    {
        "id": "00196",
        "title": "SDGNN: Learning Node Representation for Signed Directed Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "",
        "primary_area": "Application Domains",
        "author": "Junjie Huang; Huawei Shen; Liang Hou; Xueqi Cheng",
        "authorids": "",
        "aff": "",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16093/16093-13-19587-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00196-sdgnn-learning-node-representation-for-signed-directed-networks/",
        "doi": "",
        "pdf_size": 429311
    },
    {
        "id": "07413",
        "title": "SHOT-VAE: Semi-supervised Deep Generative Models With Label-aware ELBO Approximations",
        "track": "main",
        "status": "Poster",
        "abstract": "Semi-supervised variational autoencoders (VAEs) have obtained strong results, but have also encountered the challenge that good ELBO values do not always imply accurate inference results.In this paper, we investigate and propose two causes of this problem: (1) The ELBO objective cannot utilize the label information directly. (2) A bottleneck value exists, and continuing to optimize ELBO after this value will not improve inference accuracy. On the basis of the experiment results, we propose SHOT-VAE to address these problems without introducing additional prior knowledge. The SHOT-VAE offers two contributions: (1) A new ELBO approximation named smooth-ELBO that integrates the label predictive loss into ELBO. (2) An approximation based on optimal interpolation that breaks the ELBO value bottleneck by reducing the margin between ELBO and the data likelihood. The SHOT-VAE achieves good performance with 25.30% error rate on CIFAR-100 with 10k labels and reduces the error rate to 6.11% on CIFAR-10 with 4k labels.",
        "primary_area": "Machine Learning I",
        "author": "Hao-Zhe Feng; Kezhi Kong; Minghao Chen; Tianye Zhang; Minfeng Zhu; Wei Chen",
        "authorids": "",
        "aff": "Zhejiang University; University of Maryland, College Park; Zhejiang University; Zhejiang University; Zhejiang University; Zhejiang University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16909/16909-13-20403-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07413-shot-vae-semi-supervised-deep-generative-models-with-label-aware-elbo-approximations/",
        "doi": "10.1609/aaai.v35i8.16909",
        "pdf_size": 4334657
    },
    {
        "id": "03342",
        "title": "SIMPLE: SIngle-network with Mimicking and Point Learning for Bottom-up Human Pose Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "The practical application requests both accuracy and efficiency on multi-person pose estimation algorithms. But the high accuracy and fast inference speed are dominated by top-down methods and bottom-up methods respectively. To make a better trade-off between accuracy and efficiency, we propose a novel multi-person pose estimation framework, SIngle-network with Mimicking and Point Learning for Bottom-up Human Pose Estimation (SIMPLE). Specifically, in the training process, we enable SIMPLE to mimic the pose knowledge from the high-performance top-down pipeline, which significantly promotes SIMPLE's accuracy while maintaining its high efficiency during inference. Besides, SIMPLE formulates human detection and pose estimation as a unified point learning framework to complement each other in single-network.  This is quite different from previous works where the two tasks may interfere with each other. To the best of our knowledge, both mimicking strategy between different method types and unified point learning are firstly proposed in pose estimation. In experiments, our approach achieves the new state-of-the-art performance among bottom-up methods on the COCO, MPII and PoseTrack datasets. Compared with the top-down approaches, SIMPLE has comparable accuracy and faster inference speed.",
        "primary_area": "Computer Vision III",
        "author": "Jiabin Zhang; Zheng Zhu; Jiwen Lu; Junjie Huang; Guan Huang; Jie Zhou",
        "authorids": "",
        "aff": "Institute of Automation, Chinese Academy of Sciences; Tsinghua University; Tsinghua University; XForwardAI Technology Co.,Ltd; XForwardAI Technology Co.,Ltd; Tsinghua University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16446/16446-13-19940-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03342-simple-single-network-with-mimicking-and-point-learning-for-bottom-up-human-pose-estimation/",
        "doi": "10.1609/aaai.v35i4.16446",
        "pdf_size": 4288438
    },
    {
        "id": "01451",
        "title": "SMART Frame Selection for Action Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "Video classification is computationally expensive.  In this paper, we address theproblem of frame selection to reduce the computational cost of video classification.Recent work has successfully leveraged frame selection for long, untrimmed videos,where much of the content is not relevant, and easy to discard. In this work, however,we focus on the more standard short, trimmed video classification problem. Weargue that good frame selection can not only reduce the computational cost of videoclassification but also increase the accuracy by getting rid of frames that are hard toclassify. In contrast to previous work, we propose a method that instead of selectingframes by considering one at a time, considers them jointly. This results in a moreefficient selection, where \u201cgood\" frames are more effectively distributed over thevideo, like snapshots that tell a story. We call the proposed frame selection SMARTand we test it in combination with different backbone architectures and on multiplebenchmarks (Kinetics [5], Something-something [14], UCF101 [31]). We showthat the SMART frame selection consistently improves the accuracy compared toother frame selection strategies while reducing the computational cost by a factorof 4 to 10 times. Additionally, we show that when the primary goal is recognitionperformance, our selection strategy can improve over recent state-of-the-art modelsand frame selection strategies on various benchmarks (UCF101, HMDB51 [21],FCVID [17], and ActivityNet [4]).",
        "primary_area": "Computer Vision I",
        "author": "Shreyank N Gowda; Marcus Rohrbach; Laura Sevilla-Lara",
        "authorids": "",
        "aff": "University of Edinburgh; Facebook AI Research; University of Edinburgh",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16235/16235-13-19729-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01451-smart-frame-selection-for-action-recognition/",
        "doi": "10.1609/aaai.v35i2.16235",
        "pdf_size": 4753746
    },
    {
        "id": "13009",
        "title": "SMART: A Situation Model for Algebra Story Problems via Attributed Grammar",
        "track": "main",
        "status": "Poster",
        "abstract": "Solving algebra story problems remains a challenging task in artificial intelligence, which requires a detailed understanding of real-world situations and a strong mathematical reasoning capability. Previous neural solvers of math word problems directly translate problem texts into equations, lacking an explicit interpretation of the situations, and often fail to handle more sophisticated situations. To address such limits of neural solvers, we introduce the concept of a situation model, which originates from psychology studies to represent the mental states of humans in problem-solving, and propose SMART, which adopts attributed grammar as the representation of situation models for algebra story problems. Specifically, we first train an information extraction module to extract nodes, attributes and relations from problem texts and then generate a parse graph based on a pre-defined attributed grammar. An iterative learning strategy is also proposed to further improve the performance of SMART. To study this task more rigorously, we carefully curate a new dataset named ASP6.6k. Experimental results on ASP6.6k show that the proposed model outperforms all previous neural solvers by a large margin, while preserving much better interpretability. To test these models' generalization capability, we also design an out-of-distribution (OOD) evaluation, in which problems are more complex than those in the training set. Our model exceeds state-of-the-art models by 17% in the OOD evaluation, demonstrating its superior generalization ability.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Yining Hong; Qing Li; Ran Gong; Daniel Ciao; Siyuan Huang; Song-Chun Zhu",
        "authorids": "",
        "aff": "University of California, Los Angeles; University of California, Los Angeles; University of California, Los Angeles; University of California, Los Angeles; University of California, Los Angeles; University of California, Los Angeles",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17538/17538-13-21032-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13009-smart-a-situation-model-for-algebra-story-problems-via-attributed-grammar/",
        "doi": "10.1609/aaai.v35i14.17538",
        "pdf_size": 535682
    },
    {
        "id": "02302",
        "title": "SMIL: Multimodal Learning with Severely Missing Modality",
        "track": "main",
        "status": "Poster",
        "abstract": "A common assumption in multimodal learning is the completeness of training data, i.e., full modalities are available in all training examples. Although there exists research endeavor in developing novel methods to tackle the incompleteness of testing data, e.g., modalities are partially missing in testing examples, few of them can handle incomplete training modalities. The problem becomes even more challenging if considering the case of severely missing, e.g., ninety percent of training examples may have incomplete modalities. For the first time in the literature, this paper formally studies multimodal learning with missing modality in terms of flexibility (missing modalities in training, testing, or both) and efficiency (most training data have incomplete modality). Technically, we propose a new method named SMIL that leverages Bayesian meta-learning in uniformly achieving both objectives. To validate our idea, we conduct a series of experiments on three popular benchmarks: MM-IMDb, CMU-MOSI, and avMNIST. The results prove the state-of-the-art performance of SMIL over existing methods and generative baselines including autoencoders and generative adversarial networks.",
        "primary_area": "Computer Vision II",
        "author": "Mengmeng Ma; Jian Ren; Long Zhao; Sergey Tulyakov; Cathy Wu; Xi Peng",
        "authorids": "",
        "aff": "University of Delaware; Snap Inc.; Rutgers University; Snap Inc.; University of Delaware; University of Delaware",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16330/16330-13-19824-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02302-smil-multimodal-learning-with-severely-missing-modality/",
        "doi": "10.1609/aaai.v35i3.16330",
        "pdf_size": 775420
    },
    {
        "id": "06321",
        "title": "SMT-based Safety Checking of Parameterized Multi-Agent Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "We study the problem of verifying whether a given parameterized multi-agent system (PMAS) is safe, namely whether none of its possible executions can lead to bad states. These are captured by a state formula existentially quantifying over agents. As the MAS is parameterized, it only describes the finite set of possible agent templates, while the actual number of concrete agent instances that will be present at runtime, for each template, is unbounded and cannot be foreseen.  We solve this problem via infinite-state model checking based on satisfiability modulo theories (SMT), relying on the theory of array-based systems. We formally characterize the soundness, completeness and termination guarantees of our approach under specific assumptions. This gives us a technique that is implementable on top of third-party, SMT-based model checkers. Finally, we discuss how this approach lends itself to richer parameterized and data-aware MAS settings beyond the state-of-the-art solutions in the literature.",
        "primary_area": "Knowledge Representation and Reasoning",
        "author": "Paolo Felli; Alessandro Gianola; Marco Montali",
        "authorids": "",
        "aff": "Free University of Bozen-Bolzano, Bolzano, Italy; Free University of Bozen-Bolzano, Bolzano, Italy; Free University of Bozen-Bolzano, Bolzano, Italy",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16785/16785-13-20279-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06321-smt-based-safety-checking-of-parameterized-multi-agent-systems/",
        "doi": "10.1609/aaai.v35i7.16785",
        "pdf_size": 206280
    },
    {
        "id": "03305",
        "title": "SPIN: Structure-Preserving Inner Offset Network for Scene Text Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "Arbitrary text appearance poses a great challenge in scene text recognition tasks. Existing works mostly handle with the problem in consideration of the shape distortion, including perspective distortions, line curvature or other style variations. Rectification (i.e., spatial transformers) as the preprocessing stage is one popular approach and extensively studied. However, chromatic difficulties in complex scenes have not been paid much attention on. In this work, we introduce a new learnable geometric-unrelated rectification, Structure-Preserving Inner Offset Network (SPIN), which allows the color manipulation of source data within the network. This differentiable module can be inserted before any recognition architecture to ease the downstream tasks, giving neural networks the ability to actively transform input intensity rather than only the spatial rectification. It can also serve as a complementary module to known spatial transformations and work in both independent and collaborative ways with them. Extensive experiments show the proposed transformation outperforms existing rectification networks and has comparable performance among the state-of-the-arts.",
        "primary_area": "Computer Vision III",
        "author": "Chengwei Zhang; Yunlu Xu; Zhanzhan Cheng; Shiliang Pu; Yi Niu; Fei Wu; Futai Zou",
        "authorids": "",
        "aff": "Shanghai Jiaotong University; Hikvision Research Institute; Zhejiang University Hikvision Research Institute; Hikvision Research Institute; Hikvision Research Institute; Zhejiang University; Shanghai Jiaotong University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16442/16442-13-19936-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03305-spin-structure-preserving-inner-offset-network-for-scene-text-recognition/",
        "doi": "10.1609/aaai.v35i4.16442",
        "pdf_size": 16832218
    },
    {
        "id": "01105",
        "title": "SSD-GAN: Measuring the Realness in the Spatial and Spectral Domains",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper observes that there is an issue of high frequencies missing in the discriminator of standard GAN, and we reveal it stems from downsampling layers employed in the network architecture. This issue makes the generator lack the incentive from the discriminator to learn high-frequency content of data, resulting in a significant spectrum discrepancy between generated images and real images. Since the Fourier transform is a bijective mapping, we argue that reducing this spectrum discrepancy would boost the performance of GANs. To this end, we introduce SSD-GAN, an enhancement of GANs to alleviate the spectral information loss in the discriminator. Specifically, we propose to embed a frequency-aware classifier into the discriminator to measure the realness of the input in both the spatial and spectral domains. With the enhanced discriminator, the generator of SSD-GAN is encouraged to learn high-frequency content of real data and generate exact details. The proposed method is general and can be easily integrated into most existing GANs framework without excessive cost. The effectiveness of SSD-GAN is validated on various network architectures, objective functions, and datasets. Code is available at https://github.com/cyq373/SSD-GAN.",
        "primary_area": "Computer Vision I",
        "author": "Yuanqi Chen; Ge Li; Cece Jin; Shan Liu; Thomas Li",
        "authorids": "",
        "aff": "Peking University Peng Cheng Laboratory; Peking University; Peking University Peng Cheng Laboratory; Tencent America; Peking University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16196/16196-13-19690-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01105-ssd-gan-measuring-the-realness-in-the-spatial-and-spectral-domains/",
        "doi": "10.1609/aaai.v35i2.16196",
        "pdf_size": 3763654
    },
    {
        "id": "01691",
        "title": "SSN3D: Self-Separated Network to Align Parts for 3D Convolution in Video Person Re-Identification",
        "track": "main",
        "status": "Poster",
        "abstract": "Temporal appearance misalignment is a crucial problem in video person re-identification. The same part of person (e.g. head or hand) appearing on different locations in video sequence weakens its discriminative ability, especially when we apply standard temporal aggregation such as 3D convolution or LSTM. To address this issue, we propose Self-Separated network (SSN)  to seek out the same parts in different images.  As the name implies, SSN, if trained in an unsupervised strategy, guarantees the selected parts distinct. With a few samples of labeled parts to guide SSN training, this semi-supervised trained SSN seeks out the parts that are human-understandable within a frame and stable across a video snippet. Given the distinct and stable person parts, rather than performing aggregation on features, we then apply 3D convolution across different frames for person re-identification.  This SSN + 3D pipeline, dubbed SSN3D, is proved to be efficient through extensive experiments on both synthetic and real data.",
        "primary_area": "Computer Vision I",
        "author": "Xiaoke Jiang; Yu Qiao; Junjie Yan; Qichen Li; Wanrong Zheng; Dapeng Chen",
        "authorids": "",
        "aff": "ShenZhen Key Lab of Computer Vision and Pattern Recognition, SIAT-SenseTime Joint Lab, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences Sensetime Group; ShenZhen Key Lab of Computer Vision and Pattern Recognition, SIAT-SenseTime Joint Lab, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences Shanghai AI Lab, Shanghai, China; Sensetime Group; MIT; Sensetime Group; Sensetime Group",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16262/16262-13-19756-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01691-ssn3d-self-separated-network-to-align-parts-for-3d-convolution-in-video-person-re-identification/",
        "doi": "10.1609/aaai.v35i2.16262",
        "pdf_size": 1758753
    },
    {
        "id": "01140",
        "title": "SSPC-Net: Semi-supervised Semantic 3D Point Cloud Segmentation Network",
        "track": "main",
        "status": "Poster",
        "abstract": "Point cloud semantic segmentation is a crucial task in 3D scene understanding. Existing methods mainly focus on employing a large number of annotated labels for supervised semantic segmentation. Nonetheless, manually labeling such large point clouds for the supervised segmentation task is time-consuming. In order to reduce the number of annotated labels, we propose a semi-supervised semantic point cloud segmentation network, named SSPC-Net, where we train the semantic segmentation network by inferring the labels of unlabeled points from the few annotated 3D points. In our method, we first partition the whole point cloud into superpoints and build superpoint graphs to mine the long-range dependencies in point clouds. Based on the constructed superpoint graph, we then develop a dynamic label propagation method to generate the pseudo labels for the unsupervised superpoints. Particularly, we adopt a superpoint dropout strategy to dynamically select the generated pseudo labels. In order to fully exploit the generated pseudo labels of the unsupervised superpoints, we furthermore propose a coupled attention mechanism for superpoint feature embedding. Finally, we employ the cross-entropy loss to train the semantic segmentation network with the labels of the supervised superpoints and the pseudo labels of the unsupervised superpoints. Experiments on various datasets demonstrate that our semisupervised segmentation method can achieve better performance than the current semi-supervised segmentation method with fewer annotated 3D points.",
        "primary_area": "Computer Vision I",
        "author": "Mingmei Cheng; Le Hui; Jin Xie; Jian Yang",
        "authorids": "",
        "aff": "Nanjing University of Science and Technology; Nanjing University of Science and Technology; Nanjing University of Science and Technology; Nanjing University of Science and Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16200/16200-13-19694-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01140-sspc-net-semi-supervised-semantic-3d-point-cloud-segmentation-network/",
        "doi": "10.1609/aaai.v35i2.16200",
        "pdf_size": 1160898
    },
    {
        "id": "04830",
        "title": "STELAR: Spatio-temporal Tensor Factorization with Latent Epidemiological Regularization",
        "track": "main",
        "status": "Poster",
        "abstract": "Accurate prediction of the transmission of epidemic diseases such as COVID-19 is crucial for implementing effective mitigation measures. In this work, we develop a tensor method to predict the evolution of epidemic trends for many regions simultaneously. We construct a 3-way spatio-temporal tensor (location, attribute, time) of case counts and propose a nonnegative tensor factorization with latent epidemiological model regularization named STELAR. Unlike standard tensor factorization methods which cannot predict slabs ahead, STELAR enables long-term prediction by incorporating latent temporal regularization through a system of discrete-time difference equations of a widely adopted epidemiological model. We use latent instead of location/attribute-level epidemiological dynamics to capture common epidemic profile sub-types and improve collaborative learning and prediction. We conduct experiments using  both county- and state-level COVID-19 data and show that our model can identify interesting latent patterns of the epidemic. Finally, we evaluate the predictive ability of our method and show superior performance compared to the baselines, achieving up to 21% lower root mean square error and 25% lower mean absolute error for county-level prediction.",
        "primary_area": "AI Responses to the COVID-19 Pandemic",
        "author": "Nikos Kargas; Cheng Qian; Nicholas D. Sidiropoulos; Cao Xiao; Lucas M. Glass; Jimeng Sun",
        "authorids": "",
        "aff": "University of Minnesota IQVIA; IQVIA; University of Virginia; IQVIA; IQVIA Temple University; University of Illinois Urbana-Champaign",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16615/16615-13-20109-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04830-stelar-spatio-temporal-tensor-factorization-with-latent-epidemiological-regularization/",
        "doi": "10.1609/aaai.v35i6.16615",
        "pdf_size": 346068
    },
    {
        "id": "09576",
        "title": "STL-SGD: Speeding Up Local SGD with Stagewise Communication Period",
        "track": "main",
        "status": "Poster",
        "abstract": "Distributed parallel stochastic gradient descent algorithms are workhorses for large scale machine learning tasks. Among them, local stochastic gradient descent (Local SGD) has attracted significant attention due to its low communication complexity. Previous studies prove that the communication complexity of Local SGD with a fixed or an adaptive communication period  is in the order of O (N3/2 T1/2) and O (N3/4 T3/4) when the data distributions on clients are identical (IID) or otherwise (Non-IID), where N is the number of clients and T is the number of iterations. In this paper, to accelerate the convergence by reducing the communication complexity, we propose STagewise Local SGD (STL-SGD), which increases the communication period gradually along with decreasing learning rate. We prove that STL-SGD can keep the same convergence rate and linear speedup as mini-batch SGD. In addition, as the benefit of increasing the communication period, when the objective is strongly convex or satisfies the Polyak-Lojasiewicz condition, the communication complexity of STL-SGD is O (N log T ) and O (N1/2 T1/2) for the IID case and the Non-IID case respectively, achieving significant improvements over Local SGD. Experiments on both convex and non-convex problems demonstrate the superior performance of STL-SGD.",
        "primary_area": "Machine Learning IV",
        "author": "Shuheng Shen; Yifei Cheng; Jingchang Liu; Linli Xu",
        "authorids": "",
        "aff": "School of Computer Science and Technology, University of Science and Technology of China Ant Financial Services Group; School of Data Science, University of Science and Technology of China; Department of Computer Science and Engineering, Hong Kong University of Science and Technology; School of Computer Science and Technology, University of Science and Technology of China IFLYTEK Co., Ltd.",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17153/17153-13-20647-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09576-stl-sgd-speeding-up-local-sgd-with-stagewise-communication-period/",
        "doi": "10.1609/aaai.v35i11.17153",
        "pdf_size": 299453
    },
    {
        "id": "06548",
        "title": "SWIFT: Scalable Wasserstein Factorization for Sparse Nonnegative Tensors",
        "track": "main",
        "status": "Poster",
        "abstract": "Existing tensor factorization methods assume that the input tensor follows some specific distribution (i.e. Poisson, Bernoulli, and Gaussian), and solve the factorization by minimizing some empirical loss functions defined based on the corresponding distribution. However, it suffers from several drawbacks: 1) In reality, the underlying distributions are complicated and unknown, making it infeasible to be approximated by a simple distribution. 2) The correlation across dimensions of the input tensor is not well utilized, leading to sub-optimal performance. Although heuristics were proposed to incorporate such correlation as side information under Gaussian distribution, they can not easily be generalized to other distributions. Thus, a more principled way of utilizing the correlation in tensor factorization models is still an open challenge. Without assuming any explicit distribution, we formulate the tensor factorization as an optimal transport problem with Wasserstein distance, which can handle non-negative inputs.    We introduce SWIFT, which minimizes the Wasserstein distance that measures the distance between the input tensor and that of the reconstruction. In particular, we define the N-th order tensor Wasserstein loss for the widely used tensor CP factorization and derive the optimization algorithm that minimizes it. By leveraging sparsity structure and different equivalent formulations for optimizing computational efficiency, SWIFT is as scalable as other well-known CP algorithms. Using the factor matrices as features, SWIFT achieves up to 9.65% and 11.31% relative improvement over baselines for downstream prediction tasks. Under the noisy conditions, SWIFT achieves up to 15% and 17% relative improvements over the best competitors for the prediction tasks.",
        "primary_area": "Machine Learning I",
        "author": "Ardavan Afshar; Kejing Yin; Sherry Yan; Cheng Qian; Joyce Ho; Haesun Park; Jimeng Sun",
        "authorids": "",
        "aff": "Computational Science and Engineering, Georgia Institute of Technology, Atlanta, USA; Department of Computer Science, Hong Kong Baptist University, Hong Kong, China; Research Development & Dissemination, Sutter Health, Walnut Creek, USA; Analytic Center of Excellence, IQVIA, Cambridge, USA; Department of Computer Science, Emory University, Atlanta, USA; Computational Science and Engineering, Georgia Institute of Technology, Atlanta, USA; Department of Computer Science, University of Illinois at Urbana-Champaign, Urbana, USA",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16811/16811-13-20305-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06548-swift-scalable-wasserstein-factorization-for-sparse-nonnegative-tensors/",
        "doi": "10.1609/aaai.v35i8.16811",
        "pdf_size": 247505
    },
    {
        "id": "05541",
        "title": "Safe Search for Stackelberg Equilibria in Extensive-Form Games",
        "track": "main",
        "status": "Poster",
        "abstract": "Stackelberg equilibrium is a solution concept in two-player games where the leader has commitment rights over the follower. In recent years, it has become a cornerstone of many security applications, including airport patrolling and wildlife poaching prevention. Even though many of these settings are sequential in nature, existing techniques pre-compute the entire solution ahead of time. In this paper, we present a theoretically sound and empirically effective way to apply search, which leverages extra online computation to improve a solution, to the computation of Stackelberg equilibria in general-sum games. Instead of the leader attempting to solve the full game upfront, an approximate \"blueprint\" solution is first computed offline and is then improved online for the particular subgames encountered in actual play. We prove that our search technique is guaranteed to perform no worse than the pre-computed blueprint strategy, and empirically demonstrate that it enables approximately solving significantly larger games compared to purely offline methods. We also show that our search operation may be cast as a smaller Stackelberg problem, making our method complementary to existing algorithms based on strategy generation.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Chun Kai Ling; Noam Brown",
        "authorids": "",
        "aff": "Carnegie Mellon University; Facebook AI Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16697/16697-13-20191-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05541-safe-search-for-stackelberg-equilibria-in-extensive-form-games/",
        "doi": "10.1609/aaai.v35i6.16697",
        "pdf_size": 149460
    },
    {
        "id": "10630",
        "title": "Sample Complexity of Policy Gradient Finding Second-Order Stationary Points",
        "track": "main",
        "status": "Poster",
        "abstract": "The policy-based reinforcement learning (RL) can be considered as maximization of its objective. However, due to the inherent non-concavity of its objective, the policy gradient method to a first-order stationary point (FOSP) cannot guar- antee a maximal point. A FOSP can be a minimal or even a saddle point, which is undesirable for RL. It has be found that if all the saddle points are strict, all the second-order station- ary points (SOSP) are exactly equivalent to local maxima. Instead of FOSP, we consider SOSP as the convergence criteria to characterize the sample complexity of policy gradient. Our result shows that policy gradient converges to an (\u03b5, \u221a\u03b5\u03c7)-SOSP with probability at least 1 \u2212 O(\u03b4) after the total cost of O(\u03b5\u22129/2)sinificantly improves the state of the art cost O(\u03b5\u22129).Our analysis is based on the key idea that decomposes the parameter space Rp into three non-intersected regions: non-stationary point region, saddle point region, and local optimal region, then making a local improvement of the objective of RL in each region. This technique can be potentially generalized to extensive policy gradient methods. For the complete proof, please refer to https://arxiv.org/pdf/2012.01491.pdf.",
        "primary_area": "Machine Learning V",
        "author": "Long Yang; Qian Zheng; Gang Pan",
        "authorids": "",
        "aff": "Zhejiang University; Nanyang Technological University; Zhejiang University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17271/17271-13-20765-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10630-sample-complexity-of-policy-gradient-finding-second-order-stationary-points/",
        "doi": "10.1609/aaai.v35i12.17271",
        "pdf_size": 181104
    },
    {
        "id": "10887",
        "title": "Sample Efficient Reinforcement Learning with REINFORCE",
        "track": "main",
        "status": "Poster",
        "abstract": "Policy gradient methods are among the most effective methods for large-scale reinforcement learning, and their empirical success has prompted several works that develop the foundation of their global convergence theory. However, prior works have either required exact gradients or state-action visitation measure based mini-batch stochastic gradients with a diverging batch size, which limit their applicability in practical scenarios. In this paper, we consider classical policy gradient methods that compute an approximate gradient with a single trajectory or a fixed size mini-batch of trajectories under soft-max parametrization and log-barrier regularization, along with the widely-used REINFORCE gradient estimation procedure. By controlling the number of \"bad\" episodes and resorting to the classical doubling trick, we establish an anytime sub-linear high probability regret bound as well as almost sure global convergence of the average regret with an asymptotically sub-linear rate. These provide the first set of global convergence and sample efficiency results for the well-known REINFORCE algorithm and contribute to a better understanding of its performance in practice.",
        "primary_area": "Machine Learning V",
        "author": "Junzi Zhang; Jongho Kim; Brendan O'Donoghue; Stephen Boyd",
        "authorids": "",
        "aff": "Institute for Computational & Mathematical Engineering, Stanford University, USA; Department of Electrical Engineering, Stanford University, USA; DeepMind, Google; Department of Electrical Engineering, Stanford University, USA",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17300/17300-13-20794-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10887-sample-efficient-reinforcement-learning-with-reinforce/",
        "doi": "10.1609/aaai.v35i12.17300",
        "pdf_size": 182759
    },
    {
        "id": "08592",
        "title": "Sample Selection for Universal Domain Adaptation",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper studies the problem of unsupervised domain adaption in the universal scenario, in which only some of the classes are shared between the source and target domains. We present a scoring scheme that is effective in identifying the samples of the shared classes. The score is used to select samples in the target domain for which to apply specific losses during training; pseudo-labels for high scoring samples and confidence regularization for low scoring samples. Taken together, our method is shown to outperform, by a sizeable margin, the current state of the art on the literature benchmarks.",
        "primary_area": "Machine Learning III",
        "author": "Omri Lifshitz; Lior Wolf",
        "authorids": "",
        "aff": "Tel Aviv University, Israel; Tel Aviv University, Israel",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17042/17042-13-20536-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08592-sample-selection-for-universal-domain-adaptation/",
        "doi": "10.1609/aaai.v35i10.17042",
        "pdf_size": 631942
    },
    {
        "id": "07193",
        "title": "Sample-Efficient L0-L2 Constrained Structure Learning of Sparse Ising Models",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider the problem of learning the underlying graph of a sparse Ising model with p nodes from n i.i.d. samples. The most recent and best performing approaches combine an empirical loss (the logistic regression loss or the interaction screening loss) with a regularizer (an L1 penalty or an L1 constraint). This results in a convex problem that can be solved separately for each node of the graph.  In this work, we leverage the cardinality constraint L0 norm, which is known to properly induce sparsity, and further combine it with an L2 norm to better model the non-zero coefficients.  We show that our proposed estimators achieve an improved sample complexity, both (a) theoretically, by reaching new state-of-the-art upper bounds for recovery guarantees, and (b) empirically, by showing sharper phase transitions between poor and full recovery for graph topologies studied in the literature, when compared to their L1-based state-of-the-art methods.",
        "primary_area": "Machine Learning I",
        "author": "Antoine Dedieu; Miguel L\u00e1zaro-Gredilla; Dileep George",
        "authorids": "",
        "aff": "Vicarious AI; Vicarious AI; Vicarious AI",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16884/16884-13-20378-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07193-sample-efficient-l0-l2-constrained-structure-learning-of-sparse-ising-models/",
        "doi": "10.1609/aaai.v35i8.16884",
        "pdf_size": 2042892
    },
    {
        "id": "06812",
        "title": "Sample-Specific Output Constraints for Neural Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "It is common practice to constrain the output space of a neural network with the final layer to a problem-specific value range. However, for many tasks it is desired to restrict the output space for each input independently to a different subdomain with a non-trivial geometry, e.g. in safety-critical applications, to exclude hazardous outputs sample-wise. We propose ConstraintNet\u2014a scalable neural network architecture which constrains the output space in each forward pass independently. Contrary to prior approaches, which perform a projection in the final layer, ConstraintNet applies an input-dependent parametrization of the constrained output space. Thereby, the complete interior of the constrained region is covered and computational costs are reduced significantly. For constraints in form of convex polytopes, we leverage the vertex representation to specify the parametrization. The second modification consists of adding an auxiliary input in form of a tensor description of the constraint to enable the handling of multiple constraints for the same sample. Finally, ConstraintNet is end-to-end trainable with almost no overhead in the forward and backward pass. We demonstrate ConstraintNet on two regression tasks: First, we modify a CNN and construct several constraints for facial landmark detection tasks. Second, we demonstrate the application to a follow object controller for vehicles and accomplish safe reinforcement learning in this case. In both experiments, ConstraintNet improves performance and we conclude that our approach is promising for applying neural networks in safety-critical environments.",
        "primary_area": "Machine Learning I",
        "author": "Mathis Brosowsky; Florian Keck; Olaf D\u00fcnkel; Marius Z\u00f6llner",
        "authorids": "",
        "aff": "FZI Research Center for Information Technology Karlsruhe Institute of Technology; Karlsruhe Institute of Technology; Karlsruhe Institute of Technology; FZI Research Center for Information Technology Karlsruhe Institute of Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16841/16841-13-20335-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06812-sample-specific-output-constraints-for-neural-networks/",
        "doi": "10.1609/aaai.v35i8.16841",
        "pdf_size": 2105629
    },
    {
        "id": "03886",
        "title": "Satisfiability and Algorithms for Non-uniform Random k-SAT",
        "track": "main",
        "status": "Poster",
        "abstract": "Solving Satisfiability is at the core of a wide range of applications from Knowledge Representation to Logic Programming to Software and Hardware Verification. One of the models of Satisfiability, the Random Satisfiability problem, has received much attention in the literature both, as a useful benchmark for SAT solvers, and as an exciting mathematical object. In this paper we tackle a somewhat nonstandard type of Random Satisfiability, the one where instances are not chosen uniformly from a certain class of instances, but rather from a certain nontrivial distribution. More precisely, we use so-called Configuration Model, in which we start with a distribution of degrees (the number of occurrences) of a variable, sample the degree of each variable and then generate a random instance with the prescribed degrees. It has been proposed previously that by properly selecting the starting distribution (to be, say, power law or lognorm) one can approximate at least some aspect of `industrial' instances of SAT. Here we suggest an algorithm that solves such problems for a wide range of degree distributions and obtain a necessary and a sufficient condition for the satisfiability of such formulas.",
        "primary_area": "Constraint Satisfaction and Optimization",
        "author": "Oleksii Omelchenko; Andrei Bulatov",
        "authorids": "",
        "aff": "Simon Fraser University; Simon Fraser University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16507/16507-13-20001-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03886-satisfiability-and-algorithms-for-non-uniform-random-k-sat/",
        "doi": "10.1609/aaai.v35i5.16507",
        "pdf_size": 531366
    },
    {
        "id": "11947",
        "title": "Saturated Post-hoc Optimization for Classical Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Saturated cost partitioning and post-hoc optimization are two powerful cost partitioning algorithms for optimal classical planning. The main idea of saturated cost partitioning is to give each considered heuristic only the fraction of remaining operator costs that it needs to prove its estimates. We show how to apply this idea to post-hoc optimization and obtain a heuristic that dominates the original both in theory and on the IPC benchmarks.",
        "primary_area": "Planning, Routing, and Scheduling",
        "author": "Jendrik Seipp; Thomas Keller; Malte Helmert",
        "authorids": "",
        "aff": "University of Basel, Switzerland Link\u00f6ping University, Sweden; University of Basel, Switzerland; University of Basel, Switzerland",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17419/17419-13-20913-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11947-saturated-post-hoc-optimization-for-classical-planning/",
        "doi": "10.1609/aaai.v35i13.17419",
        "pdf_size": 217401
    },
    {
        "id": "04804",
        "title": "Savable but Lost Lives when ICU Is Overloaded: a Model from 733 Patients in Epicenter Wuhan, China",
        "track": "main",
        "status": "Poster",
        "abstract": "Coronavirus Disease 2019 (COVID-19) causes a sudden turnover to bad at some checkpoints and thus needs the intervention of intensive care unit (ICU). This resulted in urgent and large needs of ICUs posed great risks to the medical system. Estimating the mortality of critical in-patients who were not admitted into the ICU will be valuable to optimize the management and assignment of ICU. Retrospective, 733 in-patients diagnosed with COVID-19 at a local hospital (Wuhan, China), as of March 18, 2020. Demographic, clinical and laboratory results were collected and analyzed using machine learning to build a predictive model. Considering the shortage of ICU beds at the beginning of disease emergence, we defined the mortality for those patients who were predicted to be in needing ICU care yet they did not as Missing-ICU (MI)-mortality. To estimate MI-mortality, a prognostic classification model was built to identify the in-patients who may need ICU care. Its predictive accuracy was 0.8288, with an AUC of 0.9119. On our cohort of 733 patients, 25 in-patients who have been predicted by our model that they should need ICU, yet they did not enter ICU due to lack of shorting ICU wards. Our analysis had shown that the MI-mortality is 41%, yet the mortality of ICU is 32%, implying that enough bed of ICU in treating patients in critical conditions.",
        "primary_area": "AI Responses to the COVID-19 Pandemic",
        "author": "Tingting Dan; Yang Li; Ziwei Zhu; Xijie Chen; Wuxiu Quan; Yu Hu; Guihua Tao; Lei Zhu; Jijin Zhu; Hongmin Cai; Hanchun Wen",
        "authorids": "",
        "aff": "South China University of Technology; South China University of Technology; South China University of Technology; South China University of Technology; South China University of Technology; South China University of Technology; South China University of Technology; South China University of Technology; First Affiliated Hospital of Guangxi Medical University; South China University of Technology Key Laboratory of Big Data and Intelligent Robot, Ministry of Education; First Affiliated Hospital of Guangxi Medical University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16612/16612-13-20106-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04804-savable-but-lost-lives-when-icu-is-overloaded-a-model-from-733-patients-in-epicenter-wuhan-china/",
        "doi": "10.1609/aaai.v35i6.16612",
        "pdf_size": 704264
    },
    {
        "id": "09639",
        "title": "Scalable Affinity Propagation for Massive Datasets",
        "track": "main",
        "status": "Poster",
        "abstract": "Affinity Propagation (AP) is a fundamental algorithm to identify clusters included in data objects. Given a similarities among objects, it iteratively performs message updates between all data object pairs until convergence. Although AP yields a higher clustering quality compared with other methods, it is computationally expensive. Hence, it has difficulty handling massive datasets that include numerous data objects. This is because the message updates require a quadratic cost of the number of data objects. Here, we propose a novel fast algorithm, ScaleAP, which outputs the same clusters as AP but within a shorter computation time. ScaleAP dynamically excludes unnecessary message updates without sacrificing its clustering accuracy. Our extensive evaluations demonstrate that ScaleAP outperforms existing AP algorithms in terms of running time by up to two orders of magnitude.",
        "primary_area": "Machine Learning IV",
        "author": "Hiroaki Shiokawa",
        "authorids": "",
        "aff": "University of Tsukuba",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17160/17160-13-20654-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09639-scalable-affinity-propagation-for-massive-datasets/",
        "doi": "10.1609/aaai.v35i11.17160",
        "pdf_size": 235800
    },
    {
        "id": "05277",
        "title": "Scalable Equilibrium Computation in Multi-agent Influence Games on Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "We provide a polynomial-time, scalable algorithm for equilibrium computation in multi-agent influence games on networks, extending work of Bindel, Kleinberg, and Oren (2015) from the single-agent to the multi-agent setting. In games of influence, agents have limited advertising budget to influence the initial predisposition of nodes in some network towards their products, but the eventual decisions of the nodes are determined by the stationary state of DeGroot opinion dynamics on the network, which takes over after the seeding (Ahmadinejad et al. 2014, 2015). In multi-agent systems, how should agents spend their budgets to seed the network to maximize their utility in anticipation of other advertising agents and the network dynamics? We show that Nash equilibria of this game are pure and (under weak assumptions) unique, and can be computed in polynomial time; we test our model by computing equilibria using mirror descent for the two-agent case on random graphs.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Fotini Christia; Michael Curry; Constantinos Daskalakis; Erik Demaine; John P. Dickerson; MohammadTaghi Hajiaghayi; Adam Hesterberg; Marina Knittel; Aidan Milliff",
        "authorids": "",
        "aff": "MIT; University of Maryland; MIT; MIT; University of Maryland; University of Maryland; MIT; University of Maryland; MIT",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16666/16666-13-20160-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05277-scalable-equilibrium-computation-in-multi-agent-influence-games-on-networks/",
        "doi": "10.1609/aaai.v35i6.16666",
        "pdf_size": 321919
    },
    {
        "id": "12086",
        "title": "Scalable First-Order Methods for Robust MDPs",
        "track": "main",
        "status": "Poster",
        "abstract": "Robust Markov Decision Processes (MDPs) are a powerful framework for modeling sequential decision making problems with model uncertainty. This paper proposes the first first-order framework for solving robust MDPs. Our algorithm interleaves primal-dual first-order updates with approximate Value Iteration updates. By carefully controlling the tradeoff between the accuracy and cost of Value Iteration updates, we achieve an ergodic convergence rate that is significantly better than classical Value Iteration algorithms in terms of the number of states S and the number of actions A on ellipsoidal and Kullback-Leibler s-rectangular uncertainty sets. In numerical experiments on ellipsoidal uncertainty sets we show that our algorithm is significantly more scalable than state-of-the-art approaches. Our framework is also the first one to solve robust MDPs with s-rectangular KL uncertainty sets.",
        "primary_area": "Reasoning under Uncertainty",
        "author": "Julien Grand-Cl\u00e9ment; Christian Kroer",
        "authorids": "",
        "aff": "IEOR Department, Columbia University; IEOR Department, Columbia University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17435/17435-13-20929-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12086-scalable-first-order-methods-for-robust-mdps/",
        "doi": "10.1609/aaai.v35i13.17435",
        "pdf_size": 1657069
    },
    {
        "id": "08912",
        "title": "Scalable Graph Networks for Particle Simulations",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning system dynamics directly from observations is a promising direction in machine learning due to its potential to significantly enhance our ability to understand physical systems. However, the dynamics of many real-world systems are challenging to learn due to the presence of nonlinear potentials and a number of interactions that scales quadratically with the number of particles N, as in the case of the N-body problem. In this work we introduce an approach that transforms a fully-connected interaction graph into a hierarchical one which reduces the number of edges to O(N). This results in a linear time and space complexity while the pre-computation of the hierarchical graph requires O(N log (N)) time and O(N) space. Using our approach, we are able to train models on much larger particle counts, even on a single GPU. We evaluate how the phase space position accuracy and energy conservation depend on the number of simulated particles. Our approach retains high accuracy and efficiency even on large-scale gravitational N-body simulations which are impossible to run on a single machine if a fully-connected graph is used. Similar results are also observed when simulating Coulomb interactions. Furthermore, we make several important observations regarding the performance of this new hierarchical model, including: i) its accuracy tends to improve with the number of particles in the simulation and ii) its generalisation to unseen particle counts is also much better than for models that use all O(N^2) interactions.",
        "primary_area": "Machine Learning III",
        "author": "Karolis Martinkus; Aurelien Lucchi; Nathana\u00ebl Perraudin",
        "authorids": "",
        "aff": "ETH Zurich; ETH Zurich; Swiss Data Science Center",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17078/17078-13-20572-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08912-scalable-graph-networks-for-particle-simulations/",
        "doi": "10.1609/aaai.v35i10.17078",
        "pdf_size": 1664648
    },
    {
        "id": "03787",
        "title": "Scalable Verification of Quantized Neural Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Formal verification of neural networks is an active topic of research, and recent advances have significantly increased the size of the networks that verification tools can handle. However, most methods are designed for verification of an idealized model of the actual network which works over real arithmetic and ignores rounding imprecisions. This idealization is in stark contrast to network quantization, which is a technique that trades numerical precision for computational efficiency and is, therefore, often applied in practice. Neglecting rounding errors of such low-bit quantized neural networks has been shown to lead to wrong conclusions about the network's correctness. Thus, the desired approach for verifying quantized neural networks would be one that takes these rounding errors into account.  In this paper, we show that verifying the bit-exact implementation of quantized neural networks with bit-vector specifications is PSPACE-hard, even though verifying idealized real-valued networks and satisfiability of bit-vector specifications alone are each in NP. Furthermore, we explore several practical heuristics toward closing the complexity gap between idealized and bit-exact verification. In particular, we propose three techniques for making SMT-based verification of quantized neural networks more scalable. Our experiments demonstrate that our proposed methods allow a speedup of up to three orders of magnitude over existing approaches.",
        "primary_area": "Constraint Satisfaction and Optimization",
        "author": "Thomas A. Henzinger; Mathias Lechner; \u0110or\u0111e \u017dikeli\u0107",
        "authorids": "",
        "aff": "IST Austria; IST Austria; IST Austria",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16496/16496-13-19990-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03787-scalable-verification-of-quantized-neural-networks/",
        "doi": "10.1609/aaai.v35i5.16496",
        "pdf_size": 137235
    },
    {
        "id": "07011",
        "title": "Scalable and Explainable 1-Bit Matrix Completion via Graph Signal Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "One-bit matrix completion is an important class of positive-unlabeled (PU) learning problems where the observations consist of only positive examples, e.g., in top-N recommender systems. For the first time, we show that 1-bit matrix completion can be formulated as the problem of recovering clean graph signals from noise-corrupted signals in hypergraphs. This makes it possible to enjoy recent advances in graph signal learning. Then, we propose the spectral graph matrix completion (SGMC) method, which can recover the underlying matrix in distributed systems by filtering the noisy data in the graph frequency domain. Meanwhile, it can provide micro- and macro-level explanations by following vertex-frequency analysis. To tackle the computational and memory issue of performing graph signal operations on large graphs, we construct a scalable Nystrom algorithm which can efficiently compute orthonormal eigenvectors. Furthermore, we also develop polynomial and sparse frequency filters to remedy the accuracy loss caused by the approximations. We demonstrate the effectiveness of our algorithms on top-N recommendation tasks, and the results on three large-scale real-world datasets show that SGMC can outperform state-of-the-art top-N recommendation algorithms in accuracy while only requiring a small fraction of training time compared to the baselines.",
        "primary_area": "Machine Learning I",
        "author": "Chao Chen; Dongsheng Li; Junchi Yan; Hanchi Huang; Xiaokang Yang",
        "authorids": "",
        "aff": "MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University, Shanghai, China; School of Computer Science, Fudan University, Shanghai, China Microsoft Research Asia, Shanghai, China; MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University, Shanghai, China Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, China; MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University, Shanghai, China; MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University, Shanghai, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16863/16863-13-20357-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07011-scalable-and-explainable-1-bit-matrix-completion-via-graph-signal-learning/",
        "doi": "10.1609/aaai.v35i8.16863",
        "pdf_size": 242634
    },
    {
        "id": "11237",
        "title": "Scalable and Safe Multi-Agent Motion Planning with Nonlinear Dynamics and Bounded Disturbances",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a scalable and effective multi-agent safe motion planner that enables a group of agents to move to their desired locations while avoiding collisions with obstacles and other agents, with the presence of rich obstacles, high-dimensional, nonlinear, nonholonomic dynamics, actuation limits, and disturbances. We address this problem by finding a piecewise linear path for each agent such that the actual trajectories following these paths are guaranteed to satisfy the reach-and-avoid requirement. We show that the spatial tracking error of the actual trajectories of the controlled agents can be pre-computed for any qualified path that considers the minimum duration of each path segment due to actuation limits. Using these bounds, we find a collision-free path for each agent by solving Mixed Integer-Linear Programs and coordinate agents by using the priority-based search. We demonstrate our method by benchmarking in 2D and 3D scenarios with ground vehicles and quadrotors, respectively, and show improvements over the solving time and the solution quality compared to two state-of-the-art multi-agent motion planners.",
        "primary_area": "Multiagent Systems",
        "author": "Jingkai Chen; Jiaoyang Li; Chuchu Fan; Brian C. Williams",
        "authorids": "",
        "aff": "Massachusetts Institute of Technology; University of Southern California; Massachusetts Institute of Technology; Massachusetts Institute of Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17340/17340-13-20834-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11237-scalable-and-safe-multi-agent-motion-planning-with-nonlinear-dynamics-and-bounded-disturbances/",
        "doi": "10.1609/aaai.v35i13.17340",
        "pdf_size": 622287
    },
    {
        "id": "07694",
        "title": "Scaling-Up Robust Gradient Descent Techniques",
        "track": "main",
        "status": "Poster",
        "abstract": "We study a scalable alternative to robust gradient descent (RGD) techniques that can be used when losses and/or gradients can be heavy-tailed, though this will be unknown to the learner. The core technique is simple: instead of trying to robustly aggregate gradients at each step, which is costly and leads to sub-optimal dimension dependence in risk bounds, we choose a candidate which does not diverge too far from the majority of cheap stochastic sub-processes run over partitioned data. This lets us retain the formal strength of RGD methods at a fraction of the cost.",
        "primary_area": "Machine Learning II",
        "author": "Matthew J. Holland",
        "authorids": "",
        "aff": "Osaka University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16940/16940-13-20434-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07694-scaling-up-robust-gradient-descent-techniques/",
        "doi": "10.1609/aaai.v35i9.16940",
        "pdf_size": 324030
    },
    {
        "id": "05628",
        "title": "Scarce Societal Resource Allocation and the Price of (Local) Justice",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider the allocation of scarce societal resources, where a central authority decides which individuals receive which resources under capacity or budget constraints. Several algorithmic fairness criteria have been proposed to guide these procedures, each quantifying a notion of local justice to ensure the allocation is aligned with the principles of the local institution making the allocation. For example, the efficient allocation maximizes overall social welfare, whereas the leximin assignment seeks to help the \u201cneediest first.\u201d Although the \u201cprice of fairness\u201d (PoF) of leximin has been studied in prior work, we expand on these results by exploiting the structure inherent in real-world scenarios to provide tighter bounds. We further propose a novel criterion \u2013 which we term LoINC (leximin over individually normalized costs) \u2013 that maximizes a different but commonly used notion of local justice: prioritizing those benefiting the most from receiving the resources. We derive analogous PoF bounds for LoINC, showing that the price of LoINC is typically much lower than that of leximin. We provide extensive experimental results using both synthetic data and in a real-world setting considering the efficacy of different homelessness interventions. These results show that the empirical PoF tends to be substantially lower than worst-case bounds would imply and allow us to characterize situations where the price of LoINC fairness can be high.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Quan Nguyen; Sanmay Das; Roman Garnett",
        "authorids": "",
        "aff": "Washington University in St. Louis; George Mason University; Washington University in St. Louis",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16707/16707-13-20201-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05628-scarce-societal-resource-allocation-and-the-price-of-local-justice/",
        "doi": "10.1609/aaai.v35i6.16707",
        "pdf_size": 209141
    },
    {
        "id": "02328",
        "title": "Scene Graph Embeddings Using Relative Similarity Supervision",
        "track": "main",
        "status": "Poster",
        "abstract": "Scene graphs are a powerful structured representation of the underlying content of images, and embeddings derived from them have been shown to be useful in multiple downstream tasks. In this work, we employ a graph convolutional network to exploit structure in scene graphs and produce image embeddings useful for semantic image retrieval. Different from classification-centric supervision traditionally available for learning image representations, we address the task of learning from relative similarity labels in a ranking context. Rooted within the contrastive learning paradigm, we propose a novel loss function that operates on pairs of similar and dissimilar images and imposes relative ordering between them in embedding space. We demonstrate that this Ranking loss, coupled with an intuitive triple sampling strategy, leads to robust representations that outperform well-known contrastive losses on the retrieval task. In addition, we provide qualitative evidence of how retrieved results that utilize structured scene information capture the global context of the scene, different from visual similarity search.",
        "primary_area": "Computer Vision II",
        "author": "Paridhi Maheshwari; Ritwick Chaudhry; Vishwa Vinay",
        "authorids": "",
        "aff": "Adobe Research; Carnegie Mellon University; Adobe Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16333/16333-13-19827-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02328-scene-graph-embeddings-using-relative-similarity-supervision/",
        "doi": "10.1609/aaai.v35i3.16333",
        "pdf_size": 13173148
    },
    {
        "id": "08518",
        "title": "Scheduled Sampling in Vision-Language Pretraining with Decoupled Encoder-Decoder Network",
        "track": "main",
        "status": "Poster",
        "abstract": "Despite having impressive vision-language (VL) pretraining with BERT-based encoder for VL understanding, the pretraining of a universal encoder-decoder for both VL understanding and generation remains challenging. The difficulty originates from the inherently different peculiarities of the two disciplines, e.g., VL understanding tasks capitalize on the unrestricted message passing across modalities, while generation tasks only employ visual-to-textual message passing. In this paper, we start with a two-stream decoupled design of encoder-decoder structure, in which two decoupled cross-modal encoder and decoder are involved to separately perform each type of proxy tasks, for simultaneous VL understanding and generation pretraining. Moreover, for VL pretraining, the dominant way is to replace some input visual/word tokens with mask tokens and enforce the multi-modal encoder/decoder to reconstruct the original tokens, but no mask token is involved when fine-tuning on downstream tasks. As an alternative, we propose a primary scheduled sampling strategy that elegantly mitigates such discrepancy via pretraining encoder-decoder in a two-pass manner. Extensive experiments demonstrate the compelling generalizability of our pretrained encoder-decoder by fine-tuning on four VL understanding and generation downstream tasks. Source code is available at https://github.com/YehLi/TDEN.",
        "primary_area": "Machine Learning III",
        "author": "Yehao Li; Yingwei Pan; Ting Yao; Jingwen Chen; Tao Mei",
        "authorids": "",
        "aff": "JD AI Research; JD AI Research; JD AI Research; Sun Yat-set University; JD AI Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17034/17034-13-20528-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08518-scheduled-sampling-in-vision-language-pretraining-with-decoupled-encoder-decoder-network/",
        "doi": "10.1609/aaai.v35i10.17034",
        "pdf_size": 480337
    },
    {
        "id": "09000",
        "title": "Scheduling of Time-Varying Workloads Using Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Resource usage of production workloads running on shared compute clusters often fluctuate significantly across time. While simultaneous spike in the resource usage between two workloads running on the same machine can create performance degradation, unused resources in a machine results in wastage and undesirable operational characteristics for a compute cluster. Prior works did not consider such temporal resource fluctuations or their alignment for scheduling decisions. Due to the variety of time-varying workloads, their complex resource usage characteristics, it is challenging to design well-defined heuristics for scheduling them optimally across different machines in a cluster. In this paper, we propose a Deep Reinforcement Learning (DRL) based approach to exploit various temporal resource usage patterns of time varying workloads as well as a technique for creating equivalence classes among a large number of production workloads to improve scalability of our method. Validations with real production traces from Google and Alibaba show that our technique can significantly improve metrics for operational excellence (e.g. utilization, fragmentation, resource exhaustion etc.) for a cluster, compared to the baselines.",
        "primary_area": "Machine Learning III",
        "author": "Shanka Subhra Mondal; Nikhil Sheoran; Subrata Mitra",
        "authorids": "",
        "aff": "Princeton University; Adobe Research; Adobe Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17088/17088-13-20582-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09000-scheduling-of-time-varying-workloads-using-reinforcement-learning/",
        "doi": "10.1609/aaai.v35i10.17088",
        "pdf_size": 694187
    },
    {
        "id": "10656",
        "title": "SeCo: Exploring Sequence Supervision for Unsupervised Representation Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "A steady momentum of innovations and breakthroughs has convincingly pushed the limits of unsupervised image representation learning. Compared to static 2D images, video has one more dimension (time). The inherent supervision existing in such sequential structure offers a fertile ground for building unsupervised learning models. In this paper, we compose a trilogy of exploring the basic and generic supervision in the sequence from spatial, spatiotemporal and sequential perspectives. We materialize the supervisory signals through determining whether a pair of samples is from one frame or from one video, and whether a triplet of samples is in the correct temporal order. We uniquely regard the signals as the foundation in contrastive learning and derive a particular form named Sequence Contrastive Learning (SeCo). SeCo shows superior results under the linear protocol on action recognition (Kinetics), untrimmed activity recognition (ActivityNet) and object tracking (OTB-100). More remarkably, SeCo demonstrates considerable improvements over recent unsupervised pre-training techniques, and leads the accuracy by 2.96% and 6.47% against fully-supervised ImageNet pre-training in action recognition task on UCF101 and HMDB51, respectively. Source code is available at https://github.com/YihengZhang-CV/SeCo-Sequence-Contrastive-Learning.",
        "primary_area": "Machine Learning V",
        "author": "Ting Yao; Yiheng Zhang; Zhaofan Qiu; Yingwei Pan; Tao Mei",
        "authorids": "",
        "aff": "JD AI Research; JD AI Research; JD AI Research; JD AI Research; JD AI Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17274/17274-13-20768-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10656-seco-exploring-sequence-supervision-for-unsupervised-representation-learning/",
        "doi": "10.1609/aaai.v35i12.17274",
        "pdf_size": 575379
    },
    {
        "id": "03065",
        "title": "Searching for Alignment in Face Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "A standard pipeline of current face recognition frameworks consists of four individual steps: locating a face with a rough bounding box and several fiducial landmarks, aligning the face image using a pre-defined template, extracting representations and comparing. Among them, face detection, landmark detection and representation learning have long been studied and a lot of works have been proposed. As an important step with a big impact on recognition performance, the alignment step has attracted little attention. In this paper, we first explore and highlight the effects of different alignment templates on face recognition. Then, for the first time, we try to automatically search for the optimal template. We construct a well-defined searching space by decomposing the template searching into the crop size and vertical shift, and propose an efficient method Face Alignment Policy Search (FAPS). Besides, a well-designed benchmark is proposed to evaluate the searched policy. Experiments on our proposed benchmark validate the effectiveness of our method to improve the face recognition performance.",
        "primary_area": "Computer Vision III",
        "author": "Xiaqing Xu; Qiang Meng; Yunxiao Qin; Jianzhu Guo; Chenxu Zhao; Feng Zhou; Zhen Lei",
        "authorids": "",
        "aff": "AIBEE; AIBEE; Northwestern Polytechnical University; NLPR; Academy of Sciences, Mininglamp Technology; AIBEE; NLPR, CASIA, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16415/16415-13-19909-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03065-searching-for-alignment-in-face-recognition/",
        "doi": "10.1609/aaai.v35i4.16415",
        "pdf_size": 3404891
    },
    {
        "id": "08902",
        "title": "Searching for Machine Learning Pipelines Using a Context-Free Grammar",
        "track": "main",
        "status": "Poster",
        "abstract": "AutoML automatically selects, composes and parameterizes machine learning algorithms into a workflow or pipeline of operations that aims at maximizing performance on a given dataset. Although current methods for AutoML achieved impressive results they mostly concentrate on optimizing fixed linear workflows. In this paper, we take a different approach and focus on generating and optimizing pipelines of complex directed acyclic graph shapes. These complex pipeline structure may lead to discovering hidden features and thus boost performance considerably. We explore the power of heuristic search and context-free grammars to search and optimize these kinds of pipelines. Experiments on various benchmark datasets show that our approach is highly competitive and often outperforms existing AutoML systems.",
        "primary_area": "Machine Learning III",
        "author": "Radu Marinescu; Akihiro Kishimoto; Parikshit Ram; Ambrish Rawat; Martin Wistuba; Paulito P. Palmes; Adi Botea",
        "authorids": "",
        "aff": "IBM Research; IBM Research; IBM Research; IBM Research; IBM Research; IBM Research; Eaton",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17077/17077-13-20571-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08902-searching-for-machine-learning-pipelines-using-a-context-free-grammar/",
        "doi": "10.1609/aaai.v35i10.17077",
        "pdf_size": 571722
    },
    {
        "id": "09259",
        "title": "Second Order Techniques for Learning Time-series with Structural Breaks",
        "track": "main",
        "status": "Poster",
        "abstract": "We study fundamental problems in learning nonstationary time-series: how to effectively regularize time-series models and how to adaptively tune forgetting rates.  The effectiveness of L2 regularization depends on the choice of coordinates, and the variables need to be appropriately normalized.  In nonstationary environment, however, what is appropriate can vary over time.  Proposed regularization is invariant to the invertible linear transformation of coordinates, eliminating the necessity of normalization.  We also propose an ensemble learning approach to adaptively tuning the forgetting rate and regularization-coefficient.  We train multiple models with varying hyperparameters and evaluate their performance by the use of multiple hyper forgetting rates.  At each step, we choose the best performing model on the basis of the best performing hyper forgetting rate.  The effectiveness of the proposed approaches is demonstrated with real time-series.",
        "primary_area": "Machine Learning III",
        "author": "Takayuki Osogami",
        "authorids": "",
        "aff": "IBM Research - Tokyo",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17117/17117-13-20611-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09259-second-order-techniques-for-learning-time-series-with-structural-breaks/",
        "doi": "10.1609/aaai.v35i10.17117",
        "pdf_size": 2842594
    },
    {
        "id": "10896",
        "title": "Secure Bilevel Asynchronous Vertical Federated Learning with Backward Updating",
        "track": "main",
        "status": "Poster",
        "abstract": "Vertical federated learning (VFL) attracts increasing attention due to the emerging demands of multi-party collaborative modeling and concerns of privacy leakage. In the real VFL applications, usually only one or partial parties hold labels, which makes it challenging for all parties to collaboratively learn the model without privacy leakage. Meanwhile, most existing VFL algorithms are trapped in the synchronous computations, which leads to inefficiency in their real-world applications. To address these challenging problems, we propose a novel VFL framework integrated with new backward updating mechanism and bilevel asynchronous parallel architecture (VFB^2), under which three new algorithms, including VFB^2-SGD, -SVRG, and -SAGA, are proposed. We derive the theoretical results of the convergence rates of these three algorithms under both strongly convex and nonconvex conditions. We also prove the security of VFB^2 under semi-honest threat models. Extensive experiments on benchmark datasets demonstrate that our algorithms are efficient, scalable, and lossless.",
        "primary_area": "Machine Learning V",
        "author": "Qingsong Zhang; Bin Gu; Cheng Deng; Heng Huang",
        "authorids": "",
        "aff": "Xidian University JD Tech; MBZUAI JD Finance America Corporation; Xidian University; University of Pittsburgh JD Finance America Corporation",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17301/17301-13-20795-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10896-secure-bilevel-asynchronous-vertical-federated-learning-with-backward-updating/",
        "doi": "10.1609/aaai.v35i12.17301",
        "pdf_size": 720461
    },
    {
        "id": "12526",
        "title": "Segatron: Segment-Aware Transformer for Language Modeling and Understanding",
        "track": "main",
        "status": "Poster",
        "abstract": "Transformers are powerful for sequence modeling. Nearly all state-of-the-art language models and pre-trained language models are based on the Transformer architecture. However, it distinguishes sequential tokens only with the token position index. We hypothesize that better contextual representations can be generated from the Transformer with richer positional information. To verify this, we propose a segment-aware Transformer (Segatron), by replacing the original token position encoding with a combined position encoding of paragraph, sentence, and token. We first introduce the segment-aware mechanism to Transformer-XL, which is a popular Transformer-based language model with memory extension and relative position encoding. We find that our method can further improve the Transformer-XL base model and large model, achieving 17.1 perplexity on the WikiText-103 dataset. We further investigate the pre-training masked language modeling task with Segatron. Experimental results show that BERT pre-trained with Segatron (SegaBERT) can outperform BERT with vanilla Transformer on various NLP tasks, and outperforms RoBERTa on zero-shot sentence representation learning. Our code is available on GitHub.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "He Bai; Peng Shi; Jimmy Lin; Yuqing Xie; Luchen Tan; Kun Xiong; Wen Gao; Ming Li",
        "authorids": "",
        "aff": "University of Waterloo; University of Waterloo; University of Waterloo RSVP.ai; University of Waterloo; RSVP.ai; RSVP.ai; Peking University; University of Waterloo RSVP.ai",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17485/17485-13-20979-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12526-segatron-segment-aware-transformer-for-language-modeling-and-understanding/",
        "doi": "10.1609/aaai.v35i14.17485",
        "pdf_size": 3298906
    },
    {
        "id": "12480",
        "title": "Segmentation of Tweets with URLs and its Applications to Sentiment Analysis",
        "track": "main",
        "status": "Poster",
        "abstract": "An important means for disseminating information in social media platforms is by including URLs that point to external sources in user posts. In Twitter, we estimate that about 21% of the daily stream of English-language tweets contain URLs. We notice that NLP tools make little attempt at understanding the relationship between the content of the URL and the text surrounding it in a tweet. In this work, we study the structure of tweets with URLs relative to the content of the Web documents pointed to by the URLs. We identify several segments classes that may appear in a tweet with URLs, such as the title of a Web page and the user's original content. Our goals in this paper are: introduce, define, and analyze the segmentation problem of tweets with URLs, develop an effective algorithm to solve it, and show that our solution can benefit sentiment analysis on Twitter. We also show that the problem is an instance of the block edit distance problem, and thus an NP-hard problem.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Abdullah Aljebreen; Weiyi Meng; Eduard Dragut",
        "authorids": "",
        "aff": "Temple University; Binghamton University; Temple University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17480/17480-13-20974-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12480-segmentation-of-tweets-with-urls-and-its-applications-to-sentiment-analysis/",
        "doi": "10.1609/aaai.v35i14.17480",
        "pdf_size": 730608
    },
    {
        "id": "12963",
        "title": "Self-Attention Attribution: Interpreting Information Interactions Inside Transformer",
        "track": "main",
        "status": "Poster",
        "abstract": "The great success of Transformer-based models benefits from the powerful multi-head self-attention mechanism, which learns token dependencies and encodes contextual information from the input. Prior work strives to attribute model decisions to individual input features with different saliency measures, but they fail to explain how these input features interact with each other to reach predictions. In this paper, we propose a self-attention attribution method to interpret the information interactions inside Transformer. We take BERT as an example to conduct extensive studies. Firstly, we apply self-attention attribution to identify the important attention heads, while others can be pruned with marginal performance degradation. Furthermore, we extract the most salient dependencies in each layer to construct an attribution tree, which reveals the hierarchical interactions inside Transformer. Finally, we show that the attribution results can be used as adversarial patterns to implement non-targeted attacks towards BERT.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Yaru Hao; Li Dong; Furu Wei; Ke Xu",
        "authorids": "",
        "aff": "Beihang University Microsoft Research; Microsoft Research; Microsoft Research; Beihang University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17533/17533-13-21027-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12963-self-attention-attribution-interpreting-information-interactions-inside-transformer/",
        "doi": "10.1609/aaai.v35i14.17533",
        "pdf_size": 1242376
    },
    {
        "id": "02746",
        "title": "Self-Domain Adaptation for Face Anti-Spoofing",
        "track": "main",
        "status": "Poster",
        "abstract": "Although current face anti-spoofing methods achieve promising results under intra-dataset testing, they suffer from poor generalization to unseen attacks. Most existing works adopt domain adaptation (DA) or domain generalization (DG) techniques to address this problem. However, the target domain is often unknown during training which limits the utilization of DA methods. DG methods can conquer this by learning domain invariant features without seeing any target data. However, they fail in utilizing the information of target data. In this paper, we propose a self-domain adaptation framework to leverage the unlabeled test domain data at inference. Specifically, a domain adaptor is designed to adapt the model for test domain. In order to learn a better adaptor, a meta-learning based adaptor learning algorithm is proposed using the data of multiple source domains at the training step. At test time, the adaptor is updated using only the test domain data according to the proposed unsupervised adaptor loss to further improve the performance. Extensive experiments on four public datasets validate the effectiveness of the proposed method.",
        "primary_area": "Computer Vision III",
        "author": "Jingjing Wang; Jingyi Zhang; Ying Bian; Youyi Cai; Chunmao Wang; Shiliang Pu",
        "authorids": "",
        "aff": "Hikvision Research Institute; Hikvision Research Institute; Hikvision Research Institute; Hikvision Research Institute; Hikvision Research Institute; Hikvision Research Institute",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16379/16379-13-19873-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02746-self-domain-adaptation-for-face-anti-spoofing/",
        "doi": "10.1609/aaai.v35i4.16379",
        "pdf_size": 1178996
    },
    {
        "id": "08392",
        "title": "Self-Paced Two-dimensional PCA",
        "track": "main",
        "status": "Poster",
        "abstract": "Two-dimensional PCA (2DPCA) is an effective approach to reduce dimension and extract features in the image domain. Most recently developed techniques use different error measures to improve their robustness to outliers. When certain data points are overly contaminated, the existing methods are frequently incapable of filtering out and eliminating the excessively polluted ones. Moreover, natural systems have smooth dynamics, an opportunity is lost if an unsupervised objective function remains static. Unlike previous studies, we explicitly differentiate the samples to alleviate the impact of outliers and propose a novel method called Self-Paced 2DPCA (SP2DPCA)algorithm, which progresses from `easy\u2019 to `complex\u2019 samples. By using an alternative optimization strategy, SP2DPCA looks for optimal projection matrix and filters out outliers iteratively. Theoretical analysis demonstrates the robustness nature of our method. Extensive experiments on image reconstruction and clustering verify the superiority of our approach.",
        "primary_area": "Machine Learning II",
        "author": "Jiangxin Li; Zhao Kang; Chong Peng; Wenyu Chen",
        "authorids": "",
        "aff": "University of Electronic Science and Technology of China; University of Electronic Science and Technology of China; Qingdao University; University of Electronic Science and Technology of China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17020/17020-13-20514-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08392-self-paced-two-dimensional-pca/",
        "doi": "10.1609/aaai.v35i9.17020",
        "pdf_size": 2548475
    },
    {
        "id": "07107",
        "title": "Self-Progressing Robust Training",
        "track": "main",
        "status": "Poster",
        "abstract": "Enhancing model robustness under new and even adversarial environments is a crucial milestone toward building trustworthy machine learning systems. Current robust training methods such as adversarial training explicitly uses an ``attack'' (e.g., l_infty-norm bounded perturbation) to generate adversarial examples during model training for improving adversarial robustness. In this paper, we take a different perspective and propose a new framework SPROUT, self-progressing robust training. During model training, SPROUT progressively adjusts training label distribution via our proposed parametrized label smoothing technique, making training free of attack generation and more scalable. We also motivate SPROUT using a general formulation based on vicinity risk minimization, which includes many robust training methods as special cases. Compared with state-of-the-art adversarial training methods (PGD-l_infty and TRADES) under l_infty-norm bounded attacks and various invariance tests, SPROUT consistently attains superior performance and is more scalable to large neural networks. Our results shed new light on scalable, effective and attack-independent robust training methods.",
        "primary_area": "Machine Learning I",
        "author": "Minhao Cheng; Pin-Yu Chen; Sijia Liu; Shiyu Chang; Cho-Jui Hsieh; Payel Das",
        "authorids": "",
        "aff": "UCLA IBM Research; IBM Research; Michigan State University; IBM Research; UCLA; IBM Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16874/16874-13-20368-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07107-self-progressing-robust-training/",
        "doi": "10.1609/aaai.v35i8.16874",
        "pdf_size": 4727162
    },
    {
        "id": "10311",
        "title": "Self-Supervised Attention-Aware Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual saliency has emerged as a major visualization tool for interpreting deep reinforcement learning (RL) agents. However, much of the existing research uses it as an analyzing tool rather than an inductive bias for policy learning. In this work, we use visual attention as an inductive bias for RL agents. We propose a novel self-supervised attention learning approach which can 1. learn to select regions of interest without explicit annotations, and 2. act as a plug for existing deep RL methods to improve the learning performance. We empirically show that the self-supervised attention-aware deep RL methods outperform the baselines in the context of both the rate of convergence and performance. Furthermore, the proposed self-supervised attention is not tied with specific policies, nor restricted to a specific scene. We posit that the proposed approach is a general self-supervised attention module for multi-task learning and transfer learning, and empirically validate the generalization ability of the proposed method. Finally, we show that our method learns meaningful object keypoints highlighting improvements both qualitatively and quantitatively.",
        "primary_area": "Machine Learning V",
        "author": "Haiping Wu; Khimya Khetarpal; Doina Precup",
        "authorids": "",
        "aff": "McGill University Mila; McGill University Mila; McGill University Mila Google DeepMind",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17235/17235-13-20729-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10311-self-supervised-attention-aware-reinforcement-learning/",
        "doi": "10.1609/aaai.v35i12.17235",
        "pdf_size": 7684128
    },
    {
        "id": "04503",
        "title": "Self-Supervised Hypergraph Convolutional Networks for Session-based Recommendation",
        "track": "main",
        "status": "Poster",
        "abstract": "Session-based recommendation (SBR) focuses on next-item prediction at a certain time point. As user profiles are generally not available in this scenario, capturing the user intent lying in the item transitions plays a pivotal role. Recent graph neural networks (GNNs) based SBR methods regard the item transitions as pairwise relations, which neglect the complex high-order information among items. Hypergraph provides a natural way to capture beyond-pairwise relations, while its potential for SBR has remained unexplored. In this paper, we fill this gap by modeling session-based data as a hypergraph and then propose a dual channel hypergraph convolutional network -- DHCN to improve SBR. Moreover, to enhance hypergraph modeling, we innovatively integrate self-supervised learning into the training of our network by maximizing mutual information between the session representations learned via the two channels in DHCN, serving as an auxiliary task to improve the recommendation task. Extensive experiments on three benchmark datasets demonstrate the superiority of our model over the SOTA methods, and the ablation study validates the effectiveness and rationale of hypergraph modeling and self-supervised task. The implementation of our model is available via https://github.com/xiaxin1998/DHCN.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Xin Xia; Hongzhi Yin; Junliang Yu; Qinyong Wang; Lizhen Cui; Xiangliang Zhang",
        "authorids": "",
        "aff": "The University of Queensland; The University of Queensland; The University of Queesland; The University of Queensland; ShanDong University; King Abdullah University of Science and Technology, Saudi Arabia",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16578/16578-13-20072-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04503-self-supervised-hypergraph-convolutional-networks-for-session-based-recommendation/",
        "doi": "10.1609/aaai.v35i5.16578",
        "pdf_size": 1328307
    },
    {
        "id": "04644",
        "title": "Self-Supervised Prototype Representation Learning for Event-Based Corporate Profiling",
        "track": "main",
        "status": "Poster",
        "abstract": "Event-based corporate profiling aims to assess the evolving operational status of the corresponding corporate from its event sequence. Existing studies on corporate profiling have partially addressed the problem via (i) case-by-case empirical analysis by leveraging traditional financial methods, or (ii) the automatic profile inference by reformulating the problem into a supervised learning task. However, both approaches heavily rely on domain knowledge and are labor-intensive. More importantly, the task-specific nature of both approaches prevents the obtained corporate profiles from being applied to diversified downstream applications. To this end, in this paper, we propose a Self-Supervised Prototype Representation Learning (SePaL) framework for dynamic corporate profiling. By exploiting the topological information of an event graph and exploring self-supervised learning techniques, SePaL can obtain unified corporate representations that are robust to event noises and can be easily fine-tuned to benefit various down-stream applications with only a few annotated data. Specifically, we first infer the initial cluster distribution of noise-resistant event prototypes based on latent representations of events. Then, we construct four permutation-invariant self-supervision signals to guide the representation learning of the event prototype. In terms of applications, we exploit the learned time-evolving corporate representations for both stock price spike prediction and corporate default risk evaluation. Experimental results on two real-world corporate event datasets demonstrate the effectiveness of SePaL for these two applications.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Zixuan Yuan; Hao Liu; Renjun Hu; Denghui Zhang; Hui Xiong",
        "authorids": "",
        "aff": "Rutgers University; Business Intelligence Lab, Baidu Research; Alibaba Group; Rutgers University; Rutgers University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16594/16594-13-20088-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04644-self-supervised-prototype-representation-learning-for-event-based-corporate-profiling/",
        "doi": "10.1609/aaai.v35i5.16594",
        "pdf_size": 1500266
    },
    {
        "id": "04978",
        "title": "Self-Supervised Self-Supervision by Combining Deep Learning and Probabilistic Logic",
        "track": "main",
        "status": "Poster",
        "abstract": "Labeling training examples at scale is a perennial challenge in machine learning. Self-supervision methods compensate for the lack of direct supervision by leveraging prior knowledge to automatically generate noisy labeled examples. Deep probabilistic logic (DPL) is a unifying framework for self-supervised learning that represents unknown labels as latent variables and incorporates diverse self-supervision using probabilistic logic to train a deep neural network end-to-end using variational EM.  While DPL is successful at combining pre-specified self-supervision, manually crafting self-supervision to attain high accuracy may still be tedious and challenging. In this paper, we propose Self-Supervised Self-Supervision (S4), which adds to DPL the capability to learn new self-supervision automatically. Starting from an initial \"seed,\" S4 iteratively uses the deep neural network to propose new self-supervision. These are either added directly (a form of structured self-training) or verified by a human expert (as in feature-based active learning). Experiments show that S4 is able to automatically propose accurate self-supervision and can often nearly match the accuracy of supervised methods with a tiny fraction of the human effort.",
        "primary_area": "Neuro-Symbolic AI",
        "author": "Hunter Lang; Hoifung Poon",
        "authorids": "",
        "aff": "MIT; Microsoft Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16631/16631-13-20125-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04978-self-supervised-self-supervision-by-combining-deep-learning-and-probabilistic-logic/",
        "doi": "10.1609/aaai.v35i6.16631",
        "pdf_size": 196042
    },
    {
        "id": "02073",
        "title": "Self-Supervised Sketch-to-Image Synthesis",
        "track": "main",
        "status": "Poster",
        "abstract": "Imagining a colored realistic image from an arbitrary-drawn sketch is one of human capabilities that we eager machines to mimic.  Unlike previous methods that either require the sketch-image pairs or utilize low-quantity detected edges as sketches, we study the exemplar-based sketch-to-image (s2i) synthesis task in a self-supervised learning manner, eliminating the necessity of the paired sketch data. To this end,  we first propose an unsupervised method to efficiently synthesize line-sketches for general RGB-only datasets. With the synthetic paired-data, we then present a self-supervised Auto-Encoder (AE) to decouple the content/style features from sketches and RGB-images, and synthesize images both content-faithful to the sketches and style-consistent to the RGB-images. While prior works employ either the cycle-consistence loss or dedicated attentional modules to enforce the content/style fidelity, we show AE's superior performance with pure self-supervisions.  To further improve the synthesis quality in high resolution, we also leverage an adversarial network to refine the details of synthetic images. Extensive experiments on $1024^2$ resolution demonstrate a new state-of-art-art performance of the proposed model on CelebA-HQ and Wiki-Art datasets. Moreover, with the proposed sketch generator, the model shows a promising performance on style mixing and style transfer, which the synthesized images are not only style-consistent but also semantically meaningful.",
        "primary_area": "Computer Vision II",
        "author": "Bingchen Liu; Yizhe Zhu; Kunpeng Song; Ahmed Elgammal",
        "authorids": "",
        "aff": "Playform - Artrendex Inc., USA Department of Computer Science, Rutgers University; Department of Computer Science, Rutgers University; Playform - Artrendex Inc., USA Department of Computer Science, Rutgers University; Playform - Artrendex Inc., USA Department of Computer Science, Rutgers University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16304/16304-13-19798-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02073-self-supervised-sketch-to-image-synthesis/",
        "doi": "10.1609/aaai.v35i3.16304",
        "pdf_size": 17418563
    },
    {
        "id": "11185",
        "title": "Self-correcting Q-learning",
        "track": "main",
        "status": "Poster",
        "abstract": "The Q-learning algorithm is known to be affected by the maximization bias, i.e. the systematic overestimation of action values, an important issue that has recently received renewed attention. Double Q-learning has been proposed as an efficient algorithm to mitigate this bias. However, this comes at the price of an underestimation of action values, in addition to increased memory requirements and a slower convergence. In this paper, we introduce a new way to address the maximization bias in the form of a \"self-correcting algorithm\" for approximating the maximum of an expected value. Our method balances the overestimation of the single estimator used in conventional Q-learning and the underestimation of the double estimator used in Double Q-learning. Applying this strategy to Q-learning results in Self-correcting Q-learning. We show theoretically that this new algorithm enjoys the same convergence guarantees as Q-learning while being more accurate. Empirically, it performs better than Double Q-learning in domains with rewards of high variance, and it even attains faster convergence than Q-learning in domains with rewards of zero or low variance. These advantages transfer to a Deep Q Network implementation that we call Self-correcting DQN and which outperforms regular DQN and Double DQN on several tasks in the Atari 2600 domain.",
        "primary_area": "Machine Learning V",
        "author": "Rong Zhu; Mattia Rigotti",
        "authorids": "",
        "aff": "Fudan University; IBM Research AI",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17334/17334-13-20828-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11185-self-correcting-q-learning/",
        "doi": "10.1609/aaai.v35i12.17334",
        "pdf_size": 1054701
    },
    {
        "id": "14454",
        "title": "Self-supervised Bilingual Syntactic Alignment for Neural Machine Translation",
        "track": "main",
        "status": "Poster",
        "abstract": "While various neural machine translation (NMT) methods have integrated mono-lingual syntax knowledge into the linguistic representation of sequence-to-sequence, no research is available on aligning the syntactic structures of target language with the corresponding source language syntactic structures. This work shows the first attempt of a source-target bilingual syntactic alignment approach SyntAligner by mutual information maximization-based self-supervised neural deep modeling. Building on the word alignment for NMT, our SyntAligner firstly aligns the syntactic structures of source and target sentences and then maximizes their mutual dependency by introducing a lower bound on their mutual information. In SyntAligner, the syntactic structure of span granularity is represented by transforming source or target word hidden state into a source or target syntactic span vector. A border-sensitive span attention mechanism then captures the correlation between the source and target syntactic span vectors, which also captures the self-attention between span border-words as alignment bias. Lastly, a self-supervised bilingual syntactic mutual information maximization-based learning objective dynamically samples the aligned syntactic spans to maximize their mutual dependency. Experiment results on three typical NMT tasks: WMT'14 English to German, IWSLT'14 German to English, and NC'11 English to French show the SyntAligner effectiveness and universality of syntactic alignment.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Tianfu Zhang; Heyan Huang; Chong Feng; Longbing Cao",
        "authorids": "",
        "aff": "Beijing Institute of Technology; Beijing Institute of technology; Beijing Institute of Technology; University of Technology Sydney",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17699/17699-13-21193-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14454-self-supervised-bilingual-syntactic-alignment-for-neural-machine-translation/",
        "doi": "10.1609/aaai.v35i16.17699",
        "pdf_size": 5290665
    },
    {
        "id": "03030",
        "title": "Self-supervised Multi-view Stereo via Effective Co-Segmentation and Data-Augmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent studies have witnessed that self-supervised methods based on view synthesis obtain clear progress on multi-view stereo (MVS). However, existing methods rely on the assumption that the corresponding points among different views share the same color, which may not always be true in practice. This may lead to unreliable self-supervised signal and harm the final reconstruction performance. To address the issue, we propose a framework integrated with more reliable supervision guided by semantic co-segmentation and data-augmentation. Specially, we excavate mutual semantic from multi-view images to guide the semantic consistency. And we devise effective data-augmentation mechanism which ensures the transformation robustness by treating the prediction of regular samples as pseudo ground truth to regularize the prediction of augmented samples. Experimental results on DTU dataset show that our proposed methods achieve the state-of-the-art performance among unsupervised methods, and even compete on par with supervised methods. Furthermore, extensive experiments on Tanks&Temples dataset demonstrate the effective generalization ability of the proposed method.",
        "primary_area": "Computer Vision III",
        "author": "Hongbin Xu; Zhipeng Zhou; Yu Qiao; Wenxiong Kang; Qiuxia Wu",
        "authorids": "",
        "aff": "South China University of Technology; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences; South China University of Technology; South China University of Technology, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16411/16411-13-19905-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03030-self-supervised-multi-view-stereo-via-effective-co-segmentation-and-data-augmentation/",
        "doi": "10.1609/aaai.v35i4.16411",
        "pdf_size": 11867552
    },
    {
        "id": "13171",
        "title": "Self-supervised Pre-training and Contrastive Representation Learning for Multiple-choice Video QA",
        "track": "main",
        "status": "Poster",
        "abstract": "Video Question Answering (VideoQA) requires fine-grained understanding of both video and language modalities to answer the given questions. In this paper, we propose novel training schemes for multiple-choice video question answering with a self-supervised pre-training stage and a supervised contrastive learning in the main stage as an auxiliary learning. In the self-supervised pre-training stage, we transform the original problem format of predicting the correct answer into the one that predicts the relevant question to provide a model with broader contextual inputs without any further dataset or annotation. For contrastive learning in the main stage, we add a masking noise to the input corresponding to the ground-truth answer, and consider the original input of the ground-truth answer as a positive sample, while treating the rest as negative samples. By mapping the positive sample closer to the masked input, we show that the model performance is improved. We further employ locally aligned attention to focus more effectively on the video frames that are particularly relevant to the given corresponding subtitle sentences. We evaluate our proposed model on highly competitive benchmark datasets related to multiple-choice video QA: TVQA, TVQA+, and DramaQA. Experimental results show that our model achieves state-of-the-art performance on all datasets. We also validate our approaches through further analyses.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Seonhoon Kim; Seohyeong Jeong; Eunbyul Kim; Inho Kang; Nojun Kwak",
        "authorids": "",
        "aff": "Seoul National University Naver Search; Seoul National University; Naver Search; Naver Search; Seoul National University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17556/17556-13-21050-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13171-self-supervised-pre-training-and-contrastive-representation-learning-for-multiple-choice-video-qa/",
        "doi": "10.1609/aaai.v35i14.17556",
        "pdf_size": 3384044
    },
    {
        "id": "05185",
        "title": "Selfish Creation of Social Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Understanding real-world networks is a core research endeavor within the last two decades. Network Creation Games are a promising approach for this from a game-theoretic perspective. In these games, selfish agents corresponding to nodes in a network strategically decide which links to form to optimize their centrality. Many versions have been introduced and analyzed, but none of them fits to modeling the evolution of social networks. In real-world social networks connections are often established by recommendations from common acquaintances or by a chain of such recommendations. Thus establishing and maintaining a contact with a friend of a friend is easier than connecting to complete strangers. This explains the high clustering, i.e., the abundance of triangles, in real-world social networks.   We propose and analyze a network creation model inspired by real-world social networks. In our model edges are formed via bilateral consent of both endpoints and the cost for establishing and maintaining an edge is proportional to the distance of the endpoints before establishing the connection. We provide results for generic cost functions which essentially only must be convex functions in the distance of the endpoints without the respective edge. For this broad class of cost functions we provide many structural properties of equilibrium networks and prove (almost) tight bounds on the diameter, the Price of Anarchy and the Price of Stability. Moreover, as a proof-of-concept we show via experiments that the created equilibrium networks of our model indeed closely mimic real-world social networks. We observe degree distributions that seem to follow a power-law, high clustering, and low diameters. This can be seen as a promising first step towards game-theoretic network creation models that predict networks featuring all core real-world properties.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Davide Bil\u00f2; Tobias Friedrich; Pascal Lenzner; Stefanie Lowski; Anna Melnichenko",
        "authorids": "",
        "aff": "University of Sassari; Hasso Plattner Institute, University of Potsdam; Hasso Plattner Institute, University of Potsdam; Humboldt-University Berlin; Hasso Plattner Institute, University of Potsdam",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16655/16655-13-20149-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05185-selfish-creation-of-social-networks/",
        "doi": "10.1609/aaai.v35i6.16655",
        "pdf_size": 400547
    },
    {
        "id": "02861",
        "title": "Semantic Consistency Networks for 3D Object Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Detecting 3D objects from point clouds is a significant yet challenging issue in many applications. While most existing approaches seek to leverage geometric information of point clouds, few studies accommodate the inherent semantic characteristics of each point and the consistency between the geometric and semantic cues. In this work, we propose a novel semantic consistency network (SCNet) driven by a natural principle: the class of a predicted 3D bounding box should be consistent with the classes of all the points inside this box. Specifically, our SCNet consists of a feature extraction structure, a detection decision structure, and a semantic segmentation structure. In inference, the feature extraction and the detection decision structures are used to detect 3D objects. In training, the semantic segmentation structure is jointly trained with the other two structures to produce more robust and applicative model parameters. A novel semantic consistency loss is proposed to regulate the output 3D object boxes and the segmented points to boost the performance. Our model is evaluated on two challenging datasets and achieves comparable results to the state-of-the-art methods.",
        "primary_area": "Computer Vision III",
        "author": "Wenwen Wei; Ping Wei; Nanning Zheng",
        "authorids": "",
        "aff": "Xi'an Jiaotong University; Xi'an Jiaotong University; Xi'an Jiaotong University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16392/16392-13-19886-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02861-semantic-consistency-networks-for-3d-object-detection/",
        "doi": "10.1609/aaai.v35i4.16392",
        "pdf_size": 2770641
    },
    {
        "id": "02514",
        "title": "Semantic Grouping Network for Video Captioning",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper considers a video caption generating network referred to as Semantic Grouping Network (SGN) that attempts (1) to group video frames with discriminating word phrases of partially decoded caption and then (2) to decode those semantically aligned groups in predicting the next word. As consecutive frames are not likely to provide unique information, prior methods have focused on discarding or merging repetitive information based only on the input video. The SGN learns an algorithm to capture the most discriminating word phrases of the partially decoded caption and a mapping that associates each phrase to the relevant video frames - establishing this mapping allows semantically related frames to be clustered, which reduces redundancy. In contrast to the prior methods, the continuous feedback from decoded words enables the SGN to dynamically update the video representation that adapts to the partially decoded caption. Furthermore, a contrastive attention loss is proposed to facilitate accurate alignment between a word phrase and video frames without manual annotations. The SGN achieves state-of-the-art performances by outperforming runner-up methods by a margin of 2.1%p and 2.4%p in a CIDEr-D score on MSVD and MSR-VTT datasets, respectively. Extensive experiments demonstrate the effectiveness and interpretability of the SGN.",
        "primary_area": "Computer Vision II",
        "author": "Hobin Ryu; Sunghun Kang; Haeyong Kang; Chang D. Yoo",
        "authorids": "",
        "aff": "KAIST; KAIST; KAIST; KAIST",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16353/16353-13-19847-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02514-semantic-grouping-network-for-video-captioning/",
        "doi": "10.1609/aaai.v35i3.16353",
        "pdf_size": 1169215
    },
    {
        "id": "00964",
        "title": "Semantic MapNet: Building Allocentric Semantic Maps and Representations from Egocentric Views",
        "track": "main",
        "status": "Poster",
        "abstract": "We study the task of semantic mapping \u2013 specifically, an embodied agent (a robot or an egocentric AI assistant) is given a tour of a new environment and asked to build an allocentric top-down semantic map (\u2018what is where?\u2019) from egocentric observations of an RGB-D camera with known pose (via localization sensors). Importantly, our goal is to build neural episodic memories and spatio-semantic representations of 3D spaces that enable the agent to easily learn subsequent tasks in the same space \u2013 navigating to objects seen during the tour (\u2018Find chair\u2019) or answering questions about the space (\u2018How many chairs did you see in the house?\u2019). Towards this goal, we present Semantic MapNet (SMNet), which consists of: (1) an Egocentric Visual Encoder that encodes each egocentric RGB-D frame, (2) a Feature Projector that projects egocentric features to appropriate locations on a floor-plan, (3) a Spatial Memory Tensor of size floor-plan length\u00d7width\u00d7feature-dims that learns to accumulate projected egocentric features, and (4) a Map Decoder that uses the memory tensor to produce semantic top-down maps. SMNet combines the strengths of (known) projective camera geometry and neural representation learning. On the task of semantic mapping in the  Matterport3D dataset, SMNet significantly outperforms competitive baselines by 4.01\u221216.81% (absolute) on mean-IoU and 3.81\u221219.69% (absolute) on Boundary-F1 metrics. Moreover, we show how to use the spatio-semantic allocentric representations build by SMNet for the task of ObjectNav and Embodied Question Answering. Project page: https://vincentcartillier.github.io/smnet.html.",
        "primary_area": "Computer Vision I",
        "author": "Vincent Cartillier; Zhile Ren; Neha Jain; Stefan Lee; Irfan Essa; Dhruv Batra",
        "authorids": "",
        "aff": "Georgia Institute of Technology; Georgia Institute of Technology; Georgia Institute of Technology; Oregon State University; Georgia Institute of Technology Google Research; Georgia Institute of Technology Facebook AI Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16180/16180-13-19674-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00964-semantic-mapnet-building-allocentric-semantic-maps-and-representations-from-egocentric-views/",
        "doi": "10.1609/aaai.v35i2.16180",
        "pdf_size": 10267566
    },
    {
        "id": "01406",
        "title": "Semantic-guided Reinforced Region Embedding for Generalized Zero-Shot Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Generalized zero-shot Learning (GZSL) aims to recognize images from either seen or unseen domain, mainly by learning a joint embedding space to associate image features with the corresponding category descriptions. Recent methods have proved that localizing important object regions can effectively bridge the semantic-visual gap. However, these are all based on one-off visual localizers, lacking of interpretability and flexibility. In this paper, we propose a novel Semantic-guided Reinforced Region Embedding (SR2E) network that can localize important objects in the long-term interests to construct semantic-visual embedding space. SR2E consists of Reinforced Region Module (R2M) and Semantic Alignment Module (SAM). First, without the annotated bounding box as supervision, R2M encodes the semantic category guidance into the reward and punishment criteria to teach the localizer serialized region searching. Besides, R2M explores different action spaces during the serialized searching path to avoid local optimal localization, which thereby generates discriminative visual features with less redundancy. Second, SAM preserves the semantic relationship into visual features via semantic-visual alignment and designs a domain detector to alleviate the domain confusion. Experiments on four public benchmarks demonstrate that the proposed SR2E is an effective GZSL method with reinforced embedding space, which obtains averaged 6.1% improvements.",
        "primary_area": "Computer Vision I",
        "author": "Jiannan Ge; Hongtao Xie; Shaobo Min; Yongdong Zhang",
        "authorids": "",
        "aff": "University of Science and Technology of China; University of Science and Technology of China; University of Science and Technology of China; University of Science and Technology of China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16230/16230-13-19724-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01406-semantic-guided-reinforced-region-embedding-for-generalized-zero-shot-learning/",
        "doi": "10.1609/aaai.v35i2.16230",
        "pdf_size": 4882671
    },
    {
        "id": "13762",
        "title": "Semantics Altering Modifications for Evaluating Comprehension in Machine Reading",
        "track": "main",
        "status": "Poster",
        "abstract": "Advances in NLP have yielded impressive results for the task of machine reading comprehension (MRC), with approaches having been reported to achieve performance comparable to that of humans. In this paper, we investigate whether state-of-the-art MRC models are able to correctly process Semantics Altering Modifications (SAM): linguistically-motivated phenomena that alter the semantics of a sentence while preserving most of its lexical surface form. We present a method to automatically generate and align challenge sets featuring original and altered examples. We further propose a novel evaluation methodology to correctly assess the capability of MRC systems to process these examples independent of the data they were optimised on, by discounting for effects introduced by domain shift. In a large-scale empirical study, we apply the methodology in order to evaluate extractive MRC models with regard to their capability to correctly process SAM-enriched data. We comprehensively cover 12 different state-of-the-art neural architecture configurations and four training datasets and find that -- despite their well-known remarkable performance -- optimised models consistently struggle to correctly process semantically altered data.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Viktor Schlegel; Goran Nenadic; Riza Batista-Navarro",
        "authorids": "",
        "aff": "University of Manchester; University of Manchester; University of Manchester",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17622/17622-13-21116-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13762-semantics-altering-modifications-for-evaluating-comprehension-in-machine-reading/",
        "doi": "10.1609/aaai.v35i15.17622",
        "pdf_size": 142599
    },
    {
        "id": "14437",
        "title": "Semantics-Aware Inferential Network for Natural Language Understanding",
        "track": "main",
        "status": "Poster",
        "abstract": "For natural language understanding tasks, either machine reading comprehension or natural language inference, both semantics-aware and inference are favorable features of the concerned modeling for better understanding performance. Thus we propose a Semantics-Aware Inferential Network (SAIN) to meet such a motivation. Taking explicit contextualized semantics as a complementary input, the inferential module of SAIN enables a series of reasoning steps over semantic clues through an attention mechanism. By stringing these steps, the inferential network effectively learns to perform iterative reasoning which incorporates both explicit semantics and contextualized representations. In terms of well pre-trained language models as front-end encoder, our model achieves significant improvement on 11 tasks including machine reading comprehension and natural language inference.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Shuiliang Zhang; Hai Zhao; Junru Zhou; Xi Zhou; Xiang Zhou",
        "authorids": "",
        "aff": "Shanghai Jiao Tong University; Shanghai Jiao Tong University; Shanghai Jiao Tong University; CloudWalk Technology; CloudWalk Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17697/17697-13-21191-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14437-semantics-aware-inferential-network-for-natural-language-understanding/",
        "doi": "10.1609/aaai.v35i16.17697",
        "pdf_size": 639387
    },
    {
        "id": "09859",
        "title": "Semi-Supervised Knowledge Amalgamation for Sequence Classification",
        "track": "main",
        "status": "Poster",
        "abstract": "Sequence classification is essential for domains from medical diagnosis to online advertising. In these settings, data are typically proprietary, and annotations are expensive to acquire. Often times, so few annotations are available that training a robust model from scratch is impractical. Recently, knowledge amalgamation (KA) has emerged as a promising strategy for training models without this hard-to-come-by labeled training dataset. To achieve this, KA methods combine the knowledge of multiple pre-trained teacher models (trained on different classification tasks and proprietary datasets) into one student model that becomes an expert on the union of all teachers\u2019 classes. However, we demonstrate that the state-of-the-art solutions fail in the presence of overconfident teachers, which make confident but incorrect predictions for instances from classes upon which they were not trained. Additionally, to-date no work has explored KA for sequence models. Therefore, we propose and then solve the open problem of semi-supervised KA for sequence classification (SKA). Our SKA approach first learns to estimate how trustworthy each teacher is for a given instance, then rescales the predicted probabilities from all teachers to supervise a student model. Our solution overcomes overconfident teachers through careful use of a very small amount of labeled instances. We demonstrate that this approach beats eight state-of-the-art alternatives on four real-world datasets by on average 15% in accuracy with as little as 2% of training data being annotated.",
        "primary_area": "Machine Learning IV",
        "author": "Jidapa Thadajarassiri; Thomas Hartvigsen; Xiangnan Kong; Elke A Rundensteiner",
        "authorids": "",
        "aff": "Worcester Polytechnic Institute; Worcester Polytechnic Institute; Worcester Polytechnic Institute; Worcester Polytechnic Institute",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17185/17185-13-20679-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09859-semi-supervised-knowledge-amalgamation-for-sequence-classification/",
        "doi": "10.1609/aaai.v35i11.17185",
        "pdf_size": 4540127
    },
    {
        "id": "01882",
        "title": "Semi-Supervised Learning for Multi-Task Scene Understanding by Neural Graph Consensus",
        "track": "main",
        "status": "Poster",
        "abstract": "We address the challenging problem of semi-supervised learning in the context of multiple visual interpretations of the world by finding consensus in a graph of neural networks. Each graph node is a scene interpretation layer, while each edge is a deep net that transforms one layer at one node into another from a different node. During the supervised phase edge networks are trained independently. During the next unsupervised stage edge nets are trained on the pseudo-ground truth provided by consensus among multiple paths that reach the nets' start and end nodes. These paths act as ensemble teachers for any given edge and strong consensus is used for high-confidence supervisory signal. The unsupervised learning process is repeated over several generations, in which each edge becomes a \"student\" and also part of different ensemble \"teachers\" for training other students. By optimizing such consensus between different paths, the graph reaches consistency and robustness over multiple interpretations and generations, in the face of unknown labels. We give theoretical justifications of the proposed idea and validate it on a large dataset. We show how prediction of different representations such as depth, semantic segmentation, surface normals and pose from RGB input could be effectively learned through self-supervised consensus in our graph. We also compare to state-of-the-art methods for multi-task and semi-supervised learning and show superior performance.",
        "primary_area": "Computer Vision II",
        "author": "Marius Leordeanu; Mihai Cristian P\u00eervu; Dragos Costea; Alina E Marcu; Emil Slusanschi; Rahul Sukthankar",
        "authorids": "",
        "aff": "University \"Politehnica\" of Bucharest; University \"Politehnica\" of Bucharest; University \"Politehnica\" of Bucharest; University \"Politehnica\" of Bucharest; University \"Politehnica\" of Bucharest; Google",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16283/16283-13-19777-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01882-semi-supervised-learning-for-multi-task-scene-understanding-by-neural-graph-consensus/",
        "doi": "10.1609/aaai.v35i3.16283",
        "pdf_size": 11616492
    },
    {
        "id": "07236",
        "title": "Semi-Supervised Learning with Variational Bayesian Inference and Maximum Uncertainty Regularization",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose two generic methods for improving semi-supervised learning (SSL). The first integrates weight perturbation (WP) into existing \u201cconsistency regularization\u201d (CR) based methods. We implement WP by leveraging variational Bayesian inference (VBI). The second method proposes a novel consistency loss called \u201cmaximum uncertainty regularization\u201d (MUR). While most consistency losses act on perturbations in the vicinity of each data point, MUR actively searches for \u201cvirtual\u201d points situated beyond this region that cause the most uncertain class predictions. This allows MUR to impose smoothness on a wider area in the input-output manifold. Our experiments show clear improvements in classification errors of various CR based methods when they are combined with VBI or MUR or both.",
        "primary_area": "Machine Learning I",
        "author": "Kien Do; Truyen Tran; Svetha Venkatesh",
        "authorids": "",
        "aff": "Deakin University; Deakin University; Deakin University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16889/16889-13-20383-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07236-semi-supervised-learning-with-variational-bayesian-inference-and-maximum-uncertainty-regularization/",
        "doi": "10.1609/aaai.v35i8.16889",
        "pdf_size": 869262
    },
    {
        "id": "07279",
        "title": "Semi-Supervised Metric Learning: A Deep Resurrection",
        "track": "main",
        "status": "Poster",
        "abstract": "Distance Metric Learning (DML) seeks to learn a discriminative embedding where similar examples are closer, and dissimilar examples are apart. In this paper, we address the problem of Semi-Supervised DML (SSDML) that tries to learn a metric using a few labeled examples, and abundantly available unlabeled examples. SSDML is important because it is infeasible to manually annotate all the examples present in a large dataset. Surprisingly, with the exception of a few classical approaches that learn a linear Mahalanobis metric, SSDML has not been studied in the recent years, and lacks approaches in the deep SSDML scenario. In this paper, we address this challenging problem, and revamp SSDML with respect to deep learning. In particular, we propose a stochastic, graph-based approach that first propagates the affinities between the pairs of examples from labeled data, to that of the unlabeled pairs. The propagated affinities are used to mine triplet based constraints for metric learning. We impose orthogonality constraint on the metric parameters, as it leads to a better performance by avoiding a model collapse.",
        "primary_area": "Machine Learning I",
        "author": "Ujjal Kr Dutta; Mehrtash Harandi; C Chandra Shekhar",
        "authorids": "",
        "aff": "Data Sciences, Myntra Indian Institute of Technology Madras (IIT Madras); Monash University; Indian Institute of Technology Madras (IIT Madras)",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16894/16894-13-20388-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07279-semi-supervised-metric-learning-a-deep-resurrection/",
        "doi": "10.1609/aaai.v35i8.16894",
        "pdf_size": 607901
    },
    {
        "id": "10093",
        "title": "Semi-Supervised Node Classification on Graphs: Markov Random Fields vs. Graph Neural Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Semi-supervised node classification on graph-structured data has many applications such as fraud detection, fake account and review detection, user\u2019s private attribute inference in social networks, and community detection.  Various methods such as pairwise Markov Random Fields (pMRF) and graph neural networks were developed for semi-supervised node classification.    pMRF is more efficient than graph neural networks. However, existing pMRF-based methods are less accurate than graph neural networks, due to a key limitation that they assume a heuristics-based constant edge potential for all edges. In this work, we aim to address the key limitation of existing pMRF-based methods. In particular, we propose to learn edge potentials for pMRF.  Our evaluation results on   various types of graph datasets show that our optimized pMRF-based method consistently outperforms existing graph neural networks in terms of both accuracy and efficiency. Our results highlight that previous work may have underestimated the power of pMRF for semi-supervised node classification.",
        "primary_area": "Machine Learning IV",
        "author": "Binghui Wang; Jinyuan Jia; Neil Zhenqiang Gong",
        "authorids": "",
        "aff": "Duke University; Duke University; Duke University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17211/17211-13-20705-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10093-semi-supervised-node-classification-on-graphs-markov-random-fields-vs-graph-neural-networks/",
        "doi": "10.1609/aaai.v35i11.17211",
        "pdf_size": 920833
    },
    {
        "id": "08801",
        "title": "Semi-supervised Medical Image Segmentation through Dual-task Consistency",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep learning-based semi-supervised learning (SSL) algorithms have led to promising results in medical images segmentation and can alleviate doctors' expensive  annotations by leveraging unlabeled data. However, most of the existing SSL algorithms in literature tend to  regularize  the  model training by perturbing networks and/or data. Observing that multi/dual-task learning attends to various levels of information which have inherent prediction perturbation, we ask the question in this work: can we explicitly build task-level regularization rather than implicitly constructing networks- and/or data-level perturbation and then regularization for SSL? To answer this question, we propose a novel dual-task-consistency semi-supervised framework for the first time. Concretely, we use a dual-task deep network that jointly predicts a pixel-wise segmentation map and a geometry-aware level set representation of the target. The level set representation is converted to an approximated segmentation map through a differentiable task transform layer. Simultaneously, we introduce a dual-task consistency regularization between the level set-derived segmentation maps and directly predicted segmentation maps for both labeled and unlabeled data. Extensive experiments on two public datasets show that our method can largely improve the performance by incorporating the unlabeled data. Meanwhile, our framework outperforms the state-of-the-art semi-supervised learning methods.",
        "primary_area": "Machine Learning III",
        "author": "Xiangde Luo; Jieneng Chen; Tao Song; Guotai Wang",
        "authorids": "",
        "aff": "University of Electronic Science and Technology of China SenseTime Research; Tongji University; SenseTime Research; University of Electronic Science and Technology of China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17066/17066-13-20560-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08801-semi-supervised-medical-image-segmentation-through-dual-task-consistency/",
        "doi": "10.1609/aaai.v35i10.17066",
        "pdf_size": 1474347
    },
    {
        "id": "06574",
        "title": "Semi-supervised Sequence Classification through Change Point Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Sequential sensor data is generated in a wide variety of real-world applications. A fundamental machine learning challenge involves learning effective classifiers for such sequential data. While deep learning has led to impressive performance gains in recent years within domains such as speech, this has relied on the availability of large datasets of sequences with high-quality labels. In many applications, however, the associated class labels are often extremely limited, with precise labelling/segmentation being too expensive to perform in a high volume. However, large amounts of unlabelled data may still be available.  In this paper we propose a novel framework for semi-supervised learning in such contexts. In an unsupervised manner, change-point detection methods can be used to identify instances where classes change within in a sequence.  We show that change points provide examples of similar/dissimilar pairs of sequences which, when coupled with class labels, can be used in a semi-supervised classification setting. Pairs from labels and change points are used by a neural network to learn improved representations for classification. We provide extensive synthetic simulations and show that the learned representations are better than those learned through an autoencoder and obtain improved results on simulations and human activity recognition datasets.",
        "primary_area": "Machine Learning I",
        "author": "Nauman Ahad; Mark A. Davenport",
        "authorids": "",
        "aff": "Georgia Institute of Technology; Georgia Institute of Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16814/16814-13-20308-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06574-semi-supervised-sequence-classification-through-change-point-detection/",
        "doi": "10.1609/aaai.v35i8.16814",
        "pdf_size": 524466
    },
    {
        "id": "08865",
        "title": "Sequential Attacks on Kalman Filter-based Forward Collision Warning Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "Kalman Filter (KF) is widely used in various domains to perform sequential learning or variable estimation. In the context of autonomous vehicles, KF constitutes the core component of many Advanced Driver Assistance Systems (ADAS), such as Forward Collision Warning (FCW). It tracks the states (distance, velocity etc.) of relevant traffic objects based on sensor measurements. The tracking output of KF is often fed into downstream logic to produce alerts, which will then be used by human drivers to make driving decisions in near-collision scenarios. In this paper, we study adversarial attacks on KF as part of the more complex machine-human hybrid system of Forward Collision Warning. Our attack goal is to negatively affect human braking decisions by causing KF to output incorrect state estimations that lead to false or delayed alerts. We accomplish this by sequentially manipulating measure ments fed into the KF, and propose a novel Model Predictive Control (MPC) approach to compute the optimal manipulation. Via experiments conducted in a simulated driving environment, we show that the attacker is able to successfully change FCW alert signals through planned manipulation over measurements prior to the desired target time. These results demonstrate that our attack can stealthily mislead a distracted human driver and cause vehicle collisions.",
        "primary_area": "Machine Learning III",
        "author": "Yuzhe Ma; Jon A Sharp; Ruizhe Wang; Earlence Fernandes; Xiaojin Zhu",
        "authorids": "",
        "aff": "University of Wisconsin-Madison; University of Wisconsin- Madison; University of Wisconsin-Madison; University of Wisconsin-Madison; University of Wisconsin-Madison",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17073/17073-13-20567-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08865-sequential-attacks-on-kalman-filter-based-forward-collision-warning-systems/",
        "doi": "10.1609/aaai.v35i10.17073",
        "pdf_size": 1656653
    },
    {
        "id": "02011",
        "title": "Sequential End-to-end Network for Efficient Person Search",
        "track": "main",
        "status": "Poster",
        "abstract": "Person search aims at jointly solving Person Detection and Person Re-identification (re-ID). Existing works have designed end-to-end networks based on Faster R-CNN. However, due to the parallel structure of Faster R-CNN, the extracted features come from the low-quality proposals generated by the Region Proposal Network, rather than the detected high-quality bounding boxes. Person search is a fine-grained task and such inferior features will significantly reduce re-ID performance. To address this issue, we propose a Sequential End-to-end Network (SeqNet) to extract superior features. In SeqNet, detection and re-ID are considered as a progressive process and tackled with two sub-networks sequentially. In addition, we design a robust Context Bipartite Graph Matching (CBGM) algorithm to effectively employ context information as an important complementary cue for person matching. Extensive experiments on two widely used person search benchmarks, CUHK-SYSU and PRW, have shown that our method achieves state-of-the-art results. Also, our model runs at 11.5 fps on a single GPU and can be integrated into the existing end-to-end framework easily.",
        "primary_area": "Computer Vision II",
        "author": "Zhengjia Li; Duoqian Miao",
        "authorids": "",
        "aff": "Department of Computer Science and Technology, Tongji University, Shanghai 201804, China Key Laboratory of Embedded System and Service Computing, Ministry of Education, Shanghai 201804, China; Department of Computer Science and Technology, Tongji University, Shanghai 201804, China Key Laboratory of Embedded System and Service Computing, Ministry of Education, Shanghai 201804, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16297/16297-13-19791-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02011-sequential-end-to-end-network-for-efficient-person-search/",
        "doi": "10.1609/aaai.v35i3.16297",
        "pdf_size": 482450
    },
    {
        "id": "10700",
        "title": "Sequential Generative Exploration Model for Partially Observable Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Many challenging partially observable reinforcement learning problems have sparse rewards and most existing model-free algorithms struggle with such reward sparsity. In this paper, we propose a novel reward shaping approach to infer the intrinsic rewards for the agent from a sequential generative model. Specifically, the sequential generative model processes a sequence of partial observations and actions from the agent's historical transitions to compile a belief state for performing forward dynamics prediction. Then we utilize the error of the dynamics prediction task to infer the intrinsic rewards for the agent. Our proposed method is able to derive intrinsic rewards that could better reflect the agent's surprise or curiosity over its ground-truth state by taking a sequential inference procedure. Furthermore, we formulate the inference procedure for dynamics prediction as a multi-step forward prediction task, where the time abstraction that has been incorporated could effectively help to increase the expressiveness of the intrinsic reward signals. To evaluate our method, we conduct extensive experiments on challenging 3D navigation tasks in ViZDoom and DeepMind Lab. Empirical evaluation results show that our proposed exploration method could lead to significantly faster convergence than various state-of-the-art exploration approaches in the testified navigation domains.",
        "primary_area": "Machine Learning V",
        "author": "Haiyan Yin; Jianda Chen; Sinno Jialin Pan; Sebastian Tschiatschek",
        "authorids": "",
        "aff": "Nanyang Technological University, Singapore; Nanyang Technological University, Singapore; Nanyang Technological University, Singapore; University of Vienna, Austria",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17279/17279-13-20773-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10700-sequential-generative-exploration-model-for-partially-observable-reinforcement-learning/",
        "doi": "10.1609/aaai.v35i12.17279",
        "pdf_size": 1446841
    },
    {
        "id": "02978",
        "title": "Shape-Pose Ambiguity in Learning 3D Reconstruction from Images",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning single-image 3D reconstruction with only 2D images supervision is a promising research topic. The main challenge in image-supervised 3D reconstruction is the shape-pose ambiguity, which means a 2D supervision can be explained by an erroneous 3D shape from an erroneous pose. It will introduce high uncertainty and mislead the learning process. Existed works rely on multi-view images or pose-aware annotations to resolve the ambiguity. In this paper, we propose to resolve the ambiguity without extra pose-aware labels or annotations. Our training data is single-view images from the same object category. To overcome the shape-pose ambiguity, we introduce a pose-independent GAN to learn the category-specific shape manifold from the image collections. With the learned shape space, we resolve the shape-pose ambiguity in original images by training a pseudo pose regressor. Finally, we learn a reconstruction network with both the common re-projection loss and a pose-independent discrimination loss, making the results plausible from all views. Through experiments on synthetic and real image datasets, we demonstrate that our method can perform comparably to existing methods while not requiring any extra pose-aware annotations, making it more applicable and adaptable.",
        "primary_area": "Computer Vision III",
        "author": "Yunjie Wu; Zhengxing Sun; Youcheng Song; Yunhan Sun; YiJie Zhong; Jinlong Shi",
        "authorids": "",
        "aff": "Nanjing University; Nanjing University; Nanjing University; Nanjing University; Nanjing University; Jiangsu University of Science and Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16405/16405-13-19899-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02978-shape-pose-ambiguity-in-learning-3d-reconstruction-from-images/",
        "doi": "10.1609/aaai.v35i4.16405",
        "pdf_size": 3750132
    },
    {
        "id": "08375",
        "title": "ShapeNet: A Shapelet-Neural Network Approach for Multivariate Time Series Classification",
        "track": "main",
        "status": "Poster",
        "abstract": "Time series shapelets are short discriminative subsequences that recently have been found not only to be accurate but also interpretable for the classification problem of univariate time series (UTS). However, existing work on shapelets selection cannot be applied to multivariate time series classification (MTSC) since the candidate shapelets of MTSC may come from different variables of different lengths and thus cannot be directly compared. To address this challenge, in this paper, we propose a novel model called ShapeNet, which embeds shapelet candidates of different lengths into a unified space for shapelet selection. The network is trained using cluster-wise triplet loss, which considers the distance between anchor and multiple positive (negative) samples and the distance between positive (negative) samples, which are important for convergence. We compute representative and diversified final shapelets rather than directly using all the embeddings for model building to avoid a large fraction of non-discriminative shapelet candidates. We have conducted experiments on ShapeNet with competitive state-of-the-art and benchmark methods using UEA MTS datasets. The results show that the accuracy of ShapeNet is the best of all the methods compared. Furthermore, we illustrate the shapelets\u2019 interpretability with two case studies.",
        "primary_area": "Machine Learning II",
        "author": "Guozhong Li; Byron Choi; Jianliang Xu; Sourav S Bhowmick; Kwok-Pan Chun; Grace Lai-Hung Wong",
        "authorids": "",
        "aff": "Department of Computer Science, Hong Kong Baptist University, Hong Kong; Department of Computer Science, Hong Kong Baptist University, Hong Kong; Department of Computer Science, Hong Kong Baptist University, Hong Kong; School of Computing Engineering, Nanyang Technological University, Singapore; Department of Geography, Hong Kong Baptist University, Hong Kong; Faculty of Medicine, The Chinese University of Hong Kong, Hong Kong",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17018/17018-13-20512-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08375-shapenet-a-shapelet-neural-network-approach-for-multivariate-time-series-classification/",
        "doi": "10.1609/aaai.v35i9.17018",
        "pdf_size": 1676217
    },
    {
        "id": "12989",
        "title": "Show Me How To Revise: Improving Lexically Constrained Sentence Generation with XLNet",
        "track": "main",
        "status": "Poster",
        "abstract": "Lexically constrained sentence generation allows the incorporation of prior knowledge such as lexical constraints into the output. This technique has been applied to machine translation, and dialog response generation. Previous work usually used Markov Chain Monte Carlo (MCMC) sampling to generate lexically constrained sentences, but they randomly determined the position to be edited and the action to be taken, resulting in many invalid refinements. To overcome this challenge, we used a classifier to instruct the MCMC-based models where and how to refine the candidate sentences. First, we developed two methods to create synthetic data on which the pre-trained model is fine-tuned to obtain a reliable classifier. Next, we proposed a two-step approach, \u201cPredict and Revise\u201d, for constrained sentence generation. During the predict step, we leveraged the classifier to compute the learned prior for the candidate sentence. During the revise step, we resorted to MCMC sampling to revise the candidate sentence by conducting a sampled action at a sampled position drawn from the learned prior. We compared our proposed models with many strong baselines on two tasks, generating sentences with lexical constraints and text infilling. Experimental results have demonstrated that our proposed model performs much better than the previous work in terms of sentence fluency and diversity. Our code, pre-trained models and Appendix are available at https://github.com/NLPCode/MCMCXLNet.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Xingwei He; Victor O.K. Li",
        "authorids": "",
        "aff": "The University of Hong Kong; The University of Hong Kong",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17536/17536-13-21030-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12989-show-me-how-to-revise-improving-lexically-constrained-sentence-generation-with-xlnet/",
        "doi": "10.1609/aaai.v35i14.17536",
        "pdf_size": 1336360
    },
    {
        "id": "07945",
        "title": "Show, Attend and Distill: Knowledge Distillation via Attention-based Feature Matching",
        "track": "main",
        "status": "Poster",
        "abstract": "Knowledge distillation extracts general knowledge from a pretrained teacher network and provides guidance to a target student network. Most studies manually tie intermediate features of the teacher and student, and transfer knowledge through predefined links. However, manual selection often constructs ineffective links that limit the improvement from the distillation. There has been an attempt to address the problem, but it is still challenging to identify effective links under practical scenarios. In this paper, we introduce an effective and efficient feature distillation method utilizing all the feature levels of the teacher without manually selecting the links. Specifically, our method utilizes an attention based meta network that learns relative similarities between features, and applies identified similarities to control distillation intensities of all possible pairs. As a result, our method determines competent links more efficiently than the previous approach and provides better performance on model compression and transfer learning tasks. Further qualitative analyses and ablative studies describe how our method contributes to better distillation.",
        "primary_area": "Machine Learning II",
        "author": "Mingi Ji; Byeongho Heo; Sungrae Park",
        "authorids": "",
        "aff": "KAIST; NAVER AI LAB; Upstage AI Research, Upstage AI",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16969/16969-13-20463-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07945-show-attend-and-distill-knowledge-distillation-via-attention-based-feature-matching/",
        "doi": "10.1609/aaai.v35i9.16969",
        "pdf_size": 806583
    },
    {
        "id": "09428",
        "title": "Shuffling Recurrent Neural Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a novel recurrent neural network model, where the hidden state h\u209c is obtained by permuting the vector elements of the previous hidden state h\u209c\u208b\u2081 and adding the output of a learned function \u03b2(x\u209c) of the input x\u209c at time t. In our model, the prediction is given by a second learned function, which is applied to the hidden state s(h\u209c). The method is easy to implement, extremely efficient, and does not suffer from vanishing nor exploding gradients. In an extensive set of experiments, the method shows competitive results, in comparison to the leading literature baselines.  We share our implementation at https://github.com/rotmanmi/SRNN.",
        "primary_area": "Machine Learning IV",
        "author": "Michael Rotman; Lior Wolf",
        "authorids": "",
        "aff": "Tel Aviv University, Israel; Tel Aviv University, Israel",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17136/17136-13-20630-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09428-shuffling-recurrent-neural-networks/",
        "doi": "10.1609/aaai.v35i11.17136",
        "pdf_size": 1472474
    },
    {
        "id": "05252",
        "title": "Signaling in Bayesian Network Congestion Games: the Subtle Power of Symmetry",
        "track": "main",
        "status": "Poster",
        "abstract": "Network congestion games are a well-understood model of multi-agent strategic interactions. Despite their ubiquitous applications, it is not clear whether it is possible to design information structures to ameliorate the overall experience of the network users. We focus on Bayesian games with atomic players, where network vagaries are modeled via a (random) state of nature which determines the costs incurred by the players. A third-party entity\u2014the sender\u2014can observe the realized state of the network and exploit this additional information to send a signal to each player. A natural question is the following: is it possible for an informed sender to reduce the overall social cost via the strategic provision of information to players who update their beliefs rationally? The paper focuses on the problem of computing optimal ex ante persuasive signaling schemes, showing that symmetry is a crucial property for its solution. Indeed, we show that an optimal ex ante persuasive signaling scheme can be computed in polynomial time when players are symmetric and have affine cost functions. Moreover, the problem becomes NP-hard when players are asymmetric, even in non-Bayesian settings.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Matteo Castiglioni; Andrea Celli; Alberto Marchesi; Nicola Gatti",
        "authorids": "",
        "aff": "Politecnico di Milano; Politecnico di Milano; Politecnico di Milano; Politecnico di Milano",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16663/16663-13-20157-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05252-signaling-in-bayesian-network-congestion-games-the-subtle-power-of-symmetry/",
        "doi": "10.1609/aaai.v35i6.16663",
        "pdf_size": 1259889
    },
    {
        "id": "01218",
        "title": "Similarity Reasoning and Filtration for Image-Text Matching",
        "track": "main",
        "status": "Poster",
        "abstract": "Image-text matching plays a critical role in bridging the vision and language, and great progress has been made by exploiting the global alignment between image and sentence, or local alignments between regions and words. However, how to make the most of these alignments to infer more accurate matching scores is still underexplored. In this paper, we propose a novel Similarity Graph Reasoning and Attention Filtration (SGRAF) network for image-text matching. Specifically, the vector-based similarity representations are firstly learned to characterize the local and global alignments in a more comprehensive manner, and then the Similarity Graph Reasoning (SGR) module relying on one graph convolutional neural network is introduced to infer relation-aware similarities with both the local and global alignments. The Similarity Attention Filtration (SAF) module is further developed to integrate these alignments effectively by selectively attending on the significant and representative alignments and meanwhile casting aside the interferences of non-meaningful alignments. We demonstrate the superiority of the proposed method with achieving state-of-the-art performances on the Flickr30K and MSCOCO datasets, and the good interpretability of SGR and SAF with extensive qualitative experiments and analyses.",
        "primary_area": "Computer Vision I",
        "author": "Haiwen Diao; Ying Zhang; Lin Ma; Huchuan Lu",
        "authorids": "",
        "aff": "Dalian university of Technology; Tencent AI Lab; Meituan; Dalian University of Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16209/16209-13-19703-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01218-similarity-reasoning-and-filtration-for-image-text-matching/",
        "doi": "10.1609/aaai.v35i2.16209",
        "pdf_size": 518882
    },
    {
        "id": "03252",
        "title": "Simple and Effective Stochastic Neural Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Stochastic neural networks (SNNs) are currently topical, with several paradigms being actively investigated including dropout, Bayesian neural networks, variational information bottleneck (VIB) and noise regularized learning. These neural network variants impact several major considerations, including generalization, network compression, robustness against adversarial attack and label noise, and model calibration. However, many existing networks are complicated and expensive to train, and/or only address one or two of these practical considerations. In this paper we propose a simple and effective stochastic neural network (SE-SNN) architecture for discriminative learning by directly modeling activation uncertainty and encouraging high activation variability. Compared to existing SNNs, our SE-SNN is simpler to implement and faster to train, and produces state of the art results on network compression by pruning,  adversarial defense, learning with label noise, and model calibration.",
        "primary_area": "Computer Vision III",
        "author": "Tianyuan Yu; Yongxin Yang; Da Li; Timothy Hospedales; Tao Xiang",
        "authorids": "",
        "aff": "University of Surrey; University of Surrey; University of Edinburgh Samsung AI Centre; University of Edinburgh Samsung AI Centre; University of Surrey",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16436/16436-13-19930-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03252-simple-and-effective-stochastic-neural-networks/",
        "doi": "10.1609/aaai.v35i4.16436",
        "pdf_size": 352223
    },
    {
        "id": "03608",
        "title": "Simple is not Easy: A Simple Strong Baseline for TextVQA and TextCaps",
        "track": "main",
        "status": "Poster",
        "abstract": "Texts appearing in daily scenes that can be recognized by OCR (Optical Character Recognition) tools contain significant information, such as street name, product brand and prices. Two tasks -- text-based visual question answering and text-based image captioning, with a text extension from existing vision-language applications, are catching on rapidly.  To address these problems, many sophisticated multi-modality encoding frameworks (such as heterogeneous graph structure) are being used. In this paper, we argue that a simple attention mechanism can do the same or even better job without any bells and whistles. Under this mechanism, we simply split OCR token features into separate visual- and linguistic-attention branches, and send them to a popular Transformer decoder to generate answers or captions. Surprisingly, we find this simple baseline model is rather strong -- it consistently outperforms state-of-the-art (SOTA) models on two popular benchmarks, TextVQA and all three tasks of ST-VQA, although these SOTA models use far more complex encoding mechanisms. Transferring it to text-based image captioning, we also surpass the TextCaps Challenge 2020 winner. We wish this work to set the new baseline for these two OCR text related applications and to inspire  new thinking of multi-modality encoder design. Code is available at https://github.com/ZephyrZhuQi/ssbaseline",
        "primary_area": "Computer Vision III",
        "author": "Qi Zhu; Chenyu Gao; Peng Wang; Qi Wu",
        "authorids": "",
        "aff": "Northwestern Polytechnical University; Northwestern Polytechnical University; Northwestern Polytechnical University; University of Adelaide",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16476/16476-13-19970-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03608-simple-is-not-easy-a-simple-strong-baseline-for-textvqa-and-textcaps/",
        "doi": "10.1609/aaai.v35i4.16476",
        "pdf_size": 5392047
    },
    {
        "id": "12621",
        "title": "Simple or Complex? Learning to Predict Readability of Bengali Texts",
        "track": "main",
        "status": "Poster",
        "abstract": "Determining the readability of a text is the first step to its simplification. In this paper, we present a readability analysis tool capable of analyzing text written in the Bengali language to provide in-depth information on its readability and complexity. Despite being the 7th most spoken language in the world with 230 million native speakers, Bengali suffers from a lack of fundamental resources for natural language processing. Readability related research of the Bengali language so far can be considered to be narrow and sometimes faulty due to the lack of resources. Therefore, we correctly adopt document-level readability formulas traditionally used for U.S. based education system to the Bengali language with a proper age-to-age comparison. Due to the unavailability of large-scale human-annotated corpora, we further divide the document-level task into sentence-level and experiment with neural architectures, which will serve as a baseline for the future works of Bengali readability prediction. During the process, we present several human-annotated corpora and dictionaries such as a document-level dataset comprising 618 documents with 12 different grade levels, a large-scale sentence-level dataset comprising more than 96K sentences with simple and complex labels, a consonant conjunct count algorithm and a corpus of 341 words to validate the effectiveness of the algorithm, a list of 3,396 easy words, and an updated pronunciation dictionary with more than 67K words. These resources can be useful for several other tasks of this low-resource language.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Susmoy Chakraborty; Mir Tafseer Nayeem; Wasi Uddin Ahmad",
        "authorids": "",
        "aff": "Ahsanullah University of Science and Technology; Ahsanullah University of Science and Technology; University of California, Los Angeles",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17495/17495-13-20989-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12621-simple-or-complex-learning-to-predict-readability-of-bengali-texts/",
        "doi": "10.1609/aaai.v35i14.17495",
        "pdf_size": 497047
    },
    {
        "id": "14276",
        "title": "Simpson\u2019s Bias in NLP Training",
        "track": "main",
        "status": "Poster",
        "abstract": "In most machine learning tasks, we evaluate a model M on a given data population S by measuring a population-level metric F(S;M). Examples of such evaluation metric F include precision/recall for (binary) recognition, the F1 score for multi-class classification, and the BLEU metric for language generation. On the other hand, the model M is trained by optimizing a sample-level loss G(S_t; M) at each learning step t, where S_t is a subset of S (a.k.a. the mini-batch). Popular choices of G include cross-entropy loss, the Dice loss, and sentence-level BLEU scores. A fundamental assumption behind this paradigm is that the mean value of the sample-level loss G, if averaged over all possible samples, should effectively represent the population-level metric F of the task, such as, that E[ G(S_t; M) ] ~ F(S; M).    In this paper, we systematically investigate the above assumption in several NLP tasks. We show, both theoretically and experimentally, that some popular designs of the sample-level loss G may be inconsistent with the true population-level metric F of the task, so that models trained to optimize the former can be substantially sub-optimal to the latter, a phenomenon we call it, Simpson's bias, due to its deep connections with the classic paradox known as Simpson's reversal paradox in statistics and social sciences.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Fei Yuan; Longtu Zhang; Huang Bojun; Yaobo Liang",
        "authorids": "",
        "aff": "University of Electronic Science and Technology of China; Rakuten Institute of Technology, Rakuten, Inc.; Rakuten Institute of Technology, Rakuten, Inc.; Microsoft Research Asia",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17679/17679-13-21173-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14276-simpson-s-bias-in-nlp-training/",
        "doi": "10.1609/aaai.v35i16.17679",
        "pdf_size": 1977247
    },
    {
        "id": "05391",
        "title": "Simultaneous 2nd Price Item Auctions with No-Underbidding",
        "track": "main",
        "status": "Poster",
        "abstract": "We study the price of anarchy (PoA) of simultaneous 2nd price auctions (S2PA) under a new natural condition of no underbidding, meaning that agents never bid on items less than their marginal values. We establish improved (mostly tight) bounds on the PoA of S2PA under no underbidding for different valuation classes (including unit demand, submodular, XOS, subadditive, and general monotone valuations), in both full information and incomplete information settings.   To derive our results, we introduce a new parameterized property of auctions, termed (gamma,delta) revenue guaranteed, which implies a PoA of at least gamma/(1+delta).  Via extension theorems, this guarantee extends to coarse correlated equilibria (CCE) in full information settings, and to Bayesian PoA (BPoA) in settings with incomplete information and arbitrary (correlated) distributions. We then show that S2PA are (1,1) revenue guaranteed with respect to bids satisfying no underbidding.  This implies a PoA of at least 1/2 for general monotone valuation, which extends to BPOA with arbitrary correlated distributions. Moreover, we show that (lambda,mu) smoothness combined with (gamma,delta) revenue guaranteed guarantees a PoA of at least (gamma+lambda)/(1+delta+mu). This implies a host of results, such as a tight PoA of 2/3 for S2PA with submodular (or XOS) valuations, under no overbidding and no underbidding. Beyond establishing improved bounds for S2PA, the no underbidding assumption sheds new light on the performance of S2PA relative to  simultaneous 1st price auctions.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Michal Feldman; Galia Shabtai",
        "authorids": "",
        "aff": "Tel Aviv University; Tel Aviv University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16679/16679-13-20173-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05391-simultaneous-2nd-price-item-auctions-with-no-underbidding/",
        "doi": "10.1609/aaai.v35i6.16679",
        "pdf_size": 181583
    },
    {
        "id": "12373",
        "title": "Single Player Monte-Carlo Tree Search Based on the Plackett-Luce Model",
        "track": "main",
        "status": "Poster",
        "abstract": "The problem of minimal cost path search is especially difficult when no useful heuristics are available. A common solution is roll-out-based search like Monte Carlo Tree Search (MCTS). However, MCTS is mostly used in stochastic or adversarial environments, with the goal to identify an agent's best next move. For this reason, even though single player versions of MCTS exist, most algorithms, including UCT, are not directly tailored to classical minimal cost path search. We present Plackett-Luce MCTS (PL-MCTS), a path search algorithm based on a probabilistic model over the qualities of successor nodes. We empirically show that PL-MCTS is competitive and often superior to the state of the art.",
        "primary_area": "Search and Optimization",
        "author": "Felix Mohr; Viktor Bengs; Eyke H\u00fcllermeier",
        "authorids": "",
        "aff": "Universidad de La Sabana, Ch\u00eda, Colombia; Paderborn University, Germany; Paderborn University, Germany",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17468/17468-13-20962-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12373-single-player-monte-carlo-tree-search-based-on-the-plackett-luce-model/",
        "doi": "10.1609/aaai.v35i14.17468",
        "pdf_size": 166717
    },
    {
        "id": "02064",
        "title": "Single View Point Cloud Generation via Unified 3D Prototype",
        "track": "main",
        "status": "Poster",
        "abstract": "As 3D point clouds become the representation of choice for multiple vision and graphics applications, such as autonomous driving, robotics, etc., the generation of them by deep neural networks has attracted increasing attention in the research community. Despite the recent success of deep learning models in classification and segmentation, synthesizing point clouds remains challenging, especially from a single image. State-of-the-art (SOTA) approaches can generate a point cloud from a hidden vector, however, they treat 2D and 3D features equally and disregard the rich shape information within the 3D data. In this paper, we address this problem by integrating image features with 3D prototype features. Specifically, we propose to learn a set of 3D prototype features from a real point cloud dataset and dynamically adjust them through the training. These prototypes are then integrated with incoming image features to guide the point cloud generation process. Experimental results show that our proposed method outperforms SOTA methods on single image based 3D reconstruction tasks.",
        "primary_area": "Computer Vision II",
        "author": "Yu Lin; Yigong Wang; Yi-Fan Li; Zhuoyi Wang; Yang Gao; Latifur Khan",
        "authorids": "",
        "aff": "University of Texas at Dallas; University of Texas at Dallas; University of Texas at Dallas; University of Texas at Dallas; University of Texas at Dallas; University of Texas at Dallas",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16303/16303-13-19797-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02064-single-view-point-cloud-generation-via-unified-3d-prototype/",
        "doi": "10.1609/aaai.v35i3.16303",
        "pdf_size": 1380050
    },
    {
        "id": "00609",
        "title": "Sketch Generation with Drawing Process Guided by Vector Flow and Grayscale",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a novel image-to-pencil translation method that could not only generate high-quality pencil sketches but also offer the drawing process. Existing pencil sketch algorithms are based on texture rendering rather than the direct imitation of strokes, making them unable to show the drawing process but only a final result. To address this challenge, we first establish a pencil stroke imitation mechanism. Next, we develop a framework with three branches to guide stroke drawing: the first branch guides the direction of the strokes, the second branch determines the shade of the strokes, and the third branch enhances the details further. Under this framework's guidance, we can produce a pencil sketch by drawing one stroke every time. Our method is fully interpretable. Comparison with existing pencil drawing algorithms shows that our method is superior to others in terms of texture quality, style, and user evaluation. Our code and supplementary material are now available at: https://github.com/TZYSJTU/Sketch-Generation-withDrawing-Process-Guided-by-Vector-Flow-and-Grayscale",
        "primary_area": "Application Domains",
        "author": "Zhengyan Tong; Xuanhong Chen; Bingbing Ni; Xiaohang Wang",
        "authorids": "",
        "aff": "Shanghai Jiao Tong University; Shanghai Jiao Tong University Huawei Hisilicon; Shanghai Jiao Tong University Huawei Hisilicon; Shanghai Jiao Tong University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16140/16140-13-19634-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00609-sketch-generation-with-drawing-process-guided-by-vector-flow-and-grayscale/",
        "doi": "10.1609/aaai.v35i1.16140",
        "pdf_size": 4321370
    },
    {
        "id": "12955",
        "title": "Sketch and Customize: A Counterfactual Story Generator",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent text generation models are easy to generate relevant and fluent text for the given text, while lack of causal reasoning ability when we change some parts of the given text. Counterfactual story rewriting is a recently proposed task to test the causal reasoning ability for text generation models, which requires a model to predict the corresponding story ending when the condition is modified to a counterfactual one. Previous works have shown that the traditional sequence-to-sequence model cannot well handle this problem, as it often captures some spurious correlations between the original and counterfactual endings, instead of the causal relations between conditions and endings. To address this issue, we propose a sketch-and-customize generation model guided by the causality implicated in the conditions and endings. In the sketch stage, a skeleton is extracted by removing words which are conflict to the counterfactual condition, from the original ending. In the customize stage, a generation model is used to fill proper words in the skeleton under the guidance of the counterfactual condition. In this way, the obtained counterfactual ending is both relevant to the original ending and consistent with the counterfactual condition. Experimental results show that the proposed model generates much better endings, as compared with the traditional sequence-to-sequence model.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Changying Hao; Liang Pang; Yanyan Lan; Yan Wang; Jiafeng Guo; Xueqi Cheng",
        "authorids": "",
        "aff": "Institute of Computing Technology, Chinese Academy of Sciences; Institute of Computing Technology, Chinese Academy of Sciences; Institute of Computing Technology, Chinese Academy of Sciences; Tencent AI Lab; Institute of Computing Technology, Chinese Academy of Sciences; Institute of Computing Technology, Chinese Academy of Sciences",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17532/17532-13-21026-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12955-sketch-and-customize-a-counterfactual-story-generator/",
        "doi": "10.1609/aaai.v35i14.17532",
        "pdf_size": 262579
    },
    {
        "id": "07746",
        "title": "Slimmable Generative Adversarial Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Generative adversarial networks (GANs) have achieved remarkable progress in recent years, but the continuously growing scale of models make them challenging to deploy widely in practical applications. In particular, for real-time generation tasks, different devices require generators of different sizes due to varying computing power. In this paper, we introduce slimmable GANs (SlimGANs), which can flexibly switch the width of the generator to accommodate various quality-efficiency trade-offs at runtime. Specifically, we leverage multiple discriminators that share partial parameters to train the slimmable generator. To facilitate the consistency between generators of different widths, we present a stepwise inplace distillation technique that encourages narrow generators to learn from wide ones. As for class-conditional generation, we propose a sliceable conditional batch normalization that incorporates the label information into different widths. Our methods are validated, both quantitatively and qualitatively, by extensive experiments and a detailed ablation study.",
        "primary_area": "Machine Learning II",
        "author": "Liang Hou; Zehuan Yuan; Lei Huang; Huawei Shen; Xueqi Cheng; Changhu Wang",
        "authorids": "",
        "aff": "CAS Key Laboratory of Network Data Science and Technology, Institute of Computing Technology, Chinese Academy of Sciences University of Chinese Academy of Sciences; ByteDance AI Lab; SKLSDE, Institute of Artificial Intelligence, Beihang University; CAS Key Laboratory of Network Data Science and Technology, Institute of Computing Technology, Chinese Academy of Sciences University of Chinese Academy of Sciences; CAS Key Laboratory of Network Data Science and Technology, Institute of Computing Technology, Chinese Academy of Sciences University of Chinese Academy of Sciences; ByteDance AI Lab",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16946/16946-13-20440-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07746-slimmable-generative-adversarial-networks/",
        "doi": "10.1609/aaai.v35i9.16946",
        "pdf_size": 758487
    },
    {
        "id": "03815",
        "title": "Smooth Convex Optimization Using Sub-Zeroth-Order Oracles",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider the problem of minimizing a smooth, Lipschitz, convex function over a compact, convex set using sub-zeroth-order oracles: an oracle that outputs the sign of the directional derivative for a given point and a given direction, an oracle that compares the function values for a given pair of points, and an oracle that outputs a noisy function value for a given point. We show that the sample complexity of optimization using these oracles is polynomial in the relevant parameters. The optimization algorithm that we provide for the comparator oracle is the first algorithm with a known rate of convergence that is polynomial in the number of dimensions. We also give an algorithm for the noisy-value oracle that incurs sublinear regret in the number of queries and polynomial regret in the number of dimensions.",
        "primary_area": "Constraint Satisfaction and Optimization",
        "author": "Mustafa O. Karabag; Cyrus Neary; Ufuk Topcu",
        "authorids": "",
        "aff": "The University of Texas at Austin; The University of Texas at Austin; University of Texas at Austin",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16499/16499-13-19993-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03815-smooth-convex-optimization-using-sub-zeroth-order-oracles/",
        "doi": "10.1609/aaai.v35i5.16499",
        "pdf_size": 163266
    },
    {
        "id": "01628",
        "title": "SnapMix: Semantically Proportional Mixing for Augmenting Fine-grained Data",
        "track": "main",
        "status": "Poster",
        "abstract": "Data mixing augmentation has proved effective in training deep models. Recent methods mix labels mainly according to the mixture proportion of image pixels. Due to the major discriminative information of a fine-grained image usually resides in subtle regions, these methods tend to introduce heavy label noise in fine-grained recognition. We propose Semantically Proportional Mixing (SnapMix) that exploits class activation map (CAM) to lessen the label noise in augmenting fine-grained data. SnapMix generates the target label for a mixed image by estimating its intrinsic semantic composition. This strategy can adapt to asymmetric mixing operations and ensure semantic correspondence between synthetic images and target labels. Experiments show that our method consistently outperforms existing mixed-based approaches regardless of different datasets or network depths. Further, by incorporating the mid-level features, the proposed SnapMix achieves top-level performance, demonstrating its potential to serve as a strong baseline for fine-grained recognition.",
        "primary_area": "Computer Vision I",
        "author": "Shaoli Huang; Xinchao Wang; Dacheng Tao",
        "authorids": "",
        "aff": "The University of Sydney; Stevens Institute of Technology; The University of Sydney",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16255/16255-13-19749-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01628-snapmix-semantically-proportional-mixing-for-augmenting-fine-grained-data/",
        "doi": "10.1609/aaai.v35i2.16255",
        "pdf_size": 6095550
    },
    {
        "id": "02550",
        "title": "Social-DPF: Socially Acceptable Distribution Prediction of Futures",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider long-term path forecasting problems in crowds, where future sequence trajectories are generated given a short observation. Recent methods for this problem have focused on modeling social interactions and predicting multi-modal futures. However, it is not easy for machines to successfully consider social interactions, such as avoiding collisions while considering the uncertainty of futures under a highly interactive and dynamic scenario. In this paper, we propose a model that incorporates multiple interacting motion sequences jointly and predicts multi-modal socially acceptable distributions of futures. Specifically, we introduce a new aggregation mechanism for social interactions, which selectively models long-term inter-related dynamics between movements in a shared environment through a message passing mechanism. Moreover, we propose a loss function that not only accesses how accurate the estimated distributions of the futures are but also considers collision avoidance. We further utilize mixture density functions to describe the trajectories and learn the multi-modality of future paths.  Extensive experiments over several trajectory prediction benchmarks demonstrate that our method is able to forecast socially acceptable distributions in complex scenarios.",
        "primary_area": "Computer Vision II",
        "author": "Xiaodan Shi; Xiaowei Shao; Guangming Wu; Haoran Zhang; Zhiling Guo; Renhe Jiang; Ryosuke Shibasaki",
        "authorids": "",
        "aff": "Center for Spatial Information Science, the University of Tokyo; Center for Spatial Information Science, the University of Tokyo Earth Observation Data Integration and Fusion Research Initiative, the University of Tokyo; Center for Spatial Information Science, the University of Tokyo; Center for Spatial Information Science, the University of Tokyo; Center for Spatial Information Science, the University of Tokyo; Information Technology Center, the University of Tokyo; Center for Spatial Information Science, the University of Tokyo",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16357/16357-13-19851-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02550-social-dpf-socially-acceptable-distribution-prediction-of-futures/",
        "doi": "10.1609/aaai.v35i3.16357",
        "pdf_size": 10776051
    },
    {
        "id": "05698",
        "title": "Solution Concepts in Hierarchical Games Under Bounded Rationality With Applications to Autonomous Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "With autonomous vehicles (AV) set to integrate further into regular human traffic, there is an increasing consensus of treating AV motion planning as a multi-agent problem. However, the traditional game theoretic assumption of complete rationality is too strong for the purpose of human driving, and there is a need for understanding human driving as a bounded rational activity through a behavioral game theoretic lens. To that end, we adapt three metamodels of bounded rational behavior; two based on Quantal level-k and one based on Nash equilibria with quantal errors. We formalize the different solution concepts that can be applied in the context of hierarchical games, a framework used in multi-agent motion planning, for the purpose of creating game theoretic models of driving behavior. Furthermore, based on a contributed dataset of human driving at a busy urban intersection with a total of ~4k agents and ~44k decision points, we evaluate the behavior models on the basis of model fit to naturalistic data, as well as their predictive capacity. Our results suggest that among the behavior models evaluated, modeling driving behavior as pure strategy Nash equilibria with quantal errors at the level of maneuvers with bounds sampling of actions at the level of trajectories provides the best fit to naturalistic driving behavior, and there is a significant impact of situational factors on the performance of behavior models.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Atrisha Sarkar; Krzysztof Czarnecki",
        "authorids": "",
        "aff": "University of Waterloo, Canada; University of Waterloo, Canada",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16715/16715-13-20209-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05698-solution-concepts-in-hierarchical-games-under-bounded-rationality-with-applications-to-autonomous-driving/",
        "doi": "10.1609/aaai.v35i6.16715",
        "pdf_size": 4208643
    },
    {
        "id": "09695",
        "title": "Solving Common-Payoff Games with Approximate Policy Iteration",
        "track": "main",
        "status": "Poster",
        "abstract": "For artificially intelligent learning systems to have widespread applicability in real-world settings, it is important that they be able to operate decentrally. Unfortunately, decentralized control is difficult---computing even an epsilon-optimal joint policy is a NEXP complete problem. Nevertheless, a recently rediscovered insight---that a team of agents can coordinate via common knowledge---has given rise to algorithms capable of finding optimal joint policies in small common-payoff games. The Bayesian action decoder (BAD) leverages this insight and deep reinforcement learning to scale to games as large as two-player Hanabi. However, the approximations it uses to do so prevent it from discovering optimal joint policies even in games small enough to brute force optimal solutions. This work proposes CAPI, a novel algorithm which, like BAD, combines common knowledge with deep reinforcement learning. However, unlike BAD, CAPI prioritizes the propensity to discover optimal joint policies over scalability. While this choice precludes CAPI from scaling to games as large as Hanabi, empirical results demonstrate that, on the games to which CAPI does scale, it is capable of discovering optimal joint policies even when other modern multi-agent reinforcement learning algorithms are unable to do so.",
        "primary_area": "Machine Learning IV",
        "author": "Samuel Sokota; Edward Lockhart; Finbarr Timbers; Elnaz Davoodi; Ryan D'Orazio; Neil Burch; Martin Schmid; Michael Bowling; Marc Lanctot",
        "authorids": "",
        "aff": "University of Alberta; DeepMind; DeepMind; DeepMind; Universit\u00e9 de Montr\u00e9al; DeepMind; DeepMind; University of Alberta DeepMind; Deepmind",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17166/17166-13-20660-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09695-solving-common-payoff-games-with-approximate-policy-iteration/",
        "doi": "10.1609/aaai.v35i11.17166",
        "pdf_size": 224861
    },
    {
        "id": "03715",
        "title": "Solving Infinite-Domain CSPs Using the Patchwork Property",
        "track": "main",
        "status": "Poster",
        "abstract": "The constraint satisfaction problem (CSP) has important applications in computer science and AI. In particular, infinite-domain CSPs have been intensively used in subareas of AI such as spatio-temporal reasoning. Since constraint satisfaction is a computationally hard problem, much work has been devoted to  identifying restricted problems that are efficiently solvable.  One way of doing this is to restrict the interactions of variables and constraints, and a highly successful approach is to bound the treewidth of the underlying primal graph. Bodirsky & Dalmau [J. Comput. System. Sci., 79(1), 2013] and Huang et al. [Artif. Intell., 195, 2013] proved that CSP(\u0393) can be solved in n^(f(w)) time (where n is the size of the instance, w is the treewidth of the primal graph and f is a computable function)  for certain classes of constraint languages \u0393. We improve this bound to f(w)n^(O(1)), where the function f only depends on the language \u0393, for CSPs whose basic relations have the patchwork property.  Hence, such problems are fixed-parameter tractable and our algorithm is asymptotically faster than the previous ones. Additionally, our approach is not restricted to binary constraints, so it is applicable to a strictly  larger class of problems than that of Huang et al. However, there exist natural problems that are covered by Bodirsky & Dalmau's algorithm but not by ours.",
        "primary_area": "Constraint Satisfaction and Optimization",
        "author": "Konrad K Dabrowski; Peter Jonsson; Sebastian Ordyniak; George Osipov",
        "authorids": "",
        "aff": "Durham University; Link\u00f6ping University; University of Leeds; Link\u00f6ping University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16488/16488-13-19982-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03715-solving-infinite-domain-csps-using-the-patchwork-property/",
        "doi": "10.1609/aaai.v35i5.16488",
        "pdf_size": 168139
    },
    {
        "id": "13798",
        "title": "SongMASS: Automatic Song Writing with Pre-training and Alignment Constraint",
        "track": "main",
        "status": "Poster",
        "abstract": "Automatic song writing aims to compose a song (lyric and/or melody) by machine, which is an interesting topic in both academia and industry. In automatic song writing, lyric-to-melody generation and melody-to-lyric generation are two important tasks, both of which usually suffer from the following challenges: 1) the paired lyric and melody data are limited, which affects the generation quality of the two tasks, considering a lot of paired training data are needed due to the weak correlation between lyric and melody; 2) Strict alignments are required between lyric and melody, which relies on specific alignment modeling. In this paper, we propose SongMASS to address the above challenges, which leverages masked sequence to sequence (MASS) pre-training and attention based alignment modeling for lyric-to-melody and melody-to-lyric generation. Specifically, 1) we extend the original sentence-level MASS pre-training to song level to better capture long contextual information in music, and use a separate encoder and decoder for each modality (lyric or melody);  2) we leverage sentence-level attention mask and token-level attention constraint during training to enhance the alignment between lyric and melody. During inference, we use a dynamic programming strategy to obtain the alignment between each word/syllable in lyric and note in melody. We pre-train SongMASS on unpaired lyric and melody datasets, and both objective and subjective evaluations demonstrate that SongMASS generates lyric and melody with significantly better quality than the baseline method.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Zhonghao Sheng; Kaitao Song; Xu Tan; Yi Ren; Wei Ye; Shikun Zhang; Tao Qin",
        "authorids": "",
        "aff": "Peking University; Nanjing University of Science and Technology; Microsoft Research Asia; Zhejiang University; Peking University; Peking University; Microsoft Research Asia",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17626/17626-13-21120-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13798-songmass-automatic-song-writing-with-pre-training-and-alignment-constraint/",
        "doi": "10.1609/aaai.v35i15.17626",
        "pdf_size": 1035191
    },
    {
        "id": "13489",
        "title": "Span-Based Event Coreference Resolution",
        "track": "main",
        "status": "Poster",
        "abstract": "Motivated by the recent successful application of span-based models to entity-based information extraction tasks, we investigate span-based models for event coreference resolution, focusing on determining (1) whether the successes of span-based models of entity coreference can be extended to event coreference; (2) whether exploiting the dependency between event coreference and the related subtask of trigger detection; and (3) whether automatically computed entity coreference information can benefit span-based event coreference resolution.  Empirical results on the standard evaluation dataset provide affirmative answers to all three questions.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Jing Lu; Vincent Ng",
        "authorids": "",
        "aff": "Human Language Technology Research Institute University of Texas at Dallas; Human Language Technology Research Institute University of Texas at Dallas",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17591/17591-13-21085-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13489-span-based-event-coreference-resolution/",
        "doi": "10.1609/aaai.v35i15.17591",
        "pdf_size": 622812
    },
    {
        "id": "03101",
        "title": "Sparse Single Sweep LiDAR Point Cloud Segmentation via Learning Contextual Shape Priors from Scene Completion",
        "track": "main",
        "status": "Poster",
        "abstract": "LiDAR point cloud analysis is a core task for 3D computer vision, especially for autonomous driving. However, due to the severe sparsity and noise interference in the single sweep LiDAR point cloud, the accurate semantic segmentation is non-trivial to achieve. In this paper, we propose a novel sparse LiDAR point cloud semantic segmentation framework assisted by learned contextual shape priors. In practice, an initial semantic segmentation (SS) of a single sweep point cloud can be achieved by any appealing network and then flows into the semantic scene completion (SSC) module as the input. By merging multiple frames in the LiDAR sequence as supervision, the optimized SSC module has learned the contextual shape priors from sequential LiDAR data, completing the sparse single sweep point cloud to the dense one. Thus, it inherently improves SS optimization through fully end-to-end training. Besides, a Point-Voxel Interaction (PVI) module is proposed to further enhance the knowledge fusion between SS and SSC tasks, i.e., promoting the interaction of incomplete local geometry of point cloud and complete voxel-wise global structure. Furthermore, the auxiliary SSC and PVI modules can be discarded during inference without extra burden for SS. Extensive experiments confirm that our JS3C-Net achieves superior performance on both SemanticKITTI and SemanticPOSS benchmarks, i.e., 4% and 3% improvement correspondingly.",
        "primary_area": "Computer Vision III",
        "author": "Xu Yan; Jiantao Gao; Jie Li; Ruimao Zhang; Zhen Li; Rui Huang; Shuguang Cui",
        "authorids": "",
        "aff": "The Chinese University of Hong Kong (Shenzhen) Shenzhen Research Institute of Big Data; Shanghai University Shenzhen Research Institute of Big Data; The Chinese University of Hong Kong (Shenzhen) Shenzhen Institute of Artificial Intelligence and Robotics for Society; The Chinese University of Hong Kong (Shenzhen) Shenzhen Research Institute of Big Data; The Chinese University of Hong Kong (Shenzhen) Shenzhen Research Institute of Big Data; The Chinese University of Hong Kong (Shenzhen) Shenzhen Institute of Artificial Intelligence and Robotics for Society; The Chinese University of Hong Kong (Shenzhen) Shenzhen Research Institute of Big Data",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16419/16419-13-19913-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03101-sparse-single-sweep-lidar-point-cloud-segmentation-via-learning-contextual-shape-priors-from-scene-completion/",
        "doi": "10.1609/aaai.v35i4.16419",
        "pdf_size": 5620489
    },
    {
        "id": "08181",
        "title": "Sparsity Aware Normalization for GANs",
        "track": "main",
        "status": "Poster",
        "abstract": "Generative adversarial networks (GANs) are known to benefit from regularization or normalization of their critic (discriminator) network during training. In this paper, we analyze the popular spectral normalization scheme, find a significant drawback and introduce sparsity aware normalization (SAN), a new alternative approach for stabilizing GAN training. As opposed to other normalization methods, our approach explicitly accounts for the sparse nature of the feature maps in convolutional networks with ReLU activations. We illustrate the effectiveness of our method through extensive experiments with a variety of network architectures. As we show, sparsity is particularly dominant in critics used for image-to-image translation settings. In these cases our approach improves upon existing methods, in less training epochs and with smaller capacity networks, while requiring practically no computational overhead.",
        "primary_area": "Machine Learning II",
        "author": "Idan Kligvasser; Tomer Michaeli",
        "authorids": "",
        "aff": "Technion; Technion",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16996/16996-13-20490-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08181-sparsity-aware-normalization-for-gans/",
        "doi": "10.1609/aaai.v35i9.16996",
        "pdf_size": 6524714
    },
    {
        "id": "04189",
        "title": "Spatial-Temporal Fusion Graph Neural Networks for Traffic Flow Forecasting",
        "track": "main",
        "status": "Poster",
        "abstract": "Spatial-temporal data forecasting of traffic flow is a challenging task because of complicated spatial dependencies and dynamical trends of temporal pattern between different roads. Existing frameworks usually utilize given spatial adjacency graph and sophisticated mechanisms for modeling spatial and temporal correlations. However, limited representations of given spatial graph structure with incomplete adjacent connections may restrict effective spatial-temporal dependencies learning of those models. Furthermore, existing methods were out at elbows when solving complicated spatial-temporal data: they usually utilize separate modules for spatial and temporal correlations, or they only use independent components capturing localized or global heterogeneous dependencies. To overcome those limitations, our paper proposes a novel Spatial-Temporal Fusion Graph Neural Networks (STFGNN) for traffic flow forecasting. First, a data-driven method of generating \u201ctemporal graph\u201d is proposed to compensate several genuine correlations that spatial graph may not reflect. STFGNN could effectively learn hidden spatial-temporal dependencies by a novel fusion operation of various spatial and temporal graphs, treated for different time periods in parallel. Meanwhile, by integrating this fusion graph module and a novel gated convolution module into a unified layer parallelly, STFGNN could handle long sequences by learning more spatial-temporal dependencies with layers stacked. Experimental results on several public traffic datasets demonstrate that our method achieves state-of-the-art performance consistently than other baselines.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Mengzhang Li; Zhanxing Zhu",
        "authorids": "",
        "aff": "Peking University; Peking University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16542/16542-13-20036-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04189-spatial-temporal-fusion-graph-neural-networks-for-traffic-flow-forecasting/",
        "doi": "10.1609/aaai.v35i5.16542",
        "pdf_size": 950527
    },
    {
        "id": "01027",
        "title": "Spatial-temporal Causal Inference for Partial Image-to-video Adaptation",
        "track": "main",
        "status": "Poster",
        "abstract": "Image-to-video adaptation leverages off-the-shelf learned models in labeled images to help classification in unlabeled videos, thus alleviating the high computation overhead of training a video classifier from scratch. This task is very challenging since there exist two types of domain shifts between images and videos: 1) spatial domain shift caused by static appearance variance between images and video frames, and 2) temporal domain shift caused by the absence of dynamic motion in images. Moreover, for different video classes, these two domain shifts have different effects on the domain gap and should not be treated equally during adaptation. In this paper, we propose a spatial-temporal causal inference framework for image-to-video adaptation. We first construct a spatial-temporal causal graph to infer the effects of the spatial and temporal domain shifts by performing counterfactual causality. We then learn causality-guided bidirectional heterogeneous mappings between images and videos to adaptively reduce the two domain shifts. Moreover, to relax the assumption that the label spaces of the image and video domains are the same by the existing methods, we incorporate class-wise alignment into the learning of image-video mappings to perform partial image-to-video adaptation where the image label space subsumes the video label space. Extensive experiments on several video datasets have validated the effectiveness of our proposed method.",
        "primary_area": "Computer Vision I",
        "author": "Jin Chen; Xinxiao Wu; Yao Hu; Jiebo Luo",
        "authorids": "",
        "aff": "Beijing Institute of Technology; Beijing Institute of Technology; Alibaba Youku Cognitive and Intelligent Lab; University of Rochester",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16187/16187-13-19681-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01027-spatial-temporal-causal-inference-for-partial-image-to-video-adaptation/",
        "doi": "10.1609/aaai.v35i2.16187",
        "pdf_size": 589035
    },
    {
        "id": "01227",
        "title": "Spatio-Temporal Difference Descriptor for Skeleton-Based Action Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "In skeletal representation, intra-frame differences between body joints, as well as inter-frame dynamics between body skeletons contain discriminative information for action recognition. Conventional methods for modeling human skeleton sequences generally depend on motion trajectory and body joint dependency information, thus lacking the ability to identify the inherent differences of human skeletons. In this paper, we propose a spatio-temporal difference descriptor based on a directional convolution architecture that enables us to learn the spatio-temporal differences and contextual dependencies between different body joints simultaneously. The overall model is built on a deep symmetric positive definite (SPD) metric learning architecture designed to learn discriminative manifold features with the well-designed non-linear mapping operation. Experiments on several action datasets show that our proposed method achieves up to 3% accuracy improvement over state-of-the-art methods.",
        "primary_area": "Computer Vision I",
        "author": "Chongyang Ding; Kai Liu; Jari Korhonen; Evgeny Belyaev",
        "authorids": "",
        "aff": "Xidian University; Xidian University; Shenzhen University; ITMO University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16210/16210-13-19704-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01227-spatio-temporal-difference-descriptor-for-skeleton-based-action-recognition/",
        "doi": "10.1609/aaai.v35i2.16210",
        "pdf_size": 651104
    },
    {
        "id": "02100",
        "title": "Spatiotemporal Graph Neural Network based Mask Reconstruction for Video Object Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper addresses the task of segmenting class-agnostic objects in semi-supervised setting. Although previous detection based methods achieve relatively good performance, these approaches extract the best proposal by a greedy strategy, which may lose the local patch details outside the chosen candidate. In this paper, we propose a novel spatiotemporal graph neural network (STG-Net) to reconstruct more accurate masks for video object segmentation, which captures the local contexts by utilizing all proposals. In the spatial graph, we treat object proposals of a frame as nodes and represent their correlations with an edge weight strategy for mask context aggregation. To capture temporal information from previous frames, we use a memory network to refine the mask of current frame by retrieving historic masks in a temporal graph. The joint use of both local patch details and temporal relationships allow us to better address the challenges such as object occlusions and missing. Without online learning and fine-tuning, our STG-Net achieves state-of-the-art performance on four large benchmarks, demonstrating the effectiveness of the proposed approach.",
        "primary_area": "Computer Vision II",
        "author": "Daizong Liu; Shuangjie Xu; Xiao-Yang Liu; Zichuan Xu; Wei Wei; Pan Zhou",
        "authorids": "",
        "aff": "Huazhong University of Science and Technology; Deeproute.ai; Columbia University; Dalian University of Technology; Huazhong University of Science and Technology; Huazhong University of Science and Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16307/16307-13-19801-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02100-spatiotemporal-graph-neural-network-based-mask-reconstruction-for-video-object-segmentation/",
        "doi": "10.1609/aaai.v35i3.16307",
        "pdf_size": 2950921
    },
    {
        "id": "01734",
        "title": "Spectral Distribution Aware Image Generation",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent advances in deep generative models for photo-realistic images have led to high quality visual results. Such models learn to generate data from a given training distribution such that generated images can not be easily distinguished from real images by the human eye. Yet, recent work on the detection of such fake images pointed out that they are actually easily distinguishable by artifacts in their frequency spectra. In this paper, we propose to generate images according to the frequency distribution of the real data by employing a spectral discriminator. The proposed discriminator is lightweight, modular and works stably with different commonly used GAN losses. We show that the resulting models can better generate images with realistic frequency spectra, which are thus harder to detect by this cue.",
        "primary_area": "Computer Vision I",
        "author": "Steffen Jung; Margret Keuper",
        "authorids": "",
        "aff": "Max Planck Institute for Informatics; University of Mannheim",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16267/16267-13-19761-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01734-spectral-distribution-aware-image-generation/",
        "doi": "10.1609/aaai.v35i2.16267",
        "pdf_size": 1962457
    },
    {
        "id": "01513",
        "title": "Spherical Image Generation from a Single Image by Considering Scene Symmetry",
        "track": "main",
        "status": "Poster",
        "abstract": "Spherical images taken in all directions (360 degrees by 180 degrees) allow the full surroundings of a subject to be represented, providing an immersive experience to viewers. Generating a spherical image from a single normal-field-of-view (NFOV) image is convenient and expands the usage scenarios considerably without relying on a specific panoramic camera or images taken from multiple directions; however, achieving such images remains a challenging and unresolved problem. The primary challenge is controlling the high degree of freedom involved in generating a wide area that includes all directions of the desired spherical image. We focus on scene symmetry, which is a basic property of the global structure of spherical images, such as rotational symmetry, plane symmetry, and asymmetry. We propose a method for generating a spherical image from a single NFOV image and controlling the degree of freedom of the generated regions using the scene symmetry. To estimate and control the scene symmetry using both a circular shift and flip of the latent image features, we incorporate the intensity of the symmetry as a latent variable into conditional variational autoencoders. Our experiments show that the proposed method can generate various plausible spherical images controlled from symmetric to asymmetric, and can reduce the reconstruction errors of the generated images based on the estimated symmetry.",
        "primary_area": "Computer Vision I",
        "author": "Takayuki Hara; Yusuke Mukuta; Tatsuya Harada",
        "authorids": "",
        "aff": "The University of Tokyo; The University of Tokyo RIKEN; The University of Tokyo RIKEN",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16242/16242-13-19736-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01513-spherical-image-generation-from-a-single-image-by-considering-scene-symmetry/",
        "doi": "10.1609/aaai.v35i2.16242",
        "pdf_size": 2655088
    },
    {
        "id": "01184",
        "title": "Split then Refine: Stacked Attention-guided ResUNets for Blind Single Image Visible Watermark Removal",
        "track": "main",
        "status": "Poster",
        "abstract": "Digital watermark is a commonly used technique to protect the copyright of medias. Simultaneously, to increase the robustness of watermark, attacking technique, such as watermark removal, also gets the attention from the community. Previous watermark removal methods require to gain the watermark location from users or train a multi-task network to recover the background indiscriminately. However, when jointly learning, the network performs better on watermark detection than recovering the texture. Inspired by this observation and to erase the visible watermarks blindly, we propose a novel two-stage framework with a stacked attention-guided ResUNets to simulate the process of detection, removal and refinement.  In the first stage, we design a multi-task network called SplitNet. It learns the basis features for three sub-tasks altogether while the task-specific features separately use multiple channel attentions. Then, with the predicted mask and coarser restored image, we design RefineNet to smooth the watermarked region with a mask-guided spatial attention. Besides network structure, the proposed algorithm also combines multiple perceptual losses for better quality both visually and numerically.  We extensively evaluate our algorithm over four different datasets under various settings and the experiments show that our approach outperforms other state-of-the-art methods by a large margin.",
        "primary_area": "Computer Vision I",
        "author": "Xiaodong Cun; Chi-Man Pun",
        "authorids": "",
        "aff": "University of Macau; University of Macau",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16205/16205-13-19699-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01184-split-then-refine-stacked-attention-guided-resunets-for-blind-single-image-visible-watermark-removal/",
        "doi": "10.1609/aaai.v35i2.16205",
        "pdf_size": 12311060
    },
    {
        "id": "08137",
        "title": "Split-and-Bridge: Adaptable Class Incremental Learning within a Single Neural Network",
        "track": "main",
        "status": "Poster",
        "abstract": "Continual learning has been a major problem in the deep learning community, where the main challenge is how to effectively learn a series of newly arriving tasks without forgetting the knowledge of previous tasks. Initiated by Learning without Forgetting (LwF), many of the existing works report that knowledge distillation is effective to preserve the previous knowledge, and hence they commonly use a soft label for the old task, namely a knowledge distillation (KD) loss, together with a class label for the new task, namely a cross entropy (CE) loss, to form a composite loss for a single neural network. However, this approach suffers from learning the knowledge by a CE loss as a KD loss often more strongly influences the objective function when they are in a competitive situation within a single network. This could be a critical problem particularly in a class incremental scenario, where the knowledge across tasks as well as within the new task, both of which can only be acquired by a CE loss, is essentially learned due to the existence of a unified classifier. In this paper, we propose a novel continual learning method, called Split-and-Bridge, which can successfully address the above problem by partially splitting a neural network into two partitions for training the new task separated from the old task and re-connecting them for learning the knowledge across tasks. In our thorough experimental analysis, our Split-and-Bridge method outperforms the state-of-the-art competitors in KD-based continual learning.",
        "primary_area": "Machine Learning II",
        "author": "Jong-Yeong Kim; Dong-Wan Choi",
        "authorids": "",
        "aff": "Department of Computer Science and Engineering, Inha University, South Korea; Department of Computer Science and Engineering, Inha University, South Korea",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16991/16991-13-20485-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08137-split-and-bridge-adaptable-class-incremental-learning-within-a-single-neural-network/",
        "doi": "10.1609/aaai.v35i9.16991",
        "pdf_size": 752787
    },
    {
        "id": "09756",
        "title": "Stability and Generalization of Decentralized Stochastic Gradient Descent",
        "track": "main",
        "status": "Poster",
        "abstract": "The stability and generalization of stochastic gradient-based methods provide valuable insights into understanding the algorithmic performance of machine learning models. As the main workhorse for deep learning, the stochastic gradient descent has received a considerable amount of studies. Nevertheless, the community paid little attention to its decentralized variants. In this paper, we provide a novel formulation of the decentralized stochastic gradient descent. Leveraging this formulation together with (non)convex optimization theory, we establish the first stability and generalization guarantees for the decentralized stochastic gradient descent. Our theoretical results are built on top of a few common and mild assumptions and reveal that the decentralization deteriorates the stability of SGD for the first time. We verify our theoretical findings by using a variety of decentralized settings and benchmark machine learning models.",
        "primary_area": "Machine Learning IV",
        "author": "Tao Sun; Dongsheng Li; Bao Wang",
        "authorids": "",
        "aff": "College of Computer, National University of Defense Technology; College of Computer, National University of Defense Technology; Scientific Computing & Imaging Institute, University of Utah",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17173/17173-13-20667-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09756-stability-and-generalization-of-decentralized-stochastic-gradient-descent/",
        "doi": "10.1609/aaai.v35i11.17173",
        "pdf_size": 394487
    },
    {
        "id": "07501",
        "title": "Stabilizing Q Learning Via Soft Mellowmax Operator",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning complicated value functions in high dimensional state space by function approximation is a challenging task, partially due to that the max-operator used in temporal difference updates can theoretically cause instability for most linear or non-linear approximation schemes. Mellowmax is a recently proposed differentiable and non-expansion softmax operator that allows a convergent behavior in learning and planning. Unfortunately, the performance bound for the fixed point it converges to remains unclear, and in practice, its parameter is sensitive to various domains and has to be tuned case by case. Finally, the Mellowmax operator may suffer from oversmoothing as it ignores the probability being taken for each action when aggregating them. In this paper we address all the above issues with an enhanced Mellowmax operator, named SM2 (Soft Mellowmax). Particularly, the proposed operator is reliable, easy to implement, and has provable performance guarantee,  while preserving all the advantages of Mellowmax. Furthermore, we show that our SM2 operator can be applied to the challenging multi-agent reinforcement learning scenarios, leading to stable value function approximation and state of the art performance.",
        "primary_area": "Machine Learning II",
        "author": "Yaozhong Gan; Zhe Zhang; Xiaoyang Tan",
        "authorids": "",
        "aff": "Nanjing University of Aeronautics and Astronautics, China; Nanjing University of Aeronautics and Astronautics, China; Nanjing University of Aeronautics and Astronautics, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16919/16919-13-20413-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07501-stabilizing-q-learning-via-soft-mellowmax-operator/",
        "doi": "10.1609/aaai.v35i9.16919",
        "pdf_size": 700657
    },
    {
        "id": "08662",
        "title": "Stable Adversarial Learning under Distributional Shifts",
        "track": "main",
        "status": "Poster",
        "abstract": "Machine learning algorithms with empirical risk minimization are vulnerable under distributional shifts due to the greedy adoption of all the correlations found in training data. Recently, there are robust learning methods aiming at this problem by minimizing the worst-case risk over an uncertainty set. However, they equally treat all covariates to form the decision sets regardless of the stability of their correlations with the target, resulting in the overwhelmingly large set and low confidence of the learner. In this paper, we propose Stable Adversarial Learning (SAL) algorithm that leverages heterogeneous data sources to construct a more practical uncertainty set and conduct differentiated robustness optimization, where covariates are differentiated according to the stability of their correlations with the target. We theoretically show that our method is tractable for stochastic gradient-based optimization and provide the performance guarantees for our method. Empirical studies on both simulation and real datasets validate the effectiveness of our method in terms of uniformly good performance across unknown distributional shifts.",
        "primary_area": "Machine Learning III",
        "author": "Jiashuo Liu; Zheyan Shen; Peng Cui; Linjun Zhou; Kun Kuang; Bo Li; Yishi Lin",
        "authorids": "",
        "aff": "Tsinghua University; Tsinghua University; Tsinghua University; Tsinghua University; Zhejiang University; Tsinghua University; Tencent",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17050/17050-13-20544-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08662-stable-adversarial-learning-under-distributional-shifts/",
        "doi": "10.1609/aaai.v35i10.17050",
        "pdf_size": 318945
    },
    {
        "id": "01743",
        "title": "StarNet: towards Weakly Supervised Few-Shot Object Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Few-shot detection and classification have advanced significantly in recent years. Yet, detection approaches require strong annotation (bounding boxes) both for pre-training and for adaptation to novel classes, and classification approaches rarely provide localization of objects in the scene. In this paper, we introduce StarNet - a few-shot model featuring an end-to-end differentiable non-parametric star-model detection and classification head. Through this head, the backbone is meta-trained using only image-level labels to produce good features for jointly localizing and classifying previously unseen categories of few-shot test tasks using a star-model that geometrically matches between the query and support images (to find corresponding object instances). Being a few-shot detector, StarNet does not require any bounding box annotations, neither during pre-training nor for novel classes adaptation. It can thus be applied to the previously unexplored and challenging task of Weakly Supervised Few-Shot Object Detection (WS-FSOD), where it attains significant improvements over the baselines. In addition, StarNet shows significant gains on few-shot classification benchmarks that are less cropped around the objects (where object localization is key).",
        "primary_area": "Computer Vision I",
        "author": "Leonid Karlinsky; Joseph Shtok; Amit Alfassy; Moshe Lichtenstein; Sivan Harary; Eli Schwartz; Sivan Doveh; Prasanna Sattigeri; Rogerio Feris; Alex Bronstein; Raja Giryes",
        "authorids": "",
        "aff": "IBM Research AI; IBM Research AI; IBM Research AI Technion; IBM Research AI; IBM Research AI; IBM Research AI Tel-Aviv University; IBM Research AI; IBM Research AI; IBM Research AI; Technion; Tel-Aviv University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16268/16268-13-19762-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01743-starnet-towards-weakly-supervised-few-shot-object-detection/",
        "doi": "10.1609/aaai.v35i2.16268",
        "pdf_size": 7699842
    },
    {
        "id": "00513",
        "title": "StatEcoNet: Statistical Ecology Neural Networks for Species Distribution Modeling",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper focuses on a core task in computational sustainability and statistical ecology: species distribution modeling (SDM). In SDM, the occurrence pattern of a species on a landscape is predicted by environmental features based on observations at a set of locations. At first, SDM may appear to be a binary classification problem, and one might be inclined to employ classic tools (e.g., logistic regression, support vector machines, neural networks) to tackle it. However, wildlife surveys introduce structured noise (especially under-counting) in the species observations. If unaccounted for, these observation errors systematically bias SDMs. To address the unique challenges of SDM, this paper proposes a framework called StatEcoNet. Specifically, this work employs a graphical generative model in statistical ecology to serve as the skeleton of the proposed computational framework and carefully integrates neural networks under the framework. The advantages of StatEcoNet over related approaches are demonstrated on simulated datasets as well as bird species data. Since SDMs are critical tools for ecological science and natural resource management, StatEcoNet may offer boosted computational and analytical powers to a wide range of applications that have significant social impacts, e.g., the study and conservation of threatened species.",
        "primary_area": "Application Domains",
        "author": "Eugene Seo; Rebecca A. Hutchinson; Xiao Fu; Chelsea Li; Tyler A. Hallman; John Kilbride; W. Douglas Robinson",
        "authorids": "",
        "aff": "Oregon State University; Oregon State University; Oregon State University; Oregon State University; Swiss Ornithological Institute, Sempach, Switzerland; Oregon State University; Oregon State University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16129/16129-13-19623-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00513-stateconet-statistical-ecology-neural-networks-for-species-distribution-modeling/",
        "doi": "10.1609/aaai.v35i1.16129",
        "pdf_size": 3847537
    },
    {
        "id": "01893",
        "title": "Static-Dynamic Interaction Networks for Offline Signature Verification",
        "track": "main",
        "status": "Poster",
        "abstract": "Offline signature verification is a challenging issue that is widely used in various fields. Previous approaches model this task as a static feature matching or distance metric problem of two images. In this paper, we propose a novel Static-Dynamic Interaction Network (SDINet) model which introduces sequential representation into static signature images. A static signature image is converted to sequences by assuming pseudo dynamic processes in the static image. A static representation extracting deep features from signature images describes the global information of signatures. A dynamic representation extracting sequential features with LSTM networks characterizes the local information of signatures. A dynamic-to-static attention is learned from the sequences to refine the static features. Through the static-to-dynamic conversion and the dynamic-to-static attention, the static representation and dynamic representation are unified into a compact framework. The proposed method was evaluated on four popular datasets of different languages. The extensive experimental results manifest the strength of our model.",
        "primary_area": "Computer Vision II",
        "author": "Huan Li; Ping Wei; Ping Hu",
        "authorids": "",
        "aff": "Xi\u2019an Jiaotong University; Xi'an Jiaotong University; Xi'an Jiaotong University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16284/16284-13-19778-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01893-static-dynamic-interaction-networks-for-offline-signature-verification/",
        "doi": "10.1609/aaai.v35i3.16284",
        "pdf_size": 1168847
    },
    {
        "id": "04855",
        "title": "Steering a Historical Disease Forecasting Model Under a Pandemic: Case of Flu and COVID-19",
        "track": "main",
        "status": "Poster",
        "abstract": "Forecasting influenza in a timely manner aids health organizations and policymakers in adequate preparation and decision making. However, effective influenza forecasting still remains a challenge despite increasing research interest. It is even more challenging amidst the COVID pandemic, when the influenza-like illness (ILI) counts are affected by various factors such as symptomatic similarities with COVID-19 and shift in healthcare seeking patterns of the general population. Under the current pandemic, historical influenza models carry valuable expertise about the disease dynamics but face difficulties adapting. Therefore, we propose CALI-Net, a neural transfer learning architecture which allows us to 'steer' a historical disease forecasting model to new scenarios where flu and COVID co-exist. Our framework enables this adaptation by automatically learning when it should emphasize learning from COVID-related signals and when it should learn from the historical model. Thus, we exploit representations learned from historical ILI data as well as the limited COVID-related signals. Our experiments demonstrate that our approach is successful in adapting a historical forecasting model to the current pandemic. In addition, we show that success in our primary goal, adaptation, does not sacrifice overall performance as compared with state-of-the-art influenza forecasting approaches.",
        "primary_area": "AI Responses to the COVID-19 Pandemic",
        "author": "Alexander Rodr\u00edguez; Nikhil Muralidhar; Bijaya Adhikari; Anika Tabassum; Naren Ramakrishnan; B. Aditya Prakash",
        "authorids": "",
        "aff": "Georgia Institute of Technology; Virginia Tech; University of Iowa; Virginia tech Georgia Institute of Technology; Virginia Tech; Georgia Institute of Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16618/16618-13-20112-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04855-steering-a-historical-disease-forecasting-model-under-a-pandemic-case-of-flu-and-covid-19/",
        "doi": "10.1609/aaai.v35i6.16618",
        "pdf_size": 1113291
    },
    {
        "id": "10478",
        "title": "Step-Ahead Error Feedback for Distributed Training with Compressed Gradient",
        "track": "main",
        "status": "Poster",
        "abstract": "Although the distributed machine learning methods can speed up the training of large deep neural networks, the communication cost has become the non-negligible bottleneck to constrain the performance. To address this challenge, the gradient compression based communication-efficient distributed learning methods were designed to reduce the communication cost, and more recently the local error feedback was incorporated to compensate for the corresponding performance loss. However, in this paper, we will show that a new \"gradient mismatch\" problem is raised by the local error feedback in centralized distributed training and can lead to degraded performance compared with full-precision training. To solve this critical problem, we propose two novel techniques, 1) step ahead and 2) error averaging, with rigorous theoretical analysis. Both our theoretical and empirical results show that our new methods can handle the \"gradient mismatch\" problem. The experimental results show that we can even train faster with common gradient compression schemes than both the full-precision training and local error feedback regarding the training epochs and without performance loss.",
        "primary_area": "Machine Learning V",
        "author": "An Xu; Zhouyuan Huo; Heng Huang",
        "authorids": "",
        "aff": "University of Pittsburgh; Google; University of Pittsburgh JD Finance America Corporation",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17254/17254-13-20748-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10478-step-ahead-error-feedback-for-distributed-training-with-compressed-gradient/",
        "doi": "10.1609/aaai.v35i12.17254",
        "pdf_size": 760703
    },
    {
        "id": "02879",
        "title": "Stereopagnosia: Fooling Stereo Networks with Adversarial Perturbations",
        "track": "main",
        "status": "Poster",
        "abstract": "We study the effect of adversarial perturbations of images on the estimates of disparity by deep learning models trained for stereo. We show that imperceptible additive perturbations can significantly alter the disparity map, and correspondingly the perceived geometry of the scene. These perturbations not only affect the specific model they are crafted for, but transfer to models with different architecture, trained with different loss functions. We show that, when used for adversarial data augmentation, our perturbations result in trained models that are more robust, without sacrificing overall accuracy of the model. This is unlike what has been observed in image classification, where adding the perturbed images to the training set makes the model less vulnerable to adversarial perturbations, but to the detriment of overall accuracy. We test our method using the most recent stereo networks and evaluate their performance on public benchmark datasets.",
        "primary_area": "Computer Vision III",
        "author": "Alex Wong; Mukund Mundhra; Stefano Soatto",
        "authorids": "",
        "aff": "UCLA Vision Lab; UCLA Vision Lab; UCLA Vision Lab",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16394/16394-13-19888-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02879-stereopagnosia-fooling-stereo-networks-with-adversarial-perturbations/",
        "doi": "10.1609/aaai.v35i4.16394",
        "pdf_size": 10513285
    },
    {
        "id": "08758",
        "title": "Stochastic Bandits with Graph Feedback in Non-Stationary Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "We study a variant of stochastic bandits where the feedback model is specified by a graph. In this setting, after playing an arm, one can observe rewards of not only the played arm but also other arms that are adjacent to the played arm in the graph. Most of the existing work assumes the reward distributions are stationary over time, which, however, is often violated in common scenarios such as recommendation systems and online advertising. To address this limitation, we study stochastic bandits with graph feedback in non-stationary environments and propose algorithms with graph-dependent dynamic regret bounds. When the number of reward distribution changes L is known in advance, one of our algorithms achieves an \u00d5(\u221a(\u03b1LT)) dynamic regret bound. We also develop an adaptive algorithm that can adapt to unknown L and attain an \u00d5(\u221a(\u03b8LT)) dynamic regret. Here, \u03b1 and \u03b8 are some graph-dependent quantities and T is the time horizon.",
        "primary_area": "Machine Learning III",
        "author": "Shiyin Lu; Yao Hu; Lijun Zhang",
        "authorids": "",
        "aff": "Nanjing University; Alibaba Youku Cognitive and Intelligent Lab; Nanjing University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17061/17061-13-20555-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08758-stochastic-bandits-with-graph-feedback-in-non-stationary-environments/",
        "doi": "10.1609/aaai.v35i10.17061",
        "pdf_size": 936159
    },
    {
        "id": "08749",
        "title": "Stochastic Graphical Bandits with Adversarial Corruptions",
        "track": "main",
        "status": "Poster",
        "abstract": "We study bandits with graph-structured feedback, where a learner repeatedly selects an arm and then observes rewards of the chosen arm as well as its neighbors in the feedback graph. Existing work on graphical bandits assumes either stochastic rewards or adversarial rewards, both of which are extremes and appear rarely in real-world scenarios. In this paper, we study graphical bandits with a reward model that interpolates between the two extremes, where the rewards are overall stochastically generated but a small fraction of them can be adversarially corrupted. For this problem, we propose an online algorithm that can utilize the stochastic pattern and also tolerate the adversarial corruptions. The main idea is to restrict exploration to carefully-designed independent sets of the feedback graph and perform exploitation by adopting a soft version of arm elimination. Theoretical analysis shows that our algorithm attains an $O(alpha ln{K} ln{T} + alpha C)$ regret, where $alpha$ is the independence number of the feedback graph, $K$ is the number of arms, $T$ is the time horizon, and $C$ quantifies the total corruptions introduced by the adversary. The effectiveness of our algorithm is demonstrated by numerical experiments.",
        "primary_area": "Machine Learning III",
        "author": "Shiyin Lu; Guanghui Wang; Lijun Zhang",
        "authorids": "",
        "aff": "Nanjing University; Nanjing University; Nanjing University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17060/17060-13-20554-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08749-stochastic-graphical-bandits-with-adversarial-corruptions/",
        "doi": "10.1609/aaai.v35i10.17060",
        "pdf_size": 223890
    },
    {
        "id": "06794",
        "title": "Stochastic Precision Ensemble: Self-Knowledge Distillation for Quantized Deep Neural Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "The quantization of deep neural networks (QDNNs) has been actively studied for deployment in edge devices. Recent studies employ the knowledge distillation (KD) method to improve the performance of quantized networks. In this study, we propose stochastic precision ensemble training for QDNNs (SPEQ). SPEQ is a knowledge distillation training scheme; however, the teacher is formed by sharing the model parameters of the student network. We obtain the soft labels of the teacher by randomly changing the bit precision of the activation stochastically at each layer of the forward-pass computation. The student model is trained with these soft labels to reduce the activation quantization noise. The cosine similarity loss is employed, instead of the KL-divergence, for KD training. As the teacher model changes continuously by random bit-precision assignment, it exploits the effect of stochastic ensemble KD. SPEQ outperforms the existing quantization training methods in various tasks, such as image classification, question-answering, and transfer learning without the need for cumbersome teacher networks.",
        "primary_area": "Machine Learning I",
        "author": "Yoonho Boo; Sungho Shin; Jungwook Choi; Wonyong Sung",
        "authorids": "",
        "aff": "Seoul National University; Seoul National University; Hanyang University; Seoul national university",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16839/16839-13-20333-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06794-stochastic-precision-ensemble-self-knowledge-distillation-for-quantized-deep-neural-networks/",
        "doi": "10.1609/aaai.v35i8.16839",
        "pdf_size": 405297
    },
    {
        "id": "00497",
        "title": "Stock Selection via Spatiotemporal Hypergraph Attention Network: A Learning to Rank Approach",
        "track": "main",
        "status": "Poster",
        "abstract": "Quantitative trading and investment decision making are intricate financial tasks that rely on accurate stock selection. Despite advances in deep learning that have made significant progress in the complex and highly stochastic stock prediction problem, modern solutions face two significant limitations.  They do not directly optimize the target of investment in terms of profit, and treat each stock as independent from the others, ignoring the rich signals between related stocks' temporal price movements. Building on these limitations, we reformulate stock prediction as a learning to rank problem and propose STHAN-SR, a neural hypergraph architecture for stock selection. The key novelty of our work is the proposal of modeling the complex relations between stocks through a hypergraph and a temporal Hawkes attention mechanism to tailor a new spatiotemporal attention hypergraph network architecture to rank stocks based on profit by jointly modeling stock interdependence and the temporal evolution of their prices. Through experiments on three markets spanning over six years of data, we show that STHAN-SR significantly outperforms state-of-the-art neural stock forecasting methods. We validate our design choices through ablative and exploratory analyses over STHAN-SR's spatial and temporal components and demonstrate its practical applicability.",
        "primary_area": "Application Domains",
        "author": "Ramit Sawhney; Shivam Agarwal; Arnav Wadhwa; Tyler Derr; Rajiv Ratn Shah",
        "authorids": "",
        "aff": "IIIT Delhi; Manipal Institute of Technology; MIDAS@IIITD; Vanderbilt University; IIIT Delhi",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16127/16127-13-19621-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00497-stock-selection-via-spatiotemporal-hypergraph-attention-network-a-learning-to-rank-approach/",
        "doi": "10.1609/aaai.v35i1.16127",
        "pdf_size": 6746221
    },
    {
        "id": "07729",
        "title": "Storage Fit Learning with Feature Evolvable Streams",
        "track": "main",
        "status": "Poster",
        "abstract": "Feature evolvable learning has been widely studied in recent years where old features will vanish and new features will emerge when learning with streams. Conventional methods usually assume that a label will be revealed after prediction at each time step. However, in practice, this assumption may not hold whereas no label will be given at most time steps. A good solution is to leverage the technique of manifold regularization to utilize the previous similar data to assist the refinement of the online model. Nevertheless, this approach needs to store all previous data which is impossible in learning with streams that arrive sequentially in large volume. Thus we need a buffer to store part of them. Considering that different devices may have different storage budgets, the learning approaches should be flexible subject to the storage budget limit. In this paper, we propose a new setting: Storage-Fit Feature-Evolvable streaming Learning (SF2EL) which incorporates the issue of rarely-provided labels into feature evolution. Our framework is able to fit its behavior for different storage budgets when learning with feature evolvable streams with unlabeled data. Besides, both theoretical and empirical results validate that our approach can preserve the merit of the original feature evolvable learning i.e., can always track the best baseline and thus perform well at any time step.",
        "primary_area": "Machine Learning II",
        "author": "Bo-Jian Hou; Yu-Hu Yan; Peng Zhao; Zhi-Hua Zhou",
        "authorids": "",
        "aff": "Nanjing University; Nanjing University; Nanjing University; Nanjing University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16944/16944-13-20438-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07729-storage-fit-learning-with-feature-evolvable-streams/",
        "doi": "10.1609/aaai.v35i9.16944",
        "pdf_size": 844418
    },
    {
        "id": "13073",
        "title": "Story Ending Generation with Multi-Level Graph Convolutional Networks over Dependency Trees",
        "track": "main",
        "status": "Poster",
        "abstract": "As an interesting and challenging task, story ending generation aims at generating a reasonable and coherent ending for a given story context. The key challenge of the task is to comprehend the context sufficiently and capture the hidden logic information effectively, which has not been well explored by most existing generative models. To tackle this issue, we propose a context-aware Multi-level Graph Convolutional Networks over Dependency Parse (MGCN-DP) trees to capture dependency relations and context clues more effectively. We utilize dependency parse trees to facilitate capturing relations and events in the context implicitly, and Multi-level Graph Convolutional Networks to update and deliver the representation crossing levels to obtain richer contextual information. Both automatic and manual evaluations show that our MGCN-DP can achieve comparable performance with state-of-the-art models. Our source code is available at https://github.com/VISLANG-Lab/MLGCN-DP.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Qingbao Huang; Linzhang Mo; Pijian Li; Yi Cai; Qingguang Liu; Jielong Wei; Qing Li; Ho-fung Leung",
        "authorids": "",
        "aff": "School of Software Engineering, South China University of Technology, Guangzhou, China School of Electrical Engineering, Guangxi University, Nanning, China; School of Electrical Engineering, Guangxi University, Nanning, China; School of Electrical Engineering, Guangxi University, Nanning, China; School of Software Engineering, South China University of Technology, Guangzhou, China Key Laboratory of Big Data and Intelligent Robot (SCUT), MOE of China; School of Electrical Engineering, Guangxi University, Nanning, China; School of Electrical Engineering, Guangxi University, Nanning, China; Department of Computing, The Hong Kong Polytechnic University, Hong Kong, China; Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17545/17545-13-21039-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13073-story-ending-generation-with-multi-level-graph-convolutional-networks-over-dependency-trees/",
        "doi": "10.1609/aaai.v35i14.17545",
        "pdf_size": 513010
    },
    {
        "id": "09816",
        "title": "Strategy and Benchmark for Converting Deep Q-Networks to Event-Driven Spiking Neural Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Spiking neural networks  (SNNs) have great potential for energy-efficient implementation of Deep Neural Networks (DNNs) on dedicated neuromorphic hardware. Recent studies demonstrated competitive performance of SNNs compared with DNNs on image classification tasks, including CIFAR-10 and ImageNet data. The present work focuses on using SNNs in combination with deep reinforcement learning in ATARI games, which involves additional complexity as compared to image classification. We review the theory of converting DNNs to SNNs and extending the conversion to Deep Q-Networks (DQNs). We propose a robust representation of the firing rate to reduce the error during the conversion process. In addition, we introduce a new metric to evaluate the conversion process by comparing the decisions made by the DQN and SNN, respectively. We also analyze how the simulation time and parameter normalization influence the performance of converted SNNs. We achieve competitive scores on 17 top-performing Atari games. To the best of our knowledge, our work is the first to achieve state-of-the-art performance on multiple Atari games with SNNs. Our work serves as a benchmark for the conversion of DQNs to SNNs and paves the way for further research on solving reinforcement learning tasks with SNNs.",
        "primary_area": "Machine Learning IV",
        "author": "Weihao Tan; Devdhar Patel; Robert Kozma",
        "authorids": "",
        "aff": "University of Massachusetts Amherst; University of Massachusetts Amherst; University of Massachusetts Amherst University of Memphis",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17180/17180-13-20674-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09816-strategy-and-benchmark-for-converting-deep-q-networks-to-event-driven-spiking-neural-networks/",
        "doi": "10.1609/aaai.v35i11.17180",
        "pdf_size": 286539
    },
    {
        "id": "06488",
        "title": "Stratified Negation in Datalog with Metric Temporal Operators",
        "track": "main",
        "status": "Poster",
        "abstract": "We extend DatalogMTL\u2014Datalog with operators from metric temporal logic\u2014by adding stratified negation as failure. The new language provides additional expressive power for representing and reasoning about temporal data and knowledge in a wide range of applications. We consider models over the rational timeline, study their properties, and establish the computational complexity of reasoning. We show that, as in negation-free DatalogMTL, fact entailment in our language is PSPACE-complete in data and EXPSPACE-complete in combined complexity. Thus, the extension with stratified negation does not lead to higher complexity.",
        "primary_area": "Knowledge Representation and Reasoning",
        "author": "David J Tena Cucala; Przemys\u0142aw A Wa\u0142\u0119ga; Bernardo Cuenca Grau; Egor Kostylev",
        "authorids": "",
        "aff": "University of Oxford; University of Oxford; University of Oxford; University of Oslo",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16804/16804-13-20298-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06488-stratified-negation-in-datalog-with-metric-temporal-operators/",
        "doi": "10.1609/aaai.v35i7.16804",
        "pdf_size": 154210
    },
    {
        "id": "01567",
        "title": "Stratified Rule-Aware Network for Abstract Visual Reasoning",
        "track": "main",
        "status": "Poster",
        "abstract": "Abstract reasoning refers to the ability to analyze information, discover rules at an intangible level, and solve problems in innovative ways. Raven's Progressive Matrices (RPM) test is typically used to examine the capability of abstract reasoning. The subject is asked to identify the correct choice from the answer set to fill the missing panel at the bottom right of RPM (e.g., a 3\u00d73 matrix), following the underlying rules inside the matrix. Recent studies, taking advantage of Convolutional Neural Networks (CNNs), have achieved encouraging progress to accomplish the RPM test. However, they partly ignore necessary inductive biases of RPM solver, such as order sensitivity within each row/column and incremental rule induction. To address this problem, in this paper we propose a Stratified Rule-Aware Network (SRAN) to generate the rule embeddings for two input sequences. Our SRAN learns multiple granularity rule embeddings at different levels, and incrementally integrates the stratified embedding flows through a gated fusion module. With the help of embeddings, a rule similarity metric is applied to guarantee that SRAN can not only be trained using a tuplet loss but also infer the best answer efficiently. We further point out the severe defects existing in the popular RAVEN dataset for RPM test, which prevent from the fair evaluation of the abstract reasoning ability. To fix the defects, we propose an answer set generation algorithm called Attribute Bisection Tree (ABT), forming an improved dataset named Impartial-RAVEN (I-RAVEN for short). Extensive experiments are conducted on both PGM and I-RAVEN datasets, showing that our SRAN outperforms the state-of-the-art models by a considerable margin.",
        "primary_area": "Computer Vision I",
        "author": "Sheng Hu; Yuqing Ma; Xianglong Liu; Yanlu Wei; Shihao Bai",
        "authorids": "",
        "aff": "Beihang University; Beihang University; Beihang University; Beihang University; Beihang University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16248/16248-13-19742-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01567-stratified-rule-aware-network-for-abstract-visual-reasoning/",
        "doi": "10.1609/aaai.v35i2.16248",
        "pdf_size": 561215
    },
    {
        "id": "03270",
        "title": "StrokeGAN: Reducing Mode Collapse in Chinese Font Generation via Stroke Encoding",
        "track": "main",
        "status": "Poster",
        "abstract": "The generation of stylish Chinese fonts is an important problem involved in many applications. Most of existing generation methods are based on the deep generative models, particularly, the generative adversarial networks (GAN) based models. However, these deep generative models may suffer from the mode collapse issue, which significantly degrades the diversity and quality of generated results. In this paper, we introduce a one-bit stroke encoding to capture the key mode information of Chinese characters and then incorporate it into CycleGAN, a popular deep generative model for Chinese font generation. As a result we propose an efficient method called StrokeGAN, mainly motivated by the observation that the stroke encoding contains amount of mode information of Chinese characters. In order to reconstruct the one-bit stroke encoding of the associated generated characters, we introduce a stroke-encoding reconstruction loss imposed on the discriminator. Equipped with such one-bit stroke encoding and stroke-encoding reconstruction loss, the mode collapse issue of CycleGAN can be significantly alleviated, with an improved preservation of strokes and diversity of generated characters. The effectiveness of StrokeGAN is demonstrated by a series of generation tasks over nine datasets with different fonts. The numerical results demonstrate that StrokeGAN generally outperforms the state-of-the-art methods in terms of content and recognition accuracies, as well as certain stroke error, and also generates more realistic characters.",
        "primary_area": "Computer Vision III",
        "author": "Jinshan Zeng; Qi Chen; Yunxin Liu; Mingwen Wang; Yuan Yao",
        "authorids": "",
        "aff": "Jiangxi Normal University; Jiangxi Normal University; Jiangxi Normal University; Jiangxi Normal University; Hong Kong University of Science and Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16438/16438-13-19932-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03270-strokegan-reducing-mode-collapse-in-chinese-font-generation-via-stroke-encoding/",
        "doi": "10.1609/aaai.v35i4.16438",
        "pdf_size": 2032053
    },
    {
        "id": "06496",
        "title": "Strong Explanations in Abstract Argumentation",
        "track": "main",
        "status": "Poster",
        "abstract": "Abstract argumentation constitutes both a major research strand and a key approach that provides the core reasoning engine for a multitude of formalisms in computational argumentation in AI. Reasoning in abstract argumentation is carried out by viewing arguments and their relationships as abstract entities, with argumentation frameworks (AFs) being the most commonly used abstract formalism. Argumentation semantics then drive the reasoning by specifying formal criteria on which sets of arguments, called extensions, can be deemed as jointly acceptable. Such extensions provide a basic way of explaining argumentative acceptance. Inspired by recent research, we present a more general class of explanations: in this paper we propose and study so-called strong explanations for explaining argumentative acceptance in AFs. A strong explanation is a set of arguments such that a target set of arguments is acceptable in each subframework containing the explaining set. We formally show that strong explanations form a larger class than extensions, in particular giving the possibility of having smaller explanations. Moreover, assuming basic properties, we show that any explanation strategy, broadly construed, is a strong explanation. We show that the increase in variety of strong explanations comes with a computational trade-off: we provide an in-depth analysis of the associated complexity, showing a jump in the polynomial hierarchy compared to extensions.",
        "primary_area": "Knowledge Representation and Reasoning",
        "author": "Markus Ulbricht; Johannes P. Wallner",
        "authorids": "",
        "aff": "Department of Computer Science, Leipzig University; Institute of Software Technology, Graz University of Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16805/16805-13-20299-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06496-strong-explanations-in-abstract-argumentation/",
        "doi": "10.1609/aaai.v35i7.16805",
        "pdf_size": 148816
    },
    {
        "id": "03234",
        "title": "Structure-Consistent Weakly Supervised Salient Object Detection with Local Saliency Coherence",
        "track": "main",
        "status": "Poster",
        "abstract": "Sparse labels have been attracting much attention in recent years. However, the performance gap between weakly supervised and fully supervised salient object detection methods is huge, and most previous weakly supervised works adopt complex training methods with many bells and whistles. In this work, we propose a one-round end-to-end training approach for weakly supervised salient object detection via scribble annotations without pre/post-processing operations or extra supervision data. Since scribble labels fail to offer detailed salient regions, we propose a local coherence loss to propagate the labels to unlabeled regions based on image features and pixel distance, so as to predict integral salient regions with complete object structures. We design a saliency structure consistency loss as self-consistent mechanism to ensure consistent saliency maps are predicted with different scales of the same image as input, which could be viewed as a regularization technique to enhance the model generalization ability. Additionally, we design an aggregation module (AGGM) to better integrate high-level features, low-level features and global context information for the decoder to aggregate various information. Extensive experiments show that our method achieves a new state-of-the-art performance on six benchmarks (e.g. for the ECSSD dataset: F\u03b2 = 0.8995, E\u03be = 0.9079 and MAE = 0.0489), with an average gain of 4.60% for F-measure, 2.05% for E-measure and 1.88% for MAE over the previous best performing method on this task. Source code is available at http://github.com/siyueyu/SCWSSOD.",
        "primary_area": "Computer Vision III",
        "author": "Siyue Yu; Bingfeng Zhang; Jimin Xiao; Eng Gee Lim",
        "authorids": "",
        "aff": "Xi'an Jiaotong-Liverpool University; Xi'an Jiaotong-Liverpool University; Xi'an Jiaotong-Liverpool University; Xi'an Jiaotong-Liverpool University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16434/16434-13-19928-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03234-structure-consistent-weakly-supervised-salient-object-detection-with-local-saliency-coherence/",
        "doi": "10.1609/aaai.v35i4.16434",
        "pdf_size": 5809551
    },
    {
        "id": "02656",
        "title": "Structure-aware Person Image Generation with Pose Decomposition and Semantic Correlation",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper we tackle the problem of pose guided person image generation, which aims to transfer a person image from the source pose to a novel target pose while maintaining the source appearance. Given the inefficiency of standard CNNs in handling large spatial transformation, we propose a structure-aware flow based method for high-quality person image generation. Specifically, instead of learning the complex overall pose changes of human body, we decompose the human body into different semantic parts (e.g., head, torso, and legs) and apply different networks to predict the flow fields for these parts separately. Moreover, we carefully design the network modules to effectively capture the local and global semantic correlations of features within and among the human parts respectively. Extensive experimental results show that our method can generate high-quality results under large pose discrepancy and outperforms state-of-the-art methods in both qualitative and quantitative comparisons.",
        "primary_area": "Computer Vision II",
        "author": "Jilin Tang; Yi Yuan; Tianjia Shao; Yong Liu; Mengmeng Wang; Kun Zhou",
        "authorids": "",
        "aff": "NetEase Fuxi AI Lab; NetEase Fuxi AI Lab; Zhejiang University; Zhejiang University; Zhejiang University; Zhejiang University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16369/16369-13-19863-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02656-structure-aware-person-image-generation-with-pose-decomposition-and-semantic-correlation/",
        "doi": "10.1609/aaai.v35i3.16369",
        "pdf_size": 4438929
    },
    {
        "id": "01789",
        "title": "Structured Co-reference Graph Attention for Video-grounded Dialogue",
        "track": "main",
        "status": "Poster",
        "abstract": "A video-grounded dialogue system referred to as the Structured Co-reference Graph Attention (SCGA) is presented for decoding the answer sequence to a question regarding a given video while keeping track of the dialogue context. Although recent efforts have made great strides in improving the quality of the response, performance is still far from satisfactory. The two main challenging issues are as follows: (1) how to deduce co-reference among multiple modalities and (2) how to reason on the rich underlying semantic structure of video with complex spatial and temporal dynamics. To this end, SCGA is based on (1) Structured Co-reference Resolver that performs dereferencing via building a structured graph over multiple modalities, (2) Spatio-temporal Video Reasoner that captures local-to-global dynamics of video via gradually neighboring graph attention. SCGA makes use of pointer network to dynamically replicate parts of the question for decoding the answer sequence. The validity of the proposed SCGA is demonstrated on AVSD@DSTC7 and AVSD@DSTC8 datasets, a challenging video-grounded dialogue benchmarks, and TVQA dataset, a large-scale videoQA benchmark. Our empirical results show that SCGA outperforms other state-of-the-art dialogue systems on both benchmarks, while extensive ablation study and qualitative analysis reveal performance gain and improved interpretability.",
        "primary_area": "Computer Vision I",
        "author": "Junyeong Kim; Sunjae Yoon; Dahyun Kim; Chang D. Yoo",
        "authorids": "",
        "aff": "Korea Advanced Institute of Science and Technology (KAIST); Korea Advanced Institute of Science and Technology (KAIST); Korea Advanced Institute of Science and Technology (KAIST); Korea Advanced Institute of Science and Technology (KAIST)",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16273/16273-13-19767-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01789-structured-co-reference-graph-attention-for-video-grounded-dialogue/",
        "doi": "10.1609/aaai.v35i2.16273",
        "pdf_size": 1058547
    },
    {
        "id": "14213",
        "title": "Style-transfer and Paraphrase: Looking for a Sensible Semantic Similarity Metric",
        "track": "main",
        "status": "Poster",
        "abstract": "The rapid development of such natural language processing tasks as style transfer, paraphrase, and machine translation often calls for the use of semantic similarity metrics. In recent years a lot of methods to measure the semantic similarity of two short texts were developed. This paper provides a comprehensive analysis for more than a dozen of such methods. Using a new dataset of fourteen thousand sentence pairs human-labeled according to their semantic similarity, we demonstrate that none of the metrics widely used in the literature is close enough to human judgment in these tasks. A number of recently proposed metrics provide comparable results, yet Word Mover Distance is shown to be the most reasonable solution to measure semantic similarity in reformulated texts at the moment.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Ivan P. Yamshchikov; Viacheslav Shibaev; Nikolay Khlebnikov; Alexey Tikhonov",
        "authorids": "",
        "aff": "Max Planck Institute for Mathematics in the Sciences; Ural Federal University; Ural Federal University; Yandex",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17672/17672-13-21166-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14213-style-transfer-and-paraphrase-looking-for-a-sensible-semantic-similarity-metric/",
        "doi": "10.1609/aaai.v35i16.17672",
        "pdf_size": 346652
    },
    {
        "id": "14558",
        "title": "Stylized Dialogue Response Generation Using Stylized Unpaired Texts",
        "track": "main",
        "status": "Poster",
        "abstract": "Generating stylized responses is essential to build intelligent and engaging dialogue systems. However, this task is far from well-explored due to the difficulties of rendering a particular style in coherent responses, especially when the target style is embedded only in unpaired texts that cannot be directly used to train the dialogue model. This paper proposes a stylized dialogue generation method that can capture stylistic features embedded in unpaired texts. Specifically, our method can produce dialogue responses that are both coherent to the given context and conform to the target style. In this study, an inverse dialogue model is first introduced to predict possible posts for the input responses. Then this inverse model is used to generate stylized pseudo dialogue pairs based on these stylized unpaired texts. Further, these pseudo pairs are employed to train the stylized dialogue model with a joint training process. A style routing approach is proposed to intensify stylistic features in the decoder. Automatic and manual evaluations on two datasets demonstrate that our method outperforms competitive baselines in producing coherent and style-intensive dialogue responses.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Yinhe Zheng; Zikai Chen; Rongsheng Zhang; Shilei Huang; Xiaoxi Mao; Minlie Huang",
        "authorids": "",
        "aff": "Tsinghua University; Tsinghua University; Fuxi AI Lab, Netease Inc.; Fuxi AI Lab, Netease Inc.; Fuxi AI Lab, Netease Inc.; Tsinghua University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17711/17711-13-21205-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14558-stylized-dialogue-response-generation-using-stylized-unpaired-texts/",
        "doi": "10.1609/aaai.v35i16.17711",
        "pdf_size": 576211
    },
    {
        "id": "00169",
        "title": "Sub-Seasonal Climate Forecasting via Machine Learning: Challenges, Analysis, and Advances",
        "track": "main",
        "status": "Poster",
        "abstract": "Sub-seasonal forecasting (SSF) focuses on predicting key variables such as temperature and precipitation on the 2-week to 2-month time scale. Skillful SSF would have immense societal value in such areas as agricultural productivity, water resource management, and emergency planning for extreme weather events. However, SSF is considered more challenging than either weather prediction or even seasonal prediction, and is still a largely understudied problem. In this paper, we carefully investigate 10 Machine Learning (ML) approaches to sub-seasonal temperature forecasting over the contiguous U.S. on the SSF dataset we collect, including a variety of climate variables from the atmosphere, ocean, and land. Because of the complicated atmosphere-land-ocean couplings and the limited amount of good quality observational data, SSF imposes a great challenge for ML despite the recent advances in various domains. Our results indicate that suitable ML models, e.g., XGBoost, to some extent, capture the predictability on sub-seasonal time scales and can outperform the climatological baselines, while Deep Learning (DL) models barely manage to match the best results with carefully designed architecture. Besides, our analysis and exploration provide insights on important aspects to improve the quality of sub-seasonal forecasts, e.g., feature representation and model architecture. The SSF dataset and code are released with this paper for use by the broader research community.",
        "primary_area": "Application Domains",
        "author": "Sijie He; Xinyan Li; Timothy DelSole; Pradeep Ravikumar; Arindam Banerjee",
        "authorids": "",
        "aff": "University of Minnesota; University of Minnesota; George Mason University; Carnegie Mellon University; University of Illinois Urbana-Champaign",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16090/16090-13-19584-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00169-sub-seasonal-climate-forecasting-via-machine-learning-challenges-analysis-and-advances/",
        "doi": "10.1609/aaai.v35i1.16090",
        "pdf_size": 4459938
    },
    {
        "id": "08465",
        "title": "Sublinear Classical and Quantum Algorithms for General Matrix Games",
        "track": "main",
        "status": "Poster",
        "abstract": "We investigate sublinear classical and quantum algorithms for matrix games, a fundamental problem in optimization and machine learning, with provable guarantees. Given a matrix, sublinear algorithms for the matrix game were previously known only for two special cases: (1) the maximizing vectors live in the L1-norm unit ball, and (2) the minimizing vectors live in either the L1- or the L2-norm unit ball. We give a sublinear classical algorithm that can interpolate smoothly between these two cases: for any fixed q between 1 and 2, we solve, within some additive error, matrix games where the minimizing vectors are in an Lq-norm unit ball. We also provide a corresponding sublinear quantum algorithm that solves the same task with a quadratic improvement in dimensions of the maximizing and minimizing vectors. Both our classical and quantum algorithms are optimal in the dimension parameters up to poly-logarithmic factors. Finally, we propose sublinear classical and quantum algorithms for the approximate Carath\u00e9odory problem and the Lq-margin support vector machines as applications.",
        "primary_area": "Machine Learning III",
        "author": "Tongyang Li; Chunhao Wang; Shouvanik Chakrabarti; Xiaodi Wu",
        "authorids": "",
        "aff": "University of Maryland Massachusetts Institute of Technology; Pennsylvania State University University of Texas at Austin; University of Maryland; University of Maryland",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17028/17028-13-20522-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08465-sublinear-classical-and-quantum-algorithms-for-general-matrix-games/",
        "doi": "10.1609/aaai.v35i10.17028",
        "pdf_size": 335055
    },
    {
        "id": "12147",
        "title": "Submodel Decomposition Bounds for Influence Diagrams",
        "track": "main",
        "status": "Poster",
        "abstract": "Influence diagrams (IDs) are graphical models for representing and reasoning with sequential decision-making problems under uncertainty. Limited memory influence diagrams (LIMIDs) model a decision-maker (DM) who forgets the history in the course of making a sequence of decisions. The standard inference task in IDs and LIMIDs is to compute the maximum expected utility (MEU), which is one of the most challenging tasks in graphical models. We present a model decomposition framework in both IDs and LIMIDs, which we call submodel decomposition that generates a tree of single-stage decision problems through a tree clustering scheme. We also develop a valuation algebra over the submodels that leads to a hierarchical message passing algorithm that propagates conditional expected utility functions over a submodel-tree as external messages. We show that the overall complexity is bounded by the maximum tree-width over the submodels, common in graphical model algorithms. Finally, we present a new method for computing upper bounds over a submodel-tree by first exponentiating the utility functions yielding a standard probabilistic graphical model as an upper bound and then applying standard variational upper bounds for the marginal MAP inference, yielding tighter upper bounds compared with state-of-the-art bounding schemes for the MEU task.",
        "primary_area": "Reasoning under Uncertainty",
        "author": "Junkyu Lee; Radu Marinescu; Rina Dechter",
        "authorids": "",
        "aff": "University of California Irvine IBM Research; IBM Research; University of California Irvine",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17442/17442-13-20936-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12147-submodel-decomposition-bounds-for-influence-diagrams/",
        "doi": "10.1609/aaai.v35i13.17442",
        "pdf_size": 464073
    },
    {
        "id": "12344",
        "title": "Submodular Span, with Applications to Conditional Data Summarization",
        "track": "main",
        "status": "Poster",
        "abstract": "As an extension to the matroid span problem, we propose the submodular span problem that involves finding a large set of elements with small gain relative to a given query set. We then propose a two-stage Submodular Span Summarization (S3) framework to achieve a form of conditional or query-focused data summarization. The first stage encourages the summary to be relevant to a given query set, and the second stage encourages the final summary to be diverse, thus achieving two important necessities for a good query-focused summary. Unlike previous methods, our framework uses only a single submodular function defined over both data and query. We analyze theoretical properties in the context of both matroids and polymatroids that elucidate when our methods should work well. We find that a scalable approximation algorithm to the polymatroid submodular span problem has good theoretical and empirical properties. We provide empirical and qualitative results on three real-world tasks: conditional multi-document summarization on the DUC 2005-2007 datasets, conditional video summarization on the UT-Egocentric dataset, and conditional image corpus summarization on the ImageNet dataset. We use deep neural networks, specifically a BERT model for text, AlexNet for video frames, and Bi-directional Generative Adversarial Networks (BiGAN) for ImageNet images to help instantiate the submodular functions. The result is a minimally supervised form of conditional summarization that matches or improves over the previous state-of-the-art.",
        "primary_area": "Search and Optimization",
        "author": "Lilly Kumari; Jeff Bilmes",
        "authorids": "",
        "aff": "University of Washington, Seattle; University of Washington, Seattle",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17465/17465-13-20959-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12344-submodular-span-with-applications-to-conditional-data-summarization/",
        "doi": "10.1609/aaai.v35i14.17465",
        "pdf_size": 496703
    },
    {
        "id": "02189",
        "title": "Subtype-aware Unsupervised Domain Adaptation for Medical Diagnosis",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent advances in unsupervised domain adaptation (UDA) show that transferable prototypical learning presents a powerful means for class conditional alignment, which encourages the closeness of cross-domain class centroids. However, the cross-domain inner-class compactness and the underlying fine-grained subtype structure remained largely underexplored. In this work, we propose to adaptively carry out the fine-grained subtype-aware alignment by explicitly enforcing the class-wise separation and subtype-wise compactness with intermediate pseudo labels. Our key insight is that the unlabeled subtypes of a class can be divergent to one another with different conditional and label shifts, while inheriting the local proximity within a subtype. The cases with or without the prior information on subtype numbers are investigated to discover the underlying subtype structure in an online fashion. The proposed subtype-aware dynamic UDA achieves promising results on a medical diagnosis task.",
        "primary_area": "Computer Vision II",
        "author": "Xiaofeng Liu; Xiongchang Liu; Bo Hu; Wenxuan Ji; Fangxu Xing; Jun Lu; Jane You; C.-C. Jay Kuo; Georges El Fakhri; Jonghye Woo",
        "authorids": "",
        "aff": "Dept. of Radiology, Massachusetts General Hospital, Harvard Medical School, Boston, MA, USA Dept. of Neurology, Beth Israel Deaconess Medical Center, Harvard Medical School, Boston, MA, USA; Dept. of Neurology, Beth Israel Deaconess Medical Center, Harvard Medical School, Boston, MA, USA China University of Mining and Technology, China; Dept. of Neurology, Beth Israel Deaconess Medical Center, Harvard Medical School, Boston, MA, USA Beijing University of Posts and Telecommunications, China; School of Artificial Intelligence, Nankai University, China; Dept. of Radiology, Massachusetts General Hospital, Harvard Medical School, Boston, MA, USA; Dept. of Neurology, Beth Israel Deaconess Medical Center, Harvard Medical School, Boston, MA, USA; Dept. of Computing, The Hong Kong Polytechnic University, Hong Kong; Dept. of Electrical and Computer Engineering, University of Southern California, Los Angeles, CA, USA; Dept. of Radiology, Massachusetts General Hospital, Harvard Medical School, Boston, MA, USA; Dept. of Radiology, Massachusetts General Hospital, Harvard Medical School, Boston, MA, USA",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16317/16317-13-19811-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02189-subtype-aware-unsupervised-domain-adaptation-for-medical-diagnosis/",
        "doi": "10.1609/aaai.v35i3.16317",
        "pdf_size": 2258392
    },
    {
        "id": "11774",
        "title": "Successor Feature Sets: Generalizing Successor Representations Across Policies",
        "track": "main",
        "status": "Poster",
        "abstract": "Successor-style representations have many advantages for reinforcement learning: for example, they can help an agent generalize from past experience to new goals, and they have been proposed as explanations of behavioral and neural data from human and animal learners. They also form a natural bridge between model-based and model-free RL methods: like the former they make predictions about future experiences, and like the latter they allow efficient prediction of total discounted rewards. However, successor-style representations are not optimized to generalize across policies: typically, we maintain a limited-length list of policies, and share information among them by representation learning or GPI. Successor-style representations also typically make no provision for gathering information or reasoning about latent variables. To address these limitations, we bring together ideas from predictive state representations, belief space value iteration, successor features, and convex analysis: we develop a new, general successor-style representation, together with a Bellman equation that connects multiple sources of information within this representation, including different latent states, policies, and reward functions. The new representation is highly expressive: for example, it lets us efficiently read off an optimal policy for a new reward function, or a policy that imitates a new demonstration. For this paper, we focus on exact computation of the new representation in small, known environments, since even this restricted setting offers plenty of interesting questions. Our implementation does not scale to large, unknown environments --- nor would we expect it to, since it generalizes POMDP value iteration, which is difficult to scale. However, we believe that future work will allow us to extend our ideas to approximate reasoning in large, unknown environments. We conduct experiments to explore which of the potential barriers to scaling are most pressing.",
        "primary_area": "Planning, Routing, and Scheduling",
        "author": "Kiant\u00e9 Brantley; Soroush Mehri; Geoff J. Gordon",
        "authorids": "",
        "aff": "The University of Maryland College Park; Microsoft Research; Microsoft Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17399/17399-13-20893-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11774-successor-feature-sets-generalizing-successor-representations-across-policies/",
        "doi": "10.1609/aaai.v35i13.17399",
        "pdf_size": 593443
    },
    {
        "id": "06093",
        "title": "Supervised Training of Dense Object Nets using Optimal Descriptors for Industrial Robotic Applications",
        "track": "main",
        "status": "Poster",
        "abstract": "Dense Object Nets (DONs) by Florence, Manuelli and Tedrake (2018) introduced dense object descriptors as a novel visual object representation for the robotics community. It is suitable for many applications including object grasping, policy learning, etc. DONs map an RGB image depicting an object into a descriptor space image, which implicitly encodes key features of an object invariant to the relative camera pose. Impressively, the self-supervised training of DONs can be applied to arbitrary objects and can be evaluated and deployed within hours. However, the training approach relies on accurate depth images and faces challenges with small, reflective objects, typical for industrial settings, when using consumer grade depth cameras. In this paper we show that given a 3D model of an object, we can generate its descriptor space image, which allows for supervised training of DONs. We rely on Laplacian Eigenmaps (LE) to embed the 3D model of an object into an optimally generated space. While our approach uses more domain knowledge, it can be efficiently applied even for smaller and reflective objects, as it does not rely on depth information. We compare the training methods on generating 6D grasps for industrial objects and show that our novel supervised training approach improves the pick-and-place performance in industry-relevant tasks.",
        "primary_area": "Intelligent Robots",
        "author": "Andras Gabor Kupcsik; Markus Spies; Alexander Klein; Marco Todescato; Nicolai Waniek; Philipp Schillinger; Mathias B\u00fcrger",
        "authorids": "",
        "aff": "Bosch Center for Artificial Intelligence; Bosch Center for Artificial Intelligence; Technische Universit\u00e4t Darmstadt; Bosch Center for Artificial Intelligence; Bosch Center for Artificial Intelligence; Bosch Center for Artificial Intelligence; Bosch Center for Artificial Intelligence",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16759/16759-13-20253-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06093-supervised-training-of-dense-object-nets-using-optimal-descriptors-for-industrial-robotic-applications/",
        "doi": "10.1609/aaai.v35i7.16759",
        "pdf_size": 4368155
    },
    {
        "id": "00408",
        "title": "Symbolic Music Generation with Transformer-GANs",
        "track": "main",
        "status": "Poster",
        "abstract": "Autoregressive models using Transformers have emerged as the  dominant  approach  for  music  generation  with  the  goal of synthesizing minute-long compositions that exhibit large-scale musical structure. These models are commonly trained by minimizing the negative log-likelihood (NLL) of the observed sequence in an autoregressive manner. Unfortunately, the  quality  of  samples  from  these  models  tends  to  degrade significantly for long sequences, a phenomenon attributed to exposure bias. Fortunately, we are able to detect these failures with classifiers trained to distinguish between real and sampled sequences, an observation that motivates our exploration of adversarial losses to complement the NLL objective. We use a pre-trained Span-BERT model for the discriminator of the GAN, which in our experiments helped with training stability. We use the Gumbel-Softmax trick to obtain a differentiable approximation of the sampling process. This makes discrete sequences amenable to optimization in GANs. In addition, we break the sequences into smaller chunks to ensure that we stay within a given memory budget. We demonstrate via human evaluations and a new discriminative metric that the music generated by our approach outperforms a baseline trained with likelihood maximization, the state-of-the-art Music Transformer, and other GANs used for sequence generation. 57% of people prefer music generated via our approach while 43% prefer Music Transformer.",
        "primary_area": "Application Domains",
        "author": "Aashiq Muhamed; Liang Li; Xingjian Shi; Suri Yaddanapudi; Wayne Chi; Dylan Jackson; Rahul Suresh; Zachary C. Lipton; Alex J. Smola",
        "authorids": "",
        "aff": "Amazon Web Services; Amazon Web Services; Amazon Web Services; Amazon Web Services; Amazon Web Services; Amazon Web Services; Amazon Web Services; Carnegie Mellon University; Amazon Web Services",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16117/16117-13-19611-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00408-symbolic-music-generation-with-transformer-gans/",
        "doi": "10.1609/aaai.v35i1.16117",
        "pdf_size": 360783
    },
    {
        "id": "11744",
        "title": "Symbolic Search for Optimal Total-Order HTN Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Symbolic search has proven to be a useful approach to optimal classical planning. In Hierarchical Task Network (HTN) planning, however, there is little work on optimal planning. One reason for this is that in HTN planning, most algorithms are based on heuristic search, and admissible heuristics have to incorporate the structure of the task network in order to be informative. In this paper, we present a novel approach to optimal (totally-ordered) HTN planning, which is based on symbolic search. An empirical analysis shows that our symbolic approach outperforms the current state of the art for optimal totally-ordered HTN planning.",
        "primary_area": "Planning, Routing, and Scheduling",
        "author": "Gregor Behnke; David Speck",
        "authorids": "",
        "aff": "University of Freiburg; University of Freiburg",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17396/17396-13-20890-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11744-symbolic-search-for-optimal-total-order-htn-planning/",
        "doi": "10.1609/aaai.v35i13.17396",
        "pdf_size": 274242
    },
    {
        "id": "11972",
        "title": "Symbolic Search for Oversubscription Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "The objective of optimal oversubscription planning is to find a plan that yields an end state with a maximum utility while keeping plan cost under a certain bound. In practice, the situation occurs whenever a large number of possible, often competing goals of varying value exist, or the resources are not sufficient to achieve all goals. In this paper, we investigate the use of symbolic search for optimal oversubscription planning. Specifically, we show how to apply symbolic forward search to oversubscription planning tasks and prove that our approach is sound, complete and optimal. An empirical analysis shows that our symbolic approach favorably competes with explicit state-space heuristic search, the current state of the art for oversubscription planning.",
        "primary_area": "Planning, Routing, and Scheduling",
        "author": "David Speck; Michael Katz",
        "authorids": "",
        "aff": "University of Freiburg; IBM T. J. Watson Research Center",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17422/17422-13-20916-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11972-symbolic-search-for-oversubscription-planning/",
        "doi": "10.1609/aaai.v35i13.17422",
        "pdf_size": 332775
    },
    {
        "id": "03922",
        "title": "Symmetric Component Caching for Model Counting on Combinatorial Instances",
        "track": "main",
        "status": "Poster",
        "abstract": "Given a propositional formula \u03c8, the model counting problem, also referred to as #SAT, seeks to compute the number of satisfying assignments (or models) of \u03c8. Modern search-based model counting algorithms are built on conflict-driven clause learning, combined with the caching of certain subformulas (called components) encountered during the search process. Despite significant progress in these algorithms over the years, state-of-the-art model counters often struggle to handle large but structured instances that typically arise in combinatorial settings. Motivated by the observation that these counters do not exploit the inherent symmetries exhibited in such instances, we revisit the component caching architecture employed in current counters and introduce a novel caching scheme that focuses on identifying symmetric components. We first prove the soundness of our approach, and then integrate it into the state-of-the-art model counter GANAK. Our extensive experiments on hard combinatorial instances demonstrate that the resulting counter, SymGANAK, leads to improvements over GANAK both in terms of PAR-2 score and the number of instances solved.",
        "primary_area": "Constraint Satisfaction and Optimization",
        "author": "Timothy van Bremen; Vincent Derkinderen; Shubham Sharma; Subhajit Roy; Kuldeep S. Meel",
        "authorids": "",
        "aff": "KU Leuven; KU Leuven; Nutanix Software India Pvt. Ltd.; Indian Institute of Technology Kanpur; National University of Singapore",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16511/16511-13-20005-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03922-symmetric-component-caching-for-model-counting-on-combinatorial-instances/",
        "doi": "10.1609/aaai.v35i5.16511",
        "pdf_size": 1649732
    },
    {
        "id": "12267",
        "title": "Symmetry Breaking for k-Robust Multi-Agent Path Finding",
        "track": "main",
        "status": "Poster",
        "abstract": "During Multi-Agent Path Finding (MAPF) problems, agentscan  be  delayed  by  unexpected  events.  To  address  suchsituations  recent  work  describes k-Robust  Conflict-BasedSearch (k-CBS): an algorithm that produces coordinated andcollision-free plan that is robust for up tokdelays. In thiswork we introducing a variety of pairwise symmetry break-ing  constraints,  specific  tok-robust  planning,  that  can  effi-ciently find compatible and optimal paths for pairs of con-flicting  agents.  We  give  a  thorough  description  of  the  newconstraints and report large improvements to success rate ina range of domains including: (i) classic MAPF benchmarks;(ii)  automated  warehouse  domains  and;  (iii)  on  maps  fromthe  2019  Flatland  Challenge,  a  recently  introduced  railwaydomain wherek-robust planning can be fruitfully applied toschedule trains.",
        "primary_area": "Search and Optimization",
        "author": "Zhe Chen; Daniel D. Harabor; Jiaoyang Li; Peter J. Stuckey",
        "authorids": "",
        "aff": "Monash University; Monash University; University of Southern California; Monash University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17456/17456-13-20950-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12267-symmetry-breaking-for-k-robust-multi-agent-path-finding/",
        "doi": "10.1609/aaai.v35i14.17456",
        "pdf_size": 2292158
    },
    {
        "id": "11334",
        "title": "Synchronous Dynamical Systems on Directed Acyclic Graphs: Complexity and Algorithms",
        "track": "main",
        "status": "Poster",
        "abstract": "Discrete dynamical systems serve as useful formal models to study diffusion phenomena in social networks.  Motivated by applications in systems biology, several recent papers have studied algorithmic and complexity aspects of diffusion problems for dynamical systems whose underlying graphs are directed, and may contain directed cycles.  Such problems can be regarded as reachability problems in the phase space of the corresponding dynamical system. We show that computational intractability results for reachability problems hold even for dynamical systems on directed acyclic graphs (dags).  We also show that for dynamical systems on dags where each local function is monotone, the reachability problem can be solved efficiently.",
        "primary_area": "Multiagent Systems",
        "author": "Daniel J. Rosenkrantz; Madhav Marathe; S. S. Ravi; Richard E. Stearns",
        "authorids": "",
        "aff": "Bicomplexity Institute and Initiative, University of Virginia and Computer Science Dept., University at Albany -- SUNY; Biocomplexity Institute & Initiative and Computer Science Dept., University of Virginia; Biocomplexity Institute and Initiative, University of Virginia and Computer Science Dept., University at Albany -- SUNY; Biocomplexity Institute and Initiative, University of Virginia and Computer Science Dept., University at Albany -- SUNY",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17351/17351-13-20845-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11334-synchronous-dynamical-systems-on-directed-acyclic-graphs-complexity-and-algorithms/",
        "doi": "10.1609/aaai.v35i13.17351",
        "pdf_size": 152584
    },
    {
        "id": "12981",
        "title": "Synchronous Interactive Decoding for Multilingual Neural Machine Translation",
        "track": "main",
        "status": "Poster",
        "abstract": "To simultaneously translate a source language into multiple different target languages is one of the most common scenarios of multilingual translation. However, existing methods cannot make full use of translation model information during decoding, such as intra-lingual and inter-lingual future information, and therefore may suffer from some issues like the unbalanced outputs. In this paper, we present a new approach for synchronous interactive multilingual neural machine translation (SimNMT), which predicts each target language output simultaneously and interactively using historical and future information of all target languages. Specifically, we first propose a synchronous cross-interactive decoder in which generation of each target output does not only depend on its generated sequences, but also relies on its future information, as well as history and future contexts of other target languages. Then, we present a new interactive multilingual beam search algorithm that enables synchronous interactive decoding of all target languages in a single model. We take two target languages as an example to illustrate and evaluate the proposed SimNMT model on IWSLT datasets. The experimental results demonstrate that our method achieves significant improvements over several advanced NMT and MNMT models.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Hao He; Qian Wang; Zhipeng Yu; Yang Zhao; Jiajun Zhang; Chengqing Zong",
        "authorids": "",
        "aff": "National Laboratory of Pattern Recognition, CASIA, Beijing, China School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; National Laboratory of Pattern Recognition, CASIA, Beijing, China School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; Beijing Fanyu Technology Co., Ltd; National Laboratory of Pattern Recognition, CASIA, Beijing, China School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; National Laboratory of Pattern Recognition, CASIA, Beijing, China School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; National Laboratory of Pattern Recognition, CASIA, Beijing, China School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17535/17535-13-21029-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12981-synchronous-interactive-decoding-for-multilingual-neural-machine-translation/",
        "doi": "10.1609/aaai.v35i14.17535",
        "pdf_size": 702204
    },
    {
        "id": "08420",
        "title": "Synergetic Learning of Heterogeneous Temporal Sequences for Multi-Horizon Probabilistic Forecasting",
        "track": "main",
        "status": "Poster",
        "abstract": "Time-series is ubiquitous across applications, such as transportation, finance and healthcare. Time-series is often influenced by external factors, especially in the form of asynchronous events, making forecasting difficult. However, existing models are mainly designated for either synchronous time-series or asynchronous event sequence, and can hardly provide a synthetic way to capture the relation between them. We propose Variational Synergetic Multi-Horizon Network (VSMHN), a novel deep conditional generative model. To learn complex correlations across heterogeneous sequences, a tailored encoder is devised to combine the advances in deep point processes models and variational recurrent neural networks. In addition, an aligned time coding and an auxiliary transition scheme are carefully devised for batched training on unaligned sequences. Our model can be trained effectively using stochastic variational inference and generates probabilistic predictions with Monte-Carlo simulation. Furthermore, our model produces accurate, sharp and more realistic probabilistic forecasts. We also show that modeling asynchronous event sequences is crucial for multi-horizon time-series forecasting.",
        "primary_area": "Machine Learning III",
        "author": "Longyuan Li; Jihai Zhang; Junchi Yan; Yaohui Jin; Yunhao Zhang; Yanjie Duan; Guangjian Tian",
        "authorids": "",
        "aff": "MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University State Key Lab of Advanced Optical Communication System and Network, Shanghai Jiao Tong University; Department of Computer Science and Engineering, Shanghai Jiao Tong University; MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University Department of Computer Science and Engineering, Shanghai Jiao Tong University; MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University State Key Lab of Advanced Optical Communication System and Network, Shanghai Jiao Tong University; Department of Computer Science and Engineering, Shanghai Jiao Tong University; Huawei Noah\u2019s Ark Lab; Huawei Noah\u2019s Ark Lab",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17023/17023-13-20517-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08420-synergetic-learning-of-heterogeneous-temporal-sequences-for-multi-horizon-probabilistic-forecasting/",
        "doi": "10.1609/aaai.v35i10.17023",
        "pdf_size": 3445640
    },
    {
        "id": "11895",
        "title": "Synthesis of Search Heuristics for Temporal Planning via Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Automated temporal planning is the problem of synthesizing, starting from a model of a system, a course of actions to achieve a desired goal when temporal constraints, such as deadlines, are present in the problem. Despite considerable successes in the literature, scalability is still a severe limitation for existing planners, especially when confronted with real-world, industrial scenarios.  In this paper, we aim at exploiting recent advances in reinforcement learning, for the synthesis of heuristics for temporal planning. Starting from a set of problems of interest for a specific domain, we use a customized reinforcement learning algorithm to construct a value function that is able to estimate the expected reward for as many problems as possible. We use a reward schema that captures the semantics of the temporal planning problem and we show how the value function can be transformed in a planning heuristic for a semi-symbolic heuristic search exploration of the planning model. We show on two case-studies how this method can widen the reach of current temporal planners with encouraging results.",
        "primary_area": "Planning, Routing, and Scheduling",
        "author": "Andrea Micheli; Alessandro Valentini",
        "authorids": "",
        "aff": "Fondazione Bruno Kessler; Fondazione Bruno Kessler",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17413/17413-13-20907-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11895-synthesis-of-search-heuristics-for-temporal-planning-via-reinforcement-learning/",
        "doi": "10.1609/aaai.v35i13.17413",
        "pdf_size": 381696
    },
    {
        "id": "02384",
        "title": "TDAF: Top-Down Attention Framework for Vision Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "Human attention mechanisms often work in a top-down manner, yet it is not well explored in vision research. Here, we propose the Top-Down Attention Framework (TDAF) to capture top-down attentions, which can be easily adopted in most existing models. The designed Recursive Dual-Directional Nested Structure in it forms two sets of orthogonal paths, recursive and structural ones, where bottom-up spatial features and top-down attention features are extracted respectively. Such spatial and attention features are nested deeply, therefore, the proposed framework works in a mixed top-down and bottom-up manner. Empirical evidence shows that our TDAF can capture effective stratified attention information and boost performance. ResNet with TDAF achieves 2.0% improvements on ImageNet. For object detection, the performance is improved by 2.7% AP over FCOS. For pose estimation, TDAF improves the baseline by 1.6%. And for action recognition, the 3D-ResNet adopting TDAF achieves improvements of 1.7% accuracy.",
        "primary_area": "Computer Vision II",
        "author": "Bo Pang; Yizhuo Li; Jiefeng Li; Muchen Li; Hanwen Cao; Cewu Lu",
        "authorids": "",
        "aff": "Shanghai Jiao Tong University; Shanghai Jiao Tong University; Shanghai Jiao Tong University; Huazhong University Of Science and Technology; Shanghai Jiao Tong University; Shanghai Jiao Tong University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16339/16339-13-19833-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02384-tdaf-top-down-attention-framework-for-vision-tasks/",
        "doi": "10.1609/aaai.v35i3.16339",
        "pdf_size": 1828649
    },
    {
        "id": "07046",
        "title": "THOR, Trace-based Hardware-driven Layer-Oriented Natural Gradient Descent Computation",
        "track": "main",
        "status": "Poster",
        "abstract": "It is well-known that second-order optimizer can accelerate the training of deep neural networks, however, the huge computation cost of second-order optimization makes it impractical to apply in real practice. In order to reduce the cost, many methods have been proposed to approximate a second-order matrix. Inspired by KFAC, we propose a novel Trace-based Hardware-driven layer-ORiented Natural Gradient Descent Computation method, called THOR, to make the second-order optimization applicable in the real application models. Specifically, we gradually increase the update interval and use the matrix trace to determine which blocks of Fisher Information Matrix (FIM) need to be updated. Moreover, by resorting the power of hardware, we have designed a Hardware-driven approximation method for computing FIM to achieve better performance. To demonstrate the effectiveness of THOR, we have conducted extensive experiments. The results show that training ResNet-50 on ImageNet with THOR only takes 66.7 minutes to achieve a top-1 accuracy of 75.9 % under an 8 Ascend 910 environment with MindSpore, a new deep learning computing framework. Moreover, with more computational resources, THOR can only takes 2.7 minutes to 75.9 % with 256 Ascend 910.",
        "primary_area": "Machine Learning I",
        "author": "Mengyun Chen; Kaixin Gao; Xiaolei Liu; Zidong Wang; Ningxi Ni; Qian Zhang; Lei  Chen; Chao Ding; Zhenghai Huang; Min Wang; Shuangling Wang; Fan Yu; Xinyuan Zhao; Dachuan Xu",
        "authorids": "",
        "aff": "Huawei Technologies Co. Ltd; Tianjin University; Tianjin University; Huawei Technologies Co. Ltd; Huawei Technologies Co. Ltd; Beijing University of Technology; Hong Kong University of Science and Technology; Chinese Academy of Sciences; Tianjin University; Huawei Technologies Co. Ltd; Huawei Technologies Co. Ltd; Huawei Technologies Co. Ltd; Beijing University of Technology; Beijing University of Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16867/16867-13-20361-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07046-thor-trace-based-hardware-driven-layer-oriented-natural-gradient-descent-computation/",
        "doi": "10.1609/aaai.v35i8.16867",
        "pdf_size": 1633737
    },
    {
        "id": "02082",
        "title": "TIME: Text and Image Mutual-Translation Adversarial Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Focusing on text-to-image (T2I) generation, we propose Text and Image Mutual-Translation Adversarial Networks (TIME), a lightweight but effective model that jointly learns a T2I generator G and an image captioning discriminator D under the Generative Adversarial Network framework. While previous methods tackle the T2I problem as a uni-directional task and use pre-trained language models to enforce the image--text consistency, TIME requires neither extra modules nor pre-training. We show that the performance of G can be boosted substantially by training it jointly with D as a language model. Specifically, we adopt Transformers to model the cross-modal connections between the image features and word embeddings, and design an annealing conditional hinge loss that dynamically balances the adversarial learning. In our experiments, TIME achieves state-of-the-art (SOTA) performance on the CUB dataset (Inception Score of 4.91 and Fr\u00e9chet Inception Distance of 14.3 on CUB), and shows promising performance on MS-COCO dataset on image captioning and downstream vision-language tasks.",
        "primary_area": "Computer Vision II",
        "author": "Bingchen Liu; Kunpeng Song; Yizhe Zhu; Gerard de Melo; Ahmed Elgammal",
        "authorids": "",
        "aff": "Department of Computer Science, Rutgers University; Department of Computer Science, Rutgers University; Department of Computer Science, Rutgers University; Department of Computer Science, Rutgers University; Department of Computer Science, Rutgers University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16305/16305-13-19799-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02082-time-text-and-image-mutual-translation-adversarial-networks/",
        "doi": "10.1609/aaai.v35i3.16305",
        "pdf_size": 2057261
    },
    {
        "id": "08538",
        "title": "TRQ: Ternary Neural Networks With Residual Quantization",
        "track": "main",
        "status": "Poster",
        "abstract": "Ternary neural networks (TNNs) are potential for network acceleration by reducing the full-precision weights in network to ternary ones, e.g., {-1,0,1}. However, existing TNNs are mostly calculated based on rule-of-thumb quantization methods by simply thresholding operations, which  causes a significant accuracy loss. In this paper, we introduce a stem-residual framework which provides new  insight into Ternary quantization, termed Residual Quantization (TRQ), to achieve more powerful TNNs. Rather than directly thresholding operations, TRQ recursively performs quantization on full-precision weights for a  refined reconstruction by combining the binarized stem and residual parts. With such a unique quantization process, TRQ  endows the quantizer with high flexibility and precision. Our TRQ is generic, which can be easily extended to multiple bits through recursively encoded residual for  a better recognition accuracy. Extensive experimental results demonstrate that the proposed method yields great recognition accuracy while being accelerated.",
        "primary_area": "Machine Learning III",
        "author": "Yue Li; Wenrui Ding; Chunlei Liu; Baochang Zhang; Guodong Guo",
        "authorids": "",
        "aff": "Beihang University; Beihang University; Beihang University; Beihang University; Institute of Deep Learning,Baidu Research and National Engineering Laboratory for Deep Learning Technology and Application",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17036/17036-13-20530-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08538-trq-ternary-neural-networks-with-residual-quantization/",
        "doi": "10.1609/aaai.v35i10.17036",
        "pdf_size": 818463
    },
    {
        "id": "13297",
        "title": "TSQA: Tabular Scenario Based Question Answering",
        "track": "main",
        "status": "Poster",
        "abstract": "Scenario-based question answering (SQA) has attracted an increasing research interest. Compared with the well-studied machine reading comprehension (MRC), SQA is a more challenging task: a scenario may contain not only a textual passage to read but also structured data like tables, i.e., tabular scenario based question answering (TSQA). AI applications of TSQA such as answering multiple-choice questions in high-school exams require synthesizing data in multiple cells and combining tables with texts and domain knowledge to infer answers. To support the study of this task, we construct GeoTSQA. This dataset contains 1k real questions contextualized by tabular scenarios in the geography domain. To solve the task, we extend state-of-the-art MRC methods with TTGen, a novel table-to-text generator. It generates sentences from variously synthesized tabular data and feeds the downstream MRC method with the most useful sentences. Its sentence ranking model fuses the information in the scenario, question, and domain knowledge. Our approach outperforms a variety of strong baseline methods on GeoTSQA.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Xiao Li; Yawei Sun; Gong Cheng",
        "authorids": "",
        "aff": "State Key Laboratory for Novel Software Technology, Nanjing University, China; State Key Laboratory for Novel Software Technology, Nanjing University, China; State Key Laboratory for Novel Software Technology, Nanjing University, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17570/17570-13-21064-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13297-tsqa-tabular-scenario-based-question-answering/",
        "doi": "10.1609/aaai.v35i15.17570",
        "pdf_size": 301864
    },
    {
        "id": "14402",
        "title": "TaLNet: Voice Reconstruction from Tongue and Lip Articulation with Transfer Learning from Text-to-Speech Synthesis",
        "track": "main",
        "status": "Poster",
        "abstract": "This  paper  presents  TaLNet,  a  model  for  voice  reconstruction with ultrasound tongue and optical lip videos as inputs. TaLNet  is  based  on  an  encoder-decoder  architecture.  Separate  encoders  are  dedicated  to  processing  the  tongue  and lip data streams respectively. The decoder predicts acoustic features conditioned on encoder outputs and speaker codes.To mitigate for having only relatively small amounts of dual articulatory-acoustic data available for training, and since our task here shares with text-to-speech (TTS) the common goal of  speech  generation,  we  propose  a  novel  transfer  learning strategy to exploit the much larger amounts of acoustic-only data  available  to  train  TTS  models.  For  this,  a  Tacotron  2 TTS model is first trained, and then the parameters of its decoder are transferred to the TaLNet decoder. We have evaluated our approach on an unconstrained multi-speaker voice recovery task. Our results show the effectiveness of both the proposed  model  and  the  transfer  learning  strategy.  Speech reconstructed  using  our  proposed  method  significantly  outperformed all baselines (DNN, BLSTM and without transfer learning) in terms of both naturalness and intelligibility. When using an ASR model decoding the recovery speech, the WER of our proposed method is relatively reduced over 30% compared to baselines.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Jing-Xuan Zhang; Korin Richmond; Zhen-Hua Ling; Lirong Dai",
        "authorids": "",
        "aff": "National Engineering Laboratory for Speech and Language Information Processing, University of Science and Technology of China, P. R. China The Center for Speech Technology Research, University of Edinburgh, UK; The Center for Speech Technology Research, University of Edinburgh, UK; National Engineering Laboratory for Speech and Language Information Processing, University of Science and Technology of China, P. R. China; National Engineering Laboratory for Speech and Language Information Processing, University of Science and Technology of China, P. R. China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17693/17693-13-21187-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14402-talnet-voice-reconstruction-from-tongue-and-lip-articulation-with-transfer-learning-from-text-to-speech-synthesis/",
        "doi": "10.1609/aaai.v35i16.17693",
        "pdf_size": 379248
    },
    {
        "id": "06679",
        "title": "TabNet: Attentive Interpretable Tabular Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a novel high-performance and interpretable canonical deep tabular data learning architecture, TabNet. TabNet uses sequential attention to choose which features to reason from at each decision step, enabling interpretability and more efficient learning as the learning capacity is used for the most salient features. We demonstrate that TabNet outperforms other variants on a wide range of non-performance-saturated tabular datasets and yields interpretable feature attributions plus insights into its global behavior. Finally, we demonstrate self-supervised learning for tabular data, significantly improving performance when unlabeled data is abundant.",
        "primary_area": "Machine Learning I",
        "author": "Sercan \u00d6. Arik; Tomas Pfister",
        "authorids": "",
        "aff": "Google; Google",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16826/16826-13-20320-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06679-tabnet-attentive-interpretable-tabular-learning/",
        "doi": "10.1609/aaai.v35i8.16826",
        "pdf_size": 1231096
    },
    {
        "id": "10183",
        "title": "Tackling Instance-Dependent Label Noise via a Universal Probabilistic Model",
        "track": "main",
        "status": "Poster",
        "abstract": "The drastic increase of data quantity often brings the severe decrease of data quality, such as incorrect label annotations. It poses a great challenge for robustly training Deep Neural Networks (DNNs). Existing learning methods with label noise either employ ad-hoc heuristics or restrict to specific noise assumptions. However, more general situations, such as instance-dependent label noise, have not been fully explored, as scarce studies focus on their label corruption process. By categorizing instances into confusing and unconfusing instances, this paper proposes a simple yet universal probabilistic model, which explicitly relates noisy labels to their instances. The resultant model can be realized by DNNs, where the training procedure is accomplished by employing a novel alternating optimization algorithm. Experiments on datasets with both synthetic and real-world label noise verify the proposed method yields significant improvements on robustness over state-of-the-art counterparts.",
        "primary_area": "Machine Learning IV",
        "author": "Qizhou Wang; Bo Han; Tongliang Liu; Gang Niu; Jian Yang; Chen Gong",
        "authorids": "",
        "aff": "Key Laboratory of Intelligent Perception and Systems for High-Dimensional Information of MoE, School of Computer Science and Engineering, Nanjing University of Science and Technology Department of Computer Science, Hong Kong Baptist University; Department of Computer Science, Hong Kong Baptist University; Trustworthy Machine Learning Lab, School of Computer Science, Faculty of Engineering, The University of Sydney; RIKEN Center for Advanced Intelligence Project (AIP); Key Laboratory of Intelligent Perception and Systems for High-Dimensional Information of MoE, School of Computer Science and Engineering, Nanjing University of Science and Technology; Key Laboratory of Intelligent Perception and Systems for High-Dimensional Information of MoE, School of Computer Science and Engineering, Nanjing University of Science and Technology Department of Computing, Hong Kong Polytechnic University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17221/17221-13-20715-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10183-tackling-instance-dependent-label-noise-via-a-universal-probabilistic-model/",
        "doi": "10.1609/aaai.v35i11.17221",
        "pdf_size": 722713
    },
    {
        "id": "08776",
        "title": "Tailoring Embedding Function to Heterogeneous Few-Shot Tasks by Global and Local Feature Adaptors",
        "track": "main",
        "status": "Poster",
        "abstract": "Few-Shot Learning (FSL) is essential for visual recognition. Many methods tackle this challenging problem via learning an embedding function from seen classes and transfer it to unseen classes with a few labeled instances. Researchers recently found it beneficial to incorporate task-specific feature adaptation into FSL models, which produces the most representative features for each task. However, these methods ignore the diversity of classes and apply a global transformation to the task. In this paper, we propose Global and Local Feature Adaptor (GLoFA), a unifying framework that tailors the instance representation to specific tasks by global and local feature adaptors. We claim that class-specific local transformation helps to improve the representation ability of feature adaptor.  Global masks tend to capture sketchy patterns, while local masks focus on detailed characteristics. A strategy to measure the relationship between instances adaptively based on the characteristics of both tasks and classes endow GLoFA with the ability to handle mix-grained tasks. GLoFA outperforms other methods on a heterogeneous task distribution and achieves competitive results on benchmark datasets.",
        "primary_area": "Machine Learning III",
        "author": "Su Lu; Han-Jia Ye; De-Chuan Zhan",
        "authorids": "",
        "aff": "Nanjing University; Nanjing University; Nanjing University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17063/17063-13-20557-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08776-tailoring-embedding-function-to-heterogeneous-few-shot-tasks-by-global-and-local-feature-adaptors/",
        "doi": "10.1609/aaai.v35i10.17063",
        "pdf_size": 5491768
    },
    {
        "id": "05768",
        "title": "Targeted Negative Campaigning: Complexity and Approximations",
        "track": "main",
        "status": "Poster",
        "abstract": "Given the ubiquity of negative campaigning in recent political elections, we find it important to study its properties from a computational perspective. To this end, we present a model where elections can be manipulated by convincing voters to demote specific non-favored candidates, and study its properties in the classic setting of scoring rules.  When the goal is constructive (making a preferred candidate win),  we prove that finding such a demotion strategy is easy for Plurality and Veto, while generally hard for t-approval and Borda. We also provide a t-factor approximation for t-approval for every fixed t, and a 3-factor approximation algorithm for Borda. Interestingly enough - following recent trends in political science that show that the effectiveness of negative campaigning depends on the type of candidate and demographic - when assigning varying prices to different possible demotion operations, we are able to provide inapproximability results.   When the goal is destructive (making the leading opponent lose), we show that the problem is easy for a broad class of scoring rules.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "\u202aAvishai Zagoury\u202c\u200f; Orgad Keller; Avinatan Hassidim; Noam Hazon",
        "authorids": "",
        "aff": "Bar-Ilan University; Google Research; Google Research Bar-Ilan University; Ariel University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16723/16723-13-20217-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05768-targeted-negative-campaigning-complexity-and-approximations/",
        "doi": "10.1609/aaai.v35i6.16723",
        "pdf_size": 187251
    },
    {
        "id": "08723",
        "title": "Task Aligned Generative Meta-learning for Zero-shot Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Zero-shot learning (ZSL) refers to the problem of learning to classify instances from novel classes (unseen) that are absent in the training set (seen). Most ZSL methods infer the correlation between visual features and attributes to train the classifier for unseen classes. They may have a strong bias towards seen classes during training. Meta-learning has been introduced to mitigate the basis, but meta-ZSL methods are inapplicable when tasks used for training are sampled from diverse distributions. In this regard, we propose a novel Task-aligned Generative Meta-learning model for Zero-shot learning (TGMZ), aiming to mitigate the potentially biased training and to enable meta-ZSL to accommodate real-world datasets that contain diverse distributions. Specifically, TGMZ incorporates an attribute-conditioned task-wise distribution alignment network that projects tasks into a unified distribution to deliver an unbiased model. Our experiments show TGMZ achieves a relative improvement of 2.1%, 3.0%, 2.5%, and 7.6% over state-of-the-art algorithms on AWA1, AWA2, CUB, and aPY datasets, respectively. Overall, TGMZ outperforms competitors by 3.6% in the generalized zero-shot learning (GZSL) setting and 7.9% in our proposed fusion-ZSL setting.",
        "primary_area": "Machine Learning III",
        "author": "Zhe Liu; Yun Li; Lina Yao; Xianzhi Wang; Guodong Long",
        "authorids": "",
        "aff": "University of New South Wales; Unversity of New South Wales; University of New South Wales; University of Technology Sydney; University of Technology Sydney",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17057/17057-13-20551-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08723-task-aligned-generative-meta-learning-for-zero-shot-learning/",
        "doi": "10.1609/aaai.v35i10.17057",
        "pdf_size": 6420063
    },
    {
        "id": "10682",
        "title": "Task Cooperation for Semi-Supervised Few-Shot Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Training a model with limited data is an essential task for machine learning and visual recognition. Few-shot learning approaches meta-learn a task-level inductive bias from SEEN class few-shot tasks, and the meta-model is expected to facilitate the few-shot learning with UNSEEN classes. Inspired by the idea that unlabeled data can be utilized to smooth the model space in traditional semi-supervised learning, we propose TAsk COoperation (TACO) which takes advantage of unsupervised tasks to smooth the meta-model space. Specifically, we couple the labeled support set in a few-shot task with easily-collected unlabeled instances, prediction agreement on which encodes the relationship between tasks. The learned smooth meta-model promotes the generalization ability on supervised UNSEEN few-shot tasks. The state-of-the-art few-shot classification results on MiniImageNet and TieredImageNet verify the superiority of TACO to leverage unlabeled data and task relationship in meta-learning.",
        "primary_area": "Machine Learning V",
        "author": "Han-Jia Ye; Xin-Chun Li; De-Chuan Zhan",
        "authorids": "",
        "aff": "State Key Laboratory for Novel Software Technology, Nanjing University; State Key Laboratory for Novel Software Technology, Nanjing University; State Key Laboratory for Novel Software Technology, Nanjing University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17277/17277-13-20771-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10682-task-cooperation-for-semi-supervised-few-shot-learning/",
        "doi": "10.1609/aaai.v35i12.17277",
        "pdf_size": 17595490
    },
    {
        "id": "09028",
        "title": "Task-Agnostic Exploration via Policy Gradient of a Non-Parametric State Entropy Estimate",
        "track": "main",
        "status": "Poster",
        "abstract": "In a reward-free environment, what is a suitable intrinsic objective for an agent to pursue so that it can learn an optimal task-agnostic exploration policy? In this paper, we argue that the entropy of the state distribution induced by finite-horizon trajectories is a sensible target. Especially, we present a novel and practical policy-search algorithm, Maximum Entropy POLicy optimization (MEPOL), to learn a policy that maximizes a non-parametric, $k$-nearest neighbors estimate of the state distribution entropy. In contrast to known methods, MEPOL is completely model-free as it requires neither to estimate the state distribution of any policy nor to model transition dynamics. Then, we empirically show that MEPOL allows learning a maximum-entropy exploration policy in high-dimensional, continuous-control domains, and how this policy facilitates learning meaningful reward-based tasks downstream.",
        "primary_area": "Machine Learning III",
        "author": "Mirco Mutti; Lorenzo Pratissoli; Marcello Restelli",
        "authorids": "",
        "aff": "Politecnico di Milano Universit\u00e0 di Bologna; Politecnico di Milano; Politecnico di Milano",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17091/17091-13-20585-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09028-task-agnostic-exploration-via-policy-gradient-of-a-non-parametric-state-entropy-estimate/",
        "doi": "10.1609/aaai.v35i10.17091",
        "pdf_size": 786800
    },
    {
        "id": "02710",
        "title": "Task-Independent Knowledge Makes for Transferable Representations for Generalized Zero-Shot Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Generalized Zero-Shot Learning (GZSL) targets recognizing new categories by learning transferable image representations. Existing methods find that, by aligning image representations with corresponding semantic labels, the semantic-aligned representations can be transferred to unseen categories. However, supervised by only seen category labels, the learned semantic knowledge is highly task-specific, which makes image representations biased towards seen categories. In this paper, we propose a novel Dual-Contrastive Embedding Network (DCEN) that simultaneously learns task-specific and task-independent knowledge via semantic alignment and instance discrimination. First, DCEN leverages task labels to cluster representations of the same semantic category by cross-modal contrastive learning and exploring semantic-visual complementarity. Besides task-specific knowledge, DCEN then introduces task-independent knowledge by attracting representations of different views of the same image and repelling representations of different images. Compared to high-level seen category supervision, this instance discrimination supervision encourages DCEN to capture low-level visual knowledge, which is less biased toward seen categories and alleviates the representation bias. Consequently, the task-specific and task-independent knowledge jointly make for transferable representations of DCEN, which obtains averaged 4.1% improvement on four public benchmarks.",
        "primary_area": "Computer Vision II",
        "author": "Chaoqun Wang; Xuejin Chen; Shaobo Min; Xiaoyan Sun; Houqiang Li",
        "authorids": "",
        "aff": "School of Data Science, University of Science and Technology of China, Hefei, Anhui, China The National Engineering Laboratory for Brain-inspired Intelligence Technology and Application, University of Science and Technology of China, Hefei, Anhui, China; School of Data Science, University of Science and Technology of China, Hefei, Anhui, China The National Engineering Laboratory for Brain-inspired Intelligence Technology and Application, University of Science and Technology of China, Hefei, Anhui, China; The National Engineering Laboratory for Brain-inspired Intelligence Technology and Application, University of Science and Technology of China, Hefei, Anhui, China; The National Engineering Laboratory for Brain-inspired Intelligence Technology and Application, University of Science and Technology of China, Hefei, Anhui, China; School of Data Science, University of Science and Technology of China, Hefei, Anhui, China The National Engineering Laboratory for Brain-inspired Intelligence Technology and Application, University of Science and Technology of China, Hefei, Anhui, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16375/16375-13-19869-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02710-task-independent-knowledge-makes-for-transferable-representations-for-generalized-zero-shot-learning/",
        "doi": "10.1609/aaai.v35i3.16375",
        "pdf_size": 464910
    },
    {
        "id": "04662",
        "title": "Taxonomy Completion via Triplet Matching Network",
        "track": "main",
        "status": "Poster",
        "abstract": "Automatically constructing taxonomy finds many applications in e-commerce and web search. One critical challenge is as data and business scope grow in real applications, new concepts are emerging and needed to be added to the existing taxonomy. Previous approaches focus on the taxonomy expansion, i.e. finding an appropriate hypernym concept from the taxonomy for a new query concept. In this paper, we formulate a new task, \u201ctaxonomy completion\u201d, by discovering both the hypernym and hyponym concepts for a query. We propose Triplet Matching Network (TMN), to find the appropriate  pairs for a given query concept. TMN consists of one primal scorer and multiple auxiliary scorers. These auxiliary scorers capture various fine-grained signals (e.g., query to hypernym or query to hyponym semantics), and the primal scorer makes a holistic prediction on  triplet based on the internal feature representations of all auxiliary scorers. Also, an innovative channel-wise gating mechanism that retains task-specific information in concept representations is introduced to further boost model performance. Experiments on four real-world large-scale datasets show that TMN achieves the best performance on both taxonomy completion task and the previous taxonomy expansion task, outperforming existing methods.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Jieyu Zhang; Xiangchen Song; Ying Zeng; Jiaze Chen; Jiaming Shen; Yuning Mao; Lei Li",
        "authorids": "",
        "aff": "University of Washington; University of Illinois at Urbana-Champaign; ByteDance AI Lab; ByteDance AI Lab; University of Illinois at Urbana-Champaign; University of Illinois at Urbana-Champaign; ByteDance AI Lab",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16596/16596-13-20090-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04662-taxonomy-completion-via-triplet-matching-network/",
        "doi": "10.1609/aaai.v35i5.16596",
        "pdf_size": 577929
    },
    {
        "id": "02817",
        "title": "Teacher Guided Neural Architecture Search for Face Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "Knowledge distillation is an effective tool to compress large pre-trained convolutional neural networks (CNNs) or their ensembles into models applicable to mobile and embedded devices. However, with expected flops or latency, existing methods are hand-crafted heuristics. They propose to pre-define the target student network for knowledge distillation, which may be sub-optimal because it requires much effort to explore a powerful student from the large design space. In this paper, we develop a novel teacher guided neural architecture search method to directly search for a student network with flexible channel and layer sizes. Specifically, we define the search space as the number of the channels/layers, which is sampled based on the probability distribution and is learned by minimizing the search objective of the student network. The maximum probability for the size in each distribution serves as the final searched width and depth of the target student network. Extensive experiments on a variety of face recognition benchmarks have demonstrated the superiority of our method over the state-of-the-art alternatives.",
        "primary_area": "Computer Vision III",
        "author": "Xiaobo Wang",
        "authorids": "",
        "aff": "Sangfor Technologies Inc., Shenzhen, China CBSR & NLPR, Institute of Automation, Chinese Academy of Sciences, Beijing, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16387/16387-13-19881-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02817-teacher-guided-neural-architecture-search-for-face-recognition/",
        "doi": "10.1609/aaai.v35i4.16387",
        "pdf_size": 152869
    },
    {
        "id": "05850",
        "title": "Teaching Active Human Learners",
        "track": "main",
        "status": "Poster",
        "abstract": "Teaching humans is an important topic under the umbrella of machine teaching, and its core problem is to design an algorithm for selecting teaching examples. Existing work typically regards humans as passive learners, where an ordered set of teaching examples are generated and fed to learners sequentially. However, such a mechanism is inconsistent with the behavior of human learners in practice. A real human learner can actively choose whether to review a historical example or to receive a new example depending on the belief of her learning states. In this work,   we propose a model of active learners and design an efficient teaching algorithm accordingly. Experimental results with both simulated learners and real crowdsourcing workers demonstrate that our teaching algorithm has better teaching performance compared to existing methods.",
        "primary_area": "Human-Computation and Crowd Sourcing",
        "author": "Zizhe Wang; Hailong Sun",
        "authorids": "",
        "aff": "Beihang University, China; Beihang University, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16732/16732-13-20226-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05850-teaching-active-human-learners/",
        "doi": "10.1609/aaai.v35i7.16732",
        "pdf_size": 5489379
    },
    {
        "id": "03742",
        "title": "Teaching the Old Dog New Tricks: Supervised Learning with Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "Adding constraint support in Machine Learning has the potential to address outstanding issues in data-driven AI systems, such as safety and fairness. Existing approaches typically apply constrained optimization techniques to ML training, enforce constraint satisfaction by adjusting the model design, or use constraints to correct the output. Here, we investigate a different, complementary, strategy based on \"teaching\" constraint satisfaction to a supervised ML method via the direct use of a state-of-the-art constraint solver: this enables taking advantage of decades of research on constrained optimization with limited effort. In practice, we use a decomposition scheme alternating master steps (in charge of enforcing the constraints) and learner steps (where any supervised ML model and training algorithm can be employed). The process leads to approximate constraint satisfaction in general, and convergence properties are difficult to establish; despite this fact, we found empirically that even a naive setup of our approach performs well on ML tasks with fairness constraints, and on classical datasets with synthetic constraints.",
        "primary_area": "Constraint Satisfaction and Optimization",
        "author": "Fabrizio Detassis; Michele Lombardi; Michela Milano",
        "authorids": "",
        "aff": "DISI, University of Bologna; DISI, University of Bologna; DISI, University of Bologna Alma Mater Research Institute for Human-Centered Artificial Intelligence",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16491/16491-13-19985-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03742-teaching-the-old-dog-new-tricks-supervised-learning-with-constraints/",
        "doi": "10.1609/aaai.v35i5.16491",
        "pdf_size": 278718
    },
    {
        "id": "09765",
        "title": "TempLe: Learning Template of Transitions for Sample Efficient Multi-task RL",
        "track": "main",
        "status": "Poster",
        "abstract": "Transferring knowledge among various environments is important for efficiently learning multiple tasks online. Most existing methods directly use the previously learned models or previously learned optimal policies to learn new tasks. However, these methods may be inefficient when the underlying models or optimal policies are substantially different across tasks. In this paper, we propose Template Learning (TempLe), a PAC-MDP method for multi-task reinforcement learning that could be applied to tasks with varying state/action space without prior knowledge of inter-task mappings. TempLe gains sample efficiency by extracting similarities of the transition dynamics across tasks even when their underlying models or optimal policies have limited commonalities. We present two algorithms for an ``online'' and a ``finite-model'' setting respectively. We prove that our proposed TempLe algorithms achieve much lower sample complexity than single-task learners or state-of-the-art multi-task methods. We show via systematically designed experiments that our TempLe method universally outperforms the state-of-the-art multi-task methods (PAC-MDP or not) in various settings and regimes.",
        "primary_area": "Machine Learning IV",
        "author": "Yanchao Sun; Xiangyu Yin; Furong Huang",
        "authorids": "",
        "aff": "University of Maryland, College Park; Beijing University of Posts and Telecommunications; University of Maryland, College Park",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17174/17174-13-20668-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09765-temple-learning-template-of-transitions-for-sample-efficient-multi-task-rl/",
        "doi": "10.1609/aaai.v35i11.17174",
        "pdf_size": 582126
    },
    {
        "id": "09312",
        "title": "Tempered Sigmoid Activations for Deep Learning with Differential Privacy",
        "track": "main",
        "status": "Poster",
        "abstract": "Because learning sometimes involves sensitive data, machine learning algorithms have been extended to offer differential privacy for training data. In practice, this has been mostly an afterthought, with privacy-preserving models obtained by re-running training with a different optimizer, but using the model architectures that already performed well in a non-privacy-preserving setting. This approach leads to less than ideal privacy/utility tradeoffs, as we show here. To improve these tradeoffs, prior work introduces variants of differential privacy that weaken the privacy guarantee proved to increase model utility. We show this is not necessary and instead propose that utility be improved by choosing activation functions designed explicitly for privacy-preserving training.   A crucial operation in differentially private SGD is gradient clipping, which along with modifying the optimization path (at times resulting in not-optimizing a single objective function), may also introduce both significant bias and variance to the learning process. We empirically identify exploding gradients arising from ReLU may be one of the main sources of this. We demonstrate analytically and experimentally how a general family of bounded activation functions, the tempered sigmoids, consistently outperform the currently established choice: unbounded activation functions like ReLU. Using this paradigm, we achieve new state-of-the-art accuracy on MNIST, FashionMNIST, and CIFAR10 without any modification of the learning procedure fundamentals or differential privacy analysis. While the changes we make are simple in retrospect, the simplicity of our approach facilitates its implementation and adoption to meaningfully improve state-of-the-art machine learning while still providing strong guarantees in the original framework of differential privacy.",
        "primary_area": "Machine Learning III",
        "author": "Nicolas Papernot; Abhradeep Thakurta; Shuang Song; Steve Chien; \u00dalfar Erlingsson",
        "authorids": "",
        "aff": "Google; Google; Google; Google; Apple",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17123/17123-13-20617-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09312-tempered-sigmoid-activations-for-deep-learning-with-differential-privacy/",
        "doi": "10.1609/aaai.v35i10.17123",
        "pdf_size": 1701243
    },
    {
        "id": "09117",
        "title": "Temporal Latent Auto-Encoder: A Method for Probabilistic Multivariate Time Series Forecasting",
        "track": "main",
        "status": "Poster",
        "abstract": "Probabilistic forecasting of high dimensional multivariate time series is a notoriously challenging task, both in terms of computational burden and distribution modeling. Most previous work either makes simple distribution assumptions or abandons modeling cross-series correlations.  A promising line of work exploits scalable matrix factorization for latent-space forecasting, but is limited to linear embeddings, unable to model distributions, and not trainable end-to-end when using deep learning forecasting. We introduce a novel temporal latent auto-encoder method which enables nonlinear factorization of multivariate time series, learned end-to-end with a temporal deep learning latent space forecast model. By imposing a probabilistic latent space model, complex distributions of the input series are modeled via the decoder.    Extensive experiments demonstrate that our model achieves state-of-the-art performance on many popular multivariate datasets, with gains sometimes as high as 50% for several standard metrics.",
        "primary_area": "Machine Learning III",
        "author": "Nam Nguyen; Brian Quanz",
        "authorids": "",
        "aff": "IBM Research; IBM Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17101/17101-13-20595-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09117-temporal-latent-auto-encoder-a-method-for-probabilistic-multivariate-time-series-forecasting/",
        "doi": "10.1609/aaai.v35i10.17101",
        "pdf_size": 458117
    },
    {
        "id": "02029",
        "title": "Temporal Pyramid Network for Pedestrian Trajectory Prediction with Multi-Supervision",
        "track": "main",
        "status": "Poster",
        "abstract": "Predicting human motion behavior in a crowd is important for many applications, ranging from the natural navigation of autonomous vehicles to intelligent security systems of video surveillance. All the previous works model and predict the trajectory with a single resolution, which is relatively ineffective and difficult to simultaneously exploit the long-range information (e.g., the destination of the trajectory), and the short-range information (e.g., the walking direction and speed at a certain time) of the motion behavior. In this paper, we propose a temporal pyramid network for pedestrian trajectory prediction through a squeeze modulation and a dilation modulation. Our hierarchical framework builds a feature pyramid with increasingly richer temporal information from top to bottom, which can better capture the motion behavior at various tempos. Furthermore, we propose a coarse-to-fine fusion strategy with multi-supervision. By progressively merging the top coarse features of global context to the bottom fine features of rich local context, our method can fully exploit both the long-range and short-range information of the trajectory.  Experimental results on two benchmarks demonstrate the superiority of our method.  Our code and models will be available upon acceptance.",
        "primary_area": "Computer Vision II",
        "author": "Rongqin Liang; Yuanman Li; Xia Li; Yi Tang; Jiantao Zhou; Wenbin Zou",
        "authorids": "",
        "aff": "Guangdong Key Laboratory of Intelligent Information Processing, College of Electronics and Information Engineering, Shenzhen University; Guangdong Key Laboratory of Intelligent Information Processing, College of Electronics and Information Engineering, Shenzhen University; Guangdong Key Laboratory of Intelligent Information Processing, College of Electronics and Information Engineering, Shenzhen University; Guangdong Key Laboratory of Intelligent Information Processing, College of Electronics and Information Engineering, Shenzhen University; State Key Laboratory of Internet of Things for Smart City, Department of Computer and Information Science, University of Macau; Guangdong Key Laboratory of Intelligent Information Processing, College of Electronics and Information Engineering, Shenzhen University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16299/16299-13-19793-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02029-temporal-pyramid-network-for-pedestrian-trajectory-prediction-with-multi-supervision/",
        "doi": "10.1609/aaai.v35i3.16299",
        "pdf_size": 8617836
    },
    {
        "id": "01442",
        "title": "Temporal ROI Align for Video Object Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "Video object detection is challenging in the presence of appearance deterioration in certain video frames. Therefore, it is a natural choice to aggregate temporal information from other frames of the same video into the current frame. However, ROI Align, as one of the most core procedures of video detectors, still remains extracting features from a single-frame feature map for proposals, making the extracted ROI features lack temporal information from videos. In this work, considering the features of the same object instance are highly similar among frames in a video, a novel Temporal ROI Align operator is proposed to extract features from other frames feature maps for current frame proposals by utilizing feature similarity. The proposed Temporal ROI Align operator can extract temporal information from the entire video for proposals. We integrate it into single-frame video detectors and other state-of-the-art video detectors, and conduct quantitative experiments to demonstrate that the proposed Temporal ROI Align operator can consistently and significantly boost the performance. Besides, the proposed Temporal ROI Align can also be applied into video instance segmentation.",
        "primary_area": "Computer Vision I",
        "author": "Tao Gong; Kai Chen; Xinjiang Wang; Qi Chu; Feng Zhu; Dahua Lin; Nenghai Yu; Huamin Feng",
        "authorids": "",
        "aff": "School of Cyberspace Security, University of Science and Technology of China Key Laboratory of Electromagnetic Space Information, Chinese Academy of Sciences; SenseTime Research; SenseTime Research; School of Cyberspace Security, University of Science and Technology of China Key Laboratory of Electromagnetic Space Information, Chinese Academy of Sciences; SenseTime Research; The Chinese University of Hong Kong; School of Cyberspace Security, University of Science and Technology of China Key Laboratory of Electromagnetic Space Information, Chinese Academy of Sciences; Beijing Electronic Science and Technology Institute",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16234/16234-13-19728-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01442-temporal-roi-align-for-video-object-recognition/",
        "doi": "10.1609/aaai.v35i2.16234",
        "pdf_size": 614615
    },
    {
        "id": "02729",
        "title": "Temporal Relational Modeling with Self-Supervision for Action Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "Temporal relational modeling in video is essential for human action understanding, such as action recognition and action segmentation. Although Graph Convolution Networks (GCNs) have shown promising advantages in relation reasoning on many tasks, it is still a challenge to apply graph convolution networks on long video sequences effectively. The main reason is that large number of nodes (i.e., video frames) makes GCNs hard to capture and model temporal relations in videos. To tackle this problem, in this paper, we introduce an effective GCN module, Dilated Temporal Graph Reasoning Module (DTGRM), designed to model temporal relations and dependencies between video frames at various time spans. In particular, we capture and model temporal relations via constructing multi-level dilated temporal graphs where the nodes represent frames from different moments in video. Moreover, to enhance temporal reasoning ability of the proposed model, an auxiliary self-supervised task is proposed to encourage the dilated temporal graph reasoning module to find and correct wrong temporal relations in videos. Our DTGRM model outperforms state-of-the-art action segmentation models on three challenging datasets: 50Salads, Georgia Tech Egocentric Activities (GTEA), and the Breakfast dataset. The code is available at https://github.com/redwang/DTGRM.",
        "primary_area": "Computer Vision III",
        "author": "Dong Wang; Di Hu; Xingjian Li; Dejing Dou",
        "authorids": "",
        "aff": "Northwestern Polytechnical University; Renmin University of China Beijing Key Laboratory of Big Data Management and Analysis Methods; Baidu Research; Baidu Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16377/16377-13-19871-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02729-temporal-relational-modeling-with-self-supervision-for-action-segmentation/",
        "doi": "10.1609/aaai.v35i4.16377",
        "pdf_size": 930190
    },
    {
        "id": "02163",
        "title": "Temporal Segmentation of Fine-gained Semantic Action: A Motion-Centered Figure Skating Dataset",
        "track": "main",
        "status": "Poster",
        "abstract": "Temporal Action Segmentation (TAS) has achieved great success in many fields such as exercise rehabilitation, movie editing, etc. Currently, task-driven TAS is a central topic in human action analysis. However, motion-centered TAS, as an important topic, is little researched due to unavailable datasets. In order to explore more models and practical applications of motion-centered TAS, we introduce a Motion-Centered Figure Skating (MCFS) dataset in this paper. Compared with existing temporal action segmentation datasets, the MCFS dataset is fine-grained semantic, specialized and motion-centered. Besides, RGB-based and Skeleton-based features are provided in the MCFS dataset. Experimental results show that existing state-of-the-art methods are difficult to achieve excellent segmentation results (including accuracy, edit and F1 score) in the MCFS dataset. This indicates that MCFS is a challenging dataset for motion-centered TAS. The latest dataset can be downloaded at https://shenglanliu.github.io/mcfs-dataset/.",
        "primary_area": "Computer Vision II",
        "author": "Shenglan Liu; Aibin Zhang; Yunheng Li; Jian Zhou; Li Xu; Zhuben Dong; Renhao Zhang",
        "authorids": "",
        "aff": "Dalian University of Technology; Dalian University of Technology; Dalian University of Technology; Dalian University of Technology; Alibaba Inc.; Dalian University of Technology; Dalian University of Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16314/16314-13-19808-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02163-temporal-segmentation-of-fine-gained-semantic-action-a-motion-centered-figure-skating-dataset/",
        "doi": "10.1609/aaai.v35i3.16314",
        "pdf_size": 6585122
    },
    {
        "id": "11143",
        "title": "Temporal-Coded Deep Spiking Neural Network with Easy Training and Robust Performance",
        "track": "main",
        "status": "Poster",
        "abstract": "Spiking neural network (SNN) is promising but the development has fallen far behind conventional deep neural networks (DNNs) because of difficult training. To resolve the training problem, we analyze the closed-form input-output response of spiking neurons and use the response expression to build abstract SNN models for training. This avoids calculating membrane potential during training and makes the direct training of SNN as efficient as DNN. We show that the nonleaky integrate-and-fire neuron with single-spike temporal-coding is the best choice for direct-train deep SNNs. We develop an energy-efficient phase-domain signal processing circuit for the neuron and propose a direct-train deep SNN framework. Thanks to easy training, we train deep SNNs under weight quantizations to study their robustness over low-cost neuromorphic hardware.  Experiments show that our direct-train deep SNNs have the highest CIFAR-10 classification accuracy among SNNs, achieve ImageNet classification accuracy within 1% of the DNN of equivalent architecture, and are robust to weight quantization and noise perturbation.",
        "primary_area": "Machine Learning V",
        "author": "Shibo Zhou; Xiaohua Li; Ying Chen; Sanjeev T. Chandrasekaran; Arindam Sanyal",
        "authorids": "",
        "aff": "Binghamton University; Binghamton University; Harbin Institute of Technology; University at Buffalo-SUNY; University at Buffalo-SUNY",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17329/17329-13-20823-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11143-temporal-coded-deep-spiking-neural-network-with-easy-training-and-robust-performance/",
        "doi": "10.1609/aaai.v35i12.17329",
        "pdf_size": 2951928
    },
    {
        "id": "07995",
        "title": "Temporal-Logic-Based Reward Shaping for Continuing Reinforcement Learning Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "In continuing tasks, average-reward reinforcement learning may be a more appropriate problem formulation than the more common discounted reward formulation. As usual, learning an optimal policy in this setting typically requires a large amount of training experiences. Reward shaping is a common approach for incorporating domain knowledge into reinforcement learning in order to speed up convergence to an optimal policy. However, to the best of our knowledge, the theoretical properties of reward shaping have thus far only been established in the discounted setting. This paper presents the first reward shaping framework for average-reward learning and proves that, under standard assumptions, the optimal policy under the original reward function can be recovered. In order to avoid the need for manual construction of the shaping function, we introduce a method for utilizing domain knowledge expressed as a temporal logic formula. The formula is automatically translated to a shaping function that provides additional reward throughout the learning process. We evaluate the proposed method on three continuing tasks. In all cases, shaping speeds up the average-reward learning rate without any reduction in the performance of the learned policy compared to relevant baselines.",
        "primary_area": "Machine Learning II",
        "author": "Yuqian Jiang; Suda Bharadwaj; Bo Wu; Rishi Shah; Ufuk Topcu; Peter Stone",
        "authorids": "",
        "aff": "University of Texas at Austin; University of Texas at Austin; University of Texas at Austin; University of Texas at Austin Amazon; University of Texas at Austin; University of Texas at Austin Sony AI",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16975/16975-13-20469-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07995-temporal-logic-based-reward-shaping-for-continuing-reinforcement-learning-tasks/",
        "doi": "10.1609/aaai.v35i9.16975",
        "pdf_size": 1784488
    },
    {
        "id": "02364",
        "title": "Terrace-based Food Counting and Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper represents object instance as a terrace, where the height of terrace corresponds to object attention while the evolution of layers from peak to sea level represents the complexity in drawing the finer boundary of an object. A multitask neural network is presented to learn the terrace representation. The attention of terrace is leveraged for instance counting, and the layers provide prior for easy-to-hard pathway of progressive instance segmentation. We study the model for counting and segmentation for a variety of food instances, ranging from Chinese, Japanese to Western food. This paper presents how the terrace model deals with arbitrary shape, size, obscure boundary and occlusion of instances, where other techniques are currently short of.",
        "primary_area": "Computer Vision II",
        "author": "Huu-Thanh Nguyen; Chong-Wah Ngo",
        "authorids": "",
        "aff": "City University of Hong Kong; Singapore Management University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16337/16337-13-19831-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02364-terrace-based-food-counting-and-segmentation/",
        "doi": "10.1609/aaai.v35i3.16337",
        "pdf_size": 15095953
    },
    {
        "id": "06538",
        "title": "Testing Independence Between Linear Combinations for Causal Discovery",
        "track": "main",
        "status": "Poster",
        "abstract": "Recently, regression based conditional independence (CI) tests have been employed to solve the problem of causal discovery. These methods provide an alternative way to test for CI by transforming CI to independence between residuals. Generally, it is nontrivial to check for independence when these residuals are linearly uncorrelated. With the ability to represent high-order moments, kernel-based methods are usually used to achieve this goal, but at a cost of considerable time. In this paper, we investigate the independence between two linear combinations under linear non-Gaussian structural equation model (SEM). We show that generally the 1-st to 4-th moments of the two linear combinations contain enough information to infer whether or not they are independent. The proposed method provides a simpler but more effective way to measure CIs, with only calculating the 1-st to 4-th moments of the input variables. When applied to causal discovery, the proposed method outperforms kernel-based methods in terms of both speed and accuracy. which is validated by extensive experiments.",
        "primary_area": "Knowledge Representation and Reasoning",
        "author": "Hao Zhang; Kun Zhang; Shuigeng Zhou; Jihong Guan; Ji Zhang",
        "authorids": "",
        "aff": "Guangdong University of Petrochemical Technology; Carnegie Mellon University; Fudan University; Tongji University; Zhejiang Lab",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16810/16810-13-20304-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06538-testing-independence-between-linear-combinations-for-causal-discovery/",
        "doi": "10.1609/aaai.v35i7.16810",
        "pdf_size": 377215
    },
    {
        "id": "01610",
        "title": "Text-Guided Graph Neural Networks for Referring 3D Instance Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper addresses a new task called referring 3D instance segmentation, which aims to segment out the target instance in a 3D scene given a query sentence. Previous work on scene understanding has explored visual grounding with natural language guidance, yet the emphasis is mostly constrained on images and videos. We propose a Text-guided Graph Neural Network (TGNN) for referring 3D instance segmentation on point clouds. Given a query sentence and the point cloud of a 3D scene, our method learns to extract per-point features and predicts an offset to shift each point toward its object center. Based on the point features and the offsets, we cluster the points to produce fused features and coordinates for the candidate objects. The resulting clusters are modeled as nodes in a Graph Neural Network to learn the representations that encompass the relation structure for each candidate object. The GNN layers leverage each object's features and its relations with neighbors to generate an attention heatmap for the input sentence expression. Finally, the attention heatmap is used to \"guide\" the aggregation of information from neighborhood nodes. Our method achieves state-of-the-art performance on referring 3D instance segmentation and 3D localization on ScanRefer, Nr3D, and Sr3D benchmarks, respectively.",
        "primary_area": "Computer Vision I",
        "author": "Pin-Hao Huang; Han-Hung Lee; Hwann-Tzong Chen; Tyng-Luh Liu",
        "authorids": "",
        "aff": "Institute of Information Science, Academia Sinica, Taiwan; Department of Computer Science, National Tsing Hua University, Taiwan Institute of Information Science, Academia Sinica, Taiwan; Department of Computer Science, National Tsing Hua University, Taiwan Aeolus Robotics; Institute of Information Science, Academia Sinica, Taiwan Taiwan AI Labs",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16253/16253-13-19747-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01610-text-guided-graph-neural-networks-for-referring-3d-instance-segmentation/",
        "doi": "10.1609/aaai.v35i2.16253",
        "pdf_size": 5755297
    },
    {
        "id": "09018",
        "title": "Text-based RL Agents with Commonsense Knowledge: New Challenges, Environments and Baselines",
        "track": "main",
        "status": "Poster",
        "abstract": "Text-based games have emerged as an important test-bed for Reinforcement Learning (RL) research, requiring RL agents to combine grounded language understanding with sequential decision making. In this paper, we examine the problem of infusing RL agents with commonsense knowledge. Such knowledge would allow agents to efficiently act in the world by pruning out implausible actions, and to perform look-ahead planning to determine how current actions might affect future world states. We design a new text-based gaming environment called TextWorld Commonsense (TWC) for training and evaluating RL agents with a specific kind of commonsense knowledge about objects, their attributes, and affordances. We also introduce several baseline RL agents which track the sequential context and dynamically retrieve the relevant commonsense knowledge from ConceptNet. We show that agents which incorporate commonsense knowledge in TWC perform better, while acting more efficiently. We conduct user-studies to estimate human performance on TWC and show that there is ample room for future improvement.",
        "primary_area": "Machine Learning III",
        "author": "Keerthiram Murugesan; Mattia Atzeni; Pavan Kapanipathi; Pushkar Shukla; Sadhana Kumaravel; Gerald Tesauro; Kartik Talamadupula; Mrinmaya Sachan; Murray Campbell",
        "authorids": "",
        "aff": "IBM Research; IBM Research EPFL; IBM Research; TTI Chicago; IBM Research; IBM Research; IBM Research; ETH Zurich; IBM Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17090/17090-13-20584-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09018-text-based-rl-agents-with-commonsense-knowledge-new-challenges-environments-and-baselines/",
        "doi": "10.1609/aaai.v35i10.17090",
        "pdf_size": 526482
    },
    {
        "id": "14067",
        "title": "TextGAIL: Generative Adversarial Imitation Learning for Text Generation",
        "track": "main",
        "status": "Poster",
        "abstract": "Generative Adversarial Networks (GANs) for text generation have recently received many criticisms, as they perform worse than their MLE counterparts. We suspect previous text GANs' inferior performance is due to the lack of a reliable guiding signal in their discriminators. To address this problem, we propose a generative adversarial imitation learning framework for text generation that uses large pre-trained language models to provide more reliable reward guidance. As previous text GANs suffer from high variance of gradients, we apply contrastive discriminator, and proximal policy optimization (PPO) to stabilize and improve text generation performance. For evaluation, we conduct experiments on a diverse set of unconditional and conditional text generation tasks. Experimental results show that TextGAIL achieves better performance in terms of both quality and diversity than the MLE baseline. We also validate our intuition that TextGAIL's discriminator demonstrates the capability of providing reasonable rewards with an additional task.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Qingyang Wu; Lei Li; Zhou Yu",
        "authorids": "",
        "aff": "University of California, Davis; ByteDance AI Lab; University of California, Davis",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17656/17656-13-21150-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14067-textgail-generative-adversarial-imitation-learning-for-text-generation/",
        "doi": "10.1609/aaai.v35i16.17656",
        "pdf_size": 688983
    },
    {
        "id": "00204",
        "title": "The Causal Learning of Retail Delinquency",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper focuses on the expected difference in borrower's repayment when there is a change in the lender's credit decisions. Classical estimators overlook the confounding effects and hence the estimation error can be magnificent. As such, we propose another approach to construct the estimators such that the error can be greatly reduced. The proposed estimators are shown to be unbiased, consistent, and robust through a combination of theoretical analysis and numerical testing. Moreover, we compare the power of estimating the causal quantities between the classical estimators and the proposed estimators. The comparison is tested across a wide range of models, including linear regression models, tree-based models, and neural network-based models, under different simulated datasets that exhibit different levels of causality, different degrees of nonlinearity, and different distributional properties. Most importantly, we apply our approaches to a large observational dataset provided by a global technology firm that operates in both the e-commerce and the lending business. We find that the relative reduction of estimation error is strikingly substantial if the causal effects are accounted for correctly.",
        "primary_area": "Application Domains",
        "author": "Yiyan Huang; Cheuk Hang Leung; Xing Yan; Qi Wu; Nanbo Peng; Dongdong Wang; Zhixiang Huang",
        "authorids": "",
        "aff": "City University of Hong Kong; City University of Hong Kong; Renmin University of China; City University of Hong Kong; JD Digits; JD Digits; JD Digits",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16094/16094-13-19588-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00204-the-causal-learning-of-retail-delinquency/",
        "doi": "10.1609/aaai.v35i1.16094",
        "pdf_size": 309970
    },
    {
        "id": "06296",
        "title": "The Complexity Landscape of Claim-Augmented Argumentation Frameworks",
        "track": "main",
        "status": "Poster",
        "abstract": "Claim-augmented argumentation frameworks (CAFs) provide a formal basis to analyze conclusion-oriented problems in argumentation by adapting a claim-focused perspective; they extend Dung AFs by associating a claim to each argument representing its conclusion. This additional layer offers various possibilities to generalize abstract argumentation semantics as the re-interpretation of arguments in terms of their claims can be performed at different stages in the evaluation of the framework: One approach is to perform the evaluation entirely at argument-level before interpreting arguments by their claims (inherited semantics); alternatively, one can perform certain steps in the process (e.g., maximization) already in terms of the arguments\u2019 claims (claim-level semantics). The inherent difference of these approaches not only potentially results in different outcomes but, as we will show in this paper, is also mirrored in terms of computational complexity. To this end, we provide a comprehensive complexity analysis of the four main reasoning problems with respect to claim-level variants of preferred, naive, stable, semi-stable and stage semantics and complete the complexity results of inherited semantics by providing corresponding results for semi-stable and stage semantics. Moreover, we show that deciding, whether for a given framework the two approaches of a semantics coincide (concurrence) can be surprisingly hard, ranging up to the third level of the polynomial hierarchy.",
        "primary_area": "Knowledge Representation and Reasoning",
        "author": "Wolfgang Dvo\u0159\u00e1k; Alexander Gre\u00dfler; Anna Rapberger; Stefan Woltran",
        "authorids": "",
        "aff": "TU Wien; TU Wien; TU Wien; TU Wien",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16782/16782-13-20276-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06296-the-complexity-landscape-of-claim-augmented-argumentation-frameworks/",
        "doi": "10.1609/aaai.v35i7.16782",
        "pdf_size": 161007
    },
    {
        "id": "01388",
        "title": "The Complexity of Object Association in Multiple Object Tracking",
        "track": "main",
        "status": "Poster",
        "abstract": "Object association, i.e., the identification of which observations correspond to the same object, is a central task for the area of multiple object tracking. Two prominent models capturing this task have been introduced in the literature: the Lifted Multicut model and the more recent Lifted Paths model. Here, we carry out a detailed complexity-theoretic study of the problems arising from these two models that is aimed at complementing previous empirical work on object association. We obtain a comprehensive complexity map for both models that takes into account natural restrictions to instances such as possible bounds on the number of frames, number of tracked objects and branching degree, as well as less explicit structural restrictions such as having bounded treewidth. Our results include new fixed-parameter and XP algorithms for the problems as well as hardness proofs which altogether indicate that the Lifted Paths problem exhibits a more favorable complexity behavior than Lifted Multicut.",
        "primary_area": "Computer Vision I",
        "author": "Robert Ganian; Thekla Hamm; Sebastian Ordyniak",
        "authorids": "",
        "aff": "TU Wien; TU Wien; University of Leeds",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16228/16228-13-19722-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01388-the-complexity-of-object-association-in-multiple-object-tracking/",
        "doi": "10.1609/aaai.v35i2.16228",
        "pdf_size": 202486
    },
    {
        "id": "06210",
        "title": "The Counterfactual NESS Definition of Causation",
        "track": "main",
        "status": "Poster",
        "abstract": "Beckers & Vennekens recently proposed a definition of actual causation that is based on certain plausible principles, thereby allowing the debate on causation to shift away from its heavy focus on examples towards a more systematic analysis. This paper contributes to that analysis in two ways. First, I show that their definition is in fact a formalization of Wright\u2019s famous NESS definition of causation combined with a counterfactual difference-making condition. This means that their definition integrates two highly influential approaches to causation that are claimed to stand in opposition to each other. Second, I modify their definition to offer a substantial improvement: I weaken their difference-making condition in such a way that it avoids their problematic analysis of cases of preemption. The resulting Counterfactual NESS definition of causation forms a natural compromise between counterfactual approaches and the NESS approach.",
        "primary_area": "Knowledge Representation and Reasoning",
        "author": "Sander Beckers",
        "authorids": "",
        "aff": "Ludwig Maximilian University - Munich",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16772/16772-13-20266-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06210-the-counterfactual-ness-definition-of-causation/",
        "doi": "10.1609/aaai.v35i7.16772",
        "pdf_size": 132251
    },
    {
        "id": "13180",
        "title": "The Gap on Gap: Tackling the Problem of Differing Data Distributions in Bias-Measuring Datasets",
        "track": "main",
        "status": "Poster",
        "abstract": "Diagnostic datasets that can detect biased models are an important prerequisite for bias reduction within natural language processing. However, undesired patterns in the collected data can make such tests incorrect. For example, if the feminine subset of a gender-bias-measuring coreference resolution dataset contains sentences with a longer average distance between the pronoun and the correct candidate, an RNN-based model may perform worse on this subset due to long-term dependencies. In this work, we introduce a theoretically grounded method for weighting test samples to cope with such patterns in the test data. We demonstrate the method on the GAP dataset for coreference resolution. We annotate GAP with spans of all personal names and show that examples in the female subset contain more personal names and a longer distance between pronouns and their referents, potentially affecting the bias score in an undesired way. Using our weighting method, we find the set of weights on the test instances that should be used for coping with these correlations,   and we re-evaluate 16 recently released coreference models.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Vid Kocijan; Oana-Maria Camburu; Thomas Lukasiewicz",
        "authorids": "",
        "aff": "University of Oxford; University of Oxford Alan Turing Institute; University of Oxford Alan Turing Institute",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17557/17557-13-21051-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13180-the-gap-on-gap-tackling-the-problem-of-differing-data-distributions-in-bias-measuring-datasets/",
        "doi": "10.1609/aaai.v35i14.17557",
        "pdf_size": 188630
    },
    {
        "id": "13613",
        "title": "The Heads Hypothesis: A Unifying Statistical Approach Towards Understanding Multi-Headed Attention in BERT",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-headed attention heads are a mainstay in transformer-based models. Different methods have been proposed to classify the role of each attention head based on the relations between tokens which have high pair-wise attention. These roles include syntactic (tokens with some syntactic relation), local (nearby tokens), block (tokens in the same sentence) and delimiter (the special [CLS], [SEP] tokens). There are two main challenges with existing methods for classification: (a) there  are no standard scores across studies or across functional roles, and (b) these scores are often average quantities measured across sentences without capturing statistical significance. In this work, we formalize a simple yet effective score that generalizes to all the roles of attention heads and employs hypothesis testing on this score for robust inference. This provides us the right lens to systematically analyze attention heads and confidently comment on many commonly posed questions on analyzing the BERT model. In particular, we comment on the co-location of multiple functional roles in the same attention head, the distribution of attention heads across layers, and effect of fine-tuning for specific NLP tasks on these functional roles. The code is made publicly available at https://github.com/iitmnlp/heads-hypothesis",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Madhura Pande; Aakriti Budhraja; Preksha Nema; Pratyush Kumar; Mitesh M. Khapra",
        "authorids": "",
        "aff": "Department of Computer Science and Engineering, IIT Madras, India Robert Bosch Center for Data Science and Artificial Intelligence (RBC-DSAI) IIT Madras, India; Department of Computer Science and Engineering, IIT Madras, India Robert Bosch Center for Data Science and Artificial Intelligence (RBC-DSAI) IIT Madras, India; Department of Computer Science and Engineering, IIT Madras, India Robert Bosch Center for Data Science and Artificial Intelligence (RBC-DSAI) IIT Madras, India; Department of Computer Science and Engineering, IIT Madras, India Robert Bosch Center for Data Science and Artificial Intelligence (RBC-DSAI) IIT Madras, India; Department of Computer Science and Engineering, IIT Madras, India Robert Bosch Center for Data Science and Artificial Intelligence (RBC-DSAI) IIT Madras, India",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17605/17605-13-21099-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13613-the-heads-hypothesis-a-unifying-statistical-approach-towards-understanding-multi-headed-attention-in-bert/",
        "doi": "10.1609/aaai.v35i15.17605",
        "pdf_size": 927868
    },
    {
        "id": "07564",
        "title": "The Importance of Modeling Data Missingness in Algorithmic Fairness: A Causal Perspective",
        "track": "main",
        "status": "Poster",
        "abstract": "Training datasets for machine learning often have some form of missingness. For example, to learn a model for deciding whom to give a loan, the available training data includes individuals who were given a loan in the past, but not those who were not. This missingness, if ignored, nullifies any fairness guarantee of the training procedure when the model is deployed. Using causal graphs, we characterize the missingness mechanisms in different real-world scenarios. We show conditions under which various distributions, used in popular fairness algorithms, can or can not be recovered from the training data. Our theoretical results imply that many of these algorithms can not guarantee fairness in practice. Modeling missingness also helps to identify correct design principles for fair algorithms. For example, in multi-stage settings where decisions are made in multiple screening rounds, we use our framework to derive the minimal distributions required to design a fair algorithm. Our proposed algorithm also decentralizes the decision-making process and still achieves similar performance to the optimal algorithm that requires centralization and non-recoverable distributions.",
        "primary_area": "Machine Learning II",
        "author": "Naman Goel; Alfonso Amayuelas; Amit Deshpande; Amit Sharma",
        "authorids": "",
        "aff": "ETH Zurich; EPFL Lausanne; Microsoft Research; Microsoft Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16926/16926-13-20420-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07564-the-importance-of-modeling-data-missingness-in-algorithmic-fairness-a-causal-perspective/",
        "doi": "10.1609/aaai.v35i9.16926",
        "pdf_size": 443110
    },
    {
        "id": "11254",
        "title": "The Influence of Memory in Multi-Agent Consensus",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-agent consensus problems can often be seen as a sequence of autonomous and independent local choices between a finite set of decision options, with each local choice undertaken simultaneously, and with a shared  goal of  achieving  a global consensus state. Being able to estimate probabilities for the different outcomes and to predict how long it takes for a consensus to be formed, if ever, are core issues for such protocols.  Little attention has been given to protocols in which agents can remember past or outdated states.  In this paper, we propose a framework to study what we call `memory consensus protocol'. We show that the employment of memory allows such processes to always converge, as well as, in some scenarios, such as cycles, converge faster. We provide a theoretical analysis of the probability of each option eventually winning such processes based on the initial opinions expressed by agents. Further, we perform experiments to investigate network topologies in which agents benefit from memory on the expected time needed for consensus.",
        "primary_area": "Multiagent Systems",
        "author": "David Kohan Marzag\u00e3o; Luciana Basualdo Bonatto; Tiago Madeira; Marcelo Matheus Gauy; Peter McBurney",
        "authorids": "",
        "aff": "King's College London; University of Oxford; University of S\u00e3o Paulo; University of S\u00e3o Paulo; King's College London",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17342/17342-13-20836-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11254-the-influence-of-memory-in-multi-agent-consensus/",
        "doi": "10.1609/aaai.v35i13.17342",
        "pdf_size": 158684
    },
    {
        "id": "00548",
        "title": "The LOB Recreation Model: Predicting the Limit Order Book from TAQ History Using an Ordinary Differential Equation Recurrent Neural Network",
        "track": "main",
        "status": "Poster",
        "abstract": "In an order-driven financial market, the price of a financial asset is discovered through the interaction of orders - requests to buy or sell at a particular price - that are posted to the public limit order book (LOB). Therefore, LOB data is extremely valuable for modelling market dynamics. However, LOB data is not freely accessible, which poses a challenge to market participants and researchers wishing to exploit this information. Fortunately, trades and quotes (TAQ) data - orders arriving at the top of the LOB, and trades executing in the market - are more readily available. In this paper, we present the LOB recreation model, a first attempt from a deep learning perspective to recreate the top five price levels of the LOB for small-tick stocks using only TAQ data. Volumes of orders sitting deep in the LOB are predicted by combining outputs from: (1) a history compiler that uses a Gated Recurrent Unit (GRU) module to selectively compile prediction relevant quote history; (2) a market events simulator, which uses an Ordinary Differential Equation Recurrent Neural Network (ODE-RNN) to simulate the accumulation of net order arrivals; and (3) a weighting scheme to adaptively combine the predictions generated by (1) and (2). By the paradigm of transfer learning, the core encoder trained on one stock can be fine-tuned to enable application to other financial assets of the same class with much lower demand on additional data. Comprehensive experiments conducted on two real world intraday LOB datasets demonstrate that the proposed model can efficiently recreate the LOB with high accuracy using only TAQ data as input.",
        "primary_area": "Application Domains",
        "author": "Zijian Shi; Yu Chen; John Cartlidge",
        "authorids": "",
        "aff": "University of Bristol; University of Bristol; University of Bristol",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16133/16133-13-19627-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00548-the-lob-recreation-model-predicting-the-limit-order-book-from-taq-history-using-an-ordinary-differential-equation-recurrent-neural-network/",
        "doi": "10.1609/aaai.v35i1.16133",
        "pdf_size": 1075733
    },
    {
        "id": "05690",
        "title": "The Maximin Support Method: An Extension of the D\u2019Hondt Method to Approval-Based Multiwinner Elections",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose the maximin support method, a novel extension of the D'Hondt apportionment method to approval-based multiwinner elections. The maximin support method is a sequential procedure that aims to maximize the support of the least supported elected candidate. It can be computed efficiently and satisfies (adjusted versions of) the main properties of the original D'Hondt method: house monotonicity, population monotonicity, and proportional representation. We also establish a close relationship between the maximin support method and alternative D'Hondt extensions due to Phragm\u00e9n.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Luis S\u00e1nchez-Fern\u00e1ndez; Norberto Fern\u00e1ndez Garc\u00eda; Jes\u00fas A. Fisteus; Markus Brill",
        "authorids": "",
        "aff": "Universidad Carlos III de Madrid; Centro Universitario de la Defensa, Escuela Naval Militar; Universidad Carlos III de Madrid; TU Berlin",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16714/16714-13-20208-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05690-the-maximin-support-method-an-extension-of-the-dhondt-method-to-approval-based-multiwinner-elections/",
        "doi": "10.1609/aaai.v35i6.16714",
        "pdf_size": 241019
    },
    {
        "id": "07296",
        "title": "The Parameterized Complexity of Clustering Incomplete Data",
        "track": "main",
        "status": "Poster",
        "abstract": "We study fundamental clustering problems for incomplete data. Specifically, given a set of incomplete d-dimensional vectors (representing rows of a matrix), the goal is to complete the missing vector entries in a way that admits a partitioning of the vectors into at most k clusters with radius or diameter at most r.  We give tight characterizations of the parameterized complexity of these problems with respect to the parameters k, r, and the minimum number of rows and columns needed to cover all the missing entries. We show that the considered problems are fixed-parameter tractable when parameterized by the three parameters combined, and that dropping any of the three parameters results in parameterized intractability.  A byproduct of our results is that, for the complete data setting, all problems under consideration are fixed-parameter tractable parameterized by k+r.",
        "primary_area": "Machine Learning I",
        "author": "Eduard Eiben; Robert Ganian; Iyad Kanj; Sebastian Ordyniak; Stefan Szeider",
        "authorids": "",
        "aff": "Royal Holloway, University of London; TU Wien; DePaul University, School of Computing; University of Leeds; TU Wien",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16896/16896-13-20390-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07296-the-parameterized-complexity-of-clustering-incomplete-data/",
        "doi": "10.1609/aaai.v35i8.16896",
        "pdf_size": 165638
    },
    {
        "id": "03851",
        "title": "The Power of Literal Equivalence in Model Counting",
        "track": "main",
        "status": "Poster",
        "abstract": "The past two decades have seen the significant improvements of the scalability of practical model counters, which have been quite influential in many applications from artificial intelligence to formal verification.  While most of exact counters fall into two categories, search-based and compilation-based, Huang and Darwiche's remarkable observation ties these two categories: the trace of a search-based exact model counter corresponds to a Decision-DNNF formula.  Taking advantage of literal equivalences, this paper designs an efficient model counting technique such that its trace is a generalization of Decision-DNNF formula.  We first propose a generalization of Decision-DNNF, called CCDD, to capture literal equivalences, then show that CCDD supports model counting in linear time, and finally design a model counter, called ExactMC, whose trace corresponds to CCDD.  We perform an extensive experimental evaluation over a comprehensive set of benchmarks and conduct performance comparison of ExactMC vis-a-vis the state of the art counters, c2d, Dsharp, miniC2D, D4, ADDMC, and Ganak. Our empirical evaluation demonstrates ExactMC can solve 885 instances while the prior state of the art could solve only 843 instances, representing a significant improvement of 42 instances.",
        "primary_area": "Constraint Satisfaction and Optimization",
        "author": "Yong Lai; Kuldeep S. Meel; Roland H. C. Yap",
        "authorids": "",
        "aff": "Key Laboratory of Symbolic Computation and Knowledge Engineering of Ministry of Education, Jilin University, China School of Computing, National University of Singapore; School of Computing, National University of Singapore; School of Computing, National University of Singapore",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16503/16503-13-19997-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03851-the-power-of-literal-equivalence-in-model-counting/",
        "doi": "10.1609/aaai.v35i5.16503",
        "pdf_size": 305606
    },
    {
        "id": "05151",
        "title": "The Price of Connectivity in Fair Division",
        "track": "main",
        "status": "Poster",
        "abstract": "We study the allocation of indivisible goods that form an undirected graph and quantify the loss of fairness when we impose a constraint that each agent must receive a connected subgraph. Our focus is on the well-studied fairness notion of maximin share fairness. We introduce the price of connectivity to capture the largest gap between the graph-specific and the unconstrained maximin share, and derive bounds on this quantity which are tight for large classes of graphs in the case of two agents and for paths and stars in the general case. For instance, with two agents we show that for biconnected graphs it is possible to obtain at least 3/4 of the maximin share with connected allocations, while for the remaining graphs the guarantee is at most 1/2. Our work demonstrates several applications of graph-theoretic tools and concepts to fair division problems.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Xiaohui Bei; Ayumi Igarashi; Xinhang Lu; Warut Suksompong",
        "authorids": "",
        "aff": "Nanyang Technological University; National Institute of Informatics; Nanyang Technological University; National University of Singapore",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16651/16651-13-20145-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05151-the-price-of-connectivity-in-fair-division/",
        "doi": "10.1609/aaai.v35i6.16651",
        "pdf_size": 136525
    },
    {
        "id": "10939",
        "title": "The Sample Complexity of Teaching by Reinforcement on Q-Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "We study the sample complexity of teaching, termed as ``teaching dimension\" (TDim) in the literature, for the teaching-by-reinforcement paradigm, where the teacher guides the student through rewards. This is distinct from the teaching-by-demonstration paradigm motivated by robotics applications, where the teacher teaches by providing demonstrations of state/action trajectories. The teaching-by-reinforcement paradigm applies to a wider range of real-world settings where a demonstration is inconvenient, but has not been studied systematically.  In this paper, we focus on a specific family of reinforcement learning algorithms, Q-learning, and characterize the TDim under different teachers with varying control power over the environment, and present matching optimal teaching algorithms. Our TDim results provide the minimum number of samples needed for reinforcement learning, and we discuss their connections to standard PAC-style RL sample complexity and teaching-by-demonstration sample complexity results. Our teaching algorithms have the potential to speed up RL agent learning in applications where a helpful teacher is available.",
        "primary_area": "Machine Learning V",
        "author": "Xuezhou Zhang; Shubham Bharti; Yuzhe Ma; Adish Singla; Xiaojin Zhu",
        "authorids": "",
        "aff": "University of Wisconsin-Madison; University of Wisconsin-Madison; University of Wisconsin-Madison; MPI-SWS; University of Wisconsin-Madison",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17306/17306-13-20800-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10939-the-sample-complexity-of-teaching-by-reinforcement-on-q-learning/",
        "doi": "10.1609/aaai.v35i12.17306",
        "pdf_size": 319196
    },
    {
        "id": "05742",
        "title": "The Smoothed Complexity of Computing Kemeny and Slater Rankings",
        "track": "main",
        "status": "Poster",
        "abstract": "The computational complexity of winner determination under common voting rules is a classical and fundamental topic in the field of computational social choice. Previous work has established the NP-hardness of winner determination under some commonly-studied voting rules, such as the Kemeny rule and the Slater rule. In a recent position paper, Baumeister, Hogrebe, and Rothe (2020) questioned the relevance of the worst-case nature of NP-hardness in social choice and proposed to conduct smoothed complexity analysis (Spielman and Teng 2009) under Blaser and Manthey\u2019s (2015) framework.   In this paper, we develop the first smoothed complexity results for winner determination in voting. We prove the smoothed hardness of Kemeny and Slater using the classical smoothed runtime analysis, and prove a parameterized typical-case smoothed easiness result for Kemeny. We also make an attempt of applying Blaser and Manthey\u2019s (2015) smoothed complexity framework in social choice contexts by proving that the framework categorizes an always-exponential-time brute force search algorithm as being smoothed poly-time, under a natural noise model based on the well-studied Mallows model in social choice and statistics. Overall, our results show that smoothed complexity analysis in computational social choice is a challenging and fruitful topic.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Lirong Xia; Weiqiang Zheng",
        "authorids": "",
        "aff": "RPI; Peking University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16720/16720-13-20214-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05742-the-smoothed-complexity-of-computing-kemeny-and-slater-rankings/",
        "doi": "10.1609/aaai.v35i6.16720",
        "pdf_size": 204704
    },
    {
        "id": "13252",
        "title": "The Style-Content Duality of Attractiveness: Learning to Write Eye-Catching Headlines via Disentanglement",
        "track": "main",
        "status": "Poster",
        "abstract": "Eye-catching headlines function as the first device to trigger more clicks, bringing reciprocal effect between producers and viewers. Producers can obtain more traffic and profits, and readers can have access to outstanding articles. When generating attractive headlines, it is important to not only capture the attractive content but also follow an eye-catching writtenstyle. In this paper, we propose a Disentanglement-based Attractive Headline Generator (DAHG) that generates headline which captures the attractive content following the attractive style. Concretely, we first devise a disentanglement module to divide the style and content of an attractive prototype headline into latent spaces, with two auxiliary constraints to ensure the two spaces are indeed disentangled. The latent content information is then used to further polish the document representation and help capture the salient part. Finally, the generator takes the polished document as input to generate headline under the guidance of the attractive style.  Extensive experiments on the public Kuaibao dataset show that DAHG achieves state-of-the-art performance.  Human evaluation also demonstrates that DAHG triggers 22% more clicks than existing models.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Mingzhe Li; Xiuying Chen; Min Yang; Shen Gao; Dongyan Zhao; Rui Yan",
        "authorids": "",
        "aff": "Peking University; Peking University; Chinese Academy of Sciences; Peking University; Peking University; Renmin University of China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17565/17565-13-21059-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13252-the-style-content-duality-of-attractiveness-learning-to-write-eye-catching-headlines-via-disentanglement/",
        "doi": "10.1609/aaai.v35i15.17565",
        "pdf_size": 3048369
    },
    {
        "id": "06670",
        "title": "The Tractability of SHAP-Score-Based Explanations for Classification over Deterministic and Decomposable Boolean Circuits",
        "track": "main",
        "status": "Poster",
        "abstract": "Scores based on Shapley values are widely used for providing explanations to classification results over machine learning models. A prime example of this is the influential SHAP-score, a version of the Shapley value that can help explain the result of a learned model on a specific entity by assigning a score to every feature. While in general computing Shapley values is a computationally intractable problem, it has recently been claimed that the SHAP-score can be computed in polynomial time over the class of decision trees. In this paper, we provide a proof of a stronger result over Boolean models: the SHAP-score can be computed in polynomial time over deterministic and decomposable Boolean circuits. Such circuits, also known as tractable Boolean circuits, generalize a wide range of Boolean circuits and binary decision diagrams classes, including binary decision trees, Ordered Binary Decision Diagrams (OBDDs) and Free Binary Decision Diagrams (FBDDs). We also establish the computational limits of the notion of SHAP-score by observing that, under a mild condition, computing it over a class of Boolean models is always polynomially as hard as the model counting problem for that class. This implies that both determinism and decomposability are essential properties for the circuits that we consider, as removing one or the other renders the problem of computing the SHAP-score intractable (namely, #P-hard).",
        "primary_area": "Machine Learning I",
        "author": "Marcelo Arenas; Pablo Barcel\u00f3; Leopoldo Bertossi; Mika\u00ebl Monet",
        "authorids": "",
        "aff": "Department of Computer Science, Universidad Cat\u00f3lica de Chile Institute for Mathematical and Computational Engineering, Universidad Cat\u00f3lica de Chile IMFD Chile; Institute for Mathematical and Computational Engineering, Universidad Cat\u00f3lica de Chile IMFD Chile; Universidad Adolfo Ib\u00e1\u00f1ez, FIC IMFD Chile; Univ. Lille, Inria, CNRS, Centrale Lille, UMR 9189 - CRIStAL, F-59000 Lille, France",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16825/16825-13-20319-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06670-the-tractability-of-shap-score-based-explanations-for-classification-over-deterministic-and-decomposable-boolean-circuits/",
        "doi": "10.1609/aaai.v35i8.16825",
        "pdf_size": 162393
    },
    {
        "id": "00003",
        "title": "The Undergraduate Games Corpus: A Dataset for Machine Perception of Interactive Media",
        "track": "main",
        "status": "Poster",
        "abstract": "Machine perception research primarily focuses on processing static inputs (e.g. images and texts). We are interested in machine perception of interactive media (such as games, apps, and complex web applications) where interactive audience choices have long-term implications for the audience experience. While there is ample research on AI methods for the task of playing games (often just one game at a time), this work is difficult to apply to new and in-development games or to use for non-playing tasks such as similarity-based retrieval or authoring assistance. In response, we contribute a corpus of 755 games and structured metadata, spread across several platforms (Twine, Bitsy, Construct, and Godot), with full source and assets available and appropriately licensed for use and redistribution in research. Because these games were sourced from student projects in an undergraduate game development program, they reference timely themes in their content and represent a variety of levels of design polish rather than only representing past commercial successes. This corpus could accelerate research in understanding interactive media while anchoring that work in freshly-developed games intended as legitimate human experiences (rather than lab-created AI testbeds). We validate the utility of this corpus by setting up the novel task of predicting tags relevant to the player experience from the game source code, showing that representations that better exploit the structure of the media outperform a text-only baseline.",
        "primary_area": "Application Domains",
        "author": "Barrett R. Anderson; Adam M. Smith",
        "authorids": "",
        "aff": "UC Santa Cruz; UC Santa Cruz",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16071/16071-13-19565-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00003-the-undergraduate-games-corpus-a-dataset-for-machine-perception-of-interactive-media/",
        "doi": "10.1609/aaai.v35i1.16071",
        "pdf_size": 2315464
    },
    {
        "id": "07160",
        "title": "The Value-Improvement Path: Towards Better Representations for Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "In value-based reinforcement learning (RL), unlike in supervised learning, the agent faces not a single, stationary, approximation problem, but a sequence of value prediction problems. Each time the policy improves, the nature of the problem changes, shifting both the distribution of states and their values. In this paper we take a novel perspective, arguing that the value prediction problems faced by an RL agent should not be addressed in isolation, but rather as a single, holistic, prediction problem. An RL algorithm generates a sequence of policies that, at least approximately, improve towards the optimal policy. We explicitly characterize the associated sequence of value functions and call it the value-improvement path. Our main idea is to approximate the value-improvement path holistically, rather than to solely track the value function of the current policy. Specifically, we discuss the impact that this holistic view of RL has on representation learning. We demonstrate that a representation that spans the past value-improvement path will also provide an accurate value approximation for future policy improvements. We use this insight to better understand existing approaches to auxiliary tasks and to propose new ones. To test our hypothesis empirically, we augmented a standard deep RL agent with an auxiliary task of learning the value-improvement path. In a study of Atari 2600 games, the augmented agent achieved approximately double the mean and median performance of the baseline agent.",
        "primary_area": "Machine Learning I",
        "author": "Will Dabney; Andr\u00e9 Barreto; Mark Rowland; Robert Dadashi; John Quan; Marc G. Bellemare; David Silver",
        "authorids": "",
        "aff": "DeepMind; DeepMind; DeepMind; Google Research; DeepMind; Google Research; DeepMind",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16880/16880-13-20374-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07160-the-value-improvement-path-towards-better-representations-for-reinforcement-learning/",
        "doi": "10.1609/aaai.v35i8.16880",
        "pdf_size": 594754
    },
    {
        "id": "12293",
        "title": "Theoretical Analyses of Multi-Objective Evolutionary Algorithms on Multi-Modal Objectives",
        "track": "main",
        "status": "Poster",
        "abstract": "Previous theory work on multi-objective evolutionary algorithms considers mostly easy problems that are composed of unimodal objectives. This paper takes a first step towards a deeper understanding of how evolutionary algorithms solve multi-modal multi-objective problems. We propose the OneJumpZeroJump problem, a bi-objective problem whose single objectives are isomorphic to the classic jump functions benchmark. We prove that the simple evolutionary multi-objective optimizer (SEMO) cannot compute the full Pareto front. In contrast, for all problem sizes n and all jump sizes k in [4..n/2-1], the global SEMO (GSEMO) covers the Pareto front in \u0398((n-2k)n^k) iterations in expectation. To improve the performance, we combine the GSEMO with two approaches, a heavy-tailed mutation operator and a stagnation detection strategy, that showed advantages in single-objective multi-modal problems. Runtime improvements of asymptotic order at least k^\u03a9(k) are shown for both strategies. Our experiments verify the substantial runtime gains already for moderate problem sizes. Overall, these results show that the ideas recently developed for single-objective evolutionary algorithms can be effectively employed also in multi-objective optimization.",
        "primary_area": "Search and Optimization",
        "author": "Benjamin Doerr; Weijie Zheng",
        "authorids": "",
        "aff": "Laboratoire d'Informatique (LIX), \u00c9cole Polytechnique, CNRS, Institut Polytechnique de Paris, Palaiseau, France; Guangdong Provincial Key Laboratory of Brain-inspired Intelligent Computation, Department of Computer Science and Engineering, Southern University of Science and Technology, Shenzhen, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17459/17459-13-20953-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12293-theoretical-analyses-of-multi-objective-evolutionary-algorithms-on-multi-modal-objectives/",
        "doi": "10.1609/aaai.v35i14.17459",
        "pdf_size": 178257
    },
    {
        "id": "09558",
        "title": "Theoretically Principled Deep RL Acceleration via Nearest Neighbor Function Approximation",
        "track": "main",
        "status": "Poster",
        "abstract": "Recently, deep reinforcement learning (RL) has achieved remarkable empirical success by integrating deep neural networks into RL frameworks. However, these algorithms often require a large number of training samples and admit little theoretical understanding. To mitigate these issues, we propose a theoretically principled nearest neighbor (NN) function approximator that can replace the value networks in deep RL methods. Inspired by human similarity judgments, the NN approximator estimates the action values using rollouts on past observations and can provably obtain a small regret bound that depends only on the intrinsic complexity of the environment. We present (1) Nearest Neighbor Actor-Critic (NNAC), an online policy gradient algorithm that demonstrates the practicality of combining function approximation with deep RL, and (2) a plug-and-play NN update module that aids the training of existing deep RL methods. Experiments on classical control and MuJoCo locomotion tasks show that the NN-accelerated agents achieve higher sample efficiency and stability than the baseline agents. Based on its theoretical benefits, we believe that the NN approximator can be further applied to other complex domains to speed-up learning.",
        "primary_area": "Machine Learning IV",
        "author": "Junhong Shen; Lin F. Yang",
        "authorids": "",
        "aff": "University of California, Los Angeles; University of California, Los Angeles",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17151/17151-13-20645-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09558-theoretically-principled-deep-rl-acceleration-via-nearest-neighbor-function-approximation/",
        "doi": "10.1609/aaai.v35i11.17151",
        "pdf_size": 485018
    },
    {
        "id": "10227",
        "title": "Tied Block Convolution: Leaner and Better CNNs with Shared Thinner Filters",
        "track": "main",
        "status": "Poster",
        "abstract": "Convolution is the main building block of a convolutional neural network (CNN).  We observe that an optimized CNN often has highly correlated filters as the number of channels increases with depth, reducing the expressive power of feature representations.     We propose Tied Block Convolution (TBC) that shares the same thinner filter over equal blocks of channels and produces multiple responses with a single filter. The concept of TBC can also be extended to group convolution and fully connected layers, and can be applied to various backbone networks and attention modules.  Our extensive experimentation on classification, detection, instance segmentation, and attention demonstrates that TBC is consistently leaner and significantly better than standard convolution and group convolution. On attention, with 64 times fewer parameters, our TiedSE performs on par with the standard SE.   On detection and segmentation, TBC can effectively handle highly overlapping instances, whereas standard CNNs often fail to accurately aggregate information in the presence of occlusion and result in multiple redundant partial object proposals.  By sharing filters across channels, TBC reduces correlation and delivers a sizable gain of 6% in the average precision for object detection on MS-COCO when the occlusion ratio is 80%.",
        "primary_area": "Machine Learning IV",
        "author": "Xudong Wang; Stella X. Yu",
        "authorids": "",
        "aff": "UC Berkeley / ICSI; UC Berkeley / ICSI",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17226/17226-13-20720-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10227-tied-block-convolution-leaner-and-better-cnns-with-shared-thinner-filters/",
        "doi": "10.1609/aaai.v35i11.17226",
        "pdf_size": 4710965
    },
    {
        "id": "11674",
        "title": "Tightening Robustness Verification of Convolutional Neural Networks with Fine-Grained Linear Approximation",
        "track": "main",
        "status": "Poster",
        "abstract": "The robustness of neural networks can be quantitatively indicated by a lower bound within which any perturbation does not alter the original input\u2019s classification result. A certified lower bound is also a criterion to evaluate the performance of robustness verification approaches. In this paper, we present a tighter linear approximation approach for the robustness verification of Convolutional Neural Networks (CNNs). By the tighter approximation, we can tighten the robustness verification of CNNs, i.e., proving they are robust within a larger 10 perturbation distance. Furthermore, our approach is applicable to general sigmoid-like activation functions. We implement DeepCert, the resulting verification toolkit. We evaluate it with open-source benchmarks, including LeNet and the models trained on MNIST and CIFAR. Experimental results show that DeepCert outperforms other state-of-the-art robustness verification tools with at most 286.28% improvement to the certified lower bound and 1566.76 times speedup for the same neural networks.",
        "primary_area": "Philosophy and Ethics of AI",
        "author": "Yiting Wu; Min Zhang",
        "authorids": "",
        "aff": "Shanghai Key Laboratory for Trustworthy Computing, East China Normal University; Shanghai Key Laboratory for Trustworthy Computing, East China Normal University Shanghai Institute of Intelligent Science and Technology, Tongji University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17388/17388-13-20882-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11674-tightening-robustness-verification-of-convolutional-neural-networks-with-fine-grained-linear-approximation/",
        "doi": "10.1609/aaai.v35i13.17388",
        "pdf_size": 232533
    },
    {
        "id": "09567",
        "title": "Time Series Anomaly Detection with Multiresolution Ensemble Decoding",
        "track": "main",
        "status": "Poster",
        "abstract": "Recurrent autoencoder is a popular model for time series anomaly detection, in which outliers or abnormal segments are identified by their high reconstruction errors. However, existing recurrent autoencoders can easily suffer from overfitting and error accumulation due to sequential decoding. In this paper, we propose a simple yet efficient recurrent network ensemble called Recurrent Autoencoder with Multiresolution Ensemble Decoding (RAMED). By using decoders with different decoding lengths and a new coarse-to-fine fusion mechanism, lower-resolution information can help long-range decoding for decoders with higher-resolution outputs. A multiresolution shape-forcing loss is further introduced to encourage decoders' outputs at multiple resolutions to match the input's global temporal shape. Finally, the output from the decoder with the highest resolution is used to obtain an anomaly score at each time step. Extensive empirical studies on real-world benchmark data sets demonstrate that the proposed RAMED model outperforms recent strong baselines on time series anomaly detection.",
        "primary_area": "Machine Learning IV",
        "author": "Lifeng Shen; Zhongzhong Yu; Qianli Ma; James T. Kwok",
        "authorids": "",
        "aff": "The Hong Kong University of Science and Technology; South China University of Technology; South China University of Technology; The Hong Kong University of Science and Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17152/17152-13-20646-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09567-time-series-anomaly-detection-with-multiresolution-ensemble-decoding/",
        "doi": "10.1609/aaai.v35i11.17152",
        "pdf_size": 570122
    },
    {
        "id": "06859",
        "title": "Time Series Domain Adaptation via Sparse Associative Structure Alignment",
        "track": "main",
        "status": "Poster",
        "abstract": "Domain adaptation on time series data is an important but challenging task. Most of the existing works in this area are based on the learning of the domain-invariant representation of the data with the help of restrictions like MMD. However, such extraction of the domain-invariant representation is a non-trivial task for time series data, due to the complex dependence among the timestamps. In detail, in the fully dependent time series, a small change of the time lags or the offsets may lead to difficulty in the domain invariant extraction. Fortunately, the stability of the causality inspired us to explore the domain invariant structure of the data. To reduce the difficulty in the discovery of causal structure, we relax it to the sparse associative structure and propose a novel sparse associative structure alignment model for domain adaptation. First, we generate the segment set to exclude the obstacle of offsets. Second, the intra-variables and inter-variables sparse attention mechanisms are devised to extract associative structure time-series data with considering time lags. Finally, the associative structure alignment is used to guide the transfer of knowledge from the source domain to the target one. Experimental studies not only verify the good performance of our methods on three real-world datasets but also provide some insightful discoveries on the transferred knowledge.",
        "primary_area": "Machine Learning I",
        "author": "Ruichu Cai; Jiawei Chen; Zijian Li; Wei Chen; Keli Zhang; Junjian Ye; Zhuozhang Li; Xiaoyan Yang; Zhenjie Zhang",
        "authorids": "",
        "aff": "Guangdong University of Technology; Guangdong University of Technology; Guangdong University of Technology; Guangdong University of Technology; Huawei Noah\u2019s Ark Lab; Huawei Noah's Ark Lab; Guangdong University of Technology; Guangdong University of Technology; Guangdong University of Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16846/16846-13-20340-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06859-time-series-domain-adaptation-via-sparse-associative-structure-alignment/",
        "doi": "10.1609/aaai.v35i8.16846",
        "pdf_size": 394572
    },
    {
        "id": "05841",
        "title": "Time to Transfer: Predicting and Evaluating Machine-Human Chatting Handoff",
        "track": "main",
        "status": "Poster",
        "abstract": "Is chatbot able to completely replace the human agent? The short answer could be \u2013 ``it depends...''. For some challenging cases, e.g., dialogue's topical spectrum spreads beyond the training corpus coverage, the chatbot may malfunction and return unsatisfied utterances. This problem can be addressed by introducing the Machine-Human Chatting Handoff (MHCH) which enables human-algorithm collaboration. To detect the normal/transferable utterances, we propose a Difficulty-Assisted Matching Inference (DAMI) network, utilizing difficulty-assisted encoding to enhance the representations of utterances. Moreover, a matching inference mechanism is introduced to capture the contextual matching features. A new evaluation metric, Golden Transfer within Tolerance (GT-T), is proposed to assess the performance by considering the tolerance property of the MHCH. To provide insights into the task and validate the proposed model, we collect two new datasets. Extensive experimental results are presented and contrasted against a series of baseline models to demonstrate the efficacy of our model on MHCH.",
        "primary_area": "Human-Computation and Crowd Sourcing",
        "author": "Jiawei Liu; Zhe Gao; Yangyang Kang; Zhuoren Jiang; Guoxiu He; Changlong Sun; Xiaozhong Liu; Wei Lu",
        "authorids": "",
        "aff": "Wuhan University; Alibaba Group; Alibaba Group; Zhejiang University; Wuhan University; Alibaba Group Zhejiang University; Indiana University Bloomington; Wuhan University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16731/16731-13-20225-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05841-time-to-transfer-predicting-and-evaluating-machine-human-chatting-handoff/",
        "doi": "10.1609/aaai.v35i7.16731",
        "pdf_size": 684930
    },
    {
        "id": "11299",
        "title": "Time-Independent Planning for Multiple Moving Agents",
        "track": "main",
        "status": "Poster",
        "abstract": "Typical Multi-agent Path Finding (MAPF) solvers assume that agents move synchronously, thus neglecting the reality gap in timing assumptions, e.g., delays caused by an imperfect execution of asynchronous moves. So far, two policies enforce a robust execution of MAPF plans taken as input: either by forcing agents to synchronize or by executing plans while preserving temporal dependencies. This paper proposes an alternative approach, called time-independent planning, which is both online and distributed. We represent reality as a transition system that changes configurations according to atomic actions of agents, and use it to generate a time-independent schedule. Empirical results in a simulated environment with stochastic delays of agents' moves support the validity of our proposal.",
        "primary_area": "Multiagent Systems",
        "author": "Keisuke Okumura; Yasumasa Tamura; Xavier D\u00e9fago",
        "authorids": "",
        "aff": "Tokyo Institute of Technology; Tokyo Institute of Technology; Tokyo Institute of Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17347/17347-13-20841-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11299-time-independent-planning-for-multiple-moving-agents/",
        "doi": "10.1609/aaai.v35i13.17347",
        "pdf_size": 2415818
    },
    {
        "id": "02576",
        "title": "To Choose or to Fuse? Scale Selection for Crowd Counting",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we address the large scale variation problem in crowd counting by taking full advantage of the multi-scale feature representations in a multi-level network. We implement such an idea by keeping the counting error of a patch as small as possible with a proper feature level selection strategy, since a specific feature level tends to perform better for a certain range of scales. However, without scale annotations, it is sub-optimal and error-prone to manually assign the predictions for heads of different scales to specific feature levels. Therefore, we propose a Scale-Adaptive Selection Network (SASNet), which automatically learns the internal correspondence between the scales and the feature levels. Instead of directly using the predictions from the most appropriate feature level as the final estimation, our SASNet also considers the predictions from other feature levels via weighted average, which helps to mitigate the gap between discrete feature levels and continuous scale variation. Since the heads in a local patch share roughly a same scale, we conduct the adaptive selection strategy in a patch-wise style. However, pixels within a patch contribute different counting errors due to the various difficulty degrees of learning. Thus, we further propose a Pyramid Region Awareness Loss (PRA Loss) to recursively select the most hard sub-regions within a patch until reaching the pixel level. With awareness of whether the parent patch is over-estimated or under-estimated, the fine-grained optimization with the PRA Loss for these region-aware hard pixels helps to alleviate the inconsistency problem between training target and evaluation metric. The state-of-the-art results on four datasets demonstrate the superiority of our approach.  The code will be available at: https://github.com/TencentYoutuResearch/CrowdCounting-SASNet.",
        "primary_area": "Computer Vision II",
        "author": "Qingyu Song; Changan Wang; Yabiao Wang; Ying Tai; Chengjie Wang; Jilin Li; Jian Wu; Jiayi Ma",
        "authorids": "",
        "aff": "Tencent Youtu Lab Zhejiang University; Tencent Youtu Lab; Tencent Youtu Lab; Tencent Youtu Lab; Tencent Youtu Lab; Tencent Youtu Lab; Zhejiang University; Wuhan University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16360/16360-13-19854-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02576-to-choose-or-to-fuse-scale-selection-for-crowd-counting/",
        "doi": "10.1609/aaai.v35i3.16360",
        "pdf_size": 1191800
    },
    {
        "id": "08410",
        "title": "Token-Aware Virtual Adversarial Training in Natural Language Understanding",
        "track": "main",
        "status": "Poster",
        "abstract": "Gradient-based adversarial training is widely used in improving the robustness of neural networks, while it cannot be easily adapted to natural language processing tasks since the embedding space is discrete. In natural language processing fields, virtual adversarial training is introduced since texts are discrete and cannot be perturbed by gradients directly.  Alternatively, virtual adversarial training, which generates perturbations on the embedding space, is introduced in NLP tasks. Despite its success, existing virtual adversarial training methods generate perturbations roughly constrained by Frobenius normalization balls. To craft fine-grained perturbations, we propose a Token-Aware Virtual Adversarial Training method. We introduce a token-level accumulated perturbation vocabulary to initialize the perturbations better and use a token-level normalization ball to constrain these perturbations pertinently. Experiments show that our method improves the performance of pre-trained models such as BERT and ALBERT in various tasks by a considerable margin. The proposed method improves the score of the GLUE benchmark from 78.3 to 80.9 using BERT model and it also enhances the performance of sequence labeling and text classification tasks.",
        "primary_area": "Machine Learning II",
        "author": "Linyang Li; Xipeng Qiu",
        "authorids": "",
        "aff": "Fudan University; Fudan University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17022/17022-13-20516-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08410-token-aware-virtual-adversarial-training-in-natural-language-understanding/",
        "doi": "10.1609/aaai.v35i9.17022",
        "pdf_size": 186741
    },
    {
        "id": "09135",
        "title": "Top-k Ranking Bayesian Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel approach to top-k ranking Bayesian optimization (top-k ranking BO) which is a practical and significant generalization of  preferential BO to handle top-k ranking and tie/indifference observations. We first design a surrogate model that is not only capable of catering to the above observations, but is also supported by a classic random utility model. Another equally important contribution is the introduction of the first information-theoretic acquisition function in BO with preferential observation called multinomial predictive entropy search (MPES) which is flexible in handling these observations and optimized for all inputs of a query jointly. MPES possesses superior performance compared with existing acquisition functions that select the inputs of a query one at a time greedily. We empirically evaluate the performance of MPES using several synthetic benchmark functions,  CIFAR-10 dataset, and  SUSHI preference dataset.",
        "primary_area": "Machine Learning III",
        "author": "Quoc Phong Nguyen; Sebastian Tay; Bryan Kian Hsiang Low; Patrick Jaillet",
        "authorids": "",
        "aff": "National University of Singapore; National University of Singapore; National University of Singapore; Massachusetts Institute of Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17103/17103-13-20597-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09135-top-k-ranking-bayesian-optimization/",
        "doi": "10.1609/aaai.v35i10.17103",
        "pdf_size": 542857
    },
    {
        "id": "14176",
        "title": "Topic-Aware Multi-turn Dialogue Modeling",
        "track": "main",
        "status": "Poster",
        "abstract": "In the retrieval-based multi-turn dialogue modeling, it remains a challenge to select the most appropriate response according to extracting salient features in context utterances. As a conversation goes on, topic shift at discourse-level naturally happens through the continuous multi-turn dialogue context. However, all known retrieval-based systems are satisfied with exploiting local topic words for context utterance representation but fail to capture such essential global topic-aware clues at discourse-level. Instead of taking topic-agnostic n-gram utterance as processing unit for matching purpose in existing systems, this paper presents a novel topic-aware solution for multi-turn dialogue modeling, which segments and extracts topic-aware utterances in an unsupervised way, so that the resulted model is capable of capturing salient topic shift at discourse-level in need and thus effectively track topic flow during multi-turn conversation. Our topic-aware modeling is implemented by a newly proposed unsupervised topic-aware segmentation algorithm and Topic-Aware Dual-attention Matching (TADAM) Network, which matches each topic segment with the response in a dual cross-attention way. Experimental results on three public datasets show TADAM can outperform the state-of-the-art method, especially by 3.3% on E-commerce dataset that has an obvious topic shift.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Yi Xu; Hai Zhao; Zhuosheng Zhang",
        "authorids": "",
        "aff": "Department of Computer Science and Engineering, Shanghai Jiao Tong University Key Laboratory of Shanghai Education Commission for Intelligent Interaction and Cognitive Engineering, Shanghai Jiao Tong University, Shanghai, China MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University; Department of Computer Science and Engineering, Shanghai Jiao Tong University Key Laboratory of Shanghai Education Commission for Intelligent Interaction and Cognitive Engineering, Shanghai Jiao Tong University, Shanghai, China MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University; Department of Computer Science and Engineering, Shanghai Jiao Tong University Key Laboratory of Shanghai Education Commission for Intelligent Interaction and Cognitive Engineering, Shanghai Jiao Tong University, Shanghai, China MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17668/17668-13-21162-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14176-topic-aware-multi-turn-dialogue-modeling/",
        "doi": "10.1609/aaai.v35i16.17668",
        "pdf_size": 349682
    },
    {
        "id": "14665",
        "title": "Topic-Oriented Spoken Dialogue Summarization for Customer Service with Saliency-Aware Topic Modeling",
        "track": "main",
        "status": "Poster",
        "abstract": "In a customer service system, dialogue summarization can boost service efficiency by automatically creating summaries for long spoken dialogues in which customers and agents try to address issues about specific topics. In this work, we focus on topic-oriented dialogue summarization, which generates highly abstractive summaries that preserve the main ideas from dialogues. In spoken dialogues, abundant dialogue noise and common semantics could obscure the underlying informative content, making the general topic modeling approaches difficult to apply. In addition, for customer service, role-specific information matters and is an indispensable part of a summary. To effectively perform topic modeling on dialogues and capture multi-role information, in this work we propose a novel topic-augmented two-stage dialogue summarizer (TDS) jointly with a saliency-aware neural topic model (SATM) for topic-oriented summarization of customer service dialogues. Comprehensive studies on a real-world Chinese customer service dataset demonstrated the superiority of our method against several strong baselines.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Yicheng Zou; Lujun Zhao; Yangyang Kang; Jun Lin; Minlong Peng; Zhuoren Jiang; Changlong Sun; Qi Zhang; Xuanjing Huang; Xiaozhong Liu",
        "authorids": "",
        "aff": "Fudan University; Alibaba Group; Alibaba Group; Alibaba Group; Fudan University; Zhejiang University; Alibaba Group Zhejiang University; Fudan University; Fudan University; Indiana University Bloomington",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17723/17723-13-21217-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14665-topic-oriented-spoken-dialogue-summarization-for-customer-service-with-saliency-aware-topic-modeling/",
        "doi": "10.1609/aaai.v35i16.17723",
        "pdf_size": 814562
    },
    {
        "id": "07721",
        "title": "Topology Distance: A Topology-Based Approach for Evaluating Generative Adversarial Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Automatic evaluation of the goodness of Generative Adversarial Networks (GANs) has been a challenge for the field of machine learning. In this work, we propose a distance complementary to existing measures: Topology Distance (TD), the main idea behind which is to compare the geometric and topological features of the latent manifold of real data with those of generated data. More specifically, we build Vietoris-Rips complex on image features, and define TD based on the differences in persistent-homology groups of the two manifolds. We compare TD with the most commonly-used and relevant measures in the field, including Inception Score (IS), Fr'echet Inception Distance (FID), Kernel Inception Distance (KID) and Geometry Score (GS), in a range of experiments on various datasets. We demonstrate the unique advantage and superiority of our proposed approach over the aforementioned metrics. A combination of our empirical results and the theoretical argument we propose in favour of TD, strongly supports the claim that TD is a powerful candidate metric that researchers can employ when aiming to automatically evaluate the goodness of GANs\u2019 learning.",
        "primary_area": "Machine Learning II",
        "author": "Danijela Horak; Simiao Yu; Gholamreza Salimi-Khorshidi",
        "authorids": "",
        "aff": "AIG; AIG; AIG University of Oxford",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16943/16943-13-20437-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07721-topology-distance-a-topology-based-approach-for-evaluating-generative-adversarial-networks/",
        "doi": "10.1609/aaai.v35i9.16943",
        "pdf_size": 13933396
    },
    {
        "id": "06271",
        "title": "Topology-Aware Correlations Between Relations for Inductive Link Prediction in Knowledge Graphs",
        "track": "main",
        "status": "Poster",
        "abstract": "Inductive link prediction---where entities during training and inference stages can be different---has been shown to be promising for completing continuously evolving knowledge graphs. Existing models of inductive reasoning mainly focus on predicting missing links by learning logical rules. However, many existing approaches do not take into account semantic correlations between relations, which are commonly seen in real-world knowledge graphs. To address this challenge, we propose a novel inductive reasoning approach, namely TACT, which can effectively exploit Topology-Aware CorrelaTions between relations in an entity-independent manner. TACT is inspired by the observation that the semantic correlation between two relations is highly correlated to their topological structure in knowledge graphs. Specifically, we categorize all relation pairs into several topological patterns, and then propose a Relational Correlation Network (RCN) to learn the importance of the different patterns for inductive link prediction. Experiments demonstrate that TACT can effectively model semantic correlations between relations, and significantly outperforms existing state-of-the-art methods on benchmark datasets for the inductive link prediction task.",
        "primary_area": "Knowledge Representation and Reasoning",
        "author": "Jiajun Chen; Huarui He; Feng Wu; Jie Wang",
        "authorids": "",
        "aff": "University of Science and Technology of China; University of Science and Technology of China; University of Science and Technology of China; University of Science and Technology of China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16779/16779-13-20273-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06271-topology-aware-correlations-between-relations-for-inductive-link-prediction-in-knowledge-graphs/",
        "doi": "10.1609/aaai.v35i7.16779",
        "pdf_size": 398610
    },
    {
        "id": "02118",
        "title": "Toward Realistic Virtual Try-on Through Landmark Guided Shape Matching",
        "track": "main",
        "status": "Poster",
        "abstract": "Image-based virtual try-on aims to synthesize the customer image with an in-shop clothes image to acquire seamless and natural try-on results, which have attracted increasing attentions. The main procedures of image-based virtual try-on usually consist of clothes image generation and try-on image synthesis, whereas prior arts cannot guarantee satisfying clothes results when facing large geometric changes and complex clothes patterns, which further deteriorates the afterwards try-on results. To address this issue, we propose a novel virtual try-on network based on landmark-guided shape matching (LM-VTON). Specifically, the clothes image generation progressively learns the warped clothes and refined clothes in an end-to-end manner, where we introduce a landmark-based constraint in Thin-Plate Spline (TPS) warping to inject finer deformation constraints around the clothes. The try-on process synthesizes the warped clothes with personal characteristics via a semantic indicator. Qualitative and quantitative experiments on two public datasets validate the superiority of the proposed method, especially for challenging cases such as large geometric changes and complex clothes patterns. Code will be available at https://github.com/lgqfhwy/LM-VTON.",
        "primary_area": "Computer Vision II",
        "author": "Guoqiang Liu; Dan Song; Ruofeng Tong; Min Tang",
        "authorids": "",
        "aff": "Zhejiang University; Tianjin University; Zhejiang University; Zhejiang University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16309/16309-13-19803-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02118-toward-realistic-virtual-try-on-through-landmark-guided-shape-matching/",
        "doi": "10.1609/aaai.v35i3.16309",
        "pdf_size": 4241170
    },
    {
        "id": "09958",
        "title": "Toward Robust Long Range Policy Transfer",
        "track": "main",
        "status": "Poster",
        "abstract": "Humans can master a new task within a few trials by drawing upon skills acquired through prior experience. To mimic this capability, hierarchical models combining primitive policies learned from prior tasks have been proposed. However, these methods fall short comparing to the human's range of transferability. We propose a method, which leverages the hierarchical structure to train the combination function and adapt the set of diverse primitive polices alternatively, to efficiently produce a range of complex behaviors on challenging new tasks. We also design two regularization terms to improve the diversity and utilization rate of the primitives in the pre-training phase. We demonstrate that our method outperforms other recent policy transfer methods by combining and adapting these reusable primitives in tasks with continuous action space. The experiment results further show that our approach provides a broader transferring range. The ablation study also show the regularization terms are critical for long range policy transfer. Finally, we show that our method consistently outperforms other methods when the quality of the primitives varies.",
        "primary_area": "Machine Learning IV",
        "author": "Wei-Cheng Tseng; Jin-Siang Lin; Yao-Min Feng; Min Sun",
        "authorids": "",
        "aff": "National Tsing Hua University; National Tsing Hua University; National Tsing Hua University; National Tsing Hua University Appier Inc., Taiwan MOST Joint Research Center for AI Technology and All Vista Healthcare, Taiwan",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17196/17196-13-20690-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09958-toward-robust-long-range-policy-transfer/",
        "doi": "10.1609/aaai.v35i11.17196",
        "pdf_size": 4219909
    },
    {
        "id": "10560",
        "title": "Toward Understanding the Influence of Individual Clients in Federated Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Federated learning allows mobile clients to jointly train a global model without sending their private data to a central server. Extensive works have studied the performance guarantee of the global model, however, it is still unclear how each individual client influences the collaborative training process. In this work, we defined a new notion, called {em Fed-Influence}, to quantify this influence over the model parameters, and proposed an effective and efficient algorithm to estimate this metric. In particular, our design satisfies several desirable properties: (1) it requires neither retraining nor retracing, adding only linear computational overhead to clients and the server; (2) it strictly maintains the tenets of federated learning, without revealing any client's local private data; and (3) it works well on both convex and non-convex loss functions, and does not require the final model to be optimal. Empirical results on a synthetic dataset and the FEMNIST dataset demonstrate that our estimation method can approximate Fed-Influence with small bias. Further, we show an application of Fed-Influence in model debugging.",
        "primary_area": "Machine Learning V",
        "author": "Yihao Xue; Chaoyue Niu; Zhenzhe Zheng; Shaojie Tang; Chengfei Lyu; Fan Wu; Guihai Chen",
        "authorids": "",
        "aff": "Shanghai Jiao Tong University; Shanghai Jiao Tong University; Shanghai Jiao Tong University; University of Texas at Dallas; Alibaba Group; Shanghai Jiao Tong University; Shanghai Jiao Tong University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17263/17263-13-20757-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10560-toward-understanding-the-influence-of-individual-clients-in-federated-learning/",
        "doi": "10.1609/aaai.v35i12.17263",
        "pdf_size": 4986127
    },
    {
        "id": "00759",
        "title": "Towards Balanced Defect Prediction with Better Information Propagation",
        "track": "main",
        "status": "Poster",
        "abstract": "Defect prediction, the task of predicting the presence of defects in source code artifacts, has broad application in software development. Defect prediction faces two major challenges, label scarcity, where only a small percentage of code artifacts are labeled, and data imbalance, where the majority of labeled artifacts are non-defective. Moreover, current defect prediction methods ignore the impact of information propagation among code artifacts and this negligence leads to performance degradation. In this paper, we propose DPCAG, a novel model to address the above three issues. We treat code artifacts as nodes in a graph, and learn to propagate influence among neighboring nodes iteratively in an EM framework. DPCAG dynamically adjusts the contributions of each node and selects high-confidence nodes for data augmentation. Experimental results on real-world benchmark datasets show that DPCAG improves performance compare to the state-of-the-art models. In particular, DPCAG achieves substantial performance superiority when measured by Matthews Correlation Coefficient (MCC), a metric that is widely acknowledged to be the most suitable for imbalanced data.",
        "primary_area": "Application Domains",
        "author": "Xianda Zheng; Yuan-Fang Li; Huan Gao; Yuncheng Hua; Guilin Qi",
        "authorids": "",
        "aff": "School of Cyber Science and Engineering, Southeast University, Nanjing, China; Faculty of Information Technology, Monash University, Melbourne, Australia; Microsoft Asia-Pacific Research and Development Group, Suzhou, China; School of Computer Science and Engineering, Southeast University, Nanjing, China; School of Cyber Science and Engineering, Southeast University, Nanjing, China School of Computer Science and Engineering, Southeast University, Nanjing, China Key Laboratory of Computer Network and Information Integration, Southeast University, Nanjing, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16157/16157-13-19651-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00759-towards-balanced-defect-prediction-with-better-information-propagation/",
        "doi": "10.1609/aaai.v35i1.16157",
        "pdf_size": 255226
    },
    {
        "id": "04537",
        "title": "Towards Consumer Loan Fraud Detection: Graph Neural Networks with Role-Constrained Conditional Random Field",
        "track": "main",
        "status": "Poster",
        "abstract": "Consumer loans, i.e., loans to finance consumers to buy certain types of expenditures, is increasingly popular in e-commerce platform. Different from traditional loans with mortgage, online consumer loans only take personal credit as collateral for loans. Consequently, loan fraud detection is particularly critical for lenders to avoid economic loss. Previous methods mainly leverage applicant's attributes and historical behavior for loan fraud detection. Although these methods gain success at detecting potential charge-offs, yet they perform worse when multiple persons with various roles (e.g., sellers, intermediaries) collude to apply fraudulent loan. To combat this challenge, we consider the problem of loan fraud detection via exploiting roles of users and multi-type social relationships among users. We propose a novel Graph neural network with a Role-constrained Conditional random field, namely GRC, to learn the representation of applicants and detect loan fraud based on the learned representation. The proposed model characterizes the multiple types of relationships via self-attention mechanism and employs conditional random field to constrain users with the same role to have similar representation. We validate the proposed model through experiments in large-scale auto-loan scenario. Extensive experiments demonstrate that our model achieves state-of-the-art results in loan fraud detection on Alipay, one online credit payment service serving more than 450 million users in China.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Bingbing Xu; Huawei Shen; Bingjie Sun; Rong An; Qi Cao; Xueqi Cheng",
        "authorids": "",
        "aff": "Institute of Computing Technology, University of Chinese Academy of Sciences; Institute of Computing Technology, University of Chinese Academy of Sciences; Ant Financial Services Group; Ant Financial Services Group; Institute of Computing Technology, University of Chinese Academy of Sciences; Institute of Computing Technology, University of Chinese Academy of Sciences",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16582/16582-13-20076-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04537-towards-consumer-loan-fraud-detection-graph-neural-networks-with-role-constrained-conditional-random-field/",
        "doi": "10.1609/aaai.v35i5.16582",
        "pdf_size": 1017002
    },
    {
        "id": "09657",
        "title": "Towards Domain Invariant Single Image Dehazing",
        "track": "main",
        "status": "Poster",
        "abstract": "Presence of haze in images obscures underlying information, which is undesirable in applications requiring accurate environment information. To recover such an image, a dehazing algorithm should localize and recover affected regions while ensuring consistency between recovered and its neighboring regions. However owing to fixed receptive field of convolutional kernels and non uniform haze distribution, assuring consistency between regions is difficult. In this paper, we utilize an encoder-decoder based network architecture to perform the task of dehazing and integrate an spatially aware channel attention mechanism to enhance features of interest beyond the receptive field of traditional conventional kernels. To ensure performance consistency across diverse range of haze densities, we utilize greedy localized data augmentation mechanism. Synthetic datasets are typically used to ensure a large amount of paired training samples, however the methodology to generate such samples introduces a gap between them and real images while accounting for only uniform haze distribution and overlooking more realistic scenario of non-uniform haze distribution resulting in inferior dehazing performance when evaluated on real datasets. Despite this, the abundance of paired samples within synthetic datasets cannot be ignored. Thus to ensure performance consistency across diverse datasets, we train the proposed network within an adversarial prior-guided framework that relies on a generated image along with its low and high frequency components to determine if properties of dehazed images matches those of ground truth. We preform extensive experiments to validate the dehazing and domain invariance performance of proposed framework across diverse domains and report state-of-the-art (SoTA) results. The source code with pretrained models will be available at https://github.com/PS06/DIDH.",
        "primary_area": "Machine Learning IV",
        "author": "Pranjay Shyam; Kuk-Jin Yoon; Kyung-Soo Kim",
        "authorids": "",
        "aff": "Korea Advanced Institute of Science and technology (KAIST), Daejeon, Republic of Korea; Korea Advanced Institute of Science and technology (KAIST), Daejeon, Republic of Korea; Korea Advanced Institute of Science and technology (KAIST), Daejeon, Republic of Korea",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17162/17162-13-20656-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09657-towards-domain-invariant-single-image-dehazing/",
        "doi": "10.1609/aaai.v35i11.17162",
        "pdf_size": 15731318
    },
    {
        "id": "07457",
        "title": "Towards Effective Context for Meta-Reinforcement Learning: an Approach based on Contrastive Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Context, the embedding of previous collected trajectories, is a powerful construct for Meta-Reinforcement Learning (Meta-RL) algorithms. By conditioning on an effective context, Meta-RL policies can easily generalize to new tasks within a few adaptation steps. We argue that improving the quality of context involves answering two questions: 1. How to train a compact and sufficient encoder that can embed the task-specific information contained in prior trajectories? 2. How to collect informative trajectories of which the corresponding context reflects the specification of tasks? To this end, we propose a novel Meta-RL framework called CCM (Contrastive learning augmented Context-based Meta-RL). We first focus on the contrastive nature behind different tasks and leverage it to train a compact and sufficient context encoder. Further, we train a separate exploration policy and theoretically derive a new information-gain-based objective which aims to collect informative trajectories in a few steps. Empirically, we evaluate our approaches on common benchmarks as well as several complex sparse-reward environments. The experimental results show that CCM outperforms state-of-the-art algorithms by addressing previously mentioned problems respectively.",
        "primary_area": "Machine Learning I",
        "author": "Haotian Fu; Hongyao Tang; Jianye Hao; Chen Chen; Xidong Feng; Dong Li; Wulong Liu",
        "authorids": "",
        "aff": "College of Intelligence and Computing, Tianjin University; College of Intelligence and Computing, Tianjin University; College of Intelligence and Computing, Tianjin University; Noah\u2019s Ark Lab, Huawei; Noah\u2019s Ark Lab, Huawei; Department of Automation, Tsinghua University; Noah\u2019s Ark Lab, Huawei; Noah\u2019s Ark Lab, Huawei",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16914/16914-13-20408-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07457-towards-effective-context-for-meta-reinforcement-learning-an-approach-based-on-contrastive-learning/",
        "doi": "10.1609/aaai.v35i8.16914",
        "pdf_size": 806103
    },
    {
        "id": "00689",
        "title": "Towards Efficient Selection of Activity Trajectories based on Diversity and Coverage",
        "track": "main",
        "status": "Poster",
        "abstract": "With the prevalence of location based services, activity trajectories are being generated at a rapid pace. The activity trajectory data enriches traditional trajectory data with semantic activities of users, which not only shows where the users have been, but also the preference of users. However, the large volume of data is expensive for people to explore. To address this issue, we study the problem of Diversity-aware Activity Trajectory Selection (DaATS). Given a region of interest for a user, it finds a small number of representative activity trajectories that can provide the user with a broad coverage of different aspects of the region. The problem is challenging in both the efficiency of trajectory similarity computation and subset selection. To tackle the two challenges, we propose a novel solution by: (1) exploiting a deep metric learning method to speedup the similarity computation; and (2) proving that DaATS is an NP-hard problem, and developing an efficient approximation algorithm with performance guarantees. Experiments on two real-world datasets show that our proposal significantly outperforms state-of-the-art baselines.",
        "primary_area": "Application Domains",
        "author": "Chengcheng Yang; Lisi Chen; Hao Wang; Shuo Shang",
        "authorids": "",
        "aff": "East China Normal University; University of Electronic Science and Technology of China; Nanjing University of Information Science and Technology; University of Electronic Science and Technology of China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16149/16149-13-19643-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00689-towards-efficient-selection-of-activity-trajectories-based-on-diversity-and-coverage/",
        "doi": "10.1609/aaai.v35i1.16149",
        "pdf_size": 479340
    },
    {
        "id": "10964",
        "title": "Towards Enabling Learnware to Handle Unseen Jobs",
        "track": "main",
        "status": "Poster",
        "abstract": "The learnware paradigm attempts to change the current style of machine learning deployment, i.e., user builds her own machine learning application almost from scratch, to a style where the previous efforts of other users can be reused, given a publicly available pool of machine learning models constructed by previous users for various tasks. Each learnware is a high-quality pre-trained model associated with its specification. Although there are many models in the learnware market, only a few, even none, may be potentially helpful for the current job. Therefore, how to identify and deploy useful models becomes one of the main concerns, which particularly matters when the user\u2019s job involves certain unseen parts not covered by the current learnware market. It becomes more challenging because, due to the privacy consideration, the raw data used for training models in the learnware market are inaccessible. In this paper, we develop a novel scheme that works can effectively reuse the learnwares even when the user\u2019s job involves unseen parts. Despite the raw training data are inaccessible, our approach can provably identify samples from the unseen parts while assigning the rest to proper models in the market for predicting under a certain condition. Empirical studies also validate the efficacy of our approach.",
        "primary_area": "Machine Learning V",
        "author": "Yu-Jie Zhang; Yu-Hu Yan; Peng Zhao; Zhi-Hua Zhou",
        "authorids": "",
        "aff": "Nanjing University; Nanjing University; Nanjing University; Nanjing University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17309/17309-13-20803-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10964-towards-enabling-learnware-to-handle-unseen-jobs/",
        "doi": "10.1609/aaai.v35i12.17309",
        "pdf_size": 702295
    },
    {
        "id": "13415",
        "title": "Towards Faithfulness in Open Domain Table-to-text Generation from an Entity-centric View",
        "track": "main",
        "status": "Poster",
        "abstract": "In open domain table-to-text generation, we notice the unfaithful generation usually contains hallucinated entities which can not be aligned to any input table record. We thus try to evaluate the generation faithfulness with two entity-centric metrics: table record coverage and the ratio of hallucinated entities in text, both of which are shown to have strong agreement with human judgements. Then based on these metrics,  we quantitatively analyze the correlation between training data quality and generation fidelity which indicates the potential usage of entity information in faithful generation. Motivated by these findings, we propose two methods for faithful generation: 1) augmented training by incorporating the auxiliary entity information, including both an augmented plan-based model and an unsupervised model and 2) training instance selection based on faithfulness ranking. We show these approaches improve generation fidelity in both full dataset setting and few shot setting by both automatic and human evaluations.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Tianyu Liu; Xin Zheng; Baobao Chang; Zhifang Sui",
        "authorids": "",
        "aff": "Ministry of Education (MOE) Key Laboratory of Computational Linguistics, School of EECS, Peking University; Chinese Information Processing Laboratory, Institute of Software, Chinese Academy of Sciences University of Chinese Academy of Sciences, Beijing, China; Ministry of Education (MOE) Key Laboratory of Computational Linguistics, School of EECS, Peking University Pengcheng Laboratory, Shenzhen, China; Ministry of Education (MOE) Key Laboratory of Computational Linguistics, School of EECS, Peking University Pengcheng Laboratory, Shenzhen, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17583/17583-13-21077-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13415-towards-faithfulness-in-open-domain-table-to-text-generation-from-an-entity-centric-view/",
        "doi": "10.1609/aaai.v35i15.17583",
        "pdf_size": 294665
    },
    {
        "id": "04001",
        "title": "Towards Faster Deep Collaborative Filtering via Hierarchical Decision Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "For personalized recommendations, collaborative filtering (CF) methods aim to recommend items to users based on data of historical user-item interactions. Deep learning has indicated success in improving performance of CF methods in recent works. However, to generate an item recommendation list for each user, a lot of deep learning based CF methods require every pair of users and items to be passed through multiple neural layers. This requires intensive computation and makes real-time end-to-end neural recommendations very costly. To address this issue, in this paper, we propose a new deep learning-based hierarchical decision network to filter out irrelevant items to save computation cost while maintaining good recommendation accuracy of deep CF methods. We also develop a distillation-based training algorithm, which uses a well-trained CF model as a teacher network to guide the training of the decision network. We conducted extensive  experiments on real-world benchmark datasets to verify the effectiveness of efficiency of our decision network for making recommendations. The experimental results indicate that the proposed decision network is able to maintain or even improve the recommendation quality in terms of various metrics and meanwhile enjoy lower computational cost.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Yu Chen; Sinno Jialin Pan",
        "authorids": "",
        "aff": "Nanyang Technological University; Nanyang Technological University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16520/16520-13-20014-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04001-towards-faster-deep-collaborative-filtering-via-hierarchical-decision-networks/",
        "doi": "10.1609/aaai.v35i5.16520",
        "pdf_size": 577428
    },
    {
        "id": "10523",
        "title": "Towards Feature Space Adversarial Attack by Style Perturbation",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a new adversarial attack to Deep Neural Networks for image classification. Different from most existing attacks that directly perturb input pixels, our attack focuses on perturbing abstract features, more specifically, features that denote styles, including interpretable styles such as vivid colors and sharp outlines, and uninterpretable ones. It induces model misclassification by injecting imperceptible style changes through an optimization procedure. We show that our attack can generate adversarial samples that are more natural-looking than the state-of-the-art unbounded attacks. The experiment also supports that existing pixel-space adversarial attack detection and defense techniques can hardly ensure robustness in the style-related feature space.",
        "primary_area": "Machine Learning V",
        "author": "Qiuling Xu; Guanhong Tao; Siyuan Cheng; Xiangyu Zhang",
        "authorids": "",
        "aff": "Purdue University; Purdue University; Purdue University; Purdue University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17259/17259-13-20753-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10523-towards-feature-space-adversarial-attack-by-style-perturbation/",
        "doi": "10.1609/aaai.v35i12.17259",
        "pdf_size": 1291506
    },
    {
        "id": "12998",
        "title": "Towards Fully Automated Manga Translation",
        "track": "main",
        "status": "Poster",
        "abstract": "We tackle the problem of machine translation of manga, Japanese comics. Manga translation involves two important problems in machine translation: context-aware and multimodal translation. Since text and images are mixed up in an unstructured fashion in Manga, obtaining context from the image is essential for manga translation. However, it is still an open problem how to extract context from image and integrate into MT models. In addition, corpus and benchmarks to train and evaluate such model is currently unavailable. In this paper, we make the following four contributions that establishes the foundation of manga translation research. First, we propose multimodal context-aware translation framework. We are the first to incorporate context information obtained from manga image. It enables us to translate texts in speech bubbles that cannot be translated without using context information (e.g., texts in other speech bubbles, gender of speakers, etc.). Second, for training the model, we propose the approach to automatic corpus construction from pairs of original manga and their translations, by which large parallel corpus can be constructed without any manual labeling. Third, we created a new benchmark to evaluate manga translation. Finally, on top of our proposed methods, we devised a first compleheisive system for fully automated manga translation.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Ryota Hinami; Shonosuke Ishiwatari; Kazuhiko Yasuda; Yusuke Matsui",
        "authorids": "",
        "aff": "Mantra Inc.; Mantra Inc.; The University of Tokyo; The University of Tokyo",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17537/17537-13-21031-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12998-towards-fully-automated-manga-translation/",
        "doi": "10.1609/aaai.v35i14.17537",
        "pdf_size": 4010507
    },
    {
        "id": "10514",
        "title": "Towards Generalized Implementation of Wasserstein Distance in GANs",
        "track": "main",
        "status": "Poster",
        "abstract": "Wasserstein GANs (WGANs), built upon the Kantorovich-Rubinstein (KR) duality of Wasserstein distance, is one of the most theoretically sound GAN models. However, in practice it does not always outperform other variants of GANs. This is mostly due to the imperfect implementation of the Lipschitz condition required by the KR duality. Extensive work has been done in the community with different implementations of the Lipschitz constraint, which, however, is still hard to satisfy the restriction perfectly in practice. In this paper, we argue that the strong Lipschitz constraint might be unnecessary for optimization. Instead, we take a step back and try to relax the Lipschitz constraint. Theoretically, we first demonstrate a more general dual form of the Wasserstein distance called the Sobolev duality, which relaxes the Lipschitz constraint but still maintains the favorable gradient property of the Wasserstein distance. Moreover, we show that the KR duality is actually a special case of the Sobolev duality. Based on the relaxed duality, we further propose a generalized WGAN training scheme named Sobolev Wasserstein GAN, and empirically demonstrate the improvement over existing methods with extensive experiments.",
        "primary_area": "Machine Learning V",
        "author": "Minkai Xu",
        "authorids": "",
        "aff": "University of Montreal",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17258/17258-13-20752-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10514-towards-generalized-implementation-of-wasserstein-distance-in-gans/",
        "doi": "10.1609/aaai.v35i12.17258",
        "pdf_size": 1325892
    },
    {
        "id": "03868",
        "title": "Towards More Practical and Efficient Automatic Dominance Breaking",
        "track": "main",
        "status": "Poster",
        "abstract": "Dominance breaking is shown to be an effective technique to improve the solving speed of Constraint Optimization Problems (COPs).  The paper proposes separate techniques to generalize and make more efficient the nogood generation phase of an automated dominance breaking framework by Lee and Zhong's. The first contribution is in giving conditions that allow skipping the checking of non-efficiently checkable constraints and yet still produce sufficient useful nogoods, thus opening up possibilities to apply the technique on COPs that were previously impractical. The second contribution identifies and avoids the generation of dominance breaking nogoods that are both logically and propagation redundant.  The nogood generation model is strengthened using the notion of Common Assignment Elimination to avoid generation of nogoods that are subsumed by other nogoods, thus reducing the search space substantially. Extensive experimentation confirms the benefits of the new proposals.",
        "primary_area": "Constraint Satisfaction and Optimization",
        "author": "Jimmy H.M. Lee; Allen Z. Zhong",
        "authorids": "",
        "aff": "The Chinese University of Hong Kong; The Chinese University of Hong Kong",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16505/16505-13-19999-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03868-towards-more-practical-and-efficient-automatic-dominance-breaking/",
        "doi": "10.1609/aaai.v35i5.16505",
        "pdf_size": 492436
    },
    {
        "id": "07620",
        "title": "Towards Reusable Network Components by Learning Compatible Representations",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes to make a first step towards compatible and hence reusable network components. Rather than training networks for different tasks independently, we adapt the training process to produce network components that are compatible across tasks. In particular, we split a network into two components, a features extractor and a target task head, and propose various approaches to accomplish compatibility between them. We systematically analyse these approaches on the task of image classification on standard datasets. We demonstrate that we can produce components which are directly compatible without any fine-tuning or compromising accuracy on the original tasks. Afterwards, we demonstrate the use of compatible components on three applications: Unsupervised domain adaptation, transferring classifiers across feature extractors with different architectures, and increasing the computational efficiency of transfer learning.",
        "primary_area": "Machine Learning II",
        "author": "Michael Gygli; Jasper Uijlings; Vittorio Ferrari",
        "authorids": "",
        "aff": "Google Research; Google Research; Google Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16932/16932-13-20426-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07620-towards-reusable-network-components-by-learning-compatible-representations/",
        "doi": "10.1609/aaai.v35i9.16932",
        "pdf_size": 1988789
    },
    {
        "id": "02738",
        "title": "Towards Robust Visual Information Extraction in Real World: New Dataset and Novel Solution",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual Information Extraction (VIE) has attracted considerable attention recently owing to its various advanced applications such as document understanding, automatic marking and intelligent education. Most existing works decoupled this problem into several independent sub-tasks of text spotting (text detection and recognition) and information extraction, which completely ignored the high correlation among them during optimization. In this paper, we propose a robust Visual Information Extraction System (VIES) towards real-world scenarios, which is an unified end-to-end trainable framework for simultaneous text detection, recognition and information extraction by taking a single document image as input and outputting the structured information. Specifically, the information extraction branch collects abundant visual and semantic representations from text spotting for multimodal feature fusion and conversely, provides higher-level semantic clues to contribute to the optimization of text spotting. Moreover, regarding the shortage of public benchmarks, we construct a fully-annotated dataset called EPHOIE (https://github.com/HCIILAB/EPHOIE), which is the first Chinese benchmark for both text spotting and visual information extraction. EPHOIE consists of 1,494 images of examination paper head with complex layouts and background, including a total of 15,771 Chinese handwritten or printed text instances. Compared with the state-of-the-art methods, our VIES shows significant superior performance on the EPHOIE dataset and achieves a 9.01% F-score gain on the widely used SROIE dataset under the end-to-end scenario.",
        "primary_area": "Computer Vision III",
        "author": "Jiapeng Wang; Chongyu Liu; Lianwen  Jin; Guozhi Tang; Jiaxin Zhang; Shuaitao Zhang; Qianying Wang; Yaqiang Wu; Mingxiang Cai",
        "authorids": "",
        "aff": "South China University of Technology; South China University of Tenology; South China University of Technology SCUT-Zhuhai Institute of Modern Industrial Innovation; South China University of Technology; South China University of Technology; South China University of Technology; Lenovo Research; Lenovo Research Xi\u2019an Jiaotong University; Lenovo Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16378/16378-13-19872-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02738-towards-robust-visual-information-extraction-in-real-world-new-dataset-and-novel-solution/",
        "doi": "10.1609/aaai.v35i4.16378",
        "pdf_size": 2788269
    },
    {
        "id": "13736",
        "title": "Towards Semantics-Enhanced Pre-Training: Can Lexicon Definitions Help Learning Sentence Meanings?",
        "track": "main",
        "status": "Poster",
        "abstract": "Self-supervised pre-training techniques, albeit relying on large amounts of text, have enabled rapid growth in learning language representations for natural language understanding. However, as radically empirical models on sentences, they are subject to the input data distribution, inevitably incorporating data bias and reporting bias, which may lead to inaccurate understanding of sentences. To address this problem, we propose to adopt a human learner's approach: when we cannot make sense of a word in a sentence, we often consult the dictionary for specific meanings; but can the same work for empirical models? In this work, we try to inform the pre-trained masked language models of word meanings for semantics-enhanced pre-training. To achieve a contrastive and holistic view of word meanings, a definition pair of two related words is presented to the masked language model such that the model can better associate a word with its crucial semantic features. Both intrinsic and extrinsic evaluations validate the proposed approach on semantics-orientated tasks, with an almost negligible increase of training data.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Xuancheng Ren; Xu Sun; Houfeng Wang; Qun Liu",
        "authorids": "",
        "aff": "Peking University; Peking University; Peking University; Huawei Noah's Ark Lab",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17619/17619-13-21113-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13736-towards-semantics-enhanced-pre-training-can-lexicon-definitions-help-learning-sentence-meanings/",
        "doi": "10.1609/aaai.v35i15.17619",
        "pdf_size": 519788
    },
    {
        "id": "13243",
        "title": "Towards Topic-Aware Slide Generation For Academic Papers With Unsupervised Mutual Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Slides are commonly used to present information and tell stories. In academic and research communities, slides are typically used to summarize findings in accepted papers for presentation in meetings and conferences. These slides for academic papers usually contain common and essential topics such as major contributions, model design, experiment details and future work. In this paper, we aim to automatically generate slides for academic papers. We first conducted an in-depth analysis of how humans create slides. We then mined frequently used slide topics. Given a topic, our approach extracts relevant sentences in the paper to provide the draft slides. Due to the lack of labeling data, we integrate prior knowledge of ground truth sentences into a log-linear model to create an initial pseudo-target distribution. Two sentence extractors are learned collaboratively and bootstrap the performance of each other. Evaluation results on a labeled test set show that our model can extract more relevant sentences than baseline methods. Human evaluation also shows slides generated by our model can serve as a good basis for preparing the final presentations.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Da-Wei Li; Danqing Huang; Tingting Ma; Chin-Yew Lin",
        "authorids": "",
        "aff": "School of Software and Microelectronics, Peking University; Microsoft Research Asia; Harbin Institute of Technology; Microsoft Research Asia",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17564/17564-13-21058-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13243-towards-topic-aware-slide-generation-for-academic-papers-with-unsupervised-mutual-learning/",
        "doi": "10.1609/aaai.v35i15.17564",
        "pdf_size": 356306
    },
    {
        "id": "09886",
        "title": "Towards Trustworthy Predictions from Deep Neural Networks with Fast Adversarial Calibration",
        "track": "main",
        "status": "Poster",
        "abstract": "To facilitate a wide-spread acceptance of AI systems guiding decision making in real-world applications, trustworthiness of deployed models is key. That is, it is crucial for predictive models to be uncertainty-aware and yield well-calibrated (and thus trustworthy) predictions for both in-domain samples as well as under domain shift. Recent efforts to account for predictive uncertainty include post-processing steps for trained neural networks, Bayesian neural networks as well as alternative non-Bayesian approaches such as ensemble approaches and evidential deep learning. Here, we propose an efficient yet general modelling approach for obtaining well-calibrated, trustworthy probabilities for samples obtained after a domain shift. We introduce a new training strategy combining an entropy-encouraging loss term with an adversarial calibration loss term and demonstrate that this results in well-calibrated and technically trustworthy predictions for a wide range of domain drifts. We comprehensively evaluate previously proposed approaches on different data modalities, a large range of data sets including sequence data, network architectures and perturbation strategies. We observe that our modelling approach substantially outperforms existing state-of-the-art approaches, yielding well-calibrated predictions under domain drift.",
        "primary_area": "Machine Learning IV",
        "author": "Christian Tomani; Florian Buettner",
        "authorids": "",
        "aff": "Technical University Munich Siemens AG, Munich; Siemens AG, Munich",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17188/17188-13-20682-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09886-towards-trustworthy-predictions-from-deep-neural-networks-with-fast-adversarial-calibration/",
        "doi": "10.1609/aaai.v35i11.17188",
        "pdf_size": 1072404
    },
    {
        "id": "01236",
        "title": "Towards Universal Physical Attacks on Single Object Tracking",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent studies show that small perturbations in video frames could misguide single object trackers. However, such attacks have been mainly designed for digital-domain videos (i.e., perturbation on full images), which makes them practically infeasible to evaluate the adversarial vulnerability of trackers in real-world scenarios. Here we made the first step towards physically feasible adversarial attacks against visual tracking in real scenes with a universal patch to camouflage single object trackers. Fundamentally different from physical object detection, the essence of single object tracking lies in the feature matching between the search image and templates, and we therefore specially design the maximum textural discrepancy (MTD), a resolution-invariant and target location-independent feature de-matching loss. The MTD distills global textural information of the template and search images at hierarchical feature scales prior to performing feature attacks. Moreover, we evaluate two shape attacks, the regression dilation and shrinking, to generate stronger and more controllable attacks. Further, we employ a set of transformations to simulate diverse visual tracking scenes in the wild. Experimental results show the effectiveness of the physically feasible attacks on SiamMask and SiamRPN++ visual trackers both in digital and physical scenes.",
        "primary_area": "Computer Vision I",
        "author": "Li Ding; Yongwei Wang; Kaiwen Yuan; Minyang Jiang; Ping Wang; Hua Huang; Z. Jane Wang",
        "authorids": "",
        "aff": "Xi'an Jiaotong University, University of British Columbia; University of British Columbia; University of British Columbia; University of British Columbia; Xi'an Jiaotong University; Beijing Normal University; University of British Columbia",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16211/16211-13-19705-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01236-towards-universal-physical-attacks-on-single-object-tracking/",
        "doi": "10.1609/aaai.v35i2.16211",
        "pdf_size": 2492393
    },
    {
        "id": "00836",
        "title": "Towards a Better Understanding of VR Sickness: Physical Symptom Prediction for VR Contents",
        "track": "main",
        "status": "Poster",
        "abstract": "We address the black-box issue of VR sickness assessment (VRSA) by evaluating the level of physical symptoms of VR sickness. For the VR contents inducing the similar VR sickness level, the physical symptoms can vary depending on the characteristics of the contents. Most of existing VRSA methods focused on assessing the overall VR sickness score. To make better understanding of VR sickness, it is required to predict and provide the level of major symptoms of VR sickness rather than overall degree of VR sickness. In this paper, we predict the degrees of main physical symptoms affecting the overall degree of VR sickness, which are disorientation, nausea, and oculomotor. In addition, we introduce a new large-scale dataset for VRSA including 360 videos with various frame rates, physiological signals, and subjective scores. On VRSA benchmark and our newly collected dataset, our approach shows a potential to not only achieve the highest correlation with subjective scores, but also to better understand which symptoms are the main causes of VR sickness.",
        "primary_area": "Cognitive Modeling and Cognitive Systems",
        "author": "Hak Gu Kim; Sangmin Lee; Seongyeop Kim; Heoun-taek Lim; Yong Man Ro",
        "authorids": "",
        "aff": "KAIST, Korea EPFL, Switzerland; KAIST, Korea; KAIST, Korea; KAIST, Korea; KAIST, Korea",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16166/16166-13-19660-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00836-towards-a-better-understanding-of-vr-sickness-physical-symptom-prediction-for-vr-contents/",
        "doi": "10.1609/aaai.v35i1.16166",
        "pdf_size": 483249
    },
    {
        "id": "00142",
        "title": "Towered Actor Critic For Handling Multiple Action Types In Reinforcement Learning For Drug Discovery",
        "track": "main",
        "status": "Poster",
        "abstract": "Reinforcement learning (RL) has made significant progress in both abstract and real-world domains, but the majority of state-of-the-art algorithms deal only with monotonic actions. However, some applications require agents to reason over different types of actions. Our application simulates reaction-based molecule generation, used as part of the drug discovery pipeline, and includes both uni-molecular and bi-molecular reactions. This paper introduces  a novel framework, towered actor critic (TAC), to handle multiple action types. The TAC framework is general in that it is designed to be combined with any existing RL algorithms for continuous action space. We combine it with TD3 to empirically obtain significantly better results than existing methods in the drug discovery setting. TAC is also applied to RL benchmarks in OpenAI Gym and results show that our framework can improve, or at least does not hurt, performance relative to standard TD3.",
        "primary_area": "Application Domains",
        "author": "Sai Krishna Gottipati; Yashaswi Pathak; Boris Sattarov; Sahir; Rohan Nuttall; Mohammad Amini; Matthew E. Taylor; Sarath Chandar",
        "authorids": "",
        "aff": "99andBeyond; International Institute of Information Technology, Hyderabad; 99andBeyond; Department of Computing Science, University of Alberta; Department of Computing Science, University of Alberta; 99andBeyond; Department of Computing Science, University of Alberta Alberta Machine Intelligence Institute (Amii) Canada CIFAR AI Chair; Mila - Quebec AI Institute Canada CIFAR AI Chair Ecole Polytechnique Montreal",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16087/16087-13-19581-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00142-towered-actor-critic-for-handling-multiple-action-types-in-reinforcement-learning-for-drug-discovery/",
        "doi": "10.1609/aaai.v35i1.16087",
        "pdf_size": 481631
    },
    {
        "id": "04883",
        "title": "Tracking Disease Outbreaks from Sparse Data with Bayesian Inference",
        "track": "main",
        "status": "Poster",
        "abstract": "The COVID-19 pandemic provides new motivation for a classic problem in epidemiology: estimating the empirical rate of transmission during an outbreak (formally, the time-varying reproduction number) from case counts. While standard methods exist, they work best at coarse-grained national or state scales with abundant data, and struggle to accommodate the partial observability and sparse data common at finer scales (e.g., individual schools or towns). For example, case counts may be sparse when only a small fraction of infections are caught by a testing program. Or, whether an infected individual tests positive may depend on the kind of test and the point in time when they are tested. We propose a Bayesian framework which accommodates partial observability in a principled manner. Our model places a Gaussian process prior over the unknown reproduction number at each time step and models observations sampled from the distribution of a specific testing program. For example, our framework can accommodate a variety of kinds of tests (viral RNA, antibody, antigen, etc.) and sampling schemes (e.g., longitudinal or cross-sectional screening). Inference in this framework is complicated by the presence of tens or hundreds of thousands of discrete latent variables. To address this challenge, we propose an efficient stochastic variational inference method which relies on a novel gradient estimator for the variational objective. Experimental results for an example motivated by COVID-19 show that our method produces an accurate and well-calibrated posterior, while standard methods for estimating the reproduction number can fail badly.",
        "primary_area": "AI Responses to the COVID-19 Pandemic",
        "author": "Bryan Wilder; Michael Mina; Milind Tambe",
        "authorids": "",
        "aff": "Harvard University; Harvard University; Harvard University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16621/16621-13-20115-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04883-tracking-disease-outbreaks-from-sparse-data-with-bayesian-inference/",
        "doi": "10.1609/aaai.v35i6.16621",
        "pdf_size": 1605811
    },
    {
        "id": "13979",
        "title": "Tracking Interaction States for Multi-Turn Text-to-SQL Semantic Parsing",
        "track": "main",
        "status": "Poster",
        "abstract": "The task of multi-turn text-to-SQL semantic parsing aims to translate natural language utterances in an interaction into SQL queries in order to answer them using a database which normally contains multiple table schemas. Previous studies on this task usually utilized contextual information to enrich utterance representations and to further influence the decoding process. While they ignored to describe and track the interaction states which are determined by history SQL queries and are related with the intent of current utterance. In this paper, two kinds of interaction states are defined based on schema items and SQL keywords separately. A relational graph neural network and a non-linear layer are designed to update the representations of these two states respectively. The dynamic schema-state and SQL-state representations are then utilized to decode the SQL query corresponding to current utterance. Experimental results on the challenging CoSQL dataset demonstrate the effectiveness of our proposed method, which achieves better performance than other published methods on the task leaderboard.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Run-Ze Wang; Zhen-Hua Ling; Jingbo Zhou; Yu Hu",
        "authorids": "",
        "aff": "National Engineering Laboratory for Speech and Language Information Processing, University of Science and Technology of China; National Engineering Laboratory for Speech and Language Information Processing, University of Science and Technology of China; Business Intelligence Lab, Baidu Research; iFLYTEK Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17646/17646-13-21140-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13979-tracking-interaction-states-for-multi-turn-text-to-sql-semantic-parsing/",
        "doi": "10.1609/aaai.v35i16.17646",
        "pdf_size": 328509
    },
    {
        "id": "00294",
        "title": "Traffic Flow Prediction with Vehicle Trajectories",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a spatiotemporal deep learning framework, Trajectory-based Graph Neural Network (TrGNN), that mines the underlying causality of flows from historical vehicle trajectories and incorporates that into road traffic prediction. The vehicle trajectory transition patterns are studied to explicitly model the spatial traffic demand via graph propagation along the road network; an attention mechanism is designed to learn the temporal dependencies based on neighborhood traffic status; and finally, a fusion of multi-step prediction is integrated into the graph neural network design. The proposed approach is evaluated with a real-world trajectory dataset. Experiment results show that the proposed TrGNN model achieves over 5% error reduction when compared with the state-of-the-art approaches across all metrics for normal traffic, and up to 14% for atypical traffic during peak hours or abnormal events. The advantage of trajectory transitions especially manifest itself in inferring high fluctuation of flows as well as non-recurrent flow patterns.",
        "primary_area": "Application Domains",
        "author": "Mingqian Li; Panrong Tong; Mo Li; Zhongming Jin; Jianqiang Huang; Xian-Sheng Hua",
        "authorids": "",
        "aff": "Alibaba-NTU Singapore Joint Research Institute, Nanyang Technological University, Singapore Alibaba Group; Alibaba-NTU Singapore Joint Research Institute, Nanyang Technological University, Singapore School of Computer Science and Engineering, Nanyang Technological University, Singapore; Alibaba-NTU Singapore Joint Research Institute, Nanyang Technological University, Singapore School of Computer Science and Engineering, Nanyang Technological University, Singapore; Alibaba Group; Alibaba-NTU Singapore Joint Research Institute, Nanyang Technological University, Singapore Alibaba Group; Alibaba Group",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16104/16104-13-19598-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00294-traffic-flow-prediction-with-vehicle-trajectories/",
        "doi": "10.1609/aaai.v35i1.16104",
        "pdf_size": 3234750
    },
    {
        "id": "00574",
        "title": "Traffic Shaping in E-Commercial Search Engine: Multi-Objective Online Welfare Maximization",
        "track": "main",
        "status": "Poster",
        "abstract": "The e-commercial search engine is the primary gateway for customers to find desired products and engage in online shopping. Besides displaying items to optimize for a single objective (i.e., relevance), ranking items needs to satisfy some other business requirements in practice. Recently, traffic shaping was introduced to incorporate multiple objectives in a constrained optimization framework. However, many practical business requirements can not explicitly represented by linear constraints as in the existing work, and this may limit the scalablity of their framework. This paper presents a unified framework from the aspect of multi-objective welfare maximization where we regard all business requirements as objectives to optimize. Our framework can naturally incorporate a wide range of application-driven requirements. In addition to formulating the problem, we design an online traffic splitting algorithm that allows us to flexibly adjust the priorities of different objectives, and it has rigorous theoretical guarantees over the adversarial scenario. We also run experiments on both synthetic and real-world datasets to validate our algorithms.",
        "primary_area": "Application Domains",
        "author": "Liucheng Sun; Chenwei Weng; Chengfu Huo; Weijun Ren; Guochuan Zhang; Xin Li",
        "authorids": "",
        "aff": "Alibaba Group Zhejiang University; Alibaba Group; Alibaba Group; Alibaba Group; Zhejiang University; Alibaba Group",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16136/16136-13-19630-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00574-traffic-shaping-in-e-commercial-search-engine-multi-objective-online-welfare-maximization/",
        "doi": "10.1609/aaai.v35i1.16136",
        "pdf_size": 222694
    },
    {
        "id": "08706",
        "title": "Train a One-Million-Way Instance Classifier for Unsupervised Visual Representation Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a simple unsupervised visual representation learning method with a pretext task of discriminating all images in a dataset using a parametric, instance-level classifier. The overall framework is a replica of a supervised classification model, where semantic classes (e.g., dog, bird, and ship) are replaced by instance IDs. However, scaling up the classification task from thousands of semantic labels to millions of instance labels brings specific challenges including 1) the large-scale softmax computation; 2) the slow convergence due to the infrequent visiting of instance samples; and 3) the massive number of negative classes that can be noisy. This work presents several novel techniques to handle these difficulties. First, we introduce a hybrid parallel training framework to make large-scale training feasible. Second, we present a raw-feature initialization mechanism for classification weights, which we assume offers a contrastive prior for instance discrimination and can clearly speed up converge in our experiments. Finally, we propose to smooth the labels of a few hardest classes to avoid optimizing over very similar negative pairs. While being conceptually simple, our framework achieves competitive or superior performance compared to state-of-the-art unsupervised approaches, i.e., SimCLR, MoCoV2, and PIC under ImageNet linear evaluation protocol and on several downstream visual tasks, verifying that full instance classification is a strong pretraining technique for many semantic visual tasks.",
        "primary_area": "Machine Learning III",
        "author": "Yu Liu; Lianghua Huang; Pan Pan; Bin Wang; Yinghui Xu; Rong Jin",
        "authorids": "",
        "aff": "Alibaba Group; Alibaba Group; Alibaba Group; Alibaba Group; Alibaba Group; Alibaba Group",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17055/17055-13-20549-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08706-train-a-one-million-way-instance-classifier-for-unsupervised-visual-representation-learning/",
        "doi": "10.1609/aaai.v35i10.17055",
        "pdf_size": 378586
    },
    {
        "id": "01700",
        "title": "Training Binary Neural Network without Batch Normalization for Image Super-Resolution",
        "track": "main",
        "status": "Poster",
        "abstract": "Recently, binary neural network (BNN) based super-resolution (SR) methods have enjoyed initial success in the SR field.  However, there is a noticeable  performance gap between the binarized model and the full-precision one. Furthermore, the batch normalization (BN) in binary SR networks introduces floating-point calculations, which is unfriendly to low-precision hardwares. Therefore, there is still room for improvement in terms of model performance and efficiency. Focusing on this issue, in this paper,  we first explore a novel binary training mechanism based on the feature distribution, allowing us to replace all BN layers with a simple training method.  Then, we construct a strong baseline by combining the highlights of recent binarization methods, which  already  surpasses the state-of-the-arts. Next, to train highly accurate binarized SR model, we also develop a lightweight network architecture and a multi-stage knowledge distillation strategy to  enhance the model representation ability.   Extensive experiments demonstrate that the proposed method not only presents advantages of lower computation as compared to conventional floating-point networks  but outperforms the state-of-the-art binary methods on the standard SR networks.",
        "primary_area": "Computer Vision I",
        "author": "Xinrui Jiang; Nannan Wang; Jingwei Xin; Keyu Li; Xi Yang; Xinbo Gao",
        "authorids": "",
        "aff": "State Key Laboratory of Integrated Services Networks School of Telecommunications Engineering, Xidian University; State Key Laboratory of Integrated Services Networks School of Telecommunications Engineering, Xidian University; State Key Laboratory of Integrated Services Networks School of Electronic Engineering, Xidian University; State Key Laboratory of Integrated Services Networks School of Telecommunications Engineering, Xidian University; State Key Laboratory of Integrated Services Networks School of Telecommunications Engineering, Xidian University; Chongqing Key Laboratory of Image Cognition Chongqing University of Posts and Telecommunications",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16263/16263-13-19757-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01700-16263-training-binary-neural-network-without-batch-normalization-for-image-super-resolution/",
        "doi": "10.1609/aaai.v35i2.16263",
        "pdf_size": 978980
    },
    {
        "id": "10320",
        "title": "Training Spiking Neural Networks with Accumulated Spiking Flow",
        "track": "main",
        "status": "Poster",
        "abstract": "The fast development of neuromorphic hardwares promotes Spiking Neural Networks (SNNs) to a thrilling research avenue. Current SNNs, though much efficient, are less effective compared with leading Artificial Neural Networks (ANNs) especially in supervised learning tasks. Recent efforts further demonstrate the potential of SNNs in supervised learning by introducing  approximated  backpropagation (BP) methods. To deal with the non-differentiable spike function in SNNs, these BP methods utilize information from the spatio-temporal domain to adjust the model parameters. With the increasing of time window and network size, the computational complexity of spatio-temporal backpropagation augments dramatically. In this paper, we propose a new backpropagation method for SNNs based on the accumulated spiking flow (ASF), i.e. ASF-BP. In the proposed ASF-BP method, updating parameters does not rely on the spike train of spiking neurons but leverage accumulated inputs and outputs of spiking neurons over the time window, which reduces the BP complexity significantly. We further present an adaptive linear estimation model to approach the dynamic characteristics of spiking neurons statistically. Experimental results demonstrate that with our proposed ASF-BP method, light-weight convolutional SNNs achieve superior performances compared with other spike-based BP methods on both non-neuromorphic (MNIST, CIFAR10) and neuromorphic (CIFAR10-DVS) datasets. The code is available at https://github.com/neural-lab/ASF-BP.",
        "primary_area": "Machine Learning V",
        "author": "Hao Wu; Yueyi Zhang; Wenming Weng; Yongting Zhang; Zhiwei Xiong; Zheng-Jun Zha; Xiaoyan Sun; Feng Wu",
        "authorids": "",
        "aff": "University of Science and Technology of China; University of Science and Technology of China; University of Science and Technology of China; University of Science and Technology of China; University of Science and Technology of China; University of Science and Technology of China; University of Science and Technology of China; University of Science and Technology of China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17236/17236-13-20730-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10320-training-spiking-neural-networks-with-accumulated-spiking-flow/",
        "doi": "10.1609/aaai.v35i12.17236",
        "pdf_size": 955513
    },
    {
        "id": "08627",
        "title": "TransTailor: Pruning the Pre-trained Model for Improved Transfer Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "The increasing of pre-trained models has significantly facilitated the performance on limited data tasks with transfer learning. However, progress on transfer learning mainly focuses on optimizing the weights of pre-trained models, which ignores the structure mismatch between the model and the target task. This paper aims to improve the transfer performance from another angle - in addition to tuning the weights, we tune the structure of pre-trained models, in order to better match the target task. To this end, we propose TransTailor, targeting at pruning the pre-trained model for improved transfer learning. Different from traditional pruning pipelines, we prune and fine-tune the pre-trained model according to the target-aware weight importance, generating an optimal sub-model tailored for a specific target task. In this way, we transfer a more suitable sub-structure that can be applied during fine-tuning to benefit the final performance. Extensive experiments on multiple pre-trained models and datasets demonstrate that TransTailor outperforms the traditional pruning methods and achieves competitive or even better performance than other state-of-the-art transfer learning methods while using a smaller model. Notably, on the Stanford Dogs dataset, TransTailor can achieve 2.7% accuracy improvement over other transfer methods with 20% fewer FLOPs.",
        "primary_area": "Machine Learning III",
        "author": "Bingyan Liu; Yifeng Cai; Yao Guo; Xiangqun Chen",
        "authorids": "",
        "aff": "Peking University; Peking University; Peking University; Peking University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17046/17046-13-20540-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08627-transtailor-pruning-the-pre-trained-model-for-improved-transfer-learning/",
        "doi": "10.1609/aaai.v35i10.17046",
        "pdf_size": 952418
    },
    {
        "id": "04838",
        "title": "Transfer Graph Neural Networks for Pandemic Forecasting",
        "track": "main",
        "status": "Poster",
        "abstract": "The recent outbreak of COVID-19 has affected millions of individuals around the world and has posed a significant challenge to global healthcare. From the early days of the pandemic, it became clear that it is highly contagious and that human mobility contributes significantly to its spread. In this paper, we utilize graph representation learning to capitalize on the underlying relationship of population movement with the spread of COVID-19. Specifically, we create a graph where the nodes correspond to a country's regions, the features include the region's history of COVID-19, and the edge weights denote human mobility from one region to another. Subsequently, we employ graph neural networks to predict the number of future cases, encoding the underlying diffusion patterns that govern the spread into our learning model. Furthermore, to account for the limited amount of training data, we capitalize on the pandemic's asynchronous outbreaks across countries and use a model-agnostic meta-learning based method to transfer knowledge from one country's model to another's. We compare the proposed approach against simple baselines and more traditional forecasting techniques in 4 European countries. Experimental results demonstrate the superiority of our method, highlighting the usefulness of GNNs in epidemiological prediction. Transfer learning provides the best model, highlighting its potential to improve the accuracy of the predictions in case of secondary waves, given data from past/parallel outbreaks.",
        "primary_area": "AI Responses to the COVID-19 Pandemic",
        "author": "George Panagopoulos; Giannis Nikolentzos; Michalis Vazirgiannis",
        "authorids": "",
        "aff": "Ecole Polytechnique, Palaiseau, France; Athens University of Economics and Business, Athens, Greece; \u00c9cole Polytechnique, Palaiseau, France",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16616/16616-13-20110-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04838-transfer-graph-neural-networks-for-pandemic-forecasting/",
        "doi": "10.1609/aaai.v35i6.16616",
        "pdf_size": 1803532
    },
    {
        "id": "07125",
        "title": "Transfer Learning for Efficient Iterative Safety Validation",
        "track": "main",
        "status": "Poster",
        "abstract": "Safety validation is important during the development of safety-critical autonomous systems but can require significant computational effort. Existing algorithms often start from scratch each time the system under test changes. We apply transfer learning to improve the efficiency of reinforcement learning based safety validation algorithms when applied to related systems. Knowledge from previous safety validation tasks is encoded through the action value function and transferred to future tasks with a learned set of attention weights. Including a learned state and action value transformation for each source task can improve performance even when systems have substantially different failure modes. We conduct experiments on safety validation tasks in gridworld and autonomous driving scenarios. We show that transfer learning can improve the initial and final performance of validation algorithms and reduce the number of training steps.",
        "primary_area": "Machine Learning I",
        "author": "Anthony Corso; Mykel J. Kochenderfer",
        "authorids": "",
        "aff": "Stanford University; Stanford University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16876/16876-13-20370-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07125-transfer-learning-for-efficient-iterative-safety-validation/",
        "doi": "10.1609/aaai.v35i8.16876",
        "pdf_size": 196173
    },
    {
        "id": "04546",
        "title": "Transformer-Style Relational Reasoning with Dynamic Memory Updating for Temporal Network Modeling",
        "track": "main",
        "status": "Poster",
        "abstract": "Network modeling aims to learn the latent representations of nodes such that the representations preserve both network structures and node attribute information. This problem is fundamental due to its prevalence in numerous domains. However, existing approaches either target the static networks or struggle to capture the complicated temporal dependency, while most real-world networks evolve over time and the success of network modeling hinges on the understanding of how entities are temporally connected. In this paper, we present TRRN, a transformer-style relational reasoning network with dynamic memory updating, to deal with the above challenges. TRRN employs multi-head self-attention to reason over a set of memories, which provides a multitude of shortcut paths for information to flow from past observations to the current latent representations. By utilizing the policy networks augmented with differentiable binary routers, TRRN estimates the possibility of each memory being activated and dynamically updates the memories at the time steps when they are most relevant. We evaluate TRRN with the tasks of node classification and link prediction on four real temporal network datasets. Experimental results demonstrate the consistent performance gains for TRRN over the leading competitors.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Dongkuan Xu; Junjie Liang; Wei Cheng; Hua Wei; Haifeng Chen; Xiang Zhang",
        "authorids": "",
        "aff": "The Pennsylvania State University; The Pennsylvania State University; NEC Laboratories America, Inc.; The Pennsylvania State University; NEC Laboratories America, Inc.; The Pennsylvania State University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16583/16583-13-20077-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04546-transformer-style-relational-reasoning-with-dynamic-memory-updating-for-temporal-network-modeling/",
        "doi": "10.1609/aaai.v35i5.16583",
        "pdf_size": 531521
    },
    {
        "id": "02180",
        "title": "Translate the Facial Regions You Like Using Self-Adaptive Region Translation",
        "track": "main",
        "status": "Poster",
        "abstract": "With the progression of Generative Adversarial Networks (GANs), image translation methods has achieved increasingly remarkable performance. However, most available methods can only achieve image level translation, which is unable to precisely control the regions to be translated. In this paper, we propose a novel self-adaptive region translation network (SART) for region-level translation, which uses region-adaptive instance normalization (RIN) and a region matching loss (RML) for this task. We first encode the style and content image for each region with style and content encoder. To translate both shape and texture of the target region, we inject region-adaptive style features into the decoder by RIN. To ensure independent translation among different regions, RML is proposed to measure the similarity between the non-translated/translated regions of content and translated images. Extensive experiments on three publicly available datasets, i.e. Morph, RaFD and CelebAMask-HQ, suggest that our approach demonstrate obvious improvement over state-of-the-art methods like StarGAN, SEAN and FUNIT. Our approach has further advantages in precise control of the regions to be translated. As a result, region level expression changes and step-by-step make-up can be achieved. The video demo is available at (https://youtu.be/DvIdmcR2LEc).",
        "primary_area": "Computer Vision II",
        "author": "Wenshuang Liu; Wenting Chen; Zhanjia Yang; Linlin Shen",
        "authorids": "",
        "aff": "Computer Vision Institute, School of Computer Science & Software Engineering, Shenzhen University, Shenzhen, China Shenzhen Institute of Artificial Intelligence & Robotics for Society, Shenzhen, China Guangdong Key Laboratory of Intelligent Information Processing, Shenzhen University, Shenzhen, China; Computer Vision Institute, School of Computer Science & Software Engineering, Shenzhen University, Shenzhen, China Shenzhen Institute of Artificial Intelligence & Robotics for Society, Shenzhen, China Guangdong Key Laboratory of Intelligent Information Processing, Shenzhen University, Shenzhen, China; Computer Vision Institute, School of Computer Science & Software Engineering, Shenzhen University, Shenzhen, China Shenzhen Institute of Artificial Intelligence & Robotics for Society, Shenzhen, China Guangdong Key Laboratory of Intelligent Information Processing, Shenzhen University, Shenzhen, China; Computer Vision Institute, School of Computer Science & Software Engineering, Shenzhen University, Shenzhen, China Shenzhen Institute of Artificial Intelligence & Robotics for Society, Shenzhen, China Guangdong Key Laboratory of Intelligent Information Processing, Shenzhen University, Shenzhen, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16316/16316-13-19810-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02180-translate-the-facial-regions-you-like-using-self-adaptive-region-translation/",
        "doi": "10.1609/aaai.v35i3.16316",
        "pdf_size": 1275592
    },
    {
        "id": "10923",
        "title": "Treatment Effect Estimation with Disentangled Latent Factors",
        "track": "main",
        "status": "Poster",
        "abstract": "Much research has been devoted to the problem of estimating treatment effects from observational data; however, most methods assume that the observed variables only contain confounders, i.e., variables that affect both the treatment and the outcome. Unfortunately, this assumption is frequently violated in real-world applications, since some variables only affect the treatment but not the outcome, and vice versa. Moreover, in many cases only the proxy variables of the underlying confounding factors can be observed. In this work, we first show the importance of differentiating confounding factors from instrumental and risk factors for both average and conditional average treatment effect estimation, and then we propose a variational inference approach to simultaneously infer latent factors from the observed variables, disentangle the factors into three disjoint sets corresponding to the instrumental, confounding, and risk factors, and use the disentangled factors for treatment effect estimation. Experimental results demonstrate the effectiveness of the proposed method on a wide range of synthetic, benchmark, and real-world datasets.",
        "primary_area": "Machine Learning V",
        "author": "Weijia Zhang; Lin Liu; Jiuyong Li",
        "authorids": "",
        "aff": "University of South Australia; University of South Australia; University of South Australia",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17304/17304-13-20798-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10923-treatment-effect-estimation-with-disentangled-latent-factors/",
        "doi": "10.1609/aaai.v35i12.17304",
        "pdf_size": 521542
    },
    {
        "id": "00030",
        "title": "TreeCaps: Tree-Based Capsule Networks for Source Code Processing",
        "track": "main",
        "status": "Poster",
        "abstract": "Recently program learning techniques have been proposed to process source code based on syntactical structures (e.g., abstract syntax trees) and/or semantic information (e.g., dependency graphs). While graphs may be better than trees at capturing code semantics, constructing the graphs from code inputs through the semantic analysis of multiple viewpoints can lead to inaccurate noises for a specific software engineering task. Compared to graphs, syntax trees are more precisely defined on the grammar and easier to parse; unfortunately, previous tree-based learning techniques have not been able to learn semantic information from trees to achieve better accuracy than graph-based techniques. We have proposed a new learning technique, named TreeCaps, by fusing together capsule networks with tree-based convolutional neural networks to achieve a learning accuracy higher than some existing graph-based techniques while it is based only on trees. TreeCaps introduces novel variable-to-static routing algorithms into the capsule networks to compensate for the loss of previous routing algorithms. Aside from accuracy, we also find that TreeCaps is the most robust to withstand those semantic-preserving program transformations that change code syntax without modifying the semantics. Evaluated on a large number of Java and C/C++ programs, TreeCaps models outperform prior deep learning models of program source code, in terms of both accuracy and robustness for program comprehension tasks such as code functionality classification and function name prediction. Our implementation is publicly available at: https://github.com/bdqnghi/treecaps.",
        "primary_area": "Application Domains",
        "author": "Nghi D. Q. Bui; Yijun Yu; Lingxiao Jiang",
        "authorids": "",
        "aff": "Trustworthy Open-Source Software Engineering Lab, Huawei Research Centre, Ireland; The Open University, UK; Singapore Management University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16074/16074-13-19568-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00030-treecaps-tree-based-capsule-networks-for-source-code-processing/",
        "doi": "10.1609/aaai.v35i1.16074",
        "pdf_size": 813089
    },
    {
        "id": "06312",
        "title": "Treewidth-Aware Complexity in ASP: Not all Positive Cycles are Equally Hard",
        "track": "main",
        "status": "Poster",
        "abstract": "It is well-known that deciding consistency for normal answer set programs (ASP) is NP-complete, thus, as hard as the satisfaction problem for propositional logic (SAT). The exponential time hypothesis (ETH) implies that the best algorithms to solve these problems take exponential time in the worst case. However, accounting for the treewidth, the consistency problem for ASP is slightly harder than SAT: while SAT can be solved by an algorithm that runs in exponential time in the treewidth k, ASP requires exponential time in k \u00b7 log(k). This extra cost is due to checking that there are no self-supported true atoms due to positive cycles in the program. In this paper, we refine this recent result and show that consistency for ASP can be decided in exponential time in k \u00b7 log(\u03b9) where \u03b9 is a novel measure, bounded by both treewidth k and the size of the largest strongly-connected component of the positive dependency graph of the program. We provide a treewidth-aware reduction from ASP to SAT that adheres to the above limit.",
        "primary_area": "Knowledge Representation and Reasoning",
        "author": "Jorge Fandinno; Markus Hecher",
        "authorids": "",
        "aff": "University of Nebraska Omaha University of Potsdam; University of Potsdam TU Wien",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16784/16784-13-20278-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06312-treewidth-aware-complexity-in-asp-not-all-positive-cycles-are-equally-hard/",
        "doi": "10.1609/aaai.v35i7.16784",
        "pdf_size": 207423
    },
    {
        "id": "05566",
        "title": "Trembling-Hand Perfection and Correlation in Sequential Games",
        "track": "main",
        "status": "Poster",
        "abstract": "We initiate the study of trembling-hand perfection in sequential (i.e., extensive-form) games with correlation. We introduce the extensive-form perfect correlated equilibrium (EFPCE) as a refinement of the classical extensive-form correlated equilibrium (EFCE) that amends its weaknesses off the equilibrium path. This is achieved by accounting for the possibility that the players may make mistakes while following recommendations independently at each information set of the game. After providing an axiomatic definition of EFPCE, we show that one always exists since any perfect (Nash) equilibrium constitutes an EFPCE, and that it is a refinement of EFCE, as any EFPCE is also an EFCE. Then, we prove that, surprisingly, computing an EFPCE is not harder than finding an EFCE, since the problem can be solved in polynomial time for general n-player extensive-form games (also with chance). This is achieved by formulating the problem as that of finding a limit solution (as $epsilon rightarrow 0$) to a suitably defined trembling LP parametrized by $epsilon$, featuring exponentially-many variables and polynomially-many constraints. To this end, we show how a recently developed polynomial-time algorithm for trembling LPs can be adapted to deal with problems having an exponential number of variables. This calls for the solution of a sequence of (non-trembling) LPs with exponentially-many variables and polynomially-many constraints, which is possible in polynomial time by applying an ellipsoid against hope approach.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Alberto Marchesi; Nicola Gatti",
        "authorids": "",
        "aff": "Politecnico di Milano; Politecnico di Milano",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16700/16700-13-20194-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05566-trembling-hand-perfection-and-correlation-in-sequential-games/",
        "doi": "10.1609/aaai.v35i6.16700",
        "pdf_size": 165742
    },
    {
        "id": "11125",
        "title": "Tri-level Robust Clustering Ensemble with Multiple Graph Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Clustering ensemble generates a consensus clustering result by integrating multiple weak base clustering results. Although it often provides more robust results compared with single clustering methods, it still suffers from the robustness problem if it does not treat the unreliability of base results carefully. Conventional clustering ensemble methods often use all data for ensemble, while ignoring the noises or outliers on the data. Although some robust clustering ensemble methods are proposed, which extract the noises on the data, they still characterize the robustness in a single level, and thus they cannot comprehensively handle the complicated robustness problem. In this paper, to address this problem, we propose a novel Tri-level Robust Clustering Ensemble (TRCE) method by transforming the clustering ensemble problem to a multiple graph learning problem. Just as its name implies, the proposed method tackles robustness problem in three levels: base clustering level, graph level and instance level. By considering the robustness problem in a more comprehensive way, the proposed TRCE can achieve a more robust consensus clustering result. Experimental results on benchmark datasets also demonstrate it. Our method often outperforms other state-of-the-art clustering ensemble methods. Even compared with the robust ensemble methods, ours also performs better.",
        "primary_area": "Machine Learning V",
        "author": "Peng Zhou; Liang Du; Yi-Dong Shen; Xuejun Li",
        "authorids": "",
        "aff": "School of Computer Science and Technology, Anhui University State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences; School of Computer and Information Technology, Shanxi University; State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences; School of Computer Science and Technology, Anhui University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17327/17327-13-20821-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11125-tri-level-robust-clustering-ensemble-with-multiple-graph-learning/",
        "doi": "10.1609/aaai.v35i12.17327",
        "pdf_size": 408633
    },
    {
        "id": "04671",
        "title": "Tripartite Collaborative Filtering with Observability and Selection for Debiasing Rating Estimation on Missing-Not-at-Random Data",
        "track": "main",
        "status": "Poster",
        "abstract": "Most collaborative filtering (CF) models estimate missing ratings with an implicit assumption that the ratings are missing-at-random, which may cause the biased rating estimation and degraded performance since recent deep exploration shows that ratings may likely be missing-not-at-random (MNAR). To debias MNAR rating estimation, we introduce item observability and user selection to depict the generation of MNAR ratings and propose a tripartite CF (TCF) framework to jointly model the triple aspects of rating generation: item observability, user selection, and ratings, and to estimate the MNAR ratings. An item observability variable is introduced to a complete observability model to infer whether an item is observable to a user. TCF also conducts a complete rating model for rating generation and utilizes a user selection model dependent on the item observability and rating values to model user selection of the observable items. We further elaborately instantiate TCF as a Tripartite Probabilistic Matrix Factorization model (TPMF) by leveraging the probabilistic matrix factorization. Besides, TPMF introduces multifaceted dependency between user selection and ratings to model the influence of user selection on ratings. Extensive experiments on synthetic and real-world datasets show that modeling item observability and user selection effectively debias MNAR rating estimation, and TPMF outperforms the state-of-the-art methods in estimating the MNAR ratings.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Qi Zhang; Longbing Cao; Chongyang Shi; Liang Hu",
        "authorids": "",
        "aff": "Beijing Institute of Technology University of Technology Sydney; University of Technology Sydney; Beijing Institute of Technology; DeepBlue Academy of Science Shanghai University of Technology Sydney",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16597/16597-13-20091-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04671-tripartite-collaborative-filtering-with-observability-and-selection-for-debiasing-rating-estimation-on-missing-not-at-random-data/",
        "doi": "10.1609/aaai.v35i5.16597",
        "pdf_size": 313158
    },
    {
        "id": "11415",
        "title": "TripleTree: A Versatile Interpretable Representation of Black Box Agents and their Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "In explainable artificial intelligence, there is increasing interest in understanding the behaviour of autonomous agents to build trust and validate performance. Modern agent architectures, such as those trained by deep reinforcement learning, are currently so lacking in interpretable structure as to effectively be black boxes, but insights may still be gained from an external, behaviourist perspective. Inspired by conceptual spaces theory, we suggest that a versatile first step towards general understanding is to discretise the state space into convex regions, jointly capturing similarities over the agent's action, value function and temporal dynamics within a dataset of observations. We create such a representation using a novel variant of the CART decision tree algorithm, and demonstrate how it facilitates practical understanding of black box agents through prediction, visualisation and rule-based explanation.",
        "primary_area": "Philosophy and Ethics of AI",
        "author": "Tom Bewley; Jonathan Lawry",
        "authorids": "",
        "aff": "Department of Engineering Mathematics, University of Bristol; Department of Engineering Mathematics, University of Bristol",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17360/17360-13-20854-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11415-tripletree-a-versatile-interpretable-representation-of-black-box-agents-and-their-environments/",
        "doi": "10.1609/aaai.v35i13.17360",
        "pdf_size": 1398341
    },
    {
        "id": "13961",
        "title": "Tune-In: Training Under Negative Environments with Interference for Attention Networks Simulating Cocktail Party Effect",
        "track": "main",
        "status": "Poster",
        "abstract": "We study the cocktail party problem and propose a novel attention network called Tune-In, abbreviated for training under negative environments with interference. It firstly learns two separate spaces of speaker-knowledge and speech-stimuli based on a shared feature space, where a new block structure is designed as the building block for all spaces, and then cooperatively solves different tasks. Between the two spaces, information is cast towards each other via a novel cross- and dual-attention mechanism, mimicking the bottom-up and top-down processes of a human's cocktail party effect. It turns out that substantially discriminative and generalizable speaker representations can be learnt in severely interfered conditions via our self-supervised training. The experimental results verify this seeming paradox. The learnt speaker embedding has superior discriminative power than a standard speaker verification method; meanwhile, Tune-In achieves remarkably better speech separation performances in terms of SI-SNRi and SDRi consistently in all test modes, and especially at lower memory and computational consumption, than state-of-the-art benchmark systems.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Jun Wang; Max W. Y. Lam; Dan Su; Dong Yu",
        "authorids": "",
        "aff": "Tencent AI Lab, Shenzhen, China; Tencent AI Lab, Shenzhen, China; Tencent AI Lab, Shenzhen, China; encent AI Lab, Bellevue WA, USA",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17644/17644-13-21138-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13961-tune-in-training-under-negative-environments-with-interference-for-attention-networks-simulating-cocktail-party-effect/",
        "doi": "10.1609/aaai.v35i16.17644",
        "pdf_size": 753853
    },
    {
        "id": "03895",
        "title": "Turbocharging Treewidth-Bounded Bayesian Network Structure Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a new approach for learning the structure of a treewidth-bounded Bayesian Network (BN). The key to our approach is applying an exact method (based on MaxSAT) locally, to improve the score of a heuristically computed BN. This approach allows us to scale the power of exact methods\u2014so far only applicable to BNs with several dozens of random variables\u2014to large BNs with several thousands of random variables. Our experiments show that our method improves the score of BNs provided by state-of-the-art heuristic methods, often significantly.",
        "primary_area": "Constraint Satisfaction and Optimization",
        "author": "Vaidyanathan Peruvemba Ramaswamy; Stefan Szeider",
        "authorids": "",
        "aff": "TU Wien, Vienna, Austria; TU Wien, Vienna, Austria",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16508/16508-13-20002-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03895-turbocharging-treewidth-bounded-bayesian-network-structure-learning/",
        "doi": "10.1609/aaai.v35i5.16508",
        "pdf_size": 250743
    },
    {
        "id": "00286",
        "title": "Two-Stream Convolution Augmented Transformer for Human Activity Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "Recognition of human activities is an important task due to its far-reaching applications such as healthcare system, context-aware applications, and security monitoring. Recently, WiFi based human activity recognition (HAR) is becoming ubiquitous due to its non-invasiveness. Existing WiFi-based HAR methods regard WiFi signals as a temporal sequence of channel state information (CSI), and employ deep sequential models (e.g., RNN, LSTM) to automatically capture channel-over-time features. Although being remarkably effective, they suffer from two major drawbacks. Firstly, the granularity of a single temporal point is blindly elementary for representing meaningful CSI patterns.  Secondly, the time-over-channel features are also important, and could be a natural data augmentation. To address the drawbacks, we propose a novel Two-stream Convolution Augmented Human Activity Transformer (THAT) model. Our model proposes to utilize a two-stream structure to capture both time-over-channel and channel-over-time features, and use the multi-scale convolution augmented transformer to capture range-based patterns. Extensive experiments on four real experiment datasets demonstrate that our model outperforms state-of-the-art models in terms of both effectiveness and efficiency.",
        "primary_area": "Application Domains",
        "author": "Bing Li; Wei Cui; Wei Wang; Le Zhang; Zhenghua Chen; Min Wu",
        "authorids": "",
        "aff": "University of New South Wales, Australia; Institute for Infocomm Research, Agency for Science, Technology and Research (ASTAR), Singapore; Dongguan University of Technology, China University of New South Wales, Australia; Institute for Infocomm Research, Agency for Science, Technology and Research (ASTAR), Singapore; Institute for Infocomm Research, Agency for Science, Technology and Research (ASTAR), Singapore; Institute for Infocomm Research, Agency for Science, Technology and Research (ASTAR), Singapore",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16103/16103-13-19597-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00286-two-stream-convolution-augmented-transformer-for-human-activity-recognition/",
        "doi": "10.1609/aaai.v35i1.16103",
        "pdf_size": 416340
    },
    {
        "id": "07151",
        "title": "Type-augmented Relation Prediction in Knowledge Graphs",
        "track": "main",
        "status": "Poster",
        "abstract": "Knowledge graphs (KGs) are of great importance to many real world applications, but they generally suffer from incomplete information in the form of missing relations between entities. Knowledge graph completion (also known as relation prediction) is the task of inferring missing facts given existing ones. Most of the existing work is proposed by maximizing the likelihood of observed instance-level triples. Not much attention, however, is paid to the ontological information, such as type information of entities and relations. In this work, we propose a type-augmented relation prediction (TaRP) method, where we apply both the type information and instance-level information for the relation prediction. In particular, type information and instance-level information are encoded as prior probabilities and likelihoods of relations respectively, and are combined by following the Bayes' rule. Our proposed TaRP method achieves significantly better performance than state-of-the-art methods on four benchmark datasets: FB15K, FB15K-237, YAGO26K-906, and DB111K-174. In addition, we show that the TaRP achieves the significantly improved data efficiency. More importantly, the type information extracted from a specific dataset can generalize well to different datasets through the proposed TaRP model.",
        "primary_area": "Machine Learning I",
        "author": "Zijun Cui; Pavan Kapanipathi; Kartik Talamadupula; Tian Gao; Qiang Ji",
        "authorids": "",
        "aff": "Rensselaer Polytechnic Institute; IBM Research; IBM Research; IBM Research; Rensselaer Polytechnic Institute",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16879/16879-13-20373-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07151-type-augmented-relation-prediction-in-knowledge-graphs/",
        "doi": "10.1609/aaai.v35i8.16879",
        "pdf_size": 207767
    },
    {
        "id": "04320",
        "title": "U-BERT: Pre-training User Representations for Improved Recommendation",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning user representation is a critical task for recommendation systems as it can encode user preference for personalized services. User representation is generally learned from behavior data, such as clicking interactions and review comments. However, for less popular domains, the behavior data is insufficient to learn precise user representations. To deal with this problem, a natural thought is to leverage content-rich domains to complement user representations. Inspired by the recent success of BERT in NLP, we propose a novel pre-training and fine-tuning based approach U-BERT. Different from typical BERT applications, U-BERT is customized for recommendation and utilizes different frameworks in pre-training and fine-tuning. In pre-training, U-BERT focuses on content-rich domains and introduces a user encoder and a review encoder to model users' behaviors. Two pre-training strategies are proposed to learn the general user representations; In fine-tuning, U-BERT focuses on the target content-insufficient domains. In addition to the user and review encoders inherited from the pre-training stage, U-BERT further introduces an item encoder to model item representations. Besides, a review co-matching layer is proposed to capture more semantic interactions between the reviews of the user and item. Finally, U-BERT combines user representations, item representations and review interaction information to improve recommendation performance. Experiments on six benchmark datasets from different domains demonstrate the state-of-the-art performance of U-BERT.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Zhaopeng Qiu; Xian Wu; Jingyue Gao; Wei Fan",
        "authorids": "",
        "aff": "Tencent Medical AI Lab; Tencent Medical AI Lab; Peking University; Tencent Medical AI Lab",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16557/16557-13-20051-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04320-u-bert-pre-training-user-representations-for-improved-recommendation/",
        "doi": "10.1609/aaai.v35i5.16557",
        "pdf_size": 1204223
    },
    {
        "id": "07404",
        "title": "UAG: Uncertainty-aware Attention Graph Neural Network for Defending Adversarial Attacks",
        "track": "main",
        "status": "Poster",
        "abstract": "With the increasing popularity of graph-based learning, graph neural networks (GNNs) emerge as the essential tool for gaining insights from graphs. However, unlike the conventional CNNs that have been extensively explored and exhaustively tested, people are still worrying about the GNNs' robustness under the critical settings, such as financial services. The main reason is that existing GNNs usually serve as a black-box in predicting and do not provide the uncertainty on the predictions. On the other side, the recent advancement of Bayesian deep learning on CNNs has demonstrated its success of quantifying and explaining such uncertainties to fortify CNN models. Motivated by these observations, we propose UAG, the first systematic solution to defend adversarial attacks on GNNs through identifying and exploiting hierarchical uncertainties in GNNs. UAG develops a Bayesian uncertainty technique to explicitly capture uncertainties in GNNs and further employs an uncertainty-aware attention technique to defend adversarial attacks on GNNs. Intensive experiments show that our proposed defense approach outperforms the state-of-the-art solutions by a significant margin.",
        "primary_area": "Machine Learning I",
        "author": "Boyuan Feng; Yuke Wang; Yufei Ding",
        "authorids": "",
        "aff": "University of California, Santa Barbara; University of California, Santa Barbara; University of California, Santa Barbara",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16908/16908-13-20402-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07404-uag-uncertainty-aware-attention-graph-neural-network-for-defending-adversarial-attacks/",
        "doi": "10.1609/aaai.v35i8.16908",
        "pdf_size": 726855
    },
    {
        "id": "14230",
        "title": "UBAR: Towards Fully End-to-End Task-Oriented Dialog System with GPT-2",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents our task-oriented dialog system UBAR which models task-oriented dialogs on a dialog session level. Specifically, UBAR is acquired by fine-tuning the large pre-trained unidirectional language model GPT-2 on the sequence of the entire dialog session which is composed of user utterance, belief state, database result, system act, and system response of every dialog turn. Additionally, UBAR is evaluated in a more realistic setting, where its dialog context has access to user utterances and all content it generated such as belief states, system acts, and system responses. Experimental results on the MultiWOZ datasets show that UBAR achieves state-of-the-art performances in multiple settings, improving the combined score of response generation, policy optimization, and end-to-end modeling by 4.7, 3.5, and 9.4 points respectively. Thorough analyses demonstrate that the session-level training sequence formulation and the generated dialog context are essential for UBAR to operate as a fully end-to-end task-oriented dialog system in real life.  We also examine the transfer ability of UBAR to new domains with limited data and provide visualization and a case study to illustrate the advantages of UBAR in modeling on a dialog session level.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Yunyi Yang; Yunhao Li; Xiaojun Quan",
        "authorids": "",
        "aff": "Sun Yat-sen University; Sun Yat-sen University; Sun Yat-sen University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17674/17674-13-21168-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14230-ubar-towards-fully-end-to-end-task-oriented-dialog-system-with-gpt-2/",
        "doi": "10.1609/aaai.v35i16.17674",
        "pdf_size": 584320
    },
    {
        "id": "13480",
        "title": "UNICORN on RAINBOW: A Universal Commonsense Reasoning Model on a New Multitask Benchmark",
        "track": "main",
        "status": "Poster",
        "abstract": "Commonsense AI has long been seen as a near impossible goal---until recently. Now, research interest has sharply increased with an influx of new benchmarks and models.  We propose two new ways to evaluate commonsense models, emphasizing their generality on new tasks and building on diverse, recently introduced benchmarks. First, we propose a new multitask benchmark, Rainbow, to promote research on commonsense models that generalize well over multiple tasks and datasets. Second, we propose a novel evaluation, the cost equivalent curve, that sheds new insight on how the choice of source datasets, pretrained language models, and transfer learning methods impacts performance and data efficiency.  We perform extensive experiments---over 200 experiments encompassing 4800 models---and report multiple valuable and sometimes surprising findings, e.g., that transfer almost always leads to better or equivalent performance if following a particular recipe, that QA-based commonsense datasets transfer well with each other, while commonsense knowledge graphs do not, and that perhaps counter-intuitively, larger models benefit more from transfer than smaller ones.  Last but not least, we introduce a new universal commonsense reasoning model, UNICORN, that establishes new state-of-the-art performance across 8 popular commonsense benchmarks, aNLI (87.3%), CosmosQA (91.8%), HellaSWAG (93.9%), PIQA (90.1%), SocialIQa (83.2%), WinoGrande (86.6%), CycIC (94.0%) and CommonsenseQA (79.3%).",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Nicholas Lourie; Ronan Le Bras; Chandra Bhagavatula; Yejin Choi",
        "authorids": "",
        "aff": "Allen Institute for AI; Allen Institute for AI; Allen Institute for AI; Paul G. Allen School of Computer Science & Engineering, University of Washington Allen Institute for AI",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17590/17590-13-21084-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13480-unicorn-on-rainbow-a-universal-commonsense-reasoning-model-on-a-new-multitask-benchmark/",
        "doi": "10.1609/aaai.v35i15.17590",
        "pdf_size": 719477
    },
    {
        "id": "09685",
        "title": "UNIPoint: Universally Approximating Point Processes Intensities",
        "track": "main",
        "status": "Poster",
        "abstract": "Point processes are a useful mathematical tool for describing events over time, and so there are many recent approaches for representing and learning them. One notable open question is how to precisely describe the flexibility of point process models and whether there exists a general model that can represent all point processes. Our work bridges this gap. Focusing on the widely used event intensity function representation of point processes, we provide a proof that a class of learnable functions can universally approximate any valid intensity function. The proof connects the well known Stone-Weierstrass Theorem for function approximation, the uniform density of non-negative continuous functions using a transfer functions, the formulation of the parameters of a piece-wise continuous functions as a dynamic system, and a recurrent neural network implementation for capturing the dynamics. Using these insights, we design and implement UNIPoint, a novel neural point process model, using recurrent neural networks to parameterise sums of basis function upon each event. Evaluations on synthetic and real world datasets show that this simpler representation performs better than Hawkes process variants and more complex neural network-based approaches. We expect this result will provide a practical basis for selecting and tuning models, as well as furthering theoretical work on representational complexity and learnability.",
        "primary_area": "Machine Learning IV",
        "author": "Alexander Soen; Alexander Mathews; Daniel Grixti-Cheng; Lexing Xie",
        "authorids": "",
        "aff": "The Australian National University; The Australian National University; The Australian National University; The Australian National University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17165/17165-13-20659-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09685-unipoint-universally-approximating-point-processes-intensities/",
        "doi": "10.1609/aaai.v35i11.17165",
        "pdf_size": 494298
    },
    {
        "id": "14319",
        "title": "UWSpeech: Speech to Speech Translation for Unwritten Languages",
        "track": "main",
        "status": "Poster",
        "abstract": "Existing speech to speech translation systems heavily rely on the text of target language: they usually translate source language either to target text and then synthesize target speech from text, or directly to target speech with target text for auxiliary training. However, those methods cannot be applied to unwritten target languages, which have no written text or phoneme available. In this paper, we develop a translation system for unwritten languages, named as UWSpeech, which converts target unwritten speech into discrete tokens with a converter, and then translates source-language speech into target discrete tokens with a translator, and finally synthesizes target speech from target discrete tokens with an inverter. We propose a method called XL-VAE, which enhances vector quantized variational autoencoder (VQ-VAE) with cross-lingual (XL) speech recognition, to train the converter and inverter of UWSpeech jointly. Experiments on Fisher Spanish-English conversation translation dataset show that UWSpeech outperforms direct translation and VQ-VAE baseline by about 16 and 10 BLEU points respectively, which demonstrate the advantages and potentials of UWSpeech.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Chen Zhang; Xu Tan; Yi Ren; Tao Qin; Kejun Zhang; Tie-Yan Liu",
        "authorids": "",
        "aff": "Zhejiang University; Microsoft Research Asia; Zhejiang University; Microsoft Research Asia; Zhejiang University; Microsoft Research Asia",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17684/17684-13-21178-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14319-uwspeech-speech-to-speech-translation-for-unwritten-languages/",
        "doi": "10.1609/aaai.v35i16.17684",
        "pdf_size": 187717
    },
    {
        "id": "14266",
        "title": "Unanswerable Question Correction in Question Answering over Personal Knowledge Base",
        "track": "main",
        "status": "Poster",
        "abstract": "People often encounter situations where they need to recall past experiences from their daily life. In this paper, we aim to construct a question answering system that enables human to query their past experiences over personal knowledge base. Previous works on knowledge base question answering focus on finding answers for answerable questions. In the real world applications, however, people often muddle up facts and ask those questions that cannot be answered with knowledge base. This work presents a novel system consisting of question answering model and question generation model. It not only answers answerable questions, but also corrects unanswerable questions if necessary. Our question answering model recognizes the question that is inconsistent with the state of the personal knowledge base and suggests facts that can form a feasible question. Then, the facts are converted to an answerable question by the question generation model. For refining question, we propose a question generation model based on the reinforcement learning (RL) with question editing mechanism. Experimental results show that our proposed system is effective for correcting unanswerable questions in personal knowledge base question answering.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "An-Zi Yen; Hen-Hsen Huang; Hsin-Hsi Chen",
        "authorids": "",
        "aff": "National Taiwan University; National Chengchi University MOST Joint Research Center for AI Technology and All Vista Healthcare; National Taiwan University MOST Joint Research Center for AI Technology and All Vista Healthcare",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17678/17678-13-21172-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14266-unanswerable-question-correction-in-question-answering-over-personal-knowledge-base/",
        "doi": "10.1609/aaai.v35i16.17678",
        "pdf_size": 588946
    },
    {
        "id": "05993",
        "title": "Uncertain Graph Neural Networks for Facial  Action Unit Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Capturing the dependencies among different facial action units (AU) is extremely important for the AU detection task. Many studies have employed graph-based deep learning methods to exploit the dependencies among AUs. However, the dependencies among AUs in real world data are often noisy and the uncertainty is essential to be taken into consideration. Rather than employing a deterministic mode, we propose an uncertain graph neural network (UGN) to learn the probabilistic mask that simultaneously captures both the individual  dependencies among AUs and the uncertainties. Further, we propose an adaptive weighted loss function based on the epistemic uncertainties to adaptively vary the weights of the training samples during the training process to account for unbalanced data distributions among AUs. We also provide an insightful analysis on how the uncertainties are related to the performance of AU detection. Extensive experiments, conducted on two benchmark datasets, i.e., BP4D and DISFA, demonstrate our method achieves the state-of-the-art performance.",
        "primary_area": "Humans and AI",
        "author": "Tengfei Song; Lisha Chen; Wenming Zheng; Qiang Ji",
        "authorids": "",
        "aff": "Southeast University; Rensselaer Polytechnic Institute; Southeast University; Rensselaer Polytechnic Institute",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16748/16748-13-20242-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05993-uncertain-graph-neural-networks-for-facial-action-unit-detection/",
        "doi": "10.1609/aaai.v35i7.16748",
        "pdf_size": 955474
    },
    {
        "id": "12078",
        "title": "Uncertainty Quantification in CNN Through the Bootstrap of Convex Neural Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Despite the popularity of Convolutional Neural Networks (CNN), the problem of uncertainty quantification (UQ) of CNN has been largely overlooked. Lack of efficient UQ tools severely limits the application of CNN in certain areas, such as medicine, where prediction uncertainty is critically important. Among the few existing UQ approaches that have been proposed for deep learning, none of them has theoretical consistency that can guarantee the uncertainty quality. To address this issue, we propose a novel bootstrap based framework for the estimation of prediction uncertainty. The inference procedure we use relies on convexified neural networks to establish the theoretical consistency of bootstrap. Our approach has a significantly less computational load than its competitors, as it relies on warm-starts at each bootstrap that avoids refitting the model from scratch. We further explore a novel transfer learning method so our framework can work on arbitrary neural networks. We experimentally demonstrate our approach has a much better performance compared to other baseline CNNs and state-of-the-art methods on various image datasets.",
        "primary_area": "Reasoning under Uncertainty",
        "author": "Hongfei Du; Emre Barut; Fang Jin",
        "authorids": "",
        "aff": "George Washington University; Amazon; George Washington University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17434/17434-13-20928-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12078-uncertainty-quantification-in-cnn-through-the-bootstrap-of-convex-neural-networks/",
        "doi": "10.1609/aaai.v35i13.17434",
        "pdf_size": 244934
    },
    {
        "id": "07545",
        "title": "Uncertainty-Aware Multi-View Representation Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning from different data views by exploring the underlying complementary information among them can endow the representation with stronger expressive ability. However, high-dimensional features tend to contain noise, and furthermore, quality of data usually varies for different samples (even for different views), i.e., one view may be informative for one sample but not the case for another. Therefore, it is quite challenging to integrate multi-view noisy data under unsupervised setting. Traditional multi-view methods either simply treat each view with equal importance or tune the weights of different views to fixed values, which are insufficient to capture the dynamic noise in multi-view data. In this work, we devise a novel unsupervised multi-view learning approach, termed as Dynamic Uncertainty-Aware Networks (DUA-Nets). Guided by the uncertainty of data estimated from the generation perspective, intrinsic information from multiple views is integrated to obtain noise-free representations. Under the help of uncertainty estimation, DUA-Nets weigh each view of individual sample according to data quality so that the high-quality samples (or views) can be fully exploited while the effects from the noisy samples (or views) will be alleviated. Our model achieves superior performance in extensive experiments and shows the robustness to noisy data.",
        "primary_area": "Machine Learning II",
        "author": "Yu Geng; Zongbo Han; Changqing Zhang; Qinghua Hu",
        "authorids": "",
        "aff": "Tianjin University; Tianjin University; Tianjin university Tianjin Key Lab of Machine Learning, Tianjin, China; Tianjin University Tianjin Key Lab of Machine Learning, Tianjin, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16924/16924-13-20418-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07545-uncertainty-aware-multi-view-representation-learning/",
        "doi": "10.1609/aaai.v35i9.16924",
        "pdf_size": 2151885
    },
    {
        "id": "09377",
        "title": "Uncertainty-Aware Policy Optimization: A Robust, Adaptive Trust Region Approach",
        "track": "main",
        "status": "Poster",
        "abstract": "In order for reinforcement learning techniques to be useful in real-world decision making processes, they must be able to produce robust performance from limited data. Deep policy optimization methods have achieved impressive results on complex tasks, but their real-world adoption remains limited because they often require significant amounts of data to succeed. When combined with small sample sizes, these methods can result in unstable learning due to their reliance on high-dimensional sample-based estimates. In this work, we develop techniques to control the uncertainty introduced by these estimates. We leverage these techniques to propose a deep policy optimization approach designed to produce stable performance even when data is scarce. The resulting algorithm, Uncertainty-Aware Trust Region Policy Optimization, generates robust policy updates that adapt to the level of uncertainty present throughout the learning process.",
        "primary_area": "Machine Learning IV",
        "author": "James Queeney; Ioannis Ch. Paschalidis; Christos G. Cassandras",
        "authorids": "",
        "aff": "Boston University; Boston University; Boston University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17130/17130-13-20624-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09377-uncertainty-aware-policy-optimization-a-robust-adaptive-trust-region-approach/",
        "doi": "10.1609/aaai.v35i11.17130",
        "pdf_size": 873807
    },
    {
        "id": "09524",
        "title": "Uncertainty-Matching Graph Neural Networks to Defend Against Poisoning Attacks",
        "track": "main",
        "status": "Poster",
        "abstract": "Graph Neural Networks (GNNs), a generalization of neural networks to graph-structured data, are often implemented using message passes between entities of a graph. While GNNs are effective for node classification, link prediction and graph classification, they are vulnerable to adversarial attacks, i.e., a small perturbation to the structure can lead to a non-trivial performance degradation. In this work, we propose Uncertainty Matching GNN (UM-GNN), that is aimed at improving the robustness of GNN models, particularly against poisoning attacks to the graph structure, by leveraging epistemic uncertainties from the message passing framework. More specifically, we propose to build a surrogate predictor that does not directly access the graph structure, but systematically extracts reliable knowledge from a standard GNN through a novel uncertainty-matching strategy. Interestingly, this uncoupling makes UM-GNN immune to evasion attacks by design, and achieves significantly improved robustness against poisoning attacks. Using empirical studies with standard benchmarks and a suite of global and target attacks, we demonstrate the effectiveness of UM-GNN, when compared to existing baselines including the state-of-the-art robust GCN.",
        "primary_area": "Machine Learning IV",
        "author": "Uday Shankar Shanthamallu; Jayaraman J. Thiagarajan; Andreas Spanias",
        "authorids": "",
        "aff": "Arizona State University; Lawrence Livermore National Labs; Arizona State University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17147/17147-13-20641-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09524-uncertainty-matching-graph-neural-networks-to-defend-against-poisoning-attacks/",
        "doi": "10.1609/aaai.v35i11.17147",
        "pdf_size": 1555168
    },
    {
        "id": "08644",
        "title": "Unchain the Search Space with Hierarchical Differentiable Architecture Search",
        "track": "main",
        "status": "Poster",
        "abstract": "Differentiable architecture search (DAS) has made great progress in searching for  high-performance architectures with reduced computational cost. However, DAS-based methods mainly focus on searching for a repeatable cell structure, which is then stacked sequentially in multiple stages to form the networks. This configuration significantly reduces the search space, and ignores the importance of connections between the cells. To overcome this limitation, in this paper, we propose a Hierarchical Differentiable Architecture Search (H-DAS) that performs architecture search both at the cell level and at the stage level. Specifically, the cell-level search space is relaxed so that the networks can learn stage-specific cell structures. For the stage-level search, we systematically study the architectures of stages, including the number of cells in each stage and the connections between the cells. Based on insightful observations, we design several search rules and losses, and mange to search for  better stage-level architectures. Such hierarchical search space greatly improves the performance of the networks without introducing expensive search cost. Extensive experiments on CIFAR10 and ImageNet demonstrate the effectiveness of the proposed H-DAS. Moreover, the searched stage-level architectures can be combined with the cell structures searched by existing DAS methods to further boost the performance. Code is available at: https://github.com/msight-tech/research-HDAS",
        "primary_area": "Machine Learning III",
        "author": "Guanting Liu; Yujie Zhong; Sheng Guo; Matthew R. Scott; Weilin Huang",
        "authorids": "",
        "aff": "Malong LLC; Malong LLC; Malong LLC; Malong LLC; Malong LLC",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17048/17048-13-20542-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08644-unchain-the-search-space-with-hierarchical-differentiable-architecture-search/",
        "doi": "10.1609/aaai.v35i10.17048",
        "pdf_size": 756829
    },
    {
        "id": "04767",
        "title": "Uncovering Latent Biases in Text: Method and Application to Peer Review",
        "track": "main",
        "status": "Poster",
        "abstract": "Quantifying systematic disparities in numerical quantities such as employment rates and wages between population subgroups provides compelling evidence for the existence of societal biases. However, biases in the text written for members of different subgroups (such as in recommendation letters for male and non-male candidates), though widely reported anecdotally, remain challenging to quantify. In this work, we introduce a novel framework to quantify bias in text caused by the visibility of subgroup membership indicators. We develop a nonparametric estimation and inference procedure to estimate this bias. We then formalize an identification strategy to causally link the estimated bias to the visibility of subgroup membership indicators, provided observations from time periods both before and after an identity-hiding policy change. We identify an application wherein \u201cground truth\u201d bias can be inferred to evaluate our framework, instead of relying on synthetic or secondary data. Specifically, we apply our framework to quantify biases in the text of peer reviews from a reputed machine-learning conference before and after the conference adopted a double-blind reviewing policy. We show evidence of biases in the review ratings that serves as \u201cground truth\u201d, and show that our proposed framework accurately detects the presence (and absence) of these biases from the review text without having access to the review ratings.",
        "primary_area": "AI for Conference Organization and Delivery",
        "author": "Emaad Manzoor; Nihar B. Shah",
        "authorids": "",
        "aff": "Carnegie Mellon University; Carnegie Mellon University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16608/16608-13-20102-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04767-uncovering-latent-biases-in-text-method-and-application-to-peer-review/",
        "doi": "10.1609/aaai.v35i6.16608",
        "pdf_size": 1890126
    },
    {
        "id": "08119",
        "title": "Understanding Catastrophic Overfitting in Single-step Adversarial Training",
        "track": "main",
        "status": "Poster",
        "abstract": "Although fast adversarial training has demonstrated both robustness and efficiency, the problem of \"catastrophic overfitting\" has been observed. This is a phenomenon in which, during single-step adversarial training, the robust accuracy against projected gradient descent (PGD) suddenly decreases to 0% after a few epochs, whereas the robust accuracy against fast gradient sign method (FGSM) increases to 100%. In this paper, we demonstrate that catastrophic overfitting is very closely related to the characteristic of single-step adversarial training which uses only adversarial examples with the maximum perturbation, and not all adversarial examples in the adversarial direction, which leads to decision boundary distortion and a highly curved loss surface. Based on this observation, we propose a simple method that not only prevents catastrophic overfitting, but also overrides the belief that it is difficult to prevent multi-step adversarial attacks with single-step adversarial training.",
        "primary_area": "Machine Learning II",
        "author": "Hoki Kim; Woojin Lee; Jaewook Lee",
        "authorids": "",
        "aff": "Seoul National University; Seoul National University; Seoul National University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16989/16989-13-20483-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08119-understanding-catastrophic-overfitting-in-single-step-adversarial-training/",
        "doi": "10.1609/aaai.v35i9.16989",
        "pdf_size": 1073527
    },
    {
        "id": "06777",
        "title": "Understanding Decoupled and Early Weight Decay",
        "track": "main",
        "status": "Poster",
        "abstract": "Weight decay (WD) is a traditional regularization technique in deep learning, but despite its ubiquity, its behavior is still an area of active research. Golatkar et al. have recently shown that WD only matters at the start of the training in computer vision, upending traditional wisdom. Loshchilov et al. show that for adaptive optimizers, manually decaying weights can outperform adding an l2 penalty to the loss. This technique has become increasingly popular and is referred to as decoupled WD. The goal of this paper is to investigate these two recent empirical observations. We demonstrate that by applying WD only at the start, the network norm stays small throughout training. This has a regularizing effect as the effective gradient updates become larger. However, traditional generalizations metrics fail to capture this effect of WD, and we show how a simple scale-invariant metric can. We also show how the growth of network weights is heavily influenced by the dataset and its generalization properties. For decoupled WD, we perform experiments in NLP and RL where adaptive optimizers are the norm. We demonstrate that the primary issue that decoupled WD alleviates is the mixing of gradients from the objective function and the l2 penalty in the buffers of Adam (which stores the estimates of the first-order moment). Adaptivity itself is not problematic and decoupled WD ensures that the gradients from the l2 term cannot \"drown out\" the true objective, facilitating easier hyperparameter tuning.",
        "primary_area": "Machine Learning I",
        "author": "Johan Bjorck; Kilian Q. Weinberger; Carla Gomes",
        "authorids": "",
        "aff": "Cornell University; Cornell University; Cornell University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16837/16837-13-20331-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06777-understanding-decoupled-and-early-weight-decay/",
        "doi": "10.1609/aaai.v35i8.16837",
        "pdf_size": 3284092
    },
    {
        "id": "00973",
        "title": "Understanding Deformable Alignment in Video Super-Resolution",
        "track": "main",
        "status": "Poster",
        "abstract": "Deformable convolution, originally proposed for the adaptation to geometric variations of objects, has recently shown compelling performance in aligning multiple frames and is increasingly adopted for video super-resolution. Despite its remarkable performance, its underlying mechanism for alignment remains unclear. In this study, we carefully investigate the relation between deformable alignment and the classic flow-based alignment. We show that deformable convolution can be decomposed into a combination of spatial warping and convolution. This decomposition reveals the commonality of deformable alignment and flow-based alignment in formulation, but with a key difference in their offset diversity. We further demonstrate through experiments that the increased diversity in deformable alignment yields better-aligned features, and hence significantly improves the quality of video super-resolution output. Based on our observations, we propose an offset-fidelity loss that guides the offset learning with optical flow. Experiments show that our loss successfully avoids the overflow of offsets and alleviates the instability problem of deformable alignment. Aside from the contributions to deformable alignment, our formulation inspires a more flexible approach to introduce offset diversity to flow-based alignment, improving its performance.",
        "primary_area": "Computer Vision I",
        "author": "Kelvin C.K. Chan; Xintao Wang; Ke Yu; Chao Dong; Chen Change Loy",
        "authorids": "",
        "aff": "S-Lab, Nanyang Technological University; Applied Research Center, Tencent PCG; CUHK \u2013 SenseTime Joint Lab, The Chinese University of Hong Kong; Shenzhen Key Lab of Computer Vision and Pattern Recognition, SIAT-SenseTime Joint Lab, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences SIAT Branch, Shenzhen Institute of Artificial Intelligence and Robotics for Society; S-Lab, Nanyang Technological University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16181/16181-13-19675-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00973-understanding-deformable-alignment-in-video-super-resolution/",
        "doi": "10.1609/aaai.v35i2.16181",
        "pdf_size": 11440830
    },
    {
        "id": "10273",
        "title": "Unified Tensor Framework for Incomplete Multi-view Clustering and Missing-view Inferring",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a novel method, referred to as incomplete multi-view tensor spectral clustering with missing-view inferring (IMVTSC-MVI) to address the challenging multi-view clustering problem with missing views. Different from the existing methods which commonly focus on exploring the certain information of the available views while ignoring both of the hidden information of the missing views and the intra-view information of data, IMVTSC-MVI seeks to recover the missing views and explore the full information of such recovered views and available views for data clustering. In particular, IMVTSC-MVI incorporates the feature space based missing-view inferring and manifold space based similarity graph learning into a unified framework. In such a way, IMVTSC-MVI allows these two learning tasks to facilitate each other and can well explore the hidden information of the missing views. Moreover, IMVTSC-MVI introduces the low-rank tensor constraint to capture the high-order correlations of multiple views. Experimental results on several datasets demonstrate the effectiveness of IMVTSC-MVI for incomplete multi-view clustering.",
        "primary_area": "Machine Learning IV",
        "author": "Jie Wen; Zheng Zhang; Zhao Zhang; Lei Zhu; Lunke Fei; Bob Zhang; Yong Xu",
        "authorids": "",
        "aff": "Shenzhen Key Laboratory of Visual Object Detection and Recognition, Harbin Institute of Technology, Shenzhen, Shenzhen 518055, China; Shenzhen Key Laboratory of Visual Object Detection and Recognition, Harbin Institute of Technology, Shenzhen, Shenzhen 518055, China Peng Cheng Laboratory, Shenzhen 518055, China; School of Computer Science and Information Engineering, Hefei University of Technology, Hefei 230006, China; School of Information Science and Engineering, Shandong Normal University, Jinan 250358, China; School of Computer Science and Technology, Guangdong University of Technology, Guangzhou 510006, China; PAMI Research Group, Dept. of Computer and Information Science, University of Macau, Taipa, Macau; Shenzhen Key Laboratory of Visual Object Detection and Recognition, Harbin Institute of Technology, Shenzhen, Shenzhen 518055, China Peng Cheng Laboratory, Shenzhen 518055, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17231/17231-13-20725-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10273-unified-tensor-framework-for-incomplete-multi-view-clustering-and-missing-view-inferring/",
        "doi": "10.1609/aaai.v35i11.17231",
        "pdf_size": 2472943
    },
    {
        "id": "05339",
        "title": "United for Change: Deliberative Coalition Formation to Change the Status Quo",
        "track": "main",
        "status": "Poster",
        "abstract": "We study a setting in which a community wishes to identify a strongly supported proposal from a large space of alternatives, in order to change the status quo. We describe a deliberation process in which agents dynamically form coalitions  around proposals that they prefer over the status quo.  We formulate conditions on the space of proposals and on the ways in which coalitions are formed that guarantee deliberation to succeed, that is, to terminate by identifying a proposal with the largest possible support. Our results provide theoretical foundations for the analysis of deliberative processes in systems for democratic deliberation support, such as, e.g., LiquidFeedback or Polis.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Edith Elkind; Davide Grossi; Ehud Shapiro; Nimrod Talmon",
        "authorids": "",
        "aff": "University of Oxford; University of Groningen University of Amsterdam; Weizmann Institute of Science; Ben-Gurion University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16673/16673-13-20167-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05339-united-for-change-deliberative-coalition-formation-to-change-the-status-quo/",
        "doi": "10.1609/aaai.v35i6.16673",
        "pdf_size": 144609
    },
    {
        "id": "03296",
        "title": "Universal Adversarial Perturbations Through the Lens of Deep Steganography: Towards a Fourier Perspective",
        "track": "main",
        "status": "Poster",
        "abstract": "The booming interest in adversarial attacks stems from a misalignment between human vision and a deep neural network (DNN), ie~a human imperceptible perturbation fools the DNN. Moreover, a single perturbation, often called universal adversarial perturbation (UAP), can be generated to fool the DNN for most images. A similar misalignment phenomenon has also been observed in the deep steganography task, where a decoder network can retrieve a secret image back from a slightly perturbed cover image. We attempt explaining the success of both in a unified manner from the Fourier perspective. We perform task-specific and joint analysis and reveal that (a) frequency is a key factor that influences their performance based on the proposed entropy metric for quantifying the frequency distribution; (b) their success can be attributed to a DNN being highly sensitive to high-frequency content. We also perform feature layer analysis for providing deep insight on model generalization and robustness. Additionally, we propose two new variants of universal perturbations: (1) high-pass UAP (HP-UAP) being less visible to the human eye;  (2) Universal Secret Adversarial Perturbation (USAP) that simultaneously achieves attack and hiding.",
        "primary_area": "Computer Vision III",
        "author": "Chaoning Zhang; Philipp Benz; Adil Karjauv; In So Kweon",
        "authorids": "",
        "aff": "Korea Advanced Institute of Science and Technology (KAIST); Korea Advanced Institute of Science and Technology (KAIST); Korea Advanced Institute of Science and Technology (KAIST); Korea Advanced Institute of Science and Technology (KAIST)",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16441/16441-13-19935-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03296-universal-adversarial-perturbations-through-the-lens-of-deep-steganography-towards-a-fourier-perspective/",
        "doi": "10.1609/aaai.v35i4.16441",
        "pdf_size": 10992246
    },
    {
        "id": "00107",
        "title": "Universal Trading for Order Execution with Oracle Policy Distillation",
        "track": "main",
        "status": "Poster",
        "abstract": "",
        "primary_area": "Application Domains",
        "author": "Yuchen Fang; Kan Ren; Weiqing Liu; Dong Zhou; Weinan Zhang; Jiang Bian; Yong Yu; Tie-Yan Liu",
        "authorids": "",
        "aff": "",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16083/16083-13-19577-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00107-universal-trading-for-order-execution-with-oracle-policy-distillation/",
        "doi": "",
        "pdf_size": 400801
    },
    {
        "id": "02773",
        "title": "Unsupervised 3D Learning for Shape Analysis via Multiresolution Instance Discrimination",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose an unsupervised method for learning a generic and efficient shape encoding network for different shape analysis tasks. Our key idea is to jointly encode and learn shape and point features from unlabeled 3D point clouds. For this purpose, we adapt HRNet to octree-based convolutional neural networks for jointly encoding shape and point features with fused multiresolution subnetworks and design a simple-yet-efficient Multiresolution Instance Discrimination (MID) loss for jointly learning the shape and point features. Our network takes a 3D point cloud as input and output both shape and point features. After training, Our network is concatenated with simple task-specific back-ends and fine-tuned for different shape analysis tasks. We evaluate the efficacy and generality of our method with a set of shape analysis tasks, including shape classification, semantic shape segmentation, as well as shape registration tasks. With simple back-ends, our network demonstrates the best performance among all unsupervised methods and achieves competitive performance to supervised methods. For fine-grained shape segmentation on the PartNet dataset, our method even surpasses existing supervised methods by a large margin.",
        "primary_area": "Computer Vision III",
        "author": "Peng-Shuai Wang; Yu-Qi Yang; Qian-Fang Zou; Zhirong Wu; Yang Liu; Xin Tong",
        "authorids": "",
        "aff": "Microsoft Research Asia; Tsinghua University Microsoft Research Asia; University of Science and Technology of China Microsoft Research Asia; Microsoft Research Asia; Microsoft Research Asia; Microsoft Research Asia",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16382/16382-13-19876-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02773-unsupervised-3d-learning-for-shape-analysis-via-multiresolution-instance-discrimination/",
        "doi": "10.1609/aaai.v35i4.16382",
        "pdf_size": 295614
    },
    {
        "id": "14489",
        "title": "Unsupervised Abstractive Dialogue Summarization for Tete-a-Tetes",
        "track": "main",
        "status": "Poster",
        "abstract": "High-quality dialogue-summary paired data is expensive to produce and domain-sensitive, making abstractive dialogue summarization a challenging task. In this work, we propose the first unsupervised abstractive dialogue summarization model for tete-a-tetes (SuTaT). Unlike standard text summarization, a dialogue summarization method should consider the multi-speaker scenario where the speakers have different roles, goals, and language styles. In a tete-a-tete, such as a customer-agent conversation, SuTaT aims to summarize for each speaker by modeling the customer utterances and the agent utterances separately while retaining their correlations. SuTaT consists of a conditional generative module and two unsupervised summarization modules. The conditional generative module contains two encoders and two decoders in a variational autoencoder framework where the dependencies between two latent spaces are captured. With the same encoders and decoders, two unsupervised summarization modules equipped with sentence-level self-attention mechanisms generate summaries without using any annotations. Experimental results show that SuTaT is superior on unsupervised dialogue summarization for both automatic and human evaluations, and is capable of dialogue classification and single-turn conversation generation.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Xinyuan Zhang; Ruiyi Zhang; Manzil Zaheer; Amr Ahmed",
        "authorids": "",
        "aff": "ASAPP; Duke University; Google Research; Google Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17703/17703-13-21197-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14489-unsupervised-abstractive-dialogue-summarization-for-tete-a-tetes/",
        "doi": "10.1609/aaai.v35i16.17703",
        "pdf_size": 204484
    },
    {
        "id": "08332",
        "title": "Unsupervised Active Learning via Subspace Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Unsupervised active learning has been an active research topic in machine learning community, with the purpose of choosing representative samples to be labelled in an unsupervised manner. Previous works usually take the minimization of data reconstruction loss as the criterion to select representative samples which can better approximate original inputs. However, data are often drawn from  low-dimensional subspaces embedded in an arbitrary high-dimensional space in many scenarios, thus it might severely bring in noise if attempting to precisely reconstruct all entries of one observation, leading to a suboptimal solution. In view of this, this paper proposes a novel unsupervised Active Learning model via Subspace Learning, called ALSL. In contrast to previous approaches, ALSL aims to discovery the low-rank structures of  data, and then perform sample selection based on learnt low-rank representations. To this end, we devise two different strategies and propose two corresponding formulations to perform unsupervised active learning with and under low-rank sample representations respectively. Since the proposed formulations involve several non-smooth regularization terms, we develop a simple but effective optimization procedure to solve them. Extensive experiments are performed on five publicly available datasets, and experimental results  demonstrate the proposed first formulation achieves comparable performance with the state-of-the-arts, while the second formulation significantly outperforms them, achieving a 13% improvement over the second best baseline at most.",
        "primary_area": "Machine Learning II",
        "author": "Changsheng Li; Kaihang Mao; Lingyan Liang; Dongchun Ren; Wei Zhang; Ye Yuan; Guoren Wang",
        "authorids": "",
        "aff": "Beijing Institute of Technology; Beijing Institute of Technology; Inspur; Meituan; University of Electronic Science and Technology of China; Beijing Institute of Technology; Beijing Institute of Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17013/17013-13-20507-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08332-unsupervised-active-learning-via-subspace-learning/",
        "doi": "10.1609/aaai.v35i9.17013",
        "pdf_size": 866832
    },
    {
        "id": "03360",
        "title": "Unsupervised Domain Adaptation for Person Re-identification via Heterogeneous Graph Alignment",
        "track": "main",
        "status": "Poster",
        "abstract": "Unsupervised person re-identification (re-ID) is becoming increasingly popular due to its power in real-world systems such as public security and intelligent transportation systems. However, the person re-ID task is challenged by the problems of data distribution discrepancy across cameras and lack of label information. In this paper, we propose a coarse-to-fine heterogeneous graph alignment (HGA) method to find cross-camera person matches by characterizing the unlabeled data as a heterogeneous graph for each camera. In the coarse-alignment stage, we assign a projection for each camera and utilize an adversarial learning based method to align coarse-grained node groups from different cameras into a shared space, which consequently alleviates the distribution discrepancy between cameras. In the fine-alignment stage, we exploit potential fine-grained node groups in the shared space and introduce conservative alignment loss functions to constrain the graph aligning process, resulting in reliable pseudo labels as learning guidance. The proposed domain adaptation framework not only improves model generalization on target domain, but also facilitates mining and integrating the potential discriminative information across different cameras. Extensive experiments on benchmark datasets demonstrate that the proposed approach outperforms the state-of-the-arts.",
        "primary_area": "Computer Vision III",
        "author": "Minying Zhang; Kai Liu; Yidong Li; Shihui Guo; Hongtao Duan; Yimin Long; Yi Jin",
        "authorids": "",
        "aff": "Alibaba Group; Alibaba Group Beijing Jiaotong University; Beijing Jiaotong Univeristy; Xiamen University; Alibaba Group; Alibaba Group; Beijing JiaoTong University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16448/16448-13-19942-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03360-unsupervised-domain-adaptation-for-person-re-identification-via-heterogeneous-graph-alignment/",
        "doi": "10.1609/aaai.v35i4.16448",
        "pdf_size": 2080946
    },
    {
        "id": "08306",
        "title": "Unsupervised Domain Adaptation for Semantic Segmentation by Content Transfer",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we tackle the unsupervised domain adaptation (UDA) for semantic segmentation, which aims to segment the unlabeled real data using labeled synthetic data. The main problem of UDA for semantic segmentation relies on reducing the domain gap between the real image and synthetic image. To solve this problem, we focused on separating information in an image into content and style. Here, only the content has cues for semantic segmentation, and the style makes the domain gap. Thus, precise separation of content and style in an image leads to effect as supervision of real data even when learning with synthetic data. To make the best of this effect, we propose a zero-style loss. Even though we perfectly extract content for semantic segmentation in the real domain, another main challenge, the class imbalance problem, still exists in UDA for semantic segmentation. We address this problem by transferring the contents of tail classes from synthetic to real domain. Experimental results show that the proposed method achieves the state-of-the-art performance in semantic segmentation on the major two UDA settings.",
        "primary_area": "Machine Learning II",
        "author": "Suhyeon Lee; Junhyuk Hyun; Hongje Seong; Euntai Kim",
        "authorids": "",
        "aff": "Yonsei University; Yonsei University; Yonsei University; Yonsei University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17010/17010-13-20504-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08306-unsupervised-domain-adaptation-for-semantic-segmentation-by-content-transfer/",
        "doi": "10.1609/aaai.v35i9.17010",
        "pdf_size": 1519302
    },
    {
        "id": "13869",
        "title": "Unsupervised Learning of Deterministic Dialogue Structure with Edge-Enhanced  Graph Auto-Encoder",
        "track": "main",
        "status": "Poster",
        "abstract": "It is important for task-oriented dialogue systems to discover the dialogue structure (i.e. the general dialogue flow) from dialogue corpora automatically. Previous work models dialogue structure by extracting latent states for each utterance first and then calculating the transition probabilities among states. These two-stage methods ignore the contextual information when calculating the probabilities, which makes the transitions between the states ambiguous. This paper proposes a conversational graph (CG) to represent deterministic dialogue structure where nodes and edges represent the utterance and context information respectively. An unsupervised Edge-Enhanced Graph Auto-Encoder (EGAE) architecture is designed to model local-contextual and global-structural information for conversational graph learning. Furthermore, a self-supervised objective is introduced with the response selection task to guide the unsupervised learning of the dialogue structure. Experimental results on several public datasets demonstrate that the novel model outperforms several alternatives in aggregating utterances with similar semantics. The effectiveness of the learned dialogue structured is also verified by more than 5% joint accuracy improvement in the downstream task of low resource dialogue state tracking.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Yajing Sun; Yong Shan; Chengguang Tang; Yue Hu; Yinpei Dai; Jing Yu; Jian Sun; Fei Huang; Luo Si",
        "authorids": "",
        "aff": "Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China; Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; Alibaba Group, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China; Alibaba Group, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China; Alibaba Group, Beijing, China; Alibaba Group, Beijing, China; Alibaba Group, Beijing, China",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17634/17634-13-21128-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13869-unsupervised-learning-of-deterministic-dialogue-structure-with-edge-enhanced-graph-auto-encoder/",
        "doi": "10.1609/aaai.v35i15.17634",
        "pdf_size": 420410
    },
    {
        "id": "13107",
        "title": "Unsupervised Learning of Discourse Structures using a Tree Autoencoder",
        "track": "main",
        "status": "Poster",
        "abstract": "Discourse information, as postulated by popular discourse theories, such as RST and PDTB, has been shown to improve an increasing number of downstream NLP tasks, showing positive effects and synergies of discourse with important real-world applications. While methods for incorporating discourse become more and more sophisticated, the growing need for robust and general discourse structures has not been sufficiently met by current discourse parsers, usually trained on small scale datasets in a strictly limited number of domains. This makes the prediction for arbitrary tasks noisy and unreliable. The overall resulting lack of high-quality, high-quantity discourse trees poses a severe limitation to further progress.  In order the alleviate this shortcoming, we propose a new strategy to generate tree structures in a task-agnostic, unsupervised fashion by extending a latent tree induction framework with an auto-encoding objective. The proposed approach can be applied to any tree-structured objective, such as syntactic parsing, discourse parsing and others. However, due to the especially difficult annotation process to generate discourse trees, we initially develop a method to generate larger and more diverse discourse treebanks. In this paper we are inferring general tree structures of natural text in multiple domains, showing promising results on a diverse set of tasks.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Patrick Huber; Giuseppe Carenini",
        "authorids": "",
        "aff": "University of British Columbia; University of British Columbia",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17549/17549-13-21043-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13107-unsupervised-learning-of-discourse-structures-using-a-tree-autoencoder/",
        "doi": "10.1609/aaai.v35i14.17549",
        "pdf_size": 343661
    },
    {
        "id": "08856",
        "title": "Unsupervised Learning of Graph Hierarchical Abstractions with Differentiable Coarsening and Optimal Transport",
        "track": "main",
        "status": "Poster",
        "abstract": "Hierarchical abstractions are a methodology for solving large-scale graph problems in various disciplines. Coarsening is one such approach: it generates a pyramid of graphs whereby the one in the next level is a structural summary of the prior one. With a long history in scientific computing, many coarsening strategies were developed based on mathematically driven heuristics. Recently, resurgent interests exist in deep learning to design hierarchical methods learnable through differentiable parameterization. These approaches are paired with downstream tasks for supervised learning. In practice, however, supervised signals (e.g., labels) are scarce and are often laborious to obtain. In this work, we propose an unsupervised approach, coined OTCoarsening, with the use of optimal transport. Both the coarsening matrix and the transport cost matrix are parameterized, so that an optimal coarsening strategy can be learned and tailored for a given set of graphs. We demonstrate that the proposed approach produces meaningful coarse graphs and yields competitive performance compared with supervised methods for graph classification and regression.",
        "primary_area": "Machine Learning III",
        "author": "Tengfei Ma; Jie Chen",
        "authorids": "",
        "aff": "IBM Research; MIT-IBM Watson AI Lab",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17072/17072-13-20566-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08856-unsupervised-learning-of-graph-hierarchical-abstractions-with-differentiable-coarsening-and-optimal-transport/",
        "doi": "10.1609/aaai.v35i10.17072",
        "pdf_size": 436715
    },
    {
        "id": "02593",
        "title": "Unsupervised Model Adaptation for Continual Semantic Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "We develop an algorithm for adapting a semantic segmentation model that is trained using a labeled source domain to generalize well in an unlabeled target domain. A similar problem has been studied extensively in the unsupervised domain adaptation (UDA) literature, but existing UDA algorithms require access to both the source domain labeled data and the target domain unlabeled data for training a domain agnostic semantic segmentation model.  Relaxing this constraint enables a user to adapt  pretrained models to generalize in a target domain, without requiring access to source data. To this end, we learn a prototypical distribution for the source domain in an intermediate embedding space. This distribution encodes the abstract knowledge that is learned from the source domain. We then use this distribution for aligning the target domain distribution with the source domain distribution in the embedding space. We provide theoretical analysis and explain conditions under which our algorithm is effective. Experiments on  benchmark adaptation tasks demonstrate our method achieves competitive performance even compared with joint UDA approaches.",
        "primary_area": "Computer Vision II",
        "author": "Serban Stan; Mohammad Rostami",
        "authorids": "",
        "aff": "University of Southern California; University of Southern California, Information Sciences Institute",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16362/16362-13-19856-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02593-unsupervised-model-adaptation-for-continual-semantic-segmentation/",
        "doi": "10.1609/aaai.v35i3.16362",
        "pdf_size": 3058668
    },
    {
        "id": "12489",
        "title": "Unsupervised Opinion Summarization with Content Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "The recent success of deep learning techniques for abstractive summarization is predicated on the availability of large-scale datasets.  When summarizing reviews (e.g., for products or movies), such training data is neither available nor can be easily sourced, motivating the development of methods which rely on synthetic datasets for supervised training.  We show that explicitly incorporating content planning in a summarization model not only yields output of higher quality, but also allows the creation of synthetic datasets which are more natural, resembling real world document-summary pairs.  Our content plans take the form of aspect and sentiment distributions which we induce from data without access to expensive annotations. Synthetic datasets are created by sampling pseudo-reviews from a Dirichlet distribution parametrized by our content planner, while our model generates summaries based on input reviews and induced content plans.  Experimental results on three domains show that our approach outperforms competitive models in generating informative, coherent, and fluent summaries that capture opinion consensus.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Reinald Kim Amplayo; Stefanos Angelidis; Mirella Lapata",
        "authorids": "",
        "aff": "University of Edinburgh; University of Edinburgh; University of Edinburgh",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17481/17481-13-20975-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12489-unsupervised-opinion-summarization-with-content-planning/",
        "doi": "10.1609/aaai.v35i14.17481",
        "pdf_size": 267874
    },
    {
        "id": "14674",
        "title": "Unsupervised Summarization for Chat Logs with Topic-Oriented Ranking and Context-Aware Auto-Encoders",
        "track": "main",
        "status": "Poster",
        "abstract": "Automatic chat summarization can help people quickly grasp important information from numerous chat messages. Unlike conventional documents, chat logs usually have fragmented and evolving topics. In addition, these logs contain a quantity of elliptical and interrogative sentences, which make the chat summarization highly context dependent. In this work, we propose a novel unsupervised framework called RankAE to perform chat summarization without employing manually labeled data. RankAE consists of a topic-oriented ranking strategy that selects topic utterances according to centrality and diversity simultaneously, as well as a denoising auto-encoder that is carefully designed to generate succinct but context-informative summaries based on the selected utterances. To evaluate the proposed method, we collect a large-scale dataset of chat logs from a customer service environment and build an annotated set only for model evaluation. Experimental results show that RankAE significantly outperforms other unsupervised methods and is able to generate high-quality summaries in terms of relevance and topic coverage.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Yicheng Zou; Jun Lin; Lujun Zhao; Yangyang Kang; Zhuoren Jiang; Changlong Sun; Qi Zhang; Xuanjing Huang; Xiaozhong Liu",
        "authorids": "",
        "aff": "Fudan University; Alibaba Group; Alibaba Group; Alibaba Group; Zhejiang University; Alibaba Group Zhejiang University; Fudan University; Fudan University; Indiana University Bloomington",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17724/17724-13-21218-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14674-unsupervised-summarization-for-chat-logs-with-topic-oriented-ranking-and-context-aware-auto-encoders/",
        "doi": "10.1609/aaai.v35i16.17724",
        "pdf_size": 313743
    },
    {
        "id": "05896",
        "title": "User Driven Model Adjustment via Boolean Rule Explanations",
        "track": "main",
        "status": "Poster",
        "abstract": "AI solutions are heavily dependant on the quality and accuracy of the input training data, however the training data may not always fully reflect the most up-to-date policy landscape or may be missing business logic. The advances in explainability have opened the possibility of allowing users to interact with interpretable explanations of ML predictions in order to inject modifications or constraints that more accurately reflect current realities of the system. In this paper, we present a solution which leverages the predictive power of ML models while allowing the user to specify modifications to decision boundaries. Our interactive overlay approach achieves this goal without requiring model retraining, making it appropriate for systems that need to apply instant changes to their decision making. We demonstrate that user feedback rules can be layered with the ML predictions to provide immediate changes which in turn supports learning with less data.",
        "primary_area": "Humans and AI",
        "author": "Elizabeth M. Daly; Massimiliano Mattetti; \u00d6znur Alkan; Rahul Nair",
        "authorids": "",
        "aff": "IBM Research; IBM Research; IBM Research; IBM Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16737/16737-13-20231-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05896-user-driven-model-adjustment-via-boolean-rule-explanations/",
        "doi": "10.1609/aaai.v35i7.16737",
        "pdf_size": 1975741
    },
    {
        "id": "06993",
        "title": "Using Hindsight to Anchor Past Knowledge in Continual Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "In continual learning, the learner faces a stream of data whose distribution changes over time. Modern neural networks are known to suffer under this setting, as they quickly forget previously acquired knowledge. To address such catastrophic forgetting, many continual learning methods implement different types of experience replay, re-learning on past data stored in a small buffer known as episodic memory. In this work, we complement experience replay with a new objective that we call ``anchoring'', where the learner uses bilevel optimization to update its knowledge on the current task, while keeping intact the predictions on some anchor points of past tasks. These anchor points are learned using gradient-based optimization to maximize forgetting, which is approximated by fine-tuning the currently trained model on the episodic memory of past tasks. Experiments on several supervised learning benchmarks for continual learning demonstrate that our approach improves the standard experience replay in terms of both accuracy and forgetting metrics and for various sizes of episodic memory.",
        "primary_area": "Machine Learning I",
        "author": "Arslan Chaudhry; Albert Gordo; Puneet Dokania; Philip Torr; David Lopez-Paz",
        "authorids": "",
        "aff": "University of Oxford; Facebook AI; University of Oxford; University of Oxford; Facebook AI",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16861/16861-13-20355-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06993-using-hindsight-to-anchor-past-knowledge-in-continual-learning/",
        "doi": "10.1609/aaai.v35i8.16861",
        "pdf_size": 4089106
    },
    {
        "id": "01575",
        "title": "VIVO: Visual Vocabulary Pre-Training for Novel Object Captioning",
        "track": "main",
        "status": "Poster",
        "abstract": "It is highly desirable yet challenging to generate image captions that can describe novel objects which are unseen in caption-labeled training data, a capability that is evaluated in the novel object captioning challenge (nocaps). In this challenge, no additional image-caption training data, other than COCO Captions, is allowed for model training. Thus, conventional Vision-Language Pre-training (VLP) methods cannot be applied. This paper presents VIsual VOcabulary pre-training (VIVO) that performs pre-training in the absence of caption annotations. By breaking the dependency of paired image-caption training data in VLP, VIVO can leverage large amounts of paired image-tag data to learn a visual vocabulary. This is done by pre-training a multi-layer Transformer model that learns to align image-level tags with their corresponding image region features. To address the unordered nature of image tags, VIVO uses a Hungarian matching loss with masked tag prediction to conduct pre-training.  We validate the effectiveness of VIVO by fine-tuning the pre-trained model for image captioning. In addition, we perform an analysis of the visual-text alignment inferred by our model. The results show that our model can not only generate fluent image captions that describe novel objects, but also identify the locations of these objects. Our single model has achieved new state-of-the-art results on nocaps and surpassed the human CIDEr score.",
        "primary_area": "Computer Vision I",
        "author": "Xiaowei Hu; Xi Yin; Kevin Lin; Lei Zhang; Jianfeng Gao; Lijuan Wang; Zicheng Liu",
        "authorids": "",
        "aff": "Microsoft; Microsoft; Microsoft; Microsoft; Microsoft; Microsoft; Microsoft",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16249/16249-13-19743-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01575-vivo-visual-vocabulary-pre-training-for-novel-object-captioning/",
        "doi": "10.1609/aaai.v35i2.16249",
        "pdf_size": 1557187
    },
    {
        "id": "06165",
        "title": "VMLoc: Variational Fusion For Learning-Based Multimodal Camera Localization",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent learning-based approaches have achieved impressive results in the field of single-shot camera localization. However, how best to fuse multiple modalities (e.g., image and depth) and to deal with degraded or missing input are less well studied. In particular, we note that previous approaches towards deep fusion do not perform significantly better than models employing a single modality. We conjecture that this is because of the naive approaches to feature space fusion through summation or concatenation which do not take into account the different strengths of each modality. To address this, we propose an end-to-end framework, termed VMLoc, to fuse different sensor inputs into a common latent space through a variational Product-of-Experts (PoE) followed by attention-based fusion. Unlike previous multimodal variational works directly adapting the objective function of vanilla variational auto-encoder, we show how camera localization can be accurately estimated through an unbiased objective function based on importance weighting. Our model is extensively evaluated on RGB-D datasets and the results prove the efficacy of our model. The source code is available at https://github.com/Zalex97/VMLoc.",
        "primary_area": "Intelligent Robots",
        "author": "Kaichen Zhou; Changhao Chen; Bing Wang; Muhamad Risqi U. Saputra; Niki Trigoni; Andrew Markham",
        "authorids": "",
        "aff": "University of Oxford; National University of Defense Technology; University of Oxford; University of Oxford; University of Oxford; University of Oxford",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16767/16767-13-20261-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06165-vmloc-variational-fusion-for-learning-based-multimodal-camera-localization/",
        "doi": "10.1609/aaai.v35i7.16767",
        "pdf_size": 599433
    },
    {
        "id": "08357",
        "title": "VSQL: Variational Shadow Quantum Learning for Classification",
        "track": "main",
        "status": "Poster",
        "abstract": "Classification of quantum data is essential for quantum machine learning and near-term quantum technologies. In this paper, we propose a new hybrid quantum-classical framework for supervised quantum learning, which we call Variational Shadow Quantum Learning (VSQL). Our method in particular utilizes the classical shadows of quantum data, which fundamentally represent the side information of quantum data with respect to certain physical observables. Specifically, we first use variational shadow quantum circuits to extract classical features in a convolution way and then utilize a fully-connected neural network to complete the classification task. We show that this method could sharply reduce the number of parameters and thus better facilitate quantum circuit training. Simultaneously, less noise will be introduced since fewer quantum gates are employed in such shadow circuits. Moreover, we show that the Barren Plateau issue, a significant gradient vanishing problem in quantum machine learning, could be avoided in VSQL. Finally, we demonstrate the efficiency of VSQL in quantum classification via  numerical experiments on the classification of quantum states and the recognition of multi-labeled handwritten digits. In particular, our VSQL approach outperforms existing variational quantum classifiers in the test accuracy in the binary case of handwritten digit recognition and notably requires much fewer parameters.",
        "primary_area": "Machine Learning II",
        "author": "Guangxi Li; Zhixin Song; Xin Wang",
        "authorids": "",
        "aff": "Baidu Research University of Technology Sydney; Baidu Research; Baidu Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17016/17016-13-20510-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08357-vsql-variational-shadow-quantum-learning-for-classification/",
        "doi": "10.1609/aaai.v35i9.17016",
        "pdf_size": 2759047
    },
    {
        "id": "11352",
        "title": "Value-Decomposition Multi-Agent Actor-Critics",
        "track": "main",
        "status": "Poster",
        "abstract": "The exploitation of extra state information has been an active research area in multi-agent reinforcement learning (MARL). QMIX represents the joint action-value using a non-negative function approximator and achieves the best performance on the StarCraft II micromanagement testbed, a common MARL benchmark. However, our experiments demonstrate that, in some cases, QMIX performs sub-optimally with the A2C framework, a training paradigm that promotes algorithm training efficiency. To obtain a reasonable trade-off between training efficiency and algorithm performance, we extend value-decomposition to actor-critic methods that are compatible with A2C and propose a novel actor-critic framework, value-decomposition actor-critic (VDAC). We evaluate VDAC on the StarCraft II micromanagement task and demonstrate that the proposed framework improves median performance over other actor-critic methods. Furthermore, we use a set of ablation experiments to identify the key factors that contribute to the performance of VDAC.",
        "primary_area": "Multiagent Systems",
        "author": "Jianyu Su; Stephen Adams; Peter Beling",
        "authorids": "",
        "aff": "University of Virginia; University of Virginia; University of Virginia",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17353/17353-13-20847-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11352-value-decomposition-multi-agent-actor-critics/",
        "doi": "10.1609/aaai.v35i13.17353",
        "pdf_size": 1342472
    },
    {
        "id": "07899",
        "title": "Variance Penalized On-Policy and Off-Policy Actor-Critic",
        "track": "main",
        "status": "Poster",
        "abstract": "Reinforcement learning algorithms are typically geared towards optimizing the expected return of an agent. However, in many practical applications, low variance in the return is desired to ensure the reliability of an algorithm. In this paper, we propose on-policy and off-policy actor-critic algorithms that optimize a performance criterion involving both mean and variance in the return. Previous work uses the second moment of return to estimate the variance indirectly. Instead, we use a much simpler recently proposed direct variance estimator which updates the estimates incrementally using temporal difference methods. Using the variance-penalized criterion, we guarantee the convergence of our algorithm to locally optimal policies for finite state action Markov decision processes. We demonstrate the utility of our algorithm in tabular and continuous MuJoCo domains. Our approach not only performs on par with actor-critic and prior variance-penalization baselines in terms of expected return, but also generates trajectories which have lower variance in the return.",
        "primary_area": "Machine Learning II",
        "author": "Arushi Jain; Gandharv Patil; Ayush Jain; Khimya Khetarpal; Doina Precup",
        "authorids": "",
        "aff": "McGill University, Montreal Mila, Montreal; McGill University, Montreal Mila, Montreal; McGill University, Montreal Mila, Montreal; McGill University, Montreal Mila, Montreal; McGill University, Montreal Mila, Montreal Google DeepMind, Montreal",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16964/16964-13-20458-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/07899-variance-penalized-on-policy-and-off-policy-actor-critic/",
        "doi": "10.1609/aaai.v35i9.16964",
        "pdf_size": 666689
    },
    {
        "id": "10469",
        "title": "Variational Disentanglement for Rare Event Modeling",
        "track": "main",
        "status": "Poster",
        "abstract": "Combining the increasing availability and abundance of healthcare data and the current advances in machine learning methods have created renewed opportunities to improve clinical decision support systems. However, in healthcare risk prediction applications, the proportion of cases with the condition (label) of interest is often very low relative to the available sample size. Though very prevalent in healthcare, such imbalanced classification settings are also common and challenging in many other scenarios. So motivated, we propose a variational disentanglement approach to semi-parametrically learn from rare events in heavily imbalanced classification problems. Specifically, we leverage the imposed extreme-distribution behavior on a latent space to extract information from low-prevalence events, and develop a robust prediction arm that joins the merits of the generalized additive model and isotonic neural nets. Results on synthetic studies and diverse real-world datasets, including mortality prediction on a COVID-19 cohort, demonstrate that the proposed approach outperforms existing alternatives.",
        "primary_area": "Machine Learning V",
        "author": "Zidi Xiu; Chenyang Tao; Michael Gao; Connor Davis; Benjamin A. Goldstein; Ricardo Henao",
        "authorids": "",
        "aff": "Duke University; Duke University; Duke University; Duke Institute for Health Innovation; Duke University; Duke University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17253/17253-13-20747-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10469-variational-disentanglement-for-rare-event-modeling/",
        "doi": "10.1609/aaai.v35i12.17253",
        "pdf_size": 4272195
    },
    {
        "id": "11202",
        "title": "Variational Fair Clustering",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a general variational framework of fair clustering, which integrates an original Kullback-Leibler (KL) fairness term with a large class of clustering objectives, including prototype or graph based. Fundamentally different from the existing combinatorial and spectral solutions, our variational multi-term approach enables to control the trade-off levels between the fairness and clustering objectives. We derive a general tight upper bound based on a concave-convex decomposition of our fairness term, its Lipschitz-gradient property and the Pinsker\u2019s inequality. Our tight upper bound can be jointly optimized with various clustering objectives, while yielding a scalable solution, with convergence guarantee. Interestingly, at each iteration, it performs an independent update for each assignment variable. Therefore, it can be easily distributed for large-scale datasets. This scalability is important as it enables to explore different trade-off levels between the fairness and clustering objectives. Unlike spectral relaxation, our formulation does not require computing its eigenvalue decomposition. We report comprehensive evaluations and comparisons with state-of-the-art methods over various fair clustering benchmarks, which show that our variational formulation can yield highly competitive solutions in terms of fairness and clustering objectives.",
        "primary_area": "Machine Learning V",
        "author": "Imtiaz Masud Ziko; Jing Yuan; Eric Granger; Ismail Ben Ayed",
        "authorids": "",
        "aff": "\u00c9TS Montreal, Canada; Xidian University, China; \u00c9TS Montreal, Canada; \u00c9TS Montreal, Canada",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17336/17336-13-20830-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11202-variational-fair-clustering/",
        "doi": "10.1609/aaai.v35i12.17336",
        "pdf_size": 1016050
    },
    {
        "id": "13552",
        "title": "Variational Inference for Learning Representations of Natural Language Edits",
        "track": "main",
        "status": "Poster",
        "abstract": "Document editing has become a pervasive component of production of information, with version control systems enabling edits to be efficiently stored and applied. In light of this, the task of learning distributed representations of edits has been recently proposed.  With this in mind, we propose a novel approach that employs variational inference to learn a continuous latent space of vector representations to capture the underlying semantic information with regard to the document editing process.  We achieve this by introducing a latent variable to explicitly model the aforementioned features. This latent variable is then combined with a document representation to guide the generation of an edited-version of this document. Additionally, to facilitate standardized automatic evaluation of edit representations, which has heavily relied on direct human input thus far, we also propose a suite of downstream tasks, PEER, specifically designed to measure the quality of edit representations in the context of natural language processing.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Edison Marrese-Taylor; Machel Reid; Yutaka Matsuo",
        "authorids": "",
        "aff": "The University of Tokyo; The University of Tokyo; The University of Tokyo",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17598/17598-13-21092-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13552-variational-inference-for-learning-representations-of-natural-language-edits/",
        "doi": "10.1609/aaai.v35i15.17598",
        "pdf_size": 177090
    },
    {
        "id": "09322",
        "title": "Vector Quantized Bayesian Neural Network Inference for Data Streams",
        "track": "main",
        "status": "Poster",
        "abstract": "Bayesian neural networks (BNN) can estimate the uncertainty in predictions, as opposed to non-Bayesian neural networks (NNs). However, BNNs have been far less widely used than non-Bayesian NNs in practice since they need iterative NN executions to predict a result for one data, and it gives rise to prohibitive computational cost. This computational burden is a critical problem when processing data streams with low-latency. To address this problem, we propose a novel model VQ-BNN, which approximates BNN inference for data streams. In order to reduce the computational burden, VQ-BNN inference predicts NN only once and compensates the result with previously memorized predictions. To be specific, VQ-BNN inference for data streams is given by temporal exponential smoothing of recent predictions. The computational cost of this model is almost the same as that of non-Bayesian NNs. Experiments including semantic segmentation on real-world data show that this model performs significantly faster than BNNs while estimating predictive results comparable to or superior to the results of BNNs.",
        "primary_area": "Machine Learning III",
        "author": "Namuk Park; Taekyu Lee; Songkuk Kim",
        "authorids": "",
        "aff": "Yonsei University; Yonsei University; Yonsei University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17124/17124-13-20618-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09322-vector-quantized-bayesian-neural-network-inference-for-data-streams/",
        "doi": "10.1609/aaai.v35i10.17124",
        "pdf_size": 1380223
    },
    {
        "id": "11470",
        "title": "Verifiable Machine Ethics in Changing Contexts",
        "track": "main",
        "status": "Poster",
        "abstract": "Many systems proposed for the implementation of ethical reasoning involve an encoding of user values as a set of rules or a model.  We consider the question of how changes of context affect these encodings. We propose the use of a reasoning cycle, in which information about the ethical reasoner's context is imported in a logical form, and we propose that context-specific aspects of an ethical encoding be prefaced by a guard formula.  This guard formula should evaluate to true when the reasoner is in the appropriate context and the relevant parts of the reasoner's rule set or model should be updated accordingly.  This architecture allows techniques for the model-checking of agent-based autonomous systems to be used to verify that all contexts respect key stakeholder values.  We implement this framework using the hybrid ethical reasoning agents system (HERA) and the model-checking agent programming languages (MCAPL) framework.",
        "primary_area": "Philosophy and Ethics of AI",
        "author": "Louise A. Dennis; Martin Mose Bentzen; Felix Lindner; Michael Fisher",
        "authorids": "",
        "aff": "University of Manchester; Technical University of Denmark; Ulm University; University of Manchester",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17366/17366-13-20860-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11470-verifiable-machine-ethics-in-changing-contexts/",
        "doi": "10.1609/aaai.v35i13.17366",
        "pdf_size": 162527
    },
    {
        "id": "02809",
        "title": "Very Important Person Localization in Unconstrained Conditions: A New Benchmark",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a new high-quality dataset for Very Important Person Localization (VIPLoc), named Unconstrained-7k. Generally, current datasets: 1) are limited in scale; 2) built under simple and constrained conditions, where the number of disturbing non-VIPs is not large, the scene is relatively simple, and the face of VIP is always in frontal view and salient. To tackle these problems, the proposed Unconstrained-7k dataset is featured in two aspects. First, it contains over 7,000 annotated images, making it the largest VIPLoc dataset  under unconstrained conditions to date. Second, our dataset is collected freely on the Internet, including multiple scenes, where images are in unconstrained conditions. VIPs in the new dataset are in different settings, e.g., large view variation, varying sizes, occluded, and complex scenes. Meanwhile, each image has more persons (> 20), making the dataset more challenging.  As a minor contribution, motivated by the observation that VIPs are highly related to not only neighbors but also iconic objects, this paper proposes a Joint Social Relation and Individual Interaction Graph Neural Networks (JSRII-GNN) for VIPLoc. Experiments show that the JSRII-GNN yields competitive accuracy on NCAA (National Collegiate Athletic Association), MS (Multi-scene), and Unconstrained-7k datasets. https://github.com/xiaowang1516/VIPLoc.",
        "primary_area": "Computer Vision III",
        "author": "Xiao Wang; Zheng Wang; Toshihiko Yamasaki; Wenjun Zeng",
        "authorids": "",
        "aff": "School of Computer Science and Technology, Wuhan University of Science and Technology; Research Institute for an Inclusive Society through Engineering (RIISE), The University of Tokyo Department of Information and Communication Engineering, The University of Tokyo; Research Institute for an Inclusive Society through Engineering (RIISE), The University of Tokyo Department of Information and Communication Engineering, The University of Tokyo; Microsoft Research Asia",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16386/16386-13-19880-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02809-very-important-person-localization-in-unconstrained-conditions-a-new-benchmark/",
        "doi": "10.1609/aaai.v35i4.16386",
        "pdf_size": 8811504
    },
    {
        "id": "02412",
        "title": "Vid-ODE: Continuous-Time Video Generation with Neural Ordinary Differential Equation",
        "track": "main",
        "status": "Poster",
        "abstract": "Video generation models often operate under the assumption of fixed frame rates, which leads to suboptimal performance when it comes to handling flexible frame rates (e.g., increasing the frame rate of the more dynamic portion of the video as well as handling missing video frames). To resolve the restricted nature of existing video generation models' ability to handle arbitrary timesteps, we propose continuous-time video generation by combining neural ODE (Vid-ODE) with pixel-level video processing techniques. Using ODE-ConvGRU as an encoder, a convolutional version of the recently proposed neural ODE, which enables us to learn continuous-time dynamics, Vid-ODE can learn the spatio-temporal dynamics of input videos of flexible frame rates. The decoder integrates the learned dynamics function to synthesize video frames at any given timesteps, where the pixel-level composition technique is used to maintain the sharpness of individual frames. With extensive experiments on four real-world video datasets, we verify that the proposed Vid-ODE outperforms state-of-the-art approaches under various video generation settings, both within the trained time range (interpolation) and beyond the range (extrapolation). To the best of our knowledge, Vid-ODE is the first work successfully performing continuous-time video generation using real-world videos.",
        "primary_area": "Computer Vision II",
        "author": "Sunghyun  Park; Kangyeol Kim; Junsoo Lee; Jaegul Choo; Joonseok Lee; Sookyung Kim; Edward Choi",
        "authorids": "",
        "aff": "KAIST; KAIST; KAIST; KAIST; Google Research; Lawrence Livermore National Laboratory; KAIST",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16342/16342-13-19836-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02412-vid-ode-continuous-time-video-generation-with-neural-ordinary-differential-equation/",
        "doi": "10.1609/aaai.v35i3.16342",
        "pdf_size": 10860678
    },
    {
        "id": "01334",
        "title": "Visual Boundary Knowledge Translation for Foreground Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "When confronted with objects of unknown types in an image, humans can effortlessly and precisely tell their visual boundaries. This recognition mechanism and underlying generalization capability seem to contrast to state-of-the-art image segmentation networks that rely on large-scale category-aware annotated training samples. In this paper, we make an attempt towards building models that explicitly account for visual boundary knowledge, in hope to reduce the training effort on segmenting unseen categories. Specifically, we investigate a new task  termed as Boundary Knowledge Translation (BKT). Given a set of fully labeled categories, BKT aims to translate the visual boundary knowledge learned from the labeled categories, to a set of novel categories, each of which is provided only a few labeled samples. To this end, we propose a Translation Segmentation Network (Trans-Net), which comprises a segmentation network and two boundary discriminators. The segmentation network, combined with a boundary-aware self-supervised mechanism, is devised to conduct foreground segmentation, while the two discriminators work together in an adversarial manner to ensure an accurate segmentation of the novel categories under light supervision. Exhaustive experiments demonstrate that, with only tens of labeled samples as guidance, Trans-Net achieves close results on par with fully supervised methods.",
        "primary_area": "Computer Vision I",
        "author": "Zunlei Feng; Lechao Cheng; Xinchao Wang; Xiang Wang; Ya Jie Liu; Xiangtong Du; Mingli Song",
        "authorids": "",
        "aff": "Zhejiang University; Zhejiang Lab; Stevens Institute of Technology; Zhejiang University; Zhejiang Lab; Jiangsu University of Science and Technology; Zhejiang University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16222/16222-13-19716-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01334-visual-boundary-knowledge-translation-for-foreground-segmentation/",
        "doi": "10.1609/aaai.v35i2.16222",
        "pdf_size": 588493
    },
    {
        "id": "01762",
        "title": "Visual Comfort Aware-Reinforcement Learning for Depth Adjustment of Stereoscopic 3D Images",
        "track": "main",
        "status": "Poster",
        "abstract": "Depth adjustment aims to enhance the visual experience of stereoscopic 3D (S3D) images, which accompanied with improving visual comfort and depth perception. For a human expert, the depth adjustment procedure is a sequence of iterative decision making. The human expert iteratively adjusted the depth until he is satisfied with the both levels of visual comfort and the perceived depth. In this work, we present a novel deep reinforcement learning (DRL)-based approach for depth adjustment named VCA-RL (Visual Comfort Aware Reinforcement Learning) to explicitly model human sequential decision making in depth editing operations. We formulate the depth adjustment process as a Markov decision process where actions are defined as camera movement operations to control the distance between the left and right cameras. Our agent is trained based on the guidance of an objective visual comfort assessment metric to learn the optimal sequence of camera movement actions in terms of perceptual aspects in stereoscopic viewing. With extensive experiments and user studies, we show the effectiveness of our VCA-RL model on three different S3D databases.",
        "primary_area": "Computer Vision I",
        "author": "Hak Gu Kim; Minho Park; Sangmin Lee; Seongyeop Kim; Yong Man Ro",
        "authorids": "",
        "aff": "KAIST, Korea EPFL, Switzerland; KAIST, Korea; KAIST, Korea; KAIST, Korea; KAIST, Korea",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16270/16270-13-19764-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01762-visual-comfort-aware-reinforcement-learning-for-depth-adjustment-of-stereoscopic-3d-images/",
        "doi": "10.1609/aaai.v35i2.16270",
        "pdf_size": 2170719
    },
    {
        "id": "08172",
        "title": "Visual Concept Reasoning Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "A split-transform-merge strategy has been broadly used as an architectural constraint in convolutional neural networks for visual recognition tasks. It approximates sparsely connected networks by explicitly defining multiple branches to simultaneously learn representations with different visual concepts or properties. Dependencies or interactions between these representations are typically defined by dense and local operations, however, without any adaptiveness or high-level reasoning. In this work, we propose to exploit this strategy and combine it with our Visual Concept Reasoning Networks (VCRNet) to enable reasoning between high-level visual concepts. We associate each branch with a visual concept and derive a compact concept state by selecting a few local descriptors through an attention module. These concept states are then updated by graph-based interaction and used to adaptively modulate the local descriptors. We describe our proposed model by split-transform-attend-interact-modulate-merge stages, which are implemented by opting for a highly modularized architecture. Extensive experiments on visual recognition tasks such as image classification, semantic segmentation, object detection, scene recognition, and action recognition show that our proposed model, VCRNet, consistently improves the performance by increasing the number of parameters by less than 1%.",
        "primary_area": "Machine Learning II",
        "author": "Taesup Kim; Sungwoong Kim; Yoshua Bengio",
        "authorids": "",
        "aff": "Mila, Universit\u00e9 de Montr\u00e9al Kakao Brain; Kakao Brain; Mila, Universit\u00e9 de Montr\u00e9al",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16995/16995-13-20489-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08172-visual-concept-reasoning-networks/",
        "doi": "10.1609/aaai.v35i9.16995",
        "pdf_size": 10838712
    },
    {
        "id": "04257",
        "title": "Visual Pivoting for (Unsupervised) Entity Alignment",
        "track": "main",
        "status": "Poster",
        "abstract": "This work studies the use of visual semantic representations to align entities in heterogeneous knowledge graphs (KGs). Images are natural components of many existing KGs. By combining visual knowledge with other auxiliary information, we show that the proposed new approach,  EVA, creates a holistic entity representation that provides strong signals for cross-graph entity alignment. Besides, previous entity alignment methods require human labelled seed alignment, restricting availability. EVA provides a completely unsupervised solution by leveraging the visual similarity of entities to create an initial seed dictionary (visual pivots). Experiments on benchmark data sets DBP15k and DWY15k show that EVA offers state-of-the-art performance on both monolingual and cross-lingual entity alignment tasks. Furthermore, we discover that images are particularly useful to align long-tail KG entities, which inherently lack the structural contexts necessary for capturing the correspondences. Code release: https://github.com/cambridgeltl/eva; project page: http://cogcomp.org/page/publication view/927.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Fangyu Liu; Muhao Chen; Dan Roth; Nigel Collier",
        "authorids": "",
        "aff": "University of Cambridge; University of Southern California, University of Pennsylvania; University of Pennsylvania; University of Cambridge",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16550/16550-13-20044-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04257-visual-pivoting-for-unsupervised-entity-alignment/",
        "doi": "10.1609/aaai.v35i5.16550",
        "pdf_size": 6085192
    },
    {
        "id": "00801",
        "title": "Visual Relation Detection using Hybrid Analogical Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual Relation Detection is currently one of the most popular problems for visual understanding. Many deep-learning models are designed for relation detection on images and have achieved impressive results. However, deep-learning models have several serious problems, including poor training-efficiency and lack of understandability. Psychologists have ample evidence that analogy is central in human learning and reasoning, including visual reasoning. This paper introduces a new hybrid system for visual relation detection combining deep-learning models and analogical generalization. Object bounding boxes and masks are detected using deep-learning models and analogical generalization over qualitative representations is used for visual relation detection between object pairs. Experiments on the Visual Relation Detection dataset indicates that our hybrid system gets comparable results on the task and is more training-efficient and explainable than pure deep-learning models.",
        "primary_area": "Cognitive Modeling and Cognitive Systems",
        "author": "Kezhen Chen; Ken Forbus",
        "authorids": "",
        "aff": "Northwestern University, Evanston, IL; Northwestern University, Evanston, IL",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16162/16162-13-19656-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00801-visual-relation-detection-using-hybrid-analogical-learning/",
        "doi": "10.1609/aaai.v35i1.16162",
        "pdf_size": 600148
    },
    {
        "id": "03315",
        "title": "Visual Tracking via Hierarchical Deep Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual tracking has achieved great progress due to numerous different algorithms. However, deep trackers based on classification or Siamese network still have their specific limitations. In this work, we show how to teach machines to track a generic object in videos like humans, who can use a few search steps to perform tracking. By constructing a Markov decision process in Deep Reinforcement Learning (DRL), our agents can learn to determine hierarchical decisions on tracking mode and motion estimation. To be specific, our Hierarchical DRL framework is composed of a Siamese-based observation network which models the motion information of an arbitrary target, a policy network for mode switch and an actor-critic network for box regression. This tracking strategy is more in line with human behavior paradigm, and is effective and efficient to cope with fast motion, background clutter and large deformations. Extensive experiments on the GOT-10k, OTB-100, UAV-123, VOT and LaSOT tracking benchmarks, demonstrate that the proposed tracker achieves state-of-the-art performance while running in real-time.",
        "primary_area": "Computer Vision III",
        "author": "Dawei Zhang; Zhonglong Zheng; Riheng Jia; Minglu Li",
        "authorids": "",
        "aff": "Zhejiang Normal University; Zhejiang Normal University; Zhejiang Normal University; Zhejiang Normal University Shanghai Jiao Tong University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16443/16443-13-19937-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03315-visual-tracking-via-hierarchical-deep-reinforcement-learning/",
        "doi": "10.1609/aaai.v35i4.16443",
        "pdf_size": 2549048
    },
    {
        "id": "09454",
        "title": "Visual Transfer For Reinforcement Learning Via Wasserstein Domain Confusion",
        "track": "main",
        "status": "Poster",
        "abstract": "We introduce Wasserstein Adversarial Proximal Policy Optimization (WAPPO), a novel algorithm for visual transfer in Reinforcement Learning that explicitly learns to align the distributions of extracted features between a source and target task. WAPPO approximates and minimizes the Wasserstein-1 distance between the distributions of features from source and target domains via a novel Wasserstein Confusion objective. WAPPO outperforms the prior state-of-the-art in visual transfer and successfully transfers policies across Visual Cartpole and both the easy and hard settings of of 16 OpenAI Procgen environments.",
        "primary_area": "Machine Learning IV",
        "author": "Josh Roy; George D. Konidaris",
        "authorids": "",
        "aff": "Brown University; Brown University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17139/17139-13-20633-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09454-visual-transfer-for-reinforcement-learning-via-wasserstein-domain-confusion/",
        "doi": "10.1609/aaai.v35i11.17139",
        "pdf_size": 1386510
    },
    {
        "id": "13878",
        "title": "VisualMRC: Machine Reading Comprehension on Document Images",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent studies on machine reading comprehension have focused on text-level understanding but have not yet reached the level of human understanding of the visual layout and content of real-world documents. In this study, we introduce a new visual machine reading comprehension dataset, named VisualMRC, wherein given a question and a document image, a machine reads and comprehends texts in the image to answer the question in natural language. Compared with existing visual question answering datasets that contain texts in images, VisualMRC focuses more on developing natural language understanding and generation abilities. It contains 30,000+ pairs of a question and an abstractive answer for 10,000+ document images sourced from multiple domains of webpages. We also introduce a new model that extends existing sequence-to-sequence models, pre-trained with large-scale text corpora, to take into account the visual layout and content of documents. Experiments with VisualMRC show that this model outperformed the base sequence-to-sequence models and a state-of-the-art VQA model. However, its performance is still below that of humans on most automatic evaluation metrics.  The dataset will facilitate research aimed at connecting vision and language understanding.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Ryota Tanaka; Kyosuke Nishida; Sen Yoshida",
        "authorids": "",
        "aff": "NTT Media Intelligence Laboratories, NTT Corporation; NTT Media Intelligence Laboratories, NTT Corporation; NTT Media Intelligence Laboratories, NTT Corporation",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17635/17635-13-21129-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13878-visualmrc-machine-reading-comprehension-on-document-images/",
        "doi": "10.1609/aaai.v35i15.17635",
        "pdf_size": 5001138
    },
    {
        "id": "11545",
        "title": "Visualization of Supervised and Self-Supervised Neural Networks via Attribution Guided Factorization",
        "track": "main",
        "status": "Poster",
        "abstract": "Neural network visualization techniques mark image locations by their relevancy to the network's classification. Existing methods are effective in highlighting the regions that affect the resulting classification the most. However, as we show, these methods are limited in their ability to identify the support for alternative classifications, an effect we name the saliency bias hypothesis. In this work, we integrate two lines of research: gradient-based methods and attribution-based methods, and develop an algorithm that provides per-class explainability. The algorithm back-projects the per pixel local influence, in a manner that is guided by the local attributions, while correcting for salient features that would otherwise bias the explanation. In an extensive battery of experiments, we demonstrate the ability of our methods to class-specific visualization, and not just the predicted label. Remarkably, the method obtains state of the art results in benchmarks that are commonly applied to gradient-based methods as well as in those that are employed mostly for evaluating attribution methods. Using a new unsupervised procedure, our method is also successful in demonstrating that self-supervised methods learn semantic information. Our code is available at: https://github.com/shirgur/AGFVisualization.",
        "primary_area": "Philosophy and Ethics of AI",
        "author": "Shir Gur; Ameen Ali; Lior Wolf",
        "authorids": "",
        "aff": "Tel Aviv University, Israel; Tel Aviv University, Israel; Tel Aviv University, Israel",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17374/17374-13-20868-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11545-visualization-of-supervised-and-self-supervised-neural-networks-via-attribution-guided-factorization/",
        "doi": "10.1609/aaai.v35i13.17374",
        "pdf_size": 826640
    },
    {
        "id": "01201",
        "title": "Voxel R-CNN: Towards High Performance Voxel-based 3D Object Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent advances on 3D object detection heavily rely on how the 3D data are represented, i.e., voxel-based or point-based representation. Many existing high performance 3D detectors are point-based because this structure can better retain precise point positions. Nevertheless, point-level features lead to high computation overheads due to unordered storage. In contrast, the voxel-based structure is better suited for feature extraction but often yields lower accuracy because the input data are divided into grids. In this paper, we take a slightly different viewpoint --- we find that precise positioning of raw points is not essential for high performance 3D object detection and that the coarse voxel granularity can also offer sufficient detection accuracy. Bearing this view in mind, we devise a simple but effective voxel-based framework, named Voxel R-CNN. By taking full advantage of voxel features in a two-stage approach, our method achieves comparable detection accuracy with state-of-the-art point-based models, but at a fraction of the computation cost.  Voxel R-CNN consists of a 3D backbone network, a 2D bird-eye-view (BEV) Region Proposal Network, and a detect head. A voxel RoI pooling is devised to extract RoI features directly from voxel features for further refinement. Extensive experiments are conducted on the widely used KITTI Dataset and the more recent Waymo Open Dataset.  Our results show that compared to existing voxel-based methods, Voxel R-CNN delivers a higher detection accuracy while maintaining a real-time frame processing rate,  i.e., at a speed of 25 FPS on an NVIDIA RTX 2080 Ti GPU.  The code is available at https://github.com/djiajunustc/Voxel-R-CNN.",
        "primary_area": "Computer Vision I",
        "author": "Jiajun Deng; Shaoshuai Shi; Peiwei Li; Wengang Zhou; Yanyong Zhang; Houqiang Li",
        "authorids": "",
        "aff": "CAS Key Laboratory of GIPAS, EEIS Department, University of Science and Technology of China; Multimedia Laboratory, The Chinese University of Hong Kong; CAS Key Laboratory of GIPAS, EEIS Department, University of Science and Technology of China; CAS Key Laboratory of GIPAS, EEIS Department, University of Science and Technology of China Institute of Artificial Intelligence, Hefei Comprehensive National Science Center; Department of Computer Science, University of Science and Technology of China; CAS Key Laboratory of GIPAS, EEIS Department, University of Science and Technology of China Institute of Artificial Intelligence, Hefei Comprehensive National Science Center",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16207/16207-13-19701-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01201-voxel-r-cnn-towards-high-performance-voxel-based-3d-object-detection/",
        "doi": "10.1609/aaai.v35i2.16207",
        "pdf_size": 562091
    },
    {
        "id": "10639",
        "title": "WCSAC: Worst-Case Soft Actor Critic for Safety-Constrained Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Safe exploration is regarded as a key priority area for reinforcement learning research. With separate reward and safety signals, it is natural to cast it as constrained reinforcement learning, where expected long-term costs of policies are constrained. However, it can be hazardous to set constraints on the expected safety signal without considering the tail of the distribution. For instance, in safety-critical domains, worst-case analysis is required to avoid disastrous results. We present a novel reinforcement learning algorithm called Worst-Case Soft Actor Critic, which extends the Soft Actor Critic algorithm with a safety critic to achieve risk control. More specifically, a certain level of conditional Value-at-Risk from the distribution is regarded as a safety measure to judge the constraint satisfaction, which guides the change of adaptive safety weights to achieve a trade-off between reward and safety. As a result, we can optimize policies under the premise that their worst-case performance satisfies the constraints. The empirical analysis shows that our algorithm attains better risk control compared to expectation-based methods.",
        "primary_area": "Machine Learning V",
        "author": "Qisong Yang; Thiago D. Sim\u00e3o; Simon H Tindemans; Matthijs  T. J. Spaan",
        "authorids": "",
        "aff": "Delft University of Technology; Delft University of Technology; Delft University of Technology; Delft University of Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17272/17272-13-20766-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/10639-wcsac-worst-case-soft-actor-critic-for-safety-constrained-reinforcement-learning/",
        "doi": "10.1609/aaai.v35i12.17272",
        "pdf_size": 3429693
    },
    {
        "id": "09188",
        "title": "Warm Starting CMA-ES for Hyperparameter Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "Hyperparameter optimization (HPO), formulated as black-box optimization (BBO), is recognized as essential for automation and high performance of machine learning approaches. The CMA-ES is a promising BBO approach with a high degree of parallelism, and has been applied to HPO tasks, often under parallel implementation, and shown superior performance to other approaches including Bayesian optimization (BO). However, if the budget of hyperparameter evaluations is severely limited, which is often the case for end users who do not deserve parallel computing, the CMA-ES exhausts the budget without improving the performance due to its long adaptation phase, resulting in being outperformed by BO approaches. To address this issue, we propose to transfer prior knowledge on similar HPO tasks through the initialization of the CMA-ES, leading to significantly shortening the adaptation time. The knowledge transfer is designed based on the novel definition of task similarity, with which the correlation of the performance of the proposed approach is confirmed on synthetic problems. The proposed warm starting CMA-ES, called WS-CMA-ES, is applied to different HPO tasks where some prior knowledge is available, showing its superior performance over the original CMA-ES as well as BO approaches with or without using the prior knowledge.",
        "primary_area": "Machine Learning III",
        "author": "Masahiro Nomura; Shuhei Watanabe; Youhei Akimoto; Yoshihiko Ozaki; Masaki Onishi",
        "authorids": "",
        "aff": "CyberAgent, Inc. Artificial Intelligence Research Center, AIST; University of Freiburg; University of Tsukuba RIKEN Center for Advanced Intelligence Project; Artificial Intelligence Research Center, AIST GREE, Inc.; Artificial Intelligence Research Center, AIST",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17109/17109-13-20603-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09188-warm-starting-cma-es-for-hyperparameter-optimization/",
        "doi": "10.1609/aaai.v35i10.17109",
        "pdf_size": 446654
    },
    {
        "id": "05914",
        "title": "Wasserstein Distributionally Robust Inverse Multiobjective Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "Inverse multiobjective optimization provides a general framework for the unsupervised learning task of inferring parameters of a multiobjective decision making problem (DMP), based on a set of observed decisions from the human expert. However, the performance of this framework relies critically on the availability of an accurate DMP, sufficient decisions of high quality, and a parameter space that contains enough information about the DMP. To hedge against the uncertainties in the hypothetical DMP, the data, and the  parameter space, we investigate in this paper the distributionally robust approach for inverse multiobjective optimization. Specifically, we leverage the Wasserstein metric to construct a ball centered at the empirical distribution of these decisions. We then formulate a Wasserstein distributionally robust inverse multiobjective optimization problem (WRO-IMOP) that minimizes a worst-case expected loss function, where the worst case is taken over all distributions in the Wasserstein ball. We  show that the excess risk of the WRO-IMOP estimator has a sub-linear convergence rate. Furthermore, we propose the semi-infinite reformulations of the WRO-IMOP and develop a cutting-plane algorithm that converges to an approximate solution in finite iterations. Finally, we demonstrate the effectiveness of our method on both a synthetic multiobjective quadratic program and a real world portfolio optimization problem.",
        "primary_area": "Humans and AI",
        "author": "Chaosheng Dong; Bo Zeng",
        "authorids": "",
        "aff": "Amazon; University of Pittsburgh",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16739/16739-13-20233-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05914-wasserstein-distributionally-robust-inverse-multiobjective-optimization/",
        "doi": "10.1609/aaai.v35i7.16739",
        "pdf_size": 258351
    },
    {
        "id": "12728",
        "title": "We Can Explain Your Research in Layman\u2019s Terms: Towards Automating Science Journalism at Scale",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose to study Automating Science Journalism (ASJ), the process of producing a layman's terms summary of a research article, as a new benchmark for long neural abstractive summarization and story generation. Automating science journalism is a challenging task as it requires paraphrasing complex scientific concepts to be grasped by the general public. Thus, we create a specialized dataset that contains scientific papers and their Science Daily press releases. We demonstrate numerous sequence to sequence (seq2seq) applications using Science Daily with the aim of facilitating further research on language generation, which requires extreme paraphrasing and coping with long research articles. We further improve the quality of the press releases using co-training with scientific abstracts of sources or partitioned press releases. Finally, we apply evaluation measures beyond ROUGE and we demonstrate improved performance for our method over strong baselines, which we further confirm by quantitative and qualitative evaluation.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Rumen Dangovski; Michelle Shen; Dawson Byrd; Li Jing; Desislava Tsvetkova; Preslav Nakov; Marin Solja\u010di\u0107",
        "authorids": "",
        "aff": "Massachusetts Institute of Technology; Massachusetts Institute of Technology; Massachusetts Institute of Technology; Massachusetts Institute of Technology; Sofia University; Qatar Computing Research Institute, HBKU; Massachusetts Institute of Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17507/17507-13-21001-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12728-we-can-explain-your-research-in-layman-s-terms-towards-automating-science-journalism-at-scale/",
        "doi": "10.1609/aaai.v35i14.17507",
        "pdf_size": 454481
    },
    {
        "id": "02755",
        "title": "Weakly Supervised Deep Hyperspherical Quantization for Image Retrieval",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep quantization methods have shown high efficiency on large-scale image retrieval. However, current models heavily rely on ground-truth information, hindering the application of quantization in label-hungry scenarios. A more realistic demand is to learn from inexhaustible uploaded images that are associated with informal tags provided by amateur users. Though such sketchy tags do not obviously reveal the labels, they actually contain useful semantic information for supervising deep quantization. To this end, we propose Weakly-Supervised Deep Hyperspherical Quantization (WSDHQ), which is the first work to learn deep quantization from weakly tagged images. Specifically, 1) we use word embeddings to represent the tags and enhance their semantic information based on a tag correlation graph. 2) To better preserve semantic information in quantization codes and reduce quantization error, we jointly learn semantics-preserving embeddings and supervised quantizer on hypersphere by employing a well-designed fusion layer and tailor-made loss functions. Extensive experiments show that WSDHQ can achieve state-of-art performance in weakly-supervised compact coding.",
        "primary_area": "Computer Vision III",
        "author": "Jinpeng Wang; Bin Chen; Qiang Zhang; Zaiqiao Meng; Shangsong Liang; Shutao Xia",
        "authorids": "",
        "aff": "Tsinghua Shenzhen International Graduate School, Tsinghua University School of Computer Science and Engineering, Sun Yat-sen University; Tsinghua Shenzhen International Graduate School, Tsinghua University; University College London; University of Cambridge; School of Computer Science and Engineering, Sun Yat-sen University; Tsinghua Shenzhen International Graduate School, Tsinghua University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16380/16380-13-19874-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02755-weakly-supervised-deep-hyperspherical-quantization-for-image-retrieval/",
        "doi": "10.1609/aaai.v35i4.16380",
        "pdf_size": 2010006
    },
    {
        "id": "03421",
        "title": "Weakly Supervised Semantic Segmentation for Large-Scale Point Cloud",
        "track": "main",
        "status": "Poster",
        "abstract": "Existing methods for large-scale point cloud semantic segmentation require expensive, tedious and error-prone manual point-wise annotation. Intuitively, weakly supervised training is a direct solution to reduce the labeling costs. However, for weakly supervised large-scale point cloud semantic segmentation, too few annotations will inevitably lead to ineffective learning of network. We propose an effective weakly supervised method containing two components to solve the above problem. Firstly, we construct a pretext task, textit{i.e.,} point cloud colorization, with a self-supervised training manner to transfer the learned prior knowledge from a large amount of unlabeled point cloud to a weakly supervised network. In this way, the representation capability of the weakly supervised network can be improved by knowledge from a heterogeneous task. Besides, to generative pseudo label for unlabeled data, a sparse label propagation mechanism is proposed with the help of generated class prototypes, which is used to measure the classification confidence of unlabeled point. Our method is evaluated on large-scale point cloud datasets with different scenarios including indoor and outdoor. The experimental results show the large gain against existing weakly supervised methods and comparable results to fully supervised methods.",
        "primary_area": "Computer Vision III",
        "author": "Yachao Zhang; Zonghao Li; Yuan Xie; Yanyun Qu; Cuihua Li; Tao Mei",
        "authorids": "",
        "aff": "School of Informatics, Xiamen University; School of Informatics, Xiamen University; School of Computer Science and Technology, East China Normal University; School of Informatics, Xiamen University; School of Informatics, Xiamen University; AI Research of JD.com",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16455/16455-13-19949-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03421-weakly-supervised-semantic-segmentation-for-large-scale-point-cloud/",
        "doi": "10.1609/aaai.v35i4.16455",
        "pdf_size": 10640432
    },
    {
        "id": "02242",
        "title": "Weakly Supervised Temporal Action Localization Through Learning Explicit Subspaces for Action and Context",
        "track": "main",
        "status": "Poster",
        "abstract": "Weakly-supervised Temporal Action Localization (WS-TAL) methods learn to localize temporal starts and ends of action instances in a video under only video-level supervision. Existing WS-TAL methods rely on deep features learned for action recognition. However, due to the mismatch between classification and localization, these features cannot distinguish the frequently co-occurring contextual background, i.e., the context, and the actual action instances. We term this challenge action-context confusion, and it will adversely affect the action localization accuracy. To address this challenge, we introduce a framework that learns two feature subspaces respectively for actions and their context. By explicitly accounting for action visual elements, the action instances can be localized more precisely without the distraction from the context. To facilitate the learning of these two feature subspaces with only video-level categorical labels, we leverage the predictions from both spatial and temporal streams for snippets grouping. In addition, an unsupervised learning task is introduced to make the proposed module focus on mining temporal information. The proposed approach outperforms state-of-the-art WS-TAL methods on three benchmarks, i.e., THUMOS14, ActivityNet v1.2 and v1.3 datasets.",
        "primary_area": "Computer Vision II",
        "author": "Ziyi Liu; Le Wang; Wei Tang; Junsong Yuan; Nanning Zheng; Gang Hua",
        "authorids": "",
        "aff": "Xi'an Jiaotong University; Xi'an Jiaotong University; University of Illinois at Chicago; State University of New York at Buffalo; Xi'an Jiaotong University; Wormpex AI Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16323/16323-13-19817-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/02242-weakly-supervised-temporal-action-localization-through-learning-explicit-subspaces-for-action-and-context/",
        "doi": "10.1609/aaai.v35i3.16323",
        "pdf_size": 436201
    },
    {
        "id": "12648",
        "title": "Weakly-Supervised Hierarchical Models for Predicting Persuasive Strategies in Good-faith Textual Requests",
        "track": "main",
        "status": "Poster",
        "abstract": "Modeling persuasive language has the potential to better facilitate our decision-making processes. Despite its importance, computational modeling of persuasion is still in its infancy, largely due to the lack of benchmark datasets that can provide quantitative labels of persuasive strategies to expedite this line of research. To this end, we introduce a large-scale multi-domain text corpus for modeling persuasive strategies in good-faith text requests. Moreover, we design a hierarchical weakly-supervised latent variable model that can leverage partially labeled data to predict such associated persuasive strategies for each sentence, where the supervision comes from both the overall document-level labels and very limited sentence-level labels. Experimental results showed that our proposed method outperformed existing semi-supervised baselines significantly. We have publicly released our code at https://github.com/GT-SALT/Persuasion_Strategy_WVAE.",
        "primary_area": "Speech and Natural Language Processing I",
        "author": "Jiaao Chen; Diyi Yang",
        "authorids": "",
        "aff": "Georgia Institute of Technology; Georgia Institute of Technology",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17498/17498-13-20992-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12648-weakly-supervised-hierarchical-models-for-predicting-persuasive-strategies-in-good-faith-textual-requests/",
        "doi": "10.1609/aaai.v35i14.17498",
        "pdf_size": 623625
    },
    {
        "id": "01854",
        "title": "Weakly-supervised Temporal Action Localization by Uncertainty Modeling",
        "track": "main",
        "status": "Poster",
        "abstract": "Weakly-supervised temporal action localization aims to learn detecting temporal intervals of action classes with only video-level labels. To this end, it is crucial to separate frames of action classes from the background frames (i.e., frames not belonging to any action classes). In this paper, we present a new perspective on background frames where they are modeled as out-of-distribution samples regarding their inconsistency. Then, background frames can be detected by estimating the probability of each frame being out-of-distribution, known as uncertainty, but it is infeasible to directly learn uncertainty without frame-level labels. To realize the uncertainty learning in the weakly-supervised setting, we leverage the multiple instance learning formulation. Moreover, we further introduce a background entropy loss to better discriminate background frames by encouraging their in-distribution (action) probabilities to be uniformly distributed over all action classes. Experimental results show that our uncertainty modeling is effective at alleviating the interference of background frames and brings a large performance gain without bells and whistles. We demonstrate that our model significantly outperforms state-of-the-art methods on the benchmarks, THUMOS'14 and ActivityNet (1.2 & 1.3). Our code is available at https://github.com/Pilhyeon/WTAL-Uncertainty-Modeling.",
        "primary_area": "Computer Vision II",
        "author": "Pilhyeon Lee; Jinglu Wang; Yan Lu; Hyeran Byun",
        "authorids": "",
        "aff": "Yonsei University; Microsoft Research Asia; Microsoft Research Asia; Yonsei University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16280/16280-13-19774-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01854-weakly-supervised-temporal-action-localization-by-uncertainty-modeling/",
        "doi": "10.1609/aaai.v35i3.16280",
        "pdf_size": 1105443
    },
    {
        "id": "12400",
        "title": "Weighting-based Variable Neighborhood Search for Optimal Camera Placement",
        "track": "main",
        "status": "Poster",
        "abstract": "The optimal camera placement problem (OCP) aims to accomplish surveillance tasks with the minimum number of cameras, which is one of the topics in the GECCO 2020 Competition and can be modeled as the unicost set covering problem (USCP). This paper presents a weighting-based variable neighborhood search (WVNS) algorithm for solving OCP. First, it simplifies the problem instances with four reduction rules based on dominance and independence. Then, WVNS converts the simplified OCP into a series of decision unicost set covering subproblems and tackles them with a fast local search procedure featured by a swap-based neighborhood structure. WVNS employs an efficient incremental evaluation technique and further boosts the neighborhood evaluation by exploiting the dominance and independence features among neighborhood moves. Computational experiments on the 69 benchmark instances introduced in the GECCO 2020 Competition on OCP and USCP show that WVNS is extremely competitive comparing to the state-of-the-art methods. It outperforms or matches several best performing competitors on all instances in both the OCP and USCP tracks of the competition, and its advantage on 15 large-scale instances are over 10%. In addition, WVNS improves the previous best known results for 12 classical benchmark instances in the literature.",
        "primary_area": "Search and Optimization",
        "author": "Zhouxing Su; Qingyun Zhang; Zhipeng L\u00fc; Chu-Min Li; Weibo Lin; Fuda Ma",
        "authorids": "",
        "aff": "School of Computer Science and Technology, Huazhong University of Science and Technology; School of Computer Science and Technology, Huazhong University of Science and Technology; School of Computer Science and Technology, Huazhong University of Science and Technology; MIS, University of Picardie Jules Verne; Huawei Cloud Alkaid Lab, Huawei Technologies Co., Ltd.; Huawei Cloud Alkaid Lab, Huawei Technologies Co., Ltd.",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17471/17471-13-20965-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12400-weighting-based-variable-neighborhood-search-for-optimal-camera-placement/",
        "doi": "10.1609/aaai.v35i14.17471",
        "pdf_size": 345924
    },
    {
        "id": "05236",
        "title": "Welfare Guarantees in Schelling Segregation",
        "track": "main",
        "status": "Poster",
        "abstract": "Schelling's model is an influential model that reveals how individual perceptions and incentives can lead to racial segregation. Inspired by a recent stream of work, we study welfare guarantees and complexity in this model with respect to several welfare measures. First, we show that while maximizing the social welfare is NP-hard, computing an assignment with approximately half of the maximum welfare can be done in polynomial time. We then consider Pareto optimality and introduce two new optimality notions, and establish mostly tight bounds on the worst-case welfare loss for assignments satisfying these notions. In addition, we show that for trees, it is possible to decide whether there exists an assignment that gives every agent a positive utility in polynomial time; moreover, when every node in the topology has degree at least 2, such an assignment always exists and can be found efficiently.",
        "primary_area": "Game Theory and Economic Paradigms",
        "author": "Martin Bullinger; Warut Suksompong; Alexandros A. Voudouris",
        "authorids": "",
        "aff": "Technische Universit\u00e4t M\u00fcnchen; National University of Singapore; University of Essex",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16661/16661-13-20155-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/05236-welfare-guarantees-in-schelling-segregation/",
        "doi": "10.1609/aaai.v35i6.16661",
        "pdf_size": 137754
    },
    {
        "id": "14638",
        "title": "What the Role is vs. What Plays the Role: Semi-Supervised Event Argument Extraction via Dual Question Answering",
        "track": "main",
        "status": "Poster",
        "abstract": "Event argument extraction is an essential task in event extraction, and become particularly challenging in the case of low-resource scenarios. We solve the issues in existing studies under low-resource situations from two sides. From the perspective of the model, the existing methods always suffer from the concern of insufficient parameter sharing and do not consider the semantics of roles, which is not conducive to dealing with sparse data.  And from the perspective of the data, most existing methods focus on data generation and data augmentation.  However, these methods rely heavily on external resources, which is more laborious to create than obtain unlabeled data. In this paper, we propose DualQA, a novel framework, which models the event argument extraction task as question answering to alleviate the problem of data sparseness and leverage the duality of event argument recognition which is to ask \"What plays the role\", as well as event role recognition which is to ask \"What the role is\",  to mutually improve each other.Experimental results on two datasets prove the effectiveness of our approach, especially in extremely low-resource situations.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Yang Zhou; Yubo Chen; Jun Zhao; Yin Wu; Jiexin Xu; Jinlong Li",
        "authorids": "",
        "aff": "National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences School of Artificial Intelligence, University of Chinese Academy of Sciences; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences School of Artificial Intelligence, University of Chinese Academy of Sciences; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences School of Artificial Intelligence, University of Chinese Academy of Sciences; AI Lab, China Merchant Bank; AI Lab, China Merchant Bank; AI Lab, China Merchant Bank",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17720/17720-13-21214-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14638-what-the-role-is-vs-what-plays-the-role-semi-supervised-event-argument-extraction-via-dual-question-answering/",
        "doi": "10.1609/aaai.v35i16.17720",
        "pdf_size": 531788
    },
    {
        "id": "01708",
        "title": "What to Select: Pursuing Consistent Motion Segmentation from Multiple Geometric Models",
        "track": "main",
        "status": "Poster",
        "abstract": "Motion segmentation aims at separating motions of different moving objects in a video sequence. Facing the complicated real-world scenes, recent studies reveal that combining multiple geometric models would be a more effective way than just employing a single one. This motivates a new wave of model-fusion based motion segmentation methods. However, the vast majority of models of this kind merely seek consensus in spectral embeddings. We argue that a simple consensus might be insufficient to filter out the harmful information which is either unreliable or semantically unrelated to the segmentation task. Therefore, how to automatically select valuable patterns across multiple models should be regarded as a key challenge here. In this paper, we present a novel geometric-model-fusion framework for motion segmentation, which targets at constructing a consistent affinity matrix across all the geometric models. Specifically, it incorporates the structural information shared by affinity matrices to select those semantically consistent entries. Meanwhile, a multiplicative decomposition scheme is adopted to ensure structural consistency among multiple affinities. To solve this problem, an alternative optimization scheme is proposed, together with a proof of its global convergence. Experiments on four real-world benchmarks show the superiority of the proposed method.",
        "primary_area": "Computer Vision I",
        "author": "Yangbangyan Jiang; Qianqian Xu; Ke Ma; Zhiyong Yang; Xiaochun Cao; Qingming Huang",
        "authorids": "",
        "aff": "Institute of Information Engineering, Chinese Academy of Sciences University of Chinese Academy of Sciences; Institute of Computing Technology, Chinese Academy of Sciences; University of Chinese Academy of Sciences; Institute of Information Engineering, Chinese Academy of Sciences University of Chinese Academy of Sciences; Institute of Information Engineering, Chinese Academy of Sciences University of Chinese Academy of Sciences Peng Cheng Laboratory; University of Chinese Academy of Sciences Institute of Computing Technology, Chinese Academy of Sciences Peng Cheng Laboratory",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16264/16264-13-19758-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01708-what-to-select-pursuing-consistent-motion-segmentation-from-multiple-geometric-models/",
        "doi": "10.1609/aaai.v35i2.16264",
        "pdf_size": 5393178
    },
    {
        "id": "14292",
        "title": "What\u2019s the Best Place for an AI Conference, Vancouver or _______: Why Completing Comparative Questions is Difficult",
        "track": "main",
        "status": "Poster",
        "abstract": "Although large neural language models (LMs) like BERT can be finetuned to yield state-of-the-art results on many NLP tasks, it is often unclear what these models actually learn.  Here we study using such LMs to fill in entities in human-authored comparative questions, like ``Which country is older, India or _____?''---i.e., we study the ability of neural LMs to ask (not answer) reasonable questions.  We show that accuracy in this fill-in-the-blank task is well-correlated with human judgements of whether a question is reasonable, and that these models can be trained to achieve nearly human-level performance in completing comparative questions in three different subdomains. However, analysis shows that what they learn fails to model any sort of broad notion of which entities are semantically comparable or similar---instead the trained models are very domain-specific, and performance is highly correlated with co-occurrences between specific entities observed in the training set.  This is true both for models that are pretrained on general text corpora, as well as models trained on a large corpus of comparison questions. Our study thus reinforces recent results on the difficulty of making claims about a deep model's world knowledge or linguistic competence based on performance on specific benchmark problems. We make our evaluation datasets publicly available to foster future research on complex understanding and reasoning in such models at standards of human interaction.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "\u202aAvishai Zagoury\u202c\u200f; Einat Minkov; Idan Szpektor; William W. Cohen",
        "authorids": "",
        "aff": "Bar-Ilan University; University of Haifa; Google Research; Google Research",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17681/17681-13-21175-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14292-what-s-the-best-place-for-an-ai-conference-vancouver-or-_______-why-completing-comparative-questions-is-difficult/",
        "doi": "10.1609/aaai.v35i16.17681",
        "pdf_size": 167193
    },
    {
        "id": "00090",
        "title": "When Hashing Met Matching: Efficient Spatio-Temporal Search for Ridesharing",
        "track": "main",
        "status": "Poster",
        "abstract": "Shared on-demand mobility holds immense potential for urban transportation. However, finding ride matches in real-time at urban scale is a very difficult combinatorial optimization problem and mostly heuristic approaches are applied. In this work, we introduce a principled approach to this combinatorial problem. Our approach proceeds by constructing suitable representations for rides and driver routes capturing their essential spatio-temporal aspects in an appropriate vector space, and defining a similarity metric in this space that expresses matching utility. This then lets us mathematically model the problem of finding ride matches as that of Near Neighbor Search (NNS). Exploiting this modeling, we devise a novel spatio-temporal search algorithm for finding ride matches based on the theory of Locality Sensitive Hashing (LSH). Apart from being highly efficient, our algorithm enjoys several practically useful properties and extension possibilities. Experiments with large real-world datasets show that our algorithm consistently outperforms state-of-the-art heuristic methods thereby proving its practical applicability.",
        "primary_area": "Application Domains",
        "author": "Chinmoy Dutta",
        "authorids": "",
        "aff": "Turing Research Inc.",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16081/16081-13-19575-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00090-when-hashing-met-matching-efficient-spatio-temporal-search-for-ridesharing/",
        "doi": "10.1609/aaai.v35i1.16081",
        "pdf_size": 276759
    },
    {
        "id": "00232",
        "title": "Who You Would Like to Share With? A Study of Share Recommendation in Social E-commerce",
        "track": "main",
        "status": "Poster",
        "abstract": "The prosperous development of social e-commerce has spawned diverse recommendation demands, and accompanied a new recommendation paradigm, share recommendation. Signi\ufb01cantly different from traditional binary recommendations (e.g., item recommendation and friend recommendation), share recommendation models ternary interactions among \u3008 User, Item, Friend \u3009 , which aims to recommend a most likely friend to a user who would like to share a speci\ufb01c item, progressively becoming an indispensable service in social e-commerce. Seamlessly integrating the social relations and purchase behaviours, share recommendation improves user stickiness and monetizes the user in\ufb02uence, meanwhile encountering three unique challenges: rich heterogeneous information, complex ternary interaction, and asymmetric share action. In this paper, we \ufb01rst study the share recommendation problem and propose a heterogeneous graph neural network based share recommendation model, called HGSRec. Speci\ufb01cally, HGSRec delicately designs a tripartite heterogeneous GNNs to describe the multifold characteristics of users and items, and then dynamically fuses them via capturing potential ternary dependency with a dual co-attention mechanism, followed by a transitive triplet representation to depict the asymmetry of share action and predict whether share action happens. Of\ufb02ine experiments demonstrate the superiority of the proposed HGSRec with signi\ufb01cant improvements (11.7%-14.5%) over the state-of-the-arts, and online A/B testing on Taobao platform further demonstrates the high industrial practicability and stability of HGSRec.",
        "primary_area": "Application Domains",
        "author": "Houye Ji; Junxiong Zhu; Xiao Wang; Chuan Shi; Bai Wang; Xiaoye Tan; Yanghua Li; Shaojian He",
        "authorids": "",
        "aff": "Beijing University of Posts and Telecommunications; Alibaba Group; Beijing University of Posts and Telecommunications; Beijing University of Posts and Telecommunications; Beijing University of Posts and Telecommunications; Alibaba Group; Alibaba Group; Alibaba Group",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16097/16097-13-19591-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00232-who-you-would-like-to-share-with-a-study-of-share-recommendation-in-social-e-commerce/",
        "doi": "10.1609/aaai.v35i1.16097",
        "pdf_size": 5906059
    },
    {
        "id": "09436",
        "title": "Why Adversarial Interaction Creates Non-Homogeneous Patterns: A Pseudo-Reaction-Diffusion Model for Turing Instability",
        "track": "main",
        "status": "Poster",
        "abstract": "Long after Turing's seminal Reaction-Diffusion (RD) model, the elegance of his fundamental equations alleviated much of the skepticism surrounding pattern formation. Though Turing model is a simplification and an idealization, it is one of the best-known theoretical models to explain patterns as a reminiscent of those observed in nature. Over the years, concerted efforts have been made to align theoretical models to explain patterns in real systems. The apparent difficulty in identifying the specific dynamics of the RD system makes the problem particularly challenging. Interestingly, we observe Turing-like patterns in a system of neurons with adversarial interaction. In this study, we establish the involvement of Turing instability to create such patterns. By theoretical and empirical studies, we present a textit{pseudo-reaction-diffusion} model to explain the mechanism that may underlie these phenomena. While supervised learning attains homogeneous equilibrium, this paper suggests that the introduction of an adversary helps break this homogeneity to create non-homogeneous patterns at equilibrium. Further, we prove that randomly initialized gradient descent with over-parameterization can converge exponentially fast to an $epsilon$-stationary point even under adversarial interaction. In addition, different from sole supervision, we show that the solutions obtained under adversarial interaction are not limited to a tiny subspace around initialization.",
        "primary_area": "Machine Learning IV",
        "author": "Litu Rout",
        "authorids": "",
        "aff": "Indian Space Research Organisation",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17137/17137-13-20631-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09436-why-adversarial-interaction-creates-non-homogeneous-patterns-a-pseudo-reaction-diffusion-model-for-turing-instability/",
        "doi": "10.1609/aaai.v35i11.17137",
        "pdf_size": 194621
    },
    {
        "id": "04590",
        "title": "Why Do Attributes Propagate in Graph Convolutional Neural Networks?",
        "track": "main",
        "status": "Poster",
        "abstract": "Many efforts have been paid to enhance Graph Convolutional Network from the perspective of propagation under the philosophy that ``Propagation is the essence of the GCNNs\". Unfortunately, its adverse effect is over-smoothing, which makes the performance dramatically drop. To prevent the over-smoothing, many variants are presented. However, the perspective of propagation can't provide an intuitive and unified interpretation to their effect on prevent over-smoothing. In this paper, we aim at providing a novel explanation to the question of  \"Why do attributes propagate in GCNNs?''. which not only gives the essence of the oversmoothing, but also illustrates why the GCN extensions, including multi-scale GCN and GCN with initial residual, can improve the performance. To this end, an intuitive Graph Representation Learning (GRL) framework is presented. GRL simply constrains the node representation similar with the original attribute, and encourages the connected nodes possess similar representations (pairwise constraint).  Based on the proposed GRL, exiting GCN and its extensions can be proved as different numerical optimization algorithms, such as gradient descent, of our proposed  GRL framework.  Inspired by the superiority of conjugate gradient descent compared to common gradient descent, a novel Graph Conjugate Convolutional (GCC) network is presented to approximate the solution to GRL with fast convergence. Specifically, GCC adopts the obtained information of the last layer, which can be represented as the difference between the input and output of the last layer, as the input to the next layer. Extensive experiments demonstrate the superior performance of GCC.",
        "primary_area": "Data Mining and Knowledge Management",
        "author": "Liang Yang; Chuan Wang; Junhua Gu; Xiaochun Cao; Bingxin Niu",
        "authorids": "",
        "aff": "Hebei University of Technology State Key Laboratory of Information Security, Institute of Information Engineering, CAS Hebei Province Key Laboratory of Big Data Calculation; State Key Laboratory of Information Security, Institute of Information Engineering, CAS; Hebei University of Technology Hebei Province Key Laboratory of Big Data Calculation; State Key Laboratory of Information Security, Institute of Information Engineering, CAS; Hebei University of Technology Hebei Province Key Laboratory of Big Data Calculation",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16588/16588-13-20082-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/04590-why-do-attributes-propagate-in-graph-convolutional-neural-networks/",
        "doi": "10.1609/aaai.v35i5.16588",
        "pdf_size": 159554
    },
    {
        "id": "00724",
        "title": "Window Loss for Bone Fracture Detection and Localization in X-ray Images with Point-based Annotation",
        "track": "main",
        "status": "Poster",
        "abstract": "",
        "primary_area": "Application Domains",
        "author": "Xinyu Zhang; Yirui Wang; Chi-Tung Cheng; Le Lu; Adam P. Harrison; Jing Xiao; Chien-Hung Liao; Shun Miao",
        "authorids": "",
        "aff": "",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16153/16153-13-19647-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00724-window-loss-for-bone-fracture-detection-and-localization-in-x-ray-images-with-point-based-annotation/",
        "doi": "",
        "pdf_size": 1345682
    },
    {
        "id": "08038",
        "title": "Winning Lottery Tickets in Deep Generative Models",
        "track": "main",
        "status": "Poster",
        "abstract": "The lottery ticket hypothesis suggests that sparse, sub-networks of a given neural network, if initialized properly, can be trained to reach comparable or even better performance to that of the original network. Prior works in lottery tickets have primarily focused on the supervised learning setup, with several papers proposing effective ways of finding winning tickets in classification problems. In this paper, we confirm the existence of winning tickets in deep generative models such as GANs and VAEs. We show that the popular iterative magnitude pruning approach (with late resetting) can be used with generative losses to find the winning tickets. This approach effectively yields tickets with sparsity up to 99% for AutoEncoders, 93% for VAEs and 89% for GANs on CIFAR and Celeb-A datasets. We also demonstrate the transferability of winning tickets across different generative models (GANs and VAEs) sharing the same architecture, suggesting that winning tickets have inductive biases that could help train a wide range of deep generative models. Furthermore, we show the practical benefits of lottery tickets in generative models by detecting tickets at very early stages in training called early-bird tickets. Through early-bird tickets, we can achieve up to 88% reduction in floating-point operations (FLOPs) and 54% reduction in training time, making it possible to train large-scale generative models over tight resource constraints. These results out-perform existing early pruning methods like SNIP (Lee, Ajanthan, and Torr 2019) and GraSP(Wang, Zhang, and Grosse 2020). Our findings shed light towards existence of proper network initializations that could improve convergence and stability of generative models.",
        "primary_area": "Machine Learning II",
        "author": "Neha Mukund Kalibhat; Yogesh Balaji; Soheil Feizi",
        "authorids": "",
        "aff": "University of Maryland - College Park; University of Maryland - College Park; University of Maryland - College Park",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16980/16980-13-20474-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/08038-winning-lottery-tickets-in-deep-generative-models/",
        "doi": "10.1609/aaai.v35i9.16980",
        "pdf_size": 3149823
    },
    {
        "id": "01911",
        "title": "Write-a-speaker: Text-based Emotional and Rhythmic Talking-head Generation",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a novel text-based talking-head video generation framework that synthesizes high-fidelity facial expressions and head motions in accordance with contextual sentiments as well as speech rhythm and pauses. To be specific, our framework consists of a speaker-independent stage and a speaker-specific stage. In the speaker-independent stage, we design three parallel networks to generate animation parameters of the mouth, upper face, and head from texts, separately. In the speaker-specific stage, we present a 3D face model guided attention network to synthesize videos tailored for different individuals. It takes the animation parameters as input and exploits an attention mask to manipulate facial expression changes for the input individuals. Furthermore, to better establish authentic correspondences between visual motions (i.e., facial expression changes and head movements) and audios, we leverage a high-accuracy motion capture dataset instead of relying on long videos of specific individuals. After attaining the visual and audio correspondences, we can effectively train our network in an end-to-end fashion. Extensive experiments on qualitative and quantitative results demonstrate that our algorithm achieves high-quality photo-realistic talking-head videos including various facial expressions and head motions according to speech rhythms and outperforms the state-of-the-art.",
        "primary_area": "Computer Vision II",
        "author": "Lincheng Li; Suzhen Wang; Zhimeng Zhang; Yu Ding; Yixing Zheng; Xin Yu; Changjie Fan",
        "authorids": "",
        "aff": "Netease Fuxi AI Lab; Netease Fuxi AI Lab; Netease Fuxi AI Lab; Netease Fuxi AI Lab; Netease Fuxi AI Lab; University of Technology Sydney; Netease Fuxi AI Lab",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16286/16286-13-19780-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/01911-write-a-speaker-text-based-emotional-and-rhythmic-talking-head-generation/",
        "doi": "10.1609/aaai.v35i3.16286",
        "pdf_size": 1584115
    },
    {
        "id": "14383",
        "title": "Writing Polishment with Simile: Task, Dataset and A Neural Approach",
        "track": "main",
        "status": "Poster",
        "abstract": "A simile is a figure of speech that directly makes a comparison, showing similarities between two different things, e.g. ``Reading papers can be dull sometimes,like watching grass grow\". Human writers often interpolate appropriate similes into proper locations of the plain text to vivify their writings. However, none of existing work has explored neural simile interpolation, including both locating and generation. In this paper, we propose a new task of Writing Polishment with Simile (WPS) to investigate whether machines are able to polish texts with similes as we human do. Accordingly, we design a two-staged Locate&Gen model based on transformer architecture. Our model firstly locates where the simile interpolation should happen, and then generates a location-specific simile. We also release a large-scale Chinese Simile (CS) dataset containing 5 million similes with context. The experimental results demonstrate the feasibility of WPS task and shed light on the future research directions towards better automatic text polishment.",
        "primary_area": "Speech and Natural Language Processing III",
        "author": "Jiayi Zhang; Zhi Cui; Xiaoqiang Xia; Yalong Guo; Yanran Li; Chen Wei; Jianwei Cui",
        "authorids": "",
        "aff": "Xiaomi AI Lab; Xiaomi AI Lab; Xiaomi AI Lab; Xiaomi AI Lab; Xiaomi AI Lab; Xiaomi AI Lab; Xiaomi AI Lab",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17691/17691-13-21185-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/14383-writing-polishment-with-simile-task-dataset-and-a-neural-approach/",
        "doi": "10.1609/aaai.v35i16.17691",
        "pdf_size": 437316
    },
    {
        "id": "13648",
        "title": "XL-WSD: An Extra-Large and Cross-Lingual Evaluation Framework for Word Sense Disambiguation",
        "track": "main",
        "status": "Poster",
        "abstract": "Transformer-based architectures brought a breeze of change to Word Sense Disambiguation (WSD), improving models' performances by a large margin. The fast development of new approaches has been further encouraged by a well-framed evaluation suite for English, which has allowed their performances to be kept track of and compared fairly. However, other languages have remained largely unexplored, as testing data are available for a few languages only and the evaluation setting is rather matted. In this paper, we untangle this situation by proposing XL-WSD, a cross-lingual evaluation benchmark for the WSD task featuring sense-annotated development and test sets in 18 languages from six different linguistic families, together with language-specific silver training data. We leverage XL-WSD datasets to conduct an extensive evaluation of neural and knowledge-based approaches, including the most recent multilingual language models.  Results show that the zero-shot knowledge transfer across languages is a promising research direction within the WSD field, especially when considering low-resourced languages where large pre-trained multilingual models still perform poorly.  We make the evaluation suite and the code for performing the experiments available at https://sapienzanlp.github.io/xl-wsd/.",
        "primary_area": "Speech and Natural Language Processing II",
        "author": "Tommaso Pasini; Alessandro Raganato; Roberto Navigli",
        "authorids": "",
        "aff": "Sapienza University of Rome; University of Helsinki; Sapienza University of Rome",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17609/17609-13-21103-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/13648-xl-wsd-an-extra-large-and-cross-lingual-evaluation-framework-for-word-sense-disambiguation/",
        "doi": "10.1609/aaai.v35i15.17609",
        "pdf_size": 294313
    },
    {
        "id": "00436",
        "title": "XraySyn: Realistic View Synthesis From a Single Radiograph Through CT Priors",
        "track": "main",
        "status": "Poster",
        "abstract": "A radiograph visualizes the internal anatomy of a patient through the use of X-ray, which projects 3D information onto a 2D plane. Hence, radiograph analysis naturally requires physicians to relate their prior knowledge about 3D human anatomy to 2D radiographs. Synthesizing novel radiographic views in a small range can assist physicians in interpreting anatomy more reliably; however, radiograph view synthesis is heavily ill-posed, lacking in paired data, and lacking in differentiable operations to leverage learning-based approaches. To address these problems, we use Computed Tomography (CT) for radiograph simulation and design a differentiable projection algorithm, which enables us to achieve geometrically consistent transformations between the radiography and CT domains. Our method, XraySyn, can synthesize novel views on real radiographs through a combination of realistic simulation and finetuning on real radiographs. To the best of our knowledge, this is the first work on radiograph view synthesis. We show that by gaining an understanding of radiography in 3D space, our method can be applied to radiograph bone extraction and suppression without requiring groundtruth bone labels.",
        "primary_area": "Application Domains",
        "author": "Cheng Peng; Haofu Liao; Gina Wong; Jiebo Luo; S. Kevin Zhou; Rama Chellappa",
        "authorids": "",
        "aff": "Johns Hopkins University; University of Rochester; Johns Hopkins University; University of Rochester; Chinese Academy of Sciences; Peng Cheng Laboratory, Shenzhen; Johns Hopkins University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16120/16120-13-19614-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00436-xraysyn-realistic-view-synthesis-from-a-single-radiograph-through-ct-priors/",
        "doi": "10.1609/aaai.v35i1.16120",
        "pdf_size": 2442710
    },
    {
        "id": "00955",
        "title": "YOLObile: Real-Time Object Detection on Mobile Devices via Compression-Compilation Co-Design",
        "track": "main",
        "status": "Poster",
        "abstract": "The rapid development and wide utilization of object detection techniques have aroused attention on both accuracy and speed of object detectors. However, the current state-of-the-art object detection works are either accuracy-oriented using a large model but leading to high latency or speed-oriented using a lightweight model but sacrificing accuracy. In this work, we propose YOLObile framework, a real-time object detection on mobile devices via compression-compilation co-design. A novel block-punched pruning scheme is proposed for any kernel size. To improve computational efficiency on mobile devices, a GPU-CPU collaborative  scheme is adopted along with advanced compiler-assisted optimizations. Experimental results indicate that our pruning scheme achieves 14x compression rate of YOLOv4 with 49.0 mAP. Under our YOLObile framework, we achieve 17 FPS inference speed using GPU on Samsung Galaxy S20. By incorporating our proposed GPU-CPU collaborative scheme, the inference speed is increased to 19.1 FPS, and outperforms the original YOLOv4 by 5x speedup. Source code is at: https://github.com/nightsnack/YOLObile.",
        "primary_area": "Computer Vision I",
        "author": "Yuxuan Cai; Hongjia Li; Geng Yuan; Wei Niu; Yanyu Li; Xulong Tang; Bin Ren; Yanzhi Wang",
        "authorids": "",
        "aff": "Northeastern University; Northeastern University; Northeastern University; College of William and Mary; Northeastern University; University of Pittsburgh; William & Mary; Northeastern University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16179/16179-13-19673-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/00955-yolobile-real-time-object-detection-on-mobile-devices-via-compression-compilation-co-design/",
        "doi": "10.1609/aaai.v35i2.16179",
        "pdf_size": 1825645
    },
    {
        "id": "03500",
        "title": "ePointDA: An End-to-End Simulation-to-Real Domain Adaptation Framework for LiDAR Point Cloud Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "Due to its robust and precise distance measurements, LiDAR plays an important role in scene understanding for autonomous driving. Training deep neural networks (DNNs) on LiDAR data requires large-scale point-wise annotations, which are time-consuming and expensive to obtain. Instead, simulation-to-real domain adaptation (SRDA) trains a DNN using unlimited synthetic data with automatically generated labels and transfers the learned model to real scenarios. Existing SRDA methods for LiDAR point cloud segmentation mainly employ a multi-stage pipeline and focus on feature-level alignment. They require prior knowledge of real-world statistics and ignore the pixel-level dropout noise gap and the spatial feature gap between different domains. In this paper, we propose a novel end-to-end framework, named ePointDA, to address the above issues. Specifically, ePointDA consists of three modules: self-supervised dropout noise rendering, statistics-invariant and spatially-adaptive feature alignment, and transferable segmentation learning. The joint optimization enables ePointDA to bridge the domain shift at the pixel-level by explicitly rendering dropout noise for synthetic LiDAR and at the feature-level by spatially aligning the features between different domains, without requiring the real-world statistics. Extensive experiments adapting from synthetic GTA-LiDAR to real KITTI and SemanticKITTI demonstrate the superiority of ePointDA for LiDAR point cloud segmentation.",
        "primary_area": "Computer Vision III",
        "author": "Sicheng Zhao; Yezhen Wang; Bo Li; Bichen Wu; Yang Gao; Pengfei Xu; Trevor Darrell; Kurt Keutzer",
        "authorids": "",
        "aff": "University of California, Berkeley; Didi Chuxing University of California, San Diego; University of California, Berkeley; Facebook Inc.; Tsinghua University; Didi Chuxing; University of California, Berkeley; University of California, Berkeley",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16464/16464-13-19958-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/03500-epointda-an-end-to-end-simulation-to-real-domain-adaptation-framework-for-lidar-point-cloud-segmentation/",
        "doi": "10.1609/aaai.v35i4.16464",
        "pdf_size": 1962789
    },
    {
        "id": "06609",
        "title": "eTREE: Learning Tree-structured Embeddings",
        "track": "main",
        "status": "Poster",
        "abstract": "Matrix factorization (MF) plays an important role in a wide range of machine learning and data mining models. MF is commonly used to obtain item embeddings and feature representations due to its ability to capture correlations and higher-order statistical dependencies across dimensions. In many applications, the categories of items exhibit a hierarchical tree structure. For instance, human diseases can be divided into coarse categories, e.g., bacterial, and viral. These categories can be further divided into finer categories, e.g., viral infections can be respiratory, gastrointestinal, and exanthematous viral diseases. In e-commerce, products, movies, books, etc., are grouped into hierarchical categories, e.g., clothing items are divided by gender, then by type (formal, casual, etc.). While the tree structure and the categories of the different items may be known in some applications, they have to be learned together with the embeddings in many others. In this work, we propose eTREE, a model that incorporates the (usually ignored) tree structure to enhance the quality of the embeddings. We leverage the special uniqueness properties of Nonnegative MF (NMF) to prove identifiability of eTREE. The proposed model not only exploits the tree structure prior, but also learns the hierarchical clustering in an unsupervised data-driven fashion. We derive an efficient algorithmic solution and a scalable implementation of eTREE that exploits parallel computing, computation caching, and warm start strategies. We showcase the effectiveness of eTREE on real data from various application domains: healthcare, recommender systems, and education. We also demonstrate the meaningfulness of the tree obtained from eTREE by means of domain experts interpretation.",
        "primary_area": "Machine Learning I",
        "author": "Faisal M. Almutairi; Yunlong Wang; Dong Wang; Emily Zhao; Nicholas D. Sidiropoulos",
        "authorids": "",
        "aff": "University of Minnesota IQVIA; IQVIA; IQVIA; IQVIA; University of Virginia",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/16818/16818-13-20312-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/06609-etree-learning-tree-structured-embeddings/",
        "doi": "10.1609/aaai.v35i8.16818",
        "pdf_size": 744381
    },
    {
        "id": "12241",
        "title": "f-Aware Conflict Prioritization & Improved Heuristics For Conflict-Based Search",
        "track": "main",
        "status": "Poster",
        "abstract": "Conflict-Based Search (CBS) is a leading two-level algorithm for optimal  Multi-Agent  Path  Finding  (MAPF).  The main step of CBS is to expand nodes by resolving conflicts (where two agents collide). Choosing the \u2018right\u2019 conflict to resolve can greatly speed up the search. CBS first resolves conflicts where the costs  (g-values)  of the resulting child nodes are larger than the cost of the node to be split. However, the recent addition of high-level heuristics to CBS and expanding nodes according to f=g+h reduces the relevance of this conflict prioritization method. Therefore, we introduce an expanded categorization of conflicts, which first resolves conflicts where the f-values of the child nodes are larger than the f-value of the node to be split, and present a method for identifying such conflicts. We also enhance all known heuristics for CBS by using information about the cost of resolving certain conflicts, and with only a small computational overhead.  Finally, we experimentally demonstrate that both the expanded categorization of conflicts and the improved heuristics contribute to making CBS even more efficient.",
        "primary_area": "Search and Optimization",
        "author": "Eli Boyarski; Ariel Felner; Pierre Le Bodic; Daniel D. Harabor; Peter J. Stuckey; Sven Koenig",
        "authorids": "",
        "aff": "Ben-Gurion University of the Negev; Ben-Gurion University of the Negev; Monash University; Monash University; Monash University; University of Southern California",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17453/17453-13-20947-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/12241-f-aware-conflict-prioritization-improved-heuristics-for-conflict-based-search/",
        "doi": "10.1609/aaai.v35i14.17453",
        "pdf_size": 886835
    },
    {
        "id": "11691",
        "title": "i-Algebra: Towards Interactive Interpretability of Deep Neural Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Providing explanations for deep neural networks (DNNs) is essential for their use in domains wherein the interpretability of decisions is a critical prerequisite. Despite the plethora of work on interpreting DNNs, most existing solutions offer interpretability in an ad hoc, one-shot, and static manner, without accounting for the perception, understanding, or response of end-users, resulting in their poor usability in practice.  In this paper, we argue that DNN interpretability should be implemented as the interactions between users and models. We present i-Algebra, a first-of-its-kind interactive framework for interpreting DNNs. At its core is a library of atomic, composable operators, which explain model behaviors at varying input granularity, during different inference stages, and from distinct interpretation perspectives. Leveraging a declarative query language, users are enabled to build various analysis tools (e.g., ``drill-down'', ``comparative'', ``what-if'' analysis) via flexibly composing such operators. We prototype i-Algebra and conduct user studies in a set of representative analysis tasks, including inspecting adversarial inputs, resolving model inconsistency, and cleansing contaminated data, all demonstrating its promising usability.",
        "primary_area": "Philosophy and Ethics of AI",
        "author": "Xinyang Zhang; Ren Pang; Shouling Ji; Fenglong Ma; Ting Wang",
        "authorids": "",
        "aff": "Pennsylvania State University; Pennsylvania State University; Zhejiang University; Pennsylvania State University; Pennsylvania State University",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17390/17390-13-20884-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/11691-i-algebra-towards-interactive-interpretability-of-deep-neural-networks/",
        "doi": "10.1609/aaai.v35i13.17390",
        "pdf_size": 6446801
    },
    {
        "id": "09739",
        "title": "\u2018Less Than One\u2019-Shot Learning: Learning N Classes From M < N Samples",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep neural networks require large training sets but suffer from high computational cost and long training times. Training on much smaller training sets while maintaining nearly the same accuracy would be very beneficial. In the few-shot learning setting, a model must learn a new class given only a small number of samples from that class. One-shot learning is an extreme form of few-shot learning where the model must learn a new class from a single example. We propose the 'less than one'-shot learning task where models must learn N new classes given only M",
        "primary_area": "Machine Learning IV",
        "author": "Ilia Sucholutsky,Matthias Schonlau",
        "authorids": "",
        "aff": "University of Waterloo,University of Waterloo",
        "bibtex": "",
        "pdf": "https://cdn.aaai.org/ojs/17171/17171-13-20665-1-2-20210518.pdf",
        "site": "https://aaai.org/papers/09739-less-than-one-shot-learning-learning-n-classes-from-m-n-samples/",
        "doi": "10.1609/aaai.v35i11.17171",
        "pdf_size": 9598494
    }
]