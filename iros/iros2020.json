[
    {
        "id": "9340981",
        "title": "360\u00b0 Depth Estimation from Multiple Fisheye Images with Origami Crown Representation of Icosahedron",
        "track": "main",
        "status": "Poster",
        "abstract": "In this study, we present a method for all-around depth estimation from multiple omnidirectional images for indoor environments. In particular, we focus on plane-sweeping stereo as the method for depth estimation from the images. We propose a new icosahedron-based representation and ConvNets for omnidirectional images, which we name \"CrownConv\" because the representation resembles a crown made of origami. CrownConv can be applied to both fisheye images and equirect- angular images to extract features. Furthermore, we propose icosahedron-based spherical sweeping for generating the cost volume on an icosahedron from the extracted features. The cost volume is regularized using the three-dimensional CrownConv, and the final depth is obtained by depth regression from the cost volume. Our proposed method is robust to camera alignments by using the extrinsic camera parameters; therefore, it can achieve precise depth estimation even when the camera alignment differs from that in the training dataset. We evaluate the proposed model on synthetic datasets and demonstrate its effectiveness. As our proposed method is computationally efficient, the depth is estimated from four fisheye images in less than a second using a laptop with a GPU. Therefore, it is suitable for real-world robotics applications. Our source code is available at https://github.com/matsuren/crownconv360depth.",
        "primary_area": "",
        "author": "Ren Komatsu;Hiromitsu Fujii;Yusuke Tamura;Atsushi Yamashita;Hajime Asama;Ren Komatsu;Hiromitsu Fujii;Yusuke Tamura;Atsushi Yamashita;Hajime Asama",
        "authorids": "/37086092306;/37557309500;/37276670000;/37270922900;/37294904700;/37086092306;/37557309500;/37276670000;/37270922900;/37294904700",
        "aff": "Department of Precision Engineering, Graduate School of Engineering, The University of Tokyo, Tokyo, Japan; Department of Advanced Robotics, Faculty of Advanced Engineering, Chiba Institute of Technology, Narashino, Japan; Department of Robotics, Division of Mechanical Engineering, Tohoku University, Sendai, Japan; Department of Precision Engineering, Graduate School of Engineering, The University of Tokyo, Tokyo, Japan; Department of Precision Engineering, Graduate School of Engineering, The University of Tokyo, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340981/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6738162060836043693&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;0;0",
        "aff_unique_norm": "The University of Tokyo;Chiba Institute of Technology;Tohoku University",
        "aff_unique_dep": "Department of Precision Engineering;Department of Advanced Robotics;Department of Robotics, Division of Mechanical Engineering",
        "aff_unique_url": "https://www.u-tokyo.ac.jp;https://www.chibatech.ac.jp;https://www.tohoku.ac.jp",
        "aff_unique_abbr": "UTokyo;Chiba Tech;Tohoku U",
        "aff_campus_unique_index": "0;1;2;0;0",
        "aff_campus_unique": "Tokyo;Narashino;Sendai",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9341324",
        "title": "3D Coating Self-Assembly for Modular Robotic Scaffolds",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper addresses the self-reconfiguration problem in large-scale modular robots for the purpose of shape formation for object representation. It aims to show that this process can be accelerated without compromising on the visual aspect of the final object, by creating an internal skeleton of the shape using the previously introduced sandboxing and scaffolding techniques, and then coating this skeleton with a layer of modules for higher visual fidelity. We discuss the challenges of the coating problem, introduce a basic method for constructing the coating of a scaffold layer by layer, and show that even with a straightforward algorithm, our scaffolding and coating combo uses much fewer modules than dense shapes and offers attractive reconfiguration times. Finally, we show that it could be a strong alternative to the construction of dense shapes using traditional self-reconfiguration algorithms.",
        "primary_area": "",
        "author": "Pierre Thalamy;Beno\u00eet Piranda;Julien Bourgeois;Pierre Thalamy;Beno\u00eet Piranda;Julien Bourgeois",
        "authorids": "/37087324441;/38340189300;/37545876400;/37087324441;/38340189300;/37545876400",
        "aff": "FEMTO-ST Institute, CNRS, Univ. Bourgogne Franche-Comt\u00e9, Montb\u00e9liard, France; FEMTO-ST Institute, CNRS, Univ. Bourgogne Franche-Comt\u00e9, Montb\u00e9liard, France; FEMTO-ST Institute, CNRS, Univ. Bourgogne Franche-Comt\u00e9, Montb\u00e9liard, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341324/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16012958206051376232&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "FEMTO-ST Institute",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Montb\u00e9liard",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9341755",
        "title": "3D Gaze Estimation for Head-Mounted Devices based on Visual Saliency",
        "track": "main",
        "status": "Poster",
        "abstract": "Compared with the maturity of 2D gaze tracking technology, 3D gaze tracking has gradually become a research hotspot in recent years. The head-mounted gaze tracker has shown great potential for gaze estimation in 3D space due to its appealing flexibility and portability. The general challenge for 3D gaze tracking algorithms is that calibration is necessary before the usage, and calibration targets cannot be easily applied in some situations or might be blocked by moving human and objects. Besides, the accuracy on depth direction has always come to be a crucial problem. Regarding the issues mentioned above, a 3D gaze estimation with auto-calibration method is proposed in this study. We use an RGBD camera as the scene camera to acquire the accurate 3D structure of the environment. The automatic calibration is achieved by uniting gaze vectors with saliency maps of the scene which aligned depth information. Finally, we determine the 3D gaze point through a point cloud generated from the RGBD camera. The experiment result demonstrates that our proposed method achieves 4.34\u00b0 of average angle error in the field from 0.5m to 3m and the average depth error is 23.22mm, which is sufficient for 3D gaze estimation in the real scene.",
        "primary_area": "",
        "author": "Meng Liu;You Fu Li;Hai Liu;Meng Liu;You Fu Li;Hai Liu",
        "authorids": "/37088418231;/37088687049;/37085682440;/37088418231;/37088687049;/37085682440",
        "aff": "Department of Mechanical Engineering, City University of Hong Kong, Kowloon, Hong Kong; Department of Mechanical Engineering, City University of Hong Kong, Kowloon, Hong Kong; National Engineering Research Center for E-Learning, Central China Normal University, Wuhan, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341755/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6054050423178958740&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "City University of Hong Kong;Central China Normal University",
        "aff_unique_dep": "Department of Mechanical Engineering;National Engineering Research Center for E-Learning",
        "aff_unique_url": "https://www.cityu.edu.hk;http://www.ccnu.edu.cn",
        "aff_unique_abbr": "CityU;CCNU",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Hong Kong SAR;Wuhan",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9341098",
        "title": "3D Localization of a Sound Source Using Mobile Microphone Arrays Referenced by SLAM",
        "track": "main",
        "status": "Poster",
        "abstract": "A microphone array can provide a mobile robot with the capability of localizing, tracking and separating distant sound sources in 2D, i.e., estimating their relative elevation and azimuth. To combine acoustic data with visual information in real world settings, spatial correlation must be established. The approach explored in this paper consists of having two robots, each equipped with a microphone array, localizing themselves in a shared reference map using SLAM. Based on their locations, data from the microphone arrays are used to triangulate in 3D the location of a sound source in relation to the same map. This strategy results in a novel cooperative sound mapping approach using mobile microphone arrays. Trials are conducted using two mobile robots localizing a static or a moving sound source to examine in which conditions this is possible. Results suggest that errors under 0.3 m are observed when the relative angle between the two robots are above 30\u00b0 for a static sound source, while errors under 0.3 m for angles between 40\u00b0 and 140\u00b0 are observed with a moving sound source.",
        "primary_area": "",
        "author": "Simon Michaud;Samuel Faucher;Fran\u00e7ois Grondin;Jean-Samuel Lauzon;Mathieu Labb\u00e9;Dominic L\u00e9tourneau;Fran\u00e7ois Ferland;Fran\u00e7ois Michaud;Simon Michaud;Samuel Faucher;Fran\u00e7ois Grondin;Jean-Samuel Lauzon;Mathieu Labb\u00e9;Dominic L\u00e9tourneau;Fran\u00e7ois Ferland;Fran\u00e7ois Michaud",
        "authorids": "/37088690086;/37088688182;/38243208000;/37086282716;/38236835000;/37293868700;/37601315800;/37284461800;/37088690086;/37088688182;/38243208000;/37086282716;/38236835000;/37293868700;/37601315800;/37284461800",
        "aff": "Department of Electrical Engineering and Computer Engineering, Interdisciplinary Institute for Technological Innovation (3IT), 3000 boul. de l\u2019Universit\u00e9, Universit\u00e9 de Sherbrooke, Qu\u00e9bec, Canada; Department of Electrical Engineering and Computer Engineering, Interdisciplinary Institute for Technological Innovation (3IT), 3000 boul. de l\u2019Universit\u00e9, Universit\u00e9 de Sherbrooke, Qu\u00e9bec, Canada; Department of Electrical Engineering and Computer Engineering, Interdisciplinary Institute for Technological Innovation (3IT), 3000 boul. de l\u2019Universit\u00e9, Universit\u00e9 de Sherbrooke, Qu\u00e9bec, Canada; Department of Electrical Engineering and Computer Engineering, Interdisciplinary Institute for Technological Innovation (3IT), 3000 boul. de l\u2019Universit\u00e9, Universit\u00e9 de Sherbrooke, Qu\u00e9bec, Canada; Department of Electrical Engineering and Computer Engineering, Interdisciplinary Institute for Technological Innovation (3IT), 3000 boul. de l\u2019Universit\u00e9, Universit\u00e9 de Sherbrooke, Qu\u00e9bec, Canada; Department of Electrical Engineering and Computer Engineering, Interdisciplinary Institute for Technological Innovation (3IT), 3000 boul. de l\u2019Universit\u00e9, Universit\u00e9 de Sherbrooke, Qu\u00e9bec, Canada; Department of Electrical Engineering and Computer Engineering, Interdisciplinary Institute for Technological Innovation (3IT), 3000 boul. de l\u2019Universit\u00e9, Universit\u00e9 de Sherbrooke, Qu\u00e9bec, Canada; Department of Electrical Engineering and Computer Engineering, Interdisciplinary Institute for Technological Innovation (3IT), 3000 boul. de l\u2019Universit\u00e9, Universit\u00e9 de Sherbrooke, Qu\u00e9bec, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341098/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14665031263860999532&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Universit\u00e9 de Sherbrooke",
        "aff_unique_dep": "Department of Electrical Engineering and Computer Engineering",
        "aff_unique_url": "https://www.usherbrooke.ca",
        "aff_unique_abbr": "UdeS",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Sherbrooke",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9341164",
        "title": "3D Multi-Object Tracking: A Baseline and New Evaluation Metrics",
        "track": "main",
        "status": "Poster",
        "abstract": "3D multi-object tracking (MOT) is an essential component for many applications such as autonomous driving and assistive robotics. Recent work on 3D MOT focuses on developing accurate systems giving less attention to practical considerations such as computational cost and system complexity. In contrast, this work proposes a simple real-time 3D MOT system. Our system first obtains 3D detections from a LiDAR point cloud. Then, a straightforward combination of a 3D Kalman filter and the Hungarian algorithm is used for state estimation and data association. Additionally, 3D MOT datasets such as KITTI evaluate MOT methods in the 2D space and standardized 3D MOT evaluation tools are missing for a fair comparison of 3D MOT methods. Therefore, we propose a new 3D MOT evaluation tool along with three new metrics to comprehensively evaluate 3D MOT methods. We show that, although our system employs a combination of classical MOT modules, we achieve state-of-the-art 3D MOT performance on two 3D MOT benchmarks (KITTI and nuScenes). Surprisingly, although our system does not use any 2D data as inputs, we achieve competitive performance on the KITTI 2D MOT leaderboard. Our proposed system runs at a rate of 207.4 FPS on the KITTI dataset, achieving the fastest speed among all modern MOT systems. To encourage standardized 3D MOT evaluation, our code is publicly available at http://www.xinshuoweng.com/projects/AB3DMOT.",
        "primary_area": "",
        "author": "Xinshuo Weng;Jianren Wang;David Held;Kris Kitani;Xinshuo Weng;Jianren Wang;David Held;Kris Kitani",
        "authorids": "/37086376142;/37087079357;/37408101800;/37294510900;/37086376142;/37087079357;/37408101800;/37294510900",
        "aff": "Robotics Institute, Carnegie Mellon University, USA; Robotics Institute, Carnegie Mellon University, USA; Robotics Institute, Carnegie Mellon University, USA; Robotics Institute, Carnegie Mellon University, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341164/",
        "gs_citation": 543,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14021175366788297893&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341501",
        "title": "3D Odor Source Localization using a Micro Aerial Vehicle: System Design and Performance Evaluation",
        "track": "main",
        "status": "Poster",
        "abstract": "Finding chemical compounds in the air has applications when situations such as gas leaks, environmental emergencies and toxic chemical dispersion occur. Enabling robots to undertake this task would provide a powerful tool to prevent dangerous situations and assist humans when emergencies arise. While the dispersion of chemical compounds in the air is intrinsically a three-dimensional (3D) phenomenon, the scientific community tackled primarily two-dimensional (2D) scenarios so far. This is mainly due to the challenges of developing a platform able to successfully provide chemical compounds samples of a 3D space. In this paper, a 3D bioinspired algorithm for odor source localization, previously validated in a controlled physical environment leveraging a robotic manipulator, is adapted for deployment on a micro aerial vehicle equipped with an odor sensor. Given the effect that the propellers have on a gas distribution, the algorithmic adaptation focused on enhancing the sensing strategy of the platform. Additionally, two sensor placement configurations are assessed to determine which one yields best sensing results. A performance evaluation in different environmental scenarios is carried out to test the robustness of the implementation. Two different localization systems are used for the performance evaluation experiments to quantify the impact of localization accuracy on the algorithm's outcome.",
        "primary_area": "",
        "author": "Chiara Ercolani;Alcherio Martinoli;Chiara Ercolani;Alcherio Martinoli",
        "authorids": "/37086574560;/37325252600;/37086574560;/37325252600",
        "aff": "Distributed Intelligent Systems and Algorithms Laboratory, School of Architecture, Civil and Environmental Engineering, \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), Lausanne, Switzerland; Distributed Intelligent Systems and Algorithms Laboratory, School of Architecture, Civil and Environmental Engineering, \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), Lausanne, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341501/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=870589659987065946&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "\u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL)",
        "aff_unique_dep": "School of Architecture, Civil and Environmental Engineering",
        "aff_unique_url": "https://www.epfl.ch",
        "aff_unique_abbr": "EPFL",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Lausanne",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9340711",
        "title": "3D Printed Bio-Inspired Hair Sensor for Directional Airflow Sensing",
        "track": "main",
        "status": "Poster",
        "abstract": "With reduction in the scale of unmanned air vehicles, there is an increasing need for lightweight, compact, low-power sensors and alternate sensing modalities to facilitate flight control and navigation. This paper presents a novel method to fabricate a micro-scale artificial hair sensor that is capable of directional airflow sensing. The sensor consists of a high-aspect ratio hair structure attached to a thin flexible membrane. When subjected to airflow, the hair deflection induces a deformation of the membrane. Two pairs of perpendicular electrodes are attached to the membrane, which allow the sensing of airflow amplitude and direction through the measurement of differential capacitance. The sensor structure is fabricated by using two photon polymerization, which is integrated onto a miniature PCB circuit board to allow simple measurement. The sensor's responses to static displacement loading from different directions were characterized, and are in good agreement with the simulation results. Finally, the sensor's capability for directional airflow measurement was demonstrated with a clear correlation between flow speed and sensor output.",
        "primary_area": "",
        "author": "Keshav Rajasekaran;Hyung Dae Bae;Sarah Bergbreiter;Miao Yu;Keshav Rajasekaran;Hyung Dae Bae;Sarah Bergbreiter;Miao Yu",
        "authorids": "/37086029838;/38237628200;/37542605000;/37712030100;/37086029838;/38237628200;/37542605000;/37712030100",
        "aff": "Department of Mechanical Engineering, University of Maryland, MD, USA; Department of Mechanical Engineering, Howard University, Washington, DC, USA; Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Mechanical Engineering, University of Maryland, MD, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340711/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7318491479564358013&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "University of Maryland;Howard University;Carnegie Mellon University",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Mechanical Engineering;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.umd.edu;https://www.howard.edu;https://www.cmu.edu",
        "aff_unique_abbr": "UMD;HU;CMU",
        "aff_campus_unique_index": "0;1;2;0",
        "aff_campus_unique": "College Park;Washington, DC;Pittsburgh",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341671",
        "title": "3DMotion-Net: Learning Continuous Flow Function for 3D Motion Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper deals with predicting future 3D motions of 3D object scans from the previous two consecutive frames. Previous methods mostly focus on sparse motion prediction in the form of skeletons. While in this paper, we focus on predicting dense 3D motions in the form of 3D point clouds. To approach this problem, we propose a self-supervised approach that leverages the power of the deep neural network to learn a continuous flow function of 3D point clouds that can predict temporally consistent future motions and naturally bring out the correspondences among consecutive point clouds at the same time. More specifically, in our approach, to eliminate the unsolved and challenging process of defining a discrete point convolution on 3D point cloud sequences to encode spatial and temporal information, we introduce a learnable latent code to represent the temporal-aware shape descriptor, which is optimized during the model training. Moreover, a temporally consistent motion Morpher is proposed to learn a continuous flow field which deforms a 3D scan from the current frame to the next frame. We perform extensive experiments on D-FAUST, SCAPE, and TOSCA benchmark data sets. The results demonstrate that our approach is capable of handling temporally inconsistent input and produces consistent future 3D motion while requiring no ground truth supervision.",
        "primary_area": "",
        "author": "Shuaihang Yuan;Xiang Li;Anthony Tzes;Yi Fang;Shuaihang Yuan;Xiang Li;Anthony Tzes;Yi Fang",
        "authorids": "/37087324510;/37086429048;/37283528800;/37085619965;/37087324510;/37086429048;/37283528800;/37085619965",
        "aff": "New York University, USA; New York University, USA; New York University, USA; New York University, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341671/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12050501174136626557&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "New York University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.nyu.edu",
        "aff_unique_abbr": "NYU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340982",
        "title": "50 Benchmarks for Anthropomorphic Hand Function-based Dexterity Classification and Kinematics-based Hand Design",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic hands with anthropomorphism considerations are of prominent popularity in human-centered environment. Existing anthropomorphic robotic hands achieving part or most of human hand comparable dexterity have been applied as various robotic end-effectors and prosthetics. However, two deficiencies are evident that the design for a dexterous anthropomorphic hand is largely based on the intuition of designers and the dexterity of robotic hand is hard to evaluate. To tackle these two challenges, this paper summarizes 50 hand dexterity benchmarks (HD-marks) to evaluate hand dexterity comprehensively from three perspectives. Secondly, a novel 22-DOFs soft robotic hand (S-22) replicates human hand kinematics is used to demonstrate all the 50 HD-marks. Thirdly, 7 critical joint-based kinematic motions (K-motions) and their correlation with the 50 HD-marks are established. Therefore, a clear robotic hand design guideline is built by mapping the hand functional dexterity to the required joint kinematics.",
        "primary_area": "",
        "author": "Jianshu Zhou;Yonghua Chen;Dickson Chun Fung Li;Yuan Gao;Yunquan Li;Shing Shin Cheng;Fei Chen;Yunhui Liu;Jianshu Zhou;Yonghua Chen;Dickson Chun Fung Li;Yuan Gao;Yunquan Li;Shing Shin Cheng;Fei Chen;Yunhui Liu",
        "authorids": "/37086011742;/37293325200;/37086935346;/37086454541;/37085688324;/37085474625;/37085388569;/37279412600;/37086011742;/37293325200;/37086935346;/37086454541;/37085688324;/37085474625;/37085388569;/37279412600",
        "aff": "Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong; Department of Mechanical Engineering, the University of Hong Kong, Pokfulam, Hong Kong SAR, China; Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong; Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong; Department of Mechanical Engineering, the University of Hong Kong, Pokfulam, Hong Kong SAR, China; Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong; Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong; Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340982/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16412678708200463550&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;0;0;1;0;0;0",
        "aff_unique_norm": "The Chinese University of Hong Kong;the University of Hong Kong",
        "aff_unique_dep": "Department of Mechanical and Automation Engineering;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.cuhk.edu.hk;https://www.hku.hk",
        "aff_unique_abbr": "CUHK;HKU",
        "aff_campus_unique_index": "0;1;0;0;1;0;0;0",
        "aff_campus_unique": "Hong Kong SAR;Pokfulam",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9341189",
        "title": "6D Pose Estimation for Flexible Production with Small Lot Sizes based on CAD Models using Gaussian Process Implicit Surfaces",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a surface-to-surface (S2S) point registration algorithm by exploiting the Gaussian Process Implicit Surfaces for partially overlapping 3D surfaces to estimate the 6D pose transformation. Unlike traditional approaches, that separate the corresponding search and update steps in the inner loop, we formulate the point registration as a nonlinear non-constraints optimization problem which does not explicitly use any corresponding points between two point sets. According to the implicit function theorem, we form one point set as a Gaussian Process Implicit Surfaces utilizing the signed distance function, which implicitly creates three manifolds. Points on the same manifold share the same function value, indicated as {1, 0, -1}. The problem is thus converted into finding a rigid transformation that minimizes the inherent function value. This can be solved by using a Gauss-Newton (GN) or Levenberg-Marquardt (LM) solver. In the case of a partially overlapping 3D surface, the Fast Point Feature Histogram (FPFH) algorithm is applied to both point sets and a Principal Component Analysis (PCA) is performed on the result. Based on this, the initial transformation can then be computed. We conduct experiments on multiple point sets to evaluate the effectiveness of our proposed approach against existing state-of-the-art methods.",
        "primary_area": "",
        "author": "Jianjie Lin;Markus Rickert;Alois Knoll;Jianjie Lin;Markus Rickert;Alois Knoll",
        "authorids": "/37088691130;/37681876600;/37276234100;/37088691130;/37681876600;/37276234100",
        "aff": "fortiss, An-Institut Technische Universit\u00e4t M\u00fcnchen, Munich, Germany; fortiss, An-Institut Technische Universit\u00e4t M\u00fcnchen, Munich, Germany; Department of Informatics, Robotics and Embedded System, Technische Universit\u00e4t M\u00fcnchen, Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341189/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1164112143798243631&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Technische Universit\u00e4t M\u00fcnchen",
        "aff_unique_dep": "fortiss, An-Institut",
        "aff_unique_url": "https://www.tum.de",
        "aff_unique_abbr": "TUM",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Munich",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9341747",
        "title": "A Bayesian approach for gas source localization in large indoor environments",
        "track": "main",
        "status": "Poster",
        "abstract": "The main contribution of this paper is a probabilistic estimator that assists a mobile robot to locate a gas source in an indoor environment. The scenario is that a robot equipped with a gas sensor enters a building after the gas is released due to a leak or explosion. The problem is discretized by dividing the environment into a set of regions and time into a set of time intervals. Likelihood functions describing the probability of obtaining a certain gas concentration measurement at a given location at a given time interval are assembled using data generated with GADEN, a three-dimensional gas dispersion simulator([1]). Given a measurement of the gas concentration is available, Bayes's rule is used to compute the joint probability density describing the location of the gas source and the time at which it started spreading. To illustrate the estimation process, a relatively simple motion planner that directs the robot towards the most likely gas source location using a cost function based on the marginal probability of the gas source location is used. The motion plan is periodically revised to reflect the latest posterior probability density. Simulation experiments in a large air-conditioned building with turbulence and wind are presented to demonstrate the effectiveness of the proposed technique.",
        "primary_area": "",
        "author": "Yaqub Aris Prabowo;Ravindra Ranasinghe;Gamini Dissanayake;Bambang Riyanto;Brian Yuliarto;Yaqub Aris Prabowo;Ravindra Ranasinghe;Gamini Dissanayake;Bambang Riyanto;Brian Yuliarto",
        "authorids": "/37085709658;/37885774100;/37279864800;/38483538300;/37399828300;/37085709658;/37885774100;/37279864800;/38483538300;/37399828300",
        "aff": "Institut Teknologi Bandung, Indonesia; University of Technology Sydney, NSW, Australia; University of Technology Sydney, NSW, Australia; Institut Teknologi Bandung, Indonesia; Institut Teknologi Bandung, Indonesia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341747/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16443313656561152956&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;0;0",
        "aff_unique_norm": "Institut Teknologi Bandung;University of Technology Sydney",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.itb.ac.id;https://www.uts.edu.au",
        "aff_unique_abbr": "ITB;UTS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;1;0;0",
        "aff_country_unique": "Indonesia;Australia"
    },
    {
        "id": "9340722",
        "title": "A Bayesian-Based Controller for Snake Robot Locomotion in Unstructured Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel Bayesian-based controller for snake robots in cluttered environment. It extends the conventional shape-based compliant control into statistical field providing an explicit mathematical formulation with Bayesian network. A sequential density propagation rule is derived by introducing several probability densities in a unified framework. Specifically, two input influence densities are proposed to model the cumulative effect of various external forces that the snake robot undergoes. Moreover, the measurement likelihood model is exploited to give a more robust closed-loop feedback. Overall, the proposed approach provides an innovative way to handle challenging tasks of snake robot control in complicated environment. Experimental results have been demonstrated for both simulation and real-world data.",
        "primary_area": "",
        "author": "Yuanyuan Jia;Shugen Ma;Yuanyuan Jia;Shugen Ma",
        "authorids": "/37088689758;/37280187400;/37088689758;/37280187400",
        "aff": "Department of Robotics, Ritsumeikan University, Kusatsu, Japan; Department of Robotics, Ritsumeikan University, Kusatsu, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340722/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14400509785726299102&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Ritsumeikan University",
        "aff_unique_dep": "Department of Robotics",
        "aff_unique_url": "https://www.ritsumei.ac.jp",
        "aff_unique_abbr": "Ritsumeikan",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Kusatsu",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9341268",
        "title": "A Bio-Inspired Framework for Joint Angle Estimation from Non-Collocated Sensors in Tendon-driven Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "",
        "primary_area": "",
        "author": "Daniel A. Hagen;Ali Marjaninejad;Francisco J. Valero-Cuevas;Daniel A. Hagen;Ali Marjaninejad;Francisco J. Valero-Cuevas",
        "authorids": "/37088689968;/37085442633;/38270016900;/37088689968;/37085442633;/38270016900",
        "aff": "",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341268/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18231249821613140528&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6
    },
    {
        "id": "9341310",
        "title": "A Biomimetic Tactile Fingerprint Induces Incipient Slip",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a modified TacTip biomimetic optical tactile sensor design which demonstrates the ability to induce and detect incipient slip, as confirmed by recording the movement of markers on the sensor's external surface. Incipient slip is defined as slippage of part, but not all, of the contact surface between the sensor and object. The addition of ridges - which mimic the friction ridges in the human fingertip - in a concentric ring pattern allowed for localised shear deformation to occur on the sensor surface for a significant duration prior to the onset of gross slip. By detecting incipient slip we were able to predict when several differently shaped objects were at risk of falling and prevent them from doing so. Detecting incipient slip is useful because a corrective action can be taken before slippage occurs across the entire contact area thus minimising the risk of objects been dropped.",
        "primary_area": "",
        "author": "Jasper W. James;Stephen J. Redmond;Nathan F. Lepora;Jasper W. James;Stephen J. Redmond;Nathan F. Lepora",
        "authorids": "/37086421665;/37276764700;/37399610200;/37086421665;/37276764700;/37399610200",
        "aff": "The Bristol Robotics Laboratory, Bristol, UK; School of Electrical and Electronic Engineering, University College Dublin, Dublin, Ireland; The Bristol Robotics Laboratory, Bristol, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341310/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2770944501754658114&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Bristol Robotics Laboratory;University College Dublin",
        "aff_unique_dep": ";School of Electrical and Electronic Engineering",
        "aff_unique_url": ";https://www.ucd.ie",
        "aff_unique_abbr": ";UCD",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Bristol;Dublin",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "United Kingdom;Ireland"
    },
    {
        "id": "9341444",
        "title": "A Bio\u2013inspired Quadruped Robot Exploiting Flexible Shoulder for Stable and Efficient Walking",
        "track": "main",
        "status": "Poster",
        "abstract": "While most modern-day quadruped robots crouch their limbs during the stance phase to stabilize the trunk, mammals exploit the inverted-pendulum motions of their limbs and realize both efficient and stable walking. Although the flexibility of the shoulder region of mammals is expected to contribute to reconciling the discrepancy between the forelimbs and hindlimbs for natural walking, the complex body structure makes it difficult to understand the functionality of animal morphology. In this study, we developed a simple robot model that mimics the flexibility of shoulder region in the sagittal plane, and we conducted a two-dimensional simulation. The results suggest that the flexibility of the shoulder contributes to absorbing the different motions between the forelimbs and hindlimbs.",
        "primary_area": "",
        "author": "Akira Fukuhara;Megu Gunji;Yoichi Masuda;Kenjiro Tadakuma;Akio Ishiguro;Akira Fukuhara;Megu Gunji;Yoichi Masuda;Kenjiro Tadakuma;Akio Ishiguro",
        "authorids": "/37086249383;/37088233824;/37086173439;/38534909200;/37275189900;/37086249383;/37088233824;/37086173439;/38534909200;/37275189900",
        "aff": "Research Institute of Electrical Communication, Tohoku University, Sendai, Japan; National Museum of Nature and Science, Ibaraki, Japan; Department of Mechanical Engineering, Osaka University, Osaka, Japan; Graduate School of Information Sciences Applied Information Sciences, Tohoku University, Sendai-shi, Japan; Research Institute of Electrical Communication, Tohoku University, Sendai, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341444/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12584799347636649317&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;0;0",
        "aff_unique_norm": "Tohoku University;National Museum of Nature and Science;Osaka University",
        "aff_unique_dep": "Research Institute of Electrical Communication;;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.tohoku.ac.jp;https://www.nmns.go.jp;https://www.osaka-u.ac.jp",
        "aff_unique_abbr": "Tohoku U;;Osaka U",
        "aff_campus_unique_index": "0;1;2;3;0",
        "aff_campus_unique": "Sendai;Ibaraki;Osaka;Sendai-shi",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9341228",
        "title": "A Bottom-up Framework for Construction of Structured Semantic 3D Scene Graph",
        "track": "main",
        "status": "Poster",
        "abstract": "For high-level human-robot interaction tasks, 3D scene understanding is important and non-trivial for autonomous robots. However, parsing and utilizing effective environment information of the 3D scene is not trivial due to the complexity of the 3D environment and the limited ability for reasoning about our visual world. Although there have been great efforts on semantic detection and scene analysis, the existing solutions for parsing and representation of the 3D scene still fail to preserve accurate semantic information and equip sufficient applicability. This study proposes a bottomup construction framework for structured 3D scene graph generation, which efficiently describes the objects, relations and attributes of the 3D indoor environment with structured representation. In the proposed method, we adopt visual perception to capture the semantic information and inference from scene priors to calculate the optimal parse graph. Afterwards, an improved probabilistic grammar model is used to represent the scene priors. Experiment results demonstrate that the proposed framework significantly outperforms existing methods in terms of accuracy, and a demonstration is provided to verify the applicability in applying to high-level human-robot interaction tasks. The supplementary video can be accessed at the following link: https://youtu.be/vEWNxnSwmKI.",
        "primary_area": "",
        "author": "Bangguo Yu;Chongyu Chen;Fengyu Zhou;Fang Wan;Wenmi Zhuang;Yang Zhao;Bangguo Yu;Chongyu Chen;Fengyu Zhou;Fang Wan;Wenmi Zhuang;Yang Zhao",
        "authorids": "/37088464424;/37088689912;/37290752100;/37088463772;/37088462316;/37085348185;/37088464424;/37088689912;/37290752100;/37088463772;/37088462316;/37085348185",
        "aff": "School of Control Science and Engineering, Shandong University, Jinan, P.R. China; DarkMatter AI Research, Guangzhou, P.R. China; School of Control Science and Engineering, Shandong University, Jinan, P.R. China; School of Control Science and Engineering, Shandong University, Jinan, P.R. China; School of Control Science and Engineering, Shandong University, Jinan, P.R. China; School of Electrical Engineering and Automation, Qilu University of Technology (Shandong academy of sciences), Jinan, P.R. China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341228/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7481405255357553125&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;0;0;2",
        "aff_unique_norm": "Shandong University;DarkMatter AI Research;Qilu University of Technology",
        "aff_unique_dep": "School of Control Science and Engineering;;School of Electrical Engineering and Automation",
        "aff_unique_url": "http://www.sdu.edu.cn;;",
        "aff_unique_abbr": "SDU;;",
        "aff_campus_unique_index": "0;1;0;0;0;0",
        "aff_campus_unique": "Jinan;Guangzhou",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9341262",
        "title": "A Causal Approach to Tool Affordance Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "While abstract knowledge like cause-and-effect relations enables robots to problem-solve in new environments, acquiring such knowledge remains out of reach for many traditional machine learning techniques. In this work, we introduce a method for a robot to learn an explicit model of cause-and-effect by constructing a structural causal model through a mix of observation and self-supervised experimentation, allowing a robot to reason from causes to effects and from effects to causes. We demonstrate our method on tool affordance learning tasks, where a humanoid robot must leverage its prior learning to utilize novel tools effectively. Our results suggest that after minimal training examples, our system can preferentially choose new tools based on the context, and can use these tools for goal-directed object manipulation.",
        "primary_area": "",
        "author": "Jake Brawer;Meiying Qin;Brian Scassellati;Jake Brawer;Meiying Qin;Brian Scassellati",
        "authorids": "/37086575891;/37086803070;/37295620100;/37086575891;/37086803070;/37295620100",
        "aff": "Department of Computer Science, Yale University, New Haven, CT, USA; Department of Computer Science, Yale University, New Haven, CT, USA; Department of Computer Science, Yale University, New Haven, CT, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341262/",
        "gs_citation": 42,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8413205884654262674&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Yale University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.yale.edu",
        "aff_unique_abbr": "Yale",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "New Haven",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341487",
        "title": "A Compact, Cable-driven, Activatable Soft Wrist with Six Degrees of Freedom for Assembly Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "Physical softness has been proposed to absorb impacts when establishing contact with a robot or its workpiece, to relax control requirements and improve performance in assembly and insertion tasks. Previous work has focused on special end effector solutions for isolated tasks, such as the peg-in-hole task. However, as many robot tasks require the precision of rigid robots, and their performance would degrade when simply adding compliance, it has been difficult to take advantage of physical softness in real applications. A wrist that could switch between soft and rigid modes could solve this problem, but actuators with sufficient strength for this state transition would increase the size and weight of the module and decrease the payload of the robot. To solve this problem, we propose a novel design of a soft module consisting of a cable-driven mechanism, which allows the robot end effector to change between soft and rigid mode while being very compact and light. The module effectively combines the advantages of soft and rigid robots, and can be retrofitted to existing robots and grippers while preserving the characteristics of the robotic system. We evaluate the effectiveness of our proposed design through experiments modeling assembly tasks, and investigate design parameters quantitatively.",
        "primary_area": "",
        "author": "Felix von Drigalski;Kazutoshi Tanaka;Masashi Hamaya;Robert Lee;Chisato Nakashima;Yoshiya Shibata;Yoshihisa Ijiri;Felix von Drigalski;Kazutoshi Tanaka;Masashi Hamaya;Robert Lee;Chisato Nakashima;Yoshiya Shibata;Yoshihisa Ijiri",
        "authorids": "/37086063905;/37088507484;/37085532024;/37088507437;/37088507122;/37088505999;/37085621887;/37086063905;/37088507484;/37085532024;/37088507437;/37088507122;/37088505999;/37085621887",
        "aff": "OMRON SINIC X Corporation, Tokyo, Japan; OMRON SINIC X Corporation, Tokyo, Japan; OMRON SINIC X Corporation, Tokyo, Japan; OMRON SINIC X Corporation, Tokyo, Japan; OMRON Corporation, Tokyo, Japan; OMRON Corporation, Tokyo, Japan; OMRON Corporation, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341487/",
        "gs_citation": 35,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9786406152307401034&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;1;1;1",
        "aff_unique_norm": "OMRON SINIC X Corporation;OMRON Corporation",
        "aff_unique_dep": ";",
        "aff_unique_url": ";https://www.omron.com",
        "aff_unique_abbr": ";OMRON",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9340831",
        "title": "A Compliance Control Method Based on Viscoelastic Model for Position-Controlled Humanoid Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Compliance is important for humanoid robots, especially a position-controlled one, to perform tasks in complicated environments where unexpected or sudden contacts will result in large impacts which may cause instability or destroy the hardware of robots. This paper presents a compliance control method based on viscoelastic model for humanoid robots to survive on these conditions. The viscoelastic model is used to obtain the relationship between the differential of contact force/torque and linear/angular position. Thus a state equation of this model can be established and a state feedback controller adjusting the position to adapt to the contact force/torque can be designed to realize the compliant movement. The proposed compliance control method based on viscoelastic model has been employed in ankle compliance for stable walking on indefinite uneven terrain and arm compliance for falling protection on BHR-6P, a position-controlled humanoid robot, which validates its effectiveness.",
        "primary_area": "",
        "author": "Qingqing Li;Zhangguo Yu;Xuechao Chen;Libo Meng;Qiang Huang;Chenglong Fu;Ken Chen;Chunjing Tao;Qingqing Li;Zhangguo Yu;Xuechao Chen;Libo Meng;Qiang Huang;Chenglong Fu;Ken Chen;Chunjing Tao",
        "authorids": "/37086055387;/37631550600;/37694180400;/37075517600;/37279982900;/37086455883;/37335409100;/38236310500;/37086055387;/37631550600;/37694180400;/37075517600;/37279982900;/37086455883;/37335409100;/38236310500",
        "aff": "School of Mechatronical Engineering, Beijing Institute of Technology, Beijing, China; Beijing Advanced Innovation Center for Intelligent Robots and Systems, Beijing Institute of Technology, Beijing, China; Beijing Advanced Innovation Center for Intelligent Robots and Systems, Beijing Institute of Technology, Beijing, China; Key Laboratory of Biomimetic Robots and Systems, Ministry of Education, Beijing, China; Key Laboratory of Biomimetic Robots and Systems, Ministry of Education, Beijing, China; Department of Mechanical and Energy Engineering, Southern University of Science and Technology, Shenzhen, China; Department of Mechanical Engineering, Tsinghua University, Beijing, China; Human Biomechanics Laboratory, National Research Center for Rehabilitation Technical Aids, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340831/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15006085836591250164&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;1;1;2;3;4",
        "aff_unique_norm": "Beijing Institute of Technology;Key Laboratory of Biomimetic Robots and Systems;Southern University of Science and Technology;Tsinghua University;National Research Center for Rehabilitation Technical Aids",
        "aff_unique_dep": "School of Mechatronical Engineering;Ministry of Education;Department of Mechanical and Energy Engineering;Department of Mechanical Engineering;Human Biomechanics Laboratory",
        "aff_unique_url": "http://www.bit.edu.cn;;https://www.sustech.edu.cn;https://www.tsinghua.edu.cn;",
        "aff_unique_abbr": "BIT;;SUSTech;THU;",
        "aff_campus_unique_index": "0;0;0;2;0",
        "aff_campus_unique": "Beijing;;Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9341717",
        "title": "A Comprehensive Trajectory Planner for a Person-Following ATV",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a trajectory planning algorithm for person following that is more comprehensive than existing algorithms. This algorithm is tailored for a front-wheel-steered vehicle, is designed to follow a person while avoiding collisions with both static and moving obstacles, simultaneously optimizing speed and steering, and minimizing control effort. This algorithm uses nonlinear model predictive control, where the underling trajectory optimization problem is approximated using a simultaneous method. Results collected in an unknown environment show that the proposed planning algorithm works well with a perception algorithm to follow a person in uneven grass near obstacles and over ditches and curbs, and on asphalt over train-tracks and near buildings and cars. Overall, the results indicate that the proposed algorithm can safely follow a person in unknown, dynamic environments.",
        "primary_area": "",
        "author": "Huckleberry Febbo;Jiawei Huang;David Isele;Huckleberry Febbo;Jiawei Huang;David Isele",
        "authorids": "/37086013756;/37088689424;/37086124264;/37086013756;/37088689424;/37086124264",
        "aff": "Huckleberry Febbo; Jiawei Huang; David Isele",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341717/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=269976583162931660&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "",
        "aff_unique_norm": "",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "9341643",
        "title": "A Concept of a Miniaturized MR Clutch Utilizing MR Fluid in Squeeze Mode",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel design concept of a miniaturized Magneto-Rheological (MR) clutch. The design uses a set of spur gears as a means to control the torque. MR clutches with various configurations such as disk-, drum-, and armature-based have in the past been reported in the literature. However, to the best of our knowledge, the design of a clutch with spur gears to use MR fluid in squeeze mode is a novel concept that has never been reported previously.After a brief description of the MR clutch principles, the details of the mechanical design of the spur gear MR clutch are discussed. The distribution of the magnetic flux inside the MR clutch is studied using finite element analysis in COMSOL Multiphysics software. Preliminary experimental results using a prototype MR clutch that validates the new concept and the results therein will be presented next. To clearly show the performance of the proposed design, we compared the torque capacity of our MR clutch obtained experimentally with that of a simulated disk-type MR clutch of a similar size.",
        "primary_area": "",
        "author": "Sergey Pisetskiy;Mehrdad R. Kermani;Sergey Pisetskiy;Mehrdad R. Kermani",
        "authorids": "/37086577620;/37266294100;/37086577620;/37266294100",
        "aff": "Electrical and Computer Engineering Department, the University of Western Ontario, London, ON, Canada; Electrical and Computer Engineering Department, the University of Western Ontario, London, ON, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341643/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8644631277485554337&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Western Ontario",
        "aff_unique_dep": "Electrical and Computer Engineering Department",
        "aff_unique_url": "https://www.uwo.ca",
        "aff_unique_abbr": "UWO",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9341210",
        "title": "A Data-driven Framework for Proactive Intention-Aware Motion Planning of a Robot in a Human Environment",
        "track": "main",
        "status": "Poster",
        "abstract": "For safe and efficient human-robot interaction, a robot needs to predict and understand the intentions of humans who share the same space. Mobile robots are traditionally built to be reactive, moving in unnatural ways without following social protocol, hence forcing people to behave very differently from human-human interaction rules, which can be overcome if robots instead were proactive. In this paper, we build an intention-aware proactive motion planning strategy for mobile robots that coexist with multiple humans. We propose a framework that uses Hidden Markov Model (HMM) theory with a history of observations to: i) predict future states and estimate the likelihood that humans will cross the path of a robot, and ii) concurrently learn, update, and improve the predictive model with new observations at run-time. Stochastic reachability analysis is proposed to identify multiple possibilities of future states and a control scheme that leverages temporal virtual physics inspired by spring-mass systems is proposed to enable safe proactive motion planning. The proposed approach is validated with simulations and experiments involving an unmanned ground vehicle (UGV) performing go-to-goal operations in the presence of multiple humans, demonstrating improved performance and effectiveness of online learning when compared to reactive obstacle avoidance approaches.",
        "primary_area": "",
        "author": "Rahul Peddi;Carmelo Di Franco;Shijie Gao;Nicola Bezzo;Rahul Peddi;Carmelo Di Franco;Shijie Gao;Nicola Bezzo",
        "authorids": "/37086941760;/37086072871;/37086940518;/37546843800;/37086941760;/37086072871;/37086940518;/37546843800",
        "aff": "Department of Systems and Information Engineering and the Charles L. Brown Department of Electrical and Computer Engineering, University of Virginia, Charlottesville, VA, USA; Department of Systems and Information Engineering and the Charles L. Brown Department of Electrical and Computer Engineering, University of Virginia, Charlottesville, VA, USA; Department of Systems and Information Engineering and the Charles L. Brown Department of Electrical and Computer Engineering, University of Virginia, Charlottesville, VA, USA; Department of Systems and Information Engineering and the Charles L. Brown Department of Electrical and Computer Engineering, University of Virginia, Charlottesville, VA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341210/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16112739395995744998&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Virginia",
        "aff_unique_dep": "Department of Systems and Information Engineering",
        "aff_unique_url": "https://www.virginia.edu",
        "aff_unique_abbr": "UVA",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Charlottesville",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341183",
        "title": "A Deep Learning Based End-to-End Locomotion Mode Detection Method for Lower Limb Wearable Robot Control",
        "track": "main",
        "status": "Poster",
        "abstract": "To function effectively in real-world environments, powered wearable robots such as exoskeletons and robotic prostheses must recognize the user's motion intent by detecting the user's locomotion modes such as walking, stair ascent and descent or ramp ascent and descent. Traditionally, intent detection is achieved using rule based methods such as state machines or fuzzy logic using data from wearable sensors. Due to the difficulty of manual rule design, these methods are limited to detect certain simple locomotion modes. Machine learning (ML) based methods can perform classification on a large number of classes without manual rule design and recent research has explored several ML methods for locomotion mode classification. However, current ML based methods for locomotion mode detection use classical methods that require use of feature engineering to achieve acceptable accuracies. Additionally, current ML strategies only classify when certain motion events are detected. This strategy, while computationally efficient could result in misclassifications affecting large sections of motion recognition. To overcome these limitations, this paper proposes an end-to-end deep learning based method for locomotion mode detection that eliminates the need for feature engineering and classifies at a fixed sample rate. This paper introduces a new metric called confidence index and proposes a strategy for tuning confidence index thresholds to achieve a stable intent recognition and overall accuracy of greater than 95% on a publicly available benchmark dataset.",
        "primary_area": "",
        "author": "Zeyu Lu;Ashwin Narayan;Haoyong Yu;Zeyu Lu;Ashwin Narayan;Haoyong Yu",
        "authorids": "/37088687445;/37086263453;/37711526800;/37088687445;/37086263453;/37711526800",
        "aff": "Department of Biomedical Engineering, National University of Singapore, Singapore; Department of Biomedical Engineering, National University of Singapore, Singapore; Department of Biomedical Engineering, National University of Singapore, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341183/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2767548972350462464&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "National University of Singapore",
        "aff_unique_dep": "Department of Biomedical Engineering",
        "aff_unique_url": "https://www.nus.edu.sg",
        "aff_unique_abbr": "NUS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "9341539",
        "title": "A Distributed Range-Only Collision Avoidance Approach for Low-cost Large-scale Multi-Robot Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "The challenges of developing low-cost, large-scale multi-robot navigation systems include noisy measurements, a large number of robots, and computing efficiency for collision avoidance. This paper presents a distributed motion planning framework for a large number of robots to navigate with robust collision avoidance using low-cost range only measurements. The novelty of this work is threefold. (1) Developing a distributed collision-free navigation system for a large-scale robot group in which each robot performs motion planning based on the noisy range measurements of neighboring robots; (2) Developing a set of algorithms for each robot to accurately estimate the relative positions and orientations based on the range measurements and relative velocities; (3) Developing a velocity obstacle (VO) based motion planning algorithm for each robot which can take into account of the estimation uncertainties in relative positions and orientations. The proposed approach is tested with various numbers of differential-driven robots in the Gazebo simulator and real-world experiments. Both simulation and experiment results validate the superior performance of the proposed approach compared to other state-of-art technologies.",
        "primary_area": "",
        "author": "Ruihua Han;Shengduo Chen;Qi Hao;Ruihua Han;Shengduo Chen;Qi Hao",
        "authorids": "/37086568236;/37088504241;/37403530000;/37086568236;/37088504241;/37403530000",
        "aff": "Department of Computer Science and Engineering, Southern University of Science and Technology, Shenzhen, Guangdong, China; Department of Computer Science and Engineering, Southern University of Science and Technology, Shenzhen, Guangdong, China; Sifakis Research Institute of Trustworthy Autonomous Systems",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341539/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16395444501917458169&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Southern University of Science and Technology;Sifakis Research Institute of Trustworthy Autonomous Systems",
        "aff_unique_dep": "Department of Computer Science and Engineering;",
        "aff_unique_url": "https://www.sustech.edu.cn;https://www.sifakis.org",
        "aff_unique_abbr": "SUSTech;",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Shenzhen;",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "China;Greece"
    },
    {
        "id": "9340836",
        "title": "A Distributed Scalar Field Mapping Strategy for Mobile Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a distributed field mapping algorithm that drives a team of robots to explore and learn an unknown scalar field. The algorithm is based on a bio-inspired approach known as Speeding-Up and Slowing-Down (SUSD) for distributed source seeking problems. Our algorithm leverages a Gaussian Process model to predict field values as robots explore. By comparing Gaussian Process predictions with measurements of the field, agents search along the gradient of the model error while simultaneously improving the Gaussian Process model. We provide a proof of convergence to the gradient direction and demonstrate our approach in simulation and experiments using 2D wheeled robots and 2D flying autonomous miniature blimps.",
        "primary_area": "",
        "author": "Tony X. Lin;Said Al-Abri;Samuel Coogan;Fumin Zhang;Tony X. Lin;Said Al-Abri;Samuel Coogan;Fumin Zhang",
        "authorids": "/37088439582;/37086332221;/38232457300;/37406187900;/37088439582;/37086332221;/38232457300;/37406187900",
        "aff": "School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA; School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA; School of Electrical and Computer Engineering and the School of Civil and Environmental Engineering, Georgia Institute of Technology, Atlanta, GA, USA; School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340836/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6786461625361051203&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Georgia Institute of Technology",
        "aff_unique_dep": "School of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.gatech.edu",
        "aff_unique_abbr": "Georgia Tech",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Atlanta",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341733",
        "title": "A Fast and Robust Place Recognition Approach for Stereo Visual Odometry Using LiDAR Descriptors",
        "track": "main",
        "status": "Poster",
        "abstract": "Place recognition is a core component of Simultaneous Localization and Mapping (SLAM) algorithms. Particularly in visual SLAM systems, previously-visited places are recognized by measuring the appearance similarity between images representing these locations. However, such approaches are sensitive to visual appearance change and also can be computationally expensive. In this paper, we propose an alternative approach adapting LiDAR descriptors for 3D points obtained from stereo-visual odometry for place recognition. 3D points are potentially more reliable than 2D visual cues (e.g., 2D features) against environmental changes (e.g., variable illumination) and this may benefit visual SLAM systems in long-term deployment scenarios. Stereo-visual odometry generates 3D points with an absolute scale, which enables us to use LiDAR descriptors for place recognition with high computational efficiency. Through extensive evaluations on standard benchmark datasets, we demonstrate the accuracy, efficiency, and robustness of using 3D points for place recognition over 2D methods.",
        "primary_area": "",
        "author": "Jiawei Mo;Junaed Sattar;Jiawei Mo;Junaed Sattar",
        "authorids": "/37087322233;/37546394500;/37087322233;/37546394500",
        "aff": "",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341733/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3989849080380222143&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4
    },
    {
        "id": "9341573",
        "title": "A Flexible Dual-Core Optical Waveguide Sensor for Simultaneous and Continuous Measurement of Contact Force and Position",
        "track": "main",
        "status": "Poster",
        "abstract": "Having the merits of chemical inertness and immunity to electromagnetic interference, light weight, small size, and softness, optical waveguides have attracted much attention in making tactile sensors recently. This paper presents a new design of waveguide using two layers of cores, one of which has an uniform width and the other has an incremental width. It is deduced and verified that the contact force can be derived from the light power loss in the uniform-width core, while the contact position can be derived from the light power loss in the other core together with the estimated force. By this dual-core design, a single waveguide can simultaneously and continuously measure the contact force and position along it, which makes it very suited for integration on some thin long robotic parts, such as robotic fingers. A hardware experiment has been conducted to demonstrate its effectiveness on a two-finger gripper in an assembly task. The dual-core waveguide achieves 2 mm spatial resolution and 0.1 N sensitivity.",
        "primary_area": "",
        "author": "Zhong Zhang;Yu Zheng;Jia Pan;Xiong Li;Kaiwei Li;Zhengyou Zhang;Zhong Zhang;Yu Zheng;Jia Pan;Xiong Li;Kaiwei Li;Zhengyou Zhang",
        "authorids": "/37086920466;/37086993722;/37089401812;/37085669304;/37086043606;/37088690806;/37086920466;/37086993722;/37089401812;/37085669304;/37086043606;/37088690806",
        "aff": "Department of Biomedical Engineering, City University of Hong Kong; Tencent Robotics X, Shenzhen, China; Department of Science Computer, University of Hong Kong; Tencent Robotics X, Shenzhen, China; Institute of Photonics Technology, Jinan University; Tencent Robotics X, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341573/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14808413272871123197&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;1;3;1",
        "aff_unique_norm": "City University of Hong Kong;Tencent Robotics X;University of Hong Kong;Jinan University",
        "aff_unique_dep": "Department of Biomedical Engineering;Robotics X;Department of Science Computer;Institute of Photonics Technology",
        "aff_unique_url": "https://www.cityu.edu.hk;https://robotics.tencent.com;https://www.hku.hk;http://www.jnu.edu.cn/",
        "aff_unique_abbr": "CityU;Tencent Robotics X;HKU;",
        "aff_campus_unique_index": "0;1;0;1;1",
        "aff_campus_unique": "Hong Kong SAR;Shenzhen;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9341286",
        "title": "A Framework for Human-Robot Interaction User Studies",
        "track": "main",
        "status": "Poster",
        "abstract": "Human-Robot Interaction (HRI) user studies are challenging to evaluate and compare due to a lack of standardization and the infrastructure required to implement each study. The lack of experimental infrastructure also makes it difficult to systematically evaluate the impact of individual components (e.g., the quality of perception software) on overall system performance. This work proposes a framework to ease the implementation and reproducibility of human-robot interaction user studies. The framework utilizes ROS middleware and is implemented with four modules: perception, decision, action, and metrics. The perception module aggregates sensor data to be used by the decision and action modules. The decision module is the task-level executive and can be designed by the HRI researcher for their specific task. The action module takes subtask requests from the decision module and breaks them down into motion primitives for execution on the robot. The metrics module tracks and generates quantitative metrics for the study. The framework is implemented with modular interfaces to allow for alternate implementations within each module and can be generalized for a variety of tasks and human/robot roles. The framework is illustrated through an example scenario involving a human and a Franka Emika Panda arm collaboratively assembling a toolbox together.",
        "primary_area": "",
        "author": "Vidyasagar Rajendran;Pamela Carreno-Medrano;Wesley Fisher;Alexander Werner;Dana Kuli\u0107;Vidyasagar Rajendran;Pamela Carreno-Medrano;Wesley Fisher;Alexander Werner;Dana Kuli\u0107",
        "authorids": "/37088687822;/37085631152;/37088687203;/38541778400;/37547876700;/37088687822;/37085631152;/37088687203;/38541778400;/37547876700",
        "aff": "Department of Electrical and Computer Engineering, Faculty of Engineering, University of Waterloo, Ontario, Canada; Faculty of Engineering, Monash University, Melbourne, Australia; Department of Electrical and Computer Engineering, Faculty of Engineering, University of Waterloo, Ontario, Canada; Department of Electrical and Computer Engineering, Faculty of Engineering, University of Waterloo, Ontario, Canada; Faculty of Engineering, Monash University, Melbourne, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341286/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6059785066535267111&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;1",
        "aff_unique_norm": "University of Waterloo;Monash University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Faculty of Engineering",
        "aff_unique_url": "https://uwaterloo.ca;https://www.monash.edu",
        "aff_unique_abbr": "UW;Monash",
        "aff_campus_unique_index": "0;1;0;0;1",
        "aff_campus_unique": "Waterloo;Melbourne",
        "aff_country_unique_index": "0;1;0;0;1",
        "aff_country_unique": "Canada;Australia"
    },
    {
        "id": "9341606",
        "title": "A Framework for Online Updates to Safe Sets for Uncertain Dynamics",
        "track": "main",
        "status": "Poster",
        "abstract": "Safety is crucial for deploying robots in the real world. One way of reasoning about safety of robots is by building safe sets through Hamilton-Jacobi (HJ) reachability. However, safe sets are often computed offline, assuming perfect knowledge of the dynamics, due to high compute time. In the presence of uncertainty, the safe set computed offline becomes inaccurate online, potentially leading to dangerous situations on the robot. We propose a novel framework to learn a safe control policy in simulation, and use it to generate online safe sets under uncertain dynamics. We start with a conservative safe set and update it online as we gather more information about the robot dynamics. We also show an application of our framework to a model-based reinforcement learning problem, proposing a safe model-based RL setup. Our framework enables robots to simultaneously learn about their dynamics, accomplish tasks, and update their safe sets. It also generalizes to complex high-dimensional dynamical systems, like 3-link manipulators and quadrotors, and reliably avoids obstacles, while achieving a task, even in the presence of unmodeled noise.",
        "primary_area": "",
        "author": "Jennifer C. Shih;Franziska Meier;Akshara Rai;Jennifer C. Shih;Franziska Meier;Akshara Rai",
        "authorids": "/37086188132;/38227805500;/37085480350;/37086188132;/38227805500;/37085480350",
        "aff": "Department of Electrical Engineering and Computer Sciences, University of California, Berkeley; Facebook AI Research; Facebook AI Research",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341606/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9325914365040853383&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "University of California, Berkeley;Facebook",
        "aff_unique_dep": "Department of Electrical Engineering and Computer Sciences;Facebook AI Research",
        "aff_unique_url": "https://www.berkeley.edu;https://research.facebook.com",
        "aff_unique_abbr": "UC Berkeley;FAIR",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Berkeley;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341560",
        "title": "A Framework for Real-time and Personalisable Human Ergonomics Monitoring",
        "track": "main",
        "status": "Poster",
        "abstract": "The objective of this paper is to present a personalisable human ergonomics framework that integrates a method for real-time identification of a human model and an ergonomics monitoring function. The human model is based on a floating base structure and on a Statically Equivalent Serial Chain (SESC) model used for the estimation of the whole-body centre of Mass (CoM). A recursive linear regression algorithm (i.e., Kalman filter) is developed to achieve the online identification of the SESC parameters. A visual feedback provides a minimum set of suggested human poses to speed up the identification process, while enhancing the model accuracy based on a convergence value. The online ergonomics monitoring function computes and displays the overloading effects on body joints in heavy lifting tasks. The overloading joint torques are calculated based on the displacement of the Center of Pressure (CoP) between the measured one and the estimated one. Unlike our previous work, the entire process, from the model identification (personalisation) to ergonomics monitoring, is performed in real-time. We evaluated the efficacy of the proposed method through human experiments during model identification and load lifting tasks. Results demonstrate the high exploitation potential of the framework in industrial settings, due to its fast personalisation and ergonomics monitoring capacity.",
        "primary_area": "",
        "author": "Luca Fortini;Marta Lorenzini;Wansoo Kim;Elena De Momi;Arash Ajoudani;Luca Fortini;Marta Lorenzini;Wansoo Kim;Elena De Momi;Arash Ajoudani",
        "authorids": "/37088420670;/37086249968;/37086291232;/37947344300;/37945239900;/37088420670;/37086249968;/37086291232;/37947344300;/37945239900",
        "aff": "Department of Electronics, Information and Bioengineering, Politecnico di Milano, Milano, Italy; Department of Electronics, Information and Bioengineering, Politecnico di Milano, Milano, Italy; HRII Laboratory, Istituto Italiano di Tecnologia, Genoa, Italy; Department of Electronics, Information and Bioengineering, Politecnico di Milano, Milano, Italy; HRII Laboratory, Istituto Italiano di Tecnologia, Genoa, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341560/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11594029450260257743&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;1",
        "aff_unique_norm": "Politecnico di Milano;Istituto Italiano di Tecnologia",
        "aff_unique_dep": "Department of Electronics, Information and Bioengineering;HRII Laboratory",
        "aff_unique_url": "https://www.polimi.it;https://www.iit.it",
        "aff_unique_abbr": "Politecnico di Milano;IIT",
        "aff_campus_unique_index": "0;0;1;0;1",
        "aff_campus_unique": "Milano;Genoa",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9340988",
        "title": "A Game-Theoretic Strategy-Aware Interaction Algorithm with Validation on Real Traffic Data",
        "track": "main",
        "status": "Poster",
        "abstract": "Interactive decision-making and motion planning are important to safety-critical autonomous agents, particularly when they interact with humans. Many different interaction strategies can be exploited by humans. For instance, they might ignore the autonomous agents, or might behave as selfish optimizers by treating the autonomous agents as opponents, or might assume themselves as leaders and the autonomous agents as followers who should take responsive actions. Different interaction strategies can lead to quite different closed-loop dynamics, and misalignment between the human's policy and the autonomous agent's belief over the policy will severely impact both safety and efficiency. Moreover, a human's interaction policy can change as interaction goes on. Hence, autonomous agents need to be aware of such uncertainties on the human policy, and integrate such information into their decision-making and motion planning algorithms. In this paper, we propose a policy-aware interaction strategy based on game theory. The goal is to allow autonomous agents to estimate humans' interactive policies and respond consequently. We validate the proposed algorithm with a roundabout scenario with real traffic data. The results show that the proposed algorithm can yield trajectories that are more similar to the ground truth than those with fixed policies. Also, we estimate how humans adjust their interaction strategies statistically based on the proposed algorithm.",
        "primary_area": "",
        "author": "Liting Sun;Mu Cai;Wei Zhan;Masayoshi Tomizuka;Liting Sun;Mu Cai;Wei Zhan;Masayoshi Tomizuka",
        "authorids": "/37085425729;/37088689865;/37067099600;/37281933000;/37085425729;/37088689865;/37067099600;/37281933000",
        "aff": "Department of Mechanical Engineering, University of California, Berkeley, CA, USA; Department of Electrical Engineering, Xi\u2019an Jiaotong University, Xi\u2019an, China; Department of Mechanical Engineering, University of California, Berkeley, CA, USA; Department of Mechanical Engineering, University of California, Berkeley, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340988/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13423937469151055343&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "University of California, Berkeley;Xi'an Jiaotong University",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Electrical Engineering",
        "aff_unique_url": "https://www.berkeley.edu;http://www.xjtu.edu.cn",
        "aff_unique_abbr": "UC Berkeley;XJTU",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Berkeley;Xi'an",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "9341758",
        "title": "A Geometric Perspective on Visual Imitation Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider the problem of visual imitation learning without human kinesthetic teaching or teleoperation, nor access to an interactive reinforcement learning training environment. We present a geometric perspective to this problem where geometric feature correspondences are learned from one training video and used to execute tasks via visual servoing. Specifically, we propose VGS-IL (Visual Geometric Skill Imitation Learning), an end-to-end geometry-parameterized task concept inference method, to infer globally consistent geometric feature association rules from human demonstration video frames. We show that, instead of learning actions from image pixels, learning a geometry-parameterized task concept provides an explainable and invariant representation across demonstrator to imitator under various environmental settings. Moreover, such a task concept representation provides a direct link with geometric vision based controllers (e.g. visual servoing), allowing for efficient mapping of high-level task concepts to low-level robot actions.",
        "primary_area": "",
        "author": "Jun Jin;Laura Petrich;Masood Dehghan;Martin Jagersand;Jun Jin;Laura Petrich;Masood Dehghan;Martin Jagersand",
        "authorids": "/37086574802;/37086934069;/37951137300;/37269568300;/37086574802;/37086934069;/37951137300;/37269568300",
        "aff": "Department of Computing Science, University of Alberta, Edmonton AB, Canada; Department of Computing Science, University of Alberta, Edmonton AB, Canada; Department of Computing Science, University of Alberta, Edmonton AB, Canada; Department of Computing Science, University of Alberta, Edmonton AB, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341758/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15912123367135094290&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Alberta",
        "aff_unique_dep": "Department of Computing Science",
        "aff_unique_url": "https://www.ualberta.ca",
        "aff_unique_abbr": "UAlberta",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Edmonton",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9340864",
        "title": "A Hamilton\u2013Jacobi Formulation for Optimal Coordination of Heterogeneous Multiple Vehicle Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a method for optimal coordination of multiple vehicle teams when multiple endpoint configurations are equally desirable, such as seen in the autonomous assembly of formation flight. The individual vehicles\u2019 positions in the formation are not assigned a priori and a key challenge is to find the optimal configuration assignment along with the optimal control and trajectory. Commonly, assignment and trajectory planning problems are solved separately. We introduce a new multi-vehicle coordination paradigm, where the optimal goal assignment and optimal vehicle trajectories are found simultaneously from a viscosity solution of a single Hamilton\u2013Jacobi (HJ) partial differential equation (PDE), which provides a necessary and sufficient condition for global optimality. Intrinsic in this approach is that individual vehicle dynamic models need not be the same, and therefore can be applied to heterogeneous systems. Numerical methods to solve the HJ equation have historically relied on a discrete grid of the solution space and exhibits exponential scaling with system dimension, preventing their applicability to multiple vehicle systems. By utilizing a generalization of the Hopf formula, we avoid the use of grids and present a method that exhibits polynomial scaling in the number of vehicles.",
        "primary_area": "",
        "author": "Matthew R. Kirchner;Mark J. Debord;Jo\u00e3o P. Hespanha;Matthew R. Kirchner;Mark J. Debord;Jo\u00e3o P. Hespanha",
        "authorids": "/37086331444;/37086582071;/37275155600;/37086331444;/37086582071;/37275155600",
        "aff": "Center for Control, Dynamical Systems and Computation (CCDC), University of California, Santa Barbara, CA, USA; Image and Signal Processing Branch, Research and Intelligence Department, Code D5J1000, Naval Air Warfare Center Weapons Division, China Lake, CA, USA; Center for Control, Dynamical Systems and Computation (CCDC), University of California, Santa Barbara, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340864/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8300120052916849985&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of California, Santa Barbara;Naval Air Warfare Center Weapons Division",
        "aff_unique_dep": "Center for Control, Dynamical Systems and Computation (CCDC);Image and Signal Processing Branch, Research and Intelligence Department",
        "aff_unique_url": "https://www.ucsb.edu;",
        "aff_unique_abbr": "UCSB;",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Santa Barbara;China Lake",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341528",
        "title": "A Horse Inspired Eight-wheel Unmanned Ground Vehicle with Four-swing Arms",
        "track": "main",
        "status": "Poster",
        "abstract": "Rigid-terrain unmanned ground vehicles(UGV) can run under the field environment by the advanced adaptive ability. This paper presents a novel horse inspired rigid-terrain eight-wheel vehicle with four-swing arms. This unmanned ground vehicle is drived by distributed hydraulic motors. By cooperating with four-swing arms and eight wheels, the vehicle has the ability to work like a horse climbs an obstacle under the complex ground. The mechanism, bionic obstacle surmounting algorithm and operation strategy are analyzed in detail. The posture planning of wheel arms and the kinematic model of the UGV are studied. Automatic Dynamic Analysis of Mechanical Systems (ADAMS) simulation results and prototype experiments are executed to verify the analysis and strategy. The results show that this type of unmanned ground vehicle has good performance on crossing the obstacle and running on the rigid-terrain ground.",
        "primary_area": "",
        "author": "Miaolei HE;Jilin He;Changji Ren;Qinghua He;Miaolei HE;Jilin He;Changji Ren;Qinghua He",
        "authorids": "/37086405400;/37086598056;/37086604217;/37713351900;/37086405400;/37086598056;/37086604217;/37713351900",
        "aff": "College of Engineering and Design, Hunan Normal University, Changsha, China; College of Engineering and Design, Hunan Normal University, Changsha, China; College of Engineering and Design, Hunan Normal University, Changsha, China; College of Engineering and Design, Hunan Normal University, Changsha, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341528/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9458021730338091661&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Hunan Normal University",
        "aff_unique_dep": "College of Engineering and Design",
        "aff_unique_url": "http://www.hnu.edu.cn",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Changsha",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9341261",
        "title": "A Human-Robot Interface based on Surface Electroencephalographic Sensors",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a human-robot interface based on potentials recorded through surface Electroencephalographic sensors, aiming to decode human visual attention into motion in three-dimensional space. Low-frequency components are extracted and processed in real time, and subspace system identification methods are used to derive the optimal, in mean squared sense, linear dynamics generating the position vectors. This results in a human-robot interface that can be used directly in robot teleoperation or as part of a shared-control robotic manipulation scheme, feels natural to the user, and is appropriate for upper extremity amputees, since it requires no limb movement. We validate our methodology by teleoperating a redundant, anthropomorphic robotic arm in real time. The system's performance outruns similar EMG-based systems, and shows low long-term model drift, indicating no need for frequent model re-training.",
        "primary_area": "",
        "author": "Christos N. Mavridis;John S. Baras;Kostas J. Kyriakopoulos;Christos N. Mavridis;John S. Baras;Kostas J. Kyriakopoulos",
        "authorids": "/37086527143;/37268709400;/38181756700;/37086527143;/37268709400;/38181756700",
        "aff": "Department of Electrical and Computer Engineering and the Institute for Systems Research, University of Maryland, College Park, MD, USA; Department of Electrical and Computer Engineering and the Institute for Systems Research, University of Maryland, College Park, MD, USA; Control Systems Laboratory, School of Mechanical Engineering, National Technical University of Athens, Greece",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341261/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16821987129434206958&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "University of Maryland, College Park;National Technical University of Athens",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;School of Mechanical Engineering",
        "aff_unique_url": "https://www.umd.edu;https://www.ntua.gr",
        "aff_unique_abbr": "UMD;NTUA",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "College Park;",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "United States;Greece"
    },
    {
        "id": "9341445",
        "title": "A Learning-Driven Framework with Spatial Optimization For Surgical Suture Thread Reconstruction and Autonomous Grasping Under Multiple Topologies and Environmental Noises",
        "track": "main",
        "status": "Poster",
        "abstract": "Surgical knot tying is one of the most fundamental and important procedures in surgery, and a high-quality knot can significantly benefit the postoperative recovery of the patient. However, a longtime operation may easily cause fatigue to surgeons, especially during the tedious wound closure task. In this paper, we present a vision-based method to automate the suture thread grasping, which is a sub-task in surgical knot tying and an intermediate step between the stitching and looping manipulations. To achieve this goal, the acquisition of a suture's three-dimensional (3D) information is critical. Towards this objective, we adopt a transfer-learning strategy first to fine-tune a pre-trained model by learning the information from large legacy surgical data and images obtained by the onsite equipment. Thus, a robust suture segmentation can be achieved regardless of inherent environment noises. We further leverage a searching strategy with termination policies for a suture's sequence inference based on the analysis of multiple topologies. Exact results of the pixel-level sequence along a suture can be obtained, and they can be further applied for a 3D shape reconstruction using our optimized shortest path approach. The grasping point considering the suturing criterion can be ultimately acquired. Experiments regarding the suture 2D segmentation and ordering sequence inference under environmental noises were extensively evaluated. Results related to the automated grasping operation were demonstrated by simulations in V-REP and by robot experiments using Universal Robot (UR) together with the da Vinci Research Kit (dVRK) adopting our learning-driven framework.",
        "primary_area": "",
        "author": "Bo Lu;Wei Chen;Yue-Ming Jin;Dandan Zhang;Qi Dou;Henry K. Chu;Pheng-Ann Heng;Yun-Hui Liu;Bo Lu;Wei Chen;Yue-Ming Jin;Dandan Zhang;Qi Dou;Henry K. Chu;Pheng-Ann Heng;Yun-Hui Liu",
        "authorids": "/37085991083;/37086608021;/37086369638;/37086595836;/37085465414;/37085396213;/37283077400;/37279412600;/37085991083;/37086608021;/37086369638;/37086595836;/37085465414;/37085396213;/37283077400;/37279412600",
        "aff": "The Department of Mechanical and Automation Engineering, CUHK T stone Robotics Institute, The Chinese University of Hong Kong; The Department of Mechanical and Automation Engineering, CUHK T stone Robotics Institute, The Chinese University of Hong Kong; The Department of Computer Science and Engineering, CUHK T stone Robotics Institute, The Chinese University of Hong Kong; The Hamlyn Centre for Robotic Surgery, Imperial College London, UK; The Department of Computer Science and Engineering, CUHK T stone Robotics Institute, The Chinese University of Hong Kong; The Department of Mechanical Engineering, The Kong Kong Polytechnic University, Hong Kong; The Department of Computer Science and Engineering, CUHK T stone Robotics Institute, The Chinese University of Hong Kong; The Department of Mechanical and Automation Engineering, CUHK T stone Robotics Institute, The Chinese University of Hong Kong",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341445/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3831921352311729552&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;1;0;2;0;0",
        "aff_unique_norm": "The Chinese University of Hong Kong;Imperial College London;The Hong Kong Polytechnic University",
        "aff_unique_dep": "Department of Mechanical and Automation Engineering;The Hamlyn Centre for Robotic Surgery;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.cuhk.edu.hk;https://www.imperial.ac.uk;https://www.polyu.edu.hk",
        "aff_unique_abbr": "CUHK;Imperial College;PolyU",
        "aff_campus_unique_index": "0;0;0;1;0;0;0;0",
        "aff_campus_unique": "Hong Kong SAR;London",
        "aff_country_unique_index": "0;0;0;1;0;0;0;0",
        "aff_country_unique": "China;United Kingdom"
    },
    {
        "id": "9340904",
        "title": "A Learning-based Robotic Bin-picking with Flexibly Customizable Grasping Conditions",
        "track": "main",
        "status": "Poster",
        "abstract": "A practical robotic bin-picking system requires a high grasp success rate for various objects. Also, the system must be capable of coping with various constraints and their changes flexibly. To resolve these issues, this study proposes a novel deep learning-based method that exploits a simulator to generate desired grasping actions. The features of this method are as follows: (1) Grasping conditions for any object can be flexibly customizable in the simulated environment to improve the real-world grasping actions. (2) Sensor input (RGB image) is directly regressed to grasping actions by using convolutional processing. Owing to these features, the system using the proposed method can grasp objects with geometric variations, semi-transparent objects, and objects with a biased center of gravity. Experimental results on a real robot system show that the proposed method exhibits a high grasp success rate for four types of objects with different physical and geometric properties as well as additional constraints of grasping condition.",
        "primary_area": "",
        "author": "Hiroki Tachikake;Wataru Watanabe;Hiroki Tachikake;Wataru Watanabe",
        "authorids": "/37088688683;/37088686580;/37088688683;/37088686580",
        "aff": "Development Technology Department, AI Cube Inc., Chuo-ku, Tokyo, Japan; Development Technology Department, AI Cube Inc., Chuo-ku, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340904/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17621914129702786621&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "AI Cube Inc.",
        "aff_unique_dep": "Development Technology Department",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9341391",
        "title": "A Miniaturised Neuromorphic Tactile Sensor integrated with an Anthropomorphic Robot Hand",
        "track": "main",
        "status": "Poster",
        "abstract": "Restoring tactile sensation is essential to enable in-hand manipulation and the smooth, natural control of upper-limb prosthetic devices. Here we present a platform to contribute to that long-term vision, combining an anthropomorphic robot hand (QB SoftHand) with a neuromorphic optical tactile sensor (neuroTac). Neuromorphic sensors aim to produce efficient, spike-based representations of information for bio-inspired processing. The development of this 5-fingered, sensorized hardware platform is validated with a customized mount allowing manual control of the hand. The platform is demonstrated to succesfully identify 4 objects from the YCB object set, and accurately discriminate between 4 directions of shear during stable grasps. This platform could lead to wide-ranging developments in the areas of haptics, prosthetics and telerobotics.",
        "primary_area": "",
        "author": "Benjamin Ward-Cherrier;J\u00f6rg Conradt;Manuel G. Catalano;Matteo Bianchi;Nathan F. Lepora;Benjamin Ward-Cherrier;J\u00f6rg Conradt;Manuel G. Catalano;Matteo Bianchi;Nathan F. Lepora",
        "authorids": "/37085617128;/37326140900;/37544547800;/37394737700;/37399610200;/37085617128;/37326140900;/37544547800;/37394737700;/37399610200",
        "aff": "Dept. of Engineering Mathematics, University of Bristol and Bristol Robotics Laboratory, University of Bristol, UK; School of Electrical Engineering and Computer Science, KTH Royal Institute of Technology, Sweden; Istituto Italiano di Tecnologia, Genova, Italia; Centro di Ricerca E. Piaggio e Dipartimento di Ingegneria dell\u2019Informazione, Universita di Pisa, Pisa, Italia; Dept. of Engineering Mathematics, University of Bristol and Bristol Robotics Laboratory, University of Bristol, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341391/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8312522825342471206&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;3;0",
        "aff_unique_norm": "University of Bristol;KTH Royal Institute of Technology;Istituto Italiano di Tecnologia;Universita di Pisa",
        "aff_unique_dep": "Dept. of Engineering Mathematics;School of Electrical Engineering and Computer Science;;Dipartimento di Ingegneria dell\u2019Informazione",
        "aff_unique_url": "https://www.bristol.ac.uk;https://www.kth.se;https://www.iit.it;https://www.unipi.it",
        "aff_unique_abbr": "UoB;KTH;IIT;UniPi",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";Genova;Pisa",
        "aff_country_unique_index": "0;1;2;2;0",
        "aff_country_unique": "United Kingdom;Sweden;Italy"
    },
    {
        "id": "9341628",
        "title": "A Minimalistic Hyper-Flexible Manipulator: Modeling and Control",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic manipulators can be found today in most industries, from autonomous warehouses to advanced assembly lines in factories. Most of these industrial robots are characterized by having non-flexible and highly rigid links. In dense and complex environments these manipulators require many degrees of freedom (DOFs) which complicates the mechanical structure of the manipulator, as well as the control and path planning algorithms. In this work we present a minimalistic approach to reduce the number of active DOFs by using non-rigid, Hyper-Flexible Manipulators (HFM). We introduce a dynamic model of the HFM as well as a control scheme to bring the end-effector to a desired position from known initial configuration. Finally, we present experiments that support the analytic part and simulative results of this paper.",
        "primary_area": "",
        "author": "Amit Prigozin;Amir Degani;Amit Prigozin;Amir Degani",
        "authorids": "/37088689401;/37542443600;/37088689401;/37542443600",
        "aff": "Civil and Environmental Engineering Department, Technion-Israel Institute of Technology, Haifa, Israel; Civil and Environmental Engineering Department and with the Technion\u2019s Autonomous Systems Program, Technion-Israel Institute of Technology, Haifa, Israel",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341628/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16933299747806882268&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Technion-Israel Institute of Technology",
        "aff_unique_dep": "Civil and Environmental Engineering Department",
        "aff_unique_url": "https://www.technion.ac.il",
        "aff_unique_abbr": "Technion",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Haifa",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Israel"
    },
    {
        "id": "9341674",
        "title": "A Mixed-Integer Model Predictive Control Approach to Motion Cueing in Immersive Wheelchair Simulator",
        "track": "main",
        "status": "Poster",
        "abstract": "To allow wheelchair (electronic or manual) users to practice driving in different safe, repeatable and controlled scenarios, the use of simulator as a training tool is considered here. In this context, the capabilities of providing high fidelity motions for users of the simulator is highlighted as one of the most important aspects for the effectiveness of the tool. For this purpose, the motion cueing algorithm (MCA) is studied in our work to regenerate wheelchair motion cues by transforming motions of the real or simulated wheelchair into the simulator motion. The studied algorithm is developed based on Model Predictive Control (MPC) approach to efficiently optimize the motions of the platform. The overall problem is formulated using mixed-integer quadratic programming (MIQP) which involves not only the vestibular model, strict constraints of the platform but also the perception threshold in the optimization cost function. In the end, the performance assessment of the system using different control techniques is analyzed, showing the effectiveness of the proposed approach in the simulation environment.",
        "primary_area": "",
        "author": "Le Anh Dao;Alessio Prini;Matteo Malosio;Angelo Davalli;Marco Sacco;Le Anh Dao;Alessio Prini;Matteo Malosio;Angelo Davalli;Marco Sacco",
        "authorids": "/37085338445;/37086438334;/37402933800;/37550889900;/37720458600;/37085338445;/37086438334;/37402933800;/37550889900;/37720458600",
        "aff": "Istituto di Sistemi e Tecnologie Industriali per il Manifatturiero Avanzato Consiglio Nazionale delle Ricerche, Milano, Italia; Istituto di Sistemi e Tecnologie Industriali per il Manifatturiero Avanzato Consiglio Nazionale delle Ricerche, Milano, Italia; Istituto di Sistemi e Tecnologie Industriali per il Manifatturiero Avanzato Consiglio Nazionale delle Ricerche, Milano, Italia; Centro Protesi Inail, Vigorso di Budrio, Bologna, Italy; Istituto di Sistemi e Tecnologie Industriali per il Manifatturiero Avanzato Consiglio Nazionale delle Ricerche, Milano, Italia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341674/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=399534569890688930&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Consiglio Nazionale delle Ricerche;Centro Protesi Inail",
        "aff_unique_dep": "Istituto di Sistemi e Tecnologie Industriali per il Manifatturiero Avanzato;",
        "aff_unique_url": "https://www.cnr.it;",
        "aff_unique_abbr": "CNR;",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Milano;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9340738",
        "title": "A Mobile Robot Hand-Arm Teleoperation System by Vision and IMU",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a multimodal mobile teleoperation system that consists of a novel vision-based hand pose regression network (Transteleop) and an IMU (inertial measurement units)-based arm tracking method. Transteleop observes the human hand through a low-cost depth camera and generates not only joint angles but also depth images of paired robot hand poses through an image-to-image translation process. A keypoint-based reconstruction loss explores the resemblance in appearance and anatomy between human and robotic hands and enriches the local features of reconstructed images. A wearable camera holder enables simultaneous hand-arm control and facilitates the mobility of the whole teleoperation system. Network evaluation results on a test dataset and a variety of complex manipulation tasks that go beyond simple pick-and-place operations show the efficiency and stability of our multimodal teleoperation system.",
        "primary_area": "",
        "author": "Shuang Li;Jiaxi Jiang;Philipp Ruppel;Hongzhuo Liang;Xiaojian Ma;Norman Hendrich;Fuchun Sun;Jianwei Zhang;Shuang Li;Jiaxi Jiang;Philipp Ruppel;Hongzhuo Liang;Xiaojian Ma;Norman Hendrich;Fuchun Sun;Jianwei Zhang",
        "authorids": "/37086938152;/37088688351;/37086456160;/37086700920;/37086936937;/37449613700;/37279269000;/37281460600;/37086938152;/37088688351;/37086456160;/37086700920;/37086936937;/37449613700;/37279269000;/37281460600",
        "aff": "Department of Informatics, TAMS (Technical Aspects of Multimodal Systems), Universit\u00e4t Hamburg; Department of Computer Science, RWTH Aachen University; Department of Informatics, TAMS (Technical Aspects of Multimodal Systems), Universit\u00e4t Hamburg; Department of Informatics, TAMS (Technical Aspects of Multimodal Systems), Universit\u00e4t Hamburg; Department of Statistics, Center for Vision, Cognition, Learning and Autonomy, University of California, Los Angeles; Department of Informatics, TAMS (Technical Aspects of Multimodal Systems), Universit\u00e4t Hamburg; Department of Computer Science and Technology, Beijing National Research Center for Information Science and Technology (BNRist), State Key Lab on Intelligent Technology and Systems, Tsinghua University; Department of Informatics, TAMS (Technical Aspects of Multimodal Systems), Universit\u00e4t Hamburg",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340738/",
        "gs_citation": 75,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13727051659149602629&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;0;0;2;0;3;0",
        "aff_unique_norm": "Universit\u00e4t Hamburg;RWTH Aachen University;University of California, Los Angeles;Tsinghua University",
        "aff_unique_dep": "Department of Informatics;Department of Computer Science;Department of Statistics;Department of Computer Science and Technology",
        "aff_unique_url": "https://www.uni-hamburg.de;https://www.rwth-aachen.de;https://www.ucla.edu;https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "UHH;RWTH;UCLA;Tsinghua",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";Aachen;Los Angeles",
        "aff_country_unique_index": "0;0;0;0;1;0;2;0",
        "aff_country_unique": "Germany;United States;China"
    },
    {
        "id": "9341194",
        "title": "A Model for Optimising the Size of Climbing Robots for Navigating Truss Structures",
        "track": "main",
        "status": "Poster",
        "abstract": "Truss structures can be found in many buildings and civil infrastructure such as bridges and towers. But as these architectures age, their maintenance is required to keep them structurally sound. A legged robotic solution capable of climbing these structures for maintenance is sought, but determining the size and shape of such a robot to maximise structure coverage is a challenging task. This paper proposes a model in which the size of a multi-legged robot is optimised for coverage in a truss structure. A detailed representation of a truss structure is presented, which forms the novel framework for constraint modelling. With this framework, the overall truss structure coverage is modelled, given a robot's size and its climbing performance constraints. This is set up as an optimisation problem, such that its solution represents the optimum size of the robot that satisfies all constraints. Three case studies of practical climbing applications are conducted to verify the model. By intuitive analysis of the model's output data, the results show that the model accurately applies these constraints in a variety of truss structures.",
        "primary_area": "",
        "author": "Wesley Au;Tomoki Sakaue;Dikai Liu;Wesley Au;Tomoki Sakaue;Dikai Liu",
        "authorids": "/37088688064;/37086227409;/37290601500;/37088688064;/37086227409;/37290601500",
        "aff": "Faculty of Engineering and IT, Centre for Autonomous Systems, University of Technology Sydney, Ultimo New South Wales, Australia; Tokyo Electric Power Company Holdings, Inc., Yokohama, Japan; Faculty of Engineering and IT, Centre for Autonomous Systems, University of Technology Sydney, Ultimo New South Wales, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341194/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12258952566374754149&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Technology Sydney;Tokyo Electric Power Company Holdings, Inc.",
        "aff_unique_dep": "Faculty of Engineering and IT, Centre for Autonomous Systems;",
        "aff_unique_url": "https://www.uts.edu.au;https://www.tepco.co.jp",
        "aff_unique_abbr": "UTS;TEPCO",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Ultimo;Yokohama",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Australia;Japan"
    },
    {
        "id": "9341255",
        "title": "A Model-Free Solution for Stable Balancing and Locomotion of Floating-base Legged Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents novel control techniques for passivation and stabilisation of floating-base systems with contacts, whose dynamical models comprise both joint-space, and Cartesian floating-base coordinates. The aforementioned results are achieved using both minimally model-based, and completely model-free controllers that employ power-shaping signals. Model-free control is permitted through usage of a decoupled dynamical model, procured via coordinate transformation operations. It is demonstrated that even though passive closed-loop systems are attainable without utilisation of exteroceptive feedback, global stabilisation of a floating-base robot necessitates direct usage of either measured or estimated external forces. The presented asymptotical stabilisation results pertain to both the set-point regulation, and trajectory-tracking cases, thereby ensuring suitability for static balancing, and dynamical locomotion tasks. To ensure practicability and production of feasible input signals, a variable impedance control, power-shaping term is appended to the original design, wherein it circumstantially serves as either a power-dissipating, or power-injecting element. This enhancement provably preserves closed-loop stability, by appositely shaping the system's power. Experiments involving a metamorphic, quadrupedal walking robot, corroborate the theoretical analysis, as they attest to the system's ability to stably execute locomotory tasks using a single, unified, model-free control scheme.",
        "primary_area": "",
        "author": "Emmanouil Spyrakos-Papastavridis;Jian S. Dai;Emmanouil Spyrakos-Papastavridis;Jian S. Dai",
        "authorids": "/38287238900;/37398454800;/38287238900;/37398454800",
        "aff": "Dyson School of Design Engineering, Imperial College London, London, United Kingdom; Department of Engineering, King\u2019s College London, London, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341255/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5639504450654282596&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Imperial College London;King\u2019s College London",
        "aff_unique_dep": "Dyson School of Design Engineering;Department of Engineering",
        "aff_unique_url": "https://www.imperial.ac.uk;https://www.kcl.ac.uk",
        "aff_unique_abbr": "Imperial College;KCL",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9341437",
        "title": "A Model-based Approach to Acoustic Reflector Localization with a Robotic Platform",
        "track": "main",
        "status": "Poster",
        "abstract": "Constructing a spatial map of an indoor environment, e.g., a typical office environment with glass surfaces, is a difficult and challenging task. Current state-of-the-art, e.g., camera- and laser-based approaches are unsuitable for detecting transparent surfaces. Hence, the spatial map generated with these approaches are often inaccurate. In this paper, a method that utilizes echolocation with sound in the audible frequency range is proposed to robustly localize the position of an acoustic reflector, e.g., walls, glass surfaces etc., which could be used to construct a spatial map of an indoor environment as the robot moves. The proposed method estimate the acoustic reflector's position, using only a single microphone and a loudspeaker that are present on many socially assistive robot platforms such as the NAO robot. The experimental results show that the proposed method could robustly detect an acoustic reflector up to a distance of 1.5 m in more than 60% of the trials and works efficiently even under low SNRs. To test the proposed method, a proof-of-concept robotic platform was build to construct a spatial map of an indoor environment.",
        "primary_area": "",
        "author": "Usama Saqib;Jesper Rindom Jensen;Usama Saqib;Jesper Rindom Jensen",
        "authorids": "/37087086237;/37088686311;/37087086237;/37088686311",
        "aff": "Audio Analysis Lab, CREATE, Aalborg University, Aalborg, Denmark; Audio Analysis Lab, CREATE, Aalborg University, Aalborg, Denmark",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341437/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14597425569109602438&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Aalborg University",
        "aff_unique_dep": "Audio Analysis Lab",
        "aff_unique_url": "https://www.aau.dk",
        "aff_unique_abbr": "AAU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Aalborg",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Denmark"
    },
    {
        "id": "9340980",
        "title": "A Momentum-Based Foot Placement Strategy for Stable Postural Control of Robotic Spring-Mass Running with Point Feet",
        "track": "main",
        "status": "Poster",
        "abstract": "A long-standing argument in model-based control of locomotion is about the level of complexity that a model should have to define a behavior such as running. Even though a goldilocks model based on biomechanical evidence is often sought, it is unclear what level of complexity qualifies to be such a model. This dilemma deepens further for bipedal robotic running with point feet, since these robots are underactuated. When center-of-mass (COM) trajectories defined by the spring-loaded inverted pendulum (SLIP) model are fully tracked, angular coordinates of the robot's trunk become uncontrolled. Existing work in the literature approach this problem either by trading off COM trajectory tracking against upright trunk posture during stance or by adopting more detailed models that include effects of trunk angular dynamics. In this paper, we present a new approach based on modifying foot placement targets of the SLIP model. Theoretical analysis and numerical results show that the proposed approach can be alternative to existing strategies.",
        "primary_area": "",
        "author": "Gorkem Secer;Ali Levent Cinar;Gorkem Secer;Ali Levent Cinar",
        "authorids": "/38234973700;/37088686920;/38234973700;/37088686920",
        "aff": "Laboratory of Computational Sensing and Robotics, Johns Hopkins University, Baltimore, MD, USA; Department of Mechanical Engineering, METU, Ankara, Turkey",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340980/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7002992274639125381&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Johns Hopkins University;Middle East Technical University",
        "aff_unique_dep": "Laboratory of Computational Sensing and Robotics;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.jhu.edu;https://www.metu.edu.tr",
        "aff_unique_abbr": "JHU;METU",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Baltimore;Ankara",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "United States;Turkey"
    },
    {
        "id": "9340745",
        "title": "A Multi-Contact Motion Planning and Control Strategy for Physical Interaction Tasks Using a Humanoid Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a framework providing a full pipeline to execute a complex physical interaction behaviour of a humanoid bipedal robot, both from a theoretical and a practical standpoint. Building from a multi-contact control architecture that combines contact planning and reactive force distribution capabilities, the main contribution of this work consists in the integration of a sample-based motion planning layer conceived for transitioning movements where obstacle and self-collisions avoidance is involved. To plan these motions we use Rapidly Exploring Random Tree (RRT) projected on the contacts manifold and validated through the Centroidal Statics (CS) model, to ensure static balance on non-coplanar surfaces. Finally, we successfully validate the presented planning and control architecture on the humanoid robot COMAN+ performing a wall-plank task.",
        "primary_area": "",
        "author": "Francesco Ruscelli;Matteo Parigi Polverini;Arturo Laurenzi;Enrico Mingo Hoffman;Nikos G. Tsagarakis;Francesco Ruscelli;Matteo Parigi Polverini;Arturo Laurenzi;Enrico Mingo Hoffman;Nikos G. Tsagarakis",
        "authorids": "/37086034535;/37085589882;/37086141170;/37085377101;/37295830800;/37086034535;/37085589882;/37086141170;/37085377101;/37295830800",
        "aff": "DIBRIS, Universit\u00e0 di Genova, Italy; Department of Advanced Robotics, Istituto Italiano di Tecnologia (IIT), Genova; Department of Advanced Robotics, Istituto Italiano di Tecnologia (IIT), Genova; Department of Advanced Robotics, Istituto Italiano di Tecnologia (IIT), Genova; Department of Advanced Robotics, Istituto Italiano di Tecnologia (IIT), Genova",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340745/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9555916956588577983&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;1",
        "aff_unique_norm": "Universit\u00e0 di Genova;Istituto Italiano di Tecnologia",
        "aff_unique_dep": "DIBRIS;Department of Advanced Robotics",
        "aff_unique_url": "https://www.unige.it;https://www.iit.it",
        "aff_unique_abbr": ";IIT",
        "aff_campus_unique_index": "1;1;1;1",
        "aff_campus_unique": ";Genova",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9341478",
        "title": "A Multi-link In-pipe Inspection Robot Composed of Active and Passive Compliant Joints",
        "track": "main",
        "status": "Poster",
        "abstract": "AIRo-5.1 an in-pipe inspection robot comprised of two passive compliant joints and a single active compliant joint that is driven by a series elastic actuator (SEA) is presented in the course of this study. As an aid in pipeline maintenance, AIRo-5.1 controls joint angles and the torque of middle joints, to enable them to adapt to bend, branch, vertical pipes, and slippery surfaces. To sense the joint torques, an improved durable polyurethane rubber spring was installed. To smoothly pass through T-branches, the angle trajectory of middle joints was calculated based on the pipe geometry and thus, was interpolated using a cosine curve. Experiments to verify robot performance in bent and T-branch pipes, its joint angle and torque control was conducted.",
        "primary_area": "",
        "author": "Atsushi Kakogawa;Shugen Ma;Atsushi Kakogawa;Shugen Ma",
        "authorids": "/37846134700;/37280187400;/37846134700;/37280187400",
        "aff": "Department of Robotics, Faculty of Science and Engineering, Ritsumeikan University, Shiga, JAPAN; Department of Robotics, Faculty of Science and Engineering, Ritsumeikan University, Shiga, JAPAN",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341478/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16475679436855650567&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Ritsumeikan University",
        "aff_unique_dep": "Department of Robotics",
        "aff_unique_url": "https://www.ritsumei.ac.jp",
        "aff_unique_abbr": "Ritsumeikan",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Shiga",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9341059",
        "title": "A Multigait Stringy Robot with Bi-stable Soft-bodied Structures in Multiple Viscous Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "The exploration of spatially limited terrestrial or aquatic environments requires miniature and lightweight robots. Soft-bodied robot research is paving ways for a new class of small-scale robots that can navigate a variety of environments with minimum influence on the environment itself. However, it is generally challenging to design miniature soft-bodied robots that efficiently adapt to the change between viscous environments. A small-scale soft-bodied robot, which could slowly move on dry land, will need rapid motions to be able to swim in a wet environment. Although using snap-through buckling of a deformable body could help to create swift motions of the robot, merely applying the snap-through buckling does not improve the swimming speed of the robot so much. Here we propose a design of a stringy soft-bodied robot that can crawl on dry surfaces and swim in liquid environments. Besides taking advantage of the snap-through buckling using coil shape memory alloys (SMAs), we design the body of the robot with a geometrical overlapping of the active body segments and control the frequency of the undulation movement, which is crucial for the swimming locomotion. We evaluate the performance of the robot in different density and viscosity liquids such as cooking oil and Glycerin solution. We found that the robot needs to drastically change its undulation from low to high frequency when it moves from high to low viscosity environments. Our robot can swim at a speed of 3. 37 body-lengths per minute (BL/min) and crawl at a speed of 1. 74 BL/min. We anticipate our findings will help shed light on the design of soft-bodied robots that adapt to the changing environments efficiently.",
        "primary_area": "",
        "author": "Tung D. Ta;Takuya Umedachi;Yoshihiro Kawahara;Tung D. Ta;Takuya Umedachi;Yoshihiro Kawahara",
        "authorids": "/37086454689;/37546535500;/37269138700;/37086454689;/37546535500;/37269138700",
        "aff": "Graduate School of Engineering, The University of Tokyo, Tokyo, Japan; Falcuty ofTextile Science and Technology, Shinshu University, Ueda, Nagano, Japan; Graduate School of Engineering, The University of Tokyo, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341059/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1767372458136705886&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "The University of Tokyo;Shinshu University",
        "aff_unique_dep": "Graduate School of Engineering;Department of Textile Science and Technology",
        "aff_unique_url": "https://www.u-tokyo.ac.jp;https://www.shinshu-u.ac.jp",
        "aff_unique_abbr": "UTokyo;Shinshu U",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Tokyo;Ueda",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9340707",
        "title": "A Neural Primitive model with Sensorimotor Coordination for Dynamic Quadruped Locomotion with Malfunction Compensation",
        "track": "main",
        "status": "Poster",
        "abstract": "In the field of quadruped locomotion, dynamic locomotion behavior, and rich integration with sensory feedback represents a significant development. In this paper, we present an efficient neural model, which includes CPG and its sensorimotor coordination, and demonstrate its implementation in a quadruped robot to show how efficient integration of motor and sensory feedback can generate dynamic behavior and how sensorimotor coordination reconstructs the sensory network for leg malfunction compensation. Additionally, we delineate a network optimization strategy and suggest sensorimotor coordination as a strategy for controlling speed and regulating internal and external adaptation. The rhythm generation representing the leg injury was inactive, stimulating the sensorimotor system to reconstruct the network between CPG and feet force afferent without any commanding parameter. The performances of the simulated and real, cat-like robot on both flat and rough terrains and the leg malfunction tests demonstrated the effectiveness of the proposed model, indicating that a smooth gait-pattern transition could be generated during sudden leg malfunction.",
        "primary_area": "",
        "author": "Azhar Aulia Saputra;Auke Jan Ijspeert;Naoyuki Kubota;Azhar Aulia Saputra;Auke Jan Ijspeert;Naoyuki Kubota",
        "authorids": "/37085403752;/37268732300;/37275324300;/37085403752;/37268732300;/37275324300",
        "aff": "Graduate School of System Design, Tokyo Metropolitan University, Tokyo, Japan; Biorobotics Laboratory, Ecole Polytechnique F\u00e9deral\u00e9 de Lausanne, Switzerland; Graduate School of System Design, Tokyo Metropolitan University, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340707/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6528118117799981725&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Tokyo Metropolitan University;Ecole Polytechnique F\u00e9derale de Lausanne",
        "aff_unique_dep": "Graduate School of System Design;Biorobotics Laboratory",
        "aff_unique_url": "https://www.tmuedu.net;https://www.epfl.ch",
        "aff_unique_abbr": "TMU;EPFL",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Tokyo;",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Japan;Switzerland"
    },
    {
        "id": "9341375",
        "title": "A New Delayless Adaptive Oscillator for Gait Assistance",
        "track": "main",
        "status": "Poster",
        "abstract": "To obtain synchronized gait assistance, this paper presents a new delayless adaptive dual-oscillator (ADO) scheme to address the inherent delay issue. In the ADO structure, a new oscillator is coupled with the primitive one but the phase is adaptively feed-forward compensated. It\u2019s remarkable that the compensated phase is determined by the proposed extended phase lag observer, in which both the phase lag and phase leading can be properly estimated and eliminated in the steady and non-steady gait. Moreover, a unified exoskeleton control scheme based on ADO is further proposed to improve the gait segmentation, velocity/acceleration estimation, intention estimation, and assistance generation performances, which further enhances the assistance synergy and reduces the safety risks. Experimental results demonstrate better alignment assistance and consequently reduced muscle efforts with ADO-based assistance control.",
        "primary_area": "",
        "author": "Tao Xue;Ziwei Wang;Tao Zhang;Ou Bai;Meng Zhang;Bin Han;Tao Xue;Ziwei Wang;Tao Zhang;Ou Bai;Meng Zhang;Bin Han",
        "authorids": "/37085381580;/37086179280;/37288851000;/37275492700;/37086799676;/37086433182;/37085381580;/37086179280;/37288851000;/37275492700;/37086799676;/37086433182",
        "aff": "Department of Automation, Tsinghua University, Beijing, China; Department of Automation, Tsinghua University, Beijing, China; Department of Automation, Tsinghua University, Beijing, China; Department of Electrical and Computer Engineering, Florida International University, Miami, FL, USA; Move Robotics Technology Company, Ltd, Shanghai, China; School of Mechanical Science and Engineering, Huazhong University of Science and Technology, Wuhan, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341375/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=741186610737452883&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;2;3",
        "aff_unique_norm": "Tsinghua University;Florida International University;Move Robotics Technology Company, Ltd;Huazhong University of Science and Technology",
        "aff_unique_dep": "Department of Automation;Department of Electrical and Computer Engineering;;School of Mechanical Science and Engineering",
        "aff_unique_url": "https://www.tsinghua.edu.cn;https://www.fiu.edu;;http://www.hust.edu.cn",
        "aff_unique_abbr": "THU;FIU;;HUST",
        "aff_campus_unique_index": "0;0;0;1;3",
        "aff_campus_unique": "Beijing;Miami;;Wuhan",
        "aff_country_unique_index": "0;0;0;1;0;0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9340975",
        "title": "A Novel Endoscope Design Using Spiral Technique for Robotic-Assisted Endoscopy Insertion",
        "track": "main",
        "status": "Poster",
        "abstract": "Gastrointestinal (GI) endoscopy is a conventional and prevalent procedure used to diagnose and treat diseases in the digestive tract. This procedure requires inserting an endoscope equipped with a camera and instruments inside a patient to the target of interest. To manoeuvre the endoscope, an endoscopist would rotate the knob at the handle to change the direction of the distal tip and apply the feeding force to advance the endoscope. However, due to the nature of the design, this often causes a looping problem during insertion making it difficult to be further advanced to the deeper section of the tract such as the transverse and ascending colon. To this end, in this paper, we propose a novel robotic endoscope which is covered by a rotating screw-like sheath and uses a spiral insertion technique to generate 'pull' forces at the distal tip of the endoscope to facilitate insertion. The whole shaft of the endoscope can be actively rotated, providing the crawling ability from the attached spiral sheath. With the redundant control on a spring-like continuum joint, the bending tip is capable of maintaining its orientation to assist endoscope navigation. To test its functions and feasibility to address the looping problem, three experiments were carried out. The first two experiments were to analyse the kinematic of the device and test the ability of the device to hold its distal tip at different orientation angles during spiral insertion. In the third experiment, we inserted the device in the bent colon phantom to evaluate the effectiveness of the proposed design against looping when advancing through a curved section of a colon. Results show the moving ability using spiral technique and verify its potential of clinical application.",
        "primary_area": "",
        "author": "Wei Li;Ya-Yen Tsai;Guang-Zhong Yang;Benny Lo;Wei Li;Ya-Yen Tsai;Guang-Zhong Yang;Benny Lo",
        "authorids": "/37086577761;/37086935862;/37276270800;/38183567000;/37086577761;/37086935862;/37276270800;/38183567000",
        "aff": "Hamlyn Centre for Robotic Surgery, Imperial College London, London, UK; Hamlyn Centre for Robotic Surgery, Imperial College London, London, UK; Institute of Medical Robotics, Shanghai Jiao Tong University, Shanghai, P.R. China; Hamlyn Centre for Robotic Surgery, Imperial College London, London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340975/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7581586713379115709&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Imperial College London;Shanghai Jiao Tong University",
        "aff_unique_dep": "Hamlyn Centre for Robotic Surgery;Institute of Medical Robotics",
        "aff_unique_url": "https://www.imperial.ac.uk;https://www.sjtu.edu.cn",
        "aff_unique_abbr": "ICL;SJTU",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "London;Shanghai",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "United Kingdom;China"
    },
    {
        "id": "9341686",
        "title": "A Novel Inverse Kinematics Method for Upper-Limb Exoskeleton under Joint Coordination Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "In this study, we address the inverse kinematics problem for an upper-limb exoskeleton by presenting a novel method that guarantees the satisfaction of joint-space constraints, and solves closed-chain mechanisms in a serial robot configuration. Starting from the conventional differential kinematics method based on the inversion of the Jacobian matrix, we describe and test two improved algorithms based on the Projected-Gradient method, that take into account joint-space equality constraints. We use the Harmony exoskeleton as a platform to demonstrate the method. Specifically, we address the joint constraints that the robot maintains in order to match anatomical shoulder movement and the closed-chain mechanisms used for the robot's joint control. Results show good performances of the proposed algorithms, which are confirmed by the ability of the robot to follow the desired task-space trajectory while ensuring the fulfilment of joint-space constraints, with a maximum error of about 0.05 degrees.",
        "primary_area": "",
        "author": "Stefano Dalla Gasperina;Keya Ghonasgi;Ana C. de Oliveira;Marta Gandolla;Alessandra Pedrocchi;Ashish Deshpande;Stefano Dalla Gasperina;Keya Ghonasgi;Ana C. de Oliveira;Marta Gandolla;Alessandra Pedrocchi;Ashish Deshpande",
        "authorids": "/37086481289;/37086480491;/37086396993;/37085903691;/38264002900;/37405479700;/37086481289;/37086480491;/37086396993;/37085903691;/38264002900;/37405479700",
        "aff": "Department of Electronics, Information and Bioengineering, NearLab, Politecnico di Milano, Italy; Department of Mechanical Engineering, ReNeu Lab, University of Texas, Austin, TX, USA; Department of Mechanical Engineering, ReNeu Lab, University of Texas, Austin, TX, USA; Department of Electronics, Information and Bioengineering, NearLab, Politecnico di Milano, Italy; Department of Electronics, Information and Bioengineering, NearLab, Politecnico di Milano, Italy; Department of Mechanical Engineering, ReNeu Lab, University of Texas, Austin, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341686/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1238327300295917394&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;0;0;1",
        "aff_unique_norm": "Politecnico di Milano;University of Texas at Austin",
        "aff_unique_dep": "Department of Electronics, Information and Bioengineering;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.polimi.it;https://www.utexas.edu",
        "aff_unique_abbr": "Politecnico di Milano;UT Austin",
        "aff_campus_unique_index": "1;1;1",
        "aff_campus_unique": ";Austin",
        "aff_country_unique_index": "0;1;1;0;0;1",
        "aff_country_unique": "Italy;United States"
    },
    {
        "id": "9341566",
        "title": "A Novel Trajectory Optimization for Affine Systems: Beyond Convex-Concave Procedure",
        "track": "main",
        "status": "Poster",
        "abstract": "Trajectory optimization problems under affine motion model and convex cost function are often solved through the convex-concave procedure (CCP), wherein the non-convex collision avoidance constraints are replaced with its affine approximation. Although mathematically rigorous, CCP has some critical limitations. First, it requires a collision-free initial guess of solution trajectory which is difficult to obtain, especially in dynamic environments. Second, at each iteration, CCP involves solving a convex constrained optimization problem which becomes prohibitive for real-time computation even with a moderate number of obstacles, if long planning horizons are used.In this paper, we propose a novel trajectory optimizer which like CCP involves solving convex optimization problems but can work with an arbitrary initial guess. Moreover, the proposed optimizer can be computationally upto a few orders of magnitude faster than CCP while achieving similar or better optimal cost. The reduced computation time, in turn, stems from some interesting mathematical structures in the optimizer which allows for distributed computation and obtaining solutions in symbolic form. We validate our claims on difficult benchmarks consisting of static and dynamic obstacles.",
        "primary_area": "",
        "author": "Fatemeh Rastgar;Arun Kumar Singh;Houman Masnavi;Karl Kruusamae;Alvo Aabloo;Fatemeh Rastgar;Arun Kumar Singh;Houman Masnavi;Karl Kruusamae;Alvo Aabloo",
        "authorids": "/37086436834;/38237873200;/37088687300;/37085528953;/37565214600;/37086436834;/38237873200;/37088687300;/37085528953;/37565214600",
        "aff": "Institute of Technology, University of Tartu; Institute of Technology, University of Tartu; Institute of Technology, University of Tartu; Institute of Technology, University of Tartu; Institute of Technology, University of Tartu",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341566/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16869971092143497816&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Tartu",
        "aff_unique_dep": "Institute of Technology",
        "aff_unique_url": "https://www.ut.ee",
        "aff_unique_abbr": "UT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Estonia"
    },
    {
        "id": "9341320",
        "title": "A POMDP Treatment of Vehicle-Pedestrian Interaction: Implicit Coordination via Uncertainty-Aware Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Drivers and other road users often encounter situations (e.g., arriving at an intersection simultaneously) where priority is ambiguous or unclear but must be resolved via communication to reach agreement. This poses a challenge for autonomous vehicles, for which no direct means for expressing intent and acknowledgment has yet been established. This paper contributes a minimal model to manage ambiguity and produce actions that are expressive and encode aspects of intent. Specifically, intent is treated as a latent variable, communicated implicitly through a partially observable Markov decision process (POMDP). We validate the model in a simple setting: a simulation of a prototypical crossing with a vehicle and one pedestrian at an unsignalized intersection. We further report use of our self-driving Ford Lincoln MKZ platform, through which we conducted experimental trials of the method involving real-time interaction. The experiment shows the method achieves safe and efficient navigation.",
        "primary_area": "",
        "author": "Ya-Chuan Hsu;Swaminathan Gopalswamy;Srikanth Saripalli;Dylan A. Shell;Ya-Chuan Hsu;Swaminathan Gopalswamy;Srikanth Saripalli;Dylan A. Shell",
        "authorids": "/37086814316;/38190877000;/37278939200;/37269198900;/37086814316;/38190877000;/37278939200;/37269198900",
        "aff": "Department of Computer Science and Engineering, Texas A & M University, College Station, TX, USA; Department of Mechanical Engineering, Texas A&M University, College Station, TX, USA; Department of Mechanical Engineering, Texas A&M University, College Station, TX, USA; Department of Computer Science and Engineering, Texas A & M University, College Station, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341320/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3327345278856446131&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "Texas A & M University;Texas A&M University",
        "aff_unique_dep": "Department of Computer Science and Engineering;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.tamu.edu;https://www.tamu.edu",
        "aff_unique_abbr": "TAMU;TAMU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "College Station",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341048",
        "title": "A Passivity-Based Bilateral Teleoperation Architecture using Distributed Nonlinear Model Predictive Control",
        "track": "main",
        "status": "Poster",
        "abstract": "Bilateral teleoperation systems allow the telepresence of an operator while working remotely. Such ability becomes crucial when dealing with critical environments like space, nuclear plants, rescue, and surgery. The main properties of a teleoperation system are the stability and the transparency which, in general, are in contrast and they cannot be fully achieved at the same time. In this paper, we will present a novel model predictive controller that implements a passivity-based bilateral teleoperation algorithm. Our solution mitigates the chattering issue arising when resorting to the energy tank (or reservoir) mechanism by forcing the passivity as a hard constraint on the system evolution.",
        "primary_area": "",
        "author": "Nicola Piccinelli;Riccardo Muradore;Nicola Piccinelli;Riccardo Muradore",
        "authorids": "/37086529418;/37299825000;/37086529418;/37299825000",
        "aff": "Department of Computer Science, University of Verona, Italy; Department of Computer Science, University of Verona, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341048/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18329283660489191628&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Verona",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.univr.it",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9340944",
        "title": "A Point Cloud Registration Pipeline using Gaussian Process Regression for Bathymetric SLAM",
        "track": "main",
        "status": "Poster",
        "abstract": "Point cloud registration is a means of achieving loop closure correction within a simultaneous localization and mapping (SLAM) algorithm. Data association is a critical component in point cloud registration, and can be very challenging in feature-depleted environments such as seabed. This paper presents a point cloud registration pipeline for performing loop closure correction in feature-depleted subsea environments using data collected from an optical scanner. The pipeline uses Gaussian process regression to extract keypoint sets, and a weighted network alignment algorithm to propose point correspondences. A variant of the iterative closest point (ICP) registration algorithm is used to perform fine alignment, with point correspondences informed by the mappings determined following the network alignment step. The developed registration pipeline is deployed with success on a challenging section of field data containing topography that cannot be resolved using conventional imaging sonar.",
        "primary_area": "",
        "author": "Thomas Hitchcox;James Richard Forbes;Thomas Hitchcox;James Richard Forbes",
        "authorids": "/37088569552;/37543396800;/37088569552;/37543396800",
        "aff": "Department of Mechanical Engineering, McGill University, Montreal, QC, Canada; Department of Mechanical Engineering, McGill University, Montreal, QC, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340944/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15368282987233962762&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "McGill University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.mcgill.ca",
        "aff_unique_abbr": "McGill",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Montreal",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9341468",
        "title": "A Probabilistic Model for Planar Sliding of Objects with Unknown Material Properties: Identification and Robust Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper introduces a new technique for learning probabilistic models of mass and friction distributions of unknown objects, and performing robust sliding actions by using the learned models. The proposed method is executed in two consecutive phases. In the exploration phase, a table-top object is poked by a robot from different angles. The observed motions of the object are compared against simulated motions with various hypothesized mass and friction models. The simulation-to-reality gap is then differentiated with respect to the unknown mass and friction parameters, and the analytically computed gradient is used to optimize those parameters. Since it is difficult to disentangle the mass from the friction coefficients in low-data and quasi-static motion regimes, our approach retains a set of locally optimal pairs of mass and friction models. A probability distribution on the models is computed based on the relative accuracy of each pair of models. In the exploitation phase, a probabilistic planner is used to select a goal configuration and waypoints that are stable with a high confidence. The proposed technique is evaluated on real objects and using a real manipulator. The results show that this technique can not only identify accurately mass and friction coefficients of non-uniform heterogeneous objects, but can also be used to successfully slide an unknown object to the edge of a table and pick it up from there, without any human assistance or feedback.",
        "primary_area": "",
        "author": "Changkyu Song;Abdeslam Boularias;Changkyu Song;Abdeslam Boularias",
        "authorids": "/37086556487;/37542596800;/37086556487;/37542596800",
        "aff": "Department of Computer Science, Rutgers University, Piscataway, New Jersey, USA; Department of Computer Science, Rutgers University, Piscataway, New Jersey, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341468/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8428606318360321380&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Rutgers University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.rutgers.edu",
        "aff_unique_abbr": "Rutgers",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Piscataway",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341064",
        "title": "A Probabilistic Shared-Control Framework for Mobile Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Full teleoperation of mobile robots during the execution of complex tasks not only demands high cognitive and physical effort but also generates less optimal trajectories compared to autonomous controllers. However, the use of the latter in cluttered and dynamically varying environments is still an open and challenging topic. This is due to several factors such as sensory measurement failures and rapid changes in task requirements. Shared-control approaches have been introduced to overcome these issues. However, these either present a strong decoupling that makes them still sensitive to unexpected events, or highly complex interfaces only accessible to expert users. In this work, we focus on the development of a novel and intuitive shared-control framework for target detection and control of mobile robots. The proposed framework merges the information coming from a teleoperation device with a stochastic evaluation of the desired goal to generate autonomous trajectories while keeping a human-in-control approach. This allows the operator to react in case of goal changes, sensor failures, or unexpected disturbances. The proposed approach is validated through several experiments both in simulation and in a real environment where the users try to reach a chosen goal in the presence of obstacles and unexpected disturbances. Operators receive both visual feedback of the environment and voice feedback of the goal estimation status while teleoperating a mobile robot through a control-pad. Results of the proposed method are compared to pure teleoperation proving a better time-efficiency and easiness-of-use of the presented approach.",
        "primary_area": "",
        "author": "Soheil Gholami;Virginia Ruiz Garate;Elena De Momi;Arash Ajoudani;Soheil Gholami;Virginia Ruiz Garate;Elena De Momi;Arash Ajoudani",
        "authorids": "/37085622074;/38251628900;/37947344300;/37945239900;/37085622074;/38251628900;/37947344300;/37945239900",
        "aff": "Dept. of Electronics, Information and Bioengineering, NearLab, Milan, Italy; Human-Robot Interfaces and physical Interaction (HRI2) Lab, Istituto Italiano di Tecnologia, Genoa, Italy; Dept. of Electronics, Information and Bioengineering, NearLab, Milan, Italy; Human-Robot Interfaces and physical Interaction (HRI2) Lab, Istituto Italiano di Tecnologia, Genoa, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341064/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=132080358702135996&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;1",
        "aff_unique_norm": "Politecnico di Milano;Istituto Italiano di Tecnologia",
        "aff_unique_dep": "Dept. of Electronics, Information and Bioengineering;Human-Robot Interfaces and physical Interaction (HRI2) Lab",
        "aff_unique_url": "https://www.polimi.it/;https://www.iit.it",
        "aff_unique_abbr": "Politecnico di Milano;IIT",
        "aff_campus_unique_index": "0;1;0;1",
        "aff_campus_unique": "Milan;Genoa",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9341200",
        "title": "A Robotic Gripper Design and Integrated Solution Towards Tunnel Boring Construction Equipment",
        "track": "main",
        "status": "Poster",
        "abstract": "Creative design of grippers on their configurations, mechatronics control system, and multi-component collaborative algorithms is often utilized to realize complex operations in industrial applications, due to the environmental constraints or specific task requirements. Firstly, this paper introduces the background problems. As the main automatic equipment -- the shield machine -- in the field of tunnel boring construction, needs frequent tool (cutter) replacement during underground process, but has no practical automatic method yet, due to heavy payload, complex environment and work procedure. Thus, an integrated solution was proposed by developing a specific gripper and a snake-like manipulator to accomplish tool replacement in a cooperative way. Through simple and unique design of relative components, the solution realizes a fully automatic and precise approach including heavy load tool grasping and regrasping, posture adjustment, unlocking and disassembly, and installation and locking. Finally, this paper also describes the experimental process of tool replacement by the prototype under a real working condition, and discusses the feasibility of putting the scheme into practical application through comparison.",
        "primary_area": "",
        "author": "Jianjun Yuan;Renming Guan;Liang Du;Shugen Ma;Jianjun Yuan;Renming Guan;Liang Du;Shugen Ma",
        "authorids": "/37293594200;/37086798534;/37087006997;/37280187400;/37293594200;/37086798534;/37087006997;/37280187400",
        "aff": "Shanghai Robotics Institute, Shanghai Key Laboratory of Intelligent Manufacturing and Robotics, School of Mechatronic Engineering and Automation, Shanghai University, China; Shanghai Jiao Tong University, China; Department of Robotics, Ritsumeikan University, Shiga, Japan; Department of Robotics, Ritsumeikan University, Shiga, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341200/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15584998706446154093&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;2",
        "aff_unique_norm": "Shanghai University;Shanghai Jiao Tong University;Ritsumeikan University",
        "aff_unique_dep": "School of Mechatronic Engineering and Automation;;Department of Robotics",
        "aff_unique_url": "https://www.shu.edu.cn;https://www.sjtu.edu.cn;https://www.ritsumeikan.ac.jp",
        "aff_unique_abbr": "SHU;SJTU;Ritsumeikan",
        "aff_campus_unique_index": "0;2;2",
        "aff_campus_unique": "Shanghai;;Shiga",
        "aff_country_unique_index": "0;0;1;1",
        "aff_country_unique": "China;Japan"
    },
    {
        "id": "9341604",
        "title": "A Robust Multi-Stereo Visual-Inertial Odometry Pipeline",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper we present a novel multi-stereo visual-inertial odometry (VIO) framework which aims to improve the robustness of a robot's state estimate during aggressive motion and in visually challenging environments. Our system uses a fixed-lag smoother which jointly optimizes for poses and landmarks across all stereo pairs. We propose a 1-point RANdom SAmple Consensus (RANSAC) algorithm which is able to perform outlier rejection across features from all stereo pairs. To handle the problem of noisy extrinsics, we account for uncertainty in the calibration of each stereo pair and model it in both our front-end and back-end. The result is a VIO system which is able to maintain an accurate state estimate under conditions that have typically proven to be challenging for traditional state-of-the-art VIO systems. We demonstrate the benefits of our proposed multi-stereo algorithm by evaluating it with both simulated and real world data. We show that our proposed algorithm is able to maintain a state estimate in scenarios where traditional VIO algorithms fail.",
        "primary_area": "",
        "author": "Joshua Jaekel;Joshua G. Mangelson;Sebastian Scherer;Michael Kaess;Joshua Jaekel;Joshua G. Mangelson;Sebastian Scherer;Michael Kaess",
        "authorids": "/37086136077;/37086109836;/37584159000;/37324200400;/37086136077;/37086109836;/37584159000;/37324200400",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341604/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=573776241186861675&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341419",
        "title": "A Scalable Framework for Robust Vehicle State Estimation with a Fusion of a Low-Cost IMU, the GNSS, Radar, a Camera and Lidar",
        "track": "main",
        "status": "Poster",
        "abstract": "Automated driving requires highly precise and robust vehicle state estimation for its environmental perception, motion planning and control functions. Using GPS and environmental sensors can compensate for the deficits of the estimation based on traditional vehicle dynamics sensors. However, each type of sensor has specific strengths and limitations in accuracy and robustness due to their different properties regarding the quality of detection and robustness in diverse environmental conditions. For these reasons, we present a scalable concept for vehicle state estimation using an error-state extended Kalman filter (ESEKF) to fuse classical vehicle sensors with environmental sensors. The state variables, i.e., position, velocity and orientation, are predicted by a 6-degree-of-freedom (DoF) vehicle kinematic model that uses a low-cost inertial measurement unit (IMU) on a customer vehicle. The Error of the 6-DoF rigid body motion model is estimated using observations of global position using the global navigation satellite system (GNSS) and of the environment using radar, a camera and low-cost lidar. Our concept is scalable such that it is compatible with different sensor setups on different vehicle configurations. The experimental results compare various sensor combinations with measurement data in scenarios such as dynamic driving maneuvers on a test field. The results show that our approach ensures accuracy and robustness with redundant sensor data under regular and dynamic driving conditions.",
        "primary_area": "",
        "author": "Yuran Liang;Steffen M\u00fcller;Daniel Schwendner;Daniel Rolle;Dieter Ganesch;Immanuel Schaffer;Yuran Liang;Steffen M\u00fcller;Daniel Schwendner;Daniel Rolle;Dieter Ganesch;Immanuel Schaffer",
        "authorids": "/37088688048;/37085819911;/37088691006;/37088690027;/37088688065;/37088688253;/37088688048;/37085819911;/37088691006;/37088690027;/37088688065;/37088688253",
        "aff": "BMW Group, Munich, Germany; Department Automotive Engineering, Faculty of Mechanical Engineering and Transport Systems, Technical University of Berlin, Berlin, Germany; BMW Group, Munich, Germany; BMW Group, Munich, Germany; BMW Group, Munich, Germany; BMW Group, Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341419/",
        "gs_citation": 37,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15734892335591381200&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;0;0;0",
        "aff_unique_norm": "BMW Group;Technical University of Berlin",
        "aff_unique_dep": ";Department Automotive Engineering",
        "aff_unique_url": "https://www.bmwgroup.com;https://www.tu-berlin.de",
        "aff_unique_abbr": "BMW;TU Berlin",
        "aff_campus_unique_index": "0;1;0;0;0;0",
        "aff_campus_unique": "Munich;Berlin",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9341080",
        "title": "A Soft Humanoid Hand with In-Finger Visual Perception",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a novel underactued humanoid five finger soft hand, the KIT Finger-Vision Soft Hand, which is equipped with cameras in the fingertips and integrates a high performance embedded system for visual processing and control. We describe the actuation mechanism of the hand and the tendon-driven soft finger design with internally routed high-bandwidth flat-flex cables. For efficient on-board parallel processing of visual data from the cameras in each fingertip, we present a hybrid embedded architecture consisting of a field programmable logic array (FPGA) and a microcontroller that allows the realization of visual object segmentation based on convolutional neural networks. We evaluate the hand design by conducting durability experiments with one finger and quantify the grasp performance in terms of grasping force, speed and grasp success. The results show that the hand exhibits a grasp force of 31.8 \u00b1 1.2 N and a mechanical durability of the finger of more than 15.000 closing cycles. Finally, we evaluate the accuracy of visual object segmentation during the different phases of the grasping process using five different objects. Hereby, an accuracy above 90% can be achieved.",
        "primary_area": "",
        "author": "Felix Hundhausen;Julia Starke;Tamim Asfour;Felix Hundhausen;Julia Starke;Tamim Asfour",
        "authorids": "/37086581259;/37086278005;/37295529100;/37086581259;/37086278005;/37295529100",
        "aff": "Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341080/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15522044397289917599&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Karlsruhe Institute of Technology",
        "aff_unique_dep": "Institute for Anthropomatics and Robotics",
        "aff_unique_url": "https://www.kit.edu",
        "aff_unique_abbr": "KIT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Karlsruhe",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9341138",
        "title": "A Soft, Modular, and Bi-stable Dome Actuator for Programmable Multi-Modal Locomotion",
        "track": "main",
        "status": "Poster",
        "abstract": "Movement in bio-inspired robots typically relies on the use of a series of actuators and transmissions with one or more degrees of freedom (DOF), allowing asymmetrical ellipsoidal gaits for use in walking, running, swimming, and crawling. In an effort to simplify these multi-component systems, we present a novel, modular, soft, bi-stable, one DOF dome actuator platform that is capable of complex gaits through mechanical programming, driven by simple periodic fluid input. With a modular, reconfigurable design, the end effectors of these bi-stable dome actuators can be quickly modified for use on a variety of surfaces for specific applications. In the present study, we describe the finite element modeling, manufacturing, and characterization of different end effectors and outline a workflow for the implementation of these soft bi-stable dome actuators for the production of functional robotic prototypes.",
        "primary_area": "",
        "author": "Michael A. Bell;Luca Cattani;Benjamin Gorissen;Katia Bertoldi;James C. Weaver;Robert J. Wood;Michael A. Bell;Luca Cattani;Benjamin Gorissen;Katia Bertoldi;James C. Weaver;Robert J. Wood",
        "authorids": "/37086352780;/37089140179;/37076614400;/37085470086;/37086352694;/37326227400;/37086352780;/37089140179;/37076614400;/37085470086;/37086352694;/37326227400",
        "aff": "John A. Paulson School of Engineering and Applied Sciences and the Wyss Institute for Biologically Inspired Engineering, Harvard University, Cambridge, MA, USA; Swiss Federal Institute of Technology Lausanne (EPFL), Switzerland; John A. Paulson School of Engineering and Applied Sciences and the Wyss Institute for Biologically Inspired Engineering, Harvard University, Cambridge, MA, USA; John A. Paulson School of Engineering and Applied Sciences and the Wyss Institute for Biologically Inspired Engineering, Harvard University, Cambridge, MA, USA; John A. Paulson School of Engineering and Applied Sciences and the Wyss Institute for Biologically Inspired Engineering, Harvard University, Cambridge, MA, USA; John A. Paulson School of Engineering and Applied Sciences and the Wyss Institute for Biologically Inspired Engineering, Harvard University, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341138/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2665760063844080466&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;0;0;0",
        "aff_unique_norm": "Harvard University;Swiss Federal Institute of Technology Lausanne",
        "aff_unique_dep": "John A. Paulson School of Engineering and Applied Sciences;",
        "aff_unique_url": "https://www.harvard.edu;https://www.epfl.ch",
        "aff_unique_abbr": "Harvard;EPFL",
        "aff_campus_unique_index": "0;1;0;0;0;0",
        "aff_campus_unique": "Cambridge;Lausanne",
        "aff_country_unique_index": "0;1;0;0;0;0",
        "aff_country_unique": "United States;Switzerland"
    },
    {
        "id": "9341407",
        "title": "A Study on the Elongation Behaviour of Synthetic Fibre Ropes under Cyclic Loading",
        "track": "main",
        "status": "Poster",
        "abstract": "Synthetic fibre ropes have high tensile strength, a lower friction coefficient and are more flexible than steel ropes, and are therefore increasingly used in robotics. However, their characteristics are not well studied. In particular, previous work investigated the long-term behaviour only under static loading. In this paper, we investigate the elongation behaviour of synthetic fibre ropes under cyclic loading. In particular, we use ropes made from Dyneema DM20 (UHMWPE) and Zylon AS (PBO), which according to prior work have low creep. While Dyneema is more widely used, Zylon has higher tensile strength. We could show that under cyclic loading the Dyneema DM20 rope elongated more than 9% and kept on extending even after 500 cycles. Zylon exhibited a more stable and lower elongation of less than 3%.",
        "primary_area": "",
        "author": "Deoraj Asane;Alexander Schmitz;Yushi Wang;Shigeki Sugano;Deoraj Asane;Alexander Schmitz;Yushi Wang;Shigeki Sugano",
        "authorids": "/37088689327;/37587110100;/37086156135;/37274050800;/37088689327;/37587110100;/37086156135;/37274050800",
        "aff": "Waseda University, Tokyo, Japan; Waseda University, Tokyo, Japan; Waseda University, Tokyo, Japan; Waseda University, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341407/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5652309288874704387&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Waseda University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.waseda.ac.jp",
        "aff_unique_abbr": "Waseda",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9341270",
        "title": "A Target Tracking and Positioning Framework for Video Satellites Based on SLAM",
        "track": "main",
        "status": "Poster",
        "abstract": "With the booming development in aerospace technology, the video satellite which observes the live phenomena on the ground by video shooting has gradually emerged as a new Earth observation method. And remote sensing comes into a \"dynamic\" era with the demand for new processing techniques, especially the near-real-time tracking and geo-positioning algorithm for ground moving targets. However, many researchers merely extract pixel-level trajectories in post-processed video products, resulting in fairly limited applications. We regard the video satellite as a robot flying in space and adopt the SLAM framework for the positioning of ground moving targets. The designed framework is based on the representative ORB-SLAM and we make improvements mainly in feature extraction, satellite pose estimation, moving target tracking and positioning. We coordinate a moving fishing boat with GPS-RTK (Real-time Kinematic) devices and a video satellite observing it simultaneously for verification and evaluation of our method. Experiments demonstrate that our framework provides reasonable geolocation of the moving target in satellite videos. Finally, some open problems and potential research directions are discussed.",
        "primary_area": "",
        "author": "Xuhui Zhao;Zhi Gao;Yongjun Zhang;Ben M. Chen;Xuhui Zhao;Zhi Gao;Yongjun Zhang;Ben M. Chen",
        "authorids": "/37088686578;/37085495662;/37676480900;/38520079900;/37088686578;/37085495662;/37676480900;/38520079900",
        "aff": "School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, China; School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, China; School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, China; Department of Mechanical and Automation Engineering, Chinese University of Hong Kong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341270/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10981096604729373323&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Wuhan University;Chinese University of Hong Kong",
        "aff_unique_dep": "School of Remote Sensing and Information Engineering;Department of Mechanical and Automation Engineering",
        "aff_unique_url": "http://www.whu.edu.cn/;https://www.cuhk.edu.hk",
        "aff_unique_abbr": "WHU;CUHK",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "Wuhan;Hong Kong",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9341613",
        "title": "A Theory of Fermat Paths for 3D Imaging Sonar Reconstruction",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we present a novel method for reconstructing particular 3D surface points using an imaging sonar sensor. We derive the two-dimensional Fermat flow equation, which may be applied to the planes defined by each discrete azimuth angle in the sonar image. We show that the Fermat flow equation applies to boundary points and surface points which correspond to specular reflections within the 2D plane defined by their azimuth angle measurement. The Fermat flow equation can be used to resolve the 2D location of these surface points within the plane, and therefore also their full 3D location. This is achieved by translating the sensor to estimate the spatial gradient of the range measurement. This method does not rely on the precise image intensity values or the reflectivity of the imaged surface to solve for the surface point locations. We demonstrate the effectiveness of our proposed method by reconstructing 3D object points on both simulated and real-world datasets.",
        "primary_area": "",
        "author": "Eric Westman;Ioannis Gkioulekas;Michael Kaess;Eric Westman;Ioannis Gkioulekas;Michael Kaess",
        "authorids": "/37085993534;/37595566500;/37324200400;/37085993534;/37595566500;/37324200400",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341613/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13515765010347216746&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341152",
        "title": "A Thermoplastic Elastomer Belt Based Robotic Gripper",
        "track": "main",
        "status": "Poster",
        "abstract": "Novel robotic grippers have captured increasing interests recently because of their abilities to adapt to varieties of circumstances and their powerful functionalities. Differing from traditional gripper with mechanical components-made fingers, novel robotic grippers are typically made of novel structures and materials, using a novel manufacturing process. In this paper, a novel robotic gripper with external frame and internal thermoplastic elastomer belt-made net is proposed. The gripper grasps objects using the friction between the net and objects. It has the ability of adaptive gripping through flexible contact surface. Stress simulation has been used to explore the regularity between the normal stress on the net and the deformation of the net. Experiments are conducted on a variety of objects to measure the force needed to reliably grip and hold the object. Test results show that the gripper can successfully grip objects with varying shape, dimensions, and textures. It is promising that the gripper can be used for grasping fragile objects in the industry or out in the field, and also grasping the marine organisms without hurting them.",
        "primary_area": "",
        "author": "Xingwen Zheng;Ningzhe Hou;Pascal Johannes Dani\u00ebl Dinjens;Ruifeng Wang;Chengyang Dong;Guangming Xie;Xingwen Zheng;Ningzhe Hou;Pascal Johannes Dani\u00ebl Dinjens;Ruifeng Wang;Chengyang Dong;Guangming Xie",
        "authorids": "/37085823629;/37088690844;/37088687236;/37088687021;/37088689697;/37270592800;/37085823629;/37088690844;/37088687236;/37088687021;/37088689697;/37270592800",
        "aff": "State Key Laboratory of Turbulence and Complex Systems, Intelligent Biomimetic Design Lab, College of Engineering, Peking University, Beijing, China; Department of Electrical and Electronic Engineering, The University of Manchester, Manchester, United Kingdom; Fontys University of Applied Sciences, Eindhoven, The Netherlands; Department of Electrical and Electronic Engineering, The University of Manchester, Manchester, United Kingdom; Department of Electrical and Electronic Engineering, The University of Manchester, Manchester, United Kingdom; Peng Cheng Laboratory, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341152/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4838449406591122987&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;1;1;3",
        "aff_unique_norm": "Peking University;The University of Manchester;Fontys University of Applied Sciences;Peng Cheng Laboratory",
        "aff_unique_dep": "College of Engineering;Department of Electrical and Electronic Engineering;;",
        "aff_unique_url": "http://www.pku.edu.cn;https://www.manchester.ac.uk;https://www.fontys.nl;",
        "aff_unique_abbr": "PKU;UoM;Fontys;",
        "aff_campus_unique_index": "0;1;2;1;1;3",
        "aff_campus_unique": "Beijing;Manchester;Eindhoven;Shenzhen",
        "aff_country_unique_index": "0;1;2;1;1;0",
        "aff_country_unique": "China;United Kingdom;Netherlands"
    },
    {
        "id": "9341259",
        "title": "A Time Optimal Reactive Collision Avoidance Method for UAVs Based on a Modified Collision Cone Approach",
        "track": "main",
        "status": "Poster",
        "abstract": "UAVs or Unmanned Aerial Vehicles are an upcoming technology which has eased human lifestyles in many ways. Due to this trend future skies have a risk of getting congested. In such a situation time optimal collision avoidance would be extremely vital to travel in a shortest possible time by avoiding collisions. The paper proposes a novel method for time optimal collision avoidance for UAVs. The proposed algorithm is constructed as a three-stage approach based on the Collision Cone method with slight modifications. A sliding mode controller is used as the control law for the navigation. Mathematical proofs are included to verify the time optimality of the proposed method. The efficiency and the applicability of the work carried out is confirmed by both simulation and experimental results. An automated Matrice 600 Pro hexacopter has been used for the experiments.",
        "primary_area": "",
        "author": "Manaram Gnanasekera;Jay Katupitiya;Manaram Gnanasekera;Jay Katupitiya",
        "authorids": "/37071784900;/37273422900;/37071784900;/37273422900",
        "aff": "Mechanical and Manufacturing Engineering, University of New South Wales, Sydney, Australia; Mechanical and Manufacturing Engineering, University of New South Wales, Sydney, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341259/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8528136056929666574&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of New South Wales",
        "aff_unique_dep": "Mechanical and Manufacturing Engineering",
        "aff_unique_url": "https://www.unsw.edu.au",
        "aff_unique_abbr": "UNSW",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Sydney",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "9340950",
        "title": "A Tip Mount for Transporting Sensors and Tools using Soft Growing Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Pneumatically operated soft growing robots that extend via tip eversion are well-suited for navigation in confined spaces. Adding the ability to interact with the environment using sensors and tools attached to the robot tip would greatly enhance the usefulness of these robots for exploration in the field. However, because the material at the tip of the robot body continually changes as the robot grows and retracts, it is challenging to keep sensors and tools attached to the robot tip during actuation and environment interaction. In this paper, we analyze previous designs for mounting to the tip of soft growing robots, and we present a novel device that successfully remains attached to the robot tip while providing a mounting point for sensors and tools. Our tip mount incorporates and builds on our previous work on a device to retract the robot without undesired buckling of its body. Using our tip mount, we demonstrate two new soft growing robot capabilities: (1) pulling on the environment while retracting, and (2) retrieving and delivering objects. Finally, we discuss the limitations of our design and opportunities for improvement in future soft growing robot tip mounts.",
        "primary_area": "",
        "author": "Sang-Goo Jeong;Margaret M. Coad;Laura H. Blumenschein;Ming Luo;Usman Mehmood;Ji Hun Kim;Allison M. Okamura;Jee-Hwan Ryu;Sang-Goo Jeong;Margaret M. Coad;Laura H. Blumenschein;Ming Luo;Usman Mehmood;Ji Hun Kim;Allison M. Okamura;Jee-Hwan Ryu",
        "authorids": "/37086574861;/37086124465;/37085849839;/37085452649;/38468003200;/37088688449;/37276156400;/37274994300;/37086574861;/37086124465;/37085849839;/37085452649;/38468003200;/37088688449;/37276156400;/37274994300",
        "aff": "School of Mechanical Engineering, Korea University of Technology and Education, Cheonan-si, Republic of Korea; Department of Mechanical Engineering, Stanford University, Stanford, CA, USA; Department of Mechanical Engineering, Stanford University, Stanford, CA, USA; Department of Mechanical Engineering, Stanford University, Stanford, CA, USA; School of Mechanical Engineering, Korea University of Technology and Education, Cheonan-si, Republic of Korea; School of Mechanical Engineering, Korea University of Technology and Education, Cheonan-si, Republic of Korea; Department of Mechanical Engineering, Stanford University, Stanford, CA, USA; Department of Civil and Environmental Engineering, KAIST, Daejeon, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340950/",
        "gs_citation": 54,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5674916406422268619&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;1;1;0;0;1;2",
        "aff_unique_norm": "Korea University of Technology and Education;Stanford University;KAIST",
        "aff_unique_dep": "School of Mechanical Engineering;Department of Mechanical Engineering;Department of Civil and Environmental Engineering",
        "aff_unique_url": "http://www.kut.ac.kr;https://www.stanford.edu;https://www.kaist.ac.kr",
        "aff_unique_abbr": "KUT;Stanford;KAIST",
        "aff_campus_unique_index": "0;1;1;1;0;0;1;2",
        "aff_campus_unique": "Cheonan-si;Stanford;Daejeon",
        "aff_country_unique_index": "0;1;1;1;0;0;1;0",
        "aff_country_unique": "South Korea;United States"
    },
    {
        "id": "9341740",
        "title": "A Topological Approach to Path Planning for a Magnetic Millirobot",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a path planning strategy for a magnetic millirobot where the nonlinearities in the external magnetic force field (MFF) are encoded in the graph used for planning. The strategy creates a library of candidate MFFs and characterizes their topologies by identifying the unstable manifolds in the workspace. The path planning problem is then posed as a graph search problem where the computed path consists of a sequence of unstable manifold segments and their associated MFFs. By tracking the robot's position and sequentially applying the MFFs, the robot navigates along each unstable manifold until it reaches the goal. We discuss the theoretical guarantees of the proposed strategy and experimentally validate the strategy.",
        "primary_area": "",
        "author": "Ariella Mansfield;Dhanushka Kularatne;Edward Steager;M. Ani Hsieh;Ariella Mansfield;Dhanushka Kularatne;Edward Steager;M. Ani Hsieh",
        "authorids": "/37088688381;/37085347782;/37396511400;/38238444800;/37088688381;/37085347782;/37396511400;/38238444800",
        "aff": "General Robotics, Automation, Sensing, and Perception (GRASP) Laboratory, University of Pennsylvania, Philadelphia, Pennsylvania, USA; General Robotics, Automation, Sensing, and Perception (GRASP) Laboratory, University of Pennsylvania, Philadelphia, Pennsylvania, USA; General Robotics, Automation, Sensing, and Perception (GRASP) Laboratory, University of Pennsylvania, Philadelphia, Pennsylvania, USA; General Robotics, Automation, Sensing, and Perception (GRASP) Laboratory, University of Pennsylvania, Philadelphia, Pennsylvania, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341740/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10117224761418171943&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Pennsylvania",
        "aff_unique_dep": "General Robotics, Automation, Sensing, and Perception (GRASP) Laboratory",
        "aff_unique_url": "https://www.upenn.edu",
        "aff_unique_abbr": "UPenn",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Philadelphia",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341554",
        "title": "A Two-Fingered Robot Gripper with Variable Stiffness Flexure Hinges Based on Shape Morphing",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel approach for developing robotic grippers with variable stiffness hinges for dexterous grasps. This approach for the first time uses pneumatically actuated pouch actuators to fold and unfold morphable flaps of flexure hinges thus change stiffness of the hinge. By varying the air pressure in pouch actuators, the flexure hinge morphs into a beam with various open sections while the flaps bend, enabling stiffness variation of the flexure hinge. This design allows 3D printing of the flexure hinge using printable soft filaments. Utilizing the variable stiffness flexure hinges as the joints of robotic fingers, a light-weight and low-cost two-fingered tendon driven robotic gripper is developed. The stiffness variation caused due to the shape morphing of flexure hinges is studied by conducting static tests on fabricated hinges with different flap angles and on a flexure hinge with flaps that are bent by pouch actuators subjected to various pressures. Multiple grasp modes of the two-fingered gripper are demonstrated by grasping objects with various geometric shapes. The gripper is then integrated with a robot manipulator in a teleoperation setup for conducting a pick-and-place operation in a confined environment.",
        "primary_area": "",
        "author": "Hareesh Godaba;Aqeel Sajad;Navin Patel;Kaspar Althoefer;Ketao Zhang;Hareesh Godaba;Aqeel Sajad;Navin Patel;Kaspar Althoefer;Ketao Zhang",
        "authorids": "/37085735503;/37088687450;/37088688080;/37265264700;/38005192300;/37085735503;/37088687450;/37088688080;/37265264700;/38005192300",
        "aff": "Centre for Advanced Robotics (ARQ), Queen Mary University of London; Centre for Advanced Robotics (ARQ), Queen Mary University of London; Centre for Advanced Robotics (ARQ), Queen Mary University of London; Centre for Advanced Robotics (ARQ), Queen Mary University of London; Centre for Advanced Robotics (ARQ), Queen Mary University of London",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341554/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7872925363474904864&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Queen Mary University of London",
        "aff_unique_dep": "Centre for Advanced Robotics (ARQ)",
        "aff_unique_url": "https://www.qmul.ac.uk",
        "aff_unique_abbr": "QMUL",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9341091",
        "title": "A Two-stage Automatic Latching System for The USVs Charging in Disturbed Berth",
        "track": "main",
        "status": "Poster",
        "abstract": "Automatic latching for charging in a disturbed environment for Unmanned Surface Vehicle (USVs) is always a challenging problem. In this paper, we propose a two-stage automatic latching system for USVs charging in berth. In Stage I, a vision-guided algorithm is developed to calculate an optimal latching position for charging. In Stage II, a novel latching mechanism is designed to compensate the movement misalignments from the water disturbance. A set of experiments have been conducted in real-world environments. The results show the latching success rate has been improved from 40% to 73.3% in the best cases with our proposed system. Furthermore, the vision-guided algorithm provides a methodology to optimize the design radius of the latching mechanism with respect to different disturbance levels accordingly. Outdoor experiments have validated the efficiency of our proposed automatic latching system. The proposed system improves the autonomy intelligence of the USVs and provides great benefits for practical applications.",
        "primary_area": "",
        "author": "Kaiwen Xue;Chongfeng Liu;Hengli Liu;Ruoyu Xu;Zhenglong Sun;Tin Lun Lam;Huihuan Qian;Kaiwen Xue;Chongfeng Liu;Hengli Liu;Ruoyu Xu;Zhenglong Sun;Tin Lun Lam;Huihuan Qian",
        "authorids": "/37086587142;/37087049736;/37086607474;/37087047735;/37086799406;/37571111600;/37549401900;/37086587142;/37087049736;/37086607474;/37087047735;/37086799406;/37571111600;/37549401900",
        "aff": "The Chinese University of Hong Kong, Shenzhen; The Chinese University of Hong Kong, Shenzhen; Peng Cheng Laboratory, Shenzhen, China; The Chinese University of Hong Kong, Shenzhen; The Chinese University of Hong Kong, Shenzhen; The Chinese University of Hong Kong, Shenzhen; The Chinese University of Hong Kong, Shenzhen",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341091/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12255363940005807708&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;1;0;0;0;0",
        "aff_unique_norm": "The Chinese University of Hong Kong;Peng Cheng Laboratory",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.cuhk.edu.cn;",
        "aff_unique_abbr": "CUHK;",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9341515",
        "title": "A Unique Identifier Assignment Method for Distributed Modular Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Modular robots are autonomous systems with variable morphology, composed of independent connected computational elements, called particles or modules. Due to critical resource constraints and limited capabilities, globally unique identifier (ID) assignment to each particle is a very challenging task in modular robots. However, having a unique ID in each one remains essential for various operations and applications in this domain. For instance, it is required to establish communications between nodes and implement routing protocols. It helps in saving energy consumption and enhancing the security mechanisms. In this paper, we propose a distributed unique ID assignment method for modular robots. It is a three phases based algorithm. The first phase consists in discovering the system while building a logical tree. The second phase finds the total size of particles in the system needed for several operations in modular robots, and the third one is dedicated to the unique ID assignment. After fully optimizing the distributed algorithm, the effects of various system shapes and leader positions on the energy and time complexity are studied, while proposing fitting solutions for different requirements.",
        "primary_area": "",
        "author": "Joseph Assaker;Abdallah Makhoul;Julien Bourgeois;Jacques Demerjian;Joseph Assaker;Abdallah Makhoul;Julien Bourgeois;Jacques Demerjian",
        "authorids": "/37088687915;/37300200900;/37545876400;/37281587100;/37088687915;/37300200900;/37545876400;/37281587100",
        "aff": "FEMTO-ST institute, Univ. Bourgogne Franche-Comt\u00e9, Montb\u00e9liard, France; FEMTO-ST institute, Univ. Bourgogne Franche-Comt\u00e9, Montb\u00e9liard, France; FEMTO-ST institute, Univ. Bourgogne Franche-Comt\u00e9, Montb\u00e9liard, France; LaRRIS, Faculty of Sciences, Lebanese University, Fanar, Lebanon",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341515/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10381211129278182198&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "FEMTO-ST institute;Lebanese University",
        "aff_unique_dep": ";Faculty of Sciences",
        "aff_unique_url": ";",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "Montb\u00e9liard;Fanar",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "France;Lebanon"
    },
    {
        "id": "9341725",
        "title": "A Variable Impedance Control Strategy for Object Manipulation Considering Non\u2013Rigid Grasp",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel control strategy for the compensation of the slippage effect during non-rigidly grasped object manipulation. A detailed dynamic model of the interconnected system composed of the robotic manipulator, the object and the internal forces and torques induced by the slippage effect is provided. Next, we design a model-based variable impedance control scheme, in order to achieve simultaneously zero convergence for the trajectory tracking error and the slippage velocity of the object. The desired damping and stiffness matrices are formulated online, by taking into account the measurement of the slippage velocity on the contact. A formal Lyapunov-based analysis guarantees the stability and convergence properties of the resulting control scheme. A set of extensive simulation studies clarifies the proposed method and verifies its efficacy.",
        "primary_area": "",
        "author": "Michalis Logothetis;George C. Karras;Konstantinos Alevizos;Kostas J. Kyriakopoulos;Michalis Logothetis;George C. Karras;Konstantinos Alevizos;Kostas J. Kyriakopoulos",
        "authorids": "/37086578225;/38559666800;/37086529246;/38181756700;/37086578225;/38559666800;/37086529246;/38181756700",
        "aff": "Department of Mechanical Engineering, Control Systems Lab, National Technical University of Athens, Zografou, Greece; Department of Mechanical Engineering, Control Systems Lab, National Technical University of Athens, Zografou, Greece; Department of Mechanical Engineering, Control Systems Lab, National Technical University of Athens, Zografou, Greece; Department of Mechanical Engineering, Control Systems Lab, National Technical University of Athens, Zografou, Greece",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341725/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15063062648884955514&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "National Technical University of Athens",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.ntua.gr",
        "aff_unique_abbr": "NTUA",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Zografou",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Greece"
    },
    {
        "id": "9341357",
        "title": "A Visuo-Haptic Guidance Interface for Mobile Collaborative Robotic Assistant (MOCA)",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we propose a novel visuo-haptic guidance interface to enable mobile collaborative robots to follow human instructions in a way understandable by non-experts. The interface is composed of a haptic admittance module and a human visual tracking module. The haptic guidance enables an individual to guide the robot end-effector in the workspace to reach and grasp arbitrary items. The visual interface, on the other hand, uses a real-time human tracking system and enables autonomous and continuous navigation of the mobile robot towards the human, with the ability to avoid static and dynamic obstacles along its path. To ensure a safer human-robot interaction, the visual tracking goal is set outside of a certain area around the human body, entering which will switch robot behaviour to the haptic mode. The execution of the two modes is achieved by two different controllers, the mobile base admittance controller for the haptic guidance and the robot's whole-body impedance controller, that enables physically coupled and controllable locomotion and manipulation. The proposed interface is validated experimentally, where a human-guided robot performs the loading and transportation of a heavy object in a cluttered workspace, illustrating the potential of the proposed Follow-Me interface in removing the external loading from the human body in this type of repetitive industrial tasks.",
        "primary_area": "",
        "author": "Edoardo Lamon;Fabio Fusaro;Pietro Balatti;Wansoo Kim;Arash Ajoudani;Edoardo Lamon;Fabio Fusaro;Pietro Balatti;Wansoo Kim;Arash Ajoudani",
        "authorids": "/37086599073;/37088464502;/37086577439;/37086291232;/37945239900;/37086599073;/37088464502;/37086577439;/37086291232;/37945239900",
        "aff": "Dept. of Information Engineering, Robotics and Automation, Universita\u2019 degli Studi di Pisa, Pisa, Italy; Department of Electronics, Information and Bioengineering, Politecnico di Milano, Milano, Italy; Dept. of Information Engineering, Robotics and Automation, Universita\u2019 degli Studi di Pisa, Pisa, Italy; Dept. of Advanced Robotics, HRI Lab, Istituto Italiano di Tecnologia, Genova, Italy; Dept. of Advanced Robotics, HRI Lab, Istituto Italiano di Tecnologia, Genova, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341357/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8535036590527625654&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;2;2",
        "aff_unique_norm": "Universita\u2019 degli Studi di Pisa;Politecnico di Milano;Istituto Italiano di Tecnologia",
        "aff_unique_dep": "Dept. of Information Engineering, Robotics and Automation;Department of Electronics, Information and Bioengineering;Dept. of Advanced Robotics",
        "aff_unique_url": "https://www.unipi.it;https://www.polimi.it;https://www.iit.it",
        "aff_unique_abbr": ";Politecnico di Milano;IIT",
        "aff_campus_unique_index": "0;1;0;2;2",
        "aff_campus_unique": "Pisa;Milano;Genova",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9341723",
        "title": "A Whisker-inspired Fin Sensor for Multi-directional Airflow Sensing",
        "track": "main",
        "status": "Poster",
        "abstract": "This work presents the design, fabrication, and characterization of an airflow sensor inspired by the whiskers of animals. The body of the whisker was replaced with a fin structure in order to increase the air resistance. The fin was suspended by a micro-fabricated spring system at the bottom. A permanent magnet was attached beneath the spring, and the motion of fin was captured by a readily accessible and low- cost 3D magnetic sensor located below the magnet. The sensor system was modeled in terms of the dimension parameters of fin and the spring stiffness, which were optimized to improve the performance of the sensor. The system response was then characterized using a commercial wind tunnel and the results were used for sensor calibration. The sensor was integrated into a micro aerial vehicle (MAV) and demonstrated the capability of capturing the velocity of the MAV by sensing the relative airflow during flight.",
        "primary_area": "",
        "author": "Suhan Kim;Regan Kubicek;Aleix Paris;Andrea Tagliabue;Jonathan P. How;Sarah Bergbreiter;Suhan Kim;Regan Kubicek;Aleix Paris;Andrea Tagliabue;Jonathan P. How;Sarah Bergbreiter",
        "authorids": "/37087323805;/37088690293;/37086862338;/37086131568;/37276347700;/37542605000;/37087323805;/37088690293;/37086862338;/37086131568;/37276347700;/37542605000",
        "aff": "Department of Mechanical Engineering, Carnegie Mellon University (CMU), Pittsburgh, PA, USA; Department of Mechanical Engineering, Carnegie Mellon University (CMU), Pittsburgh, PA, USA; Department of Aeronautics and Astronautics, Massachusetts Institute of Technology (MIT), Cambridge, MA, USA; Department of Aeronautics and Astronautics, Massachusetts Institute of Technology (MIT), Cambridge, MA, USA; Department of Aeronautics and Astronautics, Massachusetts Institute of Technology (MIT), Cambridge, MA, USA; Department of Mechanical Engineering, Carnegie Mellon University (CMU), Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341723/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11794783129740441600&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;1;1;0",
        "aff_unique_norm": "Carnegie Mellon University;Massachusetts Institute of Technology",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Aeronautics and Astronautics",
        "aff_unique_url": "https://www.cmu.edu;https://web.mit.edu",
        "aff_unique_abbr": "CMU;MIT",
        "aff_campus_unique_index": "0;0;1;1;1;0",
        "aff_campus_unique": "Pittsburgh;Cambridge",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341236",
        "title": "A collision-resilient aerial vehicle with icosahedron tensegrity structure",
        "track": "main",
        "status": "Poster",
        "abstract": "Aerial vehicles with collision resilience can operate with more confidence in environments with obstacles that are hard to detect and avoid. This paper presents the methodology used to design a collision resilient aerial vehicle with icosahedron tensegrity structure. A simplified stress analysis of the tensegrity frame under impact forces is performed to guide the selection of its components. In addition, an autonomous controller is presented to reorient the vehicle from an arbitrary orientation on the ground to help it take off. Experiments show that the vehicle can successfully reorient itself after landing upside-down and can survive collisions with speed up to 6.5m/s.",
        "primary_area": "",
        "author": "Jiaming Zha;Xiangyu Wu;Joseph Kroeger;Natalia Perez;Mark W. Mueller;Jiaming Zha;Xiangyu Wu;Joseph Kroeger;Natalia Perez;Mark W. Mueller",
        "authorids": "/37086939196;/37086448421;/37086945387;/37088691502;/37086448968;/37086939196;/37086448421;/37086945387;/37088691502;/37086448968",
        "aff": "HiPeRLab, University of California, Berkeley, CA, USA; HiPeRLab, University of California, Berkeley, CA, USA; HiPeRLab, University of California, Berkeley, CA, USA; HiPeRLab, University of California, Berkeley, CA, USA; HiPeRLab, University of California, Berkeley, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341236/",
        "gs_citation": 56,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7946650437829932337&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "HiPeRLab",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341594",
        "title": "A control scheme for haptic inspection and partial modification of kinematic behaviors",
        "track": "main",
        "status": "Poster",
        "abstract": "Over the last decades, Learning from Demonstration (LfD) has become a widely accepted solution for the problem of robot programming. According to LfD, the kinematic behavior is \"taught\" to the robot, based on a set of motion demonstrations performed by the human-teacher. The demonstrations can be either captured via kinesthetic teaching or external sensors, e.g., a camera. In this work, a controller for providing haptic cues of the robot's kinematic behavior to the human-teacher is proposed. Guidance is provided in procedures of kinesthetic coaching during inspection and partial modification of encoded motions. The proposed controller is based on an artificial potential field, designed to adjust the intensity of the haptic communication automatically according to the human intentions. The control scheme is proved to be passive with respect to robot's velocity and its effectiveness is experimentally evaluated in a KUKA LWR4+ robotic manipulator.",
        "primary_area": "",
        "author": "Dimitrios Papageorgiou;Zoe Doulgeri;Dimitrios Papageorgiou;Zoe Doulgeri",
        "authorids": "/37449072200;/37274011500;/37449072200;/37274011500",
        "aff": "Dept. of Electrical and Computer Engineering, Aristotle University of Thessaloniki, Greece; Dept. of Electrical and Computer Engineering, Aristotle University of Thessaloniki, Greece",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341594/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16077097282246994405&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Aristotle University of Thessaloniki",
        "aff_unique_dep": "Dept. of Electrical and Computer Engineering",
        "aff_unique_url": "http://www.auth.gr",
        "aff_unique_abbr": "AUTH",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Thessaloniki",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Greece"
    },
    {
        "id": "9340790",
        "title": "A decentralized framework for simultaneous calibration, localization and mapping with multiple LiDARs",
        "track": "main",
        "status": "Poster",
        "abstract": "LiDAR is playing a more and more essential role in autonomous driving vehicles for objection detection, self localization and mapping. A single LiDAR frequently suffers from hardware failure (e.g., temporary loss of connection) due to the harsh vehicle environment (e.g., temperature, vibration, etc.), or performance degradation due to the lack of sufficient geometry features, especially for solid-state LiDARs with small field of view (FoV). To improve the system robustness and performance in self-localization and mapping, we develop a decentralized framework for simultaneous calibration, localization and mapping with multiple LiDARs. Our proposed framework is based on an extended Kalman filter (EKF), but is specially formulated for decentralized implementation. Such an implementation could potentially distribute the intensive computation among smaller computing devices or resources dedicated for each LiDAR and remove the single point of failure problem. Then this decentralized formulation is implemented on an unmanned ground vehicle (UGV) carrying 5 low-cost LiDARs and moving at 1.3m/s in urban environments. Experiment results show that the proposed method can successfully and simultaneously estimate the vehicle state (i.e., pose and velocity) and all LiDAR extrinsic parameters. The localization accuracy is up to 0.2% on the two datasets we collected. To share our findings and to make contributions to the community, meanwhile enable the readers to verify our work, we will release all our source codes1 and hardware design blueprint2 on our Github.",
        "primary_area": "",
        "author": "Jiarong Lin;Xiyuan Liu;Fu Zhang;Jiarong Lin;Xiyuan Liu;Fu Zhang",
        "authorids": "/37087012222;/37088689751;/38245883800;/37087012222;/37088689751;/38245883800",
        "aff": "Department of Mechanical Engineering, Hong Kong University, Hong Kong SAR, China; Department of Mechanical Engineering, Hong Kong University, Hong Kong SAR, China; Department of Mechanical Engineering, Hong Kong University, Hong Kong SAR, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340790/",
        "gs_citation": 53,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12877092161894833533&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Hong Kong University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.hku.hk",
        "aff_unique_abbr": "HKU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Hong Kong",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9341693",
        "title": "A frequency-dependent impedance controller for an active-macro/passive-mini robotic system",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents an alternative impedance controller for a macro-mini robotic system in which the mini robot is unactuated. The approach is verified experimentally on a simple two-degree-of-freedom macro-mini robot. The dynamic analysis of the robot is first presented. Then, a standard impedance controller is derived and analysed. Such a controller is shown to be experimentally unstable when used with the present macro-mini mechanism. An alternative impedance controller is then proposed and analysed. While slightly more complex than the standard controller, it provides a more stable behaviour experimentally. The alternative controller also increases the effectiveness of the control by reducing the response to high-frequency motion such as hand tremor.",
        "primary_area": "",
        "author": "Nicolas Badeau;Cl\u00e9ment Gosselin;Nicolas Badeau;Cl\u00e9ment Gosselin",
        "authorids": "/37086389190;/37293911800;/37086389190;/37293911800",
        "aff": "Department of Mechanical Engineering, Universit\u00e9 Laval, Qu\u00e9bec, Qc, Canada; Department of Mechanical Engineering, Universit\u00e9 Laval, Qu\u00e9bec, Qc, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341693/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:UTL5yAgZoNsJ:scholar.google.com/&scioq=A+frequency-dependent+impedance+controller+for+an+active-macro/passive-mini+robotic+system&hl=en&as_sdt=0,33",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Universit\u00e9 Laval",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.ulaval.ca",
        "aff_unique_abbr": "ULaval",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Qu\u00e9bec",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9341377",
        "title": "A modified Hybrid Reciprocal Velocity Obstacles approach for multi-robot motion planning without communication",
        "track": "main",
        "status": "Poster",
        "abstract": "Ensuring a safe online motion planning despite a large number of moving agents is the problem addressed in this paper. Collision avoidance is achieved without communication between the agents and without global localization system. The proposed solution is a modification of the Hybrid Reciprocal Velocity Obstacles (HRVO) combined with a tracking error estimation, in order to adapt the Velocity Obstacle paradigm to agents with kinodynamic constraints and unreliable velocity estimates. This solution, evaluated in simulation and in real test scenario with three dynamic unicycle type robots, shows an improvement over HRVO.",
        "primary_area": "",
        "author": "Maxime Sainte Catherine;Eric Lucet;Maxime Sainte Catherine;Eric Lucet",
        "authorids": "/37088688695;/37593493000;/37088688695;/37593493000",
        "aff": "CEA, LIST, Interactive Robotics Laboratory, Gif-sur-Yvette, France; CEA, LIST, Interactive Robotics Laboratory, Gif-sur-Yvette, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341377/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3509937685662277909&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "CEA",
        "aff_unique_dep": "Interactive Robotics Laboratory",
        "aff_unique_url": "https://www.cea.fr",
        "aff_unique_abbr": "CEA",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Gif-sur-Yvette",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9341774",
        "title": "A novel and controllable cell-based microrobot in real vascular network for target tumor therapy",
        "track": "main",
        "status": "Poster",
        "abstract": "Magnetic microrobots can be propelled precisely and wirelessly in vivo using magnetic field for targeted drug delivery and early detection. They are promising for clinical trials since magnetic fields are capable of penetrating most materials with minimal interaction, and are nearly harmless to human beings. However, challenges like the biocompatibility, biodegradation and therapeutic effects of these robots must be resolved before this technique is allowed for preclinical development. In this study, we proposed a cell-robot based on macrophages for carrying drugs to kill tumors propelled by magnetic gradient-based pulling. A custom-designed system with strong gradient magnetic field system in three-dimensional (3D) space using the minimum number of coils is used for precise control of the cell-based microrobot. The cell-based microrobots were fabricated by assembling magnetic nanoparticles (Fe3O4), anti-cancer drugs (DOX) into macrophages for magnetic actuation and therapeutic effects. Vitro experiments show that cell-based microrobots can be accurately transported to the destination or approaching a targeted cancer cell. The magnetic nanoparticles have negligible effects on the cell-based microrobot and the organism, which makes the cell-based microrobot safe for in vivo experiments. The carried drugs in the cell-based microrobot can be released by the irradiation of the near-field infrared and kill the cancer cells. Further in vivo experiments prove that the cell-based microrobot can be transported to tumor area and release drugs to kill cancer effectively. The research provides biocompatible and biodegradable cell-based microrobots for early tumor prevention and targeted precision therapy.",
        "primary_area": "",
        "author": "Yanmin Feng;Lin Feng;Yuguo Dai;Xue Bai;Chaonan Zhang;Yuanyuan Chen;Fumihito Arai;Yanmin Feng;Lin Feng;Yuguo Dai;Xue Bai;Chaonan Zhang;Yuanyuan Chen;Fumihito Arai",
        "authorids": "/37087124241;/37403324400;/37086561173;/37088554994;/37086022880;/37088553869;/37274069600;/37087124241;/37403324400;/37086561173;/37088554994;/37086022880;/37088553869;/37274069600",
        "aff": "Beijing Advanced Innovation Center for Biomedical Engineering, Bei hang University, Beijing, China; Beijing Advanced Innovation Center for Biomedical Engineering, Bei hang University, Beijing, China; School of Mechanical Engineering & Automation, Beihang University, Beijing, China; School of Mechanical Engineering & Automation, Beihang University, Beijing, China; School of Mechanical Engineering & Automation, Beihang University, Beijing, China; Beijing Advanced Innovation Center for Biomedical Engineering, Bei hang University, Beijing, China; Department of Micro-Nano System Engineering, Nagoya University, Nagoya, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341774/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14857831607809712843&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;1",
        "aff_unique_norm": "Beihang University;Nagoya University",
        "aff_unique_dep": "Beijing Advanced Innovation Center for Biomedical Engineering;Department of Micro-Nano System Engineering",
        "aff_unique_url": "http://www.buaa.edu.cn;https://www.nagoya-u.ac.jp",
        "aff_unique_abbr": "Beihang;Nagoya U",
        "aff_campus_unique_index": "0;0;0;0;0;0;1",
        "aff_campus_unique": "Beijing;Nagoya",
        "aff_country_unique_index": "0;0;0;0;0;0;1",
        "aff_country_unique": "China;Japan"
    },
    {
        "id": "9341603",
        "title": "A novel portable cell sonoporation device based on open-source acoustofluidics",
        "track": "main",
        "status": "Poster",
        "abstract": "Sonoporation, which typically employs acoustic cavitation microbubbles, can enhance the permeability of the cell membrane, allowing foreign matter to enter cells across the natural barriers. However, the diameter nonuniformity and random distribution of microbubbles make it difficult to achieve controllable and high-efficiency sonoporation, while complex extern acoustic driving system also limits its applicability. Herein, we demonstrate a low-cost, expandable, and portable acoustofluidic device for cell sonoporation using acoustic streaming generated by oscillating sharp edges. The streaming-induced high shear forces can (i) quickly trap target cells at the tip of sharp edges and (ii) transiently modulate the permeability of the cell membrane, which is utilized to perform cell sonoporation events. Using our device, sonoporation is successfully achieved in a microbubble-free manner, with a sonoporation efficiency of more than 90%. Furthermore, our acoustic driving system is designed around the open-source Arduino prototyping platform due to its extendibility and portability. In addition to these benefits, our acoustofluidic device is simple to fabricate and operate, and it can work at relatively low frequency (4.6 kHz). All these advantages make our novel cell sonoporation device invaluable for many biological and biomedical applications such as drug delivery and gene transfection.",
        "primary_area": "",
        "author": "Bin Song;Wei Zhang;Xue Bai;Lin Feng;Deyuan Zhang;Fumihito Arai;Bin Song;Wei Zhang;Xue Bai;Lin Feng;Deyuan Zhang;Fumihito Arai",
        "authorids": "/37086935548;/37086933988;/37088554994;/37403324400;/37309903800;/37274069600;/37086935548;/37086933988;/37088554994;/37403324400;/37309903800;/37274069600",
        "aff": "School of Mechanical Engineering & Automation, Beihang University, Beijing, China; School of Mechanical Engineering & Automation, Beihang University, Beijing, China; Beijing Advanced Innovation Center for Biomedical Engineering, Beihang University, Beijing, China; Beijing Advanced Innovation Center for Biomedical Engineering, Beihang University, Beijing, China; Beijing Advanced Innovation Center for Biomedical Engineering, Beihang University, Beijing, China; Department of Micro-Nano System Engineering, Nagoya University, Nagoya, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341603/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3674980433064862924&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;1",
        "aff_unique_norm": "Beihang University;Nagoya University",
        "aff_unique_dep": "School of Mechanical Engineering & Automation;Department of Micro-Nano System Engineering",
        "aff_unique_url": "http://www.buaa.edu.cn;https://www.nagoya-u.ac.jp",
        "aff_unique_abbr": "BUAA;Nagoya U",
        "aff_campus_unique_index": "0;0;0;0;0;1",
        "aff_campus_unique": "Beijing;Nagoya",
        "aff_country_unique_index": "0;0;0;0;0;1",
        "aff_country_unique": "China;Japan"
    },
    {
        "id": "9341399",
        "title": "A particle filter technique for human pose estimation in case of occlusion exploiting holographic human model and virtualized environment",
        "track": "main",
        "status": "Poster",
        "abstract": "In a collaborative scenario, robots working side by side with humans might rely on vision sensors to monitor the activity of the other agent. When occlusions of the human body occur, both the safety of the cooperation and the performance of the team can be penalized, since the robot could receive incorrect information about the ongoing cooperation. In this work, we propose a novel particle filter algorithm that, by merging the data acquired through a RGB-D camera and a MR headset, estimates online the human wrist position. This algorithm allows to significantly reduce the uncertainty of the human pose estimation, in case of both static and dynamic occlusions. To this purpose, the proposed particle filter is integrated with a detailed virtual model of the real workspace. Moreover, additional constraints describing the boundaries of the motion of the human upper body are included in a virtualized framework. The results showed that the proposed technique entails significant improvements, determining a relevant reduction of the estimation error and of the uncertainty of the estimate.",
        "primary_area": "",
        "author": "Costanza Messeri;Lorenzo Rebecchi;Andrea Maria Zanchettin;Paolo Rocco;Costanza Messeri;Lorenzo Rebecchi;Andrea Maria Zanchettin;Paolo Rocco",
        "authorids": "/37086437218;/37088688579;/37546427600;/37274178600;/37086437218;/37088688579;/37546427600;/37274178600",
        "aff": "Dipartimento di Elettronica, Politecnico di Milano, Informazione e Bioingegneria, Milano, Italy; Dipartimento di Elettronica, Politecnico di Milano, Informazione e Bioingegneria, Milano, Italy; Dipartimento di Elettronica, Politecnico di Milano, Informazione e Bioingegneria, Milano, Italy; Dipartimento di Elettronica, Politecnico di Milano, Informazione e Bioingegneria, Milano, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341399/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17955725743599700818&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Politecnico di Milano",
        "aff_unique_dep": "Dipartimento di Elettronica, Informazione e Bioingegneria",
        "aff_unique_url": "https://www.polimi.it",
        "aff_unique_abbr": "Polimi",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Milano",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9341216",
        "title": "A real-time unscented Kalman filter on manifolds for challenging AUV navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider the problem of localization and navigation of Autonomous Underwater Vehicles (AUV) in the context of high performance subsea asset inspection missions in deep water. We propose a solution based on the recently introduced Unscented Kalman Filter on Manifolds (UKF-M) for onboard navigation to estimate the robot's location, attitude and velocity, using a precise round and rotating Earth navigation model. Our algorithm has the merit of seamlessly handling nonlinearity of attitude, and is far simpler to implement than the extended Kalman filter (EKF), which is widely used in the navigation industry. The unscented transform notably spares the user the computation of Jacobians and lends itself well to fast prototyping in the context of multi-sensor data fusion. Besides, we provide the community with feedback about implementation, and execution time is shown to be compatible with real-time. Realistic extensive Monte-Carlo simulations prove uncertainty is estimated with accuracy by the filter, and illustrate its convergence ability. Real experiments in the context of a 900m deep dive near Marseille (France) illustrate the relevance of the method.",
        "primary_area": "",
        "author": "Th\u00e9ophile Cantelobre;Cl\u00e9ment Chahbazian;Arnaud Croux;Silv\u00e8re Bonnabel;Th\u00e9ophile Cantelobre;Cl\u00e9ment Chahbazian;Arnaud Croux;Silv\u00e8re Bonnabel",
        "authorids": "/37088689368;/37088688916;/37086171096;/37398922500;/37088689368;/37088688916;/37086171096;/37398922500",
        "aff": "INRIA and Mines ParisTech, PSL Research University, Paris, France; Schlumberger-Doll Research, Cambridge, MA; Schlumberger-Doll Research, Cambridge, MA; Institut ISEA, University of New Caledonia, Noumea, New-Caledonia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341216/",
        "gs_citation": 34,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9456085166010185913&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;2",
        "aff_unique_norm": "INRIA;Schlumberger-Doll Research;University of New Caledonia",
        "aff_unique_dep": ";;Institut ISEA",
        "aff_unique_url": "https://www.inria.fr;https://www.slb.com;https://www.univ-nc.nc",
        "aff_unique_abbr": "INRIA;;",
        "aff_campus_unique_index": "0;1;1;2",
        "aff_campus_unique": "Paris;Cambridge;Noumea",
        "aff_country_unique_index": "0;1;1;2",
        "aff_country_unique": "France;United States;New-Caledonia"
    },
    {
        "id": "9341384",
        "title": "ARAS: Ambiguity-aware Robust Active SLAM based on Multi-hypothesis State and Map Estimations",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we introduce an ambiguity-aware robust active SLAM (ARAS) framework that makes use of multi-hypothesis state and map estimations to achieve better robustness. Ambiguous measurements can result in multiple probable solutions in a multi-hypothesis SLAM (MH-SLAM) system if they are temporarily unsolvable (due to insufficient information), our ARAS aims at taking all these probable estimations into account explicitly for decision making and planning, which, to the best of our knowledge, has not yet been covered by any previous active SLAM approach (which mostly consider a single hypothesis at a time). This novel ARAS framework 1) adopts local contours for efficient multi-hypothesis exploration, 2) incorporates an active loop closing module that revisits mapped areas to acquire information for hypotheses pruning to maintain the overall computational efficiency, and 3) demonstrates how to use the output target pose for path planning under the multi-hypothesis estimations. Through extensive simulations and a real-world experiment, we demonstrate that the proposed ARAS algorithm can actively map general indoor environments more robustly than a similar single-hypothesis approach in the presence of ambiguities.",
        "primary_area": "",
        "author": "Ming Hsiao;Joshua G. Mangelson;Sudharshan Suresh;Christian Debrunner;Michael Kaess;Ming Hsiao;Joshua G. Mangelson;Sudharshan Suresh;Christian Debrunner;Michael Kaess",
        "authorids": "/37085991947;/37086109836;/37086609669;/37267326200;/37324200400;/37085991947;/37086109836;/37086609669;/37267326200;/37324200400",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Lockheed Martin Corporation, Bethesda, MD, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341384/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8927498826743135362&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Carnegie Mellon University;Lockheed Martin Corporation",
        "aff_unique_dep": "Robotics Institute;",
        "aff_unique_url": "https://www.cmu.edu;https://www.lockheedmartin.com",
        "aff_unique_abbr": "CMU;Lockheed Martin",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Pittsburgh;Bethesda",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341684",
        "title": "ARPDR: An Accurate and Robust Pedestrian Dead Reckoning System for Indoor Localization on Handheld Smartphones",
        "track": "main",
        "status": "Poster",
        "abstract": "The proliferation of mobile computing has prompted Pedestrian Dead Reckoning (PDR) to be one of the most attractive and promising indoor localization techniques for ubiquitous applications. The existing PDR approaches either suffer position drifts caused by accumulative errors or are sensitive to various users. This paper presents ARPDR, an accurate and robust PDR approach to improve the accuracy and robustness of indoor localization methods. Particularly, we propose a novel step counting algorithm based on motion models by deeply exploiting inertial sensor data. We then combine step counting with adaptive thresholding to personalize the PDR system for different users. Furthermore, we propose a novel stride-heading model with a deep neural network to predict stride lengths and walking orientations, thus the displacement errors are significantly reduced. Extensive experiments on public datasets demonstrate that ARPDR outperforms the state-of-the-art PDR methods.",
        "primary_area": "",
        "author": "Xiaoqiang Teng;Pengfei Xu;Deke Guo;Yulan Guo;Runbo Hu;Hua Chai;Didi Chuxing;Xiaoqiang Teng;Pengfei Xu;Deke Guo;Yulan Guo;Runbo Hu;Hua Chai;Didi Chuxing",
        "authorids": "/37086469693;/37088434324;/37288168600;/38562048600;/37088409318;/37088409329;/37088686309;/37086469693;/37088434324;/37288168600;/38562048600;/37088409318;/37088409329;/37088686309",
        "aff": "College of System Engineering, National University of Defense Technology, Changsha, P. R. China; College of System Engineering, National University of Defense Technology, Changsha, P. R. China; College of Electronic Science and Technology, National University of Defense Technology, Changsha, P. R. China; College of Electronic Science and Technology, National University of Defense Technology, Changsha, P. R. China; College of System Engineering, National University of Defense Technology, Changsha, P. R. China; College of System Engineering, National University of Defense Technology, Changsha, P. R. China; College of System Engineering, National University of Defense Technology, Changsha, P. R. China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341684/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=64591405627662946&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "National University of Defense Technology",
        "aff_unique_dep": "College of System Engineering",
        "aff_unique_url": "http://www.nudt.edu.cn",
        "aff_unique_abbr": "NUDT",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Changsha",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9340939",
        "title": "AVP-SLAM: Semantic Visual Mapping and Localization for Autonomous Vehicles in the Parking Lot",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous valet parking is a specific application for autonomous vehicles. In this task, vehicles need to navigate in narrow, crowded and GPS-denied parking lots. Accurate localization ability is of great importance. Traditional visual-based methods suffer from tracking lost due to texture-less regions, repeated structures, and appearance changes. In this paper, we exploit robust semantic features to build the map and localize vehicles in parking lots. Semantic features contain guide signs, parking lines, speed bumps, etc, which typically appear in parking lots. Compared with traditional features, these semantic features are long-term stable and robust to the perspective and illumination change. We adopt four surround-view cameras to increase the perception range. Assisting by an IMU (Inertial Measurement Unit) and wheel encoders, the proposed system generates a global visual semantic map. This map is further used to localize vehicles at the centimeter level. We analyze the accuracy and recall of our system and compare it against other methods in real experiments. Furthermore, we demonstrate the practicability of the proposed system by the autonomous parking application.",
        "primary_area": "",
        "author": "Tong Qin;Tongqing Chen;Yilun Chen;Qing Su;Tong Qin;Tongqing Chen;Yilun Chen;Qing Su",
        "authorids": "/37086218149;/37088688037;/37088689305;/37088688782;/37086218149;/37088688037;/37088689305;/37088688782",
        "aff": "IAS BU, Huawei Technologies, Shanghai, China; IAS BU, Huawei Technologies, Shanghai, China; IAS BU, Huawei Technologies, Shanghai, China; IAS BU, Huawei Technologies, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340939/",
        "gs_citation": 162,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9383170695965073456&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Huawei Technologies",
        "aff_unique_dep": "IAS BU",
        "aff_unique_url": "https://www.huawei.com",
        "aff_unique_abbr": "Huawei",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Shanghai",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9341155",
        "title": "Abductive Recognition of Context-dependent Utterances in Human-robot Interaction",
        "track": "main",
        "status": "Poster",
        "abstract": "Context-dependent meaning recognition in natural language utterances is one of the key problems of computational pragmatics. Abductive reasoning seems apt for modeling and understanding these phenomena. In fact, it presents observations through hypotheses, allowing us to understand subtexts and implied meanings without exact deductions. For this reason in this paper, we are going to explore abductive reasoning and context modeling in human-robot interaction. Rather than a radical inferential approach, we assumed a conventional approach towards context-depending meanings, i.e, they are conventionally encoded rather than inferred from the utterances. In order to address the problem, a case study is presented, analyzing whether such a system could manage correctly these linguistic phenomena. The results obtained confirm the validity of a conventional approach in context modeling and, on this basis, further models are proposed to work around the limitations of the case study.",
        "primary_area": "",
        "author": "Davide Lanza;Roberto Menicatti;Antonio Sgorbissa;Davide Lanza;Roberto Menicatti;Antonio Sgorbissa",
        "authorids": "/37088447334;/37086177105;/37278643700;/37088447334;/37086177105;/37278643700",
        "aff": "Department of Computer Science, Bioengineering, Robotics and Systems Engineering (DIBRIS), University of Genova, Genova, Italy; Department of Computer Science, Bioengineering, Robotics and Systems Engineering (DIBRIS), University of Genova, Genova, Italy; Department of Computer Science, Bioengineering, Robotics and Systems Engineering (DIBRIS), University of Genova, Genova, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341155/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13889709895309239833&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Genova",
        "aff_unique_dep": "Department of Computer Science, Bioengineering, Robotics and Systems Engineering (DIBRIS)",
        "aff_unique_url": "https://www.unige.it",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Genova",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9340782",
        "title": "Accelerating Bi-Directional Sampling-Based Search for Motion Planning of Non-Holonomic Mobile Manipulators",
        "track": "main",
        "status": "Poster",
        "abstract": "Determining a feasible path for nonholonomic mobile manipulators operating in congested environments is challenging. Sampling-based methods, especially bi-directional tree search-based approaches, are amongst the most promising candidates for quickly finding feasible paths. However, sampling uniformly when using these methods may result in high computation time. This paper introduces two techniques to accelerate the motion planning of such robots. The first one is coordinated focusing of samples for the manipulator and the mobile base based on the information from robot surroundings. The second one is a heuristic for making connections between the two search trees, which is challenging owing to the nonholonomic constraints on the mobile base. Incorporating these two techniques into the bi-directional RRT framework results in about 5x faster and 10x more successful computation of paths as compared to the baseline method.",
        "primary_area": "",
        "author": "Shantanu Thakar;Pradeep Rajendran;Hyojeong Kim;Ariyan M. Kabir;Satyandra K. Gupta;Shantanu Thakar;Pradeep Rajendran;Hyojeong Kim;Ariyan M. Kabir;Satyandra K. Gupta",
        "authorids": "/37085804412;/37086458768;/37088691217;/37085768994;/37878971100;/37085804412;/37086458768;/37088691217;/37085768994;/37878971100",
        "aff": "Shantanu Thakar; Pradeep Rajendran; Hyojeong Kim; Ariyan M. Kabir; Satyandra K. Gupta",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340782/",
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15468806774312450891&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "",
        "aff_unique_norm": "",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "9341702",
        "title": "Accurate Mapping and Planning for Autonomous Racing",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents the perception, mapping, and planning pipeline implemented on an autonomous race car. It was developed by the 2019 AMZ driverless team for the Formula Student Germany (FSG) 2019 driverless competition, where it won 1st place overall. The presented solution combines early fusion of camera and LiDAR data, a layered mapping approach, and a planning approach that uses Bayesian filtering to achieve high-speed driving on unknown race tracks while creating accurate maps. We benchmark the method against our team's previous solution, which won FSG 2018, and show improved accuracy when driving at the same speeds. Furthermore, the new pipeline makes it possible to reliably raise the maximum driving speed in unknown environments from 3 m/s to 12 m/s while still mapping with an acceptable RMSE of 0.29 m.",
        "primary_area": "",
        "author": "Leiv Andresen;Adrian Brandemuehl;Alex Honger;Benson Kuan;Niclas V\u00f6disch;Hermann Blum;Victor Reijgwart;Lukas Bernreiter;Lukas Schaupp;Jen Jen Chung;Mathias Burki;Martin R. Oswald;Roland Siegwart;Abel Gawel;Leiv Andresen;Adrian Brandemuehl;Alex Honger;Benson Kuan;Niclas V\u00f6disch;Hermann Blum;Victor Reijgwart;Lukas Bernreiter;Lukas Schaupp;Jen Jen Chung;Mathias Burki;Martin R. Oswald;Roland Siegwart;Abel Gawel",
        "authorids": "/37088687745;/37088689396;/37088689160;/37088029499;/37088685956;/37086048087;/37086454863;/37086451179;/37089136088;/37085668354;/37085496641;/38467098900;/37281398300;/37085766697;/37088687745;/37088689396;/37088689160;/37088029499;/37088685956;/37086048087;/37086454863;/37086451179;/37089136088;/37085668354;/37085496641;/38467098900;/37281398300;/37085766697",
        "aff": "Autonomous Systems Lab, ETH, Z\u00fcrich; Autonomous Systems Lab, ETH, Z\u00fcrich; Autonomous Systems Lab, ETH, Z\u00fcrich; Autonomous Systems Lab, ETH, Z\u00fcrich; Autonomous Systems Lab, ETH, Z\u00fcrich; Autonomous Systems Lab, ETH, Z\u00fcrich; Autonomous Systems Lab, ETH, Z\u00fcrich; Autonomous Systems Lab, ETH, Z\u00fcrich; Autonomous Systems Lab, ETH, Z\u00fcrich; Autonomous Systems Lab, ETH, Z\u00fcrich; Sevensense Robotics AG; Computer Vision and Geometry Group, ETH, Z\u00fcrich; Autonomous Systems Lab, ETH, Z\u00fcrich; Autonomous Systems Lab, ETH, Z\u00fcrich",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341702/",
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6580997966001357420&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 28,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0;0;1;0;0;0",
        "aff_unique_norm": "ETH Z\u00fcrich;Sevensense Robotics",
        "aff_unique_dep": "Autonomous Systems Lab;",
        "aff_unique_url": "https://www.ethz.ch;https://www.sevensense.io",
        "aff_unique_abbr": "ETH;Sevensense",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Z\u00fcrich;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9341764",
        "title": "Accurate and Robust Teach and Repeat Navigation by Visual Place Recognition: A CNN Approach",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a novel teach-and-repeat navigation system, SSM-Nav, which is based on the output of the recently introduced SSM visual place recognition methodology. During the teach phase, a teleoperated wheeled robot stores in a database features of images taken along an arbitrary route. During the repeat phase or navigation, a CNN-based comparison of each captured image is performed against the database. With the help of a particle filter, the image associated with the most likely location is selected at each time and its horizontal offset with respect to the current scene used to correct the steering of the robot and to navigate. Indoor tests in our lab show a maximum error of less than 10cm and excellent robustness to perturbations such as drastic changes in illumination, lateral displacements, different starting positions, or even kidnapping. Preliminary outdoor tests on a 0.22km route show promising results, with an estimated maximum error of less than 25cm.",
        "primary_area": "",
        "author": "Luis G. Camara;Tom\u00e1\u0161 Pivo\u0148ka;Martin J\u00edlek;Carl G\u00e4bert;Karel Ko\u0161nar;Libor P\u0159eu\u010dil;Luis G. Camara;Tom\u00e1\u0161 Pivo\u0148ka;Martin J\u00edlek;Carl G\u00e4bert;Karel Ko\u0161nar;Libor P\u0159eu\u010dil",
        "authorids": "/37087048230;/37088508244;/37087322174;/37088503821;/38547765500;/37550774800;/37087048230;/37088508244;/37087322174;/37088503821;/38547765500;/37550774800",
        "aff": "Czech Institute of Informatics, Robotics and Cybernetics (CIIRC), Czech Technical University in Prague, Prague, Czech Republic; Czech Institute of Informatics, Robotics and Cybernetics (CIIRC), Czech Technical University in Prague, Prague, Czech Republic; Czech Institute of Informatics, Robotics and Cybernetics (CIIRC), Czech Technical University in Prague, Prague, Czech Republic; Czech Institute of Informatics, Robotics and Cybernetics (CIIRC), Czech Technical University in Prague, Prague, Czech Republic; Czech Institute of Informatics, Robotics and Cybernetics (CIIRC), Czech Technical University in Prague, Prague, Czech Republic; Czech Institute of Informatics, Robotics and Cybernetics (CIIRC), Czech Technical University in Prague, Prague, Czech Republic",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341764/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5312003715423070250&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Czech Technical University in Prague",
        "aff_unique_dep": "Czech Institute of Informatics, Robotics and Cybernetics (CIIRC)",
        "aff_unique_url": "https://www.ciirc.cvut.cz",
        "aff_unique_abbr": "CTU",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Prague",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Czech Republic"
    },
    {
        "id": "9341090",
        "title": "Accurate estimation of the position and shape of the rolling joint in hyper-redundant manipulators",
        "track": "main",
        "status": "Poster",
        "abstract": "Hyper-redundant manipulators driven by cables are used in minimally invasive surgery because of their flexibility and small diameters. In particular, manipulators composed of many rigid links and joints have the advantages of high stiffness and payload. However, these manipulators have difficulty in estimating their positions and shapes using calculations based only on the kinematics model that assumes all joint angles are equal. In this paper, we present a method for estimating the position and shape of the rolling joint in hyper-redundant manipulators by minimizing the joint moments. This allows the determination the equilibrium position of all segments of the rolling joint, and therefore an estimation of its shape. We experimentally determine the position and shape of a prototype of the rolling joint and compare them to a simulation of our method. The maximum error between the simulation and the experimental results is 4.13 mm, which is a 77.22% improvement over the kinematic model that calculates the same joint angle. This verifies that our method accurately estimates the position and shape of the rolling joint.",
        "primary_area": "",
        "author": "Jeongryul Kim;Yonghwan Moon;Seong-il Kwon;Keri Kim;Jeongryul Kim;Yonghwan Moon;Seong-il Kwon;Keri Kim",
        "authorids": "/37088475975;/37088688641;/37086062773;/37085344004;/37088475975;/37088688641;/37086062773;/37085344004",
        "aff": "Center for Medical Robotics, Korea Institute of Science and Technology, Seoul, Korea; School of Mechanical Engineering, Korea University, Seoul, Korea; Division of Bio-Medical Science and Technology, University of Science and Technology, Daejeon, Korea; Division of Bio-Medical Science and Technology, University of Science and Technology, Daejeon, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341090/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10755637342042738693&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;2",
        "aff_unique_norm": "Korea Institute of Science and Technology;Korea University;University of Science and Technology",
        "aff_unique_dep": "Center for Medical Robotics;School of Mechanical Engineering;Division of Bio-Medical Science and Technology",
        "aff_unique_url": "https://www.kist.re.kr;http://www.korea.ac.kr;http://www.ust.ac.kr",
        "aff_unique_abbr": "KIST;KU;UST",
        "aff_campus_unique_index": "0;0;1;1",
        "aff_campus_unique": "Seoul;Daejeon",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9341683",
        "title": "Accurate, Low-Latency Visual Perception for Autonomous Racing: Challenges, Mechanisms, and Practical Solutions",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous racing provides the opportunity to test safety-critical perception pipelines at their limit. This paper describes the practical challenges and solutions to applying state-of-the-art computer vision algorithms to build a low-latency, high-accuracy perception system for DUT18 Driverless (DUT18D), a 4WD electric race car with podium finishes at all Formula Driverless competitions for which it raced. The key components of DUT18D include YOLOv3-based object detection, pose estimation, and time synchronization on its dual stereovision/monovision camera setup. We highlight modifications required to adapt perception CNNs to racing domains, improvements to loss functions used for pose estimation, and methodologies for sub-microsecond camera synchronization among other improvements. We perform a thorough experimental evaluation of the system, demonstrating its accuracy and low-latency in real-world racing scenarios.",
        "primary_area": "",
        "author": "Kieran Strobel;Sibo Zhu;Raphael Chang;Skanda Koppula;Kieran Strobel;Sibo Zhu;Raphael Chang;Skanda Koppula",
        "authorids": "/37088687347;/37088687809;/37088686549;/37086455614;/37088687347;/37088687809;/37088686549;/37086455614",
        "aff": "MIT, Cambridge, MA; MIT, Cambridge, MA; MIT, Cambridge, MA; Google DeepMind, London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341683/",
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12888672860406035294&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Massachusetts Institute of Technology;Google",
        "aff_unique_dep": ";DeepMind",
        "aff_unique_url": "https://web.mit.edu;https://deepmind.com",
        "aff_unique_abbr": "MIT;DeepMind",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "Cambridge;London",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "United States;United Kingdom"
    },
    {
        "id": "9341719",
        "title": "Acoustic Collision Detection and Localization for Robot Manipulators",
        "track": "main",
        "status": "Poster",
        "abstract": "Collision detection is critical for safe robot operation in the presence of humans. Acoustic information originating from collisions between robots and objects provides opportunities for fast collision detection and localization; however, audio information from microphones on robot manipulators needs to be robustly differentiated from motors and external noise sources. In this paper, we present Panotti, the first system to efficiently detect and localize on-robot collisions using low-cost microphones. We present a novel algorithm that can localize the source of a collision with centimeter level accuracy and is also able to reject false detections using a robust spectral filtering scheme. Our method is scalable, easy to deploy, and enables safe and efficient control for robot manipulator applications. We implement and demonstrate a prototype that consists of 8 miniature microphones on a 7 degree of freedom (DOF) manipulator to validate our design. Extensive experiments show that Panotti realizes near perfect on-robot true positive collision detection rate with almost zero false detections even in high noise environments. In terms of accuracy, it achieves an average localization error of less than 3.8 cm under various experimental settings.",
        "primary_area": "",
        "author": "Xiaoran Fan;Daewon Lee;Yuan Chen;Colin Prepscius;Volkan Isler;Larry Jackel;H. Sebastian Seung;Daniel Lee;Xiaoran Fan;Daewon Lee;Yuan Chen;Colin Prepscius;Volkan Isler;Larry Jackel;H. Sebastian Seung;Daniel Lee",
        "authorids": "/37086418973;/37599980600;/37088689677;/37088686982;/37298487800;/37089466321;/37087322312;/37280609600;/37086418973;/37599980600;/37088689677;/37088686982;/37298487800;/37089466321;/37087322312;/37280609600",
        "aff": "Samsung AI Center NY, New York, New York; Samsung AI Center NY, New York, New York; Samsung AI Center NY, New York, New York; Samsung AI Center NY, New York, New York; Samsung AI Center NY, New York, New York; Samsung AI Center NY, New York, New York; Samsung AI Center NY, New York, New York; Samsung AI Center NY, New York, New York",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341719/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12132565717699899511&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Samsung AI Center",
        "aff_unique_dep": "AI Center",
        "aff_unique_url": "https://www.samsung.com/global/innovation/ai-research/",
        "aff_unique_abbr": "SAC NY",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0",
        "aff_campus_unique": "New York",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341558",
        "title": "Acquiring Mechanical Knowledge from 3D Point Clouds",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider the problem of acquiring mechanical knowledge through visual cues to help robots use objects in new situations. In this work, we propose a novel deep learning approach that allows a robot to acquire mechanical knowledge from 3D point clouds. This presents two main challenges. The first challenge is that a robot needs to infer novel objects' functions from its experience. Secondly, the robot should also need to know how to manipulate these novel objects. To solve these problems, we present a two-branch deep neural network. The first branch detects function parts from the point clouds while the second branch predicts offset poses. Fusing the results from these two branches, our approach can not only detect what functions the novel objects may have but also generate key object states which can be used to guide a robot to manipulate these objects. We show that even though most of the training samples are synthetic data, our model still learns useful features and outputs proper results. Finally, we evaluate our approach on a real robot to run a series of tasks. The experimental results show that our approach has the capability to transfer mechanical knowledge in new situations.",
        "primary_area": "",
        "author": "Zijia Li;Kei Okada;Masayuki Inaba;Zijia Li;Kei Okada;Masayuki Inaba",
        "authorids": "/37086121448;/37280639000;/37286658200;/37086121448;/37280639000;/37286658200",
        "aff": "Department of Mechano-Infomatics, The University of Tokyo, Tokyo, Japan; Department of Mechano-Infomatics, The University of Tokyo, Tokyo, Japan; Department of Mechano-Infomatics, The University of Tokyo, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341558/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8767417958926266515&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "The University of Tokyo",
        "aff_unique_dep": "Department of Mechano-Infomatics",
        "aff_unique_url": "https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "UTokyo",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9340643",
        "title": "Action Sequence Predictions of Vehicles in Urban Environments using Map and Social Context",
        "track": "main",
        "status": "Poster",
        "abstract": "This work studies the problem of predicting the sequence of future actions for surrounding vehicles in real-world driving scenarios. To this aim, we make three main contributions. The first contribution is an automatic method to convert the trajectories recorded in real-world driving scenarios to action sequences with the help of HD maps. The method enables automatic dataset creation for this task from large-scale driving data. Our second contribution lies in applying the method to the well-known traffic agent tracking and prediction dataset Argoverse, resulting in 228,000 action sequences. Additionally, 2,245 action sequences were manually annotated for testing. The third contribution is to propose a novel action sequence prediction method by integrating past positions and velocities of the traffic agents, map information and social context into a single end-to-end trainable neural network. Our experiments prove the merit of the data creation method and the value of the created dataset - prediction performance improves consistently with the size of the dataset and shows that our action prediction method outperforms comparing models.",
        "primary_area": "",
        "author": "Jan-Nico Zaech;Dengxin Dai;Alexander Liniger;Luc Van Gool;Jan-Nico Zaech;Dengxin Dai;Alexander Liniger;Luc Van Gool",
        "authorids": "/37087103975;/37531409100;/37085702116;/37266870700;/37087103975;/37531409100;/37085702116;/37266870700",
        "aff": "Computer Vision Laboratory, ETH, Zurich, Switzerland; Computer Vision Laboratory, ETH, Zurich, Switzerland; Computer Vision Laboratory, ETH, Zurich, Switzerland; Dept. of Electrical Engineering, ESAT, KU, Leuven, Belgium",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340643/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8215076552376049858&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "ETH Zurich;Katholieke Universiteit Leuven",
        "aff_unique_dep": "Computer Vision Laboratory;Dept. of Electrical Engineering",
        "aff_unique_url": "https://www.ethz.ch;https://www.kuleuven.be",
        "aff_unique_abbr": "ETHZ;KU Leuven",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "Zurich;Leuven",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "Switzerland;Belgium"
    },
    {
        "id": "9340842",
        "title": "Active 6D Multi-Object Pose Estimation in Cluttered Scenarios with Deep Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "",
        "primary_area": "",
        "author": "Juil Sock;Guillermo Garcia-Hernando;Tae-Kyun Kim;Juil Sock;Guillermo Garcia-Hernando;Tae-Kyun Kim",
        "authorids": "/37085408287;/37085396272;/37280613000;/37085408287;/37085396272;/37280613000",
        "aff": "",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340842/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11562973951770824544&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6
    },
    {
        "id": "9341442",
        "title": "Active Alignment Control-based LED Communication for Underwater Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Achieving and maintaining line-of-sight (LOS) is challenging for underwater optical communication systems, especially when the underlying platforms are mobile. In this work, we propose and demonstrate an active alignment controlbased LED-communication system that uses the DC value of the communication signal as feedback for LOS maintenance. Utilizing the uni-modal nature of the dependence of the light signal strength on local angles, we propose a novel triangular exploration algorithm, that does not require the knowledge of the underlying light intensity model, to maximize the signal strength that leads to achieving and maintaining LOS. The method maintains an equilateral triangle shape in the angle space for any three consecutive exploration points, while ensuring the consistency of exploration direction with the local gradient of signal strength. The effectiveness of the approach is first evaluated in simulation by comparison with extremum-seeking control, where the proposed approach shows a significant advantage in the convergence speed. The efficacy is further demonstrated experimentally, where an underwater robot is controlled by a joystick via LED communication.",
        "primary_area": "",
        "author": "Pratap Bhanu Solanki;Shaunak D. Bopardikar;Xiaobo Tan;Pratap Bhanu Solanki;Shaunak D. Bopardikar;Xiaobo Tan",
        "authorids": "/37085827743;/37076274700;/37420481400;/37085827743;/37076274700;/37420481400",
        "aff": "Department of Electrical and Computer Engineering, Michigan State University, East Lansing, MI, USA; Department of Electrical and Computer Engineering, Michigan State University, East Lansing, MI, USA; Department of Electrical and Computer Engineering, Michigan State University, East Lansing, MI, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341442/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15657986958133255116&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Michigan State University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.msu.edu",
        "aff_unique_abbr": "MSU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "East Lansing",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341187",
        "title": "Active Improvement of Control Policies with Bayesian Gaussian Mixture Model",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning from demonstration (LfD) is an intuitive framework allowing non-expert users to easily (re-)program robots. However, the quality and quantity of demonstrations have a great influence on the generalization performances of LfD approaches. In this paper, we introduce a novel active learning framework in order to improve the generalization capabilities of control policies. The proposed approach is based on the epistemic uncertainties of Bayesian Gaussian mixture models (BGMMs). We determine the new query point location by optimizing a closed-form information-density cost based on the quadratic R\u00e9nyi entropy. Furthermore, to better represent uncertain regions and to avoid local optima problem, we propose to approximate the active learning cost with a Gaussian mixture model (GMM). We demonstrate our active learning framework in the context of a reaching task in a cluttered environment with an illustrative toy example and a real experiment with a Panda robot.",
        "primary_area": "",
        "author": "Hakan Girgin;Emmanuel Pignat;No\u00e9mie Jaquier;Sylvain Calinon;Hakan Girgin;Emmanuel Pignat;No\u00e9mie Jaquier;Sylvain Calinon",
        "authorids": "/37086578243;/37086455266;/37086290815;/37295947200;/37086578243;/37086455266;/37086290815;/37295947200",
        "aff": "Idiap Research Institute, Switzerland; Idiap Research Institute, Switzerland; Idiap Research Institute, Switzerland; Idiap Research Institute, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341187/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4431759089492747578&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Idiap Research Institute",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.idiap.ch",
        "aff_unique_abbr": "Idiap",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9340974",
        "title": "Active Perception for Outdoor Localisation with an Omnidirectional Camera",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel localisation framework based on an omnidirectional camera, targeted at outdoor urban environments. Bearing only information to persistent and easily observable high-level semantic landmarks (such as lamp-posts, street-signs and trees) are perceived using a Convolutional Neural Network (CNN). The framework utilises an information theoretic strategy to decide the best viewpoint to serve as an input to the CNN instead of the full 360\u00b0 coverage offered by an omnidirectional camera, in order to leverage the advantage of having a higher field of view without compromising on performance. Environmental landmark observations are supplemented with observations to ground surface boundaries corresponding to high-level features such as manhole covers, pavement edges and lane markings extracted from a second CNN. Localisation is carried out in an Extended Kalman Filter (EKF) framework using a sparse 2D map of the environmental landmarks and Vector Distance Transform (VDT) based representation of the ground surface boundaries. This is in contrast to traditional vision only localisation systems that have to carry out Visual Odometry (VO) or Simultaneous Localisation and Mapping (SLAM), since low level features (such as SIFT, SURF, ORB) do not persist over long time frames due to radical appearance changes (illumination, occlusions etc) and dynamic objects. As the proposed framework relies on highlevel persistent semantic features of the environment, it offers an opportunity to carry out localisation on a prebuilt map, which is significantly more resource efficient and robust. Experiments using a Personal Mobility Device (PMD) driven in a representative urban environment are presented to demonstrate and evaluate the effectiveness of the proposed localiser against relevant state of the art techniques.",
        "primary_area": "",
        "author": "Maleen Jayasuriya;Ravindra Ranasinghe;Gamini Dissanayake;Maleen Jayasuriya;Ravindra Ranasinghe;Gamini Dissanayake",
        "authorids": "/37087108083;/37885774100;/37279864800;/37087108083;/37885774100;/37279864800",
        "aff": "Centre for Autonomous Systems (CAS), University of Technology, Sydney, Australia; Centre for Autonomous Systems (CAS), University of Technology, Sydney, Australia; Centre for Autonomous Systems (CAS), University of Technology, Sydney, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340974/",
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=206549167274743230&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Technology, Sydney",
        "aff_unique_dep": "Centre for Autonomous Systems (CAS)",
        "aff_unique_url": "https://www.uts.edu.au",
        "aff_unique_abbr": "UTS",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Sydney",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "9341530",
        "title": "Active Preference Learning using Maximum Regret",
        "track": "main",
        "status": "Poster",
        "abstract": "We study active preference learning as a frame-work for intuitively specifying the behaviour of autonomous robots. A user chooses the preferred behaviour from a set of alternatives, from which the robot learns the user's preferences, modeled as a parameterized cost function. Previous approaches present users with alternatives that minimize the uncertainty over the parameters of the cost function. However, different parameters might lead to the same optimal behaviour; as a consequence the solution space is more structured than the parameter space. We exploit this by proposing a query selection that greedily reduces the maximum error ratio over the solution space. In simulations we demonstrate that the proposed approach outperforms other state of the art techniques in both learning efficiency and ease of queries for the user. Finally, we show that evaluating the learning based on the similarities of solutions instead of the similarities of weights allows for better predictions for different scenarios.",
        "primary_area": "",
        "author": "Nils Wilde;Dana Kuli\u0107;Stephen L. Smith;Nils Wilde;Dana Kuli\u0107;Stephen L. Smith",
        "authorids": "/37086453460;/37547876700;/37335139700;/37086453460;/37547876700;/37335139700",
        "aff": "Department of Electrical and Computer Engineering, University of Waterloo; The University of Waterloo and Monash University; Department of Electrical and Computer Engineering, University of Waterloo",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341530/",
        "gs_citation": 51,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9065759408511203340&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Waterloo;The University of Waterloo",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;",
        "aff_unique_url": "https://uwaterloo.ca;https://uwaterloo.ca",
        "aff_unique_abbr": "UW;UW",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9341124",
        "title": "Adaptability Preserving Domain Decomposition for Stabilizing Sim2Real Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "In sim-to-real transfer of Reinforcement Learning (RL) policies for robot tasks, Domain Randomization (DR) is a widely used technique for improving adaptability. However, in DR there is a conflict between adaptability and training stability, and heavy DR tends to result in instability or even failure in training. To relieve this conflict, we propose a new algorithm named Domain Decomposition (DD) that decomposes the randomized domain according to environments and trains a separate RL policy for each part. This decomposition stabilizes the training of each RL policy, and as we prove theoretically, the adaptability of the overall policy can be preserved. Our simulation results verify that DD really improves stability in training while preserving ideal adaptability. Further, we complete a complex real-world vision-based patrolling task using DD, which demonstrates DD\u2019s practicality. A video is attached as supplementary material.",
        "primary_area": "",
        "author": "Haichuan Gao;Zhile Yang;Xin Su;Tian Tan;Feng Chen;Haichuan Gao;Zhile Yang;Xin Su;Tian Tan;Feng Chen",
        "authorids": "/37088691157;/37085376875;/37329334500;/37085592701;/37536944100;/37088691157;/37085376875;/37329334500;/37085592701;/37536944100",
        "aff": "Tsinghua University, Beijing, China; Tsinghua University, Beijing, China; Tsinghua University, Beijing, China; Stanford University, Stanford, USA; Tsinghua University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341124/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9781356688536814476&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Tsinghua University;Stanford University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.tsinghua.edu.cn;https://www.stanford.edu",
        "aff_unique_abbr": "THU;Stanford",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Beijing;Stanford",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9340927",
        "title": "Adaptive Dynamic Window Approach for Local Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "Local navigation is an essential ability of any mobile robot working in a real-world environment. One of the most commonly used methods for local navigation is the Dynamic Window Approach (DWA), which heavily depends on the settings of the parameters in its cost function. Since the optimal choice of the parameters depends on the environment that may significantly vary and change at any time, the parameters should be chosen dynamically in a data-driven way. To cope with this problem, we propose a novel deep convolutional neural network, which dynamically predicts these parameters considering the sensor readings. The network is trained using a state-of-the art reinforcement learning algorithm. In this way, we combine the power of data-driven learning and the dynamic model of the robot, enabling adaptation to the current environment as well as guaranteeing collision-free movement and smooth trajectories of the mobile robot. The experimental results show that the proposed method outperforms the DWA method as well as its recent extension.",
        "primary_area": "",
        "author": "Matej Dobrevski;Danijel Sko\u010daj;Matej Dobrevski;Danijel Sko\u010daj",
        "authorids": "/37086376145;/38574777500;/37086376145;/38574777500",
        "aff": "Visual Cognitive Systems Laboratory, Faculty of Computer and Information Science, University of Ljubljana, Ljubljana, Slovenia; Visual Cognitive Systems Laboratory, Faculty of Computer and Information Science, University of Ljubljana, Ljubljana, Slovenia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340927/",
        "gs_citation": 50,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2305787418414204590&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Ljubljana",
        "aff_unique_dep": "Faculty of Computer and Information Science",
        "aff_unique_url": "https://www.fri.uni-lj.si",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Ljubljana",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Slovenia"
    },
    {
        "id": "9340920",
        "title": "Adaptive Gait Pattern Generation of a Powered Exoskeleton by Iterative Learning of Human Behavior",
        "track": "main",
        "status": "Poster",
        "abstract": "Several powered exoskeletons have been developed and commercialized to assist people with complete spinal cord injury. For motion control of a powered exoskeleton, a normal gait pattern is often applied as a reference. However, the physical ability of paraplegics and the degrees of freedom of powered exoskeletons are totally different from those of people without disabilities. Therefore, this paper introduces a novel gait pattern depart from the normal gait, which is proper to the paraplegics. Since a human is included, the system of the powered exoskeleton has lots of motion uncertainties that may not be perfectly predicted resulting from different physical properties of paraplegics (SCI level, muscular strength of the upper body, body parameters, inertia), actions from crutches (position and timing to put), several types of training (period, methodology), etc. Then, to find a stable and safe gait pattern adapted to the individual user, an iterative way to compensate the gait pattern is also required. In this paper, human iterative learning algorithm, which utilizes the accumulated data during walking to adjust the gait trajectories is proposed. Additionally, the effectiveness of the proposed gait pattern is verified by human walking experiments.",
        "primary_area": "",
        "author": "Kyeong-Won Park;Jeongsu Park;Jungsu Choi;Kyoungchul Kong;Kyeong-Won Park;Jeongsu Park;Jungsu Choi;Kyoungchul Kong",
        "authorids": "/37088687129;/37088690382;/37085898280;/37410344000;/37088687129;/37088690382;/37085898280;/37410344000",
        "aff": "Department of Mechanical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, Korea; Department of Mechanical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, Korea; Department of Robotics Engineering, Yeungnam University, Gyeongsan, Korea; Department of Mechanical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340920/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12342078725800768751&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology;Yeungnam University",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Robotics Engineering",
        "aff_unique_url": "https://www.kaist.ac.kr;http://www.yu.ac.kr",
        "aff_unique_abbr": "KAIST;YU",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Daejeon;Gyeongsan",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9341711",
        "title": "Adaptive Informative Sampling with Environment Partitioning for Heterogeneous Multi-Robot Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-robot systems are widely used in environmental exploration and modeling, especially in hazardous environments. However, different types of robots are limited by different mobility, battery life, sensor type, etc. Heterogeneous robot systems are able to utilize various types of robots and provide solutions where robots are able to compensate each other with their different capabilities. In this paper, we consider the problem of sampling and modeling environmental characteristics with a heterogeneous team of robots. To utilize heterogeneity of the system while remaining computationally tractable, we propose an environmental partitioning approach that leverages various robot capabilities by forming a uniformly defined heterogeneity cost space. We combine with the mixture of Gaussian Processes model-learning framework to adaptively sample and model the environment in an efficient and scalable manner. We demonstrate our algorithm in field experiments with ground and aerial vehicles.",
        "primary_area": "",
        "author": "Yunfei Shi;Ning Wang;Jianmin Zheng;Yang Zhang;Sha Yi;Wenhao Luo;Katia Sycara;Yunfei Shi;Ning Wang;Jianmin Zheng;Yang Zhang;Sha Yi;Wenhao Luo;Katia Sycara",
        "authorids": "/37086453749;/37088688987;/37088687002;/37088690460;/37088506867;/37085748889;/37268476900;/37086453749;/37088688987;/37088687002;/37088690460;/37088506867;/37085748889;/37268476900",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341711/",
        "gs_citation": 45,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4916559270855330012&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341099",
        "title": "Adaptive Kernel Inference for Dense and Sharp Occupancy Grids",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a new approach, AKIMap, that uses an adaptive kernel inference for dense and sharp occupancy grid representations. Our approach is based on the multivariate kernel estimation, and we propose a simple, two-stage based method that selects an adaptive bandwidth matrix for an efficient and accurate occupancy estimation. To utilize correlations of occupancy observations given sparse and non-uniform distributions of point samples, we propose to use the covariance matrix as an initial bandwidth matrix, and then optimize the bandwidth matrix by adjusting its scale in an efficient, data-driven way for on-the-fly mapping. We demonstrate that the proposed technique estimates occupancy states more accurately than state-of-the-art methods given equal-data or equal-time settings, thanks to our adaptive inference. Furthermore, we show the practical benefits of the proposed work in on-the-fly mapping and observe that our adaptive approach shows the dense as well as sharp occupancy representations in a real environment.",
        "primary_area": "",
        "author": "Youngsun Kwon;Bochang Moon;Sung-Eui Yoon;Youngsun Kwon;Bochang Moon;Sung-Eui Yoon",
        "authorids": "/37085769014;/37088687277;/37066068100;/37085769014;/37088687277;/37066068100",
        "aff": "School of Computing, Korea Advanced Institute of Science and Technology, Daejeon, South Korea; School of Integrated Technology, Gwangju Institute of Science and Technology, Gwangju, South Korea; School of Computing, Korea Advanced Institute of Science and Technology, Daejeon, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341099/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9836478873655853945&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology;Gwangju Institute of Science and Technology",
        "aff_unique_dep": "School of Computing;School of Integrated Technology",
        "aff_unique_url": "https://www.kaist.ac.kr;https://www.gist.ac.kr",
        "aff_unique_abbr": "KAIST;GIST",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Daejeon;Gwangju",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9341793",
        "title": "Adaptive Nonlinear Control For Perching of a Bioinspired Ornithopter",
        "track": "main",
        "status": "Poster",
        "abstract": "This work presents a model-free nonlinear controller for an ornithopter prototype with bioinspired wings and tail. The size and power requirements have been thought to allocate a customized autopilot on board. To assess the functionality and performance of the full mechatronic design, a controller has been designed and implemented to execute a prescribed perching 2D trajectory. Although functional, its 'handmade' nature forces many imperfections that cause uncertainty that hinder its control. Therefore, the controller is based on adaptive backstepping and does not require any knowledge of the aerodynamics. The controller is able to follow a given reference in flight path angle by actuating only on the tail deflection. A novel space-dependent nonlinear guidance law is also provided to prescribe the perching trajectory. Mechatronics, guidance and control system performance is validated by conducting indoor flight tests.",
        "primary_area": "",
        "author": "F. J. Maldonado;J. \u00c1. Acosta;J. Tormo-Barbero;P. Grau;M. M. Guzm\u00e1n;A. Ollero;F. J. Maldonado;J. \u00c1. Acosta;J. Tormo-Barbero;P. Grau;M. M. Guzm\u00e1n;A. Ollero",
        "authorids": "/37088688490;/37399220800;/37088690316;/37086922196;/37088691085;/37265412000;/37088688490;/37399220800;/37088690316;/37086922196;/37088691085;/37265412000",
        "aff": "GRVC Robotics Laboratory, Universidad de Sevilla, Sevilla; GRVC Robotics Laboratory, Universidad de Sevilla, Sevilla; GRVC Robotics Laboratory, Universidad de Sevilla, Sevilla; GRVC Robotics Laboratory, Universidad de Sevilla, Sevilla; GRVC Robotics Laboratory, Universidad de Sevilla, Sevilla; GRVC Robotics Laboratory, Universidad de Sevilla, Sevilla",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341793/",
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4056786778731800236&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Universidad de Sevilla",
        "aff_unique_dep": "GRVC Robotics Laboratory",
        "aff_unique_url": "https://www.us.es",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Sevilla",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Spain"
    },
    {
        "id": "9341417",
        "title": "Adaptive Partitioning for Coordinated Multi-agent Perimeter Defense",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-Robot Systems have been recently employed in different applications and have advantages over single-robot systems, such as increased robustness and task performance efficiency. We consider such assemblies specifically in the scenario of perimeter defense, where the task is to defend a circular perimeter by intercepting radially approaching targets. Possible intruders appear randomly at a fixed distance from the perimeter and with azimuthal location determined by some unknown probability density. Coordination among multiple defenders is a complex combinatorial optimization problem. In this work, we focus on the following two aspects: (i) estimating the probability density that describes the direction from which the next intruders are going to arrive, and (ii) partitioning of the space so that the defenders focus on capturing a disjoint subset of intruders. Results show that the proposed strategy increases the number of captures over a naive baseline strategy, especially in scenarios with non-uniform spatial distributions of intruder arrival. The proposed approach is also efficient and able to quickly adapt to time-varying intruder distributions.",
        "primary_area": "",
        "author": "Douglas G. Macharet;Austin K. Chen;Daigo Shishika;George J. Pappas;Vijay Kumar;Douglas G. Macharet;Austin K. Chen;Daigo Shishika;George J. Pappas;Vijay Kumar",
        "authorids": "/37590114800;/37088686907;/37085516690;/37281547100;/37280341400;/37590114800;/37088686907;/37085516690;/37281547100;/37280341400",
        "aff": "Department of Computer Science, Computer Vision and Robotics Laboratory (VeRLab), Universidade Federal de Minas Gerais, Brazil; GRASP Lab, University of Pennsylvania, Philadelphia, USA; GRASP Lab, University of Pennsylvania, Philadelphia, USA; GRASP Lab, University of Pennsylvania, Philadelphia, USA; GRASP Lab, University of Pennsylvania, Philadelphia, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341417/",
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2130754727743350833&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;1",
        "aff_unique_norm": "Universidade Federal de Minas Gerais;University of Pennsylvania",
        "aff_unique_dep": "Department of Computer Science;GRASP Lab",
        "aff_unique_url": "http://www.ufmg.br;https://www.upenn.edu",
        "aff_unique_abbr": "UFMG;UPenn",
        "aff_campus_unique_index": "1;1;1;1",
        "aff_campus_unique": ";Philadelphia",
        "aff_country_unique_index": "0;1;1;1;1",
        "aff_country_unique": "Brazil;United States"
    },
    {
        "id": "9341436",
        "title": "Adaptive Potential Scanning for a Tomographic Tactile Sensor with High Spatio-Temporal Resolution",
        "track": "main",
        "status": "Poster",
        "abstract": "A tactile sensor with high spatio-temporal resolution will greatly contribute to improving the performance of object recognition and human interaction in robots. In addition, being able to switch between higher spatial and higher temporal resolution will allow for more versatile sensing. To realize such a sensor, this paper introduces a method of increasing the sensing electrodes and adaptively selecting the grounding conditions in a tomography based tactile sensor. Several types of grounding conditions are proposed and evaluated using spatio-temporal metrics. As a result, the grounding method based on the location of contact had a good balance of temporal resolution (1 ms) and spatial resolution (only 1.55 times larger than using all electrodes as grounding conditions). When reconstructing dynamic contact data, the proposed method was able to obtain a much higher detailed waveform compared to the conventional method. By using the proposed method as default and switching to other grounding methods depending on the purpose of sensing, a versatile tactile sensor with high spatio-temporal resolution can be made.",
        "primary_area": "",
        "author": "Hiroki Mitsubayashi;Shunsuke Yoshimoto;Akio Yamamoto;Hiroki Mitsubayashi;Shunsuke Yoshimoto;Akio Yamamoto",
        "authorids": "/37088020599;/37683243600;/37278496400;/37088020599;/37683243600;/37278496400",
        "aff": "School of Engineering, The University of Tokyo, Tokyo, Japan; the Graduate School of Frontier Sciences, The University of Tokyo, Chiba, Japan; the Graduate School of Frontier Sciences, The University of Tokyo, Chiba, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341436/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12121166604697648481&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "The University of Tokyo",
        "aff_unique_dep": "School of Engineering",
        "aff_unique_url": "https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "UTokyo",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Tokyo;Chiba",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9341459",
        "title": "Adaptive Precision-Enhancing Hand Rendering for Wearable Fingertip Tracking Devices",
        "track": "main",
        "status": "Poster",
        "abstract": "We introduce a 3D hand rendering framework to reconstruct a visually realistic hand from a set of fingertip positions. One of the key limitations of wearable fingertip tracking devices used in VR/AR applications is the lack of detailed measurements and tracking of the hand, making the hand rendering difficult. The motivation for this paper is to develop a general framework to render a visually plausible hand given only the fingertip positions. In addition, our framework adjusts the size of a virtual hand based on the fingertip positions and device's structure, and reduces a mismatch between the pose of the rendered and user's hand by retargeting virtual finger motions. Moreover, we impose a new hinge constraint on the finger model to employ a real-time inverse kinematic solver. We show our framework is helpful for performing virtual grasping tasks more efficiently when only the measurements of fingertip positions are available.",
        "primary_area": "",
        "author": "Hyojoon Park;Jung-Min Park;Hyojoon Park;Jung-Min Park",
        "authorids": "/37088689465;/37351422900;/37088689465;/37351422900",
        "aff": "intern researcher at Korea Institute of Science and Technology (KIST), Seoul, Korea; Senior Research Scientist at the Center for Intelligent and Interactive Robotics, Korea Institute of Science and Technology (KIST), Seoul, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341459/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:UOA5MEjSx9gJ:scholar.google.com/&scioq=Adaptive+Precision-Enhancing+Hand+Rendering+for+Wearable+Fingertip+Tracking+Devices&hl=en&as_sdt=0,5",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Korea Institute of Science and Technology",
        "aff_unique_dep": "intern researcher",
        "aff_unique_url": "https://www.kist.re.kr",
        "aff_unique_abbr": "KIST",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9341736",
        "title": "Adaptive Reliable Shortest Path in Gaussian Process Regulated Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper studies the adaptive reliable shortest path (RSP) planning problem in a Gaussian process (GP) regulated environment. With the reasonable assumption that the travel times of the underlying transportation network follow a multi-variate Gaussian distribution, we propose two algorithms namely, Gaussian process reactive path planning (GPRPP), and Gaussian process proactive path planning (GP4), to generate online adaptive routing policies for the reliable shortest path. Both algorithms take advantage of the posterior analytical representation of GPs given past and/or imagined future observations of certain links in the network, and calculate the corresponding adaptive routing strategy for RSP. Theoretical analysis and simulation results (on Sioux Falls Network and Singapore road networks) show the superior performance of GPRPP and GP4 over that of the state of the arts.",
        "primary_area": "",
        "author": "Xuejie HOU;Hongliang GUO;Yucheng ZHANG;Xuejie HOU;Hongliang GUO;Yucheng ZHANG",
        "authorids": "/37088690509;/37085490043;/37405804600;/37088690509;/37085490043;/37405804600",
        "aff": "University of Electronic Science and Technology of China, China; University of Electronic Science and Technology of China, China; Intelligent Agricultural Machinery Equipment Laboratory of Chinese Academy of Sciences, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341736/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11817075800236112344&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "University of Electronic Science and Technology of China;Chinese Academy of Sciences",
        "aff_unique_dep": ";Intelligent Agricultural Machinery Equipment Laboratory",
        "aff_unique_url": "http://www.uestc.edu.cn;http://www.cas.cn",
        "aff_unique_abbr": "UESTC;CAS",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Beijing",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9341359",
        "title": "Adaptive Robot-Assisted Feeding: An Online Learning Framework for Acquiring Previously Unseen Food Items",
        "track": "main",
        "status": "Poster",
        "abstract": "A successful robot-assisted feeding system requires bite acquisition of a wide variety of food items. It must adapt to changing user food preferences under uncertain visual and physical environments. Different food items in different environmental conditions require different manipulation strategies for successful bite acquisition. Therefore, a key challenge is how to handle previously unseen food items with very different success rate distributions over strategy. Combining low-level controllers and planners into discrete action trajectories, we show that the problem can be represented using a linear contextual bandit setting. We construct a simulated environment using a doubly robust loss estimate from previously seen food items, which we use to tune the parameters of off-the-shelf contextual bandit algorithms. Finally, we demonstrate empirically on a robot- assisted feeding system that, even starting with a model trained on thousands of skewering attempts on dissimilar previously seen food items, \u03f5-greedy and LinUCB algorithms can quickly converge to the most successful manipulation strategy.",
        "primary_area": "",
        "author": "Ethan K. Gordon;Xiang Meng;Tapomayukh Bhattacharjee;Matt Barnes;Siddhartha S. Srinivasa;Ethan K. Gordon;Xiang Meng;Tapomayukh Bhattacharjee;Matt Barnes;Siddhartha S. Srinivasa",
        "authorids": "/37088688098;/37088689172;/37531634500;/37088691047;/37339877600;/37088688098;/37088689172;/37531634500;/37088691047;/37339877600",
        "aff": "Department of Computer Science and Engineering, University of Washington, Seattle, WA; Department of Statistics, University of Washington, Seattle, WA; Department of Computer Science and Engineering, University of Washington, Seattle, WA; Department of Computer Science and Engineering, University of Washington, Seattle, WA; Department of Computer Science and Engineering, University of Washington, Seattle, WA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341359/",
        "gs_citation": 49,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18055857475557796425&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Washington",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.washington.edu",
        "aff_unique_abbr": "UW",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Seattle",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340801",
        "title": "Adversarial Generation of Informative Trajectories for Dynamics System Identification",
        "track": "main",
        "status": "Poster",
        "abstract": "Dnamic System Identification approaches usually heavily rely on evolutionary and gradient-based optimisation techniques to produce optimal excitation trajectories for determining the physical parameters of robot platforms. Current optimisation techniques tend to generate single trajectories. This is expensive, and intractable for longer trajectories, thus limiting their efficacy for system identification. We propose to tackle this issue by using multiple shorter cyclic trajectories, which can be generated in parallel, and subsequently combined together to achieve the same effect as a longer trajectory. Crucially, we show how to scale this approach even further by increasing the generation speed and quality of the dataset through the use of generative adversarial network (GAN) based architectures to produce large databases of valid and diverse excitation trajectories. To the best of our knowledge, this is the first robotics work to explore system identification with multiple cyclic trajectories and to develop GAN-based techniques for scaleably producing excitation trajectories that are diverse in both control parameter and inertial parameter spaces. We show that our approach dramatically accelerates trajectory optimisation, while simultaneously providing more accurate system identification than the conventional approach.",
        "primary_area": "",
        "author": "Marija Jegorova;Joshua Smith;Michael Mistry;Timothy Hospedales;Marija Jegorova;Joshua Smith;Michael Mistry;Timothy Hospedales",
        "authorids": "/37087014381;/37086455996;/37542865600;/37398197200;/37087014381;/37086455996;/37542865600;/37398197200",
        "aff": "University of Edinburgh, UK; University of Edinburgh, UK; University of Edinburgh, UK; University of Edinburgh, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340801/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12924894203839812139&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Edinburgh",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.ed.ac.uk",
        "aff_unique_abbr": "Edinburgh",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9341402",
        "title": "Aerial Transportation of Unknown Payloads: Adaptive Path Tracking for Quadrotors",
        "track": "main",
        "status": "Poster",
        "abstract": "With the advent of intelligent transport, quadrotors are becoming an attractive aerial transport solution during emergency evacuations, construction works etc. During such operations, dynamic variations in (possibly unknown) payload and unknown external disturbances cause considerable control challenges for path tracking algorithms. In fact, the state-dependent nature of the resulting uncertainties makes state-of-the-art adaptive control solutions ineffective against such uncertainties that can be completely unknown and possibly unbounded a priori. This paper, to the best of the knowledge of the authors, proposes the first adaptive control solution for quadrotors, which does not require any a priori knowledge of the parameters of quadrotor dynamics as well as of external disturbances. The stability of the closed-loop system is studied analytically via Lyapunov theory and the effectiveness of the proposed solution is verified on a realistic simulator.",
        "primary_area": "",
        "author": "Viswa N. Sankaranarayanan;Spandan Roy;Simone Baldi;Viswa N. Sankaranarayanan;Spandan Roy;Simone Baldi",
        "authorids": "/37088685917;/37085547823;/37392245700;/37088685917;/37085547823;/37392245700",
        "aff": "Robotics Research Center, International Institute of Information Technology Hyderabad (IIIT-H), Hyderabad, India; Robotics Research Center, International Institute of Information Technology Hyderabad (IIIT-H), Hyderabad, India; School of CyberScience and Engineering, Southeast University, Nanjing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341402/",
        "gs_citation": 45,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=899149825571289166&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "International Institute of Information Technology Hyderabad;Southeast University",
        "aff_unique_dep": "Robotics Research Center;School of CyberScience and Engineering",
        "aff_unique_url": "https://iiit Hyderabad.ac.in;https://www.seu.edu.cn/",
        "aff_unique_abbr": "IIIT-H;SEU",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Hyderabad;Nanjing",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "India;China"
    },
    {
        "id": "9341482",
        "title": "Affordance-Based Grasping and Manipulation in Real World Applications",
        "track": "main",
        "status": "Poster",
        "abstract": "In real world applications, robotic solutions remain impractical due to the challenges that arise in unknown and unstructured environments. To perform complex manipulation tasks in complex and cluttered situations, robots need to be able to identify the interaction possibilities with the scene, i.e. the affordances of the objects encountered. In unstructured environments with noisy perception, insufficient scene understanding and limited prior knowledge, this is a challenging task. In this work, we present an approach for grasping unknown objects in cluttered scenes with a humanoid robot in the context of a nuclear decommissioning task. Our approach combines the convenience and reliability of autonomous robot control with the precision and adaptability of teleoperation in a semi-autonomous selection of grasp affordances. Additionally, this allows exploiting the expert knowledge of an experienced human worker. To evaluate our approach, we conducted 75 real world experiments with more than 660 grasp executions on the humanoid robot ARMAR-6. The results demonstrate that high-level decisions made by the human operator, supported by autonomous robot control, contribute significantly to successful task execution.",
        "primary_area": "",
        "author": "Christoph Pohl;Kevin Hitzler;Raphael Grimm;Antonio Zea;Uwe D. Hanebeck;Tamim Asfour;Christoph Pohl;Kevin Hitzler;Raphael Grimm;Antonio Zea;Uwe D. Hanebeck;Tamim Asfour",
        "authorids": "/37089404480;/37088340636;/37085813662;/38469787300;/37299183800;/37295529100;/37089404480;/37088340636;/37085813662;/38469787300;/37299183800;/37295529100",
        "aff": "Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341482/",
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8532341139151338067&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Karlsruhe Institute of Technology",
        "aff_unique_dep": "Institute for Anthropomatics and Robotics",
        "aff_unique_url": "https://www.kit.edu",
        "aff_unique_abbr": "KIT",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Karlsruhe",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9341337",
        "title": "Affordance-Based Mobile Robot Navigation Among Movable Obstacles",
        "track": "main",
        "status": "Poster",
        "abstract": "Avoiding obstacles in the perceived world has been the classical approach to autonomous mobile robot navigation. However, this usually leads to unnatural and inefficient motions that significantly differ from the way humans move in tight and dynamic spaces, as we do not refrain interacting with the environment around us when necessary. Inspired by this observation, we propose a framework for autonomous robot navigation among movable obstacles (NAMO) that is based on the theory of affordances and contact-implicit motion planning. We consider a realistic scenario in which a mobile service robot negotiates unknown obstacles in the environment while navigating to a goal state. An affordance extraction procedure is performed for novel obstacles to detect their movability, and a contact-implicit trajectory optimization method is used to enable the robot to interact with movable obstacles to improve the task performance or to complete an otherwise infeasible task. We demonstrate the performance of the proposed framework by hardware experiments with Toyota's Human Support Robot.",
        "primary_area": "",
        "author": "Maozhen Wang;Rui Luo;Aykut \u00d6zg\u00fcn \u00d6nol;Ta\u015fkin Padir;Maozhen Wang;Rui Luo;Aykut \u00d6zg\u00fcn \u00d6nol;Ta\u015fkin Padir",
        "authorids": "/37086457769;/37088687913;/37085735725;/38496444600;/37086457769;/37088687913;/37085735725;/38496444600",
        "aff": "Institute for Experiential Robotics, Northeastern University, Boston, MA, USA; Institute for Experiential Robotics, Northeastern University, Boston, MA, USA; Institute for Experiential Robotics, Northeastern University, Boston, MA, USA; Institute for Experiential Robotics, Northeastern University, Boston, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341337/",
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13346368202969021949&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Northeastern University",
        "aff_unique_dep": "Institute for Experiential Robotics",
        "aff_unique_url": "https://www.northeastern.edu",
        "aff_unique_abbr": "NU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Boston",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341726",
        "title": "Algorithm for Multi-Robot Chance-Constrained Generalized Assignment Problem with Stochastic Resource Consumption",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a novel algorithm for the multi-robot generalized assignment problem (GAP) with stochastic resource consumption. In this problem, each robot has a resource (e.g., battery life) constraint and it consumes a certain amount of resource to perform a task. In practice, the resource consumed for performing a task can be uncertain. Therefore, we assume that the resource consumption is a random variable with known mean and variance. The objective is to find an assignment of the robots to tasks that maximizes the team payoff. Each task is assigned to at most one robot and the resource constraint for each robot has to be satisfied with very high probability. We formulate the problem as a chance-constrained combinatorial optimization problem and call it the chance-constrained generalized assignment problem (CC-GAP). This problem is an extension of the deterministic generalized assignment problem, which is a NP-hard problem. We design an iterative algorithm for solving CC-GAP in which each robot maximizes its own objective by solving a chance-constrained knapsack problem in an iterative manner. The approximation ratio of our algorithm is (1+\u03b1), assuming that the deterministic knapsack problem is solved by an \u03b1-approximation algorithm. We present simulation results to demonstrate that our algorithm is scalable with the number of robots and tasks.",
        "primary_area": "",
        "author": "Fan Yang;Nilanjan Chakraborty;Fan Yang;Nilanjan Chakraborty",
        "authorids": "/37086018699;/37314871600;/37086018699;/37314871600",
        "aff": "Mechanical Engineering Department, Stony Brook University; Mechanical Engineering Department, Stony Brook University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341726/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=749031557146304664&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Stony Brook University",
        "aff_unique_dep": "Mechanical Engineering Department",
        "aff_unique_url": "https://www.stonybrook.edu",
        "aff_unique_abbr": "SBU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Stony Brook",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340719",
        "title": "Allocating Limited Sensing Resources to Accurately Map Dynamic Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "This work addresses the problem of learning a model of a dynamic environment using many independent Hidden Markov Models (HMMs) with a limited number of observations available per iteration. Many techniques exist to model dynamic environments, but do not consider how to deploy robots to build this model. Additionally, there are many techniques for exploring environments that do not consider how to prioritize regions when resources, in terms of robots to deploy and deployment durations, are limited. Here, we consider an environment model consisting of a series of HMMs that evolve over time independently and can be directly observed. At each iteration, we must determine which HMMs to observe in order to maximize the gain in model accuracy. We present a utility measure that balances a Pearson's \u03c72 goodness-of-fit of the dynamics model with Mutual Information (MI) to ensure that observations are allocated to maximize the convergence rate of all HMMs, resulting in a faster convergence to higher steady-state model confidence and accuracy than either \u03c72 or MI alone.",
        "primary_area": "",
        "author": "Derek Mitchell;Nathan Michael;Derek Mitchell;Nathan Michael",
        "authorids": "/37085594021;/37302499000;/37085594021;/37302499000",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340719/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:d7JuS5jptToJ:scholar.google.com/&scioq=Allocating+Limited+Sensing+Resources+to+Accurately+Map+Dynamic+Environments&hl=en&as_sdt=0,5",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341198",
        "title": "An Actor-based Programming Framework for Swarm Robotic Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "Programming cooperative tasks for autonomous swarm robotic systems has always been challenging. In this paper, we introduce a concept \u2018Actor\u2019, as a virtualization for robot platforms. Every robot platform in the swarm robotic system carries out the task and interacts with others as an Actor. We designed an Actor-based framework for the management of autonomous swarm robotic systems including modules and interfaces for the Actor, the collective Actor, and task management. The Actor-based framework enables task developers to explicitly model cooperative tasks without intricacies about the detailed robotic algorithms or the specific robot brands, and eases the burden on robotic algorithm developers by providing common functionalities. The proposed framework is implemented in C++ and validated quantitatively and qualitatively with a swarm of thirty drones by simulations and a swarm of ten drones by in-field tests.",
        "primary_area": "",
        "author": "Wei Yi;Bin Di;Ruihao Li;Huadong Dai;Xiaodong Yi;Yanzhen Wang;Xuejun Yang;Wei Yi;Bin Di;Ruihao Li;Huadong Dai;Xiaodong Yi;Yanzhen Wang;Xuejun Yang",
        "authorids": "/37086604575;/37085393192;/37089776094;/37598013900;/37085630673;/37085616944;/37401424700;/37086604575;/37085393192;/37089776094;/37598013900;/37085630673;/37085616944;/37401424700",
        "aff": "State Key Laboratory of High Performance Computing, College of Computer, National University of Defense Technology, Changesha, China; Tianjin ArtiFIcial Intelligence Innovation Center (TAIIC), Tianjin, China; Tianjin ArtiFIcial Intelligence Innovation Center (TAIIC), Tianjin, China; State Key Laboratory of High Performance Computing, College of Computer, National University of Defense Technology, Changesha, China; State Key Laboratory of High Performance Computing, College of Computer, National University of Defense Technology, Changesha, China; State Key Laboratory of High Performance Computing, College of Computer, National University of Defense Technology, Changesha, China; State Key Laboratory of High Performance Computing, College of Computer, National University of Defense Technology, Changesha, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341198/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16698919976208300243&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;1;0;0;0;0",
        "aff_unique_norm": "National University of Defense Technology;Tianjin ArtiFIcial Intelligence Innovation Center",
        "aff_unique_dep": "College of Computer;",
        "aff_unique_url": "http://www.nudt.edu.cn;",
        "aff_unique_abbr": "NUDT;TAIIC",
        "aff_campus_unique_index": "0;1;1;0;0;0;0",
        "aff_campus_unique": "Changesha;Tianjin",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9341117",
        "title": "An Approach to Reduce Communication for Multi-agent Mapping Applications",
        "track": "main",
        "status": "Poster",
        "abstract": "In the context of a multi-agent system that uses a Gaussian process to estimate a spatial field of interest, we propose an approach that enables an agent to reduce the amount of data it shares with other agents. The main idea of the strategy is to rigorously assign a novelty metric to each measurement as it is collected, and only measurements that are sufficiently novel are communicated. We consider the ideal scenario where an agent can instantly share novel measurements, and we also consider the more practical scenario in which communication suffers from low bandwidth and is range-limited. For this scenario, an agent can only broadcast an informative subset of the novel measurements when the agent encounters other agents. We explore three different informative criteria for subset selection, namely entropy, mutual information, and a new criterion that reflects the value of a measurement. We apply our approach to three real-world datasets relevant to robotic mapping. The empirical findings show that an agent can reduce the amount of communicated measurements by two orders of magnitude and that the new criterion for subset selection yields superior predictive performance relative to entropy and mutual information.",
        "primary_area": "",
        "author": "Michael E. Kepler;Daniel J. Stilwell;Michael E. Kepler;Daniel J. Stilwell",
        "authorids": "/37086590146;/37283170000;/37086590146;/37283170000",
        "aff": "Bradley Department of Electrical and Computer Engineering, Virginia Polytechnic Institute and State University, Blacksburg, VA, USA; Bradley Department of Electrical and Computer Engineering, Virginia Polytechnic Institute and State University, Blacksburg, VA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341117/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8390819571989310716&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Virginia Polytechnic Institute and State University",
        "aff_unique_dep": "Bradley Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.vt.edu",
        "aff_unique_abbr": "VT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Blacksburg",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341119",
        "title": "An Augmented Reality Human-Robot Physical Collaboration Interface Design for Shared, Large-Scale, Labour-Intensive Manufacturing Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper investigate potential use of augmented reality (AR) for physical human-robot collaboration in large-scale, labour-intensive manufacturing tasks. While it has been shown that use of AR can help increase task efficiency in teleoperative and robot programming tasks involving smaller-scale robots, its use for physical human-robot collaboration in shared workspaces and large-scale manufacturing tasks have not been well-studied. With the eventual goal of applying our AR system to collaborative aircraft body manufacturing, we compare in a user study the use of an AR interface we developed with a standard joystick for human robot collaboration in an experiment task simulating industrial carbon-fibre-reinforced-polymer manufacturing procedure. Results show that use of AR yields reduced task time and physical demand, with increased robot utilization.",
        "primary_area": "",
        "author": "Wesley P. Chan;Geoffrey Hanks;Maram Sakr;Tiger Zuo;H.F. Machiel Van der Loos;Elizabeth Croft;Wesley P. Chan;Geoffrey Hanks;Maram Sakr;Tiger Zuo;H.F. Machiel Van der Loos;Elizabeth Croft",
        "authorids": "/37085498611;/37088690211;/37089465987;/37088687912;/37085374287;/37283199500;/37085498611;/37088690211;/37089465987;/37088687912;/37085374287;/37283199500",
        "aff": "Monash University; University of British Columbia; University of British Columbia; University of British Columbia; University of British Columbia; Monash University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341119/",
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12847167246825503839&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;1;1;0",
        "aff_unique_norm": "Monash University;University of British Columbia",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.monash.edu;https://www.ubc.ca",
        "aff_unique_abbr": "Monash;UBC",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;1;1;1;0",
        "aff_country_unique": "Australia;Canada"
    },
    {
        "id": "9341037",
        "title": "An Augmented Reality Interaction Interface for Autonomous Drone",
        "track": "main",
        "status": "Poster",
        "abstract": "Human drone interaction in autonomous navigation incorporates spatial interaction tasks, including reconstructed 3D map from the drone and human desired target position. Augmented Reality (AR) devices can be powerful interactive tools for handling these spatial interactions. In this work, we build an AR interface that displays the reconstructed 3D map from the drone on physical surfaces in front of the operator. Spatial target positions can be further set on the 3D map by intuitive head gaze and hand gesture. The AR interface is deployed to interact with an autonomous drone to explore an unknown environment. A user study is further conducted to evaluate the overall interaction performance.",
        "primary_area": "",
        "author": "Chuhao Liu;Shaojie Shen;Chuhao Liu;Shaojie Shen",
        "authorids": "/37086922152;/37954847200;/37086922152;/37954847200",
        "aff": "Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong, China; Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341037/",
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=529017870870077331&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Hong Kong University of Science and Technology",
        "aff_unique_dep": "Department of Electronic and Computer Engineering",
        "aff_unique_url": "https://www.ust.hk",
        "aff_unique_abbr": "HKUST",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Hong Kong",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9340742",
        "title": "An Augmented Reality Spatial Referencing System for Mobile Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "The deployment of a mobile service robot in domestic settings is a challenging task due to the dynamic and unstructured nature of such environments. Successful operation of the robot requires continuous human supervision to update its spatial knowledge about the dynamic environment. Thus, it is essential to develop a human-robot interaction (HRI) strategy that is suitable for novice end users to effortlessly provide task-specific spatial information to the robot. Although several approaches have been developed for this purpose, most of them are not feasible or convenient for use in domestic environments. In response, we have developed an augmented reality (AR) spatial referencing system (SRS), which allows a non-expert user to tag any specific locations on a physical surface to allocate tasks to be performed by the robot at those locations. Specifically, in the AR-SRS, the user provides a spatial reference by creating an AR virtual object with a semantic label. The real-world location of the user-created virtual object is estimated and stored as spatial data along with the user-specified semantic label. We present three different approaches to establish the correspondence between the user-created virtual object locations and the real-world coordinates on an a priori static map of the service area available to the robot. The performance of each approach is evaluated and reported. We also present use-case scenarios to demonstrate potential applications of the AR-SRS for mobile service robots.",
        "primary_area": "",
        "author": "Sonia Mary Chacko;Armando Granado;Ashwin RajKumar;Vikram Kapila;Sonia Mary Chacko;Armando Granado;Ashwin RajKumar;Vikram Kapila",
        "authorids": "/37087236102;/37088686914;/37088236035;/37267175100;/37087236102;/37088686914;/37088236035;/37267175100",
        "aff": "Mechatronics, Controls, and Robotics Laboratory (MCRL), Mechanical and Aerospace Engineering, NYU Tandon School of Engineering, Brooklyn, NY, USA; Mechatronics, Controls, and Robotics Laboratory (MCRL), Mechanical and Aerospace Engineering, NYU Tandon School of Engineering, Brooklyn, NY, USA; Mechatronics, Controls, and Robotics Laboratory (MCRL), Mechanical and Aerospace Engineering, NYU Tandon School of Engineering, Brooklyn, NY, USA; Mechatronics, Controls, and Robotics Laboratory (MCRL), Mechanical and Aerospace Engineering, NYU Tandon School of Engineering, Brooklyn, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340742/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8363050749336839071&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "NYU Tandon School of Engineering",
        "aff_unique_dep": "Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://engineering.nyu.edu",
        "aff_unique_abbr": "NYU Tandon",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Brooklyn",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341166",
        "title": "An Earthworm-like Soft Robot with Integration of Single Pneumatic Actuator and Cellular Structures for Peristaltic Motion",
        "track": "main",
        "status": "Poster",
        "abstract": "Earthworm-like soft robots have been widely studied for various applications, such as medical endoscopy and pipeline inspection. Many actuation modes have been chosen to drive the soft robots, including pneumatic actuators, dielectric elastomeric actuators, and shape memory actuators. Pneumatic actuators stand out since the soft robots with pneumatic actuation can produce relatively large forces and displacements with relatively ease of fabrication. Currently, several pneumatic actuators are used to realize elongating movement and anchoring movement of the earthworm for peristaltic motion. More pneumatic actuators not only require more pumps and valves to actuate and control the earthworm, but also lead to less efficient movement control of the earthworm. To address this issue, a new design with integrated single pneumatic actuator and cellular structures is developed to realize elongating movement and anchoring movement of the earthworm-like soft robot in peristaltic motion. With the new design, the simulation model of the new earthworm is developed to simulate both elongating and anchoring movements of the earthworm. A 3D printed prototype of the earthworm-like soft robot is fabricated to validate the proposed design and simulation model. Experimental results show good agreement with the simulation in elongations of peristaltic motion as the differences between the simulated and experimental is 5.8 % in one cycle of the peristaltic motion.",
        "primary_area": "",
        "author": "Mingcan Liu;Zhaoyi Xu;Jing Jie Ong;Jian Zhu;Wen Feng Lu;Mingcan Liu;Zhaoyi Xu;Jing Jie Ong;Jian Zhu;Wen Feng Lu",
        "authorids": "/37088688615;/37088686901;/37088690264;/37085724833;/37404587400;/37088688615;/37088686901;/37088690264;/37085724833;/37404587400",
        "aff": "Department of Mechanical Engineering, National University of Singapore, Singapore; Department of Mechanical and Industrial Engineering, University of Toronto, Toronto, ON, Canada; Department of Mechanical Engineering, National University of Singapore, Singapore; Department of Mechanical Engineering, National University of Singapore, Singapore; Department of Mechanical Engineering, National University of Singapore, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341166/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12862724682899038181&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "National University of Singapore;University of Toronto",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Mechanical and Industrial Engineering",
        "aff_unique_url": "https://www.nus.edu.sg;https://www.utoronto.ca",
        "aff_unique_abbr": "NUS;U of T",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Toronto",
        "aff_country_unique_index": "0;1;0;0;0",
        "aff_country_unique": "Singapore;Canada"
    },
    {
        "id": "9341253",
        "title": "An Electrocommunication System Using FSK Modulation and Deep Learning Based Demodulation for Underwater Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Underwater communication is extremely challenging for small underwater robots which typically have stringent power and size constraints. In our previous work, we developed an artificial electrocommunication system which could be an alternative for the communication of small underwater robots. This paper further presents a new electrocommunication system that utilizes Binary Frequency Shift Keying (2FSK) modulation and deep-learning-based demodulation for underwater robots. We first derive an underwater electrocommunication model that covers both the near-field area and a large transition area outside of the near-field area. 2FSK modulation is adopted to improve the anti-interference ability of the electric signal. A deep learning algorithm is used to demodulate the electric signal by the receiver. Simulations and experiments show that with the same testing condition, the new communication system outperforms the previous system in both the communication distance and the data transmitting rate. In specific, the newly developed communication system achieves stable communication within the distance of 10 m at a data transfer rate of 5 Kbps with a power consumption of less than 0.1 W. The substantial increase in communication distance further improves the possibility of electrocommunication in underwater robotics.",
        "primary_area": "",
        "author": "Qinghao Wang;Ruijun Liu;Wei Wang;Guangming Xie;Qinghao Wang;Ruijun Liu;Wei Wang;Guangming Xie",
        "authorids": "/37088688334;/37088686021;/37073346500;/37270592800;/37088688334;/37088686021;/37073346500;/37270592800",
        "aff": "College of Engineering, State Key Laboratory of Turbulence and Complex Systems, Intelligent Biomimetic Design Lab, Peking University, Beijing, China; College of Electrical and Information Engineering, Guangxi University of Science and Technology, Liuzhou, China; Computer Science and Artificial Intelligence Lab (CSAIL), Massachusetts Institute of Technology, Cambridge, MA, USA; Peng Cheng Laboratory, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341253/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16742460287153087300&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;3",
        "aff_unique_norm": "Peking University;Guangxi University of Science and Technology;Massachusetts Institute of Technology;Peng Cheng Laboratory",
        "aff_unique_dep": "College of Engineering;College of Electrical and Information Engineering;Computer Science and Artificial Intelligence Lab (CSAIL);",
        "aff_unique_url": "http://www.pku.edu.cn;;https://www.mit.edu;",
        "aff_unique_abbr": "PKU;;MIT;",
        "aff_campus_unique_index": "0;1;2;3",
        "aff_campus_unique": "Beijing;Liuzhou;Cambridge;Shenzhen",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9341561",
        "title": "An Energy-based Approach for the Integration of Collaborative Redundant Robots in Restricted Work Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "To this day, most robots are installed behind safety fences, separated from the human. New use-case scenarios demand for collaborative robots, e.g. to assist the human with physically challenging tasks. These robots are mainly installed in work-environments with limited space, e.g. existing production lines. This brings certain challenges for the control of such robots. The presented work addresses a few of these challenges, namely: stable and safe behaviour in contact scenarios; avoidance of restricted workspace areas; prevention of joint limits in automatic mode and manual guidance. The control approach in this paper extents an Energy-aware Impedance controller by repulsive potential fields in order to comply with Cartesian and joint constraints. The presented controller was verified for a KUKA LBR iiwa 7 R800 in simulation as well as on the real robot.",
        "primary_area": "",
        "author": "Sebastian Hjorth;Johannes Lachner;Stefano Stramigioli;Ole Madsen;Dimitrios Chrysostomou;Sebastian Hjorth;Johannes Lachner;Stefano Stramigioli;Ole Madsen;Dimitrios Chrysostomou",
        "authorids": "/37088690340;/37088691248;/37282439300;/37304037600;/37541236100;/37088690340;/37088691248;/37282439300;/37304037600;/37541236100",
        "aff": "Department of Materials and Production, Aalborg University, Aalborg, Denmark; Kuka Deutschland GmbH, Augsburg, Deutschland; Faculty of Electrical Engineering, Mathematics and Computer Science University of Twente, Enschede, Netherlands; Department of Materials and Production, Aalborg University, Aalborg, Denmark; Department of Materials and Production, Aalborg University, Aalborg, Denmark",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341561/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13513693497514285542&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;0;0",
        "aff_unique_norm": "Aalborg University;Kuka Deutschland GmbH;University of Twente",
        "aff_unique_dep": "Department of Materials and Production;;Faculty of Electrical Engineering, Mathematics and Computer Science",
        "aff_unique_url": "https://www.aau.dk;https://www.kuka.com;https://www.utwente.nl",
        "aff_unique_abbr": "AAU;KUKA;UT",
        "aff_campus_unique_index": "0;1;2;0;0",
        "aff_campus_unique": "Aalborg;Augsburg;Enschede",
        "aff_country_unique_index": "0;1;2;0;0",
        "aff_country_unique": "Denmark;Germany;Netherlands"
    },
    {
        "id": "9341454",
        "title": "An External Stabilization Unit for High-Precision Applications of Robot Manipulators",
        "track": "main",
        "status": "Poster",
        "abstract": "Because of their large workspace, robot manipulators have the potential to be used for high precision non-contact manufacturing processes, such as laser cutting or welding, on large complex work pieces. However, most industrial manipulators are not able to provide the necessary accuracy requirements. Mainly because of their flexible structures, they are subject to point to point positioning errors and also vibration errors on a smaller scale. The vibration issues are especially hard to deal with. Many published solutions propose to modify the robot's own control system to deal with these problems. However, most modern control techniques require high fidelity models of the underlying system dynamics, which are quite difficult to obtain for robot manipulators. In this work, we propose an external stabilization unit with an additional set of actuators/sensors to stabilize the process tool, similar to Optical Image Stabilization systems. We show that, because of collocated control, a model of the robot's own dynamic behavior is not needed to achieve high tracking accuracy. We also provide testing results of a prototype stabilizing a dummy tool in two degrees of freedom on a UR10 robot, which reduced its tracking error by two orders of magnitude below 20 micrometers.",
        "primary_area": "",
        "author": "Tobias F. C. Berninger;Tomas Slimak;Tobias Weber;Daniel J. Rixen;Tobias F. C. Berninger;Tomas Slimak;Tobias Weber;Daniel J. Rixen",
        "authorids": "/37086542285;/37088689199;/37088689990;/37393325300;/37086542285;/37088689199;/37088689990;/37393325300",
        "aff": "Chair of Applied Mechanics, TU Munich, Garching, Germany; Chair of Applied Mechanics, TU Munich, Garching, Germany; Boeing Research & Technology - Europe, Munich, Germany; Chair of Applied Mechanics, TU Munich, Garching, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341454/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16708690697155357897&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Technical University of Munich;Boeing Research & Technology",
        "aff_unique_dep": "Chair of Applied Mechanics;",
        "aff_unique_url": "https://www.tum.de;https://www.boeing.com/research-technology/",
        "aff_unique_abbr": "TUM;Boeing R&T",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Garching;Munich",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9341688",
        "title": "An Implementation of the Adaptive Neuro-Fuzzy Inference System (ANFIS) for Odor Source Localization",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we investigate the viability of implementing machine learning (ML) algorithms to solve the odor source localization (OSL) problem. The primary objective is to obtain an ML model that guides and navigates a mobile robot to find an odor source without explicating searching algorithms. To achieve this goal, the model of an adaptive neuro-fuzzy inference system (ANFIS) is employed to generate the olfactory-based navigation strategy. To train the ANFIS model, multiple training data sets are acquired by applying two traditional olfactory-based navigation methods, namely moth-inspired and Bayesian-inference methods, in hundreds of simulated OSL tests with different environments. After training with the hybrid-learning algorithm, the ANFIS model is validated in multiple OSL tests with varying searching conditions. Experiment results show that the ANFIS model can imitate other olfactory-based navigation methods and correctly locate the odor source. Besides, by training it with the fused training data set, the ANFIS model is better than two traditional navigation methods in terms of the averaged searching time.",
        "primary_area": "",
        "author": "Lingxiao Wang;Shuo Pang;Lingxiao Wang;Shuo Pang",
        "authorids": "/37086586971;/37425425100;/37086586971;/37425425100",
        "aff": "Electrical Engineering and Computer Science Department, Embry-Riddle Aeronautical University, Daytona Beach, FL; Electrical Engineering and Computer Science Department, Embry-Riddle Aeronautical University, Daytona Beach, FL",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341688/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4206467656970375306&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Embry-Riddle Aeronautical University",
        "aff_unique_dep": "Electrical Engineering and Computer Science Department",
        "aff_unique_url": "https://www.erau.edu",
        "aff_unique_abbr": "ERAU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Daytona Beach",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341563",
        "title": "An In-Pipe Manipulator for Contamination-Less Rehabilitation of Water Distribution Pipes",
        "track": "main",
        "status": "Poster",
        "abstract": "The recent development of in-pipe robots (IPR) with locomotion and inspection functions provides a new possibility to water distribution pipe maintenance - to rehabilitate pipe defects internally. Yet only a limited number of Rehabilitation in-pipe robots (R-IPR) have been proposed. One primary concern that impedes the development of Rehabilitation in-pipe robots is the excessive amount of contamination generated during the rehabilitation process. Correspondingly, we propose a novel concept: Contamination-Less in-pipe Rehabilitation (CLR) and develop the CLR in-pipe robot as an innovative solution. The proposed robot contains three modules for pipe-surface sealing, pipe-wall cleaning, and in-pipe manipulation. This paper centers on the comprehensive design of the manipulator module. First, the manipulator features a high-DoF configuration to deploy the other two modules simultaneously. Second, the configuration adopts a nested-outer-inner architecture to ensure the seal always encloses the pipe-wall cleaning device. The holistic and detailed design process of the manipulator, including design concept, kinematics, load requirements, design for manufacturing, and simulated deployment, are presented. Eventually, the fully implemented robot accomplished the first Contamination-Less in-pipe Rehabilitation.",
        "primary_area": "",
        "author": "Yip Fun Yeung;Kamal Youcef-Toumi;Yip Fun Yeung;Kamal Youcef-Toumi",
        "authorids": "/37088687204;/38271700200;/37088687204;/38271700200",
        "aff": "Department of Mechanical Engineering, Mechatronics Research Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA; Department of Mechanical Engineering, Mechatronics Research Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341563/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12083023991352158355&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341162",
        "title": "An Obstacle-crossing Strategy Based on the Fast Self-reconfiguration for Modular Sphere Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper introduces an obstacle-crossing strategy, and the self-reconfiguration algorithm for a new class of modular robots called the rolling sphere, which can fit obstacles represented by cubes of different sizes due to the chain connection of multiple spheres. For the self-reconfiguration of the rolling spheres, a large gradient is obtained by classifying its action types and hierarchically minimizing the distance between the initial configuration and the final configuration. The most direct use of this large gradient is the fast crossing of various obstacles, by jointing multiple self-reconfigurations according to the OctoMap of the obstacles. It is verified in simulation that the self-reconfiguration takes full advantage of the parallel movement of multiple modules to reduce the total time steps, and the obstacle-crossing strategy can adapt to a variety of obstacles.",
        "primary_area": "",
        "author": "Haobo Luo;Ming Li;Guangqi Liang;Huihuan Qian;Tin Lun Lam;Haobo Luo;Ming Li;Guangqi Liang;Huihuan Qian;Tin Lun Lam",
        "authorids": "/37088686275;/37089459196;/37088687610;/37549401900;/37571111600;/37088686275;/37089459196;/37088687610;/37549401900;/37571111600",
        "aff": "Shenzhen Institute of Artificial Intelligence and Robotics for Society; Shenzhen Institute of Artificial Intelligence and Robotics for Society; Shenzhen Institute of Artificial Intelligence and Robotics for Society; Shenzhen Institute of Artificial Intelligence and Robotics for Society; Shenzhen Institute of Artificial Intelligence and Robotics for Society",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341162/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17910045566300245612&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Shenzhen Institute of Artificial Intelligence and Robotics for Society",
        "aff_unique_dep": "",
        "aff_unique_url": "http://www.siarfs.org/",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9341021",
        "title": "An Online Training Method for Augmenting MPC with Deep Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent breakthroughs both in reinforcement learning and trajectory optimization have made significant advances towards real world robotic system deployment. Reinforcement learning (RL) can be applied to many problems without needing any modeling or intuition about the system, at the cost of high sample complexity and the inability to prove any metrics about the learned policies. Trajectory optimization (TO) on the other hand allows for stability and robustness analyses on generated motions and trajectories, but is only as good as the often over-simplified derived model, and may have prohibitively expensive computation times for real-time control, for example in contact rich environments. This paper seeks to combine the benefits from these two areas while mitigating their drawbacks by (1) decreasing RL sample complexity by using existing knowledge of the problem with real-time optimal control, and (2) allowing online policy deployment at any point in the training process by using the TO (MPC) as a baseline or worst-case scenario action, while continuously improving the combined learned-optimized policy with deep RL. This method is evaluated on tasks of successively navigating a car model to a series of goal destinations over slippery terrains as fast as possible, in which drifting will allow the system to more quickly change directions while maintaining high speeds.",
        "primary_area": "",
        "author": "Guillaume Bellegarda;Katie Byl;Guillaume Bellegarda;Katie Byl",
        "authorids": "/37086456120;/37569022700;/37086456120;/37569022700",
        "aff": "Department of Electrical and Computer Engineering, Robotics Laboratory, University of California at Santa Barbara (UCSB); Department of Electrical and Computer Engineering, Robotics Laboratory, University of California at Santa Barbara (UCSB)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341021/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=363685456475870432&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of California at Santa Barbara",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.ucsb.edu",
        "aff_unique_abbr": "UCSB",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Santa Barbara",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340741",
        "title": "An Optimized Tilt Mechanism for a New Steady-Hand Eye Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Robot-assisted vitreoretinal surgery can filter surgeons' hand tremors and provide safe, accurate tool manipulation. In this paper, we report the design, optimization, and evaluation of a novel tilt mechanism for a new Steady-Hand Eye Robot (SHER). The new tilt mechanism features a four-bar linkage design and has a compact structure. Its kinematic configuration is optimized to minimize the required linear range of motion (LRM) for implementing a virtual remote center-of-motion (V-RCM) while tilting a surgical tool. Due to the different optimization constraints for the robots at the left and right sides of the human head, two configurations of this tilt mechanism are proposed. Experimental results show that the optimized tilt mechanism requires a significantly smaller LRM (e.g. 5.08 mm along Z direction and 8.77 mm along Y direction for left side robot) as compared to the slider-crank tilt mechanism used in the previous SHER (32.39 mm along Z direction and 21.10 mm along Y direction). The feasibility of the proposed tilt mechanism is verified in a mock bilateral robot-assisted vitreoretinal surgery. The ergonomically acceptable robot postures needed to access the surgical field is also determined.",
        "primary_area": "",
        "author": "Jiahao Wu;Gang Li;Muller Urias;Niravkumar A. Patel;Yun-hui Liu;Peter Gehlbach;Russell H. Taylor;Iulian Iordachita;Jiahao Wu;Gang Li;Muller Urias;Niravkumar A. Patel;Yun-hui Liu;Peter Gehlbach;Russell H. Taylor;Iulian Iordachita",
        "authorids": "/37088405816;/37085576110;/37087236636;/37086366528;/37279412600;/37547001700;/37277162900;/37330620500;/37088405816;/37085576110;/37087236636;/37086366528;/37279412600;/37547001700;/37277162900;/37330620500",
        "aff": "the Department of Mechanical and Automation Engineering, T Stone Robotics Institute, The Chinese University of Hong Kong, HKSAR, China; LCSR at the Johns Hopkins University, Baltimore, MD, USA; Wilmer Eye Institute, Johns Hopkins Hospital, Baltimore, MD, USA; LCSR at the Johns Hopkins University, Baltimore, MD, USA; the Department of Mechanical and Automation Engineering, T Stone Robotics Institute, The Chinese University of Hong Kong, HKSAR, China; Wilmer Eye Institute, Johns Hopkins Hospital, Baltimore, MD, USA; LCSR at the Johns Hopkins University, Baltimore, MD, USA; LCSR at the Johns Hopkins University, Baltimore, MD, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340741/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3557085908695697459&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;2;1;0;2;1;1",
        "aff_unique_norm": "The Chinese University of Hong Kong;Johns Hopkins University;Johns Hopkins Hospital",
        "aff_unique_dep": "Department of Mechanical and Automation Engineering;LCSR (Laboratory for Computational Sensing and Robotics);Wilmer Eye Institute",
        "aff_unique_url": "https://www.cuhk.edu.hk;https://www.jhu.edu;https://www.hopkinsmedicine.org",
        "aff_unique_abbr": "CUHK;JHU;JHH",
        "aff_campus_unique_index": "1;1;1;1;1;1",
        "aff_campus_unique": ";Baltimore",
        "aff_country_unique_index": "0;1;1;1;0;1;1;1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9341127",
        "title": "An RLS-Based Instantaneous Velocity Estimator for Extended Radar Tracking",
        "track": "main",
        "status": "Poster",
        "abstract": "Radar sensors have become an important part of the perception sensor suite due to their long range and their ability to work in adverse weather conditions. However, several shortcomings such as large amounts of noise and extreme sparsity of the point cloud result in them not being used to their full potential. In this paper, we present a novel Recursive Least Squares (RLS) based approach to estimate the instantaneous velocity of dynamic objects in real-time that is capable of handling large amounts of noise in the input data stream. We also present an end-to-end pipeline to track extended objects in real-time that uses the computed velocity estimates for data association and track initialisation. The approaches are evaluated using several real-world inspired driving scenarios that test the limits of these algorithms. It is also experimentally proven that our approaches run in real-time with frame execution time not exceeding 30 ms even in dense traffic scenarios, thus allowing for their direct implementation on autonomous vehicles.",
        "primary_area": "",
        "author": "Nikhil Bharadwaj Gosala;Xiaoli Meng;Nikhil Bharadwaj Gosala;Xiaoli Meng",
        "authorids": "/37086936682;/37088689177;/37086936682;/37088689177",
        "aff": "ETH Z\u00fcrich, Switzerland; Hyundai-Aptiv Autonomous Driving JV, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341127/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6506999432457345364&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "ETH Z\u00fcrich;Hyundai-Aptiv Autonomous Driving JV",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.ethz.ch;",
        "aff_unique_abbr": "ETHZ;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "Switzerland;Singapore"
    },
    {
        "id": "9340779",
        "title": "An SEM-Based Nanomanipulation System for Multi-Physical Characterization of Single InGaN/GaN Nanowires",
        "track": "main",
        "status": "Poster",
        "abstract": "Functional nanomaterials possess exceptional multi-physical (e.g., mechanical, electrical and optical) properties compared with their bulk counterparts. To facilitate both synthesis and device applications of these nanomaterials, it is highly desired to characterize their multi-physical properties with high accuracy and efficiency. The nanomanipulation techniques under scanning electron microscopy (SEM) has enabled the testing of mechanical and electrical properties of various nanomaterials. However, the seamless integration of mechanical, electrical, and optical testing techniques into an SEM for triple-field-coupled characterization of single nanostructures is still unexplored. In this work, we report the first SEM-based nanomanipulation system for high-resolution mechano-optoelectronic testing of single semiconductor InGaN/GaN nanowires (NWs). A custom-made optical measurement setup was integrated onto a four-probe nanomanipulator inside an SEM, with two optical microfibers actuated by the nanomanipulator for NW excitation and emission measurement. A conductive tungsten nanoprobe and a conductive atomic force microscopy (AFM) cantilever probe were integrated onto the nanomanipulator for electrical nanoprobing of single NWs for electroluminescence (EL) measurement. The AFM probe also served as a force sensor for quantifying the contact force applied to the NW during nanoprobing. Using this unique system, we examined, for the first time, the effect of mechanical compression applied to an InGaN/GaN NW on its optoelectronic properties.",
        "primary_area": "",
        "author": "Juntian Qu;Renjie Wang;Peng Pan;Linghao Du;Zetian Mi;Yu Sun;Xinyu Liu;Juntian Qu;Renjie Wang;Peng Pan;Linghao Du;Zetian Mi;Yu Sun;Xinyu Liu",
        "authorids": "/37085652104;/37085595630;/37086094236;/37088504482;/37272888100;/37309639100;/37310954100;/37085652104;/37085595630;/37086094236;/37088504482;/37272888100;/37309639100;/37310954100",
        "aff": "Department of Mechanical Engineering, Tsinghua University, Beijing, China; Department of Electrical and Computer Engineering, McGill University, Montreal, Quebec, Canada; Department of Mechanical Engineering, McGill University, Montreal, Quebec, Canada; Department of Mechanical and Industrial Engineering, University of Toronto, Toronto, Ontario, Canada; Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, MI, United States; Department of Mechanical and Industrial Engineering, University of Toronto, Toronto, Ontario, Canada; Department of Mechanical Engineering, McGill University, Montreal, Quebec, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340779/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3324037519588579734&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;1;2;3;2;1",
        "aff_unique_norm": "Tsinghua University;McGill University;University of Toronto;University of Michigan",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Electrical and Computer Engineering;Department of Mechanical and Industrial Engineering;Department of Electrical Engineering and Computer Science",
        "aff_unique_url": "https://www.tsinghua.edu.cn;https://www.mcgill.ca;https://www.utoronto.ca;https://www.umich.edu",
        "aff_unique_abbr": "THU;McGill;U of T;UM",
        "aff_campus_unique_index": "0;1;1;2;3;2;1",
        "aff_campus_unique": "Beijing;Montreal;Toronto;Ann Arbor",
        "aff_country_unique_index": "0;1;1;1;2;1;1",
        "aff_country_unique": "China;Canada;United States"
    },
    {
        "id": "9341238",
        "title": "An Untethered 216-mg Insect-Sized Jumping Robot with Wireless Power Transmission",
        "track": "main",
        "status": "Poster",
        "abstract": "We present the first demonstration of a battery-free untethered wirelessly powered sub-gram jumping robot on an insect-scale. In order to operate the insect-sized robot autonomously, the limitation in battery use emphasizes the need for a wireless power transmission system as an onboard power solution. We designed a wireless power transmission system based on inductive coupling to power the Shape Memory Alloy (SMA), which serves as an elastic energy storage element and actuator for the jumping robot. The assembled mechanical structures, onboard power and electronics yield a 2 mm (high) \u00d7 24 mm (long) \u00d7 12 mm (wide) robot with ~a weight of 216 mg. The experiments show that our jumping robot wirelessly lift-off up to 5.75 times its body length and repeats the jump around 7 times per minute. To date, out of the several untethered sub-gram insect-scale jumping robots with onboard power, this is the first wirelessly powered robot with the highest jumping performance. The novelty in this work, which addresses the engineering challenges in insect-scale jumping robots, is an untethered wirelessly powered design that achieves dynamic jumping maneuvers, and has self-righting ability.",
        "primary_area": "",
        "author": "Riccy Kurniawan;Tamaki Fukudome;Hao Qiu;Makoto Takamiya;Yoshihiro Kawahara;Jinkyu Yang;Ryuma Niiyama;Riccy Kurniawan;Tamaki Fukudome;Hao Qiu;Makoto Takamiya;Yoshihiro Kawahara;Jinkyu Yang;Ryuma Niiyama",
        "authorids": "/37088686544;/37088687811;/37086639981;/37282760800;/37269138700;/37088688976;/37591000100;/37088686544;/37088687811;/37086639981;/37282760800;/37269138700;/37088688976;/37591000100",
        "aff": "Department of Mechanical Engineering, University of Washington, Seattle, USA; Institute of Industrial Science, The University of Tokyo, Japan; Institute of Industrial Science, The University of Tokyo, Japan; Institute of Industrial Science, The University of Tokyo, Japan; Graduate School of Engineering, The University of Tokyo, Tokyo, Japan; William E. Boeing Department of Aeronautics and Astronautics, University of Washington, Seattle, USA; Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341238/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2640098817142602208&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;1;1;1;0;1",
        "aff_unique_norm": "University of Washington;The University of Tokyo",
        "aff_unique_dep": "Department of Mechanical Engineering;Institute of Industrial Science",
        "aff_unique_url": "https://www.washington.edu;https://www.iis.u-tokyo.ac.jp",
        "aff_unique_abbr": "UW;UTokyo",
        "aff_campus_unique_index": "0;1;1;1;1;0;1",
        "aff_campus_unique": "Seattle;Tokyo",
        "aff_country_unique_index": "0;1;1;1;1;0;1",
        "aff_country_unique": "United States;Japan"
    },
    {
        "id": "9341008",
        "title": "An Untethered Brittle Star-Inspired Soft Robot for Closed-Loop Underwater Locomotion",
        "track": "main",
        "status": "Poster",
        "abstract": "Soft robots are capable of inherently safer interactions with their environment than rigid robots since they can mechanically deform in response to unanticipated stimuli. However, their complex mechanics can make planning and control difficult, particularly with tasks such as locomotion. In this work, we present a mobile and untethered underwater crawling soft robot, PATRICK, paired with a testbed that demonstrates closed-loop locomotion planning. PATRICK is inspired by the brittle star, with five flexible legs actuated by a total of 20 shape-memory alloy (SMA) wires, providing a rich variety of possible motions via its large input space. We propose a motion planning infrastructure based on a simple set of PATRICK's motion primitives, and provide experiments showing that the planner can command the robot to locomote to a goal state. These experiments contribute the first examples of closed-loop, state-space goal seeking of an underwater, untethered, soft crawling robot, and make progress towards full autonomy of soft mobile robotic systems.",
        "primary_area": "",
        "author": "Zach J. Patterson;Andrew P. Sabelhaus;Keene Chin;Tess Hellebrekers;Carmel Majidi;Zach J. Patterson;Andrew P. Sabelhaus;Keene Chin;Tess Hellebrekers;Carmel Majidi",
        "authorids": "/37088688946;/37077141700;/37088383828;/37085635447;/37589572800;/37088688946;/37077141700;/37088383828;/37085635447;/37589572800",
        "aff": "Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; The Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; The Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; The Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341008/",
        "gs_citation": 47,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13035800181207956032&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341351",
        "title": "An untethered soft cellular robot with variable volume, friction, and unit-to-unit cohesion",
        "track": "main",
        "status": "Poster",
        "abstract": "A fundamental challenge in the field of modular and collective robots is balancing the trade-off between unit-level simplicity, which allows scalability, and unit-level functionality, which allows meaningful behaviors of the collective. At the same time, a challenge in the field of soft robotics is creating untethered systems, especially at a large scale with many controlled degrees of freedom (DOF). As a contribution toward addressing these challenges, here we present an untethered, soft cellular robot unit. A single unit is simple and one DOF, yet can increase its volume by 8x and apply substantial forces to the environment, can modulate its surface friction, and can switch its unit-to-unit cohesion while agnostic to unit-to-unit orientation. As a soft robot, it is robust and can achieve untethered operation of its DOF. We present the design of the unit, a volumetric actuator with a perforated strain-limiting fabric skin embedded with magnets surrounding an elastomeric membrane, which in turn encompasses a low-cost micro-pump, battery, and control electronics. We model and test this unit and show simple demonstrations of three-unit configurations that lift, crawl, and perform plate manipulation. Our untethered, soft cellular robot unit lays the foundation for new robust soft robotic collectives that have the potential to apply human-scale forces to the world.",
        "primary_area": "",
        "author": "Matthew R. Devlin;Brad T. Young;Nicholas D. Naclerio;David A. Haggerty;Elliot W. Hawkes;Matthew R. Devlin;Brad T. Young;Nicholas D. Naclerio;David A. Haggerty;Elliot W. Hawkes",
        "authorids": "/37088687226;/37088685952;/37086581043;/37086617932;/37681388800;/37088687226;/37088685952;/37086581043;/37086617932;/37681388800",
        "aff": "Department of Mechanical Engineering, University of California, Santa Barbara, CA; College of Engineering, University of California, Santa Barbara, CA; Department of Mechanical Engineering, University of California, Santa Barbara, CA; Department of Mechanical Engineering, University of California, Santa Barbara, CA; Department of Mechanical Engineering, University of California, Santa Barbara, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341351/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12187397910925138821&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of California, Santa Barbara",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.ucsb.edu",
        "aff_unique_abbr": "UCSB",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Santa Barbara",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341353",
        "title": "Analysis and Transfer of Human Movement Manipulability in Industry-like Activities",
        "track": "main",
        "status": "Poster",
        "abstract": "Humans exhibit outstanding learning, planning and adaptation capabilities while performing different types of industrial tasks. Given some knowledge about the task requirements, humans are able to plan their limbs motion in anticipation of the execution of specific skills. For example, when an operator needs to drill a hole on a surface, the posture of her limbs varies to guarantee a stable configuration that is compatible with the drilling task specifications, e.g. exerting a force orthogonal to the surface. Therefore, we are interested in analyzing the human arms motion patterns in industrial activities. To do so, we build our analysis on the so-called manipulability ellipsoid, which captures a posture-dependent ability to perform motion and exert forces along different task directions. Through thorough analysis of the human movement manipulability, we found that the ellipsoid shape is task dependent and often provides more information about the human motion than classical manipulability indices. Moreover, we show how manipulability patterns can be transferred to robots by learning a probabilistic model and employing a manipulability tracking controller that acts on the task planning and execution according to predefined control hierarchies.",
        "primary_area": "",
        "author": "No\u00e9mie Jaquier;Leonel Rozo;Sylvain Calinon;No\u00e9mie Jaquier;Leonel Rozo;Sylvain Calinon",
        "authorids": "/37086290815;/38228060200;/37295947200;/37086290815;/38228060200;/37295947200",
        "aff": "Idiap Research Institute, Martigny, Switzerland; Bosch Center for Artificial Intelligence (BCAI), Renningen, Germany; Idiap Research Institute, Martigny, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341353/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4040901370054049455&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Idiap Research Institute;Bosch Center for Artificial Intelligence",
        "aff_unique_dep": ";Artificial Intelligence",
        "aff_unique_url": "https://www.idiap.ch;https://www.bosch-ai.com",
        "aff_unique_abbr": "Idiap;BCAI",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Martigny;Renningen",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Switzerland;Germany"
    },
    {
        "id": "9341527",
        "title": "Analysis of Contact Stability and Contact Safety of a Robotic Intravascular Cardiac Catheter under Blood Flow Disturbances",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper studies the contact stability and contact safety of a robotic intravascular cardiac catheter under blood flow disturbances while in contact with tissue surface. A probabilistic blood flow disturbance model, where the blood flow drag forces on the catheter body are approximated using a quasi-static model, is introduced. Using this blood flow disturbance model, probabilistic contact stability and contact safety metrics, employing a sample based representation of the blood flow velocity distribution, are proposed. Finally, the contact stability and contact safety of a MRI-actuated robotic catheter are analyzed using these models in a specific example scenario under left pulmonary inferior vein (LIV) blood flow disturbances.",
        "primary_area": "",
        "author": "Ran Hao;Nate Lombard Poirot;M. Cenk \u00c7avu\u015fo\u011flu;Ran Hao;Nate Lombard Poirot;M. Cenk \u00c7avu\u015fo\u011flu",
        "authorids": "/37086454939;/37085859516;/37087350923;/37086454939;/37085859516;/37087350923",
        "aff": "Department of Electrical, Computer, and Systems Engineering, Case Western Reserve University, Cleveland, OH; Department of Electrical, Computer, and Systems Engineering, Case Western Reserve University, Cleveland, OH; Department of Electrical, Computer, and Systems Engineering, Case Western Reserve University, Cleveland, OH",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341527/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12001676743509592697&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Case Western Reserve University",
        "aff_unique_dep": "Department of Electrical, Computer, and Systems Engineering",
        "aff_unique_url": "https://www.case.edu",
        "aff_unique_abbr": "CWRU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Cleveland",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341512",
        "title": "Analysis, Development and Evaluation of Electro-Hydrostatic Technology for Lower Limb Prostheses Applications",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents electro-hydrostatic actuation as a valid substitute of electro-mechanical devices for powered knee prostheses. The work covers the design of a test rig exploiting linear electro-hydrostatic actuation. Typical control laws for prosthesis actuators are discussed, implemented and validated experimentally. Particularly, this work focuses on position and admittance control syntheses enhanced with feed-forward friction compensation. Finally, the efficiency of the test rig is characterized experimentally and compared to that of classical electro-mechanical designs. It is demonstrated that the electro-hydrostatic prototype is able to fulfill its targets from a control perspective, while also having the potential to outperform electro-mechanical actuation in efficiency.",
        "primary_area": "",
        "author": "Federico Tessari;Renato Galluzzi;Andrea Tonoli;Nicola Amati;Matteo Laffranchi;Lorenzo De Michieli;Federico Tessari;Renato Galluzzi;Andrea Tonoli;Nicola Amati;Matteo Laffranchi;Lorenzo De Michieli",
        "authorids": "/37088534054;/37086048778;/37322471100;/37689122700;/37528362900;/37087850759;/37088534054;/37086048778;/37322471100;/37689122700;/37528362900;/37087850759",
        "aff": "Rehab Technologies, Italian Institute of Technology, Genova GE, Italy; Department of Mechanical and Aerospace Engineering, Politecnico of Torino, Torino, Italy; Department of Mechanical and Aerospace Engineering, Politecnico of Torino, Torino, Italy; Department of Mechanical and Aerospace Engineering, Politecnico of Torino, Torino, Italy; Rehab Technologies, Italian Institute of Technology, Genova GE, Italy; Rehab Technologies, Italian Institute of Technology, Genova GE, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341512/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3385014861728910429&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;1;0;0",
        "aff_unique_norm": "Italian Institute of Technology;Politecnico of Torino",
        "aff_unique_dep": "Rehab Technologies;Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://iit.it;https://www.polito.it",
        "aff_unique_abbr": "IIT;Polito",
        "aff_campus_unique_index": "0;1;1;1;0;0",
        "aff_campus_unique": "Genova;Torino",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9341590",
        "title": "Anatomical Mesh-Based Virtual Fixtures for Surgical Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a dynamic constraint formulation to provide protective virtual fixtures of 3D anatomical structures from polygon mesh representations. The proposed approach can anisotropically limit the tool motion of surgical robots without any assumption of the local anatomical shape close to the tool. Using a bounded search strategy and Principle Directed tree, the proposed system can run efficiently at 180 Hz for a mesh object containing 989,376 triangles and 493,460 vertices. The proposed algorithm has been validated in both simulation and skull cutting experiments. The skull cutting experiment setup uses a novel piezoelectric bone cutting tool designed for the da Vinci research kit. The result shows that the virtual fixture assisted teleoperation has statistically significant improvements in the cutting path accuracy and penetration depth control. The code has been made publicly available at https://github.com/mli0603/PolygonMeshVirtualFixture.",
        "primary_area": "",
        "author": "Zhaoshuo Li;Alex Gordon;Thomas Looi;James Drake;Christopher Forrest;Russell H. Taylor;Zhaoshuo Li;Alex Gordon;Thomas Looi;James Drake;Christopher Forrest;Russell H. Taylor",
        "authorids": "/37087325398;/37086453584;/38498292300;/38512992300;/37086453757;/37277162900;/37087325398;/37086453584;/38498292300;/38512992300;/37086453757;/37277162900",
        "aff": "Laboratory for Computational Sensing and Robotics, Johns Hopkins University, Baltimore, Maryland, USA; Center for Image Guided Innovation and Therapeutic Intervention lab at Hospital for Sick Children, Toronto, Canada; Center for Image Guided Innovation and Therapeutic Intervention lab at Hospital for Sick Children, Toronto, Canada; Center for Image Guided Innovation and Therapeutic Intervention lab at Hospital for Sick Children, Toronto, Canada; Center for Image Guided Innovation and Therapeutic Intervention lab at Hospital for Sick Children, Toronto, Canada; Laboratory for Computational Sensing and Robotics, Johns Hopkins University, Baltimore, Maryland, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341590/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7827757426846015294&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;1;1;0",
        "aff_unique_norm": "Johns Hopkins University;Hospital for Sick Children",
        "aff_unique_dep": "Laboratory for Computational Sensing and Robotics;Center for Image Guided Innovation and Therapeutic Intervention",
        "aff_unique_url": "https://www.jhu.edu;https://www.sickkids.ca",
        "aff_unique_abbr": "JHU;SickKids",
        "aff_campus_unique_index": "0;1;1;1;1;0",
        "aff_campus_unique": "Baltimore;Toronto",
        "aff_country_unique_index": "0;1;1;1;1;0",
        "aff_country_unique": "United States;Canada"
    },
    {
        "id": "9340894",
        "title": "Animated Cassie: A Dynamic Relatable Robotic Character",
        "track": "main",
        "status": "Poster",
        "abstract": "Creating robots with emotional personalities will transform the usability of robots in the real-world. As previous emotive social robots are mostly based on statically stable robots whose mobility is limited, this paper develops an animation to real-world pipeline that enables dynamic bipedal robots that can twist, wiggle, and walk to behave with emotions. First, an animation method is introduced to design emotive motions for the virtual robot's character. Second, a dynamics optimizer is used to convert the animated motion to dynamically feasible motion. Third, real-time standing and walking controllers and an automaton are developed to bring the virtual character to life. This framework is deployed on a bipedal robot Cassie and validated in experiments. To the best of our knowledge, this paper is one of the first to present an animatronic dynamic legged robot that is able to perform motions with desired emotional attributes. We term robots that use dynamic motions to convey emotions as Dynamic Relatable Robotic Characters.",
        "primary_area": "",
        "author": "Zhongyu Li;Christine Cummings;Koushil Sreenath;Zhongyu Li;Christine Cummings;Koushil Sreenath",
        "authorids": "/37088691308;/37088687886;/37563179200;/37088691308;/37088687886;/37563179200",
        "aff": "Department of Mechanical Engineering, University of California, Berkeley, CA, USA; Department of Mechanical Engineering, University of California, Berkeley, CA, USA; Department of Mechanical Engineering, University of California, Berkeley, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340894/",
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3815404558787211750&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341386",
        "title": "Anomaly Detection for Autonomous Guided Vehicles using Bayesian Surprise",
        "track": "main",
        "status": "Poster",
        "abstract": "As warehouses, storage facilities and factories become more expanded and equipped with smart devices, there is a substantial need for rapid, intelligent and autonomous detection of unusual and potentially hazardous situations, also called anomalies. In particular for Autonomous Guided Vehicles (AGVs) that drive around these premises independently, unforeseen obstructions along their path-e.g. a cardboard box in the middle of a corridor or bumps in the floor-and sudden or unexpected actions executed by personnel-e.g. someone walking in a restricted area-make it hard for AGVs to navigate safely. We therefore propose a novel approach to detect such anomalies in an unsupervised manner by measuring Bayesian surprise: whenever an event is observed that does not align with the agent's prior knowledge of the world, this event is deemed surprising and could indicate an anomaly. This paper lays out the details on how to learn both the prior and posterior models of an AGV that drives around a warehouse and observes the environment through an RGBD camera. In the experiments we show that our Bayesian surprise approach outperforms a baseline that is traditionally used to detect anomalies in sequences of images.",
        "primary_area": "",
        "author": "Ozan \u00c7atal;Sam Leroux;Cedric De Boom;Tim Verbelen;Bart Dhoedt;Ozan \u00c7atal;Sam Leroux;Cedric De Boom;Tim Verbelen;Bart Dhoedt",
        "authorids": "/37088488135;/37085657642;/37085626945;/37072400100;/37279070000;/37088488135;/37085657642;/37085626945;/37072400100;/37279070000",
        "aff": "IDlab, Ghent University, Gent, Belgium; IDlab, Ghent University, Gent, Belgium; IDlab, Ghent University, Gent, Belgium; IDlab, Ghent University, Gent, Belgium; IDlab, Ghent University, Gent, Belgium",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341386/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9880819946680197675&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Ghent University",
        "aff_unique_dep": "IDlab",
        "aff_unique_url": "https://www.ugent.be",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Gent",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Belgium"
    },
    {
        "id": "9341011",
        "title": "Anticipating tumor metastasis by circulating tumor cells captured by acoustic microstreaming",
        "track": "main",
        "status": "Poster",
        "abstract": "Circulating tumor cells (CTCs) are the primary cause of tumor metastasis after surgery. Metastatic tumor recurrence is the leading reason of cancer death. It is prerequisite to develop a platform for CTCs separation to predict the cancer cell transfer in important organs. Herein, a novel acoustic microfluidic device was designed to capture the \"true\" CTCs from the whole blood sample. The blood got from the mice with breast tumors removed. There are some CTCs that have escaped from the solid tumor contained in these blood samples, instead of artificially mixing individual tumor cells into normal blood. In addition, the predictions of tumor prognosis are made based on the number of CTCs captured by the acoustofluidic device. Finally, the prediction has been confirmed through long-term observation of mice with tumor excised. The acoustofluidic device can efficiently capture CTCs and predict the tumor metastasis, which can help clinicians plan follow-up treatment for patients who have had their tumors surgically removed.",
        "primary_area": "",
        "author": "Xue Bai;Bin Song;Dixiao Chen;Yuguo Dai;Lin Feng;Fumihito Arai;Xue Bai;Bin Song;Dixiao Chen;Yuguo Dai;Lin Feng;Fumihito Arai",
        "authorids": "/37088554994;/37086935548;/37086937244;/37086561173;/37403324400;/37274069600;/37088554994;/37086935548;/37086937244;/37086561173;/37403324400;/37274069600",
        "aff": "Beihang University; School of Mechanical Engineering & Automation, Beihang University, Beijing, China; School of Mechanical Engineering & Automation, Beihang University, Beijing, China; School of Mechanical Engineering & Automation, Beihang University, Beijing, China; School of Mechanical Engineering & Automation, Beihang University, Beijing, China; Beihang University; School of Mechanical Engineering & Automation, and also with Beijing Advanced Innovation Center for Biomedical Engineering, Beihang University, Beijing, China; Department of Micro-Nano Mechanical Science & Engineering, Nagoya University, Nagoya, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341011/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:dar8Q5wmVCEJ:scholar.google.com/&scioq=Anticipating+tumor+metastasis+by+circulating+tumor+cells+captured+by+acoustic+microstreaming&hl=en&as_sdt=0,33",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0;0;1",
        "aff_unique_norm": "Beihang University;Nagoya University",
        "aff_unique_dep": ";Department of Micro-Nano Mechanical Science & Engineering",
        "aff_unique_url": "http://www.buaa.edu.cn/;https://www.nagoya-u.ac.jp",
        "aff_unique_abbr": "BUAA;Nagoya U",
        "aff_campus_unique_index": "1;1;1;1;1;2",
        "aff_campus_unique": ";Beijing;Nagoya",
        "aff_country_unique_index": "0;0;0;0;0;0;0;1",
        "aff_country_unique": "China;Japan"
    },
    {
        "id": "9341058",
        "title": "Anticipatory Human-Robot Collaboration via Multi-Objective Trajectory Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "We address the problem of adapting robot trajectories to improve safety, comfort, and efficiency in humanrobot collaborative tasks. To this end, we propose CoMOTO, a trajectory optimization framework that utilizes stochastic motion prediction to anticipate the human's motion and adapt the robot's joint trajectory accordingly. We design a multiobjective cost function that simultaneously optimizes for i) separation distance, ii) visibility of the end-effector, iii) legibility, iv) efficiency, and v) smoothness. We evaluate CoMOTO against three existing methods for robot trajectory generation when in close proximity to humans. Our experimental results indicate that our approach consistently outperforms existing methods over a combined set of safety, comfort, and efficiency metrics.",
        "primary_area": "",
        "author": "Abhinav Jain;Daphne Chen;Dhruva Bansal;Sam Scheele;Mayank Kishore;Hritik Sapra;David Kent;Harish Ravichandar;Sonia Chernova;Abhinav Jain;Daphne Chen;Dhruva Bansal;Sam Scheele;Mayank Kishore;Hritik Sapra;David Kent;Harish Ravichandar;Sonia Chernova",
        "authorids": "/37088686007;/37088506187;/37088689308;/37088691049;/37088688121;/37088688298;/37085409705;/37085429366;/37283184200;/37088686007;/37088506187;/37088689308;/37088691049;/37088688121;/37088688298;/37085409705;/37085429366;/37283184200",
        "aff": "Georgia Institute of Technology, Institute of Robotics and Intelligent Machines, Atlanta, GA, USA; Georgia Institute of Technology, Institute of Robotics and Intelligent Machines, Atlanta, GA, USA; Georgia Institute of Technology, Institute of Robotics and Intelligent Machines, Atlanta, GA, USA; Georgia Institute of Technology, Institute of Robotics and Intelligent Machines, Atlanta, GA, USA; Georgia Institute of Technology, Institute of Robotics and Intelligent Machines, Atlanta, GA, USA; Georgia Institute of Technology, Institute of Robotics and Intelligent Machines, Atlanta, GA, USA; Georgia Institute of Technology, Institute of Robotics and Intelligent Machines, Atlanta, GA, USA; Georgia Institute of Technology, Institute of Robotics and Intelligent Machines, Atlanta, GA, USA; Georgia Institute of Technology, Institute of Robotics and Intelligent Machines, Atlanta, GA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341058/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7359625688589277824&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Georgia Institute of Technology",
        "aff_unique_dep": "Institute of Robotics and Intelligent Machines",
        "aff_unique_url": "https://www.gatech.edu",
        "aff_unique_abbr": "Georgia Tech",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Atlanta",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340777",
        "title": "Antipodal Robotic Grasping using Generative Residual Convolutional Neural Network",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a modular robotic system to tackle the problem of generating and performing antipodal robotic grasps for unknown objects from the n-channel image of the scene. We propose a novel Generative Residual Convolutional Neural Network (GR-ConvNet) model that can generate robust antipodal grasps from n-channel input at real-time speeds (~20ms). We evaluate the proposed model architecture on standard datasets and a diverse set of household objects. We achieved state-of-the-art accuracy of 97.7% and 94.6% on Cornell and Jacquard grasping datasets, respectively. We also demonstrate a grasp success rate of 95.4% and 93% on household and adversarial objects, respectively, using a 7 DoF robotic arm.",
        "primary_area": "",
        "author": "Sulabh Kumra;Shirin Joshi;Ferat Sahin;Sulabh Kumra;Shirin Joshi;Ferat Sahin",
        "authorids": "/38666961800;/37088525671;/37396486100;/38666961800;/37088525671;/37396486100",
        "aff": "OSARO Inc., San Francisco, CA, USA; Multi-Agent Bio-Robotics Laboratory (MABL), Rochester Institute of Technology, Rochester, NY, USA; Multi-Agent Bio-Robotics Laboratory (MABL), Rochester Institute of Technology, Rochester, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340777/",
        "gs_citation": 402,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11757487558005571229&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "OSARO Inc.;Rochester Institute of Technology",
        "aff_unique_dep": ";Multi-Agent Bio-Robotics Laboratory (MABL)",
        "aff_unique_url": "https://www.osaro.com;https://www.rit.edu",
        "aff_unique_abbr": "OSARO;RIT",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "San Francisco;Rochester",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341349",
        "title": "Anytime Kinodynamic Motion Planning using Region-Guided Search",
        "track": "main",
        "status": "Poster",
        "abstract": "Many kinodynamic motion planners have been developed that guarantee probabilistic completeness and asymptotic optimality for systems for which steering functions are available. Recently, some planners have been developed that achieve these properties of completeness and optimality without requiring a steering function. However, these planners have not taken strong advantage of heuristic guidance to speed their search. This paper introduces Region Informed Optimal Trees (RIOT), a sampling-based, asymptotically optimal motion planner for systems without steering functions. RIOT's search is guided by a low-dimensional abstraction of the state space that is updated during planning for better guidance. Simulation results suggest RIOT is adaptable, scalable, and more effective on difficult problems than previous work.",
        "primary_area": "",
        "author": "Matthew G. Westbrook;Wheeler Ruml;Matthew G. Westbrook;Wheeler Ruml",
        "authorids": "/37088691140;/37275662000;/37088691140;/37275662000",
        "aff": "Department of Mechanical Engineering, University of New Hampshire, USA; Department of Computer Science, University of New Hampshire, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341349/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1305266321189070657&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of New Hampshire",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.unh.edu",
        "aff_unique_abbr": "UNH",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341110",
        "title": "Application of Interacting Models to Estimate the Gait Speed of an Exoskeleton User",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper outlines steps toward a framework for model-based user intent detection to enable fluent human-robot interaction in assistive exoskeletons. An interacting multi-model (IMM) estimation scheme is presented to address state estimation for lower-extremity exoskeletons and to handle their hybrid dynamics. The proposed IMM scheme includes new approaches that enable it to estimate states of hybrid systems with dynamics that are unique to each phase. Traditional IMMs only consider the probabilistic likelihood of being in each phase, while the implementation in this work has been modified to consider physical likelihood as well. The IMM compares exoskeleton sensor readings to multiple candidate gaits from a template model of walking. Candidate gaits are generated using a numerical optimization procedure applied to a Bipedal Spring-Loaded Inverted Pendulum (B-SLIP) model. The framework was tested with sensor data acquired from walking trials in an Ekso GT exoskeleton, and was used to estimate gait phase and center of mass velocity. It is shown that the standard IMM filtering approach results in incorrect estimates of gait phase, while the proposed addition to the IMM estimator using physical likelihood improves the estimates. Results with human subject data further show the ability to estimate gait phase and speed in experimental settings.",
        "primary_area": "",
        "author": "Roopak M. Karulkar;Patrick M. Wensing;Roopak M. Karulkar;Patrick M. Wensing",
        "authorids": "/37088687586;/37946046300;/37088687586;/37946046300",
        "aff": "Department of Aerospace and Mechanical Engineering, University of Notre Dame, Notre Dame, IN, USA; Department of Aerospace and Mechanical Engineering, University of Notre Dame, Notre Dame, IN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341110/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14459228540773832235&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Notre Dame",
        "aff_unique_dep": "Department of Aerospace and Mechanical Engineering",
        "aff_unique_url": "https://www.nd.edu",
        "aff_unique_abbr": "Notre Dame",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Notre Dame",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341488",
        "title": "Applications of Stretch Reflex for the Upper Limb of Musculoskeletal Humanoids: Protective Behavior, Postural Stability, and Active Induction",
        "track": "main",
        "status": "Poster",
        "abstract": "The musculoskeletal humanoid has various biomimetic benefits, and it is important that we can embed and evaluate human reflexes in the actual robot. Although stretch reflex has been implemented in lower limbs of musculoskeletal humanoids, we apply it to the upper limb to discover its useful applications. We consider the implementation of stretch reflex in the actual robot, its active/passive applications, and the change in behavior according to the difference of parameters.",
        "primary_area": "",
        "author": "Kento Kawaharazuka;Yuya Koga;Kei Tsuzuki;Moritaka Onitsuka;Yuki Asano;Kei Okada;Koji Kawasaki;Masayuki Inaba;Kento Kawaharazuka;Yuya Koga;Kei Tsuzuki;Moritaka Onitsuka;Yuki Asano;Kei Okada;Koji Kawasaki;Masayuki Inaba",
        "authorids": "/37086101930;/37088339856;/37086598284;/37086573419;/38238750500;/37280639000;/37085684621;/37286658200;/37086101930;/37088339856;/37086598284;/37086573419;/38238750500;/37280639000;/37085684621;/37286658200",
        "aff": "Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Bunkyo-ku, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Bunkyo-ku, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Bunkyo-ku, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Bunkyo-ku, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Bunkyo-ku, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Bunkyo-ku, Japan; TOYOTA MOTOR CORPORATION; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Bunkyo-ku, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341488/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3805582420812623330&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;0;1;0",
        "aff_unique_norm": "The University of Tokyo;Toyota Motor Corporation",
        "aff_unique_dep": "Department of Mechano-Informatics, Graduate School of Information Science and Technology;",
        "aff_unique_url": "https://www.u-tokyo.ac.jp;https://www.toyota-global.com",
        "aff_unique_abbr": "UTokyo;Toyota",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Bunkyo-ku;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9340638",
        "title": "Applying Force Perturbations Using a Wearable Robotic Neck Brace",
        "track": "main",
        "status": "Poster",
        "abstract": "Force perturbation is used in this paper to study cervical neuromuscular responses which can be used in the future to assess impairments in patients with neurological diseases. Current literature on this topic is limited to applying forces on the head in the anterior-posterior direction, perhaps due to technological limitations. In this paper, we propose to use a robotic neck brace to address these shortcomings due to its lightweight portable design and the ability to control forces. A controller is implemented to apply direction-specific perturbations on the head. To demonstrate the effectiveness of this capability, a human study was carried out with able-bodied subjects. We used this robotic brace to apply forces on the head of the subjects and observed their movement and muscle responses both when their eyes were open and closed. Our results suggest that the robotic brace is capable of perturbing the head and tracking the kinematic response. It revealed that ablebodied subjects reacted to the perturbations differently when their eyes were closed. They showed longer head trajectories and more muscle activation when the eyes were closed. We also show that the direction-specific perturbation feature enables us to analyze kinematic and muscle variables with respect to the direction of perturbation. This helps better understand the neuromuscular response in the head-neck.",
        "primary_area": "",
        "author": "Haohan Zhang;Victor Santamaria;Sunil Agrawal;Haohan Zhang;Victor Santamaria;Sunil Agrawal",
        "authorids": "/37086027856;/37086036653;/37281455400;/37086027856;/37086036653;/37281455400",
        "aff": "Department of Mechanical Engineering, Columbia University, New York, NY; Department of Mechanical Engineering, Columbia University, New York, NY; Department of Rehabilitation and Regenerative Medicine, Columbia University Medical Center, New York, NY",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340638/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11782773971980831618&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Columbia University;Columbia University Medical Center",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Rehabilitation and Regenerative Medicine",
        "aff_unique_url": "https://www.columbia.edu;https://www.columbia.edu",
        "aff_unique_abbr": "Columbia;CUMC",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "New York",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341340",
        "title": "Applying Surface Normal Information in Drivable Area and Road Anomaly Detection for Ground Mobile Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "The joint detection of drivable areas and road anomalies is a crucial task for ground mobile robots. In recent years, many impressive semantic segmentation networks, which can be used for pixel-level drivable area and road anomaly detection, have been developed. However, the detection accuracy still needs improvement. Therefore, we develop a novel module named the Normal Inference Module (NIM), which can generate surface normal information from dense depth images with high accuracy and efficiency. Our NIM can be deployed in existing convolutional neural networks (CNNs) to refine the segmentation performance. To evaluate the effectiveness and robustness of our NIM, we embed it in twelve state-of-the-art CNNs. The experimental results illustrate that our NIM can greatly improve the performance of the CNNs for drivable area and road anomaly detection. Furthermore, our proposed NIM-RTFNet ranks 8th on the KITTI road benchmark and exhibits a real-time inference speed.",
        "primary_area": "",
        "author": "Hengli Wang;Rui Fan;Yuxiang Sun;Ming Liu;Hengli Wang;Rui Fan;Yuxiang Sun;Ming Liu",
        "authorids": "/37086939511;/37085892666;/37085435479;/37085398677;/37086939511;/37085892666;/37085435479;/37085398677",
        "aff": "Department of Electronic and Computer Engineering, the Hong Kong University of Science and Technology, Hong Kong SAR, China; Jacobs School of Engineering as well as the UCSD Health, the University of California, San Diego, La Jolla, CA, U.S.; Department of Electronic and Computer Engineering, the Hong Kong University of Science and Technology, Hong Kong SAR, China; Department of Electronic and Computer Engineering, the Hong Kong University of Science and Technology, Hong Kong SAR, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341340/",
        "gs_citation": 75,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10626641982851703997&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Hong Kong University of Science and Technology;University of California, San Diego",
        "aff_unique_dep": "Department of Electronic and Computer Engineering;Jacobs School of Engineering",
        "aff_unique_url": "https://www.ust.hk;https://ucsd.edu",
        "aff_unique_abbr": "HKUST;UCSD",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Hong Kong SAR;La Jolla",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9341107",
        "title": "Approximated Dynamic Trait Models for Heterogeneous Multi-Robot Teams",
        "track": "main",
        "status": "Poster",
        "abstract": "To realize effective heterogeneous multi-agent teams, we must be able to leverage individual agents' relative strengths. Recent work has addressed this challenge by introducing trait-based task assignment approaches that exploit the agents' relative advantages. These approaches, however, assume that the agents' traits remain static. Indeed, in real-world scenarios, traits are likely to vary as agents execute tasks. In this paper, we present a transformation-based modeling framework to bridge the gap between state-of-the-art task assignment algorithms and the reality of dynamic traits. We define a transformation as a function that approximates dynamic traits with static traits based on a specific statistical measure. We define different candidate transformations, investigate their effects on different dynamic trait models, and the resulting task performance. Further, we propose a variance-based transformation as a general solution that approximates a variety of dynamic models, eliminating the need for hand specification. Finally, we demonstrate the benefits of reasoning about dynamic traits both in simulation and in a physical experiment involving the game of capture-the-flag.",
        "primary_area": "",
        "author": "Glen Neville;Harish Ravichandar;Kenneth Shaw;Sonia Chernova;Glen Neville;Harish Ravichandar;Kenneth Shaw;Sonia Chernova",
        "authorids": "/37087236646;/37085429366;/37088690714;/37283184200;/37087236646;/37085429366;/37088690714;/37283184200",
        "aff": "Institute of Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA, USA; Institute of Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA, USA; Institute of Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA, USA; Institute of Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341107/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3509847032990065790&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Georgia Institute of Technology",
        "aff_unique_dep": "Institute of Robotics and Intelligent Machines",
        "aff_unique_url": "https://www.gatech.edu",
        "aff_unique_abbr": "Georgia Tech",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Atlanta",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341424",
        "title": "Assessment of Soil Strength using a Robotically Deployed and Retrieved Penetrometer",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a method for performing free-fall penetrometer tests for soft soils using an instrumented dart deployed by a quadcopter. Tests were performed with three soil types and used to examine the effect of drop height on the penetration depth and the deceleration profile. Further tests analyzed the force required to remove a dart from the soil and the effect of pulling at different speeds and angles. The pull force of a consumer drone was measured, and tests were performed where a drone delivered and removed darts in soil representative of a wetland environment.",
        "primary_area": "",
        "author": "Victor M. Baez;Ami Shah;Samuel Akinwande;Navid H. Jafari;Aaron T. Becker;Victor M. Baez;Ami Shah;Samuel Akinwande;Navid H. Jafari;Aaron T. Becker",
        "authorids": "/37087413377;/37088688603;/37086397382;/37088690880;/37588897100;/37087413377;/37088688603;/37086397382;/37088690880;/37588897100",
        "aff": "Department of Electrical and Computer Engineering, University of Houston, Houston, TX, USA; Department of Electrical and Computer Engineering, University of Houston, Houston, TX, USA; Department of Electrical and Computer Engineering, University of Houston, Houston, TX, USA; Civil and Environmental Engineering, Louisiana State University, Baton Rouge, LA, USA; Department of Electrical and Computer Engineering, University of Houston, Houston, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341424/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3559729645467857873&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "University of Houston;Louisiana State University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Civil and Environmental Engineering",
        "aff_unique_url": "https://www.uh.edu;https://www.lsu.edu",
        "aff_unique_abbr": "UH;LSU",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Houston;Baton Rouge",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341514",
        "title": "Assisted Mobile Robot Teleoperation with Intent-aligned Trajectories via Biased Incremental Action Sampling",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a method to assist the operator in teleoperation of mobile robots by generating trajectories such that the vehicle completes the desired task with ease in unstructured environments. Traditional assisted teleoperation methods have focused on reactive methods to avoid collisions, but neglect the operator's intention in doing so. Instead, we generate long horizon, smooth trajectories that follow the operator's intended direction while circumventing obstacles for a seamless teleoperation experience. For mobile robot teleoperation, an explicit goal in the state space is often unclear in cases such as exploration or navigation. Therefore, we model the intent as a direction and encode it as a cost function. As trajectories of various lengths can satisfy the same directional objective, we iteratively construct a tree of sequential actions that form multiple trajectories along the intended direction. We show our algorithm on a real-time teleoperation task of a simulated hexarotor vehicle in a dense random forest environment. By doing so, our approach allows operator to achieve the navigation task while requiring less effort than reactive methods.",
        "primary_area": "",
        "author": "Xuning Yang;Nathan Michael;Xuning Yang;Nathan Michael",
        "authorids": "/37086010950;/37302499000;/37086010950;/37302499000",
        "aff": "Robotics Institute at Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute at Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341514/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14181974706554027130&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341636",
        "title": "Asynchronous Adaptive Sampling and Reduced-Order Modeling of Dynamic Processes by Robot Teams via Intermittently Connected Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "This work presents an asynchronous multi-robot adaptive sampling strategy through the synthesis of an intermittently connected mobile robot communication network. The objective is to enable a team of robots to adaptively sample and model a nonlinear dynamic spatiotemporal process. By employing an intermittently connected communication network, the team is not required to maintain an all-time connected network enabling them to cover larger areas, especially when the team size is small. The approach first determines the next meeting locations for data exchange and as the robots move towards these predetermined locations, they take measurements along the way. The data is then shared with other team members at the designated meeting locations and a reducedorder-model (ROM) of the process is obtained in a distributed fashion. The ROM is used to estimate field values in areas without sensor measurements, which informs the path planning algorithm when determining a new meeting location for the team. The main contribution of this work is an intermittent communication framework for asynchronous adaptive sampling of dynamic spatiotemporal processes. We demonstrate the framework in simulation and compare different reduced-order models under full, all-time and intermittent connectivity.",
        "primary_area": "",
        "author": "Hannes Rovina;Tahiya Salam;Yiannis Kantaros;M. Ani Hsieh;Hannes Rovina;Tahiya Salam;Yiannis Kantaros;M. Ani Hsieh",
        "authorids": "/37088689033;/37086484571;/37085499544;/37085672471;/37088689033;/37086484571;/37085499544;/37085672471",
        "aff": "GRASP Laboratory, University of Pennsylvania, Philadelphia, PA, USA; GRASP Laboratory, University of Pennsylvania, Philadelphia, PA, USA; GRASP Laboratory, University of Pennsylvania, Philadelphia, PA, USA; GRASP Laboratory, University of Pennsylvania, Philadelphia, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341636/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8543300962021876912&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Pennsylvania",
        "aff_unique_dep": "GRASP Laboratory",
        "aff_unique_url": "https://www.upenn.edu",
        "aff_unique_abbr": "UPenn",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Philadelphia",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341240",
        "title": "Asynchronous Event-based Line Tracking for Time-to-Contact Maneuvers in UAS",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents an bio-inspired event-based perception scheme for agile aerial robot maneuvering. It tries to mimic birds, which perform purposeful maneuvers by closing the separation in the retinal image (w.r.t. the goal) to follow time-to-contact trajectories. The proposed approach is based on event cameras, also called artificial retinas, which provide fast response and robustness against motion blur and lighting conditions. Our scheme guides the robot by only adjusting the position of features extracted in the event image plane to their goal positions at a predefined time using smooth time-to-contact trajectories. The proposed scheme is robust, efficient and can be added on top of commonly-used aerial robot velocity controllers. It has been validated on-board a UAV with real-time computation in low-cost hardware during sets of experiments with different descent maneuvers and lighting conditions.",
        "primary_area": "",
        "author": "A. G\u00f3mez Egu\u00edluz;J.P. Rodr\u00edguez-G\u00f3mez;J.R. Mart\u00ednez-de Dios;A. Ollero;A. G\u00f3mez Egu\u00edluz;J.P. Rodr\u00edguez-G\u00f3mez;J.R. Mart\u00ednez-de Dios;A. Ollero",
        "authorids": "/37088600868;/37087994966;/38303554600;/37265412000;/37088600868;/37087994966;/38303554600;/37265412000",
        "aff": "GRVC Robotics laboratory, University of Seville, Seville, Spain; GRVC Robotics laboratory, University of Seville, Seville, Spain; GRVC Robotics laboratory, University of Seville, Seville, Spain; GRVC Robotics laboratory, University of Seville, Seville, Spain",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341240/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6610192566060510997&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Seville",
        "aff_unique_dep": "GRVC Robotics laboratory",
        "aff_unique_url": "https://www.us.es",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Seville",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Spain"
    },
    {
        "id": "9341350",
        "title": "Auditory Feedback Effectiveness for Enabling Safe Sclera Force in Robot-Assisted Vitreoretinal Surgery: a Multi-User Study",
        "track": "main",
        "status": "Poster",
        "abstract": "Robot-assisted retinal surgery has become increasingly prevalent in recent years in part due to the potential for robots to help surgeons improve the safety of an immensely delicate and difficult set of tasks. The integration of robots into retinal surgery has resulted in diminished surgeon perception of tool-to-tissue interaction forces due to robot's stiffness. The tactile perception of these interaction forces (sclera force) has long been a crucial source of feedback for surgeons who rely on them to guide surgical maneuvers and to prevent damaging forces from being applied to the eye. This problem is exacerbated when there are unfavorable sclera forces originating from patient movements (dynamic eyeball manipulation) during surgery which may cause the sclera forces to increase even drastically. In this study we aim at evaluating the efficacy of providing warning auditory feedback based on the level of sclera force measured by force sensing instruments. The intent is to enhance safety during dynamic eye manipulations in robot-assisted retinal surgery. The disturbances caused by lateral movement of patient's head are simulated using a piezo-actuated linear stage. The Johns Hopkins Steady-Hand Eye Robot (SHER), is then used in a multi-user experiment. Twelve participants are asked to perform a mock retinal surgery by following painted vessels inside an eye phantom using a force sensing instrument while auditory feedback is provided. The results indicate that the users are able to handle the eye motion disturbances while maintaining the sclera forces within safe boundaries when audio feedback is provided.",
        "primary_area": "",
        "author": "Ali Ebrahimi;Marina Roizenblatt;Niravkumar Patel;Peter Gehlbach;Iulian Iordachita;Ali Ebrahimi;Marina Roizenblatt;Niravkumar Patel;Peter Gehlbach;Iulian Iordachita",
        "authorids": "/37086189127;/37086496352;/37086366528;/37547001700;/37330620500;/37086189127;/37086496352;/37086366528;/37547001700;/37330620500",
        "aff": "Mechanical Engineering Department and Laboratory for Computational Sensing and Robotics (LCSR), Johns Hopkins University, Baltimore, MD, USA; Federal University of Sao Paulo, Sao Paulo, Brazil; Mechanical Engineering Department and Laboratory for Computational Sensing and Robotics (LCSR), Johns Hopkins University, Baltimore, MD, USA; Federal University of Sao Paulo, Sao Paulo, Brazil; Mechanical Engineering Department and Laboratory for Computational Sensing and Robotics (LCSR), Johns Hopkins University, Baltimore, MD, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341350/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3654071675936337400&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;1;0",
        "aff_unique_norm": "Johns Hopkins University;Federal University of Sao Paulo",
        "aff_unique_dep": "Mechanical Engineering Department;",
        "aff_unique_url": "https://www.jhu.edu;https://www.unifesp.br",
        "aff_unique_abbr": "JHU;UNIFESP",
        "aff_campus_unique_index": "0;1;0;1;0",
        "aff_campus_unique": "Baltimore;Sao Paulo",
        "aff_country_unique_index": "0;1;0;1;0",
        "aff_country_unique": "United States;Brazil"
    },
    {
        "id": "9341595",
        "title": "Augmented Memory for Correlation Filters in Real-Time UAV Tracking",
        "track": "main",
        "status": "Poster",
        "abstract": "The outstanding computational efficiency of discriminative correlation filter (DCF) fades away with various complicated improvements. Previous appearances are also gradually forgotten due to the exponential decay of historical views in traditional appearance updating scheme of DCF framework, reducing the model's robustness. In this work, a novel tracker based on DCF framework is proposed to augment memory of previously appeared views while running at real-time speed. Several historical views and the current view are simultaneously introduced in training to allow the tracker to adapt to new appearances as well as memorize previous ones. A novel rapid compressed context learning is proposed to increase the discriminative ability of the filter efficiently. Substantial experiments on UAVDT and UAV123 datasets have validated that the proposed tracker performs competitively against other 26 top DCF and deep-based trackers with over 40fps on CPU.",
        "primary_area": "",
        "author": "Yiming Li;Changhong Fu;Fangqiang Ding;Ziyuan Huang;Jia Pan;Yiming Li;Changhong Fu;Fangqiang Ding;Ziyuan Huang;Jia Pan",
        "authorids": "/37087323806;/37086797986;/37088456219;/37086868757;/37535628800;/37087323806;/37086797986;/37088456219;/37086868757;/37535628800",
        "aff": "School of Mechanical Engineering, Tongji University, Shanghai, China; School of Mechanical Engineering, Tongji University, Shanghai, China; School of Mechanical Engineering, Tongji University, Shanghai, China; Advanced Robotics Centre, National University of Singapore, Singapore; Computer Science Department, The University of Hong Kong, Hong Kong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341595/",
        "gs_citation": 44,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7276816960303673993&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;2",
        "aff_unique_norm": "Tongji University;National University of Singapore;The University of Hong Kong",
        "aff_unique_dep": "School of Mechanical Engineering;Advanced Robotics Centre;Computer Science Department",
        "aff_unique_url": "https://www.tongji.edu.cn;https://www.nus.edu.sg;https://www.hku.hk",
        "aff_unique_abbr": "Tongji;NUS;HKU",
        "aff_campus_unique_index": "0;0;0;2",
        "aff_campus_unique": "Shanghai;;Hong Kong",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "China;Singapore"
    },
    {
        "id": "9341422",
        "title": "Augmented Reality User Interfaces for Heterogeneous Multirobot Control",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent advances in the design of head-mounted augmented reality (AR) interfaces for assistive human-robot interaction (HRI) have allowed untrained users to rapidly and fluently control single-robot platforms. In this paper, we investigate how such interfaces transfer onto multirobot architectures, as several assistive robotics applications need to be distributed among robots that are different both physically and in terms of software. As part of this investigation, we introduce a novel head-mounted AR interface for heterogeneous multirobot control. This interface generates and displays dynamic joint-affordance signifiers, i.e. signifiers that combine and show multiple actions from different robots that can be applied simultaneously to an object. We present a user study with 15 participants analysing the effects of our approach on their perceived fluency. Participants were given the task of filling-out a cup with water making use of a multirobot platform. Our results show a clear improvement in standard HRI fluency metrics when users applied dynamic joint-affordance signifiers, as opposed to a sequence of independent actions.",
        "primary_area": "",
        "author": "Rodrigo Chacon-Quesada;Yiannis Demiris;Rodrigo Chacon-Quesada;Yiannis Demiris",
        "authorids": "/37086064938;/37296338900;/37086064938;/37296338900",
        "aff": "Department of Electrical and Electronic Engineering, Personal Robotics Laboratory, Imperial College Lon-don, London, United Kingdom; Department of Electrical and Electronic Engineering, Personal Robotics Laboratory, Imperial College Lon-don, London, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341422/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4064575403028862004&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Imperial College London",
        "aff_unique_dep": "Department of Electrical and Electronic Engineering",
        "aff_unique_url": "https://www.imperial.ac.uk",
        "aff_unique_abbr": "ICL",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9341153",
        "title": "Augmenting Control Policies with Motion Planning for Robust and Safe Multi-robot Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "This work proposes a novel method of incorporating calls to a motion planner inside a potential field control policy for safe multi-robot navigation with uncertain dynamics. The proposed framework can handle more general scenes than the control policy and has low computational costs. Our work is robust to uncertain dynamics and quickly finds high-quality paths in scenarios generated from real-world floor plans. In the proposed approach, we attempt to follow the control policy as much as possible, and use calls to the motion planner to escape local minima. Trajectories returned from the motion planner are followed using a path-following controller guaranteeing robustness. We demonstrate the utility of our approach with experiments based on floor plans gathered from real buildings.",
        "primary_area": "",
        "author": "Tianyang Pan;Christos K. Verginis;Andrew M. Wells;Lydia E. Kavraki;Dimos V. Dimarogonas;Tianyang Pan;Christos K. Verginis;Andrew M. Wells;Lydia E. Kavraki;Dimos V. Dimarogonas",
        "authorids": "/37086938153;/37085751745;/37086687629;/37279015600;/37282084700;/37086938153;/37085751745;/37086687629;/37279015600;/37282084700",
        "aff": "Dept. of Comp. Sci., Rice Univ; School of Electr. Engin. and Comp. Sci., KTH Center of Autonomous Systems; Dept. of Comp. Sci., Rice Univ; Dept. of Comp. Sci., Rice Univ; School of Electr. Engin. and Comp. Sci., KTH Center of Autonomous Systems",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341153/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13238026580349415950&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 13,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;1",
        "aff_unique_norm": "Rice University;KTH Royal Institute of Technology",
        "aff_unique_dep": "Department of Computer Science;School of Electrical Engineering and Computer Science",
        "aff_unique_url": "https://www.rice.edu;https://www.kth.se",
        "aff_unique_abbr": "Rice;KTH",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0;0;1",
        "aff_country_unique": "United States;Sweden"
    },
    {
        "id": "9341724",
        "title": "AutoLay: Benchmarking amodal layout estimation for autonomous driving",
        "track": "main",
        "status": "Poster",
        "abstract": "Given an image or a video captured from a monocular camera, amodal layout estimation is the task of predicting semantics and occupancy in bird's eye view. The term amodal implies we also reason about entities in the scene that are occluded or truncated in image space. While several recent efforts have tackled this problem, there is a lack of standardization in task specification, datasets, and evaluation protocols. We address these gaps with AutoLay, a dataset and benchmark for amodal layout estimation from monocular images. AutoLay encompasses driving imagery from two popular datasets: KITTI [1] and Argoverse [2]. In addition to fine-grained attributes such as lanes, sidewalks, and vehicles, we also provide semantically annotated 3D point clouds. We implement several baselines and bleeding edge approaches, and release our data and code.1.",
        "primary_area": "",
        "author": "Kaustubh Mani;N. Sai Shankar;Krishna Murthy Jatavallabhula;K. Madhava Krishna;Kaustubh Mani;N. Sai Shankar;Krishna Murthy Jatavallabhula;K. Madhava Krishna",
        "authorids": "/37086153849;/37088690526;/37088689541;/37395945400;/37086153849;/37088690526;/37088689541;/37395945400",
        "aff": "IIIT Hyderabad; Robotics Research Center, KCIS; Universit\u00e9 de Montr\u00e9al; IIIT Hyderabad",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341724/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2861457402390943219&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "International Institute of Information Technology, Hyderabad;Korea Advanced Institute of Science and Technology;Universit\u00e9 de Montr\u00e9al",
        "aff_unique_dep": ";Robotics Research Center;",
        "aff_unique_url": "https://iiit Hyderabad.ac.in;https://www.kaist.ac.kr;https://www.umontreal.ca",
        "aff_unique_abbr": "IIIT-H;KAIST;UdeM",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Hyderabad;",
        "aff_country_unique_index": "0;1;2;0",
        "aff_country_unique": "India;South Korea;Canada"
    },
    {
        "id": "9341145",
        "title": "Automated Design and Construction of a Single Incision Laparoscopic System Adapted to the Required Workspace",
        "track": "main",
        "status": "Poster",
        "abstract": "Currently, laparoscopic surgery systems are adapted for a large number of indications and patients and are therefore not optimized for one specific case. The challenge to create systems with an optimized kinematic structure for a specific patient regarding reachability and manipulability in the needed workspace is the automated design and construction process. We have developed an automated design and construction process for a patient-specific Single Incision Laparoscopic System that is optimized for a specific indication, procedure, patient, and surgeon. The kinematic structure is adapted to the required workspace, needed instrumentation, and manufacturing parameters. First results show that the patient-specific Single Incision Laparoscopic System is better suited for the specific application regarding the combination of reachability, manipulability, and system size in the required workspace than the standard Single Incision Laparoscopic System in different standard sizes or one simple standard size.",
        "primary_area": "",
        "author": "Sandra V. Brecht;Johannes S. A. Voegerl;Tim C. Lueth;Sandra V. Brecht;Johannes S. A. Voegerl;Tim C. Lueth",
        "authorids": "/37085991401;/37088689439;/37389804500;/37085991401;/37088689439;/37389804500",
        "aff": "Department of Mechanical Engineering, Institute of Micro Technology and Medical Device Technology (MiMed), Technical University of Munich, Munich, Germany; Department of Mechanical Engineering, Institute of Micro Technology and Medical Device Technology (MiMed), Technical University of Munich, Munich, Germany; Department of Mechanical Engineering, Institute of Micro Technology and Medical Device Technology (MiMed), Technical University of Munich, Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341145/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14679869211908416321&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Technical University of Munich",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.tum.de",
        "aff_unique_abbr": "TUM",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Munich",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9341239",
        "title": "Automated Folding of a Deformable Thin Object through Robot Manipulators",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a model-free approach to automate folding of a deformable object with robot manipulators, where its surface was labelled with markers to facilitate vision-based control and alignment. While performing the task involves solving nonconvex or nonlinear terms, in this paper, linearization was first performed to approximate the problem. By using the Levenberg-Marquardt algorithm, the task of folding a deformable thin object can be reformulated as a convex optimization problem. The mapping relationship between the motions of markers on the image and the joint inputs of the robot manipulator was evaluated through a Jacobian matrix. To account for the uncertainty in the matrix due to the deformable object, a two-stage evaluation scheme, which consists of approximate-rigidity rule and Broyden-update rule, was performed. Proper constraints were also added to avoid causing damage to the object. The performance and the robustness of the proposed approach were examined through simulation using Bullet simulator. The video of the simulation can be retrieved from the attachment. The results confirm that the thin object can be precisely folded together based on different markers labelled on the surface.",
        "primary_area": "",
        "author": "Zhenxi Cui;Kaicheng Huang;Bo Lu;Henry K. Chu;Zhenxi Cui;Kaicheng Huang;Bo Lu;Henry K. Chu",
        "authorids": "/37087053346;/37086798188;/37085991083;/37085396213;/37087053346;/37086798188;/37085991083;/37085396213",
        "aff": "Department of Mechanical Engineering, The Hong Kong Polytechnic University, Hong Kong; Department of Mechanical Engineering, The Hong Kong Polytechnic University, Hong Kong; The Department of Mechanical and Automation Engineering, T stone Robotics Institute, The Chinese University of Hong Kong; Department of Mechanical Engineering, The Hong Kong Polytechnic University, Hong Kong",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341239/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2242765857529983437&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "The Hong Kong Polytechnic University;The Chinese University of Hong Kong",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Mechanical and Automation Engineering",
        "aff_unique_url": "https://www.polyu.edu.hk;https://www.cuhk.edu.hk",
        "aff_unique_abbr": "PolyU;CUHK",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9341466",
        "title": "Automatic Control Synthesis for Swarm Robots from Formation and Location-based High-level Specifications",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose an abstraction that captures high-level formation and location-based swarm behaviors, and an automated control synthesis framework to generate correct-by-construction behaviors. Our abstraction includes symbols representing both possible formations and physical locations in the workspace. We allow users to write linear temporal logic (LTL) specifications over the symbols to specify high-level tasks for the swarm. To satisfy a specification, we automatically synthesize a centralized symbolic plan, and environment and swarm-size-dependent motion controllers that are guaranteed to implement the symbolic transitions. In addition, using integer programming (IP), we assign robots to different sub-swarms to execute the synthesized symbolic plan. Our framework gives insights into controlling a large fleet of autonomous robots to achieve complex tasks which require composition of behaviors at different locations and coordination among different groups of robots in a correct-by-construction way. We demonstrate the proposed framework in simulation with 16 UAVs and 8 ground vehicles, and on a physical platform with 20 ground robots, showcasing the generality of the approach and discussing the implications of controlling constrained physical hardware.",
        "primary_area": "",
        "author": "Ji Chen;Hanlin Wang;Michael Rubenstein;Hadas Kress-Gazit;Ji Chen;Hanlin Wang;Michael Rubenstein;Hadas Kress-Gazit",
        "authorids": "/37088686645;/37087323331;/37282496500;/38307602100;/37088686645;/37087323331;/37282496500;/38307602100",
        "aff": "Sibley School of Mechanical and Aerospace Engineering, Cornell University, Ithaca, NY, USA; Department of Computer Science, Northwestern University, Evanston, IL, USA; Department of Computer Science, Northwestern University, Evanston, IL, USA; Sibley School of Mechanical and Aerospace Engineering, Cornell University, Ithaca, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341466/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14416311624149737951&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "Cornell University;Northwestern University",
        "aff_unique_dep": "Sibley School of Mechanical and Aerospace Engineering;Department of Computer Science",
        "aff_unique_url": "https://www.cornell.edu;https://www.northwestern.edu",
        "aff_unique_abbr": "Cornell;NU",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Ithaca;Evanston",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341744",
        "title": "Automatic Failure Recovery and Re-Initialization for Online UAV Tracking with Joint Scale and Aspect Ratio Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "Current unmanned aerial vehicle (UAV) visual tracking algorithms are primarily limited with respect to: (i) the kind of size variation they can deal with, (ii) the implementation speed which hardly meets the real-time requirement. In this work, a real-time UAV tracking algorithm with powerful size estimation ability is proposed. Specifically, the overall tracking task is allocated to two 2D filters: (i) translation filter for location prediction in the space domain, (ii) size filter for scale and aspect ratio optimization in the size domain. Besides, an efficient two-stage re-detection strategy is introduced for long-term UAV tracking tasks. Large-scale experiments on four UAV benchmarks demonstrate the superiority of the presented method which has computation feasibility on a low-cost CPU.",
        "primary_area": "",
        "author": "Fangqiang Ding;Changhong Fu;Yiming Li;Jin Jin;Chen Feng;Fangqiang Ding;Changhong Fu;Yiming Li;Jin Jin;Chen Feng",
        "authorids": "/37088456219;/37086797986;/37087323806;/37088686956;/37086391326;/37088456219;/37086797986;/37087323806;/37088686956;/37086391326",
        "aff": "School of Mechanical Engineering, Tongji University, Shanghai, China; School of Mechanical Engineering, Tongji University, Shanghai, China; School of Mechanical Engineering, Tongji University, Shanghai, China; School of Mechanical Engineering, Tongji University, Shanghai, China; Tandon School of Engineering, New York University, NY, New York, United States",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341744/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3595537023429728824&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "Tongji University;New York University",
        "aff_unique_dep": "School of Mechanical Engineering;Tandon School of Engineering",
        "aff_unique_url": "https://www.tongji.edu.cn;https://www.nyu.edu",
        "aff_unique_abbr": "Tongji;NYU",
        "aff_campus_unique_index": "0;0;0;0;1",
        "aff_campus_unique": "Shanghai;New York",
        "aff_country_unique_index": "0;0;0;0;1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9340789",
        "title": "Automatic Gait Pattern Selection for Legged Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "An important issue when synthesizing legged locomotion plans is the combinatorial complexity that arises from gait pattern selection. Though it can be defined manually, the gait pattern plays an important role in the feasibility and optimality of a motion with respect to a task. Replacing human intuition with an automatic and efficient approach for gait pattern selection would allow for more autonomous robots, responsive to task and environment changes. To this end, we propose the idea of building a map from task to gait pattern selection for given environment and performance objective. Indeed, we show that for a 2D half-cheetah model and a quadruped robot, a direct mapping between a given task and an optimal gait pattern can be established. We use supervised learning to capture the structure of this map in a form of gait regions. Furthermore, we propose to construct a warm-starting trajectory for each gait region. We empirically show that these warm-starting trajectories improve the convergence speed of our trajectory optimization problem up to 60 times when compared with random initial guesses. Finally, we conduct experimental trials on the ANYmal robot to validate our method.",
        "primary_area": "",
        "author": "Jiayi Wang;Iordanis Chatzinikolaidis;Carlos Mastalli;Wouter Wolfslag;Guiyang Xin;Steve Tonneau;Sethu Vijayakumar;Jiayi Wang;Iordanis Chatzinikolaidis;Carlos Mastalli;Wouter Wolfslag;Guiyang Xin;Steve Tonneau;Sethu Vijayakumar",
        "authorids": "/37088686909;/37086266513;/37085537096;/37085495847;/37085531864;/37085790049;/37295595500;/37088686909;/37086266513;/37085537096;/37085495847;/37085531864;/37085790049;/37295595500",
        "aff": "School of Informatics, The University of Edinburgh, Edinburgh, United Kingdom; School of Informatics, The University of Edinburgh, Edinburgh, United Kingdom; Artificial Intelligence Programme, The Alan Turing Institute, London, United Kingdom; School of Informatics, The University of Edinburgh, Edinburgh, United Kingdom; School of Informatics, The University of Edinburgh, Edinburgh, United Kingdom; School of Informatics, The University of Edinburgh, Edinburgh, United Kingdom; Artificial Intelligence Programme, The Alan Turing Institute, London, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340789/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10893847280336335764&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;1;0;0;0;1",
        "aff_unique_norm": "The University of Edinburgh;The Alan Turing Institute",
        "aff_unique_dep": "School of Informatics;Artificial Intelligence Programme",
        "aff_unique_url": "https://www.ed.ac.uk;https://www.turing.ac.uk",
        "aff_unique_abbr": "Edinburgh;Turing",
        "aff_campus_unique_index": "0;0;1;0;0;0;1",
        "aff_campus_unique": "Edinburgh;London",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9341729",
        "title": "Automatic Lane Change Maneuver in Dynamic Environment Using Model Predictive Control Method",
        "track": "main",
        "status": "Poster",
        "abstract": "The lane change maneuver is one of the typical maneuvers in various driving situations. Therefore the automatic lane change function is one of the key functions for autonomous vehicles. Many researches have been conducted in this field. Most existing work focused on the solutions for the static environment and assume that the surrounding vehicles are running at constant speeds. However, in reality, if not all the vehicles on the road are fully autonomous, the situation could be much more complicated and the ego vehicle has to deal with the dynamic environment. This paper proposes a Model Predictive Control (MPC)-based method to achieve automatic lane change in a dynamic environment. A two-wheel dynamic bicycle model, which combines the longitudinal and lateral motion of the ego vehicle, together with a utility function, which helps to automatically determine the target lane have been used in the algorithm. The simulation results have demonstrated the capability of the proposed algorithm in a dynamic environment.",
        "primary_area": "",
        "author": "Zhaolun Li;Jingjing Jiang;Wen-Hua Chen;Zhaolun Li;Jingjing Jiang;Wen-Hua Chen",
        "authorids": "/37089855394;/37279090300;/37279192700;/37089855394;/37279090300;/37279192700",
        "aff": "Department of Aeronautical and Automotive Engineering, Loughborough University, Loughborough, United Kingdom; Department of Aeronautical and Automotive Engineering, Loughborough University, Loughborough, United Kingdom; Department of Aeronautical and Automotive Engineering, Loughborough University, Loughborough, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341729/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13133328247821448904&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Loughborough University",
        "aff_unique_dep": "Department of Aeronautical and Automotive Engineering",
        "aff_unique_url": "https://www.lboro.ac.uk",
        "aff_unique_abbr": "Lboro",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Loughborough",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9341666",
        "title": "Automatic Synthesis of Human Motion from Temporal Logic Specifications",
        "track": "main",
        "status": "Poster",
        "abstract": "Humans and robots are increasingly sharing their workspaces to benefit from the precision, endurance, and strength of machines and the universal capabilities of humans. Instead of performing time-consuming real experiments, computer simulations of humans could help to optimally orchestrate human and robotic tasks\u2014either for setting up new production cells or by optimizing the motion planning of already installed robots. Especially when human-robot coexistence is optimized using machine learning, being able to synthesize a huge number of human motions is indispensable. However, no solution exists that automatically creates a range of human motions from a high-level specification of tasks. We propose a novel method that automatically generates human motions from linear temporal logic specifications and demonstrate our approach by numerical examples.",
        "primary_area": "",
        "author": "Matthias Althoff;Matthias Mayer;Robert M\u00fcller;Matthias Althoff;Matthias Mayer;Robert M\u00fcller",
        "authorids": "/37541135900;/37089259681;/37088688518;/37541135900;/37089259681;/37088688518",
        "aff": "Fakult\u00e4t f\u00fcr Informatik, Lehrstuhl f\u00fcr Robotik und Echtzeitsysteme, Technische Universit\u00e4t M\u00fcnchen, Garching, Germany; Fakult\u00e4t f\u00fcr Informatik, Lehrstuhl f\u00fcr Robotik und Echtzeitsysteme, Technische Universit\u00e4t M\u00fcnchen, Garching, Germany; Fakult\u00e4t f\u00fcr Informatik, Lehrstuhl f\u00fcr Robotik und Echtzeitsysteme, Technische Universit\u00e4t M\u00fcnchen, Garching, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341666/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16327309130350009546&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Technische Universit\u00e4t M\u00fcnchen",
        "aff_unique_dep": "Lehrstuhl f\u00fcr Robotik und Echtzeitsysteme",
        "aff_unique_url": "https://www.tum.de",
        "aff_unique_abbr": "TUM",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Garching",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9340866",
        "title": "Automatic Targetless Extrinsic Calibration of Multiple 3D LiDARs and Radars",
        "track": "main",
        "status": "Poster",
        "abstract": "Many self-driving vehicles use a multi-sensor system comprising multiple 3D LiDAR and radar sensors for robust all-round perception. Precise calibration of this multi-sensor system is a critical prerequisite for accurate perception data which facilitates safe operation of self-driving vehicles in highly dynamic urban environments. This paper proposes the first-known automatic targetless method for extrinsic calibration of multiple 3D LiDAR and radar sensors, and which only requires the vehicle to be driven over a short distance. The proposed method first estimates the 6-DoF pose of each LiDAR sensor with respect to the vehicle reference frame by minimizing point-to-plane distances between scans from different LiDAR sensors. In turn, a 3D map of the environment is built using data from all calibrated LiDAR sensors on the vehicle. We find the 6-DoF pose of each radar sensor with respect to the vehicle reference frame by minimizing (1) point-to-plane distances between radar scans and the 3D map, and (2) radial velocity errors. Our proposed calibration method does not require overlapping fields of view between LiDAR and radar sensors. Real-world experiments demonstrate the accuracy and repeatability of the proposed calibration method.",
        "primary_area": "",
        "author": "Lionel Heng;Lionel Heng",
        "authorids": "/37968251100;/37968251100",
        "aff": "Robotics Autonomy Lab, Robotics Division, DSO National Laboratories, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340866/",
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3941051416399799215&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 2,
        "aff_unique_index": "0",
        "aff_unique_norm": "DSO National Laboratories",
        "aff_unique_dep": "Robotics Division",
        "aff_unique_url": "https://www.dso.org.sg",
        "aff_unique_abbr": "DSO",
        "aff_country_unique_index": "0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "9340997",
        "title": "Autonomous Detection and Assessment with Moving Sensors",
        "track": "main",
        "status": "Poster",
        "abstract": "Current approaches to physical security suffer from high false alarm rates and frequent human operator involvement, despite the relative rarity of real-world threats. We present a novel architecture for autonomous adaptive physical security called autonomous detection and assessment with moving sensors (ADAMS). ADAMS is a framework for reducing nuisance and false alarms by placing mobile robotic platforms equipped with sensors outside the normal asset perimeter. These robotic agents integrate sensor data from multiple perspectives over time, and autonomously move to obtain the best new data to reduce uncertainty in the threat scene. Inferences drawn from data fused over time provide ultimate decisions regarding whether to alert human operators. This paper describes the framework and algorithms used in a prototype ADAMS implementation. We describe the results of simulations comparing this framework to alternate paradigms. These simulations show ADAMS has a 4x increase in the range at which threats are identified versus traditional static sensors, and a 5x reduction in false alarms triggered versus frameworks where all sensor detections become alarms, leading to reduced operator load. Further, these simulations show this framework for reacting to new potential threats significantly outperforms methods which merely patrol the site. We also present the results of preliminary hardware trials of an exemplar prototype system, providing limited validation of the simulations in a real-time physical demonstration.",
        "primary_area": "",
        "author": "Steven J. Spencer;Anup Parikh;Daniel R. McArthur;Carol C. Young;Timothy J. Blada;Jonathon E. Slightam;Stephen P. Buerger;Steven J. Spencer;Anup Parikh;Daniel R. McArthur;Carol C. Young;Timothy J. Blada;Jonathon E. Slightam;Stephen P. Buerger",
        "authorids": "/37979247100;/37085389823;/37086097573;/37089195738;/37085482394;/37086431338;/37294845300;/37979247100;/37085389823;/37086097573;/37089195738;/37085482394;/37086431338;/37294845300",
        "aff": "Robotics and Counter Robotics Research and Development group, Sandia National Laboratories, Albuquerque, NM, USA; Robotics and Counter Robotics Research and Development group, Sandia National Laboratories, Albuquerque, NM, USA; Robotics and Counter Robotics Research and Development group, Sandia National Laboratories, Albuquerque, NM, USA; Robotics and Counter Robotics Research and Development group, Sandia National Laboratories, Albuquerque, NM, USA; Robotics and Counter Robotics Research and Development group, Sandia National Laboratories, Albuquerque, NM, USA; Robotics and Counter Robotics Research and Development group, Sandia National Laboratories, Albuquerque, NM, USA; Robotics and Counter Robotics Research and Development group, Sandia National Laboratories, Albuquerque, NM, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340997/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15764381278037726902&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Sandia National Laboratories",
        "aff_unique_dep": "Robotics and Counter Robotics Research and Development group",
        "aff_unique_url": "https://www.sandia.gov",
        "aff_unique_abbr": "SNL",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Albuquerque",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341657",
        "title": "Autonomous Exploration Under Uncertainty via Deep Reinforcement Learning on Graphs",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider an autonomous exploration problem in which a range-sensing mobile robot is tasked with accurately mapping the landmarks in an a priori unknown environment efficiently in real-time; it must choose sensing actions that both curb localization uncertainty and achieve information gain. For this problem, belief space planning methods that forward- simulate robot sensing and estimation may often fail in real-time implementation, scaling poorly with increasing size of the state, belief and action spaces. We propose a novel approach that uses graph neural networks (GNNs) in conjunction with deep reinforcement learning (DRL), enabling decision-making over graphs containing exploration information to predict a robot's optimal sensing action in belief space. The policy, which is trained in different random environments without human intervention, offers a real-time, scalable decision-making process whose high-performance exploratory sensing actions yield accurate maps and high rates of information gain.",
        "primary_area": "",
        "author": "Fanfei Chen;John D. Martin;Yewei Huang;Jinkun Wang;Brendan Englot;Fanfei Chen;John D. Martin;Yewei Huang;Jinkun Wang;Brendan Englot",
        "authorids": "/37086209616;/37088688605;/37086487764;/37085734204;/37601539900;/37086209616;/37088688605;/37086487764;/37085734204;/37601539900",
        "aff": "Department of Mechanical Engineering, Stevens Institute of Technology, Hoboken, NJ; Department of Mechanical Engineering, Stevens Institute of Technology, Hoboken, NJ; Department of Mechanical Engineering, Stevens Institute of Technology, Hoboken, NJ; Department of Mechanical Engineering, Stevens Institute of Technology, Hoboken, NJ; Department of Mechanical Engineering, Stevens Institute of Technology, Hoboken, NJ",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341657/",
        "gs_citation": 86,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16724915335506695434&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Stevens Institute of Technology",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.stevens.edu",
        "aff_unique_abbr": "SIT",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Hoboken",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341298",
        "title": "Autonomous Multi-Robot Assembly of Solar Array Modules: Experimental Analysis and Insights",
        "track": "main",
        "status": "Poster",
        "abstract": "To allow for the construction of large space structures to support future space endeavors, autonomous robotic solutions would serve to reduce cost and risk of human extravehicular activity (EVA). Practicality of autonomous assembly requires both theoretical and algorithmic advances, and hardware experimentation across a spectrum of technological readiness levels. Analysis of hardware experiments provides novel insights not readily apparent in simulations alone, which serves to inform future developments.This paper describes analysis and insights gained from an autonomous assembly experiment consisting of a dexterous manipulator, a gross positioning serial arm, and a 1 degree of freedom (DOF) turntable to facilitate the assembly and deployment of a solar array mockup. This experiment combined state estimation in an uncertain environment with contact-heavy operations such as grasping, self-reconfiguring, joining, and deploying. Insights gained are presented due to their applicability to other field-based manipulation tasks by a team of robots.",
        "primary_area": "",
        "author": "Holly Everson;Joshua Moser;Amy Quartaro;Samantha Glassner;Erik Komendera;Holly Everson;Joshua Moser;Amy Quartaro;Samantha Glassner;Erik Komendera",
        "authorids": "/37088691169;/37088686474;/37086332266;/37060967900;/37071755500;/37088691169;/37088686474;/37086332266;/37060967900;/37071755500",
        "aff": "Field and Space Experimental Robotics (FASER) Laboratory, Virginia Tech, Blacksburg, VA; FASER Laboratory, Virginia Tech, Blacksburg, VA; FASER Laboratory, Tech, Blacksburg, VA; FASER Laboratory, Tech, Blacksburg, VA; Mechanical Engineering and Director of the FASER Laboratory, Virginia Polytechnic Institute and State University, Blacksburg, VA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341298/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9595181556234169729&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;1;1",
        "aff_unique_norm": "Virginia Tech;Virginia Polytechnic Institute and State University",
        "aff_unique_dep": "Field and Space Experimental Robotics (FASER) Laboratory;FASER Laboratory",
        "aff_unique_url": "https://www.vt.edu;https://www.vt.edu",
        "aff_unique_abbr": "VT;VT",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Blacksburg",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341256",
        "title": "Autonomous Navigation and Obstacle Avoidance of a Snake Robot with Combined Velocity-Heading Control",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents combined velocity-heading control of a planar snake robot for the autonomous navigation and obstacle avoidance in a simulation environment. The kinematics and dynamics of the snake robot were derived using the articulated-body algorithm without considering the non-holonomic constraints. A double-layer controller was designed to control both heading direction and average velocity through joint motion control. We adopted a rule-based expert system for autonomous navigation while avoiding obstacles/restricted-areas. The guidance commands were realized by two proportional controllers that use feedback of the estimated speed and heading of the robot. To validate the combined velocity-heading controller, a series of simulations were carried out for a snake robot with 6 links (8 DOF). The autonomous navigation and obstacle-avoidance algorithms provided the commands to follow the desired trajectories. The simulation results showed the effectiveness of the controller in following the desired heading directions and achieving targeted velocities with small errors to reach the goal position by avoiding obstacles.",
        "primary_area": "",
        "author": "Mahdi Haghshenas-Jaryani;Hakki Erhan Sevil;Mahdi Haghshenas-Jaryani;Hakki Erhan Sevil",
        "authorids": "/38275372500;/38073914300;/38275372500;/38073914300",
        "aff": "Department of Mechanical and Aerospace Engineering, New Mexico State University, Las Cruces, NM, USA; Department of Intelligent Systems & Robotics, University of West Florida, Pensacola, FL, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341256/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5851644677545013857&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "New Mexico State University;University of West Florida",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering;Department of Intelligent Systems & Robotics",
        "aff_unique_url": "https://www.nmsu.edu;https://www.uwf.edu",
        "aff_unique_abbr": "NMSU;UWF",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Las Cruces;Pensacola",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341494",
        "title": "Autonomous Navigation in Complex Environments with Deep Multimodal Fusion Network",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous navigation in complex environments is a crucial task in time-sensitive scenarios such as disaster response or search and rescue. However, complex environments pose significant challenges for autonomous platforms to navigate due to their challenging properties: constrained narrow passages, unstable pathway with debris and obstacles, or irregular geological structures and poor lighting conditions. In this work, we propose a multimodal fusion approach to address the problem of autonomous navigation in complex environments such as collapsed cites, or natural caves. We first simulate the complex environments in a physics-based simulation engine and collect a large-scale dataset for training. We then propose a Navigation Multimodal Fusion Network (NMFNet) which has three branches to effectively handle three visual modalities: laser, RGB images, and point cloud data. The extensively experimental results show that our NMFNet outperforms recent state of the art by a fair margin while achieving real-time performance. We further show that the use of multiple modalities is essential for autonomous navigation in complex environments. Finally, we successfully deploy our network to both simulated and real mobile robots.",
        "primary_area": "",
        "author": "Anh Nguyen;Ngoc Nguyen;Kim Tran;Erman Tjiputra;Quang D. Tran;Anh Nguyen;Ngoc Nguyen;Kim Tran;Erman Tjiputra;Quang D. Tran",
        "authorids": "/37086209468;/37088688676;/37088690691;/37088219840;/37088218362;/37086209468;/37088688676;/37088690691;/37088219840;/37088218362",
        "aff": "Department of Computing, Imperial College, London, UK; AIOZ Pte Ltd, Singapore; AIOZ Pte Ltd, Singapore; AIOZ Pte Ltd, Singapore; AIOZ Pte Ltd, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341494/",
        "gs_citation": 52,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3477521885134244573&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;1",
        "aff_unique_norm": "Imperial College London;AIOZ Pte Ltd",
        "aff_unique_dep": "Department of Computing;",
        "aff_unique_url": "https://www.imperial.ac.uk;",
        "aff_unique_abbr": "Imperial;",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "London;",
        "aff_country_unique_index": "0;1;1;1;1",
        "aff_country_unique": "United Kingdom;Singapore"
    },
    {
        "id": "9341234",
        "title": "Autonomous Navigation over Europa Analogue Terrain for an Actively Articulated Wheel-on-Limb Rover",
        "track": "main",
        "status": "Poster",
        "abstract": "The ocean world Europa is a prime target for exploration given its potential habitability [1]. We propose a mobile robotic system that is capable of autonomously traversing tens of meters to visit multiple sites of interest on a Europan analogue surface. Due to the topology of Europan terrain being largely unknown, it is desired that this mobility system traverse a large variety of terrain types. The mobility system should also be capable of crossing unstructured terrain in an autonomous manner given the communications limitations between Earth and Europa.A wheel-on-limb robotic rover is presented that may actively conform to terrain features up to 1.5 wheel diameters tall while driving. The robot uses a sampling-based motion planner to generate paths that leverage its unique locomotive capabilities. The planner assesses terrain hazards and wheel workspace limits as obstacles. It may also select a mobility mode based on predicted energy usage and the need for limb articulation on the terrain being traversed. This autonomous mobility was evaluated on chaotic salt-evaporite terrain found in Death Valley, CA, an analogue to the Europan surface. Over the course of 38 trials, the rover autonomously traversed 435m of extreme terrain while maintaining a rate of 0.64 traverse ending failures for every 10m driven.",
        "primary_area": "",
        "author": "William Reid;Michael Paton;Sisir Karumanchi;Brendan Chamberlain-Simon;Blair Emanuel;Gareth Meirion-Griffith;William Reid;Michael Paton;Sisir Karumanchi;Brendan Chamberlain-Simon;Blair Emanuel;Gareth Meirion-Griffith",
        "authorids": "/37085773969;/38252759300;/38251608900;/37085788952;/37087177346;/38274856700;/37085773969;/38252759300;/38251608900;/37085788952;/37087177346;/38274856700",
        "aff": "Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341234/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10435982456195190587&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "California Institute of Technology",
        "aff_unique_dep": "Jet Propulsion Laboratory",
        "aff_unique_url": "https://www.caltech.edu",
        "aff_unique_abbr": "Caltech",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Pasadena",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341432",
        "title": "Autonomous Obstacle Avoidance for UAV based on Fusion of Radar and Monocular Camera",
        "track": "main",
        "status": "Poster",
        "abstract": "UAVs face many challenges in autonomous obstacle avoidance in large outdoor scenarios, specifically the long communication distance from ground stations. The computing power of onboard computers is limited, and the unknown obstacles cannot be accurately detected. In this paper, an autonomous obstacle avoidance scheme based on the fusion of millimeter wave radar and monocular camera is proposed. The visual detection is designed to detect unknown obstacles which is more robust than traditional algorithms. Then extended Kalman filter (EKF) data fusion is used to build exact real 3D coordinates of the obstacles. Finally, an efficient path planning algorithm is used to obtain the path to avoid obstacles. Based on the theoretical design, an experimental platform is built to verify the UAV autonomous obstacle avoidance scheme proposed in this paper. The experiment results show the proposed scheme cannot only detect different kinds of unknown obstacles, but can also take up very little computing resources to run on an onboard computer. The outdoor flight experiment shows the feasibility of the proposed scheme.",
        "primary_area": "",
        "author": "Hang Yu;Fan Zhang;Panfeng Huang;Chen Wang;Li Yuanhao;Hang Yu;Fan Zhang;Panfeng Huang;Chen Wang;Li Yuanhao",
        "authorids": "/37088687816;/37085568879;/37293059500;/37088349103;/37089435654;/37088687816;/37085568879;/37293059500;/37088349103;/37089435654",
        "aff": "National Key Laboratory of Aerospace Flight Dynamics, Research Center for Intelligent Robotics, School of Astronautics, Northwestern Polytechnical University, Xi\u2019an, China; National Key Laboratory of Aerospace Flight Dynamics, Research Center for Intelligent Robotics, School of Astronautics, Northwestern Polytechnical University, Xi\u2019an, China; National Key Laboratory of Aerospace Flight Dynamics, Research Center for Intelligent Robotics, School of Astronautics, Northwestern Polytechnical University, Xi\u2019an, China; Key Laboratory for Highway Construction Technology and Equipment of Ministry of Education, Chang\u2019an University, Xi\u2019an, China; National Key Laboratory of Aerospace Flight Dynamics, Research Center for Intelligent Robotics, School of Astronautics, Northwestern Polytechnical University, Xi\u2019an, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341432/",
        "gs_citation": 45,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16307212187493799176&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Northwestern Polytechnical University;Chang\u2019an University",
        "aff_unique_dep": "School of Astronautics;Key Laboratory for Highway Construction Technology and Equipment of Ministry of Education",
        "aff_unique_url": "http://www.nwpu.edu.cn;",
        "aff_unique_abbr": "NPU;",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Xi'an",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9341622",
        "title": "Autonomous Planning for Multiple Aerial Cinematographers",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a planning algorithm for autonomous media production with multiple Unmanned Aerial Vehicles (UAVs) in outdoor events. Given filming tasks specified by a media Director, we formulate an optimization problem to maximize the filming time considering battery constraints. As we conjecture that the problem is NP-hard, we consider a discretization version, and propose a graph-based algorithm that can find an optimal solution of the discrete problem for a single UAV in polynomial time. Then, a greedy strategy is applied to solve the problem sequentially for multiple UAVs. We demonstrate that our algorithm is efficient for small teams (3-5 UAVs) and that its performance is close to the optimum. We showcase our system in field experiments carrying out actual media production in an outdoor scenario with multiple UAVs.",
        "primary_area": "",
        "author": "Luis-Evaristo Caraballo;\u00c1ngel Montes-Romero;Jos\u00e9-Miguel D\u00edaz-B\u00e1\u00f1ez;Jes\u00fas Capit\u00e1n;Arturo Torres-Gonz\u00e1lez;An\u00edbal Ollero;Luis-Evaristo Caraballo;\u00c1ngel Montes-Romero;Jos\u00e9-Miguel D\u00edaz-B\u00e1\u00f1ez;Jes\u00fas Capit\u00e1n;Arturo Torres-Gonz\u00e1lez;An\u00edbal Ollero",
        "authorids": "/37086187337;/37088691431;/37085544890;/37392123200;/37085481740;/37265412000;/37086187337;/37088691431;/37085544890;/37392123200;/37085481740;/37265412000",
        "aff": "Department of Applied Mathematics II, University of Seville, Seville, Spain; GRVC Robotics Lab, University of Seville, Seville, Spain; Department of Applied Mathematics II, University of Seville, Seville, Spain; GRVC Robotics Lab, University of Seville, Seville, Spain; GRVC Robotics Lab, University of Seville, Seville, Spain; GRVC Robotics Lab, University of Seville, Seville, Spain",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341622/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5915828210823784763&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of Seville",
        "aff_unique_dep": "Department of Applied Mathematics II",
        "aff_unique_url": "https://www.us.seville.es",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Seville",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Spain"
    },
    {
        "id": "9340941",
        "title": "Autonomous RGBD-based Industrial Staircase Localization from Tracked Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents an industrial staircase localization algorithm based on RGBD data from a tracked robot. This situation is really challenging as the camera is placed close to the ground. Moreover, RGBD can be really noisy on sparse staircases. Contrary to existing works, our evaluation relies on ground truth data provided by a motion capture system. Our experiments suggest that our algorithm can robustly locate industrial staircase. We also propose a new framework to evaluate stair localization performance from RGBD data. The overall performance allows to safety control a robot to rally the staircase.",
        "primary_area": "",
        "author": "J\u00e9r\u00e9my FOURRE;Vincent VAUCHEY;Yohan DUPUIS;Xavier SAVATIER;J\u00e9r\u00e9my FOURRE;Vincent VAUCHEY;Yohan DUPUIS;Xavier SAVATIER",
        "authorids": "/37088690712;/37086698197;/37586291800;/37293923700;/37088690712;/37086698197;/37586291800;/37293923700",
        "aff": "Normandie Univ, UNIROUEN, ESIGELEC, IRSEEM, Rouen, France; Normandie Univ, UNIROUEN, ESIGELEC, IRSEEM, Rouen, France; Normandie Univ, UNIROUEN, ESIGELEC, IRSEEM, Rouen, France; Normandie Univ, UNIROUEN, ESIGELEC, IRSEEM, Rouen, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340941/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11649873164166449793&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Normandie University",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "Normandie Univ",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Rouen",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9341304",
        "title": "Autonomous Robot Navigation Based on Multi-Camera Perception",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose an autonomous method for robot navigation based on a multi-camera setup that takes advantage of a wide field of view. A new multi-task network is designed for handling the visual information supplied by the left, central and right cameras to find the passable area, detect the intersection and infer the steering. Based on the outputs of the network, three navigation indicators are generated and then combined with the high-level control commands extracted by the proposed MapNet, which are finally fed into the driving controller. The indicators are also used through the controller for adjusting the driving velocity, which assists the robot to adjust the speed for smoothly bypassing obstacles. Experiments in real-world environments demonstrate that our method performs well in both local obstacle avoidance and global goal-directed navigation tasks.",
        "primary_area": "",
        "author": "Kunyan Zhu;Wei Chen;Wei Zhang;Ran Song;Yibin Li;Kunyan Zhu;Wei Chen;Wei Zhang;Ran Song;Yibin Li",
        "authorids": "/37088686633;/37086331006;/37085379581;/37546859100;/37279897500;/37088686633;/37086331006;/37085379581;/37546859100;/37279897500",
        "aff": "School of Control Science and Engineering, Shandong University, Jinan, China; School of Control Science and Engineering, Shandong University, Jinan, China; School of Control Science and Engineering, Shandong University, Jinan, China; School of Control Science and Engineering, Shandong University, Jinan, China; School of Control Science and Engineering, Shandong University, Jinan, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341304/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12177368279472044347&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Shandong University",
        "aff_unique_dep": "School of Control Science and Engineering",
        "aff_unique_url": "http://www.sdu.edu.cn",
        "aff_unique_abbr": "SDU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Jinan",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9341361",
        "title": "Autonomous Spot: Long-Range Autonomous Exploration of Extreme Environments with Legged Locomotion",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper serves as one of the first efforts to enable large-scale and long-duration autonomy using the Boston Dynamics Spot robot. Motivated by exploring extreme environments, particularly those involved in the DARPA Subterranean Challenge, this paper pushes the boundaries of the state-of-practice in enabling legged robotic systems to accomplish real-world complex missions in relevant scenarios. In particular, we discuss the behaviors and capabilities which emerge from the integration of the autonomy architecture NeBula (Networked Belief-aware Perceptual Autonomy) with next-generation mobility systems. We will discuss the hardware and software challenges, and solutions in mobility, perception, autonomy, and very briefly, wireless networking, as well as lessons learned and future directions. We demonstrate the performance of the proposed solutions on physical systems in real-world scenarios.3 The proposed solution contributed to winning 1st-place in the 2020 DARPA Subterranean Challenge, Urban Circuit.4",
        "primary_area": "",
        "author": "Amanda Bouman;Muhammad Fadhil Ginting;Nikhilesh Alatur;Matteo Palieri;David D. Fan;Thomas Touma;Torkom Pailevanian;Sung-Kyun Kim;Kyohei Otsu;Joel Burdick;Ali-akbar Agha-Mohammadi;Amanda Bouman;Muhammad Fadhil Ginting;Nikhilesh Alatur;Matteo Palieri;David D. Fan;Thomas Touma;Torkom Pailevanian;Sung-Kyun Kim;Kyohei Otsu;Joel Burdick;Ali-akbar Agha-Mohammadi",
        "authorids": "/37087322528;/37086345435;/37088507022;/37088506663;/37086010932;/37088472679;/37086540727;/37598024600;/37085558541;/37265975700;/38274170800;/37087322528;/37086345435;/37088507022;/37088506663;/37086010932;/37088472679;/37086540727;/37598024600;/37085558541;/37265975700;/38274170800",
        "aff": "Department of Mechanical and Civil Engineering, Division of Engineering and Applied Science, California Institute of Technology, Pasadena, CA, USA; NASA Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, USA; Department of Mechanical and Civil Engineering, Division of Engineering and Applied Science, California Institute of Technology, Pasadena, CA, USA; NASA Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, USA; NASA Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, USA; Department of Mechanical and Civil Engineering, Division of Engineering and Applied Science, California Institute of Technology, Pasadena, CA, USA; NASA Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, USA; NASA Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, USA; NASA Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, USA; Department of Mechanical and Civil Engineering, Division of Engineering and Applied Science, California Institute of Technology, Pasadena, CA, USA; NASA Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341361/",
        "gs_citation": 198,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5530732713764609045&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 22,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "California Institute of Technology",
        "aff_unique_dep": "Department of Mechanical and Civil Engineering",
        "aff_unique_url": "https://www.caltech.edu",
        "aff_unique_abbr": "Caltech",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Pasadena",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340902",
        "title": "Autonomous Vehicle Benchmarking using Unbiased Metrics",
        "track": "main",
        "status": "Poster",
        "abstract": "With the recent development of autonomous vehicle technology, there have been active efforts on the deployment of this technology at different scales that include urban and highway driving. While many of the prototypes showcased have been shown to operate under specific cases, little effort has been made to better understand their shortcomings and generalizability to new areas. Distance, uptime and number of manual disengagements performed during autonomous driving provide a high-level idea on the performance of an autonomous system but without proper data normalization, testing location information, and the number of vehicles involved in testing, the disengagement reports alone do not fully encompass system performance and robustness. Thus, in this study a complete set of metrics are applied for benchmarking autonomous vehicle systems in a variety of scenarios that can be extended for comparison with human drivers and other autonomous vehicle systems. These metrics have been used to benchmark UC San Diego's autonomous vehicle platforms during early deployments for micro-transit and autonomous mail delivery applications.",
        "primary_area": "",
        "author": "David Paz;Po-jung Lai;Nathan Chan;Yuqing Jiang;Henrik I. Christensen;David Paz;Po-jung Lai;Nathan Chan;Yuqing Jiang;Henrik I. Christensen",
        "authorids": "/37088688508;/37088691009;/37088686213;/37088689366;/37281307400;/37088688508;/37088691009;/37088686213;/37088689366;/37281307400",
        "aff": "Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, CA; Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, CA; Department of Computer Science and Engineering, University of California, San Diego, La Jolla, CA; Department of Computer Science and Engineering, University of California, San Diego, La Jolla, CA; Department of Computer Science and Engineering, University of California, San Diego, La Jolla, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340902/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5848893387126459660&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;1;1",
        "aff_unique_norm": "University of California San Diego;University of California, San Diego",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.ucsd.edu;https://www.ucsd.edu",
        "aff_unique_abbr": "UCSD;UCSD",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "La Jolla",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341232",
        "title": "Autonomous model-based assessment of mechanical failures of reconfigurable modular robots with a Conjugate Gradient solver",
        "track": "main",
        "status": "Poster",
        "abstract": "Large-scale 3D autonomous self-reconfigurable modular robots are made of numerous interconnected robotic modules that operate in a close packing. The modules are assumed to have their own CPU and memory, and are only able to communicate with their direct neighbors. As such, the robots embody a special computing architecture: a distributed memory and distributed CPU system with a local message-passing interface. The modules can move and rearrange themselves changing the robot's connection topology. This may potentially cause mechanical failures (e.g., overloading of some inter-modular connections), which are irreversible and need to be detected in advance. In the present contribution, we further develop the idea of performing model-based detection of mechanical failures, posed in the form of balance equations solved by the modular robot itself in a distributed manner. A special implementation of the Conjugate Gradient iterative solution method is proposed and shown to greatly reduce the required number of iterations compared with the weighted Jacobi method used previously. The algorithm is verified in a virtual test bed-the VisibleSim emulator of the modular robot. The assessments of time-, CPU-, communication- and memory complexities of the proposed scheme are provided.",
        "primary_area": "",
        "author": "Pawe\u0142 Ho\u0142obut;St\u00e9phane P. A. Bordas;Jakub Lengiewicz;Pawe\u0142 Ho\u0142obut;St\u00e9phane P. A. Bordas;Jakub Lengiewicz",
        "authorids": "/37085341485;/37643704500;/37085352578;/37085341485;/37643704500;/37085352578",
        "aff": "Institute of Fundamental Technological Research, Polish Academy of Sciences, Poland; Department of Engineering, Faculty of Science, Technology and Medicine, University of Luxembourg, Luxembourg; Department of Engineering, Faculty of Science, Technology and Medicine, University of Luxembourg, Luxembourg",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341232/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5077673408499084696&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Institute of Fundamental Technological Research;University of Luxembourg",
        "aff_unique_dep": "Polish Academy of Sciences;Department of Engineering",
        "aff_unique_url": ";https://wwwen.unil.lu",
        "aff_unique_abbr": ";UniLu",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "Poland;Luxembourg"
    },
    {
        "id": "9341382",
        "title": "Autonomous task planning and situation awareness in robotic surgery",
        "track": "main",
        "status": "Poster",
        "abstract": "The use of robots in minimally invasive surgery has improved the quality of standard surgical procedures. So far, only the automation of simple surgical actions has been investigated by researchers, while the execution of structured tasks requiring reasoning on the environment and the choice among multiple actions is still managed by human surgeons. In this paper, we propose a framework to implement surgical task automation. The framework consists of a task-level reasoning module based on answer set programming, a low-level motion planning module based on dynamic movement primitives, and a situation awareness module. The logic-based reasoning module generates explainable plans and is able to recover from failure conditions, which are identified and explained by the situation awareness module interfacing to a human supervisor, for enhanced safety. Dynamic Movement Primitives allow to replicate the dexterity of surgeons and to adapt to obstacles and changes in the environment. The framework is validated on different versions of the standard surgical training peg-and-ring task.",
        "primary_area": "",
        "author": "Michele Ginesi;Daniele Meli;Andrea Roberti;Nicola Sansonetto;Paolo Fiorini;Michele Ginesi;Daniele Meli;Andrea Roberti;Nicola Sansonetto;Paolo Fiorini",
        "authorids": "/37087469596;/37087465814;/37086566937;/37087465920;/37279139000;/37087469596;/37087465814;/37086566937;/37087465920;/37279139000",
        "aff": "Department of Computer Science, University of Verona, Verona, Italy; Department of Computer Science, University of Verona, Verona, Italy; Department of Computer Science, University of Verona, Verona, Italy; Department of Computer Science, University of Verona, Verona, Italy; Department of Computer Science, University of Verona, Verona, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341382/",
        "gs_citation": 55,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7155246913707219436&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Verona",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.univr.it",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Verona",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9341768",
        "title": "B-spline Surfaces for Range-Based Environment Mapping",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a mapping technique that builds a continuous representation of the environment from range data. The strategy presented here encodes the probability of points in space to be occupied using 2.5D B-spline surfaces. For a fast update rate, the surface is recursively updated as new measurements arrive. The proposed B-spline map is less susceptible to precision and interpolation errors that are present in occupancy grid-based methods. From simulation and experimental results, we show that this approach leverages the floating point resolution of continuous metric maps and the fast update/access/merging advantages of discrete metric maps. Thus, the proposed method is suitable for online robotic tasks such as localization and path planning, requiring minor modification to existing software that usually operates on metric maps.",
        "primary_area": "",
        "author": "R\u00f4mulo T. Rodrigues;Nikolaos Tsiogkas;A. Pedro Aguiar;Ant\u00f3nio Pascoal;R\u00f4mulo T. Rodrigues;Nikolaos Tsiogkas;A. Pedro Aguiar;Ant\u00f3nio Pascoal",
        "authorids": "/37085349500;/37085584313;/37427058500;/37284324100;/37085349500;/37085584313;/37427058500;/37284324100",
        "aff": "Faculty of Electrical Engineering, University of Porto, Porto, Portugal; Core Lab ROB, FlandersMake@KULeuven, Leuven, Belgium; Faculty of Electrical Engineering, University of Porto, Porto, Portugal; Laboratory of Robotics and Engineering Systems (LARSyS), ISR/IST, University of Lisbon, Lisbon, Portugal",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341768/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4337824574691073749&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;2",
        "aff_unique_norm": "University of Porto;KU Leuven;University of Lisbon",
        "aff_unique_dep": "Faculty of Electrical Engineering;Core Lab ROB;Laboratory of Robotics and Engineering Systems (LARSyS)",
        "aff_unique_url": "https://www.fe.up.pt;https://www.kuleuven.be;https://www.ulusiada.pt",
        "aff_unique_abbr": "UPorto;KUL;ULisbon",
        "aff_campus_unique_index": "0;1;0;2",
        "aff_campus_unique": "Porto;Leuven;Lisbon",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "Portugal;Belgium"
    },
    {
        "id": "9341222",
        "title": "BARK: Open Behavior Benchmarking in Multi-Agent Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Predicting and planning interactive behaviors in complex traffic situations presents a challenging task. Especially in scenarios involving multiple traffic participants that interact densely, autonomous vehicles still struggle to interpret situations and to eventually achieve their own mission goal. As driving tests are costly and challenging scenarios are hard to find and reproduce, simulation is widely used to develop, test, and benchmark behavior models. However, most simulations rely on datasets and simplistic behavior models for traffic participants and do not cover the full variety of real-world, interactive human behaviors. In this work, we introduce BARK, an open-source behavior benchmarking environment designed to mitigate the shortcomings stated above. In BARK, behavior models are (re-)used for planning, prediction, and simulation. A range of models is currently available, such as MonteCarlo Tree Search and Reinforcement Learning-based behavior models. We use a public dataset and sampling-based scenario generation to show the inter-exchangeability of behavior models in BARK. We evaluate how well the models used cope with interactions and how robust they are towards exchanging behavior models. Our evaluation shows that BARK provides a suitable framework for a systematic development of behavior models.",
        "primary_area": "",
        "author": "Julian Bernhard;Klemens Esterle;Patrick Hart;Tobias Kessler;Julian Bernhard;Klemens Esterle;Patrick Hart;Tobias Kessler",
        "authorids": "/37086547457;/37086546990;/37086486894;/37085608419;/37086547457;/37086546990;/37086486894;/37085608419",
        "aff": "fortiss GmbH, Research Institute of the Free State of Bavaria, Munich, Germany; fortiss GmbH, Research Institute of the Free State of Bavaria, Munich, Germany; fortiss GmbH, Research Institute of the Free State of Bavaria, Munich, Germany; fortiss GmbH, Research Institute of the Free State of Bavaria, Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341222/",
        "gs_citation": 58,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5070530627722765750&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "fortiss GmbH",
        "aff_unique_dep": "Research Institute of the Free State of Bavaria",
        "aff_unique_url": "https://www.fortiss.de",
        "aff_unique_abbr": "fortiss",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Munich",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9341151",
        "title": "BIT-VO: Visual Odometry at 300 FPS using Binary Features from the Focal Plane",
        "track": "main",
        "status": "Poster",
        "abstract": "Focal-plane Sensor-processor (FPSP) is a next-generation camera technology which enables every pixel on the sensor chip to perform computation in parallel, on the focal plane where the light intensity is captured. SCAMP-5 is a general-purpose FPSP used in this work and it carries out computations in the analog domain before analog to digital conversion. By extracting features from the image on the focal plane, data which is digitised and transferred is reduced. As a consequence, SCAMP-5 offers a high frame rate while maintaining low energy consumption. Here, we present BITVO, which is the first 6-Degrees of Freedom visual odometry algorithm which utilises the FPSP. Our entire system operates at 300 FPS in a natural environment, using binary edges and corner features detected by the SCAMP-5.",
        "primary_area": "",
        "author": "Riku Murai;Sajad Saeedi;Paul H. J. Kelly;Riku Murai;Sajad Saeedi;Paul H. J. Kelly",
        "authorids": "/37088690569;/38192904000;/37300638200;/37088690569;/38192904000;/37300638200",
        "aff": "Department of Computing, Imperial College London; Ryerson University; Department of Computing, Imperial College London",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341151/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18016184910857245797&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Imperial College London;Ryerson University",
        "aff_unique_dep": "Department of Computing;",
        "aff_unique_url": "https://www.imperial.ac.uk;https://www.ryerson.ca",
        "aff_unique_abbr": "Imperial;Ryerson",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "London;",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "United Kingdom;Canada"
    },
    {
        "id": "9341682",
        "title": "BRM Localization: UAV Localization in GNSS-Denied Environments Based on Matching of Numerical Map and UAV Images",
        "track": "main",
        "status": "Poster",
        "abstract": "Localization is one of the most important technologies needed to use Unmanned Aerial Vehicles (UAVs) in actual fields. Currently, most UAVs use GNSS to estimate their position. Recently, there have been attacks that target the weaknesses of UAVs that use GNSS, such as interrupting GNSS signal to crash the UAVs or sending fake GNSS signals to hijack the UAVs. To avoid this kind of situation, this paper proposes an algorithm that deals with the localization problem of the UAV in GNSS-denied environments. We propose a localization method, named as BRM (Building Ratio Map based) localization, for a UAV by matching an existing numerical map with UAV images. The building area is extracted from the UAV images. The ratio of buildings that occupy in the corresponding image frame is calculated and matched with the building information on the numerical map. The position estimation is started in the range of several km2 area, so that the position estimation can be performed without knowing the exact initial coordinate. Only freely available maps are used for training data set and matching the ground truth. Finally, we get real UAV images, IMU data, and GNSS data from UAV flight to show that the proposed method can achieve better performance than the conventional methods.",
        "primary_area": "",
        "author": "Junho Choi;Hyun Myung;Junho Choi;Hyun Myung",
        "authorids": "/37088691491;/37424926900;/37088691491;/37424926900",
        "aff": "Urban Robotics Laboratory, Korea Advanced Institute of Science and Technology(KAIST), Daejeon, South Korea; School of Electrical Engineering, KI-AI, and KI-R at KAIST",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341682/",
        "gs_citation": 49,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18005187210105403271&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology;KAIST",
        "aff_unique_dep": "Urban Robotics Laboratory;School of Electrical Engineering, KI-AI, and KI-R",
        "aff_unique_url": "https://www.kaist.ac.kr;https://www.kaist.ac.kr",
        "aff_unique_abbr": "KAIST;KAIST",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Daejeon;",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9341769",
        "title": "Balanced Depth Completion between Dense Depth Inference and Sparse Range Measurements via KISS-GP",
        "track": "main",
        "status": "Poster",
        "abstract": "Estimating a dense and accurate depth map is the key requirement for autonomous driving and robotics. Recent advances in deep learning have allowed depth estimation in full resolution from a single image. Despite this impressive result, many deep-learning-based monocular depth estimation (MDE) algorithms have failed to keep their accuracy yielding a meter-level estimation error. In many robotics applications, accurate but sparse measurements are readily available from Light Detection and Ranging (LiDAR). Although they are highly accurate, the sparsity limits full resolution depth map reconstruction. Targeting the problem of dense and accurate depth map recovery, this paper introduces the fusion of these two modalities as a depth completion (DC) problem by dividing the role of depth inference and depth regression. Utilizing the state-of-the-art MDE and our Gaussian process (GP) based depth-regression method, we propose a general solution that can flexibly work with various MDE modules by enhancing its depth with sparse range measurements. To overcome the major limitation of GP, we adopt Kernel Interpolation for Scalable Structured (KISS)-GP and mitigate the computational complexity from O(N3) to O(N). Our experiments demonstrate that the accuracy and robustness of our method outperform state-of-the-art unsupervised methods for sparse and biased measurements.",
        "primary_area": "",
        "author": "Sungho Yoon;Ayoung Kim;Sungho Yoon;Ayoung Kim",
        "authorids": "/37088657667;/37403315600;/37088657667;/37403315600",
        "aff": "Robotics Program, KAIST, Daejeon, S. Korea; Department of Civil and Environmental Engineering, KAIST, Daejeon, S. Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341769/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15548087522946842604&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "KAIST",
        "aff_unique_dep": "Robotics Program",
        "aff_unique_url": "https://www.kaist.ac.kr",
        "aff_unique_abbr": "KAIST",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Daejeon",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9341691",
        "title": "Barometer-based Tactile Skin for Anthropomorphic Robot Hand",
        "track": "main",
        "status": "Poster",
        "abstract": "We present our second generation tactile sensor for the Shadow Dexterous Hand's palm. We were able to significantly improve the tactile sensor characteristics by utilizing our latest barometer-based tactile sensing technology with linear (R2 \u2265 0.9996) sensor output and no noticeable hysteresis. The sensitivity threshold of the tactile cells and the spatial density were both dramatically increased. We demonstrate the benefits of the new sensor by re-running an experiment to estimate the stiffness of different objects that we originally used to test our first generation palm sensor. The results underline a considerable performance boost in estimation accuracy, just due to the improved tactile skin. We also propose a revised neural network architecture that even further improves the average classification accuracy to 96% in a 5-fold cross-validation.",
        "primary_area": "",
        "author": "Risto K\u00f5iva;Tobias Schwank;Guillaume Walck;Martin Meier;Robert Haschke;Helge Ritter;Risto K\u00f5iva;Tobias Schwank;Guillaume Walck;Martin Meier;Robert Haschke;Helge Ritter",
        "authorids": "/37705809000;/37086580547;/37393489800;/37850185900;/37565751900;/37266153900;/37705809000;/37086580547;/37393489800;/37850185900;/37565751900;/37266153900",
        "aff": "Institute of Cognitive Interaction Technology (CITEC), Bielefeld University, Bielefeld, Germany; Institute of Cognitive Interaction Technology (CITEC), Bielefeld University, Bielefeld, Germany; Institute of Cognitive Interaction Technology (CITEC), Bielefeld University, Bielefeld, Germany; Institute of Cognitive Interaction Technology (CITEC), Bielefeld University, Bielefeld, Germany; Institute of Cognitive Interaction Technology (CITEC), Bielefeld University, Bielefeld, Germany; Institute of Cognitive Interaction Technology (CITEC), Bielefeld University, Bielefeld, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341691/",
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=256610867051193776&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Bielefeld University",
        "aff_unique_dep": "Institute of Cognitive Interaction Technology (CITEC)",
        "aff_unique_url": "https://www.uni-bielefeld.de",
        "aff_unique_abbr": "Uni Bielefeld",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Bielefeld",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9341602",
        "title": "Basic Implementation of FPGA-GPU Dual SoC Hybrid Architecture for Low-Latency Multi-DOF Robot Motion Control",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper describes basic implementation of an embedded controller board based on a hybrid architecture equipped with an Intel FPGA SoC and an NVIDIA GPU SoC. Embedded distributed network involving motor-drivers or other embedded boards is constructed with low-latency optical transmission link. The central controller for high-level motion planning is connected via Gigabit Ethernet. The controller board with the hybrid architecture provides lower-latency feedback control performance. Computing performance of the FPGA SoC, the GPU SoC, and the central controller is evaluated by computation time of matrix multiplication. Then, the total feedback latency is estimated to show the performance of the hybrid architecture.",
        "primary_area": "",
        "author": "Yuya Nagamatsu;Fumihito Sugai;Kei Okada;Masayuki Inaba;Yuya Nagamatsu;Fumihito Sugai;Kei Okada;Masayuki Inaba",
        "authorids": "/37086275431;/37085651948;/37280639000;/37286658200;/37086275431;/37085651948;/37280639000;/37286658200",
        "aff": "Graduate School of Information Science and Technology, the University of Tokyo, Tokyo, Japan; Graduate School of Information Science and Technology, the University of Tokyo, Tokyo, Japan; Graduate School of Information Science and Technology, the University of Tokyo, Tokyo, Japan; Graduate School of Information Science and Technology, the University of Tokyo, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341602/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6411238929306590374&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Tokyo",
        "aff_unique_dep": "Graduate School of Information Science and Technology",
        "aff_unique_url": "https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "UTokyo",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9341244",
        "title": "Batch Normalization Masked Sparse Autoencoder for Robotic Grasping Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "To improve the accuracy of the grasping detection, this paper proposes a novel detector with batch normalization masked evaluation model. It is designed with a two-layer sparse autoencoder, and a Batch Normalization based mask is incorporated into the second layer of the model to effectively reduce the features with weak correlation. The extracted features from such model are more distinctive, which guarantees the higher accuracy of the grasping detection. Extensive experiments show that the proposed evaluation model outperforms the state-of- the-art, and the recognition accuracy can reach 95.51% for robotic grasping detection.",
        "primary_area": "",
        "author": "Zhenzhou Shao;Ying Qu;Guangli Ren;Guohui Wang;Yong Guan;Zhiping Shi;Jindong Tan;Zhenzhou Shao;Ying Qu;Guangli Ren;Guohui Wang;Yong Guan;Zhiping Shi;Jindong Tan",
        "authorids": "/37085555595;/37085888305;/37086288569;/37675083800;/37308153300;/37085742076;/37065245900;/37085555595;/37085888305;/37086288569;/37675083800;/37308153300;/37085742076;/37065245900",
        "aff": "The College of Information Engineering, Beijing Advanced Innovation Center for Imaging Technology and Beijing Key Laboratory of Light Industrial Robot and Safety Verification, Capital Normal University, Beijing, China; The Engineering College, The University of Tennessee, Knoxville, TN, USA; Chinese Academy of Sciences, State Key Laboratory for Management and Control of Complex Systems, Institute of Automation, Beijing, China; The College of Information Engineering, Beijing Advanced Innovation Center for Imaging Technology and Beijing Key Laboratory of Light Industrial Robot and Safety Verification, Capital Normal University, Beijing, China; The College of Information Engineering, Beijing Advanced Innovation Center for Imaging Technology and Beijing Key Laboratory of Light Industrial Robot and Safety Verification, Capital Normal University, Beijing, China; The College of Information Engineering, Beijing Advanced Innovation Center for Imaging Technology and Beijing Key Laboratory of Light Industrial Robot and Safety Verification, Capital Normal University, Beijing, China; The Engineering College, The University of Tennessee, Knoxville, TN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341244/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16267468326320187822&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;2;0;0;0;1",
        "aff_unique_norm": "Capital Normal University;The University of Tennessee;Chinese Academy of Sciences",
        "aff_unique_dep": "College of Information Engineering;The Engineering College;State Key Laboratory for Management and Control of Complex Systems, Institute of Automation",
        "aff_unique_url": "http://www.cnu.edu.cn;https://www.tennessee.edu;http://www.cas.cn",
        "aff_unique_abbr": "CNU;UT;CAS",
        "aff_campus_unique_index": "0;1;0;0;0;0;1",
        "aff_campus_unique": "Beijing;Knoxville",
        "aff_country_unique_index": "0;1;0;0;0;0;1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9341410",
        "title": "Bayesian Fusion of Unlabeled Vision and RF Data for Aerial Tracking of Ground Targets",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a method for target localization and tracking in clutter using Bayesian fusion of vision and Radio Frequency (RF) sensors used aboard a small Unmanned Aircraft System (sUAS). Sensor fusion is used to ensure tracking robustness and reliability in case of camera occlusion or RF signal interference. Camera data is processed using an off-the-shelf algorithm that detects possible objects of interest in a given image frame, and the true RF emitting target needs to be identified from among these if it is present. These data sources, as well as the unknown motion of the target, lead to a heavily non-linear non-Gaussian target state uncertainties, which are not amenable to typical data association methods for tracking. A probabilistic model is thus first rigorously developed to relate conditional dependencies between target movements, RF data and visual object detections. A modified particle filter is then developed to simultaneously reason over target states and RF emitter association hypothesis labels for visual object detections. Truth model simulations are presented to compare and validate the effectiveness of the RF + visual data fusion filter.",
        "primary_area": "",
        "author": "Ramya Kanlapuli Rajasekaran;Nisar Ahmed;Eric Frew;Ramya Kanlapuli Rajasekaran;Nisar Ahmed;Eric Frew",
        "authorids": "/37086057442;/37533152500;/37268793800;/37086057442;/37533152500;/37268793800",
        "aff": "Department of Aerospace Engineering Sciences, University of Colorado Boulder, Boulder, Colorado; Department of Aerospace Engineering Sciences, University of Colorado Boulder, Boulder, Colorado; Department of Aerospace Engineering Sciences, University of Colorado Boulder, Boulder, Colorado",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341410/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15111900996515728248&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Colorado Boulder",
        "aff_unique_dep": "Department of Aerospace Engineering Sciences",
        "aff_unique_url": "https://www.colorado.edu",
        "aff_unique_abbr": "CU Boulder",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Boulder",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341061",
        "title": "Bayesian Particles on Cyclic Graphs",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider the problem of designing synthetic cells to achieve a complex goal (e.g., mimicking the immune system by seeking invaders) in a complex environment (e.g., the circulatory system), where they might have to change their control policy, communicate with each other, and deal with stochasticity including false positives and negatives-all with minimal capabilities and only a few bits of memory. We simulate the immune response in cyclic, maze-like environments and use targets at unknown locations to represent invading cells. Using only a few bits of memory, the synthetic cells are programmed to perform a physically-feasible algorithm with which they update their control policy based on randomized encounters with other cells. As the synthetic cells work together to find the target, their interactions as an ensemble function as a physical implementation of a Bayesian update. That is, the particles act as a particle filter. This result provides formal properties about the behavior of the synthetic cell ensemble that can be used to ensure robustness and safety. This method of self-organization is evaluated in simulations, and applied to an actual model of the human circulatory system.",
        "primary_area": "",
        "author": "Ana Pervan;Todd D. Murphey;Ana Pervan;Todd D. Murphey",
        "authorids": "/37086548416;/37329499800;/37086548416;/37329499800",
        "aff": "Department of Mechanical Engineering, Northwestern University, Evanston, Illinois, USA; Department of Mechanical Engineering, Northwestern University, Evanston, Illinois, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341061/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1847580401085444697&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Northwestern University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.northwestern.edu",
        "aff_unique_abbr": "NU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Evanston",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341493",
        "title": "Behaviorally Diverse Traffic Simulation via Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Traffic simulators are important tools in autonomous driving development. While continuous progress has been made to provide developers more options for modeling various traffic participants, tuning these models to increase their behavioral diversity while maintaining quality is often very challenging. This paper introduces an easily-tunable policy generation algorithm for autonomous driving agents. The proposed algorithm balances diversity and driving skills by leveraging the representation and exploration abilities of deep reinforcement learning via a distinct policy set selector. Moreover, we present an algorithm utilizing intrinsic rewards to widen behavioral differences in the training. To provide quantitative assessments, we develop two trajectory-based evaluation metrics which measure the differences among policies and behavioral coverage. We experimentally show the effectiveness of our methods on several challenging intersection scenes.",
        "primary_area": "",
        "author": "Shinya Shiroshita;Shirou Maruyama;Daisuke Nishiyama;Mario Ynocente Castro;Karim Hamzaoui;Guy Rosman;Jonathan DeCastro;Kuan-Hui Lee;Adrien Gaidon;Shinya Shiroshita;Shirou Maruyama;Daisuke Nishiyama;Mario Ynocente Castro;Karim Hamzaoui;Guy Rosman;Jonathan DeCastro;Kuan-Hui Lee;Adrien Gaidon",
        "authorids": "/37088595378;/37088594961;/37088595370;/37088597521;/37088598316;/37393688300;/37400557200;/37072359700;/37945420900;/37088595378;/37088594961;/37088595370;/37088597521;/37088598316;/37393688300;/37400557200;/37072359700;/37945420900",
        "aff": "Preferred Networks, Inc., Japan; Preferred Networks, Inc., Japan; Preferred Networks, Inc., Japan; Preferred Networks, Inc., Japan; Preferred Networks, Inc., Japan; Toyota Research Institute, U.S.; Toyota Research Institute, U.S.; Toyota Research Institute, U.S.; Toyota Research Institute, U.S.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341493/",
        "gs_citation": -1,
        "gs_cited_by_link": "",
        "gs_version_total": -1,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;0;0;1;1;1;1",
        "aff_unique_norm": "Preferred Networks, Inc.;Toyota Research Institute",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.preferred-networks.com;https://www.tri.global",
        "aff_unique_abbr": "PFN;TRI",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;1;1;1;1",
        "aff_country_unique": "Japan;United States"
    },
    {
        "id": "9341789",
        "title": "Better Together: Online Probabilistic Clique Change Detection in 3D Landmark-Based Maps",
        "track": "main",
        "status": "Poster",
        "abstract": "Many modern simultaneous localization and mapping (SLAM) techniques rely on sparse landmark-based maps due to their real-time performance. However, these techniques frequently assert that these landmarks are fixed in position over time, known as the static-world assumption. This is rarely, if ever, the case in most real-world environments. Even worse, over long deployments, robots are bound to observe traditionally static landmarks change, for example when an autonomous vehicle encounters a construction zone. This work addresses this challenge, accounting for changes in complex three-dimensional environments with the creation of a probabilistic filter that operates on the features that give rise to landmarks. To accomplish this, landmarks are clustered into cliques and a filter is developed to estimate their persistence jointly among observations of the landmarks in a clique. This filter uses estimated spatial-temporal priors of geometric objects, allowing for dynamic and semi-static objects to be removed from a formally static map. The proposed algorithm is validated in a 3D simulated environment.",
        "primary_area": "",
        "author": "Samuel Bateman;Kyle Harlow;Christoffer Heckman;Samuel Bateman;Kyle Harlow;Christoffer Heckman",
        "authorids": "/37088688613;/37088690321;/37086032368;/37088688613;/37088690321;/37086032368",
        "aff": "Department of Computer Science, University of Colorado, Boulder, CO, USA; Department of Computer Science, University of Colorado, Boulder, CO, USA; Department of Computer Science, University of Colorado, Boulder, CO, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341789/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4936801160694172993&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Colorado Boulder",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.colorado.edu",
        "aff_unique_abbr": "CU Boulder",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Boulder",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341543",
        "title": "Bi-Modal Hemispherical Sensors for Dynamic Locomotion and Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "The ability to measure multi-axis contact forces and contact surface normals in real time is critical to allow robots to improve their dexterous manipulation and locomotion abilities. This paper presents a new fingertip sensor for 3-axis contact force and contact location detection, as well as improvements on an existing footpad sensor through use of a new artificial neural network estimator. The fingertip sensor is intended for use in manipulation, while the footpad sensor is intended for high force use in locomotion. Both sensors consist of pressure sensing elements embedded within a rubber hemisphere, and utilize an artificial neural network to estimate the applied forces (fx, fy, and fz), and contact angles (\u03b8 and \u03c6) from the individual sensor element readings. The sensors are inherently robust, and the hemispherical shape allows for easy integration into point feet and fingertips. Both the fingertip and footpad sensors demonstrate the ability to track forces and angles accurately over the surface of the hemisphere (\u03b8=\u00b145\u00b0 and \u03c6=\u00b145\u00b0) and can experience up to 25N and 450N normal force, respectively, without saturating. The performance of the sensor is demonstrated with experimental results of dynamic control of a robotic arm with real-time sensor feedback.",
        "primary_area": "",
        "author": "Lindsay Epstein;Andrew SaLoutos;Donghyun Kim;Sangbae Kim;Lindsay Epstein;Andrew SaLoutos;Donghyun Kim;Sangbae Kim",
        "authorids": "/37087323559;/37088688960;/37085554176;/37537397200;/37087323559;/37088688960;/37085554176;/37537397200",
        "aff": "Biomimetic Robotics Laboratory at the Department of Mechanical Engineering, Massachusetts Institute of Technology (MIT), Cambridge, MA, USA; Biomimetic Robotics Laboratory at the Department of Mechanical Engineering, Massachusetts Institute of Technology (MIT), Cambridge, MA, USA; Biomimetic Robotics Laboratory at the Department of Mechanical Engineering, Massachusetts Institute of Technology (MIT), Cambridge, MA, USA; Biomimetic Robotics Laboratory at the Department of Mechanical Engineering, Massachusetts Institute of Technology (MIT), Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341543/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2962342977188976890&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341732",
        "title": "Bio-inspired Inverted Landing Strategy in a Small Aerial Robot Using Policy Gradient",
        "track": "main",
        "status": "Poster",
        "abstract": "Landing upside down on a ceiling is challenging as it requires a flier to invert its body and land against the gravity, a process that demands a stringent spatiotemporal coordination of body translational and rotational motion. Although such an aerobatic feat is routinely performed by biological fliers such as flies, it is not yet achieved in aerial robots using onboard sensors. This work describes the development of a bio-inspired inverted landing strategy using computationally efficient Relative Retinal Expansion Velocity (RREV) as a visual cue. This landing strategy consists of a sequence of two motions, i.e. an upward acceleration and a rapid angular maneuver. A policy search algorithm is applied to optimize the landing strategy and improve its robustness by learning the transition timing between the two motions and the magnitude of the target body angular velocity. Simulation results show that the aerial robot is able to achieve robust inverted landing, and it tends to exploit its maximal maneuverability. In addition to the computational aspects of the landing strategy, the robustness of landing is also significantly dependent on the mechanical design of the landing gear, the upward velocity at the start of body rotation, and timing of rotor shutdown.",
        "primary_area": "",
        "author": "Pan Liu;Junyi Geng;Yixian Li;Yanran Cao;Yagiz E. Bayiz;Jack W. Langelaan;Bo Cheng;Pan Liu;Junyi Geng;Yixian Li;Yanran Cao;Yagiz E. Bayiz;Jack W. Langelaan;Bo Cheng",
        "authorids": "/37086454649;/37089251620;/37088688628;/37088690739;/37086455709;/37546827400;/37536373700;/37086454649;/37089251620;/37088688628;/37088690739;/37086455709;/37546827400;/37536373700",
        "aff": "Department of Mechanical Engineering, Biological and Robotic Intelligent Fluid Locomotion Lab, The Pennsylvania State University, University Park, PA, USA; Department of Aerospace Engineering, Air Vehicle Intelligence and Autonomy Lab, The Pennsylvania State University, University Park, PA, USA; Department of Mechanical Engineering, Biological and Robotic Intelligent Fluid Locomotion Lab, The Pennsylvania State University, University Park, PA, USA; Department of Mechanical Engineering, Biological and Robotic Intelligent Fluid Locomotion Lab, The Pennsylvania State University, University Park, PA, USA; Department of Mechanical Engineering, Biological and Robotic Intelligent Fluid Locomotion Lab, The Pennsylvania State University, University Park, PA, USA; Department of Aerospace Engineering, Air Vehicle Intelligence and Autonomy Lab, The Pennsylvania State University, University Park, PA, USA; Department of Mechanical Engineering, Biological and Robotic Intelligent Fluid Locomotion Lab, The Pennsylvania State University, University Park, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341732/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1972081918833790042&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "The Pennsylvania State University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.psu.edu",
        "aff_unique_abbr": "PSU",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "University Park",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340935",
        "title": "BioARS: Designing Adaptive and Reconfigurable Bionic Assembly Robotic System with Inchworm Modules",
        "track": "main",
        "status": "Poster",
        "abstract": "Designing a swarm of robots to address different tasks and adapt to various environments through self-assembly is one of the most challenging topics in the field of robotics research. Here, we present an assembly robotic system with inchworm robots as modules. The system is called BioARS (Bionic Assembly Robotic System). It can either work as a swarm of individual untethered inchworm robots or be assembled into a quadruped robot. The inchworm robots are connected by magnets using a \"shoulder-to-shoulder\" connecting method, which helps strengthen the magnetic connection. Central pattern generators are used to control the trot gait of the quadruped robot. Our experiments demonstrate that the bionic assembly system is adaptive in that it can pass through confined spaces in the form of inchworms and walk on rough terrain in the form of a quadruped robot. The proposed BioARS, therefore, combines the flexibility of inchworms and the adaptability of quadruped animals, which is promising for application in planetary exploration, earthquake search and rescue operations. We also provide several examples of directions for future research regarding our system.",
        "primary_area": "",
        "author": "Yide Liu;Donghao Zhao;Yanhong Chen;Dongqi Wang;Zhou Wen;Ziyi Ye;Jianhui Guo;Haofei Zhou;Shaoxing Qu;Wei Yang;Yide Liu;Donghao Zhao;Yanhong Chen;Dongqi Wang;Zhou Wen;Ziyi Ye;Jianhui Guo;Haofei Zhou;Shaoxing Qu;Wei Yang",
        "authorids": "/37088690647;/37088691325;/37088689533;/37088690400;/37088688908;/37089419563;/37088688135;/37088686072;/37086485994;/37085393598;/37088690647;/37088691325;/37088689533;/37088690400;/37088688908;/37089419563;/37088688135;/37088686072;/37086485994;/37085393598",
        "aff": "State Key Laboratory of Fluid Power & Mechatronic System, Key Laboratory of Soft Machines and Smart Devices of Zhejiang Provinces, Center for X-Mechanics, Zhejiang University, China; State Key Laboratory of Fluid Power & Mechatronic System, Key Laboratory of Soft Machines and Smart Devices of Zhejiang Provinces, Center for X-Mechanics, Zhejiang University, China; Department of Engineering Mechanics, Zhejiang University, China; Department of Engineering Mechanics, Zhejiang University, China; Department of Engineering Mechanics, Zhejiang University, China; Department of Engineering Mechanics, Zhejiang University, China; Department of Engineering Mechanics, Zhejiang University, China; State Key Laboratory of Fluid Power & Mechatronic System, Key Laboratory of Soft Machines and Smart Devices of Zhejiang Provinces, Center for X-Mechanics, Zhejiang University, China; State Key Laboratory of Fluid Power & Mechatronic System, Key Laboratory of Soft Machines and Smart Devices of Zhejiang Provinces, Center for X-Mechanics, Zhejiang University, China; State Key Laboratory of Fluid Power & Mechatronic System, Key Laboratory of Soft Machines and Smart Devices of Zhejiang Provinces, Center for X-Mechanics, Zhejiang University, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340935/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15424152598824418375&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 20,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Zhejiang University",
        "aff_unique_dep": "State Key Laboratory of Fluid Power & Mechatronic System",
        "aff_unique_url": "http://www.zju.edu.cn",
        "aff_unique_abbr": "ZJU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9340896",
        "title": "Biomimetic Control Scheme for Musculoskeletal Humanoids Based on Motor Directional Tuning in the Brain",
        "track": "main",
        "status": "Poster",
        "abstract": "In this research, we have taken a biomimetic approach to the control of musculoskeletal humanoids. A controller was designed based on the motor directional tuning phenomenon seen in the motor cortex of primates. Despite the simple implementation of the control scheme, complex coordinated movements such as reaching for target objects with its upper body was achieved, and is demonstrated in the accompanying video. The controller does not require an internal model, and instead constantly observes its body in relation to the external world to update motor commands. We claim that such an embodied approach to the control of musculoskeletal robots will be able to effectively take advantage of their complex bodies to achieve motion.",
        "primary_area": "",
        "author": "Yasunori Toshimitsu;Kento Kawaharazuka;Kei Tsuzuki;Moritaka Onitsuka;Manabu Nishiura;Yuya Koga;Yusuke Omura;Motoki Tomita;Yuki Asano;Kei Okada;Koji Kawasaki;Masayuki Inaba;Yasunori Toshimitsu;Kento Kawaharazuka;Kei Tsuzuki;Moritaka Onitsuka;Manabu Nishiura;Yuya Koga;Yusuke Omura;Motoki Tomita;Yuki Asano;Kei Okada;Koji Kawasaki;Masayuki Inaba",
        "authorids": "/37086842924;/37086101930;/37086598284;/37086573419;/37088690295;/37088339856;/37088340210;/37088687939;/38238750500;/37280639000;/37085684621;/37286658200;/37086842924;/37086101930;/37086598284;/37086573419;/37088690295;/37088339856;/37088340210;/37088687939;/38238750500;/37280639000;/37085684621;/37286658200",
        "aff": "Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; TOYOTA MOTOR CORPORATION; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340896/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4688860882561149876&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 24,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0;0;1;0",
        "aff_unique_norm": "The University of Tokyo;Toyota Motor Corporation",
        "aff_unique_dep": "Department of Mechano-Informatics;",
        "aff_unique_url": "https://www.u-tokyo.ac.jp;https://www.toyota-global.com",
        "aff_unique_abbr": "UTokyo;Toyota",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Tokyo;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9341423",
        "title": "Blind Bin Picking of Small Screws Through In-finger Manipulation With Compliant Robotic Fingers",
        "track": "main",
        "status": "Poster",
        "abstract": "Although picking up objects a few centimeters in size is a common task, achieving such ability in a robot manipulator remains challenging. We take a step toward solving this problem by focusing on the task of picking a 1.0-cm screw from a bulk bin using only tactile information to achieve the task. Inspired by how humans pick up small objects from a bin, we propose a \"grasp-separate\" strategy for robotic picking, which involves grasping many objects first and then separating a single object through manipulation in the fingers, for robotic picking. Based on this strategy, we developed a tactile-based screw bin-picking system. We trained a convolution neural network to estimate the number of screws in the fingers first and built a controller that generates manipulation behaviors to separate a screw using reinforcement learning. To compensate for the low resolution of off-the-shelf tactile sensor arrays, we adopted active sensing, which uses observations obtained during a predefined simple movement. We show that this approach enhances the estimation accuracy and manipulation performance. Furthermore, to enable flexible finger motion, such as between the thumb and the index finger in a human hand, we propose a soft robot finger structure that leverages compliant materials. A soft actor-critic algorithm successfully found dexterous screw separation behaviors in compliant soft robotic fingers. In the evaluation, the system obtained an average success rate of 80%, which was difficult to achieve without the grasp-separate manipulation technique.",
        "primary_area": "",
        "author": "Matthew Ishige;Takuya Umedachi;Yoshihisa Ijiri;Tadahiro Taniguchi;Yoshihiro Kawahara;Matthew Ishige;Takuya Umedachi;Yoshihisa Ijiri;Tadahiro Taniguchi;Yoshihiro Kawahara",
        "authorids": "/37086573816;/37546535500;/37085621887;/37273806600;/37269138700;/37086573816;/37546535500;/37085621887;/37273806600;/37269138700",
        "aff": "Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; OMRON SINIC X Corporation, Tokyo, Japan; Department of Information Science and Engineering, Ritsumeikan University, Kusatsu, Japan; Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341423/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11131827673173906574&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;2;0",
        "aff_unique_norm": "The University of Tokyo;OMRON SINIC X Corporation;Ritsumeikan University",
        "aff_unique_dep": "Graduate School of Information Science and Technology;;Department of Information Science and Engineering",
        "aff_unique_url": "https://www.u-tokyo.ac.jp;;https://www.ritsumei.ac.jp",
        "aff_unique_abbr": "UTokyo;;Ritsumeikan",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Tokyo;Kusatsu",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9341047",
        "title": "Bounded Sub-optimal Multi-Robot Path Planning Using Satisfiability Modulo Theory (SMT) Approach",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-robot path planning (MRPP) is a task of planning collision free paths for a group of robots in a graph. Each robot starts in its individual starting vertex and its task is to reach a given goal vertex. Existing techniques for solving MRPP optimally under various objectives include search-based and compilation-based approaches. Often however finding an optimal solution is too difficult hence sub-optimal algorithms that trade-off the quality of solutions and the runtime have been devised. We suggest eSMT-CBS, a new bounded sub-optimal algorithm built on top of recent compilation-based method for optimal MRPP based on satisfiability modulo theories (SMT). We compare eSMT-CBS with ECBS, a major representative of bounded sub-optimal search-based algorithms. The experimental evaluation shows significant advantage of eSMT-CBS across variety of scenarios.",
        "primary_area": "",
        "author": "Pavel Surynek;Pavel Surynek",
        "authorids": "/37698202400;/37698202400",
        "aff": "Faculty of Information Technology, Czech Technical University in Prague, Praha 6, Czech Republic",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341047/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1298327681996385903&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 2,
        "aff_unique_index": "0",
        "aff_unique_norm": "Czech Technical University in Prague",
        "aff_unique_dep": "Faculty of Information Technology",
        "aff_unique_url": "https://www.fel.cvut.cz",
        "aff_unique_abbr": "CTU",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Praha 6",
        "aff_country_unique_index": "0",
        "aff_country_unique": "Czech Republic"
    },
    {
        "id": "9340807",
        "title": "Brainless Running: A Quasi-quadruped Robot with Decentralized Spinal Reflexes by Solely Mechanical Devices",
        "track": "main",
        "status": "Poster",
        "abstract": "As a strategy to address the difficulties encountered when modeling and controlling a musculoskeletal system, we present a straightforward implementation of an autonomous decentralized motion control system in this paper; the system is inspired by the spinal reflex system of animals. We developed an artificial receptor, a muscle, and a neuron to mechanically implement the reflex mechanisms of animals. Among the reflex mechanisms, this paper presents a reflex system with reciprocal innervation for a musculoskeletal quasi-quadruped robot, including antagonist muscles. In the experiments, the robot autonomously generated a leg trajectory and a gait pattern with smooth alternating motions of the antagonist muscles through the interaction between the body, the ground, and the artificial reflex systems. To evaluate the reciprocal innervation, we compared the developed robot with one that does not include antagonist muscles. The reciprocal innervation allows for twice as many muscle implementations as those offered by the robot without antagonist muscles. Moreover, it improves the running speed by 5% on average and the flexion and extension velocities of all joints by 28% on average at around touchdowns and liftoffs of the foot. This successful result lead to implement more advanced nervous systems by solely mechanical devices.",
        "primary_area": "",
        "author": "Yoichi Masuda;Kazuhiro Miyashita;Kaisei Yamagishi;Masato Ishikawa;Koh Hosoda;Yoichi Masuda;Kazuhiro Miyashita;Kaisei Yamagishi;Masato Ishikawa;Koh Hosoda",
        "authorids": "/37086173439;/37088686749;/37088686069;/37276508600;/37270101900;/37086173439;/37088686749;/37088686069;/37276508600;/37270101900",
        "aff": "Department of Mechanical Engineering, Osaka University, Japan; Department of Mechanical Engineering, Osaka University, Japan; Department of Mechanical Engineering, Osaka University, Japan; Department of Mechanical Engineering, Osaka University, Japan; Department of System Innovation, Osaka University, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340807/",
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11919234278791325085&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Osaka University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.osaka-u.ac.jp",
        "aff_unique_abbr": "Osaka U",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9341627",
        "title": "Building Plannable Representations with Mixed Reality",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose Action-Oriented Semantic Maps (AOSMs), a representation that enables a robot to acquire object manipulation behaviors and semantic information about the environment from a human teacher with a Mixed Reality Head-Mounted Display (MR-HMD). AOSMs are a representation that captures both: a) high-level object manipulation actions in an object class's local frame, and b) semantic representations of objects in the robot's global map that are grounded for navigation. Humans can use a MR-HMD to teach the agent the information necessary for planning object manipulation and navigation actions by interacting with virtual 3D meshes overlaid on the physical workspace. We demonstrate that our system enables users to quickly and accurately teach a robot the knowledge required to autonomously plan and execute three household tasks: picking up a bottle and throwing it in the trash, closing a sink faucet, and flipping a light switch off.",
        "primary_area": "",
        "author": "Eric Rosen;Nishanth Kumar;Nakul Gopalan;Daniel Ullman;George Konidaris;Stefanie Tellex;Eric Rosen;Nishanth Kumar;Nakul Gopalan;Daniel Ullman;George Konidaris;Stefanie Tellex",
        "authorids": "/37086078687;/37086938151;/37077656800;/38571208100;/38318614200;/37402794800;/37086078687;/37086938151;/37077656800;/38571208100;/38318614200;/37402794800",
        "aff": "Department of Computer Science, Brown University; Department of Computer Science, Brown University; Department of Computer Science, Brown University; Department of Computer Science, Brown University; Department of Computer Science, Brown University; Department of Computer Science, Brown University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341627/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17703515427444141322&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Brown University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.brown.edu",
        "aff_unique_abbr": "Brown",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340858",
        "title": "CAZSL: Zero-Shot Regression for Pushing Models by Generalizing Through Context",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning accurate models of the physical world is required for a lot of robotic manipulation tasks. However, during manipulation, robots are expected to interact with un-known workpieces so that building predictive models which can generalize over a number of these objects is highly desirable. In this paper, we study the problem of designing deep learning agents which can generalize their models of the physical world by building context-aware learning models. The purpose of these agents is to quickly adapt and/or generalize their notion of physics of interaction in the real world based on certain features about the interacting objects that provide different contexts to the predictive models. With this motivation, we present context-aware zero shot learning (CAZSL, pronounced as casual) models, an approach utilizing a Siamese network architecture, embedding space masking and regularization based on context variables which allows us to learn a model that can generalize to different parameters or features of the interacting objects. We test our proposed learning algorithm on the recently released Omnipush datatset that allows testing of meta-learning capabilities using low-dimensional data. Codes for CAZSL are available at https://www.merl.com/research/license/CAZSL.",
        "primary_area": "",
        "author": "Wenyu Zhang;Skyler Seto;Devesh K. Jha;Wenyu Zhang;Skyler Seto;Devesh K. Jha",
        "authorids": "/37086044256;/37088689018;/37072717800;/37086044256;/37088689018;/37072717800",
        "aff": "",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340858/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=200944053137986967&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6
    },
    {
        "id": "9341791",
        "title": "CLOCs: Camera-LiDAR Object Candidates Fusion for 3D Object Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "There have been significant advances in neural networks for both 3D object detection using LiDAR and 2D object detection using video. However, it has been surprisingly difficult to train networks to effectively use both modalities in a way that demonstrates gain over single-modality networks. In this paper, we propose a novel Camera-LiDAR Object Candidates (CLOCs) fusion network. CLOCs fusion provides a low-complexity multi-modal fusion framework that significantly improves the performance of single-modality detectors. CLOCs operates on the combined output candidates before Non-Maximum Suppression (NMS) of any 2D and any 3D detector, and is trained to leverage their geometric and semantic consistencies to produce more accurate final 3D and 2D detection results. Our experimental evaluation on the challenging KITTI object detection benchmark, including 3D and bird's eye view metrics, shows significant improvements, especially at long distance, over the state-of-the-art fusion based methods. At time of submission, CLOCs ranks the highest among all the fusion-based methods in the official KITTI leaderboard. We will release our code upon acceptance.",
        "primary_area": "",
        "author": "Su Pang;Daniel Morris;Hayder Radha;Su Pang;Daniel Morris;Hayder Radha",
        "authorids": "/37086815663;/37085641369;/37269513400;/37086815663;/37085641369;/37269513400",
        "aff": "Department of Electrical and Computer Engineering, College of Engineering, Michigan State University, Michigan, United States; Department of Electrical and Computer Engineering, College of Engineering, Michigan State University, Michigan, United States; Department of Electrical and Computer Engineering, College of Engineering, Michigan State University, Michigan, United States",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341791/",
        "gs_citation": 560,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1329660228088859136&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Michigan State University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.msu.edu",
        "aff_unique_abbr": "MSU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Michigan",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341720",
        "title": "CMetric: A Driving Behavior Measure using Centrality Functions",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a new measure, CMetric, to classify driver behaviors using centrality functions. Our formulation combines concepts from computational graph theory and social traffic psychology to quantify and classify the behavior of human drivers. CMetric is used to compute the probability of a vehicle executing a driving style, as well as the intensity used to execute the style. Our approach is designed for realtime autonomous driving applications, where the trajectory of each vehicle or road-agent is extracted from a video. We compute a dynamic geometric graph (DGG) based on the positions and proximity of the road-agents and centrality functions corresponding to closeness and degree. These functions are used to compute the CMetric based on style likelihood and style intensity estimates. Our approach is general and makes no assumption about traffic density, heterogeneity, or how driving behaviors change over time. We present an algorithm to compute CMetric and demonstrate its performance on real-world traffic datasets. To test the accuracy of CMetric, we introduce a new evaluation protocol (called \"Time Deviation Error\") that measures the difference between human prediction and the prediction made by CMetric.",
        "primary_area": "",
        "author": "Rohan Chandra;Uttaran Bhattacharya;Trisha Mittal;Aniket Bera;Dinesh Manocha;Rohan Chandra;Uttaran Bhattacharya;Trisha Mittal;Aniket Bera;Dinesh Manocha",
        "authorids": "/37086365992;/37087234810;/37085492830;/37085393882;/37267825600;/37086365992;/37087234810;/37085492830;/37085393882;/37267825600",
        "aff": "University of Maryland, College Park; University of Maryland, College Park; University of Maryland, College Park; University of Maryland, College Park; University of Maryland, College Park",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341720/",
        "gs_citation": 47,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17675204492810185261&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Maryland",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www/umd.edu",
        "aff_unique_abbr": "UMD",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "College Park",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340910",
        "title": "CNN-based Foothold Selection for Mechanically Adaptive Soft Foot",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we consider a problem of foothold selection for the quadrupedal robots equipped with compliant adaptive feet. Starting from a model of the foot we compute the quality of the potential footholds considering also kinematic constraints and collisions during evaluation. Since terrain assessment and constraints checking are computationally expensive we applied a Convolutional Neural Network (CNN) to evaluate the potential footholds on the elevation map. We propose an efficient strategy for data clustering and segmentation with CNN. The data for training the neural network is collected off-line but the inference works on-line when the robot walks on rough terrains and allows for efficient adaptation to the terrain and exploitation of the properties of the soft adaptive feet.",
        "primary_area": "",
        "author": "Jakub Bednarek;Noel Maalouf;Mathew J. Pollayil;Manolo Garabini;Manuel G. Catalano;Giorgio Grioli;Dominik Belter;Jakub Bednarek;Noel Maalouf;Mathew J. Pollayil;Manolo Garabini;Manuel G. Catalano;Giorgio Grioli;Dominik Belter",
        "authorids": "/37086546179;/37085774822;/37088690055;/37947205100;/37544547800;/37590311700;/37542853100;/37086546179;/37085774822;/37088690055;/37947205100;/37544547800;/37590311700;/37542853100",
        "aff": "Institute of Robotics and Machine Intelligence, Poznan University of Technology, Poznan, Poland; Institute of Robotics and Machine Intelligence, Poznan University of Technology, Poznan, Poland; Research Center \"E. Piaggio\", University of Pisa, Pisa, Italy; Research Center \"E. Piaggio\", University of Pisa, Pisa, Italy; Research Line SoftBots, Italian Institute of Technology, Genova, Italy; Research Line SoftBots, Italian Institute of Technology, Genova, Italy; Institute of Robotics and Machine Intelligence, Poznan University of Technology, Poznan, Poland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340910/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5419644270560750739&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;1;1;2;2;0",
        "aff_unique_norm": "Poznan University of Technology;University of Pisa;Italian Institute of Technology",
        "aff_unique_dep": "Institute of Robotics and Machine Intelligence;Research Center \"E. Piaggio\";Research Line SoftBots",
        "aff_unique_url": "https://www.put.poznan.pl/;https://www.unipi.it;https://www.iit.it",
        "aff_unique_abbr": "PUT;;IIT",
        "aff_campus_unique_index": "0;0;1;1;2;2;0",
        "aff_campus_unique": "Poznan;Pisa;Genova",
        "aff_country_unique_index": "0;0;1;1;1;1;0",
        "aff_country_unique": "Poland;Italy"
    },
    {
        "id": "9341317",
        "title": "CUHK-AHU Dataset: Promoting Practical Self-Driving Applications in the Complex Airport Logistics, Hill and Urban Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel dataset targeting three types of challenging environments for autonomous driving, i.e., the industrial logistics environment, the undulating hill environment and the mixed complex urban environment. To the best of the author\u2019s knowledge, similar dataset has not been published in the existing public datasets, especially for the logistics environment collected in the functioning Hong Kong Air Cargo Terminal (HACT). Structural changes always suddenly appeared in the airport logistics environment due to the frequent movement of goods in and out. In the structureless and noisy hill environment, the non-flat plane movement is usual. In the mixed complex urban environment, the highly dynamic residence blocks, sloped roads and highways are included in a single collection. The presented dataset includes LiDAR, image, IMU and GPS data by repeatedly driving along several paths to capture the structural changes, the illumination changes and the different degrees of undulation of the roads. The baseline trajectories are provided which are estimated by Simultaneous Localization and Mapping (SLAM).",
        "primary_area": "",
        "author": "Wen Chen;Zhe Liu;Hongchao Zhao;Shunbo Zhou;Haoang Li;Yun-Hui Liu;Wen Chen;Zhe Liu;Hongchao Zhao;Shunbo Zhou;Haoang Li;Yun-Hui Liu",
        "authorids": "/37087239966;/37089937755;/37086346685;/37086345412;/37086937885;/37089735347;/37087239966;/37089937755;/37086346685;/37086345412;/37086937885;/37089735347",
        "aff": "T Stone Robotics Institute and Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, China; T Stone Robotics Institute and Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, China; T Stone Robotics Institute and Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, China; T Stone Robotics Institute and Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, China; T Stone Robotics Institute and Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, China; T Stone Robotics Institute and Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341317/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11042076209631819389&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "The Chinese University of Hong Kong",
        "aff_unique_dep": "Department of Mechanical and Automation Engineering",
        "aff_unique_url": "https://www.cuhk.edu.hk",
        "aff_unique_abbr": "CUHK",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9341147",
        "title": "CalibRCNN: Calibrating Camera and LiDAR by Recurrent Convolutional Neural Network and Geometric Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present Calibration Recurrent Convolutional Neural Network (CalibRCNN) to infer a 6 degrees of freedom (DOF) rigid body transformation between 3D LiDAR and 2D camera. Different from the existing methods, our 3D-2D CalibRCNN not only uses the LSTM network to extract the temporal features between 3D point clouds and RGB images of consecutive frames, but also uses the geometric loss and photometric loss obtained by the interframe constraint to refine the calibration accuracy of the predicted transformation parameters. The CalibRCNN aims at inferring the correspondence between projected depth image and RGB image to learn the underlying geometry of 2D-3D calibration. Thus, the proposed calibration model achieves a good generalization ability to adapt to unknown initial calibration error ranges, and other 3D LiDAR and 2D camera pairs with different intrinsic parameters from the training dataset. Extensive experiments have demonstrated that our CalibRCNN can achieve state-of-the-art accuracy by comparison with other CNN based methods.",
        "primary_area": "",
        "author": "Jieying Shi;Ziheng Zhu;Jianhua Zhang;Ruyu Liu;Zhenhua Wang;Shengyong Chen;Honghai Liu;Jieying Shi;Ziheng Zhu;Jianhua Zhang;Ruyu Liu;Zhenhua Wang;Shengyong Chen;Honghai Liu",
        "authorids": "/37088686214;/37088639315;/37678556700;/37086354166;/37075914500;/37290961700;/37310131600;/37088686214;/37088639315;/37678556700;/37086354166;/37075914500;/37290961700;/37310131600",
        "aff": "College of Computer Science and Technology, Zhejiang University of Technology, Hangzhou, China; College of Computer Science and Technology, Zhejiang University of Technology, Hangzhou, China; College of Computer Science and Technology, Zhejiang University of Technology, Hangzhou, China; College of Computer Science and Technology, Zhejiang University of Technology, Hangzhou, China; College of Computer Science and Technology, Zhejiang University of Technology, Hangzhou, China; School of Computer Science and Engineering, Tianjin University of Technology; School of Computing, University of Portsmouth, Portsmouth, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341147/",
        "gs_citation": 72,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2076513022833299629&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;1;2",
        "aff_unique_norm": "Zhejiang University of Technology;Tianjin University of Technology;University of Portsmouth",
        "aff_unique_dep": "College of Computer Science and Technology;School of Computer Science and Engineering;School of Computing",
        "aff_unique_url": "https://www.zjut.edu.cn;http://www.tjut.edu.cn;https://www.port.ac.uk",
        "aff_unique_abbr": "ZJUT;;UoP",
        "aff_campus_unique_index": "0;0;0;0;0;2",
        "aff_campus_unique": "Hangzhou;;Portsmouth",
        "aff_country_unique_index": "0;0;0;0;0;0;1",
        "aff_country_unique": "China;United Kingdom"
    },
    {
        "id": "9340729",
        "title": "Can I lift it? Humanoid robot reasoning about the feasibility of lifting a heavy box with unknown physical properties",
        "track": "main",
        "status": "Poster",
        "abstract": "A robot cannot lift up an object if it is not feasible to do so. However, in most research on robot lifting, \"feasibility\" is usually presumed to exist a priori. This paper proposes a three-step method for a humanoid robot to reason about the feasibility of lifting a heavy box with physical properties that are unknown to the robot. Since feasibility of lifting is directly related to the physical properties of the box, we first discretize a range for the unknown values of parameters describing these properties and tabulate all valid optimal quasi-static lifting trajectories generated by simulations over all combinations of indices. Second, a physical-interaction-based algorithm is introduced to identify the robust gripping position and physical parameters corresponding to the box. During this process, the stability and safety of the robot are ensured. On the basis of the above two steps, a third step of mapping operation is carried out to best match the estimated parameters to the indices in the table. The matched indices are then queried to determine whether a valid trajectory exists. If so, the lifting motion is feasible; otherwise, the robot decides that the task is beyond its capability. Our method efficiently evaluates the feasibility of a lifting task through simple interactions between the robot and the box, while simultaneously obtaining the desired safe and stable trajectory. We successfully demonstrated the proposed method using a NAO humanoid robot.",
        "primary_area": "",
        "author": "Yuanfeng Han;Ruixin Li;Gregory S. Chirikjian;Yuanfeng Han;Ruixin Li;Gregory S. Chirikjian",
        "authorids": "/37088689259;/37088686627;/37283175100;/37088689259;/37088686627;/37283175100",
        "aff": "Department of Mechanical Engineering, Johns Hopkins University, Baltimore, MD; Department of Mechanical Engineering, Johns Hopkins University, Baltimore, MD; Department of Mechanical Engineering, National University of Singapore, Singapore and the Laboratory for Computational Sensing and Robotics, Johns Hopkins University, Baltimore, MD",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340729/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14286223964150796259&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Johns Hopkins University;National University of Singapore",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.jhu.edu;https://www.nus.edu.sg",
        "aff_unique_abbr": "JHU;NUS",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Baltimore;Singapore",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "United States;Singapore"
    },
    {
        "id": "9340874",
        "title": "Can a Robot's Touches Express the Feeling of Kawaii toward an Object?",
        "track": "main",
        "status": "Poster",
        "abstract": "Kawaii, a Japanese word that means \"cute,\" is an essential design concept in consumer and pop culture in Japan. In this study, we focused on a situation where a social robot describes an object during an information-providing task, which is commonly required for social robots in daily environments. Since past studies reported kawaii feelings are associated with a motivation to approach a target, our robot expressed feelings of kawaii to objects touch behaviors. We also focused on whether touch behaviors that emphasize style increase the feeling of kawaii of the touched object, following a phenomenon where people strongly touch a target when they overwhelmingly feel positive emotion: cute aggression. Our experimental results showed the effectiveness of touch behaviors to express the feelings of kawaii from the robot toward objects and to increase the participants' feelings of kawaii toward the object. We identified fewer effects from the participants to the robot. The emphasized motion style did not show any significant effects for the kawaii feelings.",
        "primary_area": "",
        "author": "Yuka Okada;Mitsuhiko Kimoto;Takamasa Iio;Katsunori Shimohara;Hiroshi Nittono;Masahiro Shiomi;Yuka Okada;Mitsuhiko Kimoto;Takamasa Iio;Katsunori Shimohara;Hiroshi Nittono;Masahiro Shiomi",
        "authorids": "/37088529057;/37085752016;/37586374100;/37271120700;/38506169000;/37296827100;/37088529057;/37085752016;/37586374100;/37271120700;/38506169000;/37296827100",
        "aff": "Doshisha Univ., Kyoto, Japan; Keio Univ., Tokyo, Japan; University of Tsukuba / JST PRESTO, Ibaraki, Japan; Doshisha Univ., Kyoto, Japan; Osaka Univ., Osaka, Japan; ATR, Kyoto, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340874/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14348824140292804183&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;0;3;4",
        "aff_unique_norm": "Doshisha University;Keio University;University of Tsukuba;Osaka University;ATR",
        "aff_unique_dep": ";;JST PRESTO;;",
        "aff_unique_url": "https://www.doshisha.ac.jp;https://www.keio.ac.jp;https://www.tsukuba.ac.jp;https://www.osaka-u.ac.jp;https://www.atr.jp",
        "aff_unique_abbr": "Doshisha;Keio;UT;Osaka U.;ATR",
        "aff_campus_unique_index": "0;1;0;3;0",
        "aff_campus_unique": "Kyoto;Tokyo;;Osaka",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9341531",
        "title": "Cascaded Non-local Neural Network for Point Cloud Semantic Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a cascaded non-local neural network for point cloud segmentation. The proposed network aims to build the long-range dependencies of point clouds for the accurate segmentation. Specifically, we develop a novel cascaded non-local module, which consists of the neighborhood-level, superpoint-level and global-level non-local blocks. First, in the neighborhood-level block, we extract the local features of the centroid points of point clouds by assigning different weights to the neighboring points. The extracted local features of the centroid points are then used to encode the superpoint-level block with the non-local operation. Finally, the global-level block aggregates the non-local features of the superpoints for semantic segmentation in an encoder-decoder framework. Benefiting from the cascaded structure, geometric structure information of different neighborhoods with the same label can be propagated. In addition, the cascaded structure can largely reduce the computational cost of the original non-local operation on point clouds. Experiments on different indoor and outdoor datasets show that our method achieves state-of-the-art performance and effectively reduces the time consumption and memory occupation.",
        "primary_area": "",
        "author": "Mingmei Cheng;Le Hui;Jin Xie;Jian Yang;Hui Kong;Mingmei Cheng;Le Hui;Jin Xie;Jian Yang;Hui Kong",
        "authorids": "/37086516919;/37086381563;/37085622059;/37280205100;/37061510500;/37086516919;/37086381563;/37085622059;/37280205100;/37061510500",
        "aff": "PCA Lab, Key Lab of Intelligent Perception and Systems for High-Dimensional Information of Ministry of Education, and Jiangsu Key Lab of Image and Video Understanding for Social Security, School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; PCA Lab, Key Lab of Intelligent Perception and Systems for High-Dimensional Information of Ministry of Education, and Jiangsu Key Lab of Image and Video Understanding for Social Security, School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; PCA Lab, Key Lab of Intelligent Perception and Systems for High-Dimensional Information of Ministry of Education, and Jiangsu Key Lab of Image and Video Understanding for Social Security, School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; PCA Lab, Key Lab of Intelligent Perception and Systems for High-Dimensional Information of Ministry of Education, and Jiangsu Key Lab of Image and Video Understanding for Social Security, School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; PCA Lab, Key Lab of Intelligent Perception and Systems for High-Dimensional Information of Ministry of Education, and Jiangsu Key Lab of Image and Video Understanding for Social Security, School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341531/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9705200388185824918&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Nanjing University of Science and Technology",
        "aff_unique_dep": "School of Computer Science and Engineering",
        "aff_unique_url": "http://www.nust.edu.cn",
        "aff_unique_abbr": "NJUST",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Nanjing",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9341134",
        "title": "Catch the Ball: Accurate High-Speed Motions for Mobile Manipulators via Inverse Dynamics Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Mobile manipulators consist of a mobile platform equipped with one or more robot arms and are of interest for a wide array of challenging tasks because of their extended workspace and dexterity. Typically, mobile manipulators are deployed in slow-motion collaborative robot scenarios. In this paper, we consider scenarios where accurate high-speed motions are required. We introduce a framework for this regime of tasks including two main components: (i) a bi-level motion optimization algorithm for real-time trajectory generation, which relies on Sequential Quadratic Programming (SQP) and Quadratic Programming (QP), respectively; and (ii) a learning-based controller optimized for precise tracking of high-speed motions via a learned inverse dynamics model. We evaluate our framework with a mobile manipulator platform through numerous high-speed ball catching experiments, where we show a success rate of 85.33%. To the best of our knowledge, this success rate exceeds the reported performance of existing related systems [1], [2] and sets a new state of the art.",
        "primary_area": "",
        "author": "Ke Dong;Karime Pereida;Florian Shkurti;Angela P. Schoellig;Ke Dong;Karime Pereida;Florian Shkurti;Angela P. Schoellig",
        "authorids": "/37088689487;/38546763000;/37706697200;/38488605800;/37088689487;/38546763000;/37706697200;/38488605800",
        "aff": "Dynamic Systems Lab (www.dynsyslab.org), University of Toronto Institute for Aerospace Studies (UTIAS), and the Vector Institute for artificial Intelligence, Canada; Dynamic Systems Lab (www.dynsyslab.org), University of Toronto Institute for Aerospace Studies (UTIAS), and the Vector Institute for artificial Intelligence, Canada; Department of Computer Science, University of Toronto, Canada; Dynamic Systems Lab (www.dynsyslab.org), University of Toronto Institute for Aerospace Studies (UTIAS), and the Vector Institute for artificial Intelligence, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341134/",
        "gs_citation": 34,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5104207285199419001&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "University of Toronto Institute for Aerospace Studies;University of Toronto",
        "aff_unique_dep": "Institute for Aerospace Studies;Department of Computer Science",
        "aff_unique_url": "https://www.ias.utoronto.ca;https://www.utoronto.ca",
        "aff_unique_abbr": "UTIAS;U of T",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Toronto;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9340878",
        "title": "Category-Level 3D Non-Rigid Registration from Single-View RGB Images",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a novel approach to solve the 3D non-rigid registration problem from RGB images using Convolutional Neural Networks (CNNs). Our objective is to find a deformation field (typically used for transferring knowledge between instances, e.g., grasping skills) that warps a given 3D canonical model into a novel instance observed by a single-view RGB image. This is done by training a CNN that infers a deformation field for the visible parts of the canonical model and by employing a learned shape (latent) space for inferring the deformations of the occluded parts. As result of the registration, the observed model is reconstructed. Because our method does not need depth information, it can register objects that are typically hard to perceive with RGB-D sensors, e.g. with transparent or shiny surfaces. Even without depth data, our approach outperforms the Coherent Point Drift (CPD) registration method for the evaluated object categories.",
        "primary_area": "",
        "author": "Diego Rodriguez;Florian Huber;Sven Behnke;Diego Rodriguez;Florian Huber;Sven Behnke",
        "authorids": "/37086373727;/37088687719;/37295987100;/37086373727;/37088687719;/37295987100",
        "aff": "Autonomous Intelligent Systems (AIS) Group, Computer Science Institute VI, University of Bonn, Germany; Autonomous Intelligent Systems (AIS) Group, Computer Science Institute VI, University of Bonn, Germany; Autonomous Intelligent Systems (AIS) Group, Computer Science Institute VI, University of Bonn, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340878/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17739196846736127609&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Bonn",
        "aff_unique_dep": "Computer Science Institute VI",
        "aff_unique_url": "https://www.uni-bonn.de",
        "aff_unique_abbr": "Uni Bonn",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9341050",
        "title": "Centroids Triplet Network and Temporally-Consistent Embeddings for In-Situ Object Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "This work proposes learning to recognize objects from a small number of training examples collected and deployed in-situ. That is, from data collected where the objects are commonly placed or being used, perhaps after first encountering them, the learning algorithm immediately is able to recognize them again. We refer to this method-ology as in-situ learning, and it opposes to the conventional methodology of using complex data acquisition mechanisms, such as rotating tables or synthetic data, to build a large-scale dataset for training convolutional neural networks (ConvNets). To learn in-situ, we propose a novel loss function that generates discriminative features for known and unseen objects, by utilizing a regularization term that reduces the distance between features and their manifold centroid. Additionally, we propose a temporal filter that is particularly useful to quickly react to appearing objects on the scene, which depending on the distance between neighboring video-frame features, it applies a weighted average between the current and the previous frame. Our framework achieves state-of-the-art accuracy for in-situ and on-the-fly learning, for the case of known objects achieves an average increase in accuracy of 3.01%, an increase of 3.3% for novel objects, and an average increase of 7.07% for the combined case, compared with the closest baseline. Utilizing the temporal filtering, led to a further increase in accuracy against nuisances of 7.32% for the known and novels objects case.",
        "primary_area": "",
        "author": "Miguel Lagunes-Fortiz;Dima Damen;Walterio Mayol-Cuevas;Miguel Lagunes-Fortiz;Dima Damen;Walterio Mayol-Cuevas",
        "authorids": "/37086933320;/38535144900;/38270046600;/37086933320;/38535144900;/38270046600",
        "aff": "Department of Computer Science, University of Bristol, Bristol, UK; Department of Computer Science, University of Bristol, Bristol, UK; Department of Computer Science, University of Bristol, Bristol, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341050/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8219430629859344460&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Bristol",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.bristol.ac.uk",
        "aff_unique_abbr": "UoB",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Bristol",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9340969",
        "title": "Choosing Classification Thresholds for Mobile Robot Coverage",
        "track": "main",
        "status": "Poster",
        "abstract": "Many robotic coverage applications involve detection of spatially distributed targets, followed by path planning to visit them for service. In these applications, the performance of the detection algorithm can have profound effect on planning decisions and costs. Range of operation, in both space and time, for robots is typically finite over a single mission and is a common constraint that needs to be accounted for in decision making. Misclassification may result in wastage of resources and can even jeopardize the completion of a mission if the length of a path extends beyond the range of the robot. In this work, we develop techniques on the computation of planning-aware classification thresholds. We discuss two versions that compute binary classification thresholds as a function of planning budget and detection accuracy. We present an implementation of our methods in path planning applications for an autonomous mower and show results on real and simulated data. Our method allows upto 25% improvement in coverage as compared to standard thresholding methods.",
        "primary_area": "",
        "author": "Parikshit Maini;Volkan Isler;Parikshit Maini;Volkan Isler",
        "authorids": "/37085340497;/37298487800;/37085340497;/37298487800",
        "aff": "Department of Computer Science, University of Minnesota - Twin Cities, United States; Department of Computer Science, University of Minnesota - Twin Cities, United States",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340969/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:MlfCAKVZ0kEJ:scholar.google.com/&scioq=Choosing+Classification+Thresholds+for+Mobile+Robot+Coverage&hl=en&as_sdt=0,5",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Minnesota",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.minnesota.edu",
        "aff_unique_abbr": "UMN",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Twin Cities",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341066",
        "title": "CinemAirSim: A Camera-Realistic Robotics Simulator for Cinematographic Purposes",
        "track": "main",
        "status": "Poster",
        "abstract": "Unmanned Aerial Vehicles (UAVs) are becoming increasingly popular in the film and entertainment industries, in part because of their maneuverability and perspectives they enable. While there exists methods for controlling the position and orientation of the drones for visibility, other artistic elements of the filming process, such as focal blur, remain unexplored in the robotics community. The lack of cinematographic robotics solutions is partly due to the cost associated with the cameras and devices used in the filming industry, but also because state-of-the-art photo-realistic robotics simulators only utilize a full in-focus pinhole camera model which does not incorporate these desired artistic attributes. To overcome this, the main contribution of this work is to endow the well-known drone simulator, AirSim, with a cinematic camera as well as extend its API to control all of its parameters in real time, including various filming lenses and common cinematographic properties. In this paper, we detail the implementation of our AirSim modification, CinemAirSim, present examples that illustrate the potential of the new tool, and highlight the new research opportunities that the use of cinematic cameras can bring to research in robotics and control.",
        "primary_area": "",
        "author": "Pablo Pueyo;Eric Cristofalo;Eduardo Montijano;Mac Schwager;Pablo Pueyo;Eric Cristofalo;Eduardo Montijano;Mac Schwager",
        "authorids": "/37088690443;/37085655200;/37681715400;/37424620600;/37088690443;/37085655200;/37681715400;/37424620600",
        "aff": "Instituto de Investigaci\u00f3n en Ingenier\u00eda de Arag\u00f3n, Universidad de Zaragoza, Spain; Department of Aeronautics and Astronautics, Stanford University, USA; Instituto de Investigaci\u00f3n en Ingenier\u00eda de Arag\u00f3n, Universidad de Zaragoza, Spain; Department of Aeronautics and Astronautics, Stanford University, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341066/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13127343067064598449&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;1",
        "aff_unique_norm": "Universidad de Zaragoza;Stanford University",
        "aff_unique_dep": "Instituto de Investigaci\u00f3n en Ingenier\u00eda de Arag\u00f3n;Department of Aeronautics and Astronautics",
        "aff_unique_url": "https://www.unizar.es;https://www.stanford.edu",
        "aff_unique_abbr": ";Stanford",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Stanford",
        "aff_country_unique_index": "0;1;0;1",
        "aff_country_unique": "Spain;United States"
    },
    {
        "id": "9340990",
        "title": "City-Scale Grid-Topological Hybrid Maps for Autonomous Mobile Robot Navigation in Urban Area",
        "track": "main",
        "status": "Poster",
        "abstract": "Extensive city navigation remains an unresolved problem for autonomous mobile robots that share space with pedestrians. This paper proposes a configuration for a navigation map that expresses urban structures and an autonomous navigation scheme that uses the configuration. The proposed map configuration is a hybrid structure of multiple 2D grid maps and a topological graph. The occupancy grids for path planning are automatically converted from a given 3D point cloud and publicly available maps. The topological graph enables the connections between the subdivisions of occupancy grids to be managed and are used for route planning. This hybrid configuration can embed various urban structures automatically and is applicable to a wide range of autonomous navigation tasks. We evaluated the map by generating the pro-posed navigation map in real city and performing path planning using on the hybrid map. Experimental results demonstrated that the hybrid map can reduce the planning time and memory usage compared to the conventional single 2D grid map based path planning.",
        "primary_area": "",
        "author": "Shun Niijima;Ryusuke Umeyama;Yoko Sasaki;Hiroshi Mizoguchi;Shun Niijima;Ryusuke Umeyama;Yoko Sasaki;Hiroshi Mizoguchi",
        "authorids": "/37086449149;/37088688036;/37418160900;/37273843100;/37086449149;/37088688036;/37418160900;/37273843100",
        "aff": "National Institute of Advanced Industrial Science and Technology, Tokyo, Japan; National Institute of Advanced Industrial Science and Technology, Tokyo, Japan; National Institute of Advanced Industrial Science and Technology, Tokyo, Japan; National Institute of Advanced Industrial Science and Technology, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340990/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12751699146874151812&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "National Institute of Advanced Industrial Science and Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.aist.go.jp",
        "aff_unique_abbr": "AIST",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9340930",
        "title": "Cleaning Robot Operation Decision Based on Causal Reasoning and Attribute Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "In order to improve the operation ability of cleaning robots, this paper proposes a decision method for cleaning robot\u2019s operation mode. Firstly, we use the hierarchical expression ability of deep network to obtain the attributes of garbage such as state, shape, distribution, size and so on. Then the causal relationship between the attributes and the operation modes can be built by using joint learning of association attributes with depth network model and causal inference. Based on this, a fuzzy inference decision network is designed. With the help of causal analysis, the structure of the decision model is greatly simplified. Compared with conventional fuzzy neural networks, the total parameters of the model are reduced by 2 / 3. The method proposed in this paper imitates the way that human dispose of different types of garbage and has good interpretability. The experimental results verify the effectiveness of the proposed method.",
        "primary_area": "",
        "author": "Yapeng Li;Dongbo Zhang;Feng Yin;Ying Zhang;Yapeng Li;Dongbo Zhang;Feng Yin;Ying Zhang",
        "authorids": "/37088516402;/37834313100;/37088517541;/37085637382;/37088516402;/37834313100;/37088517541;/37085637382",
        "aff": "Institute of Automation and Electronic Information, Xiangtan University, Xiangtan, China; Institute of National Engineering Laboratory of Robot Vision Perception and Control Technology, Xiangtan University, Xiangtan, China; Institute of National Engineering Laboratory of Robot Vision Perception and Control Technology, Xiangtan University, Xiangtan, China; Institute of National Engineering Laboratory of Robot Vision Perception and Control Technology, Xiangtan University, Xiangtan, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340930/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10575752292753193156&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Xiangtan University",
        "aff_unique_dep": "Institute of Automation and Electronic Information",
        "aff_unique_url": "http://www.xtu.edu.cn/",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Xiangtan",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9341663",
        "title": "Closing the Loop: Real-Time Perception and Control for Robust Collision Avoidance with Occluded Obstacles",
        "track": "main",
        "status": "Poster",
        "abstract": "Robots have been successfully used in well-structured and deterministic environments, but they are still unable to function in unstructured environments mainly because of missing reliable real-time systems that integrate perception and control. In this paper, we close the loop between perception and control for real-time obstacle avoidance by introducing a new robust perception algorithm and a new collision avoidance strategy, which combines local artificial potential fields with global elastic planning to maintain the convergence towards the goal. We evaluate our new approach in real-world experiments using a Franka Panda robot and show that it is able to robustly avoid dynamic or even partially occluded obstacles while performing position or path following tasks.",
        "primary_area": "",
        "author": "Andreea Tulbure;Oussama Khatib;Andreea Tulbure;Oussama Khatib",
        "authorids": "/37086133908;/37283150000;/37086133908;/37283150000",
        "aff": "Stanford Robotics Lab, Stanford, CA, USA; Stanford Robotics Lab, Stanford, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341663/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14041982759057417798&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "Robotics Lab",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341121",
        "title": "Cloth Region Segmentation for Robust Grasp Selection",
        "track": "main",
        "status": "Poster",
        "abstract": "Cloth detection and manipulation is a common task in domestic and industrial settings, yet such tasks remain a challenge for robots due to cloth deformability. Furthermore, in many cloth-related tasks like laundry folding and bed making, it is crucial to manipulate specific regions like edges and corners, as opposed to folds. In this work, we focus on the problem of segmenting and grasping these key regions. Our approach trains a network to segment the edges and corners of a cloth from a depth image, distinguishing such regions from wrinkles or folds. We also provide a novel algorithm for estimating the grasp location, direction, and directional uncertainty from the segmentation. We demonstrate our method on a real robot system and show that it outperforms baseline methods on grasping success. Video and other supplementary materials are available at: https://sites.google.com/view/cloth-segmentation.",
        "primary_area": "",
        "author": "Jianing Qian;Thomas Weng;Luxin Zhang;Brian Okorn;David Held;Jianing Qian;Thomas Weng;Luxin Zhang;Brian Okorn;David Held",
        "authorids": "/37086365807;/37085767512;/37088689225;/37393124300;/37408101800;/37086365807;/37085767512;/37088689225;/37393124300;/37408101800",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341121/",
        "gs_citation": 58,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12046756673430134714&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341219",
        "title": "Clothoid-based Moving Formation Control Using Virtual Structures",
        "track": "main",
        "status": "Poster",
        "abstract": "Formation control is a canonical problem in multi-agent systems as many multi-agent problems require agents to travel in coordination at some point during execution. This paper develops a method for coordinated moving formation control by building upon existing virtual structures approaches to define the relative vehicle positions and orientations and building upon clothoid-based motion planning to create the desired motion of the structure. The result is a coordinated formation control method that respects individual curvature constraints of each agent while allowing agents to track their desired positions within the formation with asymptotic convergence.",
        "primary_area": "",
        "author": "Brian Merrell;Greg Droge;Brian Merrell;Greg Droge",
        "authorids": "/37088486074;/37949403300;/37088486074;/37949403300",
        "aff": "Department of Electrical and Computer Engineering, Utah State University, Logan, UT, USA; Department of Electrical and Computer Engineering, Utah State University, Logan, UT, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341219/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12120306474563598945&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Utah State University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.usu.edu",
        "aff_unique_abbr": "USU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Logan",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340857",
        "title": "CoBigICP: Robust and Precise Point Set Registration using Correntropy Metrics and Bidirectional Correspondence",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a novel probabilistic variant of iterative closest point (ICP) dubbed as CoBigICP. The method leverages both local geometrical information and global noise characteristics. Locally, the 3D structure of both target and source clouds are incorporated into the objective function through bidirectional correspondence. Globally, error metric of correntropy is introduced as noise model to resist outliers. Importantly, the close resemblance between normal-distributions transform (NDT) and correntropy is revealed. To ease the minimization step, an on-manifold parameterization of the special Euclidean group is proposed. Extensive experiments validate that CoBigICP outperforms several well-known and state-of-the-art methods.",
        "primary_area": "",
        "author": "Pengyu Yin;Di Wang;Shaoyi Du;Shihui Ying;Yue Gao;Nanning Zheng;Pengyu Yin;Di Wang;Shaoyi Du;Shihui Ying;Yue Gao;Nanning Zheng",
        "authorids": "/37088687728;/37086061043;/37577669900;/37943249200;/37421869300;/37271536700;/37088687728;/37086061043;/37577669900;/37943249200;/37421869300;/37271536700",
        "aff": "Artificial Intelligence and Robotics, College of Artificial Intelligence, Xi\u2019an Jiaotong University, Shaanxi, P.R. China; Artificial Intelligence and Robotics, College of Artificial Intelligence, Xi\u2019an Jiaotong University, Shaanxi, P.R. China; Artificial Intelligence and Robotics, College of Artificial Intelligence, Xi\u2019an Jiaotong University, Shaanxi, P.R. China; Shanghai University, Shanghai, P.R. China; Tsinghua University, Beijing, P.R. China; Artificial Intelligence and Robotics, College of Artificial Intelligence, Xi\u2019an Jiaotong University, Shaanxi, P.R. China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340857/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1398432276419709664&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;2;0",
        "aff_unique_norm": "Xi'an Jiaotong University;Shanghai University;Tsinghua University",
        "aff_unique_dep": "College of Artificial Intelligence;;",
        "aff_unique_url": "http://www.xjtu.edu.cn;https://www.shu.edu.cn;https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "XJTU;SHU;THU",
        "aff_campus_unique_index": "0;0;0;1;2;0",
        "aff_campus_unique": "Xi'an;Shanghai;Beijing",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9341369",
        "title": "Collaborative Interaction Models for Optimized Human-Robot Teamwork",
        "track": "main",
        "status": "Poster",
        "abstract": "Effective human-robot collaboration requires informed anticipation. The robot must anticipate the human\u2019s actions, but also react quickly and intuitively when its predictions are wrong. The robot must plan its actions to account for the human\u2019s own plan, with the knowledge that the human\u2019s behavior will change based on what the robot actually does. This cyclical game of predicting a human\u2019s future actions and generating a corresponding motion plan is extremely difficult to model using standard techniques. In this work, we describe a novel Model Predictive Control (MPC)-based framework for finding optimal trajectories in a collaborative, multi-agent setting, in which we simultaneously plan for the robot while predicting the actions of its external collaborators. We use human-robot handovers to demonstrate that with a strong model of the collaborator, our framework produces fluid, reactive human-robot interactions in novel, cluttered environments. Our method efficiently generates coordinated trajectories, and achieves a high success rate in handover, even in the presence of significant sensor noise.",
        "primary_area": "",
        "author": "Adam Fishman;Chris Paxton;Wei Yang;Dieter Fox;Byron Boots;Nathan Ratliff;Adam Fishman;Chris Paxton;Wei Yang;Dieter Fox;Byron Boots;Nathan Ratliff",
        "authorids": "/37088690696;/37085403975;/37069403600;/37284329000;/37085459219;/37579950900;/37088690696;/37085403975;/37069403600;/37284329000;/37085459219;/37579950900",
        "aff": "University of Washington; NVIDIA; NVIDIA; University of Washington; University of Washington; NVIDIA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341369/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1813002641998694970&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;0;0;1",
        "aff_unique_norm": "University of Washington;NVIDIA Corporation",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.washington.edu;https://www.nvidia.com",
        "aff_unique_abbr": "UW;NVIDIA",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341212",
        "title": "Collaborative Programming of Conditional Robot Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "Conventional robot programming methods are not suited for non-experts to intuitively teach robots new tasks. For this reason, the potential of collaborative robots for production cannot yet be fully exploited. In this work, we propose an active learning framework, in which the robot and the user collaborate to incrementally program a complex task. Starting with a basic model, the robot's task knowledge can be extended over time if new situations require additional skills. An on-line anomaly detection algorithm therefore automatically identifies new situations during task execution by monitoring the deviation between measured- and commanded sensor values. The robot then triggers a teaching phase, in which the user decides to either refine an existing skill or demonstrate a new skill. The different skills of a task are encoded in separate probabilistic models and structured in a high-level graph, guaranteeing robust execution and successful transition between skills. In the experiments, our approach is compared to two state-of-the-art Programming by Demonstration frameworks on a real system. Increased intuitiveness and task performance of the method can be shown, allowing shop-floor workers to program industrial tasks with our framework.",
        "primary_area": "",
        "author": "Christoph Willibald;Thomas Eiband;Dongheui Lee;Christoph Willibald;Thomas Eiband;Dongheui Lee",
        "authorids": "/37088687395;/37086126374;/37068725100;/37088687395;/37086126374;/37068725100",
        "aff": "German Aerospace Center (DLR), Institute of Robotics and Mechatronics, Wessling, Germany; German Aerospace Center (DLR), Institute of Robotics and Mechatronics, Wessling, Germany; Chair of Human-centered Assistive Robotics, Technical University of Munich, Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341212/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13542983765351597692&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "German Aerospace Center (DLR);Technical University of Munich",
        "aff_unique_dep": "Institute of Robotics and Mechatronics;Chair of Human-centered Assistive Robotics",
        "aff_unique_url": "https://www.dlr.de;https://www.tum.de",
        "aff_unique_abbr": "DLR;TUM",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Munich",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9340970",
        "title": "Collaborative Semantic Perception and Relative Localization Based on Map Matching",
        "track": "main",
        "status": "Poster",
        "abstract": "In order to enable a team of robots to operate successfully, retrieving accurate relative transformation between robots is the fundamental requirement. So far, most research on relative localization mainly focus on geometry features such as points, lines and planes. To address this problem, collaborative semantic map matching is proposed to perform semantic perception and relative localization. This paper performs semantic perception, probabilistic data association and nonlinear optimization within an integrated framework. Since the voxel correspondence between partial maps is a hidden variable, a probabilistic semantic data association algorithm is proposed based on Expectation-Maximization. Instead of specifying hard geometry data association, semantic and geometry association are jointly updated and estimated. The experimental verification on Semantic KITTI benchmarks demonstrate the improved robustness and accuracy.",
        "primary_area": "",
        "author": "Yufeng Yue;Chunyang Zhao;Mingxing Wen;Zhenyu Wu;Danwei Wang;Yufeng Yue;Chunyang Zhao;Mingxing Wen;Zhenyu Wu;Danwei Wang",
        "authorids": "/37086172414;/37088406475;/37086451677;/37088406849;/37279547600;/37086172414;/37088406475;/37086451677;/37088406849;/37279547600",
        "aff": "School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340970/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4156521976424540093&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Nanyang Technological University",
        "aff_unique_dep": "School of Electrical and Electronic Engineering",
        "aff_unique_url": "https://www.ntu.edu.sg",
        "aff_unique_abbr": "NTU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Singapore",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "9341248",
        "title": "Collision Avoidance in Human-Robot Interaction Using Kinect Vision System Combined With Robot\u2019s Model and Data",
        "track": "main",
        "status": "Poster",
        "abstract": "Human-Robot Interaction (HRI) is a largely ad-dressed subject today. Collision avoidance is one of main strategies that allow space sharing and interaction without contact between human and robot. It is thus usual to use a 3D depth camera sensor which may involves issues related to occluded robot in camera view. While several works overcame this issue by applying infinite depth principle or increasing the number of cameras, we developed in the current work a new and an original approach based on the combination of a 3D depth sensor (Microsoft\u00ae Kinect V2) and the proprioceptive robot position sensors. This method uses a principle of limited safety contour around the obstacle to dynamically estimate the robot-obstacle distance, and then generate the repulsive force that controls the robot. For validation, our approach is applied in real time to avoid collision between dynamical obstacles (humans or objects) and the end-effector of a real 7-dof Kuka LBR iiwa collaborative robot.Several strategies based on distancing and its combination with dodging were tested. Results have shown a reactive and efficient collision avoidance, by ensuring a minimum obstacle-robot distance (of \u2248 240mm), even when the robot is in an occluded zone in the Kinect camera view.",
        "primary_area": "",
        "author": "Hugo Nascimento;Martin Mujica;Mourad Benoussaad;Hugo Nascimento;Martin Mujica;Mourad Benoussaad",
        "authorids": "/37085934591;/37088506956;/37586646300;/37085934591;/37088506956;/37586646300",
        "aff": "LGP-ENIT, University of Toulouse, Tarbes, France; LGP-ENIT, University of Toulouse, Tarbes, France; LGP-ENIT, University of Toulouse, Tarbes, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341248/",
        "gs_citation": 37,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18388042388685351440&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Toulouse",
        "aff_unique_dep": "LGP-ENIT",
        "aff_unique_url": "https://www.univ-toulouse.fr",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Tarbes",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9341221",
        "title": "Collision Reaction Through Internal Stress Loading in Cooperative Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Cooperative manipulation offers many advantages over single-arm manipulation. However, this comes at a cost of added complexity, both in modeling and control of multi-arm systems. Much research has been focused on determining optimal load distribution strategies based on several objective functions, some of which include manipulability, energy consumption and joint torque minimization. This paper presents an internal loading strategy that is subject to the estimate of the external disturbances along the body of one or more of the arms involved in the manipulation process. The authors of this paper propose a reaction strategy to external disturbances by transforming the disturbance forces into internal forces on the object through appropriate load distribution on the cooperative arms. The goal is to have a set-point on the object, track a given trajectory while compensating for external disturbances along the links of some of the robot arms involved in the cooperative manipulation.",
        "primary_area": "",
        "author": "Victor Aladele;Seth Hutchinson;Victor Aladele;Seth Hutchinson",
        "authorids": "/37088687995;/37282386200;/37088687995;/37282386200",
        "aff": "Department of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA; Department of Interactive Computing, Georgia Institute of Technology, Atlanta, GA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341221/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7771180101982293399&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Georgia Institute of Technology",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.gatech.edu",
        "aff_unique_abbr": "Georgia Tech",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Atlanta",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341599",
        "title": "Collision Risk Assessment via Awareness Estimation Toward Robotic Attendant",
        "track": "main",
        "status": "Poster",
        "abstract": "With the aim of contributing to the development of a robotic attendant system, this study proposes the concept of assessing the risk of collision using awareness estimation. The proposed approach enables an attendant robot to assess a person's risk of colliding with an obstacle by estimating whether he/she is aware of it based on behavior, and to take the requisite preventative action. To implement the proposed concept, we design a model that can simultaneously estimate a person's awareness of obstacles and predict his/her trajectory based on a convolutional neural network. When trained on a dataset of collision-related behaviors generated from people trajectory datasets, the model can detect objects of which the person is not aware and with which he/she at risk of colliding. The proposed method was evaluated in an empirical environment, and the results verified its effectiveness.",
        "primary_area": "",
        "author": "Kenji Koide;Jun Miura;Kenji Koide;Jun Miura",
        "authorids": "/37086179385;/37328632700;/37086179385;/37328632700",
        "aff": "Department of Information Technology and Human Factors, the National Institute of Advanced Industrial Science and Technology, Tsukuba, Ibaraki, Japan; Department of Computer Science and Engineering, Toyohashi University of Technology, Aichi, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341599/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3654007783018410710&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "National Institute of Advanced Industrial Science and Technology;Toyohashi University of Technology",
        "aff_unique_dep": "Department of Information Technology and Human Factors;Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.aist.go.jp;https://www.tut.ac.jp",
        "aff_unique_abbr": "AIST;TUT",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Tsukuba;Toyohashi",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9341126",
        "title": "Collision-Free Distributed Multi-Target Tracking Using Teams of Mobile Robots with Localization Uncertainty",
        "track": "main",
        "status": "Poster",
        "abstract": "Accurately tracking dynamic targets relies on robots accounting for uncertainties in their own states to share information and maintain safety. The problem becomes even more challenging when there is an unknown and time-varying number of targets in the environment. In this paper we address this problem by introducing four new distributed algorithms that allow large teams of robots to: i) run the prediction and ii) update steps of a distributed recursive Bayesian multi- target tracker, iii) determine the set of local neighbors that must exchange data, and iv) exchange data in a consistent manner. All of these algorithms account for a bounded level of localization uncertainty in the robots by leveraging our recent introduction of the convex uncertainty Voronoi (CUV) diagram, which extends the traditional Voronoi diagram to account for localization uncertainty. The CUV diagram introduces a tessellation over the environment, which we use in this work both to distribute the multi-target tracker and to make control decisions about where to search next. We examine the efficacy of our method via a series of simulations and compare them to our previous work which assumed perfect localization.",
        "primary_area": "",
        "author": "Jun Chen;Philip Dames;Jun Chen;Philip Dames",
        "authorids": "/37088479962;/38547257300;/37088479962;/38547257300",
        "aff": "Department of Mechanical Engineering, Temple University, Philadelphia, PA, USA; Department of Mechanical Engineering, Temple University, Philadelphia, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341126/",
        "gs_citation": 36,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12302791111149862764&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Temple University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.temple.edu",
        "aff_unique_abbr": "Temple",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Philadelphia",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340869",
        "title": "Combining Compliance Control, CAD Based Localization, and a Multi-Modal Gripper for Rapid and Robust Programming of Assembly Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "Current trends in industrial automation favor agile systems that allow adaptation to rapidly changing task requirements and facilitate customized production in smaller batches. This work presents a flexible manufacturing system relying on compliance control, CAD based localization, and a multi-modal gripper to enable fast and efficient task programming for assembly operations. CAD file processing is employed to extract component pose data from 3D assembly models, while the system's active compliance compensates for errors in calibration or positioning. To minimize retooling delays, a novel gripper design incorporating both a parallel jaw element and a rotating module is proposed. The developed system placed first in the manufacturing track of the Robotic Grasping and Manipulation Competition of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) 2019, experimentally validating its efficiency.",
        "primary_area": "",
        "author": "Gal Gorjup;Geng Gao;Anany Dwivedi;Minas Liarokapis;Gal Gorjup;Geng Gao;Anany Dwivedi;Minas Liarokapis",
        "authorids": "/37087237844;/37087027460;/37086133073;/38558084100;/37087237844;/37087027460;/37086133073;/38558084100",
        "aff": "Department of Mechanical Engineering, New Dexterity research group, The University of Auckland, New Zealand; Department of Mechanical Engineering, New Dexterity research group, The University of Auckland, New Zealand; Department of Mechanical Engineering, New Dexterity research group, The University of Auckland, New Zealand; Department of Mechanical Engineering, New Dexterity research group, The University of Auckland, New Zealand",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340869/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12567915647285493459&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "The University of Auckland",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.auckland.ac.nz",
        "aff_unique_abbr": "UoA",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "New Zealand"
    },
    {
        "id": "9341159",
        "title": "Comparing Visual Odometry Systems in Actively Deforming Simulated Colon Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a new open-source dataset with ground truth position in a simulated colon environment to promote development of real-time feedback systems for physicians performing colonoscopies. Four systems (DSO, LSD-SLAM, SfMLearner, ORB-SLAM2) are tested on this dataset and their failures are analyzed. A data collection platform was fabricated and used to take the dataset in a colonoscopy training simulator that was affixed to a flat surface. The noise in the ground truth positional data induced from the metal in the data collection platform was then characterized and corrected. The Absolute Trajectory RMSE Error (ATE) and Relative Error (RE) metrics were performed on each of the sequences in the dataset for each of the Simultaneous Localization And Mapping (SLAM) systems. While these systems all had good performance in idealized conditions, more realistic conditions in the harder sequences caused them to produce poor results or fail completely. These failures will be a hindrance to physicians in a real-world scenario, so future systems made for this environment must be more robust to the difficulties found in the colon, even at the expense of trajectory accuracy. The authors believe that this is the first open-source dataset with groundtruth data displaying a simulated in vivo environment with active deformation, and that this is the first step toward achieving useful SLAM within the colon. The dataset is available at www.colorado.edu/lab/amtl/datasets.",
        "primary_area": "",
        "author": "Mitchell J. Fulton;J. Micah Prendergast;Emily R. DiTommaso;Mark E. Rentschler;Mitchell J. Fulton;J. Micah Prendergast;Emily R. DiTommaso;Mark E. Rentschler",
        "authorids": "/37088691494;/37088686453;/37088688753;/37396717100;/37088691494;/37088686453;/37088688753;/37396717100",
        "aff": "Department of Mechanical Engineering, University of Colorado Boulder, Boulder, CO, USA; Department of Mechanical Engineering, University of Colorado Boulder, Boulder, CO, USA; Department of Electrical, Computer, and Energy Engineering, University of Colorado Boulder, Boulder, CO, USA; Department of Mechanical Engineering, University of Colorado Boulder, Boulder, CO, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341159/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13333274301470957670&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Colorado Boulder",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.colorado.edu",
        "aff_unique_abbr": "CU Boulder",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Boulder",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341141",
        "title": "Comparison between Stationary and Crawling Multi-Arm Robotics for In-Space Assembly",
        "track": "main",
        "status": "Poster",
        "abstract": "In-space assembly (ISA) is the next step to building larger and more permanent structures in orbit. The use of a robotic in-space assembler saves on costly and potentially risky EVAs. Determining the best robot for ISA is difficult as it will depend on the structure being assembled. A comparison between two categories of robots is presented: a stationary robot and robot which crawls along the truss. The estimated mass, energy, and time are presented for each system as it, in simulation, builds a desired truss system. There are trade-offs to every robot design and understanding those trade-offs is essential to building a system that is not only efficient but also cost-effective.",
        "primary_area": "",
        "author": "Katherine McBryan;Katherine McBryan",
        "authorids": "/38529231600;/38529231600",
        "aff": "US Naval Research Laboratory, Washington DC, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341141/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4927779290363138012&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 2,
        "aff_unique_index": "0",
        "aff_unique_norm": "US Naval Research Laboratory",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.nrl.navy.mil",
        "aff_unique_abbr": "NRL",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Washington DC",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340903",
        "title": "Competitive Coverage: (Full) Information as a Game Changer",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper introduces the competitive coverage problem, a new variant of the robotic coverage problem in which a robot R competes with another robot O in order to be the first to cover an area. In the variant discussed in this paper, the asymmetric competitive coverage, O is unaware of the existence of R, which attempts to take that fact into consideration in order to succeed in being the first to cover as many parts of the environment as possible. We consider different information models of R that define how much it knows about the location of O and its planned coverage path. We present an optimal algorithm for R in the full-information case, and show that unless R has information about O's initial location, it is as if it has no information at all. Lastly, we describe a correlation between the time it takes R to reach O's initial location and the coverage paths quality, and present a heuristic algorithm for the case in which R has information only about O's initial location, showing its superiority compared to other coverage algorithms in rigorous simulation experiments.",
        "primary_area": "",
        "author": "Moshe N. Samson;Noa Agmon;Moshe N. Samson;Noa Agmon",
        "authorids": "/37088687869;/37695468400;/37088687869;/37695468400",
        "aff": "Computer Science Department, Bar-Ilan University, Ramat Gan, Israel; Computer Science Department, Bar-Ilan University, Ramat Gan, Israel",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340903/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12851355416369957804&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Bar-Ilan University",
        "aff_unique_dep": "Computer Science Department",
        "aff_unique_url": "https://www.biu.ac.il",
        "aff_unique_abbr": "BIU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Ramat Gan",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Israel"
    },
    {
        "id": "9340786",
        "title": "Completeness Seeking Probabilistic Coverage Estimation using Uncertain State Estimates",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper develops a coverage-centric adaptive path planner to visually survey a planar environment. This is achieved by modifying an existing path planning architecture to use a novel coverage estimation approach called convolved coverage estimation (CCE). The planner maximizes the probability of terrain coverage and exploits terrain features for loop closure to keep path uncertainty in check. The developed algorithm considers multi-dimensional uncertainty, operates in real-time, and does not require external correction methods like GPS. These characteristics are validated in high-fidelity simulation and flight tests on an unmanned aerial vehicle (UAV).",
        "primary_area": "",
        "author": "Aditya Mahajan;Stephen Rock;Aditya Mahajan;Stephen Rock",
        "authorids": "/37086014914;/37267840600;/37086014914;/37267840600",
        "aff": "Department of Aeronautics & Astronautics, Stanford University, Stanford, CA, United States; Monterey Bay Aquarium Research Institute, Moss Landing, CA, United States",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340786/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6931039744947422815&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Stanford University;Monterey Bay Aquarium Research Institute",
        "aff_unique_dep": "Department of Aeronautics & Astronautics;",
        "aff_unique_url": "https://www.stanford.edu;https://www.mbARI.org",
        "aff_unique_abbr": "Stanford;MBARI",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Stanford;Moss Landing",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340703",
        "title": "Compliance Control of a Cable-Suspended Aerial Manipulator using Hierarchical Control Framework",
        "track": "main",
        "status": "Poster",
        "abstract": "Aerial robotic manipulation is an emergent trend that poses several challenges. To overcome some of these, the DLR cable-Suspended Aerial Manipulator (SAM) has been envisioned. SAM is composed of a fully actuated multi-rotor anchored to a main carrier through a cable and a KUKA LWR attached below the multi-rotor. This work presents a control method to allow SAM, which is a holonomically constrained system, to perform such interaction tasks using a hierarchical control framework. Within this framework, compliance control of the manipulator end-effector is considered to have the highest priority. The second priority is the control of the oscillations induced by, for example, the motion of the arm or physical contact with the environment. A third priority task is related to the internal motion of the manipulator. The proposed approach is validated through simulations and experiments.",
        "primary_area": "",
        "author": "Chiara Gabellieri;Yuri S Sarkisov;Andre Coelho;Lucia Pallottino;Konstantin Kondak;Min Jun Kim;Chiara Gabellieri;Yuri S Sarkisov;Andre Coelho;Lucia Pallottino;Konstantin Kondak;Min Jun Kim",
        "authorids": "/37086361091;/37086345232;/37086573823;/37278580100;/37427143400;/38239144100;/37086361091;/37086345232;/37086573823;/37278580100;/37427143400;/38239144100",
        "aff": "Dipartimento di Ingegneria dell\u2019Informazione, Centro di Ricerca E. Piaggio, Universit\u00e0 di Pisa, Pisa, Italia; Space CREI, Skolkovo Institute of Science and Technology (Skoltech), Moscow, Russia; German Aerospace Center (DLR), Institute of Robotics and Mechatronics, Wessling, Germany; Dipartimento di Ingegneria dell\u2019Informazione, Centro di Ricerca E. Piaggio, Universit\u00e0 di Pisa, Pisa, Italia; German Aerospace Center (DLR), Institute of Robotics and Mechatronics, Wessling, Germany; German Aerospace Center (DLR), Institute of Robotics and Mechatronics, Wessling, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340703/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1550382396934730532&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;0;2;2",
        "aff_unique_norm": "Universit\u00e0 di Pisa;Skolkovo Institute of Science and Technology;German Aerospace Center (DLR)",
        "aff_unique_dep": "Dipartimento di Ingegneria dell\u2019Informazione;Space CREI;Institute of Robotics and Mechatronics",
        "aff_unique_url": "https://www.unipi.it;https://www.skoltech.ru;https://www.dlr.de",
        "aff_unique_abbr": "UniPi;Skoltech;DLR",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Pisa;Moscow;",
        "aff_country_unique_index": "0;1;2;0;2;2",
        "aff_country_unique": "Italy;Russia;Germany"
    },
    {
        "id": "9341027",
        "title": "Computational Design of Balanced Open Link Planar Mechanisms with Counterweights from User Sketches",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider the design of under-actuated articulated mechanism that are able to maintain stable static balance. Our method augments an user-provided design with counter-weights whose mass and attachment locations are automatically computed. The optimized counterweights adjust the center of gravity such that, for bounded external perturbations, the mechanism returns to its original configuration. Using our sketch-based system, we present several examples illustrating a wide range of user-provided designs can be successfully converted into statically-balanced mechanisms. We further validate our results with a set of physical prototypes.",
        "primary_area": "",
        "author": "Takuto Takahashi;Hiroshi G. Okuno;Shigeki Sugano;Stelian Coros;Bernhard Thomaszewski;Takuto Takahashi;Hiroshi G. Okuno;Shigeki Sugano;Stelian Coros;Bernhard Thomaszewski",
        "authorids": "/37086576201;/37273831200;/37274050800;/37077396200;/37087059770;/37086576201;/37273831200;/37274050800;/37077396200;/37087059770",
        "aff": "Department of Computer Science and Operations Research, Universit\u00e9 de Montr\u00e9al, Canada; Department of Modern Mechanical Engineering, Waseda University, Japan; Department of Modern Mechanical Engineering, Waseda University, Japan; Department of Computer Science, ETH Zurich, Switzerland; Department of Computer Science and Operations Research, Universit\u00e9 de Montr\u00e9al, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341027/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7992743000980295300&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;2;0",
        "aff_unique_norm": "Universit\u00e9 de Montr\u00e9al;Waseda University;ETH Zurich",
        "aff_unique_dep": "Department of Computer Science and Operations Research;Department of Modern Mechanical Engineering;Department of Computer Science",
        "aff_unique_url": "https://www.umontreal.ca;https://www.waseda.jp/top;https://www.ethz.ch",
        "aff_unique_abbr": "UdeM;Waseda;ETHZ",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;1;2;0",
        "aff_country_unique": "Canada;Japan;Switzerland"
    },
    {
        "id": "9340778",
        "title": "Computationally Efficient Obstacle Avoidance Trajectory Planner for UAVs Based on Heuristic Angular Search Method",
        "track": "main",
        "status": "Poster",
        "abstract": "For accomplishing a variety of missions in challenging environments, the capability of navigating with full autonomy while avoiding unexpected obstacles is the most crucial requirement for UAVs in real applications. In this paper, we proposed such a computationally efficient obstacle avoidance trajectory planner that can be used in unknown cluttered environments. Because of the narrow view field of single depth camera on a UAV, the information of obstacles around is quite limited thus the shortest entire path is difficult to achieve. Therefore we focus on the time cost of the trajectory planner and safety rather than other factors. This planner is mainly composed of a point cloud processor, a waypoint publisher with Heuristic Angular Search(HAS) method and a motion planner with minimum acceleration optimization. Furthermore, we propose several techniques to enhance safety by making the possibility of finding a feasible trajectory as large as possible. The proposed approach is implemented to run onboard in real-time and is tested extensively in simulation and the average control output calculating time of iteration steps is less than 18 ms.",
        "primary_area": "",
        "author": "Han Chen;Peng Lu;Han Chen;Peng Lu",
        "authorids": "/37087245382;/37087243038;/37087245382;/37087243038",
        "aff": "The Adaptive Robotic Controls Lab (ArcLab), Hong Kong Polytechnic University, Hung Hom, Kowloon, Hong Kong, China; Department of Mechanical Engineering, The University of Hong Kong, Pokfulam, Hong Kong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340778/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12607431573208368902&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Hong Kong Polytechnic University;The University of Hong Kong",
        "aff_unique_dep": "The Adaptive Robotic Controls Lab (ArcLab);Department of Mechanical Engineering",
        "aff_unique_url": "https://www.polyu.edu.hk;https://www.hku.hk",
        "aff_unique_abbr": "PolyU;HKU",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Hung Hom, Kowloon;Pokfulam",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9341144",
        "title": "Computing High-Quality Clutter Removal Solutions for Multiple Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "We investigate the task and motion planning problem of clearing clutter from a workspace with limited ingress/egress access for multiple robots. We call the problem multi-robot clutter removal (MRCR). Targeting practical applications where motion planning is non-trivial but is not a bottle-neck, we focus on finding high-quality solutions for feasible MRCR instances, which depends on the ability to efficiently compute high-quality object removal sequences. Despite the challenging multi-robot setting, our proposed search algorithms based on A*, dynamic programming, and best-first heuristics all produce solutions for tens of objects that significantly outperform single robot solutions. Realistic simulations with multiple Kuka youBots further confirms the effectiveness of our algorithmic solutions. In contrast, we also show that deciding the optimal object removal sequence for MRCR is computationally intractable.",
        "primary_area": "",
        "author": "Wei N. Tang;Shuai D. Han;Jingjin Yu;Wei N. Tang;Shuai D. Han;Jingjin Yu",
        "authorids": "/37086100283;/37086094452;/37536570700;/37086100283;/37086094452;/37536570700",
        "aff": "Department of Computer Science, Rutgers, the State University of New Jersey, Piscataway, NJ, USA; Department of Computer Science, Rutgers, the State University of New Jersey, Piscataway, NJ, USA; Department of Computer Science, Rutgers, the State University of New Jersey, Piscataway, NJ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341144/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7959576849450247162&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Rutgers, the State University of New Jersey",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://rutgers.edu",
        "aff_unique_abbr": "Rutgers",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Piscataway",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341188",
        "title": "Confidence Guided Stereo 3D Object Detection with Split Depth Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Accurate and reliable 3D object detection is vital to safe autonomous driving. Despite recent developments, the performance gap between stereo-based methods and LiDAR-based methods is still considerable. Accurate depth estimation is crucial to the performance of stereo-based 3D object detection methods, particularly for those pixels associated with objects in the foreground. Moreover, stereo-based methods suffer from high variance in the depth estimation accuracy, which is often not considered in the object detection pipeline. To tackle these two issues, we propose CG-Stereo, a confidence-guided stereo 3D object detection pipeline that uses separate decoders for foreground and background pixels during depth estimation, and leverages the confidence estimation from the depth estimation network as a soft attention mechanism in the 3D object detector. Our approach outperforms all state-of-the-art stereo-based 3D detectors on the KITTI benchmark.",
        "primary_area": "",
        "author": "Chengyao Li;Jason Ku;Steven L. Waslander;Chengyao Li;Jason Ku;Steven L. Waslander",
        "authorids": "/37087015492;/37087234619;/37301169100;/37087015492;/37087234619;/37301169100",
        "aff": "University of Toronto Institute for Aerospace Studies; University of Toronto Institute for Aerospace Studies; University of Toronto Institute for Aerospace Studies",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341188/",
        "gs_citation": 64,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18081458795137581815&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Toronto",
        "aff_unique_dep": "Institute for Aerospace Studies",
        "aff_unique_url": "https://www.utoronto.ca",
        "aff_unique_abbr": "UTIAS",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Toronto",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9341526",
        "title": "Configuration Space Decomposition for Learning-based Collision Checking in High-DOF Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Motion planning for robots of high degrees-of-freedom (DOFs) is an important problem in robotics with sampling-based methods in configuration space \\mathcal{C}\\mathcal{C} as one popular solution. Recently, machine learning methods have been introduced into sampling-based motion planning methods, which train a classifier to distinguish collision free subspace from in-collision subspace in \\mathcal{C}\\mathcal{C}. In this paper, we propose a novel configuration space decomposition method and show two nice properties resulted from this decomposition. Using these two properties, we build a composite classifier that works compatibly with previous machine learning methods by using them as the elementary classifiers. Experimental results are presented, showing that our composite classifier outperforms state-of-the-art single-classifier methods by a large margin. A real application of motion planning in a multi-robot system in plant phenotyping using three UR5 robotic arms is also presented.",
        "primary_area": "",
        "author": "Yiheng Han;Wang Zhao;Jia Pan;Yong-Jin Liu;Yiheng Han;Wang Zhao;Jia Pan;Yong-Jin Liu",
        "authorids": "/37086529078;/37087232745;/37535628800;/37279426700;/37086529078;/37087232745;/37535628800;/37279426700",
        "aff": "Department of Computer Science and Technology, BNRist, MOE-Key Laboratory of Pervasive Computing, Tsinghua University, Beijing, China; Department of Computer Science and Technology, BNRist, MOE-Key Laboratory of Pervasive Computing, Tsinghua University, Beijing, China; Department of Computer Science, The University of Hong Kong; Department of Computer Science and Technology, BNRist, MOE-Key Laboratory of Pervasive Computing, Tsinghua University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341526/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3295961766613988782&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Tsinghua University;The University of Hong Kong",
        "aff_unique_dep": "Department of Computer Science and Technology;Department of Computer Science",
        "aff_unique_url": "https://www.tsinghua.edu.cn;https://www.hku.hk",
        "aff_unique_abbr": "THU;HKU",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Beijing;Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9340833",
        "title": "Consistent Covariance Pre-Integration for Invariant Filters with Delayed Measurements",
        "track": "main",
        "status": "Poster",
        "abstract": "Sensor fusion systems merging (multiple) delayed sensor signals through a statistical approach are challenging setups, particularly for resource constrained platforms. For statistical consistency, one would be required to keep an appropriate history, apply the correcting signal at the given time stamp in the past, and re-apply all information received until the present time. This re-calculation becomes impractical (the bottleneck being the re-propagation of the covariance matrices for estimator consistency) for platforms with multiple sensors/states and low compute power.This work presents a novel approach for consistent covariance pre-integration allowing delayed sensor signals to be incorporated in a statistically consistent fashion with very low complexity. We leverage recent insights in Invariant Extended Kalman Filters (IEKF) and their log-linear, state independent error propagation together with insights from the scattering theory to mimic the re-calculation process as a medium through which we can propagate waves (covariance information in this case) in single operation steps. We support our findings in simulation and with real data.",
        "primary_area": "",
        "author": "Eren Allak;Alessandro Fornasier;Stephan Weiss;Eren Allak;Alessandro Fornasier;Stephan Weiss",
        "authorids": "/37086580226;/37088685957;/37535323400;/37086580226;/37088685957;/37535323400",
        "aff": "Control of Networked Systems Group, Universit\u00e4t Klagenfurt, Austria; Control of Networked Systems Group, Universit\u00e4t Klagenfurt, Austria; Control of Networked Systems Group, Universit\u00e4t Klagenfurt, Austria",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340833/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9641665544608548793&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Universit\u00e4t Klagenfurt",
        "aff_unique_dep": "Control of Networked Systems Group",
        "aff_unique_url": "https://www.aau.at",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Austria"
    },
    {
        "id": "9341012",
        "title": "Construction of Multiple Hepatic Lobule like 3D Vascular Networks by Manipulating Magnetic Tweezers toward Tissue Engineering",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we have constructed actively perfusable multiple hepatic lobule-like vascular networks in a 3D cellular structure by using magnetic tweezers. Without well-organized channel networks, cells in a large 3D tissue cannot receive nutrients and oxygen from the channel, and therefore, the cells will be dead after few days. To construct well-organized channel networks, we fabricated a hepatic lobule like vascular networks by using magnetic fields in our previous works. However, the size of the hepatic lobule like vascular network was more than five times larger than real hepatic tissue. To improve the previous research, we have proposed several things. First, we have constructed the vascular network having similar size of the real thing in this step. Second, we have cultured the constructed structure for a long-time (more than two weeks) to verify the biocompatible condition. Third, we assemble the constructed hepatic tissues to make a large size of organ, liver. Finally, an actively perfusable system have been adopted to implement a bioreactor system by adding micro pump.",
        "primary_area": "",
        "author": "Eunhye Kim;Masaru Takeuchi;Taro Kozuka;Takuto Nomura;Akihiko Ichikawa;Yasuhisa Hasegawa;Qiang Huang;Toshio Fukuda;Eunhye Kim;Masaru Takeuchi;Taro Kozuka;Takuto Nomura;Akihiko Ichikawa;Yasuhisa Hasegawa;Qiang Huang;Toshio Fukuda",
        "authorids": "/37086347339;/37573622500;/37086345403;/37086346854;/37276491800;/37272575600;/37279982900;/37279174500;/37086347339;/37573622500;/37086345403;/37086346854;/37276491800;/37272575600;/37279982900;/37279174500",
        "aff": "Department of Mechatronics Engineering, Meijo University, Nagoya, Japan; Department of Micro-Nano Systems Engineering, Nagoya University, Nagoya, Japan; Department of Mechatronics Engineering, Meijo University, Nagoya, Japan; Department of Mechatronics Engineering, Meijo University, Nagoya, Japan; Department of Mechatronics Engineering, Meijo University, Nagoya, Japan; Department of Micro-Nano Systems Engineering, Nagoya University, Nagoya, Japan; Beijing Institute of Technology, Beijing, China; Meijo University, Nagoya University and Beijing Institute of Technology, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341012/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:4USj5aisp0IJ:scholar.google.com/&scioq=Construction+of+Multiple+Hepatic+Lobule+like+3D+Vascular+Networks+by+Manipulating+Magnetic+Tweezers+toward+Tissue+Engineering&hl=en&as_sdt=0,5",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;0;0;0;1;2;0",
        "aff_unique_norm": "Meijo University;Nagoya University;Beijing Institute of Technology",
        "aff_unique_dep": "Department of Mechatronics Engineering;Department of Micro-Nano Systems Engineering;",
        "aff_unique_url": "https://www.meijo-u.ac.jp;https://www.nagoya-u.ac.jp;http://www.bit.edu.cn/",
        "aff_unique_abbr": "Meijo;Nagoya U;BIT",
        "aff_campus_unique_index": "0;0;0;0;0;0;1",
        "aff_campus_unique": "Nagoya;Beijing;",
        "aff_country_unique_index": "0;0;0;0;0;0;1;0",
        "aff_country_unique": "Japan;China"
    },
    {
        "id": "9340785",
        "title": "Contact Force Estimation and Regulation of a Position-controlled Floating Base System without Joint Torque Information",
        "track": "main",
        "status": "Poster",
        "abstract": "A floating base system is inevitably to contact the environment while it is moving. This paper explores the contact force estimation and regulation algorithm for a position-controlled floating base system without joint torque information. First, the joint space dynamic model of the system is presented and transformed into the contact space. Then, the inverse dynamics method is employed to estimate the contact forces. After that, a proportional-integral (PI) regulator is designed to drive the contact forces to track the desired values. Finally, the feasibility of this algorithm is demonstrated on a simulated bipedal platform.",
        "primary_area": "",
        "author": "Guoteng Zhang;Shugen Ma;Yibin Li;Guoteng Zhang;Shugen Ma;Yibin Li",
        "authorids": "/37085406403;/37280187400;/37279897500;/37085406403;/37280187400;/37279897500",
        "aff": "School of Control Science and Engineering, Shandong University, Jinan, China; Department of Robotics, Ritsumeikan University, Shiga, Japan; School of Control Science and Engineering, Shandong University, Jinan, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340785/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15154473652717949134&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Shandong University;Ritsumeikan University",
        "aff_unique_dep": "School of Control Science and Engineering;Department of Robotics",
        "aff_unique_url": "http://www.sdu.edu.cn;https://www.ritsumeikan.ac.jp",
        "aff_unique_abbr": "SDU;Ritsumeikan",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Jinan;Shiga",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "China;Japan"
    },
    {
        "id": "9341751",
        "title": "Contact Localization using Velocity Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "Localizing contacts and collisions is an important aspect of failure detection and recovery for robots and can aid perception and exploration of the environment. Contrary to state-of-the-art methods that rely on forces and torques measured on the robot, this paper proposes a kinematic method for proprioceptive contact localization on compliant robots using velocity measurements. The method is validated on two planar robots, the quadrupedal Minitaur and the two-fingered Direct Drive (DD) Hand which are compliant due to inherent transparency from direct drive actuation. Comparisons to other state-of-the-art proprioceptive methods are shown in simulation. Preliminary results on further extensions to complex geometry (through numerical methods) and spatial robots (with a particle filter) are discussed.",
        "primary_area": "",
        "author": "Sean Wang;Ankit Bhatia;Matthew T. Mason;Aaron M. Johnson;Sean Wang;Ankit Bhatia;Matthew T. Mason;Aaron M. Johnson",
        "authorids": "/37088687699;/37085416761;/37273994200;/37589025300;/37088687699;/37085416761;/37273994200;/37589025300",
        "aff": "Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341751/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12536802378824849672&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340709",
        "title": "Contextual Policy Search for Micro-Data Robot Motion Learning through Covariate Gaussian Process Latent Variable Models",
        "track": "main",
        "status": "Poster",
        "abstract": "In the next few years, the amount and variety of context-aware robotic manipulator applications is expected to increase significantly, especially in household environments. In such spaces, thanks to programming by demonstration, non-expert people will be able to teach robots how to perform specific tasks, for which the adaptation to the environment is imperative, for the sake of effectiveness and users safety. These robot motion learning procedures allow the encoding of such tasks by means of parameterized trajectory generators, usually a Movement Primitive (MP) conditioned on contextual variables. However, naively sampled solutions from these MPs are generally suboptimal/inefficient, according to a given reward function. Hence, Policy Search (PS) algorithms leverage the information of the experienced rewards to improve the robot performance over executions, even for new context configurations. Given the complexity of the aforementioned tasks, PS methods face the challenge of exploring in high-dimensional parameter search spaces. In this work, a solution combining Bayesian Optimization, a data-efficient PS algorithm, with covariate Gaussian Process Latent Variable Models, a recent Dimensionality Reduction technique, is presented. It enables reducing dimensionality and exploiting prior demonstrations to converge in few iterations, while also being compliant with context requirements. Thus, contextual variables are considered in the latent search space, from which a surrogate model for the reward function is built. Then, samples are generated in a low-dimensional latent space, and mapped to a context-dependent trajectory. This allows us to drastically reduce the search space with the covariate GPLVM, e.g. from 105 to 2 parameters, plus a few contextual features. Experimentation in two different scenarios proves the data-efficiency and the power of dimensionality reduction of our approach.",
        "primary_area": "",
        "author": "Juan Antonio Delgado-Guerrero;Adri\u00e0 Colom\u00e9;Carme Torras;Juan Antonio Delgado-Guerrero;Adri\u00e0 Colom\u00e9;Carme Torras",
        "authorids": "/37088689591;/38540317200;/37354713800;/37088689591;/38540317200;/37354713800",
        "aff": "Institut de Rob\u00f2tica i Inform\u00e0tica Industrial (IRI), CSIC-UPC, Barcelona, Spain; Institut de Rob\u00f2tica i Inform\u00e0tica Industrial (IRI), CSIC-UPC, Barcelona, Spain; Institut de Rob\u00f2tica i Inform\u00e0tica Industrial (IRI), CSIC-UPC, Barcelona, Spain",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340709/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1614324641030280783&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Institut de Rob\u00f2tica i Inform\u00e0tica Industrial",
        "aff_unique_dep": "IRI",
        "aff_unique_url": "https://www.iri.upc.edu",
        "aff_unique_abbr": "IRI",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Barcelona",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Spain"
    },
    {
        "id": "9341202",
        "title": "Continuous Tension Validation for Cable-Driven Parallel Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper deals with continuous tension validation for Cable-Driven Parallel Robots (CDPRs). The proposed method aims at determining whether or not a quasi-static path is feasible regarding cable tension limits. The available wrench set (AWS) is the set of wrenches that can be generated with cable tensions within given minimum and maximum limits. A pose of the robot is considered valid regarding the tensions if and only if the wrench induced by the platform weight is inside the AWS. The hyperplane shifting method gives a geometric representation of the AWS as the intersection of half-spaces. For each facet-defining hyperplane of the AWS, we define a value which is positive when the pose is valid, i.e. when the corresponding wrench lies on the proper side of the hyperplane. Using this value and an upper bound on its time derivative along the path, the half-length of a valid time interval is obtained. Intervals are repeatedly validated for each hyperplane until either the whole path is validated or a non-valid pose is found. The presented method is integrated within the open-source software Humanoid Path Planner (HPP) and implementation results using the configuration of the CDPR CoGiRo are presented.",
        "primary_area": "",
        "author": "Diane Bury;Jean-Baptiste Izard;Marc Gouttefarde;Florent Lamiraux;Diane Bury;Jean-Baptiste Izard;Marc Gouttefarde;Florent Lamiraux",
        "authorids": "/37087322534;/37391770800;/37542917900;/37279738200;/37087322534;/37391770800;/37542917900;/37279738200",
        "aff": "LAAS-CNRS, University of Toulouse, Toulouse, France; TECNALIA, Basque Research and Technology Alliance (BRTA), Montpellier, France; LIRMM, Universit\u00e9 de Montpellier, CNRS, Montpellier, France; LAAS-CNRS, University of Toulouse, Toulouse, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341202/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11477654380019548525&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "University of Toulouse;TECNALIA;Universit\u00e9 de Montpellier",
        "aff_unique_dep": "LAAS-CNRS;;LIRMM",
        "aff_unique_url": "https://www.univ-toulouse.fr;;https://www.univ-montp2.fr",
        "aff_unique_abbr": ";TECNALIA;UM",
        "aff_campus_unique_index": "0;2;0",
        "aff_campus_unique": "Toulouse;;Montpellier",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9340637",
        "title": "Control Framework for a Hybrid-steel Bridge Inspection Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous navigation of steel bridge inspection robots are essential for proper maintenance. Majority of existing robotic solutions for bridge inspection require human intervention to assist in the control and navigation. In this paper, a control system framework has been proposed for a previously designed ARA robot [1], which facilitates autonomous real-time navigation and minimizes human involvement. The mechanical design and control framework of ARA robot enables two different configurations, namely the mobile and inch-worm transformation. In addition, a switching control was developed with 3D point clouds of steel surfaces as the input which allow the robot to switch between mobile and inch-worm transformation. The surface availability algorithm (considers plane, area and height) of the switching control enables the robot to perform inch-worm jumps autonomously. The mobile transformation allows the robot to move on continuous steel surfaces and perform visual inspection of steel bridge structures. Practical experiments on actual steel bridge structures highlight the effective performance of ARA robot with the proposed control framework for autonomous navigation during visual inspection of steel bridges.",
        "primary_area": "",
        "author": "Hoang-Dung Bui;Son Nguyen;U-H. Billah;Chuong Le;Alireza Tavakkoli;Hung M. La;Hoang-Dung Bui;Son Nguyen;U-H. Billah;Chuong Le;Alireza Tavakkoli;Hung M. La",
        "authorids": "/37088687696;/37087321874;/37088689349;/37088235131;/38048907300;/37542872700;/37088687696;/37087321874;/37088689349;/37088235131;/38048907300;/37542872700",
        "aff": "Department of Computer Science and Engineering, Advanced Robotics and Automation (ARA) Lab, University of Nevada, Reno, NV, USA; Department of Computer Science and Engineering, Advanced Robotics and Automation (ARA) Lab, University of Nevada, Reno, NV, USA; Department of Computer Science and Engineering, Advanced Robotics and Automation (ARA) Lab, University of Nevada, Reno, NV, USA; Department of Computer Science and Engineering, Advanced Robotics and Automation (ARA) Lab, University of Nevada, Reno, NV, USA; Department of Computer Science and Engineering, Advanced Robotics and Automation (ARA) Lab, University of Nevada, Reno, NV, USA; Department of Computer Science and Engineering, Advanced Robotics and Automation (ARA) Lab, University of Nevada, Reno, NV, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340637/",
        "gs_citation": 34,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11259630033019797881&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of Nevada, Reno",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.unr.edu",
        "aff_unique_abbr": "UNR",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Reno",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340875",
        "title": "Control Interface for Hands-free Navigation of Standing Mobility Vehicles based on Upper-Body Natural Movements",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose and evaluate a novel human-machine interface (HMI) for controlling a standing mobility vehicle or person carrier robot, aiming for a hands-free control through upper-body natural postures derived from gaze tracking while walking. We target users with lower-body impairment with remaining upper-body motion capabilities. The developed HMI bases on a sensing array for capturing body postures; an intent recognition algorithm for continuous mapping of body motions to robot control space; and a personalizing system for multiple body sizes and shapes. We performed two user studies: first, an analysis of the required body muscles involved in navigating with the proposed control; and second, an assessment of the HMI compared with a standard joystick through quantitative and qualitative metrics in a narrow circuit task. We concluded that the main user control contribution comes from Rectus Abdominis and Erector Spinae muscle groups at different levels. Finally, the comparative study showed that a joystick still outperforms the proposed HMI in usability perceptions and controllability metrics, however, the smoothness of user control was similar in jerk and fluency. Moreover, users' perceptions showed that hands-free control made it more anthropomorphic, animated, and even safer.",
        "primary_area": "",
        "author": "Yang Chen;Diego Paez-Granados;Hideki Kadone;Kenji Suzuki;Yang Chen;Diego Paez-Granados;Hideki Kadone;Kenji Suzuki",
        "authorids": "/37088554009;/37085669907;/37295550300;/37334425200;/37088554009;/37085669907;/37295550300;/37334425200",
        "aff": "School of Integrative and Global Majors (SIGMA), University of Tsukuba, Japan; Learning Algorithms and Systems Laboratory (LASA), Ecole Polytechnique Federale de Lausanne (EPFL), Lausanne, Switzerland; Center for Innovative Medicine and Engineering, University of Tsukuba Hospital, Japan; Faculty of Engineering and Center for Cybernics Research, University of Tsukuba, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340875/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3742315059837831212&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "University of Tsukuba;Ecole Polytechnique Federale de Lausanne;University of Tsukuba Hospital",
        "aff_unique_dep": "School of Integrative and Global Majors (SIGMA);Learning Algorithms and Systems Laboratory (LASA);Center for Innovative Medicine and Engineering",
        "aff_unique_url": "https://www.tsukuba.ac.jp;https://www.epfl.ch;",
        "aff_unique_abbr": "UT;EPFL;",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Lausanne",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "Japan;Switzerland"
    },
    {
        "id": "9341394",
        "title": "Control of Magnetically-Driven Screws in a Viscoelastic Medium",
        "track": "main",
        "status": "Poster",
        "abstract": "Magnetically-driven screws operating in soft-tissue environments could be used to deploy localized therapy or achieve minimally invasive interventions. In this work, we characterize the closed-loop behavior of magnetic screws in an agar gel tissue phantom using a permanent magnet-based robotic system with an open-configuration. Our closed-loop control strategy capitalizes on an analytical calculation of the swimming speed of the screw in viscoelastic fluids and the magnetic point-dipole approximation of magnetic fields. The analytical solution is based on the Stokes/Oldroyd-B equations and its predictions are compared to experimental results at different actuation frequencies of the screw. Our measurements matches the theoretical prediction of the analytical model before the step-out frequency of the screw owing to the linearity of the analytical model. We demonstrate open-loop control in two-dimensional space, and point-to-point closed-loop motion control of the screw (length and diameter of 6 mm and 2 mm, respectively) with maximum positioning error of 1.8 mm.",
        "primary_area": "",
        "author": "Zhengya Zhang;Anke Klingner;Sarthak Misra;Islam S. M. Khalil;Zhengya Zhang;Anke Klingner;Sarthak Misra;Islam S. M. Khalil",
        "authorids": "/37088690839;/37314012900;/37536488800;/37409115400;/37088690839;/37314012900;/37536488800;/37409115400",
        "aff": "Department of Biomedical Engineering, Surgical Robotics Laboratory, University of Groningen and University Medical Center Groningen, Groningen, The Netherlands; Physics Department, The German University in Cairo, Cairo, Egypt; Department of Biomechanical Engineering, Faculty of Engineering Technology, Surgical Robotics Laboratory, University of Twente, Enschede, The Netherlands; Department of Biomechanical Engineering, Faculty of Engineering Technology, Surgical Robotics Laboratory, University of Twente, Enschede, The Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341394/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7679841063044643675&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;2",
        "aff_unique_norm": "University of Groningen;The German University in Cairo;University of Twente",
        "aff_unique_dep": "Department of Biomedical Engineering;Physics Department;Department of Biomechanical Engineering",
        "aff_unique_url": "https://www.rug.nl;https://www.guc.edu.eg;https://www.utwente.nl",
        "aff_unique_abbr": "RUG;GUC;UT",
        "aff_campus_unique_index": "0;1;2;2",
        "aff_campus_unique": "Groningen;Cairo;Enschede",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "Netherlands;Egypt"
    },
    {
        "id": "9341376",
        "title": "Cooperative Control of Mobile Robots with Stackelberg Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-robot cooperation requires agents to make decisions that are consistent with the shared goal without disregarding action-specific preferences that might arise from asymmetry in capabilities and individual objectives. To accomplish this goal, we propose a method named SLiCC: Stackelberg Learning in Cooperative Control. SLiCC models the problem as a partially observable stochastic game composed of Stackelberg bimatrix games, and uses deep reinforcement learning to obtain the payoff matrices associated with these games. Appropriate cooperative actions are then selected with the derived Stackelberg equilibria. Using a bi-robot cooperative object transportation problem, we validate the performance of SLiCC against centralized multi-agent Q-learning and demonstrate that SLiCC achieves better combined utility.",
        "primary_area": "",
        "author": "Joewie J. Koh;Guohui Ding;Christoffer Heckman;Lijun Chen;Alessandro Roncone;Joewie J. Koh;Guohui Ding;Christoffer Heckman;Lijun Chen;Alessandro Roncone",
        "authorids": "/37088687889;/37086064182;/37086032368;/37089654207;/37085343755;/37088687889;/37086064182;/37086032368;/37089654207;/37085343755",
        "aff": "Department of Computer Science, University of Colorado, Boulder; Department of Computer Science, University of Colorado, Boulder; Department of Computer Science, University of Colorado, Boulder; Department of Computer Science, University of Colorado, Boulder; Department of Computer Science, University of Colorado, Boulder",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341376/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12010855739084711384&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Colorado",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.colorado.edu",
        "aff_unique_abbr": "CU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Boulder",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340835",
        "title": "Cooperative Simultaneous Tracking and Jamming for Disabling a Rogue Drone",
        "track": "main",
        "status": "Poster",
        "abstract": "This work investigates the problem of simultaneous tracking and jamming of a rogue drone in 3D space with a team of cooperative unmanned aerial vehicles (UAVs). We propose a decentralized estimation, decision and control framework in which a team of UAVs cooperate in order to a) optimally choose their mobility control actions that result in accurate target tracking and b) select the desired transmit power levels which cause uninterrupted radio jamming and thus ultimately disrupt the operation of the rogue drone. The proposed decision and control framework allows the UAVs to reconfigure themselves in 3D space such that the cooperative simultaneous tracking and jamming (CSTJ) objective is achieved; while at the same time ensures that the unwanted inter-UAV jamming interference caused during CSTJ is kept below a specified critical threshold. Finally, we formulate this problem under challenging conditions i.e., uncertain dynamics, noisy measurements and false alarms. Extensive simulation experiments illustrate the performance of the proposed approach.",
        "primary_area": "",
        "author": "Savvas Papaioannou;Panayiotis Kolios;Christos G. Panayiotou;Marios M. Polycarpou;Savvas Papaioannou;Panayiotis Kolios;Christos G. Panayiotou;Marios M. Polycarpou",
        "authorids": "/38666812600;/37669519700;/37270755700;/37273723800;/38666812600;/37669519700;/37270755700;/37273723800",
        "aff": "Department of Electrical and Computer Engineering, KIOS Research and Innovation Centre of Excellence (KIOS CoE), University of Cyprus, Nicosia, Cyprus; Department of Electrical and Computer Engineering, KIOS Research and Innovation Centre of Excellence (KIOS CoE), University of Cyprus, Nicosia, Cyprus; Department of Electrical and Computer Engineering, KIOS Research and Innovation Centre of Excellence (KIOS CoE), University of Cyprus, Nicosia, Cyprus; Department of Electrical and Computer Engineering, KIOS Research and Innovation Centre of Excellence (KIOS CoE), University of Cyprus, Nicosia, Cyprus",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340835/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15712420599507357029&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Cyprus",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.ucy.ac.cy",
        "aff_unique_abbr": "UCY",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Nicosia",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Cyprus"
    },
    {
        "id": "9341311",
        "title": "Coordinate-free Isoline Tracking in Unknown 2-D Scalar Fields",
        "track": "main",
        "status": "Poster",
        "abstract": "The isoline tracking of this work is concerned with the control design for a sensing robot to track a given isoline of an unknown 2-D scalar filed. To this end, we propose a coordinate-free controller with a simple PI-like form using only the concentration feedback for a Dubins robot, which is particularly useful in GPS-denied environments. The key idea lies in the novel design of a sliding surface based error term in the standard PI controller. Interestingly, we also prove that the tracking error can be reduced by increasing the proportion gain, and be eliminated for circular fields with a non-zero integral gain. The effectiveness of our controller is validated via simulations by using a fixed-wing UAV on the real dataset of the concentration distribution of PM2.5 in an area of China.",
        "primary_area": "",
        "author": "Fei Dong;Keyou You;Jian Wang;Fei Dong;Keyou You;Jian Wang",
        "authorids": "/37086332920;/37391177800;/37406476300;/37086332920;/37391177800;/37406476300",
        "aff": "Department of Automation, and Beijing National Research Center for Info. Sci. & Tech. (BNRist), Tsinghua University, Beijing, China; Department of Automation, and Beijing National Research Center for Info. Sci. & Tech. (BNRist), Tsinghua University, Beijing, China; Department of Electronic Engineering, Tsinghua University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341311/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2008884416412680696&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Tsinghua University",
        "aff_unique_dep": "Department of Automation",
        "aff_unique_url": "https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "Tsinghua",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9341364",
        "title": "Core-centered Actuation for Biped Locomotion of Humanoid Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper we examine a novel method of core-located actuation that we believe can be used to vary gaits in a compass-gait walker, using critical analysis of a ball-in-tray mechanism to apply forces at the robot's \"pelvis\". The dynamic equations of motion of a tilting ball-tray system with several design parameters are developed and simulated for various tray designs. Results show that changes in tray design do indeed significantly affect the trajectory. When compared to a hardware ball-tray system, the results show good agreement with the simulation. The sagittal plane component of the ball's trajectory is applied to the motion of a corresponding mass at the \"pelvis\" of a compass-gait walker. Simulations of the compass-gait walker show that this trajectory generates a feasible gait.",
        "primary_area": "",
        "author": "Caleb Fuller;Umer Huzaifa;Amy LaViers;Joshua Schultz;Caleb Fuller;Umer Huzaifa;Amy LaViers;Joshua Schultz",
        "authorids": "/37087321847;/37085834336;/37706085100;/37890321900;/37087321847;/37085834336;/37706085100;/37890321900",
        "aff": "Department of Mechanical Engineering, University of Tulsa, Tulsa, OK, USA; Department of Electrical and Computer Engineering, Rose-Hulman Institute of Technology, Terre Haute, IN, USA; Department of Mechanical Science and Engineering, University of Illinois at Urbana-Champaign, Champaign, IL, USA; Department of Mechanical Engineering, University of Tulsa, Tulsa, OK, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341364/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15936433897983161012&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "University of Tulsa;Rose-Hulman Institute of Technology;University of Illinois at Urbana-Champaign",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Electrical and Computer Engineering;Department of Mechanical Science and Engineering",
        "aff_unique_url": "https://www.utulsa.edu;https://www.rose-hulman.edu;https://illinois.edu",
        "aff_unique_abbr": "UTulsa;Rose-Hulman;UIUC",
        "aff_campus_unique_index": "0;1;2;0",
        "aff_campus_unique": "Tulsa;Terre Haute;Champaign",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341343",
        "title": "Crop Height and Plot Estimation for Phenotyping from Unmanned Aerial Vehicles using 3D LiDAR",
        "track": "main",
        "status": "Poster",
        "abstract": "We present techniques to measure crop heights using a 3D Light Detection and Ranging (LiDAR) sensor mounted on an Unmanned Aerial Vehicle (UAV). Knowing the height of plants is crucial to monitor their overall health and growth cycles, especially for high-throughput plant phenotyping. We present a methodology for extracting plant heights from 3D LiDAR point clouds, specifically focusing on plot-based phenotyping environments. We also present a toolchain that can be used to create phenotyping farms for use in Gazebo simulations. The tool creates a randomized farm with realistic 3D plant and terrain models. We conducted a series of simulations and hardware experiments in controlled and natural settings. Our algorithm was able to estimate the plant heights in a field with 112 plots with a root mean square error (RMSE) of 6.1 cm. This is the first such dataset for 3D LiDAR from an airborne robot over a wheat field. The developed simulation toolchain, algorithmic implementation, and datasets can be found on our GitHub repository.1",
        "primary_area": "",
        "author": "Harnaik Dhami;Kevin Yu;Tianshu Xu;Qian Zhu;Kshitiz Dhakal;James Friel;Song Li;Pratap Tokekar;Harnaik Dhami;Kevin Yu;Tianshu Xu;Qian Zhu;Kshitiz Dhakal;James Friel;Song Li;Pratap Tokekar",
        "authorids": "/37088686981;/37086454721;/37088690770;/37088687360;/37088687919;/37088687828;/37088691482;/37546532700;/37088686981;/37086454721;/37088690770;/37088687360;/37088687919;/37088687828;/37088691482;/37546532700",
        "aff": "Department of Computer Science, University of Maryland, U.S.A; Department of Electrical and Computer Engineering, Virginia Tech, U.S.A; Department of Computer Science, University of Maryland, U.S.A; School of Plant and Environmental Sciences, Virginia Tech, U.S.A; School of Plant and Environmental Sciences, Virginia Tech, U.S.A; School of Plant and Environmental Sciences, Virginia Tech, U.S.A; School of Plant and Environmental Sciences, Virginia Tech, U.S.A; Department of Computer Science, University of Maryland, U.S.A",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341343/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9970250383111526843&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;0;1;1;1;1;0",
        "aff_unique_norm": "University of Maryland;Virginia Tech",
        "aff_unique_dep": "Department of Computer Science;Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www/umd.edu;https://www.vt.edu",
        "aff_unique_abbr": "UMD;VT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341015",
        "title": "Cross Scene Prediction via Modeling Dynamic Correlation using Latent Space Shared Auto-Encoders",
        "track": "main",
        "status": "Poster",
        "abstract": "This work addresses on the following problem: given a set of unsynchronized history observations of two scenes that are correlative on their dynamic changes, the purpose is to learn a cross-scene predictor, so that with the observation of one scene, a robot can onlinely predict the dynamic state of the other. A method is proposed to solve the problem via modeling dynamic correlation using latent space shared auto-encoders. Assuming that the inherent correlation of scene dynamics can be represented by shared latent space, where a common latent state is reached if the observations of both scenes are at an approximate time. A learning model is developed by connecting two auto-encoders through the latent space, and a prediction model is built by concatenating the encoder of the input scene with the decoder of the target one. Simulation datasets are generated imitating the dynamic flows at two adjacent gates of a campus, where the dynamic changes are triggered by a common working and teaching schedule. Similar scenarios can also be found at successive intersections on a single road, gates of a subway station, etc. Accuracy of cross-scene prediction is examined at various conditions of scene correlation and pairwise observations. Potentials of the proposed method are demonstrated by comparing with conventional end-to-end methods and linear predictions.",
        "primary_area": "",
        "author": "Shaochi Hu;Donghao Xu;Huijing Zhao;Shaochi Hu;Donghao Xu;Huijing Zhao",
        "authorids": "/37087103020;/37085536354;/37290336200;/37087103020;/37085536354;/37290336200",
        "aff": "Key Laboratory of Machine Perception (MOE), School of Electronics Engineering and Computer Science, Peking University; Key Laboratory of Machine Perception (MOE), School of Electronics Engineering and Computer Science, Peking University; Key Laboratory of Machine Perception (MOE), School of Electronics Engineering and Computer Science, Peking University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341015/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:3ZlYdNYoBakJ:scholar.google.com/&scioq=Cross+Scene+Prediction+via+Modeling+Dynamic+Correlation+using+Latent+Space+Shared+Auto-Encoders&hl=en&as_sdt=0,33",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Peking University",
        "aff_unique_dep": "School of Electronics Engineering and Computer Science",
        "aff_unique_url": "http://www.pku.edu.cn",
        "aff_unique_abbr": "PKU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9341617",
        "title": "Crossing the Gap: A Deep Dive into Zero-Shot Sim-to-Real Transfer for Dynamics",
        "track": "main",
        "status": "Poster",
        "abstract": "Zero-shot sim-to-real transfer of tasks with complex dynamics is a highly challenging and unsolved problem. A number of solutions have been proposed in recent years, but we have found that many works do not present a thorough evaluation in the real world, or underplay the significant engineering effort and task-specific fine tuning that is required to achieve the published results. In this paper, we dive deeper into the sim-to-real transfer challenge, investigate why this is such a difficult problem, and present objective evaluations of a number of transfer methods across a range of real-world tasks. Surprisingly, we found that a method which simply injects random forces into the simulation performs just as well as more complex methods, such as those which randomise the simulator's dynamics parameters, or adapt a policy online using recurrent network architectures.",
        "primary_area": "",
        "author": "Eugene Valassakis;Zihan Ding;Edward Johns;Eugene Valassakis;Zihan Ding;Edward Johns",
        "authorids": "/37088689402;/37088504955;/37602799000;/37088689402;/37088504955;/37602799000",
        "aff": "The Robot Learning Lab at Imperial College, London; The Robot Learning Lab at Imperial College, London; The Robot Learning Lab at Imperial College, London",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341617/",
        "gs_citation": 49,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6410083740634093372&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Imperial College London",
        "aff_unique_dep": "Robot Learning Lab",
        "aff_unique_url": "https://www.imperial.ac.uk",
        "aff_unique_abbr": "ICL",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9341243",
        "title": "Crowdsourced 3D Mapping: A Combined Multi-View Geometry and Self-Supervised Learning Approach",
        "track": "main",
        "status": "Poster",
        "abstract": "The ability to efficiently utilize crowd-sourced visual data carries immense potential for the domains of large scale dynamic mapping and autonomous driving. However, state-of-the-art methods for crowdsourced 3D mapping assume prior knowledge of camera intrinsics. In this work we propose a framework that estimates the 3D positions of semantically meaningful landmarks such as traffic signs without assuming known camera intrinsics, using only monocular color camera and GPS. We utilize multi-view geometry as well as deep learning based self-calibration, depth, and ego-motion estimation for traffic sign positioning, and show that combining their strengths is important for increasing the map coverage. To facilitate research on this task, we construct and make available a KITTI based 3D traffic sign ground truth positioning dataset. Using our proposed framework, we achieve an average single-journey relative and absolute positioning accuracy of 39cm and 1.26m respectively, on this dataset.",
        "primary_area": "",
        "author": "Hemang Chawla;Matti Jukola;Terence Brouns;Elahe Arani;Bahram Zonooz;Hemang Chawla;Matti Jukola;Terence Brouns;Elahe Arani;Bahram Zonooz",
        "authorids": "/37088595013;/37088598011;/37088687055;/37088597781;/37088596827;/37088595013;/37088598011;/37088687055;/37088597781;/37088596827",
        "aff": "Advanced Research Lab, NavInfo Europe, Eindhoven, The Netherlands; Advanced Research Lab, NavInfo Europe, Eindhoven, The Netherlands; Advanced Research Lab, NavInfo Europe, Eindhoven, The Netherlands; Advanced Research Lab, NavInfo Europe, Eindhoven, The Netherlands; Advanced Research Lab, NavInfo Europe, Eindhoven, The Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341243/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=925416119564938172&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "NavInfo Europe",
        "aff_unique_dep": "Advanced Research Lab",
        "aff_unique_url": "https://www.navinfo.com",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Eindhoven",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Netherlands"
    },
    {
        "id": "9341313",
        "title": "D2VO: Monocular Deep Direct Visual Odometry",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a novel deep learning and direct method based monocular visual odometry system named D2VO. Our system reconstructs the dense depth map of each keyframe and tracks camera poses based on these keyframes. Combining direct method and deep learning, both tracking and mapping of the system could benefit from the geometric measurement and semantic information. For each input frame, a feature pyramid is built and shared by both tracking and mapping process. The depth map of keyframe is efficiently estimated from coarse to fine with the followed multi-view hierarchical depth estimation network. We optimize the camera pose by minimizing photometric error between re-projected features of each frame and its reference keyframe with bundle adjustment. Experimental results on TUM dataset demonstrate that our approach outperforms the state-of-the-art methods on both tracking and mapping.",
        "primary_area": "",
        "author": "Qizeng Jia;Yuechuan Pu;Jingyu Chen;Junda Cheng;Chunyuan Liao;Xin Yang;Qizeng Jia;Yuechuan Pu;Jingyu Chen;Junda Cheng;Chunyuan Liao;Xin Yang",
        "authorids": "/37088690745;/37088689901;/37088596828;/37088687260;/37085818411;/37534298600;/37088690745;/37088689901;/37088596828;/37088687260;/37085818411;/37534298600",
        "aff": "School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; HiScene Information Technology, Co., Ltd, China; School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341313/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4688301028997977698&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;0",
        "aff_unique_norm": "Huazhong University of Science and Technology;HiScene Information Technology",
        "aff_unique_dep": "School of Electronic Information and Communications;Information Technology",
        "aff_unique_url": "http://www.hust.edu.cn;",
        "aff_unique_abbr": "HUST;",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Wuhan;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9341782",
        "title": "DGAZE: Driver Gaze Mapping on Road",
        "track": "main",
        "status": "Poster",
        "abstract": "Driver gaze mapping is crucial to estimate driver attention and determine which objects the driver is focusing on while driving. We introduce DGAZE, the first large-scale driver gaze mapping dataset. Unlike previous works, our dataset does not require expensive wearable eye-gaze trackers and instead relies on mobile phone cameras for data collection. The data was collected in a lab setting designed to mimic real driving conditions and has point and object-level annotation. It consists of 227,178 road-driver image pairs collected from 20 drivers and contains 103 unique objects on the road belonging to 7 classes: cars, pedestrians, traffic signals, motorbikes, auto-rickshaws, buses and signboards.We also present I-DGAZE, a fused convolutional neural network for predicting driver gaze on the road, which was trained on the DGAZE dataset. Our architecture combines facial features such as face location and head pose along with the image of the left eye to get optimum results. Our model achieves an error of 186.89 pixels on the road view of resolution 1920\u00d71080 pixels. We compare our model with state-of-the-art eye gaze works and present extensive ablation results.",
        "primary_area": "",
        "author": "Isha Dua;Thrupthi Ann John;Riya Gupta;C.V. Jawahar;Isha Dua;Thrupthi Ann John;Riya Gupta;C.V. Jawahar",
        "authorids": "/37085688588;/37088689671;/37088687612;/37270075200;/37085688588;/37088689671;/37088687612;/37270075200",
        "aff": "KCIS, Centre of Visual Information Technology, IIIT, Hyderabad; KCIS, Centre of Visual Information Technology, IIIT, Hyderabad; KCIS, Centre of Visual Information Technology, IIIT, Hyderabad; KCIS, Centre of Visual Information Technology, IIIT, Hyderabad",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341782/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9049557050409015166&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "International Institute of Information Technology, Hyderabad",
        "aff_unique_dep": "Centre of Visual Information Technology",
        "aff_unique_url": "https://iiit Hyderabad.ac.in",
        "aff_unique_abbr": "IIIT Hyderabad",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Hyderabad",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "9340744",
        "title": "DIAT (Depth-Infrared Image Annotation Transfer) for Training a Depth-Based Pig-Pose Detector",
        "track": "main",
        "status": "Poster",
        "abstract": "Precision livestock farming uses artificial intelligence to individually monitor livestock activity and health. Tracking individuals over time can reveal health indicators that correlate with productivity and longevity. For instance, locomotion patterns observed in lame pigs have been shown to correlate with poor animal welfare and productivity. Kinematic analysis of pigs using pose estimates provides a means of assessing locomotion. New dense depth sensors have potential to achieve full 3D pose estimation and tracking. However, the lack of annotated dense depth datasets has limited use of these sensors in detecting animal pose. Current annotation methods rely on human labeling, but identifying hip and shoulder locations is difficult for pigs with few prominent features, and is especially difficult in depth images as these lack albedo texture. This work proposes a solution to quickly generate high accuracy pig landmark annotations for depth-based pose estimation. We propose Depth-Infrared Annotation Transfer (DIAT), an approach that semi-automatically finds, identifies, and tracks marks visible in infrared, and transfers these labels to depth images. As a result, we are able to train a precise pig pose detector that operates on depth images.",
        "primary_area": "",
        "author": "Steven Yik;Madonna Benjamin;Michael Lavagnino;Daniel Morris;Steven Yik;Madonna Benjamin;Michael Lavagnino;Daniel Morris",
        "authorids": "/37088689911;/37088689306;/38222705700;/37085641369;/37088689911;/37088689306;/38222705700;/37085641369",
        "aff": "Department of Electrical and Computer Engineering, Michigan State University, East Lansing, MI, USA; Swine Extension Veterinarian of College of Veterinary Medicine, Michigan State University, East Lansing, MI, USA; Academic Specialists in Mechanical Engineering, Michigan State University, East Lansing, MI, USA; Electrical and Computer Engineering, Michigan State University, East Lansing, MI, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340744/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10504103621691978663&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Michigan State University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.msu.edu",
        "aff_unique_abbr": "MSU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "East Lansing",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341206",
        "title": "DMLO: Deep Matching LiDAR Odometry",
        "track": "main",
        "status": "Poster",
        "abstract": "LiDAR odometry is a fundamental task for various areas such as robotics, autonomous driving. This problem is difficult since it requires the systems to be highly robust running in noisy real-world data. Existing methods are mostly local iterative methods. Feature-based global registration methods are not preferred since extracting accurate matching pairs in the nonuniform and sparse LiDAR data remains challenging. In this paper, we present Deep Matching LiDAR Odometry (DMLO), a novel learning-based framework which makes the feature matching method applicable to LiDAR odometry task. Unlike many recent learning-based methods, DMLO explicitly enforces geometry constraints in the framework. Specifically, DMLO decomposes the 6-DoF pose estimation into two parts, a learning-based matching network which provides accurate correspondences between two scans and rigid transformation estimation with a close-formed solution by Singular Value Decomposition (SVD). Comprehensive experimental results on real-world datasets KITTI and Argoverse demonstrate that our DMLO dramatically outperforms existing learning-based methods and is comparable with the state-of-the-art geometry- based approaches.",
        "primary_area": "",
        "author": "Zhichao Li;Naiyan Wang;Zhichao Li;Naiyan Wang",
        "authorids": "/37088691225;/37085671305;/37088691225;/37085671305",
        "aff": "Tusimple, Beijing, China; Tusimple, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341206/",
        "gs_citation": 53,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10657371432464339291&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Tusimple",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9341689",
        "title": "DR-SPAAM: A Spatial-Attention and Auto-regressive Model for Person Detection in 2D Range Data",
        "track": "main",
        "status": "Poster",
        "abstract": "Detecting persons using a 2D LiDAR is a challenging task due to the low information content of 2D range data. To alleviate the problem caused by the sparsity of the LiDAR points, current state-of-the-art methods fuse multiple previous scans and perform detection using the combined scans. The downside of such a backward looking fusion is that all the scans need to be aligned explicitly, and the necessary alignment operation makes the whole pipeline more expensive - often too expensive for real-world applications. In this paper, we propose a person detection network which uses an alternative strategy to combine scans obtained at different times. Our method, Distance Robust SPatial Attention and Auto-regressive Model (DR-SPAAM), follows a forward looking paradigm. It keeps the intermediate features from the backbone network as a template and recurrently updates the template when a new scan becomes available. The updated feature template is in turn used for detecting persons currently in the scene. On the DROW dataset, our method outperforms the existing state-of-the-art, while being approximately four times faster, running at 87.2 FPS on a laptop with a dedicated GPU and at 22.6 FPS on an NVIDIA Jetson AGX embedded GPU. We release our code in PyTorch and a ROS node including pre-trained models.",
        "primary_area": "",
        "author": "Dan Jia;Alexander Hermans;Bastian Leibe;Dan Jia;Alexander Hermans;Bastian Leibe",
        "authorids": "/37088688308;/37085358298;/37298473000;/37088688308;/37085358298;/37298473000",
        "aff": "Visual Computing Institute, RWTH Aachen University; Visual Computing Institute, RWTH Aachen University; Visual Computing Institute, RWTH Aachen University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341689/",
        "gs_citation": 45,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1787165181973709171&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "RWTH Aachen University",
        "aff_unique_dep": "Visual Computing Institute",
        "aff_unique_url": "https://www.rwth-aachen.de",
        "aff_unique_abbr": "RWTH",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Aachen",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9341761",
        "title": "DR2Track: Towards Real-Time Visual Tracking for UAV via Distractor Repressed Dynamic Regression",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual tracking has yielded promising applications with unmanned aerial vehicle (UAV). In literature, the advanced discriminative correlation filter (DCF) type trackers generally distinguish the foreground from the background with a learned regressor which regresses the implicit circulated samples into a fixed target label. However, the predefined and unchanged regression target results in low robustness and adaptivity to uncertain aerial tracking scenarios. In this work, we exploit the local maximum points of the response map generated in the detection phase to automatically locate current distractors1. By repressing the response of distractors in the regressor learning, we can dynamically and adaptively alter our regression target to leverage the tracking robustness as well as adaptivity. Substantial experiments conducted on three challenging UAV benchmarks demonstrate both excellent performance and extraordinary speed (~50fps on a cheap CPU) of our tracker.",
        "primary_area": "",
        "author": "Changhong Fu;Fangqiang Ding;Yiming Li;Jin Jin;Chen Feng;Changhong Fu;Fangqiang Ding;Yiming Li;Jin Jin;Chen Feng",
        "authorids": "/37086797986;/37088456219;/37087323806;/37088686956;/37086391326;/37086797986;/37088456219;/37087323806;/37088686956;/37086391326",
        "aff": "School of Mechanical Engineering, Tongji University, Shanghai, China; School of Mechanical Engineering, Tongji University, Shanghai, China; School of Mechanical Engineering, Tongji University, Shanghai, China; School of Mechanical Engineering, Tongji University, Shanghai, China; Tandon School of Engineering, New York University, New York, NY, United States",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341761/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2040600600069325338&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "Tongji University;New York University",
        "aff_unique_dep": "School of Mechanical Engineering;Tandon School of Engineering",
        "aff_unique_url": "https://www.tongji.edu.cn;https://www.nyu.edu",
        "aff_unique_abbr": "Tongji;NYU",
        "aff_campus_unique_index": "0;0;0;0;1",
        "aff_campus_unique": "Shanghai;New York",
        "aff_country_unique_index": "0;0;0;0;1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9340898",
        "title": "DSSF-net: Dual-Task Segmentation and Self-supervised Fitting Network for End-to-End Lane Mark Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Lane mark detection is one of the key tasks for autonomous driving systems. Accurate detection of lane marks under complex urban environments remains a challenge. In this paper, an end-to-end lane mark detection network named DSSF-net, which is capable of directly outputting the accurate fitted lane curves, is proposed. First, a dual-task segmentation framework for jointing lane category prediction and spatial partition is presented. An IoU-based loss function is put forward to tackle the severely imbalanced category distribution problem. Then a fully self-supervised curve fitting network is proposed to directly output the parameters of lane line upon the probability map. To achieve better accuracy, the fitting network is trained with two sub-stages: coarse regression and confidence-based optimization. Finally the entire DSSF-net is implemented end-to-end. Comprehensive experiments conducted on challenging CULane dataset show that our model achieves 74.9% in F1-score and outperforms the state-of-the-art models.",
        "primary_area": "",
        "author": "Wentao Du;Zhiyu Xiang;Yiman Chen;Shuya Chen;Wentao Du;Zhiyu Xiang;Yiman Chen;Shuya Chen",
        "authorids": "/37086558399;/37331922100;/37086954010;/37086953294;/37086558399;/37331922100;/37086954010;/37086953294",
        "aff": "College of Information Science & Electronic Engineering, Zhejiang University, Hangzhou, China; College of Information Science & Electronic Engineering, Zhejiang University, Hangzhou, China; College of Information Science & Electronic Engineering, Zhejiang University, Hangzhou, China; College of Information Science & Electronic Engineering, Zhejiang University, Hangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340898/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9993778667818893779&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Zhejiang University",
        "aff_unique_dep": "College of Information Science & Electronic Engineering",
        "aff_unique_url": "http://www.zju.edu.cn",
        "aff_unique_abbr": "ZJU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Hangzhou",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9341592",
        "title": "DUI-VIO: Depth Uncertainty Incorporated Visual Inertial Odometry based on an RGB-D Camera",
        "track": "main",
        "status": "Poster",
        "abstract": "",
        "primary_area": "",
        "author": "He Zhang;Cang Ye;He Zhang;Cang Ye",
        "authorids": "/37086004148;/37291591400;/37086004148;/37291591400",
        "aff": "",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341592/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1443216136842556223&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4
    },
    {
        "id": "9340907",
        "title": "DXSLAM: A Robust and Efficient Visual SLAM System with Deep Features",
        "track": "main",
        "status": "Poster",
        "abstract": "A robust and efficient Simultaneous Localization and Mapping (SLAM) system is essential for robot autonomy. For visual SLAM algorithms, though the theoretical framework has been well established for most aspects, feature extraction and association is still empirically designed in most cases, and can be vulnerable in complex environments. This paper shows that feature extraction with deep convolutional neural networks (CNNs) can be seamlessly incorporated into a modern SLAM framework. The proposed SLAM system utilizes a state-of-the-art CNN to detect keypoints in each image frame, and to give not only keypoint descriptors, but also a global descriptor of the whole image. These local and global features are then used by different SLAM modules, resulting in much more robustness against environmental changes and viewpoint changes compared with using hand-crafted features. We also train a visual vocabulary of local features with a Bag of Words (BoW) method. Based on the local features, global features, and the vocabulary, a highly reliable loop closure detection method is built. Experimental results show that all the proposed modules significantly outperforms the baseline, and the full system achieves much lower trajectory errors and much higher correct rates on all evaluated data. Furthermore, by optimizing the CNN with Intel OpenVINO toolkit and utilizing the Fast BoW library, the system benefits greatly from the SIMD (single-instruction-multiple-data) techniques in modern CPUs. The full system can run in real-time without any GPU or other accelerators. The code is public at https://github.com/ivipsourcecode/dxslam.",
        "primary_area": "",
        "author": "Dongjiang Li;Xuesong Shi;Qiwei Long;Shenghui Liu;Wei Yang;Fangshi Wang;Qi Wei;Fei Qiao;Dongjiang Li;Xuesong Shi;Qiwei Long;Shenghui Liu;Wei Yang;Fangshi Wang;Qi Wei;Fei Qiao",
        "authorids": "/37088395695;/37086577986;/37088394848;/37088687047;/37276965400;/37290980000;/37582779500;/37272195200;/37088395695;/37086577986;/37088394848;/37088687047;/37276965400;/37290980000;/37582779500;/37272195200",
        "aff": "Beijing Jiaotong University, Beijing, China; Intel Corporation, China; Beijing Jiaotong University, Beijing, China; Intel Corporation, China; Beijing Jiaotong University, Beijing, China; Beijing Jiaotong University, Beijing, China; Tsinghua University, Beijing, China; Tsinghua University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340907/",
        "gs_citation": 155,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13108032052312273977&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;0;1;0;0;2;2",
        "aff_unique_norm": "Beijing Jiaotong University;Intel Corporation;Tsinghua University",
        "aff_unique_dep": ";;",
        "aff_unique_url": "http://www.bjtu.edu.cn;https://www.intel.cn;https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "BJTU;Intel;THU",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Beijing;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9340775",
        "title": "Data Driven Online Multi-Robot Formation Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "This work addresses planning for multi-robot formations online in cluttered environments via a data-driven search approach. The user-specified objective function governing formation shape and rotation is expressed in terms of offline demonstrations of robot motions (performed in an obstacle free environment). We leverage the offline demonstration to inform online planning for coordinated motions in the presence of obstacles. We formulate planning as a discrete search over demonstrated multi-robot actions, and select actions using a best-first approach to minimize edge expansions for fast online operation. Actions are selected using a heuristic based on their probability distribution exhibited in the demonstration, and we show that this approach is able to recreate coordinated motions exhibited in the demonstration when navigating in the obstructed conditions of the cluttered test environments. We demonstrate results in simulation over environments with increasing numbers of obstacles, and show that resulting plans are collision free and obey dynamic constraints.",
        "primary_area": "",
        "author": "Ellen A. Cappo;Arjav Desai;Nathan Michael;Ellen A. Cappo;Arjav Desai;Nathan Michael",
        "authorids": "/37085480774;/37086938215;/37302499000;/37085480774;/37086938215;/37302499000",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340775/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6125862894453818366&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341481",
        "title": "Data-Driven Distributionally Robust Electric Vehicle Balancing for Mobility-on-Demand Systems under Demand and Supply Uncertainties",
        "track": "main",
        "status": "Poster",
        "abstract": "As electric vehicle (EV) technologies become mature, EV has been rapidly adopted in modern transportation systems, and is expected to provide future autonomous mobility-on-demand (AMoD) service with economic and societal benefits. However, EVs require frequent recharges due to their limited and unpredictable cruising ranges, and they have to be managed efficiently given the dynamic charging process. It is urgent and challenging to investigate a computationally efficient algorithm that provide EV AMoD system performance guarantees under model uncertainties, instead of using heuristic demand or charging models. To accomplish this goal, this work designs a data-driven distributionally robust optimization approach for vehicle supply-demand ratio and charging station utilization balancing, while minimizing the worst-case expected cost considering both passenger mobility demand uncertainties and EV supply uncertainties. We then derive an equivalent computationally tractable form for solving the distributionally robust problem in a computationally efficient way under ellipsoid uncertainty sets constructed from data. Based on E-taxi system data of Shenzhen city, we show that the average total balancing cost is reduced by 14.49%, the average unfairness of supply-demand ratio and utilization is reduced by 15.78% and 34.51% respectively with the distributionally robust vehicle balancing method, compared with solutions which do not consider model uncertainties.",
        "primary_area": "",
        "author": "Sihong He;Lynn Pepin;Guang Wang;Desheng Zhang;Fei Miao;Sihong He;Lynn Pepin;Guang Wang;Desheng Zhang;Fei Miao",
        "authorids": "/37088688721;/37087406618;/37086594982;/38547561000;/37072758500;/37088688721;/37087406618;/37086594982;/38547561000;/37072758500",
        "aff": "Department of Computer Science and Engineering, University of Connecticut, Storrs Mansfield, CT, USA; Department of Computer Science and Engineering, University of Connecticut, Storrs Mansfield, CT, USA; Department of Computer Science, Rutgers University, Piscataway, NJ, USA; Department of Computer Science, Rutgers University, Piscataway, NJ, USA; Department of Computer Science and Engineering, University of Connecticut, Storrs Mansfield, CT, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341481/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16922884955963504408&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;1;0",
        "aff_unique_norm": "University of Connecticut;Rutgers University",
        "aff_unique_dep": "Department of Computer Science and Engineering;Department of Computer Science",
        "aff_unique_url": "https://www.uconn.edu;https://www.rutgers.edu",
        "aff_unique_abbr": "UConn;Rutgers",
        "aff_campus_unique_index": "0;0;1;1;0",
        "aff_campus_unique": "Storrs Mansfield;Piscataway",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341786",
        "title": "Data-Driven Models with Expert Influence: A Hybrid Approach to Spatiotemporal Process Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, our motivating application lies in precision agriculture where accurate modeling of forage is essential for informing rotational grazing strategies. Unfortunately, a major difficulty arises in modeling forage processes as they evolve on large scales according to complex ecological influences. As robots can collect data over large scales in a forage environment, they act as a promising resource for the forage modeling problem when combined with a data-driven Gaussian processes (GPs) technique. However, GPs are nonparametric in nature and may be blind to certain nuances of a process that a parameterized expert model may predict well. Indeed, for the forage modeling problem specifically, there exist several highly parameterized models from agricultural experts that exhibit powerful predictive capabilities. Expert models, however, often come with two shortcomings: (1) parameters may be difficult to determine in general; and (2) the model may not make complete spatiotemporal predictions. For example, a stochastic differential equation (SDE) that models the dynamics of the average output of an environment may be available from experts (a typical case). In such cases, we propose to take advantage of both data-driven (GPs) and expert (SDE) models, by fusing data collected by robots, which often yields spatial insight, with models from experienced professionals that often yield temporal insights. Specifically, we propose to leverage Bayesian estimation to combine these two methods, resulting in a posterior prediction that is a hybrid of data-driven and expert models. Finally, we provide simulations to demonstrate the effectiveness of the proposed method.",
        "primary_area": "",
        "author": "Jun Liu;Ryan K. Williams;Jun Liu;Ryan K. Williams",
        "authorids": "/37086453932;/38238005300;/37086453932;/38238005300",
        "aff": "Department of Electrical and Computer Engineering, Virginia Polytechnic Institute and State University, Blacksburg, VA, USA; Department of Electrical and Computer Engineering, Virginia Polytechnic Institute and State University, Blacksburg, VA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341786/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3288827801611697474&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Virginia Polytechnic Institute and State University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.vt.edu",
        "aff_unique_abbr": "VT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Blacksburg",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341388",
        "title": "Data-driven Characterization of Human Interaction for Model-based Control of Powered Prostheses",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a data-driven method for powered prosthesis control that achieves stable walking without the need for additional sensors on the human. The key idea is to extract the nominal gait and the human interaction information from motion capture data, and reconstruct the walking behavior with a dynamic model of the human-prosthesis system. The walking behavior of a human wearing a powered prosthesis is obtained through motion capture, which yields the limb and joint trajectories. Then a nominal trajectory is obtained by solving a gait optimization problem designed to reconstruct the walking behavior observed by motion capture. Moreover, the interaction force profiles between the human and the prosthesis are recovered by simulating the model following the recorded gaits, which are then used to construct a force tube that covers all the interaction force profiles. Finally, a robust Control Lyapunov Function (CLF) Quadratic Programming (QP) controller is designed to guarantee the convergence to the nominal trajectory under all possible interaction forces within the tube. Simulation results show this controller's improved tracking performance with a perturbed force profile compared to other control methods with less model information.",
        "primary_area": "",
        "author": "Rachel Gehlhar;Yuxiao Chen;Aaron D. Ames;Rachel Gehlhar;Yuxiao Chen;Aaron D. Ames",
        "authorids": "/37088435299;/37088427220;/37300877900;/37088435299;/37088427220;/37300877900",
        "aff": "Department of Mechanical and Civil Engineering, California Institute of Technology, Pasadena, CA, USA; Department of Mechanical and Civil Engineering, California Institute of Technology, Pasadena, CA, USA; Department of Mechanical and Civil Engineering, California Institute of Technology, Pasadena, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341388/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15005574215451942444&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "California Institute of Technology",
        "aff_unique_dep": "Department of Mechanical and Civil Engineering",
        "aff_unique_url": "https://www.caltech.edu",
        "aff_unique_abbr": "Caltech",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pasadena",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340838",
        "title": "Data-driven Distributed State Estimation and Behavior Modeling in Sensor Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Nowadays, the prevalence of sensor networks has enabled tracking of the states of dynamic objects for a wide spectrum of applications from autonomous driving to environmental monitoring and urban planning. However, tracking realworld objects often faces two key challenges: First, due to the limitation of individual sensors, state estimation needs to be solved in a collaborative and distributed manner. Second, the objects' movement behavior model is unknown, and needs to be learned using sensor observations. In this work, for the first time, we formally formulate the problem of simultaneous state estimation and behavior learning in a sensor network. We then propose a simple yet effective solution to this new problem by extending the Gaussian process-based Bayes filters (GPBayesFilters) to an online, distributed setting. The effectiveness of the proposed method is evaluated on tracking objects with unknown movement behaviors using both synthetic data and data collected from a multi-robot platform.",
        "primary_area": "",
        "author": "Rui Yu;Zhenyuan Yuan;Minghui Zhu;Zihan Zhou;Rui Yu;Zhenyuan Yuan;Minghui Zhu;Zihan Zhou",
        "authorids": "/37088689897;/37088480445;/37085383581;/37085991262;/37088689897;/37088480445;/37085383581;/37085991262",
        "aff": "College of Information Sciences and Technology, Pennsylvania State University, PA, USA; School of Electrical Engineering and Computer Science, Pennsylvania State University, PA, USA; School of Electrical Engineering and Computer Science, Pennsylvania State University, PA, USA; College of Information Sciences and Technology, Pennsylvania State University, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340838/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5182278840085474138&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Pennsylvania State University",
        "aff_unique_dep": "College of Information Sciences and Technology",
        "aff_unique_url": "https://www.psu.edu",
        "aff_unique_abbr": "PSU",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "University Park;PA",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341289",
        "title": "DeComplex: Task planning from complex natural instructions by a collocating robot",
        "track": "main",
        "status": "Poster",
        "abstract": "As the number of robots in our daily surroundings like home, office, restaurants, factory floors, etc. are increasing rapidly, the development of natural human-robot interaction mechanism becomes more vital as it dictates the usability and acceptability of the robots. One of the valued features of such a cohabitant robot is that it performs tasks that are instructed in natural language. However, it is not trivial to execute the human intended tasks as natural language expressions can have large linguistic variations. Existing works assume either single task instruction is given to the robot at a time or there are multiple independent tasks in an instruction. However, complex task instructions composed of multiple inter-dependent tasks are not handled efficiently in the literature. There can be ordering dependency among the tasks, i.e., the tasks have to be executed in a certain order or there can be execution dependency, i.e., input parameter or execution of a task depends on the outcome of another task. Understanding such dependencies in a complex instruction is not trivial if an unconstrained natural language is allowed. In this work, we propose a method to find the intended order of execution of multiple inter-dependent tasks given in natural language instruction. Based on our experiment, we show that our system is very accurate in generating a viable execution plan from a complex instruction.",
        "primary_area": "",
        "author": "Pradip Pramanick;Hrishav Bakul Barua;Chayan Sarkar;Pradip Pramanick;Hrishav Bakul Barua;Chayan Sarkar",
        "authorids": "/37086512563;/37086806703;/37085392494;/37086512563;/37086806703;/37085392494",
        "aff": "TCS Research & Innovation, India; TCS Research & Innovation, India; TCS Research & Innovation, India",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341289/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3360967513803429139&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Tata Consultancy Services",
        "aff_unique_dep": "Research & Innovation",
        "aff_unique_url": "https://www.tcs.com",
        "aff_unique_abbr": "TCS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "9340888",
        "title": "Dec-PPCPP: A Decentralized Predator\u2013Prey-based Approach to Adaptive Coverage Path Planning Amid Moving Obstacles",
        "track": "main",
        "status": "Poster",
        "abstract": "Enabling multiple robots to collaboratively per-form coverage path planning on complex surfaces embedded in {{\\mathbb{R}}^3}{{\\mathbb{R}}^3} in the presence of moving obstacles is a challenging problem that has not received much attention from researchers. As robots start to be practically deployed, it is becoming important to address this problem. A novel decentralized multi-robot coverage path planning approach is proposed that is adaptive to unexpected stationary and moving obstacles while aiming to achieve complete coverage with minimal cost. The approach is inspired by the predator-prey relation. For a robot (a prey), a virtual stationary predator enforces spatial ordering on the prey, and dynamic predators (other robots) cause the prey to be repelled resulting in better task allocation and collision-avoidance. The approach makes the best use of both worlds: offline global planning for tuning of model parameters based on a prior map of the surface, and real-time local planning for adaptive and swift decision making amid moving obstacles and other robots while preserving global behavior. Comparisons with other approaches and extensive testing and validation using different number of robots, different surfaces and obstacles, and various scenarios are conducted.",
        "primary_area": "",
        "author": "Mahdi Hassan;Daut Mustafic;Dikai Liu;Mahdi Hassan;Daut Mustafic;Dikai Liu",
        "authorids": "/37085392456;/37088689643;/37290601500;/37085392456;/37088689643;/37290601500",
        "aff": "Robotics Institute at the University of Tech-nology Sydney (UTS:RI), Ultimo, NSW, Australia; Robotics Institute at the University of Tech-nology Sydney (UTS:RI), Ultimo, NSW, Australia; Robotics Institute at the University of Tech-nology Sydney (UTS:RI), Ultimo, NSW, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340888/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17710406711066298024&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Technology Sydney",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.uts.edu.au",
        "aff_unique_abbr": "UTS",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Ultimo",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "9341106",
        "title": "Decentralised Self-Organising Maps for Multi-Robot Information Gathering",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a new coordination algorithm for decentralised multi-robot information gathering. We consider planning for an online variant of the multi-agent orienteering problem with neighbourhoods. This formulation closely aligns with a number of important tasks in robotics, including inspection, surveillance, and reconnaissance. We propose a decentralised variant of the self-organising map (SOM) learning procedure, named Dec-SOM, which efficiently plans sequences of waypoints for a team of robots. Decentralisation is achieved by performing a distributed allocation scheme jointly with a series of SOM adaptations. We also offer an efficient heuristic to select when to perform negotiations, which reduces communication resource usage. Simulation results in two settings, including an infrastructure inspection scenario with a real-world dataset of oil rigs, demonstrate that Dec-SOM outperforms baseline methods and other SOM variants, is competitive with centralised SOM, and is a viable solution for decentralised information gathering.",
        "primary_area": "",
        "author": "Graeme Best;Geoffrey A. Hollinger;Graeme Best;Geoffrey A. Hollinger",
        "authorids": "/37085672100;/37543482700;/37085672100;/37543482700",
        "aff": "Collaborative Robotics and Intelligent Systems (CoRIS) Institute, Oregon State University, Corvallis, OR, USA; Collaborative Robotics and Intelligent Systems (CoRIS) Institute, Oregon State University, Corvallis, OR, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341106/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13820117450875096876&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Oregon State University",
        "aff_unique_dep": "Collaborative Robotics and Intelligent Systems (CoRIS) Institute",
        "aff_unique_url": "https://oregonstate.edu",
        "aff_unique_abbr": "OSU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Corvallis",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341321",
        "title": "Decentralized Control Schemes for Stable Quadrupedal Locomotion: A Decomposition Approach from Centralized Controllers",
        "track": "main",
        "status": "Poster",
        "abstract": "Although legged robots are becoming more nonlinear with higher degrees of freedom (DOFs), the centralized nonlinear control methods required to achieve stable locomotion cannot scale with the dimensionality of these robots. This paper investigates time-varying decentralized feedback control architectures based on hybrid zero dynamics (HZD) that stabilize dynamic legged locomotion with high degrees of freedom. By conforming to the natural symmetries present in the robot's full-order model, three decentralization schemes are proposed for control synthesis, namely left-right, front-hind and diagonal. Our approach considers the strong nonlinear interactions between the subsystems and relies only on the intrinsic communication of the body's translation and rotational data that is readily available. Further, a quadratic programming (QP) based feedback linearization is employed to compute the control inputs for each subsystem. The effectiveness of the HZD-based decentralization scheme is demonstrated numerically for the stabilization of forward and inplace walking gaits on an 18 DOF robot.",
        "primary_area": "",
        "author": "Abhishek Pandala;Vinay R. Kamidi;Kaveh Akbari Hamed;Abhishek Pandala;Vinay R. Kamidi;Kaveh Akbari Hamed",
        "authorids": "/37086914371;/37086318455;/37592529600;/37086914371;/37086318455;/37592529600",
        "aff": "Department of Mechanical Engineering, Virginia Tech, Blacksburg, VA, USA; Department of Mechanical Engineering, Virginia Tech, Blacksburg, VA, USA; Department of Mechanical Engineering, Virginia Tech, Blacksburg, VA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341321/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8098113363546261428&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Virginia Tech",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.vt.edu",
        "aff_unique_abbr": "VT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Blacksburg",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341754",
        "title": "Decentralized Deep Reinforcement Learning for a Distributed and Adaptive Locomotion Controller of a Hexapod Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Locomotion is a prime example for adaptive behavior in animals and biological control principles have inspired control architectures for legged robots. While machine learning has been successfully applied to many tasks in recent years, Deep Reinforcement Learning approaches still appear to struggle when applied to real world robots in continuous control tasks and in particular do not appear as robust solutions that can handle uncertainties well. Therefore, there is a new interest in incorporating biological principles into such learning architectures. While inducing a hierarchical organization as found in motor control has shown already some success, we here propose a decentralized organization as found in insect motor control for coordination of different legs. A decentralized and distributed architecture is introduced on a simulated hexapod robot and the details of the controller are learned through Deep Reinforcement Learning. We first show that such a concurrent local structure is able to learn better walking behavior. Secondly, that the simpler organization is learned faster compared to holistic approaches.",
        "primary_area": "",
        "author": "Malte Schilling;Kai Konen;Frank W. Ohl;Timo Korthals;Malte Schilling;Kai Konen;Frank W. Ohl;Timo Korthals",
        "authorids": "/37590805000;/37089816656;/38181466900;/37086064814;/37590805000;/37089816656;/38181466900;/37086064814",
        "aff": "Neuroinformatics Group, Bielefeld University, Bielefeld, Germany; Neuroinformatics Group, Bielefeld University, Bielefeld, Germany; Department of Systems Physiology of Learning, Leibniz Institute for Neurobiology and with the Institute of Biology, Otto-von-Guericke University, Magdeburg, Germany; Kognitronik and Sensorik Group, Bielefeld University, Bielefeld, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341754/",
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4235191649555538828&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Bielefeld University;Leibniz Institute for Neurobiology",
        "aff_unique_dep": "Neuroinformatics Group;Department of Systems Physiology of Learning",
        "aff_unique_url": "https://www.uni-bielefeld.de;https://www.leibniz-izn.de",
        "aff_unique_abbr": ";IZN",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Bielefeld;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9341023",
        "title": "Decentralized Nonlinear MPC for Robust Cooperative Manipulation by Heterogeneous Aerial-Ground Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Cooperative robotics is a trending topic nowadays as it makes possible a number of tasks that cannot be performed by individual robots, such as heavy payload transportation and agile manipulation. In this work, we address the problem of cooperative transportation by heterogeneous, manipulator- endowed robots. Specifically, we consider a generic number of robotic agents simultaneously grasping an object, which is to be transported to a prescribed set point while avoiding obstacles. The procedure is based on a decentralized leader-follower Model Predictive Control scheme, where a designated leader agent is responsible for generating a trajectory compatible with its dynamics, and the followers must compute a trajectory for their own manipulators that aims at minimizing the internal forces and torques that might be applied to the object by the different grippers. The Model Predictive Control approach appears to be well suited to solve such a problem, because it provides both a control law and a technique to generate trajectories, which can be shared among the agents. The proposed algorithm is implemented using a system comprised of a ground and an aerial robot, both in the robotic Gazebo simulator as well as in experiments with real robots, where the methodological approach is assessed and the controller design is shown to be effective for the cooperative transportation task.",
        "primary_area": "",
        "author": "Nicola Lissandrini;Christos K. Verginis;Pedro Roque;Angelo Cenedese;Dimos V. Dimarogonas;Nicola Lissandrini;Christos K. Verginis;Pedro Roque;Angelo Cenedese;Dimos V. Dimarogonas",
        "authorids": "/37088686773;/37085751745;/37086198375;/37297010400;/37282084700;/37088686773;/37085751745;/37086198375;/37297010400;/37282084700",
        "aff": "Department of Information Engineering, University of Padova, Padova, Italy; Centre for Autonomous Systems at Kungliga Tekniska Hogskolan, Stockholm, Sweden; Centre for Autonomous Systems at Kungliga Tekniska Hogskolan, Stockholm, Sweden; Department of Information Engineering, University of Padova, Padova, Italy; Centre for Autonomous Systems at Kungliga Tekniska Hogskolan, Stockholm, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341023/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5291116622167599348&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;0;1",
        "aff_unique_norm": "University of Padova;Kungliga Tekniska Hogskolan",
        "aff_unique_dep": "Department of Information Engineering;Centre for Autonomous Systems",
        "aff_unique_url": "https://www.unipd.it;https://www.kth.se",
        "aff_unique_abbr": "UNIPD;KTH",
        "aff_campus_unique_index": "0;1;1;0;1",
        "aff_campus_unique": "Padova;Stockholm",
        "aff_country_unique_index": "0;1;1;0;1",
        "aff_country_unique": "Italy;Sweden"
    },
    {
        "id": "9341624",
        "title": "Decentralized Safe Reactive Planning under TWTL Specifications",
        "track": "main",
        "status": "Poster",
        "abstract": "We investigate a multi-agent planning problem, where each agent aims to achieve an individual task while avoiding collisions with others. We assume that each agent's task is expressed as a Time-Window Temporal Logic (TWTL) specification defined over a 3D environment. We propose a decentralized receding horizon algorithm for online planning of trajectories. We show that when the environment is sufficiently connected, the resulting agent trajectories are always safe (collision-free) and lead to the satisfaction of the TWTL specifications or their finite temporal relaxations. Accordingly, deadlocks are always avoided and each agent is guaranteed to safely achieve its task with a finite time-delay in the worst case. Performance of the proposed algorithm is demonstrated via numerical simulations and experiments with quadrotors.",
        "primary_area": "",
        "author": "Ryan Peterson;Ali Tevfik Buyukkocak;Derya Aksaray;Yasin Yaz\u0131c\u0131oglu;Ryan Peterson;Ali Tevfik Buyukkocak;Derya Aksaray;Yasin Yaz\u0131c\u0131oglu",
        "authorids": "/37088691462;/37088687384;/37072799400;/37088649088;/37088691462;/37088687384;/37072799400;/37088649088",
        "aff": "Department of Aerospace Engineering and Mechanics, University of Minnesota, Minneapolis, MN; Department of Aerospace Engineering and Mechanics, University of Minnesota, Minneapolis, MN; Department of Aerospace Engineering and Mechanics, University of Minnesota, Minneapolis, MN; Department of Electrical and Computer Engineering, University of Minnesota, Minneapolis, MN",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341624/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11965279167389560474&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Minnesota",
        "aff_unique_dep": "Department of Aerospace Engineering and Mechanics",
        "aff_unique_url": "https://www.umn.edu",
        "aff_unique_abbr": "UMN",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Minneapolis",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341578",
        "title": "Deep Adversarial Reinforcement Learning for Object Disentangling",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep learning in combination with improved training techniques and high computational power has led to recent advances in the field of reinforcement learning (RL) and to successful robotic RL applications such as in-hand manipulation. However, most robotic RL relies on a well known initial state distribution. In real-world tasks, this information is however often not available. For example, when disentangling waste objects the actual position of the robot w.r.t. the objects may not match the positions the RL policy was trained for. To solve this problem, we present a novel adversarial reinforcement learning (ARL) framework. The ARL framework utilizes an adversary, which is trained to steer the original agent, the protagonist, to challenging states. We train the protagonist and the adversary jointly to allow them to adapt to the changing policy of their opponent. We show that our method can generalize from training to test scenarios by training an end-to-end system for robot control to solve a challenging object disentangling task. Experiments with a KUKA LBR+ 7-DOF robot arm show that our approach outperforms the baseline method in disentangling when starting from different initial states than provided during training.",
        "primary_area": "",
        "author": "Melvin Laux;Oleg Arenz;Jan Peters;Joni Pajarinen;Melvin Laux;Oleg Arenz;Jan Peters;Joni Pajarinen",
        "authorids": "/37088686953;/37086208473;/37533077600;/37398592200;/37088686953;/37086208473;/37533077600;/37398592200",
        "aff": "Intelligent Autonomous Systems, TU Darmstadt, Germany; Intelligent Autonomous Systems, TU Darmstadt, Germany; MPI for Intelligent Systems, Tuebingen, Germany; Learning for Intelligent Autonomous Robots, Tampere University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341578/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4947364844311490405&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 13,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;2",
        "aff_unique_norm": "Technische Universit\u00e4t Darmstadt;Max Planck Institute for Intelligent Systems;Tampere University",
        "aff_unique_dep": "Intelligent Autonomous Systems;;Learning for Intelligent Autonomous Robots",
        "aff_unique_url": "https://www.tu-darmstadt.de;https://www.mpituebingen.mpg.de;https://www.tuni.fi",
        "aff_unique_abbr": "TU Darmstadt;MPI-IS;Tuni",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Tuebingen",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "Germany;Finland"
    },
    {
        "id": "9341448",
        "title": "Deep Depth Estimation from Visual-Inertial SLAM",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper addresses the problem of learning to complete a scene's depth from sparse depth points and images of indoor scenes. Specifically, we study the case in which the sparse depth is computed from a visual-inertial simultaneous localization and mapping (VI-SLAM) system. The resulting point cloud has low density, it is noisy, and has nonuniform spatial distribution, as compared to the input from active depth sensors, e.g., LiDAR or Kinect. Since the VI-SLAM produces point clouds only over textured areas, we compensate for the missing depth of the low-texture surfaces by leveraging their planar structures and their surface normals which is an important intermediate representation. The pre-trained surface normal network, however, suffers from large performance degradation when there is a significant difference in the viewing direction (especially the roll angle) of the test image as compared to the trained ones. To address this limitation, we use the available gravity estimate from the VI-SLAM to warp the input image to the orientation prevailing in the training dataset. This results in a significant performance gain for the surface normal estimate, and thus the dense depth estimates. Finally, we show that our method outperforms other state-of-the-art approaches both on training (ScanNet [1] and NYUv2 [2]) and testing (collected with Azure Kinect [3]) datasets.",
        "primary_area": "",
        "author": "Kourosh Sartipi;Tien Do;Tong Ke;Khiem Vuong;Stergios I. Roumeliotis;Kourosh Sartipi;Tien Do;Tong Ke;Khiem Vuong;Stergios I. Roumeliotis",
        "authorids": "/37085803736;/37088690498;/37087323518;/37088686343;/37274078800;/37085803736;/37088690498;/37087323518;/37088686343;/37274078800",
        "aff": "University of Minnesota, Minneapolis, MN; University of Minnesota, Minneapolis, MN; University of Minnesota, Minneapolis, MN; University of Minnesota, Minneapolis, MN; University of Minnesota, Minneapolis, MN",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341448/",
        "gs_citation": 36,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8901027674469211294&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Minnesota",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.minnesota.edu",
        "aff_unique_abbr": "UMN",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Minneapolis",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341799",
        "title": "Deep Gated Multi-modal Learning: In-hand Object Pose Changes Estimation using Tactile and Image Data",
        "track": "main",
        "status": "Poster",
        "abstract": "For in-hand manipulation, estimation of the object pose inside the hand is one of the important functions to manipulate objects to the target pose. Since in-hand manipulation tends to cause occlusions by the hand or the object itself, image information only is not sufficient for in-hand object pose estimation. Multiple modalities can be used in this case, the advantage is that other modalities can compensate for occlusion, noise, and sensor malfunctions. Even though deciding the utilization rate of a modality (referred to as reliability value) corresponding to the situations is important, the manual design of such models is difficult, especially for various situations. In this paper, we propose deep gated multi-modal learning, which self-determines the reliability value of each modality through end-to-end deep learning. For the experiments, an RGB camera and a GelSight tactile sensor were attached to the parallel gripper of the Sawyer robot, and the object pose changes were estimated during grasping. A total of 15 objects were used in the experiments. In the proposed model, the reliability values of the modalities were determined according to the noise level and failure of each modality, and it was confirmed that the pose change was estimated even for unknown objects.",
        "primary_area": "",
        "author": "Tomoki Anzai;Kuniyuki Takahashi;Tomoki Anzai;Kuniyuki Takahashi",
        "authorids": "/37086287194;/37086937050;/37086287194;/37086937050",
        "aff": "The University of Tokyo; Preferred Networks, Inc.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341799/",
        "gs_citation": 46,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16856822722830198447&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of Tokyo;Preferred Networks, Inc.",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.u-tokyo.ac.jp;https://www.preferred-networks.com",
        "aff_unique_abbr": "UTokyo;PFN",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9341608",
        "title": "Deep Imitation Learning of Sequential Fabric Smoothing From an Algorithmic Supervisor",
        "track": "main",
        "status": "Poster",
        "abstract": "Sequential pulling policies to flatten and smooth fabrics have applications from surgery to manufacturing to home tasks such as bed making and folding clothes. Due to the complexity of fabric states and dynamics, we apply deep imitation learning to learn policies that, given color (RGB), depth (D), or combined color-depth (RGBD) images of a rectangular fabric sample, estimate pick points and pull vectors to spread the fabric to maximize coverage. To generate data, we develop a fabric simulator and an algorithmic supervisor that has access to complete state information. We train policies in simulation using domain randomization and dataset aggregation (DAgger) on three tiers of difficulty in the initial randomized configuration. We present results comparing five baseline policies to learned policies and report systematic comparisons of RGB vs D vs RGBD images as inputs. In simulation, learned policies achieve comparable or superior performance to analytic baselines. In 180 physical experiments with the da Vinci Research Kit (dVRK) surgical robot, RGBD policies trained in simulation attain coverage of 83% to 95% depending on difficulty tier, suggesting that effective fabric smoothing policies can be learned from an algorithmic supervisor and that depth sensing is a valuable addition to color alone. Supplementary material is available at https://sites.google.com/view/fabric-smoothing.",
        "primary_area": "",
        "author": "Daniel Seita;Aditya Ganapathi;Ryan Hoque;Minho Hwang;Edward Cen;Ajay Kumar Tanwani;Ashwin Balakrishna;Brijen Thananjeyan;Jeffrey Ichnowski;Nawid Jamali;Katsu Yamane;Soshi Iba;John Canny;Ken Goldberg;Daniel Seita;Aditya Ganapathi;Ryan Hoque;Minho Hwang;Edward Cen;Ajay Kumar Tanwani;Ashwin Balakrishna;Brijen Thananjeyan;Jeffrey Ichnowski;Nawid Jamali;Katsu Yamane;Soshi Iba;John Canny;Ken Goldberg",
        "authorids": "/37086012763;/37088688406;/37088687016;/37085406507;/37088688072;/37086537563;/37085692655;/37086105009;/38541287200;/37546207800;/37291289300;/37329555300;/37329993400;/37273026700;/37086012763;/37088688406;/37088687016;/37085406507;/37088688072;/37086537563;/37085692655;/37086105009;/38541287200;/37546207800;/37291289300;/37329555300;/37329993400;/37273026700",
        "aff": "AUTOLAB, University of California, Berkeley, USA; AUTOLAB, University of California, Berkeley, USA; AUTOLAB, University of California, Berkeley, USA; AUTOLAB, University of California, Berkeley, USA; AUTOLAB, University of California, Berkeley, USA; AUTOLAB, University of California, Berkeley, USA; AUTOLAB, University of California, Berkeley, USA; AUTOLAB, University of California, Berkeley, USA; AUTOLAB, University of California, Berkeley, USA; Honda Research Institute, USA; Honda Research Institute, USA; Honda Research Institute, USA; AUTOLAB, University of California, Berkeley, USA; AUTOLAB, University of California, Berkeley, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341608/",
        "gs_citation": 162,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8531557903987200503&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 28,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0;1;1;1;0;0",
        "aff_unique_norm": "University of California, Berkeley;Honda Research Institute",
        "aff_unique_dep": "AUTOLAB;",
        "aff_unique_url": "https://www.berkeley.edu;https://honda-ri.com",
        "aff_unique_abbr": "UC Berkeley;HRI",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Berkeley;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341308",
        "title": "Deep Inverse Sensor Models as Priors for evidential Occupancy Mapping",
        "track": "main",
        "status": "Poster",
        "abstract": "With the recent boost in autonomous driving, increased attention has been paid on radars as an input for occupancy mapping. Besides their many benefits, the inference of occupied space based on radar detections is notoriously difficult because of the data sparsity and the environment dependent noise (e.g. multipath reflections). Recently, deep learning-based inverse sensor models, from here on called deep ISMs, have been shown to improve over their geometric counterparts in retrieving occupancy information [1], [2], [3]. Nevertheless, these methods perform a data-driven interpolation which has to be verified later on in the presence of measurements. In this work, we describe a novel approach to integrate deep ISMs together with geometric ISMs into the evidential occupancy mapping framework. Our method leverages both the capabilities of the data-driven approach to initialize cells not yet observable for the geometric model effectively enhancing the perception field and convergence speed, while at the same time use the precision of the geometric ISM to converge to sharp boundaries. We further define a lower limit on the deep ISM estimate's certainty together with analytical proofs of convergence which we use to distinguish cells that are solely allocated by the deep ISM from cells already verified using the geometric approach.",
        "primary_area": "",
        "author": "Daniel Bauer;Lars Kuhnert;Lutz Eckstein;Daniel Bauer;Lars Kuhnert;Lutz Eckstein",
        "authorids": "/37086955845;/37706537400;/37598017400;/37086955845;/37706537400;/37598017400",
        "aff": "Ford Werke GmbH, Germany; Ford Werke GmbH, Germany; Institute of Automotive Engineering, RWTH Aachen University, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341308/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7385862983610582610&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Ford Werke GmbH;RWTH Aachen University",
        "aff_unique_dep": ";Institute of Automotive Engineering",
        "aff_unique_url": "https://www.ford.de;https://www.rwth-aachen.de",
        "aff_unique_abbr": "Ford DE;RWTH",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Aachen",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9341229",
        "title": "Deep Keypoint-Based Camera Pose Estimation with Geometric Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "Estimating relative camera poses from consecutive frames is a fundamental problem in visual odometry (VO) and simultaneous localization and mapping (SLAM), where classic methods consisting of hand-crafted features and sampling-based outlier rejection have been a dominant choice for over a decade. Although multiple works propose to replace these modules with learning-based counterparts, most have not yet been as accurate, robust and generalizable as conventional methods. In this paper, we design an end-to-end trainable framework consisting of learnable modules for detection, feature extraction, matching and outlier rejection, while directly optimizing for the geometric pose objective. We show both quantitatively and qualitatively that pose estimation performance may be achieved on par with the classic pipeline. Moreover, we are able to show by end-to-end training, the key components of the pipeline could be significantly improved, which leads to better generalizability to unseen datasets compared to existing learning-based methods.",
        "primary_area": "",
        "author": "You-Yi Jau;Rui Zhu;Hao Su;Manmohan Chandraker;You-Yi Jau;Rui Zhu;Hao Su;Manmohan Chandraker",
        "authorids": "/37088690285;/37087231914;/37085651928;/37397476800;/37088690285;/37087231914;/37085651928;/37397476800",
        "aff": "University of California, San Diego; University of California, San Diego; University of California, San Diego; University of California, San Diego",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341229/",
        "gs_citation": 63,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1925086224585055015&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of California, San Diego",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.ucsd.edu",
        "aff_unique_abbr": "UCSD",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "San Diego",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341041",
        "title": "Deep Learning-Based Autonomous Scanning Electron Microscope",
        "track": "main",
        "status": "Poster",
        "abstract": "By virtue of their ultra high resolution, scanning electron microscopes (SEMs) are essential to study topography, morphology, composition, and crystallography of materials, and thus are widely used for advanced researches in physics, chemistry, pharmacy, geology, etc. The major hindrance of using SEMs is that obtaining high quality images from SEMs requires a professional control of many control parameters. Therefore, it is not an easy task even for an experienced researcher to get high quality sample images without any help from SEM experts. In this paper, we propose and implement a deep learning-based autonomous SEM machine, which assesses image quality and controls parameters autonomously to get high quality sample images just as if human experts do. This world's first autonomous SEM machine may be the first step to bring SEMs, previously used only for advanced researches due to its difficulty in use, into much broader applications such as education, manufacture, and mechanical diagnosis, which are previously meant for optical microscopes.",
        "primary_area": "",
        "author": "Jonggyu Jang;Hyeonsu Lyu;Hyun Jong Yang;Moohyun Oh;Junhee Lee;Jonggyu Jang;Hyeonsu Lyu;Hyun Jong Yang;Moohyun Oh;Junhee Lee",
        "authorids": "/37085786779;/37086520049;/37291243600;/37088686779;/37088691536;/37085786779;/37086520049;/37291243600;/37088686779;/37088691536",
        "aff": "School of Electrical and Computer Engineering, Ulsan National Institute of Science and Technology (UNIST), Ulsan, Republic of Korea; School of Electrical and Computer Engineering, Ulsan National Institute of Science and Technology (UNIST), Ulsan, Republic of Korea; Egovid Inc., Ulsan, Republic of Korea; Egovid Inc., Ulsan, Republic of Korea; Coxem Co. Ltd, Daejeon, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341041/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5503533405024326192&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;1;2",
        "aff_unique_norm": "Ulsan National Institute of Science and Technology;Egovid Inc.;Coxem Co. Ltd",
        "aff_unique_dep": "School of Electrical and Computer Engineering;;",
        "aff_unique_url": "https://www.unist.ac.kr;;",
        "aff_unique_abbr": "UNIST;;",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Ulsan;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9340882",
        "title": "Deep Mixture Density Network for Probabilistic Object Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Mistakes/uncertainties in object detection could lead to catastrophes when deploying robots in the real world. In this paper, we measure the uncertainties of object localization to minimize this kind of risk. Uncertainties emerge upon challenging cases like occlusion. The bounding box borders of an occluded object can have multiple plausible configurations. We propose a deep multivariate mixture of Gaussians model for probabilistic object detection. The covariances help to learn the relationship between the borders, and the mixture components potentially learn different configurations of an occluded part. Quantitatively, our model improves the AP of the baselines by 3.9% and 1.4% on CrowdHuman and MS-COCO respectively with almost no computational or memory overhead. Qualitatively, our model enjoys explainability since the resulting covariance matrices and the mixture components help measure uncertainties.",
        "primary_area": "",
        "author": "Yihui He;Jianren Wang;Yihui He;Jianren Wang",
        "authorids": "/37087080169;/37087079357;/37087080169;/37087079357",
        "aff": "Robotics Institute, Carnegie Mellon University, PA, USA; Robotics Institute, Carnegie Mellon University, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340882/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16070625163947788732&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341396",
        "title": "Deep Prediction of Swept Volume Geometries: Robots and Resolutions",
        "track": "main",
        "status": "Poster",
        "abstract": "Computation of the volume of space required for a robot to execute a sweeping motion from a start to a goal has long been identified as a critical primitive operation in both task and motion planning. However, swept volume computation is particularly challenging for multi-link robots with geometric complexity, e.g., manipulators, due to the non-linear geometry. While earlier work has shown that deep neural networks can approximate the swept volume quantity, a useful parameter in sampling-based planning, general network structures do not lend themselves to outputting geometries. In this paper we train and evaluate the learning of a deep neural network that predicts the swept volume geometry from pairs of robot configurations and outputs discretized voxel grids. We perform this training on a variety of robots from 6 to 16 degrees of freedom. We show that most errors in the prediction of the geometry lie within a distance of 3 voxels from the surface of the true geometry and it is possible to adjust the rates of different error types using a heuristic approach. We also show it is possible to train these networks at varying resolutions by training networks with up to 4x smaller grid resolution with errors remaining close to the boundary of the true swept volume geometry surface.",
        "primary_area": "",
        "author": "John Baxter;Mohammad R. Yousefi;Satomi Sugaya;Marco Morales;Lydia Tapia;John Baxter;Mohammad R. Yousefi;Satomi Sugaya;Marco Morales;Lydia Tapia",
        "authorids": "/37089196053;/37088689191;/37087323775;/37701227800;/37564283100;/37089196053;/37088689191;/37087323775;/37701227800;/37564283100",
        "aff": "Department of Computer Science, University of New Mexico, MSC01 11301 University of New Mexico, Albuquerque, NM, USA; Department of Computer Science, University of New Mexico, MSC01 11301 University of New Mexico, Albuquerque, NM, USA; Department of Computer Science, University of New Mexico, MSC01 11301 University of New Mexico, Albuquerque, NM, USA; Department of Digital Systems, Instituto Tecnol\u00f3gico Aut\u00f3nomo de M\u00e9xico, M\u00e9xico; Department of Computer Science, University of New Mexico, MSC01 11301 University of New Mexico, Albuquerque, NM, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341396/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10616840386785272723&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "University of New Mexico;Instituto Tecnol\u00f3gico Aut\u00f3nomo de M\u00e9xico",
        "aff_unique_dep": "Department of Computer Science;Department of Digital Systems",
        "aff_unique_url": "https://www.unm.edu;https://www.itam.mx",
        "aff_unique_abbr": "UNM;ITAM",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Albuquerque;",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "United States;Mexico"
    },
    {
        "id": "9341626",
        "title": "Deep R-Learning for Continual Area Sweeping",
        "track": "main",
        "status": "Poster",
        "abstract": "Coverage path planning is a well-studied problem in robotics in which a robot must plan a path that passes through every point in a given area repeatedly, usually with a uniform frequency. To address the scenario in which some points need to be visited more frequently than others, this problem has been extended to non-uniform coverage planning. This paper considers the variant of non-uniform coverage in which the robot does not know the distribution of relevant events beforehand and must nevertheless learn to maximize the rate of detecting events of interest. This continual area sweeping problem has been previously formalized in a way that makes strong assumptions about the environment, and to date only a greedy approach has been proposed. We generalize the continual area sweeping formulation to include fewer environmental constraints, and propose a novel approach based on reinforcement learning in a Semi-Markov Decision Process. This approach is evaluated in an abstract simulation and in a high fidelity Gazebo simulation. These evaluations show significant improvement upon the existing approach in general settings, which is especially relevant in the growing area of service robotics. We also present a video demonstration on a real service robot.",
        "primary_area": "",
        "author": "Rishi Shah;Yuqian Jiang;Justin Hart;Peter Stone;Rishi Shah;Yuqian Jiang;Justin Hart;Peter Stone",
        "authorids": "/37086577747;/37086936635;/37410293800;/37269574900;/37086577747;/37086936635;/37410293800;/37269574900",
        "aff": "Amazon (work done prior to joining Amazon); Department of Computer Science, The University of Texas at Austin; Department of Computer Science, The University of Texas at Austin; Sony AI",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341626/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7271229312852181055&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;2",
        "aff_unique_norm": "Amazon.com, Inc.;The University of Texas at Austin;Sony",
        "aff_unique_dep": ";Department of Computer Science;Sony AI",
        "aff_unique_url": "https://www.amazon.com;https://www.utexas.edu;https://www.sony.com",
        "aff_unique_abbr": "Amazon;UT Austin;Sony AI",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Austin",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "United States;Japan"
    },
    {
        "id": "9341714",
        "title": "Deep Reinforcement Learning for Industrial Insertion Tasks with Visual Inputs and Natural Rewards",
        "track": "main",
        "status": "Poster",
        "abstract": "Connector insertion and many other tasks commonly found in modern manufacturing settings involve complex contact dynamics and friction. Since it is difficult to capture related physical effects with first-order modeling, traditional control methods often result in brittle and inaccurate controllers, which have to be manually tuned. Reinforcement learning (RL) methods have been demonstrated to be capable of learning controllers in such environments from autonomous interaction with the environment, but running RL algorithms in the real world poses sample efficiency and safety challenges. Moreover, in practical real-world settings, we cannot assume access to perfect state information or dense reward signals. In this paper, we consider a variety of difficult industrial insertion tasks with visual inputs and different natural reward specifications, namely sparse rewards and goal images. We show that methods that combine RL with prior information, such as classical controllers or demonstrations, can solve these tasks from a reasonable amount of real-world interaction.",
        "primary_area": "",
        "author": "Gerrit Schoettler;Ashvin Nair;Jianlan Luo;Shikhar Bahl;Juan Aparicio Ojea;Eugen Solowjow;Sergey Levine;Gerrit Schoettler;Ashvin Nair;Jianlan Luo;Shikhar Bahl;Juan Aparicio Ojea;Eugen Solowjow;Sergey Levine",
        "authorids": "/37088690341;/37086106243;/37086453933;/37086937856;/37088413576;/37947855300;/37085481973;/37088690341;/37086106243;/37086453933;/37086937856;/37088413576;/37947855300;/37085481973",
        "aff": "Siemens Corporation; University of California, Berkeley; University of California, Berkeley; University of California, Berkeley; Siemens Corporation; Siemens Corporation; University of California, Berkeley",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341714/",
        "gs_citation": 237,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2360911920570145801&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;1;1;0;0;1",
        "aff_unique_norm": "Siemens AG;University of California, Berkeley",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.siemens.com;https://www.berkeley.edu",
        "aff_unique_abbr": "Siemens;UC Berkeley",
        "aff_campus_unique_index": "1;1;1;1",
        "aff_campus_unique": ";Berkeley",
        "aff_country_unique_index": "0;1;1;1;0;0;1",
        "aff_country_unique": "Germany;United States"
    },
    {
        "id": "9341596",
        "title": "Deep Tactile Experience: Estimating Tactile Sensor Output from Depth Sensor Data",
        "track": "main",
        "status": "Poster",
        "abstract": "Tactile sensing is inherently contact based. To use tactile data, robots need to make contact with the surface of an object. This is inefficient in applications where an agent needs to make a decision between multiple alternatives that depend the physical properties of the contact location. We propose a method to get tactile data in a non-invasive manner. The proposed method estimates the output of a tactile sensor from the depth data of the surface of the object based on past experiences. An experience dataset is built by allowing the robot to interact with various objects, collecting tactile data and the corresponding object surface depth data. We use the experience dataset to train a neural network to estimate the tactile output from depth data alone. We use GelSight tactile sensors, an image-based sensor, to generate images that capture detailed surface features at the contact location. We train a network with a dataset containing 578 tactile-image to depth- map correspondences. Given a depth-map of the surface of an object, the network outputs an estimate of the response of the tactile sensor, should it make a contact with the object. We evaluate the method with structural similarity index matrix (SSIM), a similarity metric between two images commonly used in image processing community. We present experimental results that show the proposed method outperforms a baseline that uses random images with statistical significance getting an SSIM score of 0.84 \u00b1 0.0056 and 0.80 \u00b1 0.0036, respectively.",
        "primary_area": "",
        "author": "Karankumar Patel;Soshi Iba;Nawid Jamali;Karankumar Patel;Soshi Iba;Nawid Jamali",
        "authorids": "/37088691487;/37329555300;/37546207800;/37088691487;/37329555300;/37546207800",
        "aff": "Honda Research Institute USA, Inc.; Honda Research Institute USA, Inc.; Honda Research Institute USA, Inc.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341596/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11778717239500382005&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Honda Research Institute USA",
        "aff_unique_dep": "Research Institute",
        "aff_unique_url": "https://honda-ri.com",
        "aff_unique_abbr": "HRI USA",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341077",
        "title": "DeepLiDARFlow: A Deep Learning Architecture For Scene Flow Estimation Using Monocular Camera and Sparse LiDAR",
        "track": "main",
        "status": "Poster",
        "abstract": "Scene flow is the dense 3D reconstruction of motion and geometry of a scene. Most state-of-the-art methods use a pair of stereo images as input for full scene reconstruction. These methods depend a lot on the quality of the RGB images and perform poorly in regions with reflective objects, shadows, ill-conditioned light environment and so on. LiDAR measurements are much less sensitive to the aforementioned conditions but LiDAR features are in general unsuitable for matching tasks due to their sparse nature. Hence, using both LiDAR and RGB can potentially overcome the individual disadvantages of each sensor by mutual improvement and yield robust features which can improve the matching process. In this paper, we present DeepLiDARFlow, a novel deep learning architecture which fuses high level RGB and LiDAR features at multiple scales in a monocular setup to predict dense scene flow. Its performance is much better in the critical regions where image-only and LiDAR-only methods are inaccurate. We verify our DeepLiDARFlow using the established data sets KITTI and FlyingThings3D and we show strong robustness compared to several state-of-the-art methods which used other input modalities. The code of our paper is available at https://github.com/dfki-av/DeepLiDARFlow.",
        "primary_area": "",
        "author": "Rishav Rishav;Ramy Battrawy;Ren\u00e9 Schuster;Oliver Wasenm\u00fcller;Didier Stricker;Rishav Rishav;Ramy Battrawy;Ren\u00e9 Schuster;Oliver Wasenm\u00fcller;Didier Stricker",
        "authorids": "/37088689999;/37086784293;/37086375640;/37085789724;/37326112700;/37088689999;/37086784293;/37086375640;/37085789724;/37326112700",
        "aff": "Birla Institute of Technology and Science - BITS Pilani, Pilani, India; German Research Center for Artificial Intelligence - DFKI, Kaisers-lautern, Germany; German Research Center for Artificial Intelligence - DFKI, Kaisers-lautern, Germany; University of Applied Sciences Mannheim, Mannheim, Germany; University of Kaiserslautern - TUK, Kaiserslautern, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341077/",
        "gs_citation": 38,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1188602688320046235&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;2;3",
        "aff_unique_norm": "Birla Institute of Technology and Science;German Research Center for Artificial Intelligence;University of Applied Sciences Mannheim;University of Kaiserslautern",
        "aff_unique_dep": ";DFKI;;",
        "aff_unique_url": "https://www.bits-pilani.ac.in;https://www.dfki.de;https://www.hochschule-mannheim.de;https://www.uni-kl.de",
        "aff_unique_abbr": "BITS Pilani;DFKI;;TUK",
        "aff_campus_unique_index": "0;1;1;2;1",
        "aff_campus_unique": "Pilani;Kaiserslautern;Mannheim",
        "aff_country_unique_index": "0;1;1;1;1",
        "aff_country_unique": "India;Germany"
    },
    {
        "id": "9341805",
        "title": "DeepMNavigate: Deep Reinforced Multi-Robot Navigation Unifying Local & Global Collision Avoidance",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a novel algorithm (DeepMNavigate) for global multi-agent navigation in dense scenarios using deep reinforcement learning (DRL). Our approach uses local and global information for each robot from motion information maps. We use a three-layer CNN that takes these maps as input to generate a suitable action to drive each robot to its goal position. Our approach is general, learns an optimal policy using a multi-scenario, multi-state training algorithm, and can directly handle raw sensor measurements for local observations. We demonstrate the performance on dense, complex benchmarks with narrow passages and environments with tens of agents. We highlight the algorithm\u2019s benefits over prior learning methods and geometric decentralized algorithms in complex scenarios.",
        "primary_area": "",
        "author": "Qingyang Tan;Tingxiang Fan;Jia Pan;Dinesh Manocha;Qingyang Tan;Tingxiang Fan;Jia Pan;Dinesh Manocha",
        "authorids": "/37086567528;/37086615218;/37535628800;/37267825600;/37086567528;/37086615218;/37535628800;/37267825600",
        "aff": "Department of Computer Science and Electrical & Computer Engineering, University of Maryland at College Park; Department of Computer Science, University of Hong Kong; Department of Computer Science, University of Hong Kong; Department of Computer Science and Electrical & Computer Engineering, University of Maryland at College Park",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341805/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16895073549762538572&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "University of Maryland;University of Hong Kong",
        "aff_unique_dep": "Department of Computer Science and Electrical & Computer Engineering;Department of Computer Science",
        "aff_unique_url": "https://www.umd.edu;https://www.hku.hk",
        "aff_unique_abbr": "UMD;HKU",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "College Park;Hong Kong SAR",
        "aff_country_unique_index": "0;1;1;0",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "9341201",
        "title": "DeepURL: Deep Pose Estimation Framework for Underwater Relative Localization",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a real-time deep learning approach for determining the 6D relative pose of Autonomous Underwater Vehicles (AUV) from a single image. A team of autonomous robots localizing themselves in a communication-constrained underwater environment is essential for many applications such as underwater exploration, mapping, multi-robot convoying, and other multi-robot tasks. Due to the profound difficulty of collecting ground truth images with accurate 6D poses underwater, this work utilizes rendered images from the Unreal Game Engine simulation for training. An image-to-image translation network is employed to bridge the gap between the rendered and the real images producing synthetic images for training. The proposed method predicts the 6D pose of an AUV from a single image as 2D image keypoints representing 8 corners of the 3D model of the AUV, and then the 6D pose in the camera coordinates is determined using RANSAC-based PnP. Experimental results in real-world underwater environments (swimming pool and ocean) with different cameras demonstrate the robustness and accuracy of the proposed technique in terms of translation error and orientation error over the state-of-the-art methods. The code is publicly available.",
        "primary_area": "",
        "author": "Bharat Joshi;Md Modasshir;Travis Manderson;Hunter Damron;Marios Xanthidis;Alberto Quattrini Li;Ioannis Rekleitis;Gregory Dudek;Bharat Joshi;Md Modasshir;Travis Manderson;Hunter Damron;Marios Xanthidis;Alberto Quattrini Li;Ioannis Rekleitis;Gregory Dudek",
        "authorids": "/37087324582;/37086170911;/38491501400;/37086573954;/37085810183;/37085808885;/37281356300;/37274057100;/37087324582;/37086170911;/38491501400;/37086573954;/37085810183;/37085808885;/37281356300;/37274057100",
        "aff": "University of South Carolina, Columbia, SC, USA; University of South Carolina, Columbia, SC, USA; McGill University, Montreal, Quebec, Canada; University of South Carolina, Columbia, SC, USA; University of South Carolina, Columbia, SC, USA; Dartmouth College, Hanover, NH, USA; University of South Carolina, Columbia, SC, USA; McGill University, Montreal, Quebec, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341201/",
        "gs_citation": 34,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11270211515446296417&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;1;0;0;2;0;1",
        "aff_unique_norm": "University of South Carolina;McGill University;Dartmouth College",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.sc.edu;https://www.mcgill.ca;https://www.dartmouth.edu",
        "aff_unique_abbr": "USC;McGill;Dartmouth",
        "aff_campus_unique_index": "0;0;1;0;0;2;0;1",
        "aff_campus_unique": "Columbia;Montreal;Hanover",
        "aff_country_unique_index": "0;0;1;0;0;0;0;1",
        "aff_country_unique": "United States;Canada"
    },
    {
        "id": "9341650",
        "title": "Demonstration of a Novel Phase Lag Controlled Roll Rotation Mechanism using a Two-DOF Soft Swimming Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Underwater roll rotation is a basic but essential maneuver that allows many biological swimmers to achieve high maneuverability and complex locomotion patterns. In particular, sea mammals (e.g., sea otter) with flexible vertebra structures have a unique mechanism to efficiently achieve roll rotation, not propelled mainly by inter-digital webbing or fin, but by bending and twisting their body.In this work, we attempt to implement and effectively control the roll rotation by mimicking this kind of efficient biomorphic roll mechanism on our two degrees of freedom (DOF) soft modular swimming robot. The robot also allows the achievement of other common maneuvers, such as pitch/yaw rotation and linear swimming patterns. The proposed 2DOF soft swimming robot platform includes an underactuated, cable-driven design that mimics the flexible cascaded skeletal structure of soft spine tissue and hard spine bone seen in many fish species. The cable-driven actuation mechanism is oriented laterally for forwarding motion and steering in a 3D plane. The robot can perform a steady and controllable roll rotation with a maximum angular speed of 41.6 deg/s. A hypothesis explaining this novel roll rotation mechanism is set forth, and the phenomenon is systematically studied at different frequencies and phase lag gait conditions. Preliminary results show a linear relationship between roll angular velocity and frequency within a specific range. Additionally, the roll rotation can be controlled independently in some special conditions. These abilities form the foundation for future research on 3D underwater locomotion with adaptive, controllable maneuvering capabilities.",
        "primary_area": "",
        "author": "Bangyuan Liu;Frank L. Hammond;Bangyuan Liu;Frank L. Hammond",
        "authorids": "/37086840054;/37394264300;/37086840054;/37394264300",
        "aff": "Woodruff School of Mechanical Engineering, Georgia Institute of Technology, Atlanta, GA; Woodruff School of Mechanical Engineering, Georgia Institute of Technology, Atlanta, GA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341650/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13898419606744652741&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Georgia Institute of Technology",
        "aff_unique_dep": "Woodruff School of Mechanical Engineering",
        "aff_unique_url": "https://www.gatech.edu",
        "aff_unique_abbr": "Georgia Tech",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Atlanta",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341680",
        "title": "Dense Decentralized Multi-robot SLAM based on locally consistent TSDF submaps",
        "track": "main",
        "status": "Poster",
        "abstract": "This article introduces a decentralized multi-robot algorithm for Simultaneous Localization And Mapping (SLAM) inspired from previous work on collaborative mapping [1]. This method makes robots jointly build and exchange i) a collection of 3D dense locally consistent submaps, based on a Truncated Signed Distance Field (TSDF) representation of the environment, and ii) a pose-graph representation which encodes the relative pose constraints between the TSDF submaps and the trajectory keyframes, derived from the odometry, inter-robot observations and loop closures. Such loop closures are spotted by aligning and fusing the TSDF submaps. The performances of this method have been evaluated on multi-robot scenarios built from the EuRoC dataset [2].",
        "primary_area": "",
        "author": "Rodolphe Dubois;Alexandre Eudes;Julien Moras;Vincent Fr\u00e9mont;Rodolphe Dubois;Alexandre Eudes;Julien Moras;Vincent Fr\u00e9mont",
        "authorids": "/37086521705;/37892221500;/37706535000;/37428082500;/37086521705;/37892221500;/37706535000;/37428082500",
        "aff": "Centrale Nantes, LS2N, Nantes, France; DTIS, ONERA, Universit\u00e9 Paris Saclay, Palaiseau, France; DTIS, ONERA, Universit\u00e9 Paris Saclay, Palaiseau, France; Centrale Nantes, LS2N, Nantes, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341680/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18074061223778629823&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "Centrale Nantes;ONERA",
        "aff_unique_dep": "LS2N;DTIS",
        "aff_unique_url": "https://www.centrale-nantes.fr;https://www.onera.fr",
        "aff_unique_abbr": ";ONERA",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Nantes;Palaiseau",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9341658",
        "title": "Dense Incremental Metric-Semantic Mapping via Sparse Gaussian Process Regression",
        "track": "main",
        "status": "Poster",
        "abstract": "We develop an online probabilistic metric-semantic mapping approach for autonomous robots relying on streaming RGB-D observations. We cast this problem as a Bayesian inference task, requiring encoding both the geometric surfaces and semantic labels (e.g., chair, table, wall) of the unknown environment. We propose an online Gaussian Process (GP) training and inference approach, which avoids the complexity of GP classification by regressing a truncated signed distance function representation of the regions occupied by different semantic classes. Online regression is enabled through sparse GP approximation, compressing the training data to a finite set of inducing points, and through spatial domain partitioning into an Octree data structure with overlapping leaves. Our experiments demonstrate the effectiveness of this technique for large-scale probabilistic metric-semantic mapping of 3D environments. A distinguishing feature of our approach is that the generated maps contain full continuous distributional information about the geometric surfaces and semantic labels, making them appropriate for uncertainty-aware planning.",
        "primary_area": "",
        "author": "Ehsan Zobeidi;Alec Koppel;Nikolay Atanasov;Ehsan Zobeidi;Alec Koppel;Nikolay Atanasov",
        "authorids": "/37088481826;/37085457697;/37670511000;/37088481826;/37085457697;/37670511000",
        "aff": "Department of Electrical and Computer Engineering, University of California, CA, USA; Computational and Information Sciences Directorate, U.S. Army Research Laboratory, Adelphi, MD, USA; Department of Electrical and Computer Engineering, University of California, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341658/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2543261265536943666&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of California;U.S. Army Research Laboratory",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Computational and Information Sciences Directorate",
        "aff_unique_url": "https://www.universityofcalifornia.edu;https://www.arl.army.mil",
        "aff_unique_abbr": "UC;ARL",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "CA;Adelphi",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341413",
        "title": "DenseFusion: Large-Scale Online Dense Pointcloud and DSM Mapping for UAVs",
        "track": "main",
        "status": "Poster",
        "abstract": "With the rapidly developing unmanned aerial vehicles, the requirements of generating maps efficiently and quickly are increasing. To realize online mapping, we develop a real-time dense mapping framework named DenseFusion which can incrementally generates dense geo-referenced 3D point cloud, digital orthophoto map (DOM) and digital surface model (DSM) from sequential aerial images with optional GPS information. The proposed method works in real-time on standard CPUs even for processing high resolution images. Based on the advanced monocular SLAM, our system first estimates appropriate camera poses and extracts effective keyframes, and next constructs virtual stereo-pair from consecutive frame to generate pruned dense 3D point clouds; then a novel realtime DSM fusion method is proposed which can incrementally process dense point cloud. Finally, a high efficiency visualization system is developed to adopt dynamic levels of detail (LoD) method, which makes it render dense point cloud and DSM smoothly. The performance of the proposed method is evaluated through qualitative and quantitative experiments. The results indicate that compared to traditional structure from motion based approaches, the presented framework is able to output both large-scale high-quality DOM and DSM in real-time with low computational cost.",
        "primary_area": "",
        "author": "Lin Chen;Yong Zhao;Shibiao Xu;Shuhui Bu;Pengcheng Han;Gang Wan;Lin Chen;Yong Zhao;Shibiao Xu;Shuhui Bu;Pengcheng Han;Gang Wan",
        "authorids": "/37088686775;/37086205716;/37085335553;/37409668400;/37086811972;/37402119900;/37088686775;/37086205716;/37085335553;/37409668400;/37086811972;/37402119900",
        "aff": "Northwestern Polytechnical University, Xi\u2019an, China; Northwestern Polytechnical University, Xi\u2019an, China; Chinese Academy of Sciences, Institute of Automation, Beijing, China; Northwestern Polytechnical University, Xi\u2019an, China; Northwestern Polytechnical University, Xi\u2019an, China; The School of Aerospace Information, Aerospace Engineering University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341413/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14039079871805954880&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;0;0;2",
        "aff_unique_norm": "Northwestern Polytechnical University;Chinese Academy of Sciences;Aerospace Engineering University",
        "aff_unique_dep": ";Institute of Automation;School of Aerospace Information",
        "aff_unique_url": "http://www.nwpu.edu.cn;http://www.ia.cas.cn;",
        "aff_unique_abbr": "NWPU;CAS;",
        "aff_campus_unique_index": "0;0;1;0;0;1",
        "aff_campus_unique": "Xi'an;Beijing",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9341385",
        "title": "Depth Completion via Inductive Fusion of Planar LIDAR and Monocular Camera",
        "track": "main",
        "status": "Poster",
        "abstract": "Modern high-definition LIDAR is expensive for commercial autonomous driving vehicles and small indoor robots. An affordable solution to this problem is fusion of planar LIDAR with RGB images to provide a similar level of perception capability. Even though state-of-the-art methods provide approaches to predict depth information from limited sensor input, they are usually a simple concatenation of sparse LIDAR features and dense RGB features through an end-to-end fusion architecture. In this paper, we introduce an inductive late-fusion block which better fuses different sensor modalities inspired by a probability model. The proposed demonstration and aggregation network propagates the mixed context and depth features to the prediction network and serves as a prior knowledge of the depth completion. This late-fusion block uses the dense context features to guide the depth prediction based on demonstrations by sparse depth features. In addition to evaluating the proposed method on benchmark depth completion datasets including NYUDepthV2 and KITTI, we also test the proposed method on a simulated planar LIDAR dataset. Our method shows promising results compared to previous approaches on both the benchmark datasets and simulated dataset with various 3D densities.",
        "primary_area": "",
        "author": "Chen Fu;Chiyu Dong;Christoph Mertz;John M. Dolan;Chen Fu;Chiyu Dong;Christoph Mertz;John M. Dolan",
        "authorids": "/37086544947;/37086089544;/37666676000;/37283756800;/37086544947;/37086089544;/37666676000;/37283756800",
        "aff": "Department of Electrical and Computer Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Electrical and Computer Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341385/",
        "gs_citation": 35,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16001085112990424925&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340998",
        "title": "Depth Estimation from Monocular Images and Sparse Radar Data",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we explore the possibility of achieving a more accurate depth estimation by fusing monocular images and Radar points using a deep neural network. We give a comprehensive study of the fusion between RGB images and Radar measurements from different aspects and proposed a working solution based on the observations. We find that the noise existing in Radar measurements is one of the main key reasons that prevents one from applying the existing fusion methods developed for LiDAR data and images to the new fusion problem between Radar data and images. The experiments are conducted on the nuScenes dataset, which is one of the first datasets which features Camera, Radar, and LiDAR recordings in diverse scenes and weather conditions. Extensive experiments demonstrate that our method outperforms existing fusion methods. We also provide detailed ablation studies to show the effectiveness of each component in our method.",
        "primary_area": "",
        "author": "Juan-Ting Lin;Dengxin Dai;Luc Van Gool;Juan-Ting Lin;Dengxin Dai;Luc Van Gool",
        "authorids": "/37086454051;/37531409100;/37266870700;/37086454051;/37531409100;/37266870700",
        "aff": "Computer Vision Lab, ETH, Zurich, Switzerland; Computer Vision Lab, ETH, Zurich, Switzerland; Computer Vision Lab, ETH, Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340998/",
        "gs_citation": 85,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1029963076453856677&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Computer Vision Lab",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Zurich",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9340953",
        "title": "Design and Control of Roller Grasper V2 for In-Hand Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "The ability to perform in-hand manipulation still remains an unsolved problem; having this capability would allow robots to perform sophisticated tasks requiring repositioning and reorienting of grasped objects. In this work, we present a novel non-anthropomorphic robot grasper with the ability to manipulate objects by means of active surfaces at the fingertips. Active surfaces are achieved by spherical rolling fingertips with two degrees of freedom (DoF) - a pivoting motion for surface reorientation - and a continuous rolling motion for moving the object. A further DoF is in the base of each finger, allowing the fingers to grasp objects over a range of size and shapes. Instantaneous kinematics was derived and objects were successfully manipulated both with a custom handcrafted control scheme as well as one learned through imitation learning, in simulation and experimentally on the hardware.",
        "primary_area": "",
        "author": "Shenli Yuan;Lin Shao;Connor L. Yako;Alex Gruebele;J. Kenneth Salisbury;Shenli Yuan;Lin Shao;Connor L. Yako;Alex Gruebele;J. Kenneth Salisbury",
        "authorids": "/37088506196;/37086423705;/37088686183;/37086092763;/37355483800;/37088506196;/37086423705;/37088686183;/37086092763;/37355483800",
        "aff": "Stanford Artificial Intelligence Lab (SAIL), Stanford University; Stanford Artificial Intelligence Lab (SAIL), Stanford University; Stanford Artificial Intelligence Lab (SAIL), Stanford University; Department of Mechanical Engineering, Stanford University; Stanford Artificial Intelligence Lab (SAIL), Stanford University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340953/",
        "gs_citation": 57,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6307295890186257333&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "Stanford Artificial Intelligence Lab (SAIL)",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341143",
        "title": "Design and Control of SLIDER: An Ultra-lightweight, Knee-less, Low-cost Bipedal Walking Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Most state-of-the-art bipedal robots are designed to be anthropomorphic and therefore possess legs with knees. Whilst this facilitates more human-like locomotion, there are implementation issues that make walking with straight or near-straight legs difficult. Most bipedal robots have to move with a constant bend in the legs to avoid singularities at the knee joints, and to keep the centre of mass at a constant height for control purposes. Furthermore, having a knee on the leg increases the design complexity as well as the weight of the leg, hindering the robot\u2019s performance in agile behaviours such as running and jumping.We present SLIDER, an ultra-lightweight, low-cost bipedal walking robot with a novel knee-less leg design. This non-anthropomorphic straight-legged design reduces the weight of the legs significantly whilst keeping the same functionality as anthropomorphic legs. Simulation results show that SLIDER\u2019s low-inertia legs contribute to less vertical motion in the center of mass (CoM) than anthropomorphic robots during walking, indicating that SLIDER\u2019s model is closer to the widely used Inverted Pendulum (IP) model. Finally, stable walking on flat terrain is demonstrated both in simulation and in the physical world, and feedback control is implemented to address challenges with the physical robot.",
        "primary_area": "",
        "author": "Ke Wang;David Marsh;Roni Permana Saputra;Digby Chappell;Zhonghe Jiang;Akshay Raut;Bethany Kon;Petar Kormushev;Ke Wang;David Marsh;Roni Permana Saputra;Digby Chappell;Zhonghe Jiang;Akshay Raut;Bethany Kon;Petar Kormushev",
        "authorids": "/37088686222;/37088690413;/37086076815;/37088691283;/37088686430;/37088689505;/37088687448;/37590229500;/37088686222;/37088690413;/37086076815;/37088691283;/37088686430;/37088689505;/37088687448;/37590229500",
        "aff": "Robot Intelligence Lab, Dyson School of Design Engineering, Imperial College, London, UK; Department of Mechanical Engineering, Imperial College, London, UK; Research Center for Electrical Power and Mechatronics, Indonesian Institute of Sciences - LIPI, Indonesia; Robot Intelligence Lab, Dyson School of Design Engineering, Imperial College, London, UK; Department of Electrical and Electronic Engineering, Imperial College, London, UK; Department of Mechanical Engineering, Imperial College, London, UK; Department of Bioengineering, Imperial College, London, UK; Robot Intelligence Lab, Dyson School of Design Engineering, Imperial College, London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341143/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3968291359579704360&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;1;0;0;0;0;0",
        "aff_unique_norm": "Imperial College London;Indonesian Institute of Sciences",
        "aff_unique_dep": "Dyson School of Design Engineering;Research Center for Electrical Power and Mechatronics",
        "aff_unique_url": "https://www.imperial.ac.uk;https://www.lipi.go.id",
        "aff_unique_abbr": "ICL;LIPI",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "London;",
        "aff_country_unique_index": "0;0;1;0;0;0;0;0",
        "aff_country_unique": "United Kingdom;Indonesia"
    },
    {
        "id": "9341730",
        "title": "Design and Control of SQUEEZE: A Spring-augmented QUadrotor for intEractions with the Environment to squeeZE-and-fly",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents the design and control of a novel quadrotor with a variable geometry to physically interact with cluttered environments and fly through narrow gaps and passageways. This compliant quadrotor with passive morphing capabilities is designed using torsional springs at every arm hinge to allow for rotation driven by external forces. We derive the dynamic model of this variable geometry quadrotor (SQUEEZE), and develop an adaptive controller for trajectory tracking. The corresponding Lyapunov stability proof of attitude tracking is also presented. Further, an admittance controller is designed to account for changes in yaw due to physical interactions with the environment. Finally, the proposed design is validated in flight tests with two setups: a small gap and a passageway. The experimental results demonstrate the unique capability of the SQUEEZE in navigating through constrained narrow spaces.",
        "primary_area": "",
        "author": "Karishma Patnaik;Shatadal Mishra;Seyed Mostafa Rezayat Sorkhabadi;Wenlong Zhang;Karishma Patnaik;Shatadal Mishra;Seyed Mostafa Rezayat Sorkhabadi;Wenlong Zhang",
        "authorids": "/37088454310;/37086962705;/37088686127;/37085823780;/37088454310;/37086962705;/37088686127;/37085823780",
        "aff": "Ira A. Fulton Schools of Engineering, The Polytechnic School, Arizona State University, Mesa, AZ, USA; Ira A. Fulton Schools of Engineering, The Polytechnic School, Arizona State University, Mesa, AZ, USA; Ira A. Fulton Schools of Engineering, The Polytechnic School, Arizona State University, Mesa, AZ, USA; Ira A. Fulton Schools of Engineering, The Polytechnic School, Arizona State University, Mesa, AZ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341730/",
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13616267592537274487&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Arizona State University",
        "aff_unique_dep": "Ira A. Fulton Schools of Engineering",
        "aff_unique_url": "https:// Fulton.asu.edu",
        "aff_unique_abbr": "ASU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Mesa",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341100",
        "title": "Design and Evaluation of a Perching Hexacopter Drone for Energy Harvesting from Power Lines",
        "track": "main",
        "status": "Poster",
        "abstract": "With a growing number of applications in the world for UAVs, there is a clear limitation regarding the need for extended battery life. With the current flight times, many users would benefit greatly with an innovative option of field charging these devices. The objective of this project is to investigate feasibility of inductively harvesting energy from a power line cable for applications such as charging a UAV drone. Research investigates a dual hook perching device that securely attaches to a power cable and aligns an inductive core with the cable for harvesting energy from its electro-magnetic field. Modeling and analysis of the core highlights critical design parameters, leading to evaluation of circular, semi-cylindrical, and u-shaped prototypes designed to interface with a 1\" power cable. Underactuated two jaw manipulators at each end of the coil are proposed for grasping the cable and aligning it with the charging coil, ultimately providing a firm grasp and perch. An open source hexacopter drone was used in this study to integrate with the charging novelty. The results provided can be used as a starting point to study the reliability of this method of charging and to further investigate perching abilities of UAVs.",
        "primary_area": "",
        "author": "Ryan Kitchen;Nick Bierwolf;Sean Harbertson;Brage Platt;Dean Owen;Klaus Griessmann;Mark A. Minor;Ryan Kitchen;Nick Bierwolf;Sean Harbertson;Brage Platt;Dean Owen;Klaus Griessmann;Mark A. Minor",
        "authorids": "/37088686163;/37088687541;/37088691166;/37088686407;/37088690238;/37088687462;/37279831800;/37088686163;/37088687541;/37088691166;/37088686407;/37088690238;/37088687462;/37279831800",
        "aff": "University of Utah, Salt Lake City, UT; University of Utah, Salt Lake City, UT; University of Utah, Salt Lake City, UT; University of Utah, Salt Lake City, UT; University of Utah, Salt Lake City, UT; University of Utah, Salt Lake City, UT; University of Utah, Salt Lake City, UT, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341100/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1954502678170698355&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "University of Utah",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.utah.edu",
        "aff_unique_abbr": "U of U",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Salt Lake City",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341497",
        "title": "Design and Experimentation of a Variable Stiffness Bistable Gripper",
        "track": "main",
        "status": "Poster",
        "abstract": "Grasping and manipulating objects is an integral part of many robotic systems. Both soft and rigid grippers have been investigated for manipulating objects in a multitude of different roles. Rigid grippers can hold heavy objects and apply large amounts of force, while soft grippers can conform to the size and shape of objects as well as protect fragile objects from excess stress. However, grippers that possess the qualities of both rigid and soft grippers are under-explored. In this paper, we present a novel gripper with two distinct properties: 1) it can vary its stiffness to become either a soft gripper that can conform its shape to fit complex objects or a rigid gripper that can hold a large weight; 2) when the gripper is soft, it has two stable states (i.e., bistable): open and closed: allowing it to be closed without an actuator but through contact force with a target object. The variable stiffness is accomplished by heating a shape memory polymer (SMP) material through its glass transition temperature. The bi-stability is achieved by shaping the gripper's energy landscape through two elastic elements. This paper details the design and fabrication process of this gripper, as well as quantifies the influence of temperature variations on this gripper. The capability of the gripper is experimentally verified by grasping different objects with various shapes and weights. We expect such a gripper to be suitable for many applications that traditionally require either a rigid or a soft gripper.",
        "primary_area": "",
        "author": "Elisha Lerner;Haijie Zhang;Jianguo Zhao;Elisha Lerner;Haijie Zhang;Jianguo Zhao",
        "authorids": "/37088690535;/37085825593;/37537638600;/37088690535;/37085825593;/37537638600",
        "aff": "Department of Mechanical Engineering, Colorado State University, Fort Collins, CO, USA; Department of Mechanical Engineering, Colorado State University, Fort Collins, CO, USA; Department of Mechanical Engineering, Colorado State University, Fort Collins, CO, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341497/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6933431524513553436&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Colorado State University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.colostate.edu",
        "aff_unique_abbr": "CSU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Fort Collins",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341007",
        "title": "Design and Experiments with LoCO AUV: A Low Cost Open-Source Autonomous Underwater Vehicle",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper we present the LoCO AUV, a Low-Cost, Open Autonomous Underwater Vehicle. LoCO is a general-purpose, single-person-deployable, vision-guided AUV, rated to a depth of 100 meters. We discuss the open and expandable design of this underwater robot, as well as the design of a simulator in Gazebo. Additionally, we explore the platform's preliminary local motion control and state estimation abilities, which enable it to perform maneuvers autonomously. In order to demonstrate its usefulness for a variety of tasks, we implement a variety of our previously presented human-robot interaction capabilities on LoCO, including gestural control, diver following, and robot communication via motion. Finally, we discuss the practical concerns of deployment and our experiences in using this robot in pools, lakes, and the ocean. All design details, instructions on assembly, and code will be released under a permissive, open-source license.",
        "primary_area": "",
        "author": "Chelsey Edge;Sadman Sakib Enan;Michael Fulton;Jungseok Hong;Jiawei Mo;Kimberly Barthelemy;Hunter Bashaw;Berik Kallevig;Corey Knutson;Kevin Orpen;Junaed Sattar;Chelsey Edge;Sadman Sakib Enan;Michael Fulton;Jungseok Hong;Jiawei Mo;Kimberly Barthelemy;Hunter Bashaw;Berik Kallevig;Corey Knutson;Kevin Orpen;Junaed Sattar",
        "authorids": "/37086933249;/37088507552;/37086541498;/37088505608;/37087322233;/37088688580;/37088690240;/37088686865;/37088691233;/37088686080;/37546394500;/37086933249;/37088507552;/37086541498;/37088505608;/37087322233;/37088688580;/37088690240;/37088686865;/37088691233;/37088686080;/37546394500",
        "aff": "University of Minnesota Computer Science; University of Minnesota Computer Science; University of Minnesota Computer Science; University of Minnesota Computer Science; University of Minnesota Computer Science; University of Minnesota Aerospace Engineering; Clarkson University Computer Science; University of Minnesota Mechanical Engineering; University of Minnesota - Duluth Computer Science; University of Minnesota Aerospace Engineering; Computer Science at University of Minnesota",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341007/",
        "gs_citation": 59,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1093157152950125937&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 22,
        "aff_unique_index": "0;0;0;0;0;0;1;0;2;0;0",
        "aff_unique_norm": "University of Minnesota;Clarkson University;University of Minnesota Duluth",
        "aff_unique_dep": "Computer Science;Computer Science;Computer Science",
        "aff_unique_url": "https://www.umn.edu;https://www.clarkson.edu;https://d.umn.edu",
        "aff_unique_abbr": "UMN;Clarkson;UMD",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";Duluth;Minneapolis",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340976",
        "title": "Design and Implementation of a Haptic Measurement Glove to Create Realistic Human-Telerobot Interactions",
        "track": "main",
        "status": "Poster",
        "abstract": "Although research indicates that telepresence robots offer a more socially telepresent alternative to conventional forms of remote communication, the lack of touch-based interactions presents challenges for both remote and local users. In order to address these challenges, we have designed and implemented a robotic manipulator emulating a human arm. However, contact interactions like handshakes with a robotic manipulator may feel awkward and unnatural to local users. In this work, we present the design of a wearable haptic measurement glove (HMG) and use it to collect force and inertial data on handshakes in human-human and humanrobot interactions in the interest of developing intelligent shared control algorithms for natural, human-like contact interactions in human-robot interactions.",
        "primary_area": "",
        "author": "Evan Capelle;William N. Benson;Zachary Anderson;Jerry B. Weinberg;Jenna L. Gorlewicz;Evan Capelle;William N. Benson;Zachary Anderson;Jerry B. Weinberg;Jenna L. Gorlewicz",
        "authorids": "/37088689317;/37088686218;/37086578386;/37276596000;/37085810962;/37088689317;/37088686218;/37086578386;/37276596000;/37085810962",
        "aff": "Department of Mechanical and Aerospace Engineering, Saint Louis University, Saint Louis, MO, USA; Department of Mechanical and Aerospace Engineering, Saint Louis University, Saint Louis, MO, USA; Department of Computer Science, Southern Illinois University Edwardsville, Edwardsville, IL, USA; Department of Computer Science, Southern Illinois University Edwardsville, Edwardsville, IL, USA; Department of Mechanical and Aerospace Engineering, Saint Louis University, Saint Louis, MO, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340976/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7498847188857770082&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;1;0",
        "aff_unique_norm": "Saint Louis University;Southern Illinois University Edwardsville",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering;Department of Computer Science",
        "aff_unique_url": "https://www.slu.edu;https://www.siu.edu",
        "aff_unique_abbr": "SLU;SIUE",
        "aff_campus_unique_index": "0;0;1;1;0",
        "aff_campus_unique": "Saint Louis;Edwardsville",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341533",
        "title": "Design and Modeling of a Parallel Shifted-Routing Cable-Driven Continuum Manipulator for Endometrial Regeneration Surgery",
        "track": "main",
        "status": "Poster",
        "abstract": "Endometrial regeneration surgery is a new therapy for intrauterine adhesion (IUA). However, existing instruments lacking dexterity and compliance are with difficulty to successfully perform the tasks of generating transplant wounds and transplanting stem cells during endometrial regeneration surgery. This paper presents a novel shifted-routing continuum manipulator which is driven by only two cables but has high dexterity, simple structure and small size. The design of the continuum manipulator with novel actuation strategy is introduced and the manipulator's kinematic model is also derived. The analysis and simulation imply that shifted-routing strategy improves the dexterity of manipulators under limited actuation numbers and enhances the ability of reaching targets on fundus and corpus of the uterus. Finally, the shifted-routing continuum manipulator is used to reach targets in a planner endometrium model. The experimental results show that the tip of the manipulator can reach all the area of endometrium from proper directions.",
        "primary_area": "",
        "author": "Jianhua Li;Yuanyuan Zhou;Jichun Tan;Zhidong Wang;Hao Liu;Jianhua Li;Yuanyuan Zhou;Jichun Tan;Zhidong Wang;Hao Liu",
        "authorids": "/37088424634;/37075101900;/37088686863;/37279258300;/37069200800;/37088424634;/37075101900;/37088686863;/37279258300;/37069200800",
        "aff": "University of Chinese Academy of Sciences, Beijing, China; Institutes for Robotics and Intelligent Manufacturing, Chinese Academy of Sciences, Shenyang, China; Obstetrics and Gynecology Department, Assisted Reproduction Center, Shengjing Hospital affiliated to China Medical University, Shenyang, China; Department of Advanced Robotics, Chiba Institute of Technology, Narashino, Japan; Key Laboratory of Minimally Invasive Surgical Robot, Shenyang, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341533/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11187096426903544879&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;3;4",
        "aff_unique_norm": "University of Chinese Academy of Sciences;Chinese Academy of Sciences;China Medical University;Chiba Institute of Technology;Key Laboratory of Minimally Invasive Surgical Robot",
        "aff_unique_dep": ";Institutes for Robotics and Intelligent Manufacturing;Obstetrics and Gynecology Department;Department of Advanced Robotics;",
        "aff_unique_url": "http://www.ucas.ac.cn;http://www.cas.cn;http://www.cmu.edu.cn;https://www.chibatech.ac.jp;",
        "aff_unique_abbr": "UCAS;CAS;CMU;;",
        "aff_campus_unique_index": "0;1;1;2",
        "aff_campus_unique": "Beijing;Shenyang;Narashino;",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "China;Japan"
    },
    {
        "id": "9341503",
        "title": "Design and implementation of a pipeline inspection robot with camera image compensation",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we updated an inspection robot with passive adaptation ability, which is used to detect small size water supply pipeline. By geometric calculation and kinematic verification, static model of the robot is checked for flexible movement in the pipeline. Besides, inertial measurement unit is leveraged to simultaneously detect the attitude of robot, and different algorithm is tested to compensate the camera image rotation, stabilizing the image output.",
        "primary_area": "",
        "author": "Zhaohan Yuan;Jianjun Yuan;Shugen Ma;Zhaohan Yuan;Jianjun Yuan;Shugen Ma",
        "authorids": "/37087005494;/37293594200;/37280187400;/37087005494;/37293594200;/37280187400",
        "aff": "Robotics Institute of Shanghai Jiao Tong University, Shanghai; Shanghai Robotics Institute, Shanghai Key Laboratory of Intelligent Manufacturing and Robotics, School of Mechatronic Engineering and Automation, Shanghai University; Department of Robotics, Ritsumeikan University, Shiga, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341503/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10623372869777619453&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Shanghai Jiao Tong University;Shanghai University;Ritsumeikan University",
        "aff_unique_dep": "Robotics Institute;School of Mechatronic Engineering and Automation;Department of Robotics",
        "aff_unique_url": "https://www.sjtu.edu.cn;https://www.shu.edu.cn;https://www.ritsumeikan.ac.jp",
        "aff_unique_abbr": "SJTU;SHU;Ritsumeikan",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Shanghai;Shiga",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "China;Japan"
    },
    {
        "id": "9341363",
        "title": "Design of Fully Soft Actuator with Double-Helix Tendon Routing Path for Twisting Motion",
        "track": "main",
        "status": "Poster",
        "abstract": "Soft actuators have been widely studied in recent years because of their ability to adapt to diverse environments and safely interact with humans. Their softness broadens their potential range of medical applications since they can provide inherent safety. Among the various motions a soft robot can perform, \"torsion\" can maximize the efficiency of motion in confined spaces like the human abdominal cavity. This paper presents a fully soft actuator with a double-helix tendon routing path for large-angle torsional motions. The double-helix tendon routing enables the actuator to generate large twisting deformations, while also avoiding buckling generally associated with the torque imbalance in small diameter soft cylinder structures. A sequential casting method was developed for cylindrical structures with internal double-helix pathing. A parametric study of the actuator\u2019s twisting angle and the axial contraction with respect to different design parameters was conducted, including the wire tension and path pitch. From the results, when the tendon was pulled with 40 N after the pitch was decreased, the axial contraction of the soft actuator was reduced by half and the torsional angle was doubled up to 600\u00b0 without buckling.",
        "primary_area": "",
        "author": "Joonmyeong Choi;Se Hyeok Ahn;Kyu-Jin Cho;Joonmyeong Choi;Se Hyeok Ahn;Kyu-Jin Cho",
        "authorids": "/37086921445;/37088562166;/37404709400;/37086921445;/37088562166;/37404709400",
        "aff": "Department of Medicine, University of Ulsan College of Medicine, Seoul, Republic of Korea; Department of Mechanical & Aerospace Engineering, Seoul National University, Seoul, Republic of Korea; Department of Mechanical & Aerospace Engineering, Seoul National University, Seoul, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341363/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6672790185118389842&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "University of Ulsan College of Medicine;Seoul National University",
        "aff_unique_dep": "Department of Medicine;Department of Mechanical & Aerospace Engineering",
        "aff_unique_url": "https://www.uu.ac.kr;https://www.snu.ac.kr",
        "aff_unique_abbr": "UUCM;SNU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9341322",
        "title": "Design of a High-level Teleoperation Interface Resilient to the Effects of Unreliable Robot Autonomy",
        "track": "main",
        "status": "Poster",
        "abstract": "High-level control is generally preferred for the control of complex robot platforms and by users inexperienced with robot teleoperation. However, high-level teleoperation interfaces can be less effective if the robot autonomy is not reliable. To address this problem, it is important to understand how the users' preference of teleoperation interface may vary with the reliability of the robot autonomy, and understand what design features ameliorate the frustration and effort caused by unreliable autonomy.This paper proposes a graphical user interface for high-level robot control. The framework of the interface enables teleoperators to control a robot at the action level, and incorporates a simple but effective design that enables teleoperators to recover from task failure in a number of ways. We conducted a user study (N = 25) to compare the performance and user experience when using the proposed high-level interface to a low-level interface (i.e., gamepad) for robot low-level control, on a representative manipulation task. We also investigated if the high-level teleoperation interface remains effective if the reliability of robot autonomy decreases. Our results show that a high-level interface able to handle the most frequent errors is resilient to the effects of unreliable robot autonomy. Although the total task completion time increased as the robot autonomy becomes unreliable, the users' perception of workload and task performance are not affected. Through the user study, we also reveal the desirable interface features.",
        "primary_area": "",
        "author": "Samuel S. White;Keion W. Bisland;Michael C. Collins;Zhi Li;Samuel S. White;Keion W. Bisland;Michael C. Collins;Zhi Li",
        "authorids": "/37088228963;/37088594151;/37088690872;/37085821311;/37088228963;/37088594151;/37088690872;/37085821311",
        "aff": "Robotics Engineering Program, Worcester Polytechnic Institute, Worcester, MA, USA; Robotics Engineering Program, Worcester Polytechnic Institute, Worcester, MA, USA; Robotics Engineering Program, Worcester Polytechnic Institute, Worcester, MA, USA; Robotics Engineering Program, Worcester Polytechnic Institute, Worcester, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341322/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4633583178468239020&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Worcester Polytechnic Institute",
        "aff_unique_dep": "Robotics Engineering Program",
        "aff_unique_url": "https://www.wpi.edu",
        "aff_unique_abbr": "WPI",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Worcester",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340803",
        "title": "Design of a Highly-Maneuverable Pneumatic Soft Actuator Driven by Intrinsic SMA Coils (PneuSMA Actuator)",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents the design of a new soft pneumatic actuator whose direction and magnitude of bending may be precisely controlled via activation of different shape memory alloy (SMA) springs within the actuator, in conjunction with pneumatic actuation. This design is inspired by examples seen in nature such as the human tongue, where the combination of hydrostatic pressure and contraction of intrinsic muscle groups enables precise maneuverability and morphing capabilities. Here, SMA springs are embedded in the walls of the actuator, serving as intrinsic muscles that may be selectively activated to constrain the device. The pneumatic SMA (PneuSMA) actuator demonstrates remarkable spatial controllability evidenced by testing under different pressures and SMA activation combinations. A baseline finite element model is also developed to predict the actuator deformation under different pressure and activation conditions.",
        "primary_area": "",
        "author": "Emily A. Allen;John P. Swensen;Emily A. Allen;John P. Swensen",
        "authorids": "/37087322023;/37949206100;/37087322023;/37949206100",
        "aff": "School of Mechanical and Materials Engineering, Washington State University, Pullman, WA, USA; School of Mechanical and Materials Engineering, Washington State University, Pullman, WA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340803/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12576566608476445231&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Washington State University",
        "aff_unique_dep": "School of Mechanical and Materials Engineering",
        "aff_unique_url": "https://wsu.edu",
        "aff_unique_abbr": "WSU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Pullman",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341700",
        "title": "Design of a Linear Gravity Compensator for a Prismatic Joint",
        "track": "main",
        "status": "Poster",
        "abstract": "Most existing mechanical gravity compensators have been developed for revolute joints that are found in majority of articulated robot arms. However, robots such as patient transport robots use prismatic joints, which need to handle a heavy payload. In this study, a high-capacity linear gravity compensator (LGC), which comprises pure mechanical components, such as coil springs, a rack-pinion gear, a cam, and a wire, is proposed to compensate for the payload applied to a prismatic joint. The LGC is designed to generate a constant compensation force regardless of the payload position. The device can be manufactured at a low cost and has a significantly long lifespan because it uses coil springs to serve as an elastic body. Experiments demonstrate that the robot with the LGC can handle a load of 100 kg more than the robot using the same motors without it.",
        "primary_area": "",
        "author": "Do-Won Kim;Won-Bum Lee;Jae-Bok Song;Do-Won Kim;Won-Bum Lee;Jae-Bok Song",
        "authorids": "/37088363731;/37086055736;/37277430400;/37088363731;/37086055736;/37277430400",
        "aff": "School of Mechanical Eng., Korea University, Seoul, Korea; School of Mechanical Eng., Korea University, Seoul, Korea; School of Mechanical Eng., Korea University, Seoul, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341700/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6624935791839307563&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Korea University",
        "aff_unique_dep": "School of Mechanical Engineering",
        "aff_unique_url": "http://www.korea.ac.kr",
        "aff_unique_abbr": "KU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9341204",
        "title": "Design of a new electroactive polymer based continuum actuator for endoscopic surgical robots",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a smart continuum actuator based on a promising class of materials: ElectroActive polymer (EAP). Indeed these polymers undergo dimensional change in response to an applied electrical field and could be integrated directly in an endoscopic robot structure. We focuses on one of such materials, an electrostrictive polymer, for its valuable strain performances. An analytical model leading to the development of an experimental analysis of such a material in an attempts to overcome the technical gap of their integration into a multilayer composite sheet to perform robotic actuation is the subject of this article.",
        "primary_area": "",
        "author": "Q. JACQUEMIN;Q. SUN;D. THUAU;E. MONTEIRO;S. TENCE-GIRAULT;N. MECHBAL;Q. JACQUEMIN;Q. SUN;D. THUAU;E. MONTEIRO;S. TENCE-GIRAULT;N. MECHBAL",
        "authorids": "/37088687824;/37088686595;/37088688924;/37086128340;/37088689434;/37374081200;/37088687824;/37088686595;/37088688924;/37086128340;/37088689434;/37374081200",
        "aff": "PIMM, Arts et Metiers ParisTech, CNRS, Cnam, HESAM Universite, Paris, France; Laboratoire de l\u2019Integration du Materiau au Systeme (IMS, UMR 5218), Talence, Cedex, France; Laboratoire de l\u2019Integration du Materiau au Systeme (IMS, UMR 5218), Talence, Cedex, France; PIMM, Arts et Metiers ParisTech, CNRS, Cnam, HESAM Universite, Paris, France; Arkema, CERDATO, Serquigny, France; PIMM, Arts et Metiers ParisTech, CNRS, Cnam, HESAM Universite, Paris, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341204/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=805605794486894337&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;0;2;0",
        "aff_unique_norm": "Arts et Metiers ParisTech;Laboratoire de l\u2019Integration du Materiau au Systeme;Arkema",
        "aff_unique_dep": "PIMM;IMS, UMR 5218;CERDATO",
        "aff_unique_url": "https://www.arts-et-metiers.fr;;",
        "aff_unique_abbr": "Arts et Metiers;IMS;",
        "aff_campus_unique_index": "0;1;1;0;0",
        "aff_campus_unique": "Paris;Talence;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9340978",
        "title": "Design of an Underactuated Peristaltic Robot on Soft Terrain",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents an innovative robotic mechanism for generating peristaltic motion for robotic locomotion systems. The designed underactuated peristaltic robot utilizes a minimum amount of electromechanical hardware. Such a minimal electromechanical design not only reduces the number of potential failure modes but also provides the robot design with great potential for scaling to larger and smaller applications. We performed several speed and force generation tests atop a variety of granular media. Our experiments show the effective design of robot mechanism where the robot can travel with a small input power (1.14W) at 6.0 mm/sec with 2.45 N force atop sand.",
        "primary_area": "",
        "author": "Scott Scheraga;Alireza Mohammadi;Taehyung Kim;Stanley Baek;Scott Scheraga;Alireza Mohammadi;Taehyung Kim;Stanley Baek",
        "authorids": "/37088688738;/38230840400;/37280612300;/37086767349;/37088688738;/38230840400;/37280612300;/37086767349",
        "aff": "Department of Mechanical Engineering, University of Colorado, Boulder, CO, USA; Department of Electrical and Computer Engineering, University of Michigan-Dearborn, Dearborn, MI, USA; Department of Electrical and Computer Engineering, University of Michigan-Dearborn, Dearborn, MI, USA; Department of Electrical and Computer Engineering, United States Air Force Academy, USAF Academy, CO, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340978/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7678880507532484219&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;2",
        "aff_unique_norm": "University of Colorado;University of Michigan-Dearborn;United States Air Force Academy",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Electrical and Computer Engineering;Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.colorado.edu;https://umdearborn.edu;https://www.usafa.edu/",
        "aff_unique_abbr": "CU;UM-Dearborn;USAFA",
        "aff_campus_unique_index": "0;1;1;2",
        "aff_campus_unique": "Boulder;Dearborn;USAF Academy",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341276",
        "title": "Design, Analysis and Preliminary Validation of a 3-DOF Rotational Inertia Generator",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper investigates the design of a three-degree-of-freedom rotational inertia generator using the gyroscopic effect to provide ungrounded torque feedback. It uses a rotating mass in order to influence the torques needed to move the device, creating a perceived inertia. The dynamic model and the control law of the device are derived, along with those of a comparable concept using three flywheels instead of a gyroscope. Both models are then validated through simulations. Further simulations are conducted to establish motor torque and velocity requirements, and the gyroscopic concept is identified as having the less demanding requirements. The mechatronic design of a prototype of an inertia generator is presented, along with modifications to the dynamic model. Preliminary experimental validations are conducted. As the prototype faces instability issues when using the flywheels at high velocities, they are conducted using 0 RPM initial velocities. The results confirm that it is possible to both reduce and increase the rendered inertia even with current limitations. Finally, improvements for a second version of the prototype are discussed.",
        "primary_area": "",
        "author": "Jean-F\u00e9lix Tremblay-Bugeaud;Thierry Lalibert\u00e9;Cl\u00e9ment Gosselin;Jean-F\u00e9lix Tremblay-Bugeaud;Thierry Lalibert\u00e9;Cl\u00e9ment Gosselin",
        "authorids": "/37088688622;/37442629800;/37293911800;/37088688622;/37442629800;/37293911800",
        "aff": "Department of Mechanical Engineering, Universit\u00e9 Laval, Qu\u00e9bec, QC, Canada; Department of Mechanical Engineering, Universit\u00e9 Laval, Qu\u00e9bec, QC, Canada; Department of Mechanical Engineering, Universit\u00e9 Laval, Qu\u00e9bec, QC, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341276/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12642738152509442718&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Universit\u00e9 Laval",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.ulaval.ca",
        "aff_unique_abbr": "ULaval",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Qu\u00e9bec",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9340850",
        "title": "Designing A Dummy Skin by Evaluating Contacts between A Human Hand and A Robot End Tip",
        "track": "main",
        "status": "Poster",
        "abstract": "Many manufacturing industries have a high demand for the construction of collaborative operation systems using industrial robots. Although there is a preexisting set of safety verification data in ISO/TS 15066 for collaborative operations, there is no established testing method for safety validation. To establish a testing method, it is effective to use a dummy that has mechanical properties similar to those of a human. However, there is no parametric study that exists for designing a dummy that represents the static and dynamic mechanical properties and the nonlinearity of the static mechanical properties. In this study, static and dynamic experiments were conducted to obtain the mechanical stiffness of human subjects and the contact force transitions during the dynamic contact between a robot system and a human. Subsequently, the same experiment was conducted using the proposed dummy. The biofidelity of the dummy was examined by comparing the parameters of a viscoelastic model. This study contributes to increasing the safety of collaborative operations by developing a dummy that can be used for risk assessments in collaborative operations.",
        "primary_area": "",
        "author": "Yumena Iki;Yoji Yamada;Yasuhiro Akiyama;Shogo Okamoto;Jian Liu;Yumena Iki;Yoji Yamada;Yasuhiro Akiyama;Shogo Okamoto;Jian Liu",
        "authorids": "/37088689792;/37280504200;/37085425767;/37286053600;/37088687695;/37088689792;/37280504200;/37085425767;/37286053600;/37088687695",
        "aff": "Department of Mechanical Systems Engineering, Nagoya University, Nagoya, Japan; Department of Mechanical Systems Engineering, Nagoya University, Nagoya, Japan; Department of Mechanical Systems Engineering, Nagoya University, Nagoya, Japan; Department of Mechanical Systems Engineering, Nagoya University, Nagoya, Japan; Department of Mechanical Systems Engineering, Nagoya University, Nagoya, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340850/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12482725869812464459&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Nagoya University",
        "aff_unique_dep": "Department of Mechanical Systems Engineering",
        "aff_unique_url": "https://www.nagoya-u.ac.jp",
        "aff_unique_abbr": "Nagoya U",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Nagoya",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9340832",
        "title": "Designing Environments Conducive to Interpretable Robot Behavior",
        "track": "main",
        "status": "Poster",
        "abstract": "Designing robots capable of generating interpretable behavior is essential for effective human-robot collaboration. This requires robots to be able to generate behavior that aligns with human expectations but exhibiting such behavior in arbitrary environments could be quite expensive for robots, and in some cases, the robot may not even be able to exhibit expected behavior. However, in structured environments (like warehouses, restaurants, etc.), it may be possible to design the environment so as to boost the interpretability of a robot's behavior or to shape the human's expectations of the robot's behavior. In this paper, we investigate the opportunities and limitations of environment design as a tool to promote a particular type of interpretable behavior - known in the literature as explicable behavior. We formulate a novel environment design framework that considers design over multiple tasks and over a time horizon. In addition, we explore the longitudinal effect of explicable behavior and the trade-off that arises between the cost of design and the cost of generating explicable behavior over an extended time horizon.",
        "primary_area": "",
        "author": "Anagha Kulkarni;Sarath Sreedharan;Sarah Keren;Tathagata Chakraborti;David E. Smith;Subbarao Kambhampati;Anagha Kulkarni;Sarath Sreedharan;Sarah Keren;Tathagata Chakraborti;David E. Smith;Subbarao Kambhampati",
        "authorids": "/37085996203;/37085994795;/37088691161;/38072648300;/38183537200;/37283197000;/37085996203;/37085994795;/37088691161;/38072648300;/38183537200;/37283197000",
        "aff": "Dept of Computer Science, Arizona State University; Dept of Computer Science, Arizona State University; School of Engineering and Applied Sciences, Harvard University, and Center for Research on Computation and Society, Harvard University; IBM Research; David E. Smith; Dept of Computer Science, Arizona State University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340832/",
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17884583966743283775&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;2;0",
        "aff_unique_norm": "Arizona State University;Harvard University;IBM;",
        "aff_unique_dep": "Dept of Computer Science;School of Engineering and Applied Sciences;IBM Research;",
        "aff_unique_url": "https://www.asu.edu;https://www.harvard.edu;https://www.ibm.com/research;",
        "aff_unique_abbr": "ASU;Harvard;IBM;",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Cambridge",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States;"
    },
    {
        "id": "9341000",
        "title": "Detecting Usable Planar Regions for Legged Robot Locomotion",
        "track": "main",
        "status": "Poster",
        "abstract": "Awareness of the environment is essential for mobile robots. Perception for legged robots requires high levels of reliability and accuracy in order to walk stably in the types of complex, cluttered environments we are interested in. In this paper, we present a usable environmental perception algorithm designed to detect steppable areas and obstacles for the autonomous generation of desired footholds for legged robots. To produce an efficient representation of the environment, the proposed perception algorithm is desired to cluster point cloud data to planar regions composed of convex polygons. We describe in this paper the end-to-end pipeline from data collection to generation of the regions, where we first compose an octree in order to create a more efficient data representation. We then group the leaves in the tree using a nearest neighbor search into a planar region, which is composed of the concave hull of points that is decomposed into convex polygons. We present a variety of environments, and illustrate the usability of this approach by the Atlas humanoid robots walking over rough terrain. We also discuss various challenges we faced and insights we gained in the development of this approach.",
        "primary_area": "",
        "author": "Sylvain Bertrand;Inho Lee;Bhavyansh Mishra;Duncan Calvert;Jerry Pratt;Robert Griffin;Sylvain Bertrand;Inho Lee;Bhavyansh Mishra;Duncan Calvert;Jerry Pratt;Robert Griffin",
        "authorids": "/37089144753;/37086209643;/37086319200;/37088689927;/37283041800;/37085631429;/37089144753;/37086209643;/37086319200;/37088689927;/37283041800;/37085631429",
        "aff": "Florida Institute for Human and Machine Cognition, Pensacola, FL, United States; Florida Institute for Human and Machine Cognition, Pensacola, FL, United States; University of West Florida, Pensacola, FL, United States; University of West Florida, Pensacola, FL, United States; University of West Florida, Pensacola, FL, United States; University of West Florida, Pensacola, FL, United States",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341000/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4207468959472094926&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;1;1;1",
        "aff_unique_norm": "Florida Institute for Human and Machine Cognition;University of West Florida",
        "aff_unique_dep": ";",
        "aff_unique_url": ";https://www.uwf.edu",
        "aff_unique_abbr": ";UWF",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Pensacola",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341368",
        "title": "Detection-Aware Trajectory Generation for a Drone Cinematographer",
        "track": "main",
        "status": "Poster",
        "abstract": "This work investigates an efficient trajectory generation for chasing a dynamic target, which incorporates the detectability objective. The proposed method actively guides the motion of a cinematographer drone so that the color of a target is well-distinguished against the colors of the background in the view of the drone. For the objective, we define a measure of color detectability given a chasing path. After computing a discrete path optimized for the metric, we generate a dynamically feasible trajectory. The whole pipeline can be updated on-the- fly to respond to the motion of the target. For the efficient discrete path generation, we construct a directed acyclic graph (DAG) for which a topological sorting can be determined analytically without the depth-first search. The smooth path is obtained in quadratic programming (QP) framework. We validate the enhanced performance of state-of-the-art object detection and tracking algorithms when the camera drone executes the trajectory obtained from the proposed method.",
        "primary_area": "",
        "author": "Boseong Felipe Jeon;Dongsuk Shim;H. Jin Kim;Boseong Felipe Jeon;Dongsuk Shim;H. Jin Kim",
        "authorids": "/37087323064;/37088567748;/38137327000;/37087323064;/37088567748;/38137327000",
        "aff": "Department of mechanical and aerospace engineering, Seoul national university, South Korea; Department of mechanical and aerospace engineering, Seoul national university, South Korea; Department of mechanical and aerospace engineering, Seoul national university, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341368/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13097017918973504630&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Seoul National University",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.snu.ac.kr",
        "aff_unique_abbr": "SNU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9341661",
        "title": "Developing Thermal Endoscope for Endoscopic Photothermal Therapy for Peritoneal Dissemination",
        "track": "main",
        "status": "Poster",
        "abstract": "As a novel therapy for peritoneal dissemination, it is desired to actualize an endoscopic photothermal therapy, which is minimally invasive and is highly therapeutically effective. However, since the endoscopic tumor temperature control has not been actualized, conventional therapies could damage healthy tissues by overhearing. In this paper, we develop a thermal endoscope system that controls the tumor temperature so that the heated tumor gets necrotic. In fact, our thermal endoscope contains a thermal image sensor, a visible light endoscope and a laser fiber. Concerning the thermal image sensor, the conventional thermal endoscope has the problem that the diameter is too large, because the conventional endoscope loads a large thermal image sensor with high-resolution. Therefore, this paper uses a small thermal image sensor with low resolution, because the diameter of the thermal endoscope needs to be smaller than 15mm in order to be inserted into the trocar. However, this thermal image sensor is contaminated by much noise. Thus, we develop a tumor temperature control system using a feedback control and tumor temperature estimation based on Gaussian function, so that the noisy, small thermal image sensor can be used. As experimental results of the proposed endoscopic photothermal therapy for the hepatophyma carcinoma model of rats, it turns out that the tumor temperature by which the heated tumor gets necrotic can be kept stable. It can be said that our endoscopic photothermal therapy achieves a certain degree of therapy effect.",
        "primary_area": "",
        "author": "Mutsuki Ohara;Sohta Sanpei;Chanjin Seo;Jun Ohya;Ken Masamune;Hiroshi Nagahashi;Yuji Morimoto;Manabu Harada;Mutsuki Ohara;Sohta Sanpei;Chanjin Seo;Jun Ohya;Ken Masamune;Hiroshi Nagahashi;Yuji Morimoto;Manabu Harada",
        "authorids": "/37088686352;/37088687996;/37088478729;/37269392200;/37294218500;/37374740200;/37088687499;/37088690904;/37088686352;/37088687996;/37088478729;/37269392200;/37294218500;/37374740200;/37088687499;/37088690904",
        "aff": "Department of Modern Mechanical Engineering, School of Creative Science and Engineering, Waseda University, Tokyo, Japan; Department of Modern Mechanical Engineering, School of Creative Science and Engineering, Waseda University, Tokyo, Japan; Department of Modern Mechanical Engineering, School of Creative Science and Engineering, Waseda University, Tokyo, Japan; Department of Modern Mechanical Engineering, School of Creative Science and Engineering, Waseda University, Tokyo, Japan; Faculty of Advanced Techno-Surgery, Institute of Advanced Biomedical Engineering and Science, Tokyo Women\u2019s Medical University; Divisions of Mathematical and Physical Sciences, Graduate School of Science, Japan Women's University; Integrative Physiology and Bio-Nano Medicine, National Defense Medical College; Department of Surgery, National Defense Medical College",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341661/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5127942784575950195&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;1;2;3;3",
        "aff_unique_norm": "Waseda University;Tokyo Women\u2019s Medical University;Japan Women's University;National Defense Medical College",
        "aff_unique_dep": "Department of Modern Mechanical Engineering;Faculty of Advanced Techno-Surgery, Institute of Advanced Biomedical Engineering and Science;Divisions of Mathematical and Physical Sciences, Graduate School of Science;Integrative Physiology and Bio-Nano Medicine",
        "aff_unique_url": "https://www.waseda.jp/top;https://www.twmu.ac.jp;https://www.jwu.ac.jp;https://www.ndmc.edu.jp",
        "aff_unique_abbr": "Waseda;TWMU;JWU;NDMC",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Tokyo;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9341230",
        "title": "Development and Analysis of Digging and Soil Removing Mechanisms for Mole-Bot: Bio-Inspired Mole-Like Drilling Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "",
        "primary_area": "",
        "author": "Junseok Lee;Christian Tirtawardhana;Hyun Myung;Junseok Lee;Christian Tirtawardhana;Hyun Myung",
        "authorids": "/37087124781;/37087405692;/37424926900;/37087124781;/37087405692;/37424926900",
        "aff": "",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341230/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17231341208055413358&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6
    },
    {
        "id": "9341293",
        "title": "Development and Evaluation of a Linear Series Clutch Actuator for Vertical Joint Application with Static Balancing",
        "track": "main",
        "status": "Poster",
        "abstract": "Future robots are expected to share their workspace with humans. Controlling and limiting the forces that such robots exert on their environment is crucial. While force control can be achieved actively with the help of force sensing, passive mechanisms have no time delay in their response to external forces, and would therefore be preferable. Series clutch actuators can be used to achieve high levels of safety and backdrivability. This work presents the first implementation of a linear series clutch actuator. It can exert forces of more than 110N while weighing less than 2kg. Force controllability and safety are demonstrated. Static balancing, which is important for the application in a vertical joint, is also implemented. The power consumption is evaluated, and for a payload of 3kg and with the maximum speed of 94mm/s, the power consumed by the actuator is 11W. Overall, a practical implementation of a linear series clutch actuator is reported, which can be used for future collaborative robots.",
        "primary_area": "",
        "author": "Shardul Kulkarni;Alexander Schmitz;Satoshi Funabashi;Shigeki Sugano;Shardul Kulkarni;Alexander Schmitz;Satoshi Funabashi;Shigeki Sugano",
        "authorids": "/37088690679;/37587110100;/37085727304;/37274050800;/37088690679;/37587110100;/37085727304;/37274050800",
        "aff": "Sugano Lab, School of Creative Science and Engineering, Waseda University, Tokyo, Japan; Sugano Lab, School of Creative Science and Engineering, Waseda University, Tokyo, Japan; Sugano Lab, School of Creative Science and Engineering, Waseda University, Tokyo, Japan; Sugano Lab, School of Creative Science and Engineering, Waseda University, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341293/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2685766457202163085&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Waseda University",
        "aff_unique_dep": "School of Creative Science and Engineering",
        "aff_unique_url": "https://www.waseda.jp/top",
        "aff_unique_abbr": "Waseda",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9340906",
        "title": "Development of A Passive Skid for Multicopter Landing on Rough Terrain",
        "track": "main",
        "status": "Poster",
        "abstract": "Landing is an essential part of multicopter task operations. A multicopter has relatively stringent requirements for landing, particularly for achieving flatness. Currently, landing on rough terrain with normal skids is difficult. Therefore, research is being conducted to obtain skids capable of landing on rough terrain. In this paper, a passive skid for multicopter landing on rough terrain is proposed. The proposed device is based on an existing previous study of the multicopter carried with a electric robo-arm only for object manipulation. This innovative idea stems from the aim of giving the multicopter carried with a electric robo-arm the ability to land on various occasions and then the passive skid is designed. By using a slope to simulate a rough terrain, the range of available landing in which a multicopter can maintain its pose and the frictional torque of the passive joint are analyzed. Further, experiments are conducted to demonstrate that landing can be achieved using the skid proposed in our study.",
        "primary_area": "",
        "author": "Maozheng Xu;Naoto Sumida;Takeshi Takaki;Maozheng Xu;Naoto Sumida;Takeshi Takaki",
        "authorids": "/37088690563;/37088691304;/37281345000;/37088690563;/37088691304;/37281345000",
        "aff": "Graduate School of Engineering, Robotics Laboratory, Hiroshima University, Japan; Graduate School of Engineering, Robotics Laboratory, Hiroshima University, Japan; Graduate School of Engineering, Robotics Laboratory, Hiroshima University, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340906/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5110983950504578524&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Hiroshima University",
        "aff_unique_dep": "Graduate School of Engineering, Robotics Laboratory",
        "aff_unique_url": "https://www.hiroshima-u.ac.jp",
        "aff_unique_abbr": "Hiroshima U",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Hiroshima",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9341746",
        "title": "Development of Deployable Bending Wrist for Minimally Invasive Laparoscopic Endoscope",
        "track": "main",
        "status": "Poster",
        "abstract": "During the last two decades, minimally invasive surgery (MIS) has become popular because it offers advantages such as less pain, faster recovery, improved cosmesis, and reduced complications. Single-port laparoscopic surgery is a form of MIS where surgeons operate exclusively through a single entry. However, the view from the rigid endoscope is often obscured by the instruments which pass through the same single entry. To remove the need for a secondary viewing port and the blind spots during operation, we propose a deployable wrist mechanism for minimally invasive laparoscopic surgery. It utilizes an S-shape nitinol tube with a curvature of 15 mm and 1.83 mm in diameter. When retracted, the s-shaped wrist is straightened into the main shaft of the laparoscopic tool. As the wrist translates outward, the S-shaped nitinol wrist emerges from an opening on the tool shaft and bends to point at the tooltip. The wrist has two degrees of freedom: translational displacement for controlling the bending and rotational movement of the wrist. The bending mechanism was analyzed by finite element method simulation and validated by experiments. For future work, we will try to widen the scope of its applications including laser ablation tools, triangularization, and other microsurgical procedures.",
        "primary_area": "",
        "author": "Jongwoo Kim;Thomas Looi;Allen Newman;James Drake;Jongwoo Kim;Thomas Looi;Allen Newman;James Drake",
        "authorids": "/37085385839;/38498292300;/37088688316;/38512992300;/37085385839;/38498292300;/37088688316;/38512992300",
        "aff": "Center for Image-Guided Innovation & Therapeutic Intervention (CIGITI), The Hospital for Sick Children, University of Toronto, Toronto, ON, Canada; Center for Image-Guided Innovation & Therapeutic Intervention (CIGITI), The Hospital for Sick Children, University of Toronto, Toronto, ON, Canada; Endopodium Inc., San Diego, CA, United States of America; Center for Image-Guided Innovation & Therapeutic Intervention (CIGITI), The Hospital for Sick Children, University of Toronto, Toronto, ON, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341746/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5018497559736337305&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "University of Toronto;Endopodium Inc.",
        "aff_unique_dep": "Center for Image-Guided Innovation & Therapeutic Intervention (CIGITI);",
        "aff_unique_url": "https://www.utoronto.ca;",
        "aff_unique_abbr": "U of T;",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Toronto;San Diego",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "Canada;United States"
    },
    {
        "id": "9341609",
        "title": "Development of Exo-Glove for Measuring 3-axis Forces Acting on the Human Finger without Obstructing Natural Human-Object Interaction",
        "track": "main",
        "status": "Poster",
        "abstract": "Measuring the forces that humans exert with their fingers could have many potential applications, such as skill transfer from human experts to robots or monitoring humans. In this paper we introduce the \"Exo-Glove\" system, which can measure the joint angles and forces acting on the human finger without covering the skin that is in contact with the manipulated object. In particular, 3-axis sensors measure the deformation of the human skin on the sides of the finger to indirectly measure the 3-axis forces acting on the finger. To provide a frame of reference for the sensors, and to measure the joint angles of the human finger, an exoskeleton with remote center of motion (RCM) joints is used. Experiments showed that with the exoskeleton the quality of the force measurements can be improved.",
        "primary_area": "",
        "author": "Prathamesh Sathe;Alexander Schmitz;Harris Kristanto;Chincheng Hsu;Tito Pradhono Tomo;Sophon Somlor;Sugano Shigeki;Prathamesh Sathe;Alexander Schmitz;Harris Kristanto;Chincheng Hsu;Tito Pradhono Tomo;Sophon Somlor;Sugano Shigeki",
        "authorids": "/37086439164;/37587110100;/37086100897;/37087054791;/37085618711;/37085510233;/37600131400;/37086439164;/37587110100;/37086100897;/37087054791;/37085618711;/37085510233;/37600131400",
        "aff": "Waseda University, Tokyo, Japan; Waseda University, Tokyo, Japan; Waseda University, Tokyo, Japan; Waseda University, Tokyo, Japan; Waseda University, Tokyo, Japan; Waseda University, Tokyo, Japan; Waseda University, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341609/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7772552308199972363&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Waseda University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.waseda.ac.jp",
        "aff_unique_abbr": "Waseda",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9340868",
        "title": "Development of Selective Driving Joint Forceps Using Shape Memory Polymer",
        "track": "main",
        "status": "Poster",
        "abstract": "In this study, we developed a selective driving joint forceps (SDJF) for laparoscopic surgery. The SDJF has a mechanism that the driving joints can be selected arbitrarily, therefore each joint doesn't require an individual actuator for operating. The developed SDJF has six joints that can be operated using only four actuators. Each joint has 2-degrees-of-freedom (DOF) of flexion. Therefore, the SDJF has the same working area as the forceps having six driving joints (each joints can bend \u00b130\u00b0 around the X and Y axes). The mechanism of the SDJF is realized by fixing each joint with a collar made of shape memory polymer. The proposed mechanism not only reduces the number of actuators required for joint operation, but also has the rigidity of the forceps, which is important in surgery. In addition, a driving section of the forceps is driven by pneumatic cylinders, therefore, the forceps joint has high-back-drivability, lightweight and high-output. We measured the heating and cooling time required to change the driving joint, dynamic response and rigidity of the prototype SDJF.",
        "primary_area": "",
        "author": "Katsuhiko Fukushima;Takahiro Kanno;Tetsuro Miyazaki;Toshihiro Kawase;Kenji Kawashima;Katsuhiko Fukushima;Takahiro Kanno;Tetsuro Miyazaki;Toshihiro Kawase;Kenji Kawashima",
        "authorids": "/37088688984;/37085394750;/37086294776;/37086578826;/37280901500;/37088688984;/37085394750;/37086294776;/37086578826;/37280901500",
        "aff": "Institute of Biomaterials and Bioengineering, Tokyo Medical and Dental University, Tokyo, Japan; RiverField Inc., Tokyo, Japan; Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Institute of Innovative Research, Tokyo Institute of Technology, Kanagawa, Japan; Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340868/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18191217083348518556&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;3;2",
        "aff_unique_norm": "Tokyo Medical and Dental University;RiverField Inc.;The University of Tokyo;Tokyo Institute of Technology",
        "aff_unique_dep": "Institute of Biomaterials and Bioengineering;;Graduate School of Information Science and Technology;Institute of Innovative Research",
        "aff_unique_url": "https://www.tmd.ac.jp;;https://www.u-tokyo.ac.jp;https://www.titech.ac.jp",
        "aff_unique_abbr": "TMDU;;UTokyo;Titech",
        "aff_campus_unique_index": "0;0;2;0",
        "aff_campus_unique": "Tokyo;;Kanagawa",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9341093",
        "title": "Development of a Maneuverable Un-Tethered Multi-fin Soft Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, the design, fabrication, numerical studies, and preliminary characterization of a multi-fin soft robot are presented. The design is simple, robust, and fully autonomous. The robot has a 216mm body length and displays great potential to achieve uncoupled surge (forwards and backwards), sway, and heave motions. Computational fluid dynamic (CFD) studies are employed to evaluate appropriate fin control approaches and their influence on force generation. By using asymmetric input functions to actuate all fins in phase, the robot can achieve close to pure heave motions while single fin symmetric actuation enables forwards, backwards, and sway motions.",
        "primary_area": "",
        "author": "T.V. Truong;R.C. Mysa;T. Stalin;P.M. Aby Raj;P. Valdivia y Alvarado;T.V. Truong;R.C. Mysa;T. Stalin;P.M. Aby Raj;P. Valdivia y Alvarado",
        "authorids": "/37087324738;/37088686468;/37088384129;/37088688757;/37085957550;/37087324738;/37088686468;/37088384129;/37088688757;/37085957550",
        "aff": "SUTD International Design Centre (IDC); SUTD International Design Centre (IDC); SUTD Digital Manufacturing and Design Centre (DManD); Engineering Product Development Pillar, Singapore University of Technology and Design (SUTD); Engineering Product Development Pillar, Singapore University of Technology and Design (SUTD)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341093/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11081575409963962847&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Singapore University of Technology and Design",
        "aff_unique_dep": "International Design Centre (IDC)",
        "aff_unique_url": "https://www.sutd.edu.sg",
        "aff_unique_abbr": "SUTD",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "9340811",
        "title": "Development of a Running Hexapod Robot with Differentiated Front and Hind Leg Morphology and Functionality",
        "track": "main",
        "status": "Poster",
        "abstract": "This article introduces an innovative model-based strategy for designing a legged robot to generate animal-like running dynamics with differentiated leg braking and thrusting force patterns. Linear springs were utilized as legs, but instead of having one end of each spring connected directly to the hip joint, one extra bar was added to offset the spring's direction. The robot's front and hind legs were offset with the same magnitudes but in different directions. Therefore, the legs produced different ground braking and thrusting force patterns. The robot's running motion was planned based on its reduced-order model. The model's fixed-point and passive-dynamics motion served as the robot's reference motion. The proposed strategy was experimentally validated, and the results confirmed that the robot could successfully perform stable running in a differentiated leg force pattern.",
        "primary_area": "",
        "author": "Jia-Ruei Chiu;Yu-Chih Huang;Hui-Ching Chen;Kuan-Yu Tseng;Pei-Chun Lin;Jia-Ruei Chiu;Yu-Chih Huang;Hui-Ching Chen;Kuan-Yu Tseng;Pei-Chun Lin",
        "authorids": "/37088690419;/37088686560;/37088688949;/37087051282;/37577492700;/37088690419;/37088686560;/37088688949;/37087051282;/37577492700",
        "aff": "Department of Mechanical Engineering, National Taiwan University, Taipei, Taiwan; Department of Mechanical Engineering, National Taiwan University, Taipei, Taiwan; Department of Mechanical Engineering, National Taiwan University, Taipei, Taiwan; Department of Mechanical Engineering, National Taiwan University, Taipei, Taiwan; Department of Mechanical Engineering, National Taiwan University, Taipei, Taiwan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340811/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10220115641849052542&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "National Taiwan University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.ntu.edu.tw",
        "aff_unique_abbr": "NTU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Taiwan",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9340844",
        "title": "Development of a Spherical 2-DOF Wrist Employing Spatial Parallelogram Structure",
        "track": "main",
        "status": "Poster",
        "abstract": "A spherical two-degree-of- freedom wrist adapting the structure of the spatial parallelogram is proposed. A U type extended link out of three UU type limbs of the spatial parallelogram is selected as an output link. As a result, the wrist can be interpreted as being formed by combination of a U type limb and a (2-UU)+U type hybrid limb. Screw theory is employed to analyze its first-order kinematic model. Then a compact wrist prototype suitable for wrist module supporting the robot hand is designed and implemented. Finally, experiments with the prototype confirm that the wrist has a very high potential application for wrist modules in terms of dexterity and maximum load handling capacity.",
        "primary_area": "",
        "author": "Hyunhwan Jeong;Sunhyuk Baek;Wheekuk Kim;Byung-Ju Yi;Hyunhwan Jeong;Sunhyuk Baek;Wheekuk Kim;Byung-Ju Yi",
        "authorids": "/37595092400;/37088690942;/37278278700;/37273970700;/37595092400;/37088690942;/37278278700;/37273970700",
        "aff": "Department of Electro-Mechanical System Engineering, Korea University, Sejong, Korea; Department of Electro-Mechanical System Engineering, Korea University, Sejong, Korea; Department of Electro-Mechanical System Engineering, Korea University, Sejong, Korea; Department of Electronic Systems Engineering, Hanyang University, Ansan, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340844/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15856736081688552983&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Korea University;Hanyang University",
        "aff_unique_dep": "Department of Electro-Mechanical System Engineering;Department of Electronic Systems Engineering",
        "aff_unique_url": "http://www.korea.ac.kr;http://www.hanyang.ac.kr",
        "aff_unique_abbr": "KU;HYU",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "Sejong;Ansan",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9341524",
        "title": "Development of a Steep Slope Mobile Robot with Propulsion Adhesion",
        "track": "main",
        "status": "Poster",
        "abstract": "A mobile robot that can achieve a stable attitude and locomotion on steep slopes is needed to overcome the problems of slipping and falling for automation of works on steep slopes. The conventional approaches to achieve a stable attitude and locomotion have been researched by adopting tracked wheels and multi-legged mechanisms instead of wheel mechanisms. However, these robots have limitations in term of application angles. A systematic theory for stable attitude and locomotion on steep slopes has not been established. Therefore, research on control strategies for wheeled mobile robots on steep slopes is essential. In this paper, a method to realize a stable attitude and locomotion on a steep slope for the wheeled mobile robot by using propellers for propulsion adhesion is proposed. The proposed robot can generate a large frictional force by pushing its body against the slope with a thrust force. This force prevents the robot from slipping while maneuvering on the slope. The magnitude and the direction of the thrust force is optimized using an appropriate control mechanism influencing the moment of force acting on it to avoid falling and side slipping during locomotion on steep slopes. A simulation experiment was conducted from the perspective of mechanics and dynamics to arrive at an optimal design of the mobile robot. The developed robot has four propellers to generate thrust forces and a rotation axis to control the direction of the generated thrust forces. Evaluation experiments were performed to validate the stability of the robot at a resting position and during lateral locomotion and its ability to climb over a slope. The experimental results confirmed that the proposed robot with propellers realized a steady attitude and locomotion on a slope of up to 90\u00b0 by controlling the magnitude and the direction of the thrust force.",
        "primary_area": "",
        "author": "Yuki Nishimura;Tomoyuki Yamaguchi;Yuki Nishimura;Tomoyuki Yamaguchi",
        "authorids": "/37088690965;/37289932000;/37088690965;/37289932000",
        "aff": "Ph. D. Program in Empowerment Informatics, University of Tsukuba, School of Integrative and Global Majors, Tsukuba, Japan; Faculty of Engineering, Information and Systems, University of Tsukuba, Ibaraki, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341524/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11810507432618002294&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Tsukuba",
        "aff_unique_dep": "School of Integrative and Global Majors",
        "aff_unique_url": "https://www.tsukuba.ac.jp",
        "aff_unique_abbr": "UT",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Tsukuba;Ibaraki",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9341706",
        "title": "Development of a pneumatically-driven Growing Sling to assist patient transfer",
        "track": "main",
        "status": "Poster",
        "abstract": "In this study, a new type of sling for assisting bedridden patients is developed using a pneumatic growing mechanism. Growing Sling focuses on minimizing the labor input of the caregivers by automating the sling insertion and retraction process while maintaining safety and comfort. Improvements over the typical growing mechanism were made by reinforcing the sling with shafts and filament tape for restricting the height of the sling to ensure its design purpose. Analysis of forces exerted on the structure was made to interpret the driving power of the automated insertion process and to ensure the structural integrity of components. Experiments on materials and prototype devices were conducted to determine the quantitative load that the sling needs to endure and what type of material is suitable for fabrication. Further, we propose a fabrication process for the Growing Sling, including its dimensions, and validate the performance of the fabricated prototype.",
        "primary_area": "",
        "author": "Jonggyu Choi;Seungjun Lee;Jeongryul Kim;MyungJoong Lee;Keri Kim;Hyunki In;Jonggyu Choi;Seungjun Lee;Jeongryul Kim;MyungJoong Lee;Keri Kim;Hyunki In",
        "authorids": "/37088691476;/37088688353;/37088475975;/37088687411;/37085344004;/37589373000;/37088691476;/37088688353;/37088475975;/37088687411;/37085344004;/37589373000",
        "aff": "Center for Medical Robotics, Korea Institute of Science and Technology, Seoul, Republic of Korea; Center for Medical Robotics, Korea Institute of Science and Technology, Seoul, Republic of Korea; Center for Medical Robotics, Korea Institute of Science and Technology, Seoul, Republic of Korea; Division of Nano-Information Technology (HCI & Robotics), University of Science and Technology, Daejeon, Republic of Korea; Division of Bio-Medical Science and Technology, University of Science and Technology, Daejeon, Republic of Korea; Center for Medical Robotics, Korea Institute of Science and Technology, Seoul, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341706/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11040398507280605719&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;1;0",
        "aff_unique_norm": "Korea Institute of Science and Technology;University of Science and Technology",
        "aff_unique_dep": "Center for Medical Robotics;Division of Nano-Information Technology (HCI & Robotics)",
        "aff_unique_url": "https://www.kist.re.kr;http://www.ust.ac.kr",
        "aff_unique_abbr": "KIST;UST",
        "aff_campus_unique_index": "0;0;0;1;1;0",
        "aff_campus_unique": "Seoul;Daejeon",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9341039",
        "title": "Development of dementia care training system based on augmented reality and whole body wearable tactile sensor",
        "track": "main",
        "status": "Poster",
        "abstract": "This study develops a training system for a multimodal comprehensive care methodology for dementia patients called Humanitude. Humanitude has attracted much attention as a gentle and effective care technique. It consists of four main techniques, namely, eye contact, verbal communication, touch, and standing up, and more than 150 care elements. Learning Humanitude thus requires much time. To provide an effective training system for Humanitude, we develop a training system that realizes sensing and interaction simultaneously by combining a real entity and augmented reality technology. To imitate the interaction between a patient and a caregiver, we superimpose a three-dimensional CG model of a patient\u2019s face onto the head of a soft doll using augmented reality technology. Touch information such as position and force is sensed using the whole body wearable tactile sensor developed to quantify touch skills. This training system enables the evaluation of eye contact and touch skills simultaneously. We build a prototype of the proposed training system and evaluate the usefulness of the system in public lectures.",
        "primary_area": "",
        "author": "Tomoki Hiramatsu;Masaya Kamei;Daiji Inoue;Akihiro Kawamura;Qi An;Ryo Kurazume;Tomoki Hiramatsu;Masaya Kamei;Daiji Inoue;Akihiro Kawamura;Qi An;Ryo Kurazume",
        "authorids": "/37086820584;/37088689808;/37088688176;/37682708900;/37642718800;/37271916800;/37086820584;/37088689808;/37088688176;/37682708900;/37642718800;/37271916800",
        "aff": "Graduate School of Information Science and Electrical Engineering, Kyushu University, Fukuoka, Japan; Graduate School of Information Science and Electrical Engineering, Kyushu University, Fukuoka, Japan; Graduate School of Information Science and Electrical Engineering, Kyushu University, Fukuoka, Japan; Faculty of Information Science and Electrical Engineering, Kyushu University, Fukuoka, Japan; Faculty of Information Science and Electrical Engineering, Kyushu University, Fukuoka, Japan; Faculty of Information Science and Electrical Engineering, Kyushu University, Fukuoka, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341039/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17705849491296541629&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Kyushu University",
        "aff_unique_dep": "Graduate School of Information Science and Electrical Engineering",
        "aff_unique_url": "https://www.kyushu-u.ac.jp",
        "aff_unique_abbr": "Kyushu U",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Fukuoka",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9341074",
        "title": "DiPE: Deeper into Photometric Errors for Unsupervised Learning of Depth and Ego-motion from Monocular Videos",
        "track": "main",
        "status": "Poster",
        "abstract": "Unsupervised learning of depth and ego-motion from unlabelled monocular videos has recently drawn great attention, which avoids the use of expensive ground truth in the supervised one. It achieves this by using the photometric errors between the target view and the synthesized views from its adjacent source views as the loss. Despite significant progress, the learning still suffers from occlusion and scene dynamics. This paper shows that carefully manipulating photometric errors can tackle these difficulties better. The primary improvement is achieved by a statistical technique that can mask out the invisible or nonstationary pixels in the photometric error map and thus prevents misleading the networks. With this outlier masking approach, the depth of objects moving in the opposite direction to the camera can be estimated more accurately. To the best of our knowledge, such scenarios have not been seriously considered in the previous works, even though they pose a higher risk in applications like autonomous driving. We also propose an efficient weighted multi-scale scheme to reduce the artifacts in the predicted depth maps. Extensive experiments on the KITTI dataset show the effectiveness of the proposed approaches. The overall system achieves state-of-the-art performance on both depth and ego-motion estimation.",
        "primary_area": "",
        "author": "Hualie Jiang;Laiyan Ding;Zhenglong Sun;Rui Huang;Hualie Jiang;Laiyan Ding;Zhenglong Sun;Rui Huang",
        "authorids": "/37087245479;/37088686872;/37086799406;/37085486482;/37087245479;/37088686872;/37086799406;/37085486482",
        "aff": "School of Science and Engineering, The Chinese University of Hong Kong, Shenzhen, P.R. China; School of Science and Engineering, The Chinese University of Hong Kong, Shenzhen, P.R. China; Shenzhen Institute of Artificial Intelligence and Robotics for Society, Shenzhen, P.R. China; Shenzhen Institute of Artificial Intelligence and Robotics for Society, Shenzhen, P.R. China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341074/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4976288863376675238&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;1",
        "aff_unique_norm": "The Chinese University of Hong Kong;Shenzhen Institute of Artificial Intelligence and Robotics for Society",
        "aff_unique_dep": "School of Science and Engineering;",
        "aff_unique_url": "https://www.cuhk.edu.cn;",
        "aff_unique_abbr": "CUHK;",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Shenzhen",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9341775",
        "title": "Diabolo Orientation Stabilization by Learning Predictive Model for Unstable Unknown-Dynamics Juggling Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Juggling manipulation is one of difficult manipulation to acquire since some of such manipulation is unstable and also its physical model is unknown due to the complex non-prehensile manipulation. To acquire these unstable unknown-dynamics juggling manipulation, we propose a method for designing the predictive model of manipulation with a deep neural network, and a real-time optimal control law with some robustness and adaptability using backpropagation of the network. In this study, we apply this method to diabolo orientation stabilization, which is one of unstable unknown-dynamics juggling manipulation. We verify the effectiveness of the proposed method by comparing with basic controllers such as P Controller or PID Controller, and also check the adaptability of the proposed controller by some experiments with a real life-sized humanoid robot.",
        "primary_area": "",
        "author": "Takayuki Murooka;Kei Okada;Masayuki Inaba;Takayuki Murooka;Kei Okada;Masayuki Inaba",
        "authorids": "/37088341446;/37280639000;/37286658200;/37088341446;/37280639000;/37286658200",
        "aff": "JSK Laboratory, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; JSK Laboratory, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; JSK Laboratory, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341775/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11914753833993369150&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "The University of Tokyo",
        "aff_unique_dep": "Graduate School of Information Science and Technology",
        "aff_unique_url": "https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "UTokyo",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9340750",
        "title": "Diagnose like a Clinician: Third-order Attention Guided Lesion Amplification Network for WCE Image Classification",
        "track": "main",
        "status": "Poster",
        "abstract": "Wireless capsule endoscopy (WCE) is a novel imaging tool that allows the noninvasive visualization of the entire gastrointestinal (GI) tract without causing discomfort to the patients. Although convolutional neural networks (CNNs) have obtained promising performance for the automatic lesion recognition, the results of the current approaches are still limited due to the small lesions and the background interference in the WCE images. To overcome these limits, we propose a Third-order Attention guided Lesion Amplification Network (TALA-Net) for WCE image classification. The TALA-Net consists of two branches, including a global branch and an attention-aware branch. Specifically, taking the high-level features in the global branch as the input, we propose a Third-order Attention (ToA) module to generate attention maps that can indicate potential lesion regions. Then, an Attention Guided Lesion Amplification (AGLA) module is proposed to deform multiple level features in the global branch, so as to zoom in the potential lesion features. The deformed features are fused into the attention-aware branch to achieve finer-scale lesion recognition. Finally, predictions from the global and attention-aware branches are averaged to obtain the classification results. Extensive experiments show that the proposed TALA-Net outperforms state-of-the-art methods with an overall classification accuracy of 94.72% on the WCE dataset.",
        "primary_area": "",
        "author": "Xiaohan Xing;Yixuan Yuan;Max Q.-H. Meng;Xiaohan Xing;Yixuan Yuan;Max Q.-H. Meng",
        "authorids": "/37086496866;/37075918800;/37274117000;/37086496866;/37075918800;/37274117000",
        "aff": "Department of Electronic Engineering, The Chinese University of Hong Kong, Hong Kong, China; Department of Electrical Engineering, City University of Hong Kong, Hong Kong, China; Shenzhen Research Institute of the Chinese University of Hong Kong in Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340750/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17544808371424527630&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "The Chinese University of Hong Kong;City University of Hong Kong;Chinese University of Hong Kong",
        "aff_unique_dep": "Department of Electronic Engineering;Department of Electrical Engineering;Shenzhen Research Institute",
        "aff_unique_url": "https://www.cuhk.edu.hk;https://www.cityu.edu.hk;https://www.cuhk.edu.hk",
        "aff_unique_abbr": "CUHK;CityU;CUHK",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Hong Kong;Shenzhen",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9341046",
        "title": "Dielecrophoretic introduction of the membrane proteins into the BLM platforms for the electrophygiological analysis systems",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposed a technique to introduce the membrane protein into the lab-on-chip analysis system having a planar lipid bilayer. The proposed technique utilized a dielectrophoretic(DEP) force generated by the asymmetric configuration of the solid electrodes on the aqueous buffer separator. By applying the alternating current to the separator and the counter electrode, we manipulated liposomes that could host the membrane proteins on the surface. The key point for the dielectrophoretic manipulation on this system was the effective configuration of the droplet separator having the taperedge on the contour of the micropore. This configuration made a strong interpenetrating DEP force at the lipid bilayer, and prompted the fusion of liposome into the lipid bilayer. The separator was fabricated by micromachining techniques. Using the separator, we formed the lipid bilayer without evading the solid electrode on the surface. Finally, we elucidated the introduction of the liposome by monitoring with the optical microscopy.",
        "primary_area": "",
        "author": "Hirotaka Sugiura;Toshihisa Osaki;Hisatoshi Mimura;Tetsuya Yamada;Shoji Takeuchi;Hirotaka Sugiura;Toshihisa Osaki;Hisatoshi Mimura;Tetsuya Yamada;Shoji Takeuchi",
        "authorids": "/37085415264;/37402970800;/37088360091;/37350363000;/37275286500;/37085415264;/37402970800;/37088360091;/37350363000;/37275286500",
        "aff": "Graduate School of Mechanical Engineering, The University of Tokyo, Japan; Institute of Industrial Science, The University of Tokyo, Japan; Kanagawa Institute of Industrial Science and Technology, Japan; Kanagawa Institute of Industrial Science and Technology, Japan; Graduate School of Information Science and Technology, The University of Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341046/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:dtRFJTOuyOgJ:scholar.google.com/&scioq=Dielecrophoretic+introduction+of+the+membrane+proteins+into+the+BLM+platforms+for+the+electrophygiological+analysis+systems&hl=en&as_sdt=0,5",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;1;0",
        "aff_unique_norm": "The University of Tokyo;Kanagawa Institute of Industrial Science and Technology",
        "aff_unique_dep": "Graduate School of Mechanical Engineering;",
        "aff_unique_url": "https://www.u-tokyo.ac.jp;http://www.kiist.ac.jp",
        "aff_unique_abbr": "UTokyo;",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Tokyo;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9341043",
        "title": "Differential Image Based Robot to MRI Scanner Registration with Active Fiducial Markers for an MRI-Guided Robotic Catheter System",
        "track": "main",
        "status": "Poster",
        "abstract": "In magnetic resonance imaging (MRI) guided robotic catheter ablation procedures, reliable tracking of the catheter within the MRI scanner is needed to safely navigate the catheter. This requires accurate registration of the catheter to the scanner. This paper presents a differential, multi-slice image-based registration approach utilizing active fiducial coils. The proposed method would be used to pre-operatively register the MRI image space with the physical catheter space. In the proposed scheme, the registration is performed with the help of a registration frame, which has a set of embedded electromagnetic coils designed to actively create MRI image artifacts. These coils are detected in the MRI scanner's coordinate system by background subtraction. The detected coil locations in each slice are weighted by the artifact size and then registered to known ground truth coil locations in the catheter's coordinate system via least-squares fitting. The proposed approach is validated by using a set of target coils placed withing the workspace, employing multi-planar capabilities of the MRI scanner. The average registration and validation errors are respectively computed as 1.97 mm and 2.49 mm. The multi-slice approach is also compared to the single-slice method and shown to improve registration and validation by respectively 0.45 mm and 0.66 mm.",
        "primary_area": "",
        "author": "E. Erdem Tuna;Nate Lombard Poirot;Juana Barrera Bayona;Dominique Franson;Sherry Huang;Julian Narvaez;Nicole Seiberlich;Mark Griswold;M. Cenk \u00c7avu\u015fo\u011flu;E. Erdem Tuna;Nate Lombard Poirot;Juana Barrera Bayona;Dominique Franson;Sherry Huang;Julian Narvaez;Nicole Seiberlich;Mark Griswold;M. Cenk \u00c7avu\u015fo\u011flu",
        "authorids": "/38540673100;/37086580754;/37088691461;/37085857992;/37088508320;/37088688986;/37085761432;/38185461800;/37373298800;/38540673100;/37086580754;/37088691461;/37085857992;/37088508320;/37088688986;/37085761432;/38185461800;/37373298800",
        "aff": "Department of Electrical, Computer, and Systems Engineering, Case Western Reserve University, Cleveland, OH, USA; Department of Electrical, Computer, and Systems Engineering, Case Western Reserve University, Cleveland, OH, USA; Department of Electrical, Computer, and Systems Engineering, Case Western Reserve University, Cleveland, OH, USA; Department of Biomedical Engineering, Case Western Reserve University, Cleveland, OH, USA; Department of Biomedical Engineering, Case Western Reserve University, Cleveland, OH, USA; Department of Electrical, Computer, and Systems Engineering, Case Western Reserve University, Cleveland, OH, USA; Department of Radiology, University of Michigan, Ann-Anbor, MI, USA; Department of Biomedical Engineering, Case Western Reserve University, Cleveland, OH, USA; Department of Electrical, Computer and Systems Engineering, Case Western Reserve University, Cleveland, OH, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341043/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2228392869351557019&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;0;0;0;1;0;0",
        "aff_unique_norm": "Case Western Reserve University;University of Michigan",
        "aff_unique_dep": "Department of Electrical, Computer, and Systems Engineering;Department of Radiology",
        "aff_unique_url": "https://www.case.edu;https://www.michigan.edu",
        "aff_unique_abbr": "CWRU;UM",
        "aff_campus_unique_index": "0;0;0;0;0;0;1;0;0",
        "aff_campus_unique": "Cleveland;Ann Arbor",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341536",
        "title": "Diminished Reality for Close Quarters Robotic Telemanipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "In robot telemanipulation tasks, the robot can sometimes occlude a target object from the user's view. We investigate the potential of diminished reality to address this problem. Our method uses an optical see-through head-mounted display to create a diminished reality illusion that the robot is transparent, allowing users to see occluded areas behind the robot. To investigate benefits and drawbacks of robot transparency, we conducted a user study that examined diminished reality in a simple telemanipulation task involving both occluded and unoccluded targets. We discovered that while these visualizations show promise for reducing user effort, there are drawbacks in terms of task efficiency and user preference. We identified several friction points in user experiences with diminished reality interfaces. Finally, we describe several design trade-offs among different visualization options.",
        "primary_area": "",
        "author": "Ada V. Taylor;Ayaka Matsumoto;Elizabeth J. Carter;Alexander Plopski;Henny Admoni;Ada V. Taylor;Ayaka Matsumoto;Elizabeth J. Carter;Alexander Plopski;Henny Admoni",
        "authorids": "/37087232002;/37088686138;/37071687700;/37085577666;/38570430500;/37087232002;/37088686138;/37071687700;/37085577666;/38570430500",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA; Nara Institute of Science and Technology; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA; University of Otago; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341536/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2459046490687938875&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;2;0",
        "aff_unique_norm": "Carnegie Mellon University;Nara Institute of Science and Technology;University of Otago",
        "aff_unique_dep": "Robotics Institute;;",
        "aff_unique_url": "https://www.cmu.edu;https://www.nist.go.jp;https://www.otago.ac.nz",
        "aff_unique_abbr": "CMU;NIST;Otago",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pittsburgh;",
        "aff_country_unique_index": "0;1;0;2;0",
        "aff_country_unique": "United States;Japan;New Zealand"
    },
    {
        "id": "9341800",
        "title": "Disappearance of chaotic attractor of passive dynamic walking by stretch-bending deformation in basin of attraction",
        "track": "main",
        "status": "Poster",
        "abstract": "Passive dynamic walking is a model that walks down a shallow slope without any control or input. This model has been widely used to investigate how stable walking is generated from a dynamic viewpoint, which is useful to provide design principles for developing energy-efficient biped robots. However, the basin of attraction is very small and thin, and it has a fractal-like complicated shape. This makes it difficult to produce stable walking. Furthermore, the passive dynamic walking shows chaotic attractor through a period-doubling cascade by increasing the slope angle, and the chaotic attractor suddenly disappears at a critical slope angle. These make it further difficult to produce stable walking. In our previous work, we used the simplest walking model and investigated the fractal-like basin of attraction based on dynamical systems theory by focusing on the hybrid dynamics of the model composed of the continuous dynamics with saddle hyperbolicity and the discontinuous dynamics by the impact at foot contact. We elucidated that the fractal-like basin of attraction is generated through iterative stretch and bending deformations of the domain of the Poincar\u00e9 map by sequential inverse images of the Poincar\u00e9 map. In this study, we investigated the mechanism for the disappearance of the chaotic attractor by improving our previous analysis. In particular, we focused on the range of the Poincar\u00e9 map to specify the regions to be stretched and bent by the inverse image of the Poincar\u00e9 map. We clarified the condition for the chaotic attractor to disappear and the mechanism why the chaotic attractor disappears based on the stretch-bending deformation in the basin of attraction.",
        "primary_area": "",
        "author": "Kota Okamoto;Shinya Aoi;Ippei Obayashi;Hiroshi Kokubu;Kei Senda;Kazuo Tsuchiya;Kota Okamoto;Shinya Aoi;Ippei Obayashi;Hiroshi Kokubu;Kei Senda;Kazuo Tsuchiya",
        "authorids": "/37088689598;/37283598200;/37088688129;/37832540000;/37275342100;/37271139800;/37088689598;/37283598200;/37088688129;/37832540000;/37275342100;/37271139800",
        "aff": "Department of Aeronautics and Astronautics, Graduate School of Engineering, Kyoto University, Kyoto, Japan; Department of Aeronautics and Astronautics, Graduate School of Engineering, Kyoto University, Kyoto, Japan; Center for Advanced Intelligence Project, RIKEN, Tokyo, Japan; Department of Mathematics, Graduate School of Science, Kyoto University, Kyoto, Japan; Department of Aeronautics and Astronautics, Graduate School of Engineering, Kyoto University, Kyoto, Japan; Department of Aeronautics and Astronautics, Graduate School of Engineering, Kyoto University, Kyoto, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341800/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8826856227130283091&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;0;0;0",
        "aff_unique_norm": "Kyoto University;RIKEN",
        "aff_unique_dep": "Department of Aeronautics and Astronautics;Center for Advanced Intelligence Project",
        "aff_unique_url": "https://www.kyoto-u.ac.jp;https://www.riken.jp",
        "aff_unique_abbr": "Kyoto U;RIKEN",
        "aff_campus_unique_index": "0;0;1;0;0;0",
        "aff_campus_unique": "Kyoto;Tokyo",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9340893",
        "title": "Distilling Location Proposals of Unknown Objects through Gaze Information for Human-Robot Interaction",
        "track": "main",
        "status": "Poster",
        "abstract": "Successful and meaningful human-robot interaction requires robots to have knowledge about the interaction context - e.g., which objects should be interacted with. Unfortunately, the corpora of interactive objects is - for all practical purposes - infinite. This fact hinders the deployment of robots with pre-trained object-detection neural networks other than in pre-defined scenarios. A more flexible alternative to pre-training is to let a human teach the robot about new objects after deployment. However, doing so manually presents significant usability issues as the user must manipulate the object and communicate the object's boundaries to the robot. In this work, we propose streamlining this process by using automatic object location proposal methods in combination with human gaze to distill pertinent object location proposals. Experiments show that the proposed method 1) increased the precision by a factor of approximately 21 compared to location proposal alone, 2) is able to locate objects sufficiently similar to a state-of-the-art pre-trained deep-learning method (FCOS) without any training, and 3) detected objects that were completely missed by FCOS. Furthermore, the method is able to locate objects for which FCOS was not trained on, which are undetectable for FCOS by definition.",
        "primary_area": "",
        "author": "Daniel Weber;Thiago Santini;Andreas Zell;Enkelejda Kasneci;Daniel Weber;Thiago Santini;Andreas Zell;Enkelejda Kasneci",
        "authorids": "/37088688485;/37085666096;/37276583400;/37085505106;/37088688485;/37085666096;/37276583400;/37085505106",
        "aff": "University of T\u00fcbingen, T\u00fcbingen, Germany; University of T\u00fcbingen, T\u00fcbingen, Germany; University of T\u00fcbingen, T\u00fcbingen, Germany; University of T\u00fcbingen, T\u00fcbingen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340893/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8062581753474596920&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of T\u00fcbingen",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.uni-tuebingen.de/",
        "aff_unique_abbr": "Uni T\u00fcbingen",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "T\u00fcbingen",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9341541",
        "title": "Distributed Model Predictive Control for UAVs Collaborative Payload Transport",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider the problem of collaborative transport of a payload using several quadrotor vehicles. The payload is assumed to be a rigid body and is attached to the vehicles with rigid rods. The model of the system is presented and is employed to formulate a Model Predictive Controller. The centralized MPC formulation differs from others in the literature in the way the linearized model of the system is employed about a non-equilibrium state-input pair. We then present a decentralized formulation of MPC by distributing the computations among the vehicles. Simulations of both versions of the controller are carried out for a four-quadrotor system carrying out a transport maneuver of a box payload, for a cost penalizing the deviations of the vehicles from the desired trajectory and the attitude perturbations of the payload. The results confirm that the decentralized controller can yield a comparable performance to the centralized MPC implementation, for the same computation time of the two algorithms.",
        "primary_area": "",
        "author": "Jad Wehbeh;Shatil Rahman;Inna Sharf;Jad Wehbeh;Shatil Rahman;Inna Sharf",
        "authorids": "/37088686972;/37086959705;/37283633500;/37088686972;/37086959705;/37283633500",
        "aff": "Department of Mechanical Engineering, McGill University, Montreal, QC, Canada; Department of Mechanical Engineering, McGill University, Montreal, QC, Canada; Department of Mechanical Engineering, McGill University, Montreal, QC, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341541/",
        "gs_citation": 55,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12360883674957103625&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "McGill University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.mcgill.ca",
        "aff_unique_abbr": "McGill",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Montreal",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9340743",
        "title": "Distributed Motion Control for Multiple Connected Surface Vessels",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a scalable cooperative control approach which coordinates a group of rigidly connected autonomous surface vessels to track desired trajectories in a planar water environment as a single floating modular structure. Our approach leverages the implicit information of the structure\u2019s motion for force and torque allocation without explicit communication among the robots. In our system, a leader robot steers the entire group by adjusting its force and torque according to the structure\u2019s deviation from the desired trajectory, while follower robots run distributed consensus-based controllers to match their inputs to amplify the leader\u2019s intent using only onboard sensors as feedback. To cope with the nonlinear system dynamics in the water, the leader robot employs a nonlinear model predictive controller (NMPC), where we experimentally estimated the dynamics model of the floating modular structure in order to achieve superior performance for leader-following control. Our method has a wide range of potential applications in transporting humans and goods in many of today\u2019s existing waterways. We conducted trajectory and orientation tracking experiments in hardware with three custom-built autonomous modular robotic boats, called Roboat, which are capable of holonomic motions and onboard state estimation. Simulation results with up to 65 robots also prove the scalability of our proposed approach.",
        "primary_area": "",
        "author": "Wei Wang;Zijian Wang;Luis Mateos;Kuan Wei Huang;Mac Schwager;Carlo Ratti;Daniela Rus;Wei Wang;Zijian Wang;Luis Mateos;Kuan Wei Huang;Mac Schwager;Carlo Ratti;Daniela Rus",
        "authorids": "/37073346500;/37086084215;/38228214600;/37087092513;/37424620600;/37590016800;/37279652300;/37073346500;/37086084215;/38228214600;/37087092513;/37424620600;/37590016800;/37279652300",
        "aff": "Computer Science and Artificial Intelligence Lab (CSAIL), Massachusetts Institute of Technology, Cambridge, MA, USA; Department of Aeronautics and Astronautics, Stanford University, Stanford, CA, USA; Computer Science and Artificial Intelligence Lab (CSAIL), Massachusetts Institute of Technology, Cambridge, MA, USA; SENSEable City Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA; Department of Aeronautics and Astronautics, Stanford University, Stanford, CA, USA; SENSEable City Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA; Computer Science and Artificial Intelligence Lab (CSAIL), Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340743/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18313661593385123567&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;0;0;1;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;Stanford University",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Lab (CSAIL);Department of Aeronautics and Astronautics",
        "aff_unique_url": "https://www.mit.edu;https://www.stanford.edu",
        "aff_unique_abbr": "MIT;Stanford",
        "aff_campus_unique_index": "0;1;0;0;1;0;0",
        "aff_campus_unique": "Cambridge;Stanford",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341652",
        "title": "Distributed Near-optimal Multi-robots Coordination in Heterogeneous Task Allocation",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper explores the heterogeneous task allocation problem in Multi-robot systems. A game-theoretic formulation of the problem is proposed to align the goal of individual robots with the system objective. The concept of Nash equilibrium is applied to define a desired solution for the task allocation problem in which each robot can allocate itself to an appropriate task group. We also introduce a market-based distributed mechanism, called DisNE, to allow the robots to exchange messages with tasks and move between task groups, eventually reaching an equilibrium solution. We carry out comprehensive empirical studies to demonstrate that DisNE achieves near-optimal system utility in significantly shorter computation times when compared with the state-of-the-art mechanisms.",
        "primary_area": "",
        "author": "Qinyuan Li;Minyi Li;Bao Quoc Vo;Ryszard Kowalczyk;Qinyuan Li;Minyi Li;Bao Quoc Vo;Ryszard Kowalczyk",
        "authorids": "/37088688492;/37088559828;/37540335000;/37288259800;/37088688492;/37088559828;/37540335000;/37288259800",
        "aff": "Faculty of Science, Engineering and Technology, Swinburne University of Technology, Melbourne, Australia; School of Science, RMIT University, Melbourne, Australia; Faculty of Science, Engineering and Technology, Swinburne University of Technology, Melbourne, Australia; Systems Research Institute, Polish Academy of Sciences, Warsaw, Poland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341652/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3691790044251573933&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;2",
        "aff_unique_norm": "Swinburne University of Technology;RMIT University;Polish Academy of Sciences",
        "aff_unique_dep": "Faculty of Science, Engineering and Technology;School of Science;Systems Research Institute",
        "aff_unique_url": "https://www.swinburne.edu.au;https://www.rmit.edu.au;https://www.pan.pl",
        "aff_unique_abbr": "Swinburne;RMIT;PAS",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "Melbourne;Warsaw",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "Australia;Poland"
    },
    {
        "id": "9341605",
        "title": "Distributed Reinforcement Learning of Targeted Grasping with Active Vision for Mobile Manipulators",
        "track": "main",
        "status": "Poster",
        "abstract": "Developing personal robots that can perform a diverse range of manipulation tasks in unstructured environments necessitates solving several challenges for robotic grasping systems. We take a step towards this broader goal by presenting the first RL-based system, to our knowledge, for a mobile manipulator that can (a) achieve targeted grasping generalizing to unseen target objects, (b) learn complex grasping strategies for cluttered scenes with occluded objects, and (c) perform active vision through its movable wrist camera to better locate objects. The system is informed of the desired target object in the form of a single, arbitrary-pose RGB image of that object, enabling the system to generalize to unseen objects without retraining. To achieve such a system, we combine several advances in deep reinforcement learning and present a large-scale distributed training system using synchronous SGD that seamlessly scales to multi-node, multi-GPU infrastructure to make rapid prototyping easier. We train and evaluate our system in a simulated environment, identify key components for improving performance, analyze its behaviors, and transfer to a real-world setup.",
        "primary_area": "",
        "author": "Yasuhiro Fujita;Kota Uenishi;Avinash Ummadisingu;Prabhat Nagarajan;Shimpei Masuda;Mario Ynocente Castro;Yasuhiro Fujita;Kota Uenishi;Avinash Ummadisingu;Prabhat Nagarajan;Shimpei Masuda;Mario Ynocente Castro",
        "authorids": "/37088686917;/37088690586;/37088690436;/37088686622;/37086604931;/37088597521;/37088686917;/37088690586;/37088690436;/37088686622;/37086604931;/37088597521",
        "aff": "Preferred Networks, Inc., Tokyo, Japan; Preferred Networks, Inc., Tokyo, Japan; Preferred Networks, Inc., Tokyo, Japan; Preferred Networks, Inc., Tokyo, Japan; Preferred Networks, Inc., Tokyo, Japan; Preferred Networks, Inc., Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341605/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7026821354142578171&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Preferred Networks, Inc.",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.preferred-networks.com",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9341044",
        "title": "Domain Adaptation for Outdoor Robot Traversability Estimation from RGB data with Safety-Preserving Loss",
        "track": "main",
        "status": "Poster",
        "abstract": "Being able to estimate the traversability of the area surrounding a mobile robot is a fundamental task in the design of a navigation algorithm. However, the task is often complex, since it requires evaluating distances from obstacles, type and slope of terrain, and dealing with non-obvious discontinuities in detected distances due to perspective. In this paper, we present an approach based on deep learning to estimate and anticipate the traversing score of different routes in the field of view of an on-board RGB camera. The backbone of the proposed model is based on a state-of-the-art deep segmentation model, which is fine-tuned on the task of predicting route traversability. We then enhance the model's capabilities by a) addressing domain shifts through gradient-reversal unsupervised adaptation, and b) accounting for the specific safety requirements of a mobile robot, by encouraging the model to err on the safe side, i.e., penalizing errors that would cause collisions with obstacles more than those that would cause the robot to stop in advance. Experimental results show that our approach is able to satisfactorily identify traversable areas and to generalize to unseen locations.",
        "primary_area": "",
        "author": "Simone Palazzo;Dario C. Guastella;Luciano Cantelli;Paolo Spadaro;Francesco Rundo;Giovanni Muscato;Daniela Giordano;Concetto Spampinato;Simone Palazzo;Dario C. Guastella;Luciano Cantelli;Paolo Spadaro;Francesco Rundo;Giovanni Muscato;Daniela Giordano;Concetto Spampinato",
        "authorids": "/38506467100;/37088561922;/37691497000;/37088690933;/37294498700;/37283226100;/37356118000;/37547440100;/38506467100;/37088561922;/37691497000;/37088690933;/37294498700;/37283226100;/37356118000;/37547440100",
        "aff": "Department of Electrical, Electronics and Computer Engineering, University of Catania, Catania, Italy; Department of Electrical, Electronics and Computer Engineering, University of Catania, Catania, Italy; Department of Electrical, Electronics and Computer Engineering, University of Catania, Catania, Italy; Department of Electrical, Electronics and Computer Engineering, University of Catania, Catania, Italy; ADG Central R&D, STMicroelectronics, Catania, Italy; Department of Electrical, Electronics and Computer Engineering, University of Catania, Catania, Italy; Department of Electrical, Electronics and Computer Engineering, University of Catania, Catania, Italy; Department of Electrical, Electronics and Computer Engineering, University of Catania, Catania, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341044/",
        "gs_citation": 39,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16567220661002815118&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;1;0;0;0",
        "aff_unique_norm": "University of Catania;STMicroelectronics",
        "aff_unique_dep": "Department of Electrical, Electronics and Computer Engineering;ADG Central R&D",
        "aff_unique_url": "https://www.unict.it;https://www.st.com",
        "aff_unique_abbr": ";STM",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Catania",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9341508",
        "title": "Domain Transfer for Semantic Segmentation of LiDAR Data using Deep Neural Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Inferring semantic information towards an understanding of the surrounding environment is crucial for autonomous vehicles to drive safely. Deep learning-based segmentation methods can infer semantic information directly from laser range data, even in the absence of other sensor modalities such as cameras. In this paper, we address improving the generalization capabilities of such deep learning models to range data that was captured using a different sensor and in situations where no labeled data is available for the new sensor setup. Our approach assists the domain transfer of a LiDAR-only semantic segmentation model to a different sensor and environment exploiting existing geometric mapping systems. To this end, we fuse sequential scans in the source dataset into a dense mesh and render semi-synthetic scans that match those of the target sensor setup. Unlike simulation, this approach provides a real-to-real transfer of geometric information and delivers additionally more accurate remission information. We implemented and thoroughly tested our approach by transferring semantic scans between two different real-world datasets with different sensor setups. Our experiments show that we can improve the segmentation performance substantially with zero manual re-labeling. This approach solves the number one feature request since we released our semantic segmentation library LiDAR-bonnetal [18].",
        "primary_area": "",
        "author": "Ferdinand Langer;Andres Milioto;Alexandre Haag;Jens Behley;Cyrill Stachniss;Ferdinand Langer;Andres Milioto;Alexandre Haag;Jens Behley;Cyrill Stachniss",
        "authorids": "/37088690657;/37086400161;/37088687443;/37593243900;/37329668600;/37088690657;/37086400161;/37088687443;/37593243900;/37329668600",
        "aff": "University of Bonn, Germany; University of Bonn, Germany; Argo.ai, Munich, Germany; University of Bonn, Germany; University of Bonn, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341508/",
        "gs_citation": 71,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11569061717605098867&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "University of Bonn;Argo.ai",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.uni-bonn.de;https://argo.ai",
        "aff_unique_abbr": "UBonn;",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Munich",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9341705",
        "title": "Domain-Adversarial and -Conditional State Space Model for Imitation Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "State representation learning (SRL) in partially observable Markov decision processes has been studied to learn abstract features of data useful for robot control tasks. For SRL, acquiring domain-agnostic states is essential for achieving efficient imitation learning. Without these states, imitation learning is hampered by domain-dependent information useless for control. However, existing methods fail to remove such disturbances from the states when the data from experts and agents show large domain shifts. To overcome this issue, we propose a domain-adversarial and -conditional state space model (DAC-SSM) that enables control systems to obtain domain-agnostic and task- and dynamics-aware states. DAC-SSM jointly optimizes the state inference, observation reconstruction, forward dynamics, and reward models. To remove domain-dependent information from the states, the model is trained with domain discriminators in an adversarial manner, and the reconstruction is conditioned on domain labels. We experimentally evaluated the model predictive control performance via imitation learning for continuous control of sparse reward tasks in simulators and compared it with the performance of the existing SRL method. The agents from DAC-SSM achieved performance comparable to experts and more than twice the baselines. We conclude domain-agnostic states are essential for imitation learning that has large domain shifts and can be obtained using DAC-SSM.",
        "primary_area": "",
        "author": "Ryo Okumura;Masashi Okada;Tadahiro Taniguchi;Ryo Okumura;Masashi Okada;Tadahiro Taniguchi",
        "authorids": "/37089696496;/37086454122;/37273806600;/37089696496;/37086454122;/37273806600",
        "aff": "Core Element Technology Development Center, Panasonic Corporation, Japan; AI Solutions Center, Business Innovation Division, Panasonic Corporation, Japan; College of Information Science and Engineering, Ritsumeikan University, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341705/",
        "gs_citation": -1,
        "gs_cited_by_link": "",
        "gs_version_total": -1,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Panasonic Corporation;Ritsumeikan University",
        "aff_unique_dep": "Core Element Technology Development Center;College of Information Science and Engineering",
        "aff_unique_url": "https://www.panasonic.com;https://www.ritsumei.ac.jp",
        "aff_unique_abbr": "Panasonic;Ritsumeikan",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9341217",
        "title": "Drive-Train Design in JAXON3-P and Realization of Jump Motions: Impact Mitigation and Force Control Performance for Dynamic Motions",
        "track": "main",
        "status": "Poster",
        "abstract": "For mitigating joint impact torques, researchers have reduced joint stiffness by series elastic actuators, reflected inertia by low gear ratios, and friction torque from drive-trains. However, these impact mitigation methods may impair the control performance of contact forces or may increase motor and robot mass. This paper proposes a design method for achieving a balance between impact mitigation performance and force control fidelity. We introduce an inertia-to-square-torque ratio as a new index for integrating the parameters of torque generation (motor continuous torque limits, gear ratios, etc.) and the parameters of impact mitigation (joint stiffness, reflected inertia, etc.). In the process, we make a hypothesis that a motor mass is negatively correlated with the ratio. Based on the hypothesis, we calculate a joint breakdown region of impact torques, joint stiffnesses, and motor masses. Finally, we decide the drive-train specifications of JAXON3-P and demonstrate that the proposed method provides high impact mitigation and force control capabilities through several experiments including the jumping motion of 0.3 m COG height.",
        "primary_area": "",
        "author": "Kunio Kojima;Yuta Kojio;Tatsuya Ishikawa;Fumihito Sugai;Yohei Kakiuchi;Kei Okada;Masayuki Inaba;Kunio Kojima;Yuta Kojio;Tatsuya Ishikawa;Fumihito Sugai;Yohei Kakiuchi;Kei Okada;Masayuki Inaba",
        "authorids": "/37085360901;/37086211574;/38148331500;/37085651948;/38242437800;/37280639000;/37286658200;/37085360901;/37086211574;/38148331500;/37085651948;/38242437800;/37280639000;/37286658200",
        "aff": "Graduate School of Information Science and Technology, The University of Tokyo, Bunkyo-ku, Tokyo, Japan; Graduate School of Information Science and Technology, The University of Tokyo, Bunkyo-ku, Tokyo, Japan; Graduate School of Information Science and Technology, The University of Tokyo, Bunkyo-ku, Tokyo, Japan; Graduate School of Information Science and Technology, The University of Tokyo, Bunkyo-ku, Tokyo, Japan; Graduate School of Information Science and Technology, The University of Tokyo, Bunkyo-ku, Tokyo, Japan; Graduate School of Information Science and Technology, The University of Tokyo, Bunkyo-ku, Tokyo, Japan; Graduate School of Information Science and Technology, The University of Tokyo, Bunkyo-ku, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341217/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13624300050715054917&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "The University of Tokyo",
        "aff_unique_dep": "Graduate School of Information Science and Technology",
        "aff_unique_url": "https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "UTokyo",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9340639",
        "title": "Driving Through Ghosts: Behavioral Cloning with False Positives",
        "track": "main",
        "status": "Poster",
        "abstract": "Safe autonomous driving requires robust detection of other traffic participants. However, robust does not mean perfect, and safe systems typically minimize missed detections at the expense of a higher false positive rate. This results in conservative and yet potentially dangerous behavior such as avoiding imaginary obstacles. In the context of behavioral cloning, perceptual errors at training time can lead to learning difficulties or wrong policies, as expert demonstrations might be inconsistent with the perceived world state. In this work, we propose a behavioral cloning approach that can safely leverage imperfect perception without being conservative. Our core contribution is a novel representation of perceptual uncertainty for learning to plan. We propose a new probabilistic birds-eye-view semantic grid to encode the noisy output of object perception systems. We then leverage expert demonstrations to learn an imitative driving policy using this probabilistic representation. Using the CARLA simulator, we show that our approach can safely overcome critical false positives that would otherwise lead to catastrophic failures or conservative behavior.",
        "primary_area": "",
        "author": "Andreas B\u00fchler;Adrien Gaidon;Andrei Cramariuc;Rares Ambrus;Guy Rosman;Wolfram Burgard;Andreas B\u00fchler;Adrien Gaidon;Andrei Cramariuc;Rares Ambrus;Guy Rosman;Wolfram Burgard",
        "authorids": "/37088028624;/37945420900;/37085840497;/37871304500;/37393688300;/37270485300;/37088028624;/37945420900;/37085840497;/37871304500;/37393688300;/37270485300",
        "aff": "Toyota Research Institute (TRI), USA; Toyota Research Institute (TRI), USA; Autonomous Systems Lab (ASL), ETH Zurich, Switzerland; Toyota Research Institute (TRI), USA; Toyota Research Institute (TRI), USA; Toyota Research Institute (TRI), USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340639/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13691956037690445352&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;0;0;0",
        "aff_unique_norm": "Toyota Research Institute;ETH Zurich",
        "aff_unique_dep": ";Autonomous Systems Lab (ASL)",
        "aff_unique_url": "https://www.tri.global;https://www.ethz.ch",
        "aff_unique_abbr": "TRI;ETHZ",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1;0;0;0",
        "aff_country_unique": "United States;Switzerland"
    },
    {
        "id": "9341250",
        "title": "Dual-Arm Control for Enhanced Magnetic Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Magnetically actuated soft robots have recently been identified for application in medicine, due to their potential to perform minimally invasive exploration of human cavities. Magnetic solutions permit further miniaturization when compared to other actuation techniques, without loss in functionalities. Our long-term goal is to propose a novel actuation method for magnetically actuated soft robots, based on dual-arm collaborative magnetic manipulation. A fundamental step in this direction is to show that this actuation method is capable of controlling up to 8 coincident, independent Degrees of Freedom (DOFs). In present paper, we prove this concept by measuring the independent wrench components on a second pair of static permanent magnets, by means of a high resolution 6-axis load cell. The experiments show dominant activation of the desired DOFs, with mean cross-activation error of the undesired DOFs ranging from 2% to 10%.",
        "primary_area": "",
        "author": "Giovanni Pittiglio;James H. Chandler;Michiel Richter;Venkatasubramanian K. Venkiteswaran;Sarthak Misra;Pietro Valdastri;Giovanni Pittiglio;James H. Chandler;Michiel Richter;Venkatasubramanian K. Venkiteswaran;Sarthak Misra;Pietro Valdastri",
        "authorids": "/37086690861;/37085707243;/37088688470;/37086693104;/37536488800;/37282537500;/37086690861;/37085707243;/37088688470;/37086693104;/37536488800;/37282537500",
        "aff": "the STORM Lab, School of Electronic and Electrical Engineering, University of Leeds, Leeds, UK; the STORM Lab, School of Electronic and Electrical Engineering, University of Leeds, Leeds, UK; Department of Biomechanical Engineering, Surgical Robotics Laboratory, University of Twente, Enschede, The Netherlands; Department of Biomechanical Engineering, Surgical Robotics Laboratory, University of Twente, Enschede, The Netherlands; Department of Biomedical Engineering, University of Groningen and University Medical Centre Groningen, Groningen, The Netherlands; the STORM Lab, School of Electronic and Electrical Engineering, University of Leeds, Leeds, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341250/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14220194143722921660&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;1;2;0",
        "aff_unique_norm": "University of Leeds;University of Twente;University of Groningen",
        "aff_unique_dep": "School of Electronic and Electrical Engineering;Department of Biomechanical Engineering;Department of Biomedical Engineering",
        "aff_unique_url": "https://www.leeds.ac.uk;https://www.utwente.nl;https://www.rug.nl",
        "aff_unique_abbr": "Leeds;UT;RUG",
        "aff_campus_unique_index": "0;0;1;1;2;0",
        "aff_campus_unique": "Leeds;Enschede;Groningen",
        "aff_country_unique_index": "0;0;1;1;1;0",
        "aff_country_unique": "United Kingdom;Netherlands"
    },
    {
        "id": "9341513",
        "title": "Dual-SLAM: A framework for robust single camera navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "SLAM (Simultaneous Localization And Mapping) seeks to provide a moving agent with real-time self-localization. To achieve real-time speed, SLAM incrementally propagates position estimates. This makes SLAM fast but also makes it vulnerable to local pose estimation failures. As local pose estimation is ill-conditioned, local pose estimation failures happen regularly, making the overall SLAM system brittle. This paper attempts to correct this problem. We note that while local pose estimation is ill-conditioned, pose estimation over longer sequences is well-conditioned. Thus, local pose estimation errors eventually manifest themselves as mapping inconsistencies. When this occurs, we save the current map and activate two new SLAM threads. One processes incoming frames to create a new map and the other, recovery thread, backtracks to link new and old maps together. This creates a Dual-SLAM framework that maintains real-time performance while being robust to local pose estimation failures. Evaluation on benchmark datasets shows Dual-SLAM can reduce failures by a dramatic 88%.",
        "primary_area": "",
        "author": "Huajian Huang;Wen-Yan Lin;Siying Liu;Dong Zhang;Sai-Kit Yeung;Huajian Huang;Wen-Yan Lin;Siying Liu;Dong Zhang;Sai-Kit Yeung",
        "authorids": "/37088691434;/37085494398;/37964577600;/38251817400;/37529101500;/37088691434;/37085494398;/37964577600;/38251817400;/37529101500",
        "aff": "Department of Computer Science and Engineering, Hong Kong University of Science and Technology; School of information systems, Singapore Management University; Institute for Infocomm Research, Singapore; School of Electronics and Information Technology, Sun Yat-sen University; Department of Computer Science and Engineering, Hong Kong University of Science and Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341513/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17244064596777591652&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 13,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;3;0",
        "aff_unique_norm": "Hong Kong University of Science and Technology;Singapore Management University;Institute for Infocomm Research;Sun Yat-sen University",
        "aff_unique_dep": "Department of Computer Science and Engineering;School of information systems;;School of Electronics and Information Technology",
        "aff_unique_url": "https://www.ust.hk;https://www.smu.edu.sg;https://www.i2r.a-star.edu.sg;http://www.sysu.edu.cn",
        "aff_unique_abbr": "HKUST;SMU;I2R;SYSU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Hong Kong SAR;",
        "aff_country_unique_index": "0;1;1;0;0",
        "aff_country_unique": "China;Singapore"
    },
    {
        "id": "9341323",
        "title": "Dynamic Assistance for Human Balancing with Inertia of a Wearable Robotic Appendage",
        "track": "main",
        "status": "Poster",
        "abstract": "A reduced balance ability can lead to falls and critical injuries. To prevent falls, humans use reaction forces and torques generated by swinging their arms. In animals, we can find that a similar strategy is taken using tails. Inspired by these strategies, we propose an approach that utilizes a robotic appendage as a human balance supporter without assistance from environmental contact. As a proof of concept, we developed a wearable robotic appendage that has one actuated degree of freedom and rotates around the sagittal axis of the wearer. To validate the feasibility of our proposed approach, we conducted an evaluation experiment with human subjects. Controlling the robotic appendage we developed improved the subjects' balance ability and enabled the subject to withstand up to 22.8 % larger impulse disturbances on average than in the fixed appendage condition.",
        "primary_area": "",
        "author": "Azumi Maekawa;Kei Kawamura;Masahiko Inami;Azumi Maekawa;Kei Kawamura;Masahiko Inami",
        "authorids": "/37086800846;/37088690468;/37282894600;/37086800846;/37088690468;/37282894600",
        "aff": "Graduate School of Engineering, the University of Tokyo, Tokyo, Japan; Graduate School of Arts and Sciences, the University of Tokyo, Tokyo, Japan; Research Center for Advanced Science and Technology, the University of Tokyo, Meguro-ku Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341323/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14673310249024508434&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Tokyo;the University of Tokyo",
        "aff_unique_dep": "Graduate School of Engineering;Graduate School of Arts and Sciences",
        "aff_unique_url": "https://www.u-tokyo.ac.jp;https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "UTokyo;UTokyo",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Tokyo;Meguro-ku Tokyo",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9340890",
        "title": "Dynamic Attention-based Visual Odometry",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a dynamic attention-based visual odometry framework (DAVO), a learning-based VO method, for estimating the ego-motion of a monocular camera. DAVO dynamically adjusts the attention weights on different semantic categories for different motion scenarios based on optical flow maps. These weighted semantic categories can then be used to generate attention maps that highlight the relative importance of different semantic regions in input frames for pose estimation. In order to examine the proposed DAVO, we perform a number of experiments on the KITTI Visual Odometry and SLAM benchmark suite to quantitatively and qualitatively inspect the impacts of the dynamically adjusted weights on the accuracy of the evaluated trajectories. Moreover, we design a set of ablation analyses to justify each of our design choices, and validate the effectiveness as well as the advantages of DAVO. Our experiments on the KITTI dataset shows that the proposed DAVO framework does provide satisfactory performance in ego-motion estimation, and is able deliver competitive performance when compared to the contemporary VO methods.",
        "primary_area": "",
        "author": "Xin-Yu Kuo;Chien Liu;Kai-Chen Lin;Evan Luo;Yu-Wen Chen;Chun-Yi Lee;Xin-Yu Kuo;Chien Liu;Kai-Chen Lin;Evan Luo;Yu-Wen Chen;Chun-Yi Lee",
        "authorids": "/37088450064;/37088448733;/37088448797;/37088690639;/37089939294;/37086565629;/37088450064;/37088448733;/37088448797;/37088690639;/37089939294;/37086565629",
        "aff": "Department of Computer Science, Elsa Lab, National Tsing Hua University, Hsinchu, Taiwan; Department of Computer Science, Elsa Lab, National Tsing Hua University, Hsinchu, Taiwan; Department of Computer Science, Elsa Lab, National Tsing Hua University, Hsinchu, Taiwan; Department of Computer Science, Elsa Lab, National Tsing Hua University, Hsinchu, Taiwan; Department of Computer Science, Elsa Lab, National Tsing Hua University, Hsinchu, Taiwan; Department of Computer Science, Elsa Lab, National Tsing Hua University, Hsinchu, Taiwan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340890/",
        "gs_citation": 44,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10899481507981107125&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "National Tsing Hua University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.nthu.edu.tw",
        "aff_unique_abbr": "NTHU",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Taiwan",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9341218",
        "title": "Dynamic Legged Manipulation of a Ball Through Multi-Contact Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "The feet of robots are typically used to design locomotion strategies, such as balancing, walking, and running. However, they also have great potential to perform manipulation tasks. In this paper, we propose a model predictive control (MPC) framework for a quadrupedal robot to dynamically balance on a ball and simultaneously manipulate it to follow various trajectories such as straight lines, sinusoids, circles and in-place turning. We numerically validate our controller on the Mini Cheetah robot using different gaits including trotting, bounding, and pronking on the ball.",
        "primary_area": "",
        "author": "Chenyu Yang;Bike Zhang;Jun Zeng;Ayush Agrawal;Koushil Sreenath;Chenyu Yang;Bike Zhang;Jun Zeng;Ayush Agrawal;Koushil Sreenath",
        "authorids": "/366738887380486;/37086917680;/37086963288;/37086081045;/37563179200;/366738887380486;/37086917680;/37086963288;/37086081045;/37563179200",
        "aff": "Department of Mechanical Engineering, University of California Berkeley, California, CA, USA; Department of Mechanical Engineering, University of California Berkeley, California, CA, USA; Department of Mechanical Engineering, University of California Berkeley, California, CA, USA; Department of Mechanical Engineering, University of California Berkeley, California, CA, USA; Department of Mechanical Engineering, University of California Berkeley, California, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341218/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=591329413138093132&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340958",
        "title": "Dynamic Object Tracking and Masking for Visual SLAM",
        "track": "main",
        "status": "Poster",
        "abstract": "In dynamic environments, performance of visual SLAM techniques can be impaired by visual features taken from moving objects. One solution is to identify those objects so that their visual features can be removed for localization and mapping. This paper presents a simple and fast pipeline that uses deep neural networks, extended Kalman filters and visual SLAM to improve both localization and mapping in dynamic environments (around 14 fps on a GTX 1080). Results on the dynamic sequences from the TUM dataset using RTAB-Map as visual SLAM suggest that the approach achieves similar localization performance compared to other state-of-the-art methods, while also providing the position of the tracked dynamic objects, a 3D map free of those dynamic objects, better loop closure detection with the whole pipeline able to run on a robot moving at moderate speed.",
        "primary_area": "",
        "author": "Jonathan Vincent;Mathieu Labb\u00e9;Jean-Samuel Lauzon;Fran\u00e7ois Grondin;Pier-Marc Comtois-Rivet;Fran\u00e7ois Michaud;Jonathan Vincent;Mathieu Labb\u00e9;Jean-Samuel Lauzon;Fran\u00e7ois Grondin;Pier-Marc Comtois-Rivet;Fran\u00e7ois Michaud",
        "authorids": "/37088686642;/38236835000;/37086282716;/38243208000;/37088687567;/37284461800;/37088686642;/38236835000;/37086282716;/38243208000;/37088687567;/37284461800",
        "aff": "Dept. Elec. Eng. and Comp. Eng., Interdisciplinary Institute for Technological Innovation (3IT), Universit\u00e9 de Sherbrooke, Qu\u00e9bec, Canada; Dept. Elec. Eng. and Comp. Eng., Interdisciplinary Institute for Technological Innovation (3IT), Universit\u00e9 de Sherbrooke, Qu\u00e9bec, Canada; Dept. Elec. Eng. and Comp. Eng., Interdisciplinary Institute for Technological Innovation (3IT), Universit\u00e9 de Sherbrooke, Qu\u00e9bec, Canada; Dept. Elec. Eng. and Comp. Eng., Interdisciplinary Institute for Technological Innovation (3IT), Universit\u00e9 de Sherbrooke, Qu\u00e9bec, Canada; Institut du V\u00e9hicule Innovant (IVI), Qu\u00e9bec, Canada; Dept. Elec. Eng. and Comp. Eng., Interdisciplinary Institute for Technological Innovation (3IT), Universit\u00e9 de Sherbrooke, Qu\u00e9bec, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340958/",
        "gs_citation": 57,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12719930200906157045&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;0",
        "aff_unique_norm": "Universit\u00e9 de Sherbrooke;Institut du V\u00e9hicule Innovant",
        "aff_unique_dep": "Dept. Elec. Eng. and Comp. Eng.;",
        "aff_unique_url": "https://www.usherbrooke.ca;",
        "aff_unique_abbr": "UdeS;IVI",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Sherbrooke;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9341179",
        "title": "Dynamic Object Tracking for Self-Driving Cars Using Monocular Camera and LIDAR",
        "track": "main",
        "status": "Poster",
        "abstract": "The detection and tracking of dynamic traffic participants (e.g., pedestrians, cars, and bicyclists) plays an important role in reliable decision-making and intelligent navigation for autonomous vehicles. However, due to the rapid movement of the target, most current vision-based tracking methods, which perform tracking in the image domain or invoke 3D information in parts of their pipeline, have real-life limitations such as lack of the ability to recover tracking after the target is lost. In this work, we overcome such limitations and propose a complete system for dynamic object tracking in 3D space that combines: (1) a 3D position tracking algorithm based on monocular camera and LIDAR for the dynamic object; (2) a re-tracking mechanism (RTM) that restore tracking when the target reappears in camera's field of view. Compared with the existing methods, each sensor in our method is capable of performing its role to preserve reliability, and further extending its functions through a novel multimodality fusion module. We perform experiments in the real-world self-driving environment and achieve a desired 10Hz update rate for real-time performance. Our quantitative and qualitative analysis shows that this system is reliable for dynamic object tracking purposes of self-driving cars.",
        "primary_area": "",
        "author": "Lin Zhao;Meiling Wang;Sheng Su;Tong Liu;Yi Yang;Lin Zhao;Meiling Wang;Sheng Su;Tong Liu;Yi Yang",
        "authorids": "/37088689394;/37406965500;/37088688208;/37085425408;/37899921700;/37088689394;/37406965500;/37088688208;/37085425408;/37899921700",
        "aff": "Integrated Navigation and Intelligent Navigation laboratory, School of Automation, Beijing Institute of Technology, China; Integrated Navigation and Intelligent Navigation laboratory, School of Automation, Beijing Institute of Technology, China; Integrated Navigation and Intelligent Navigation laboratory, School of Automation, Beijing Institute of Technology, China; Integrated Navigation and Intelligent Navigation laboratory, School of Automation, Beijing Institute of Technology, China; Integrated Navigation and Intelligent Navigation laboratory, School of Automation, Beijing Institute of Technology, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341179/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10794342383433733977&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Beijing Institute of Technology",
        "aff_unique_dep": "School of Automation",
        "aff_unique_url": "http://www.bit.edu.cn/",
        "aff_unique_abbr": "BIT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9341518",
        "title": "Dynamic Parameter Estimation Utilizing Optimized Trajectories",
        "track": "main",
        "status": "Poster",
        "abstract": "We suggest a procedure for dynamic parameter estimation of serial robot manipulators. Its basic idea relies on the synthesis of an optimal manipulation trajectory, which is based on properly introduced parameter aggregates to ensure a collection of numerically well-conditioned data-sets, yielding an accurate computation of parameter estimates. The optimal trajectory itself is computed by using a memetic algorithm, which represents a metaheuristic combination of genetic and gradient based algorithms. The algorithm is experimentally verified by estimating the parameters of the UR5 robot by Universal Robots.",
        "primary_area": "",
        "author": "Argtim Tika;Jonas Ulmen;Naim Bajcinca;Argtim Tika;Jonas Ulmen;Naim Bajcinca",
        "authorids": "/37088688783;/37088689952;/37426387700;/37088688783;/37088689952;/37426387700",
        "aff": "Department of Mechanical and Process Engineering, Technische Universit\u00e4t Kaiserslautern, Germany; TU Kaiserslautern, Germany; TU Kaiserslautern, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341518/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15206293562764507958&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Technische Universit\u00e4t Kaiserslautern",
        "aff_unique_dep": "Department of Mechanical and Process Engineering",
        "aff_unique_url": "https://www.uni-kl.de",
        "aff_unique_abbr": "TU Kaiserslautern",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9341242",
        "title": "Dynamic Stability Control of Inverted-Pendulum-Type Robotic Wheelchair for Going Up and Down Stairs",
        "track": "main",
        "status": "Poster",
        "abstract": "The wheelchair is the major means of transport for elderly and physically disabled people in their daily lives. However it cannot overcome architectural barriers such as curbs and stairs. In this study, we developed an inverted-pendulum-type robotic wheelchair for climbing stairs. The wheelchair has a seat slider and two rotary links between the front and rear wheels on each side. When climbing up stairs, the wheelchair rotates the rotary links while maintaining an inverted state of a movable body by controlling the position of the center of gravity using the seat slider. In previous research, we proposed the control method for climbing up stairs using the rotary links and seat slider, confirming a period of approximately 5 s to rotate the rotary links. In this paper, we propose a control method for going down stairs, and experimentally verify the control effectiveness and stability.",
        "primary_area": "",
        "author": "Yuya Onozuka;Nobuyasu Tomokuni;Genki Murata;Motoki Shino;Yuya Onozuka;Nobuyasu Tomokuni;Genki Murata;Motoki Shino",
        "authorids": "/37088690172;/37294459400;/37085511803;/38192315700;/37088690172;/37294459400;/37085511803;/38192315700",
        "aff": "Department of Human and Engineered Environmental Studies, Graduate School of Frontier Sciences, The University of Tokyo, Kashiwa, Chiba, Japan; Department of Robotics, Kindai University, Hiroshima, Japan; JTEKT Corporation, Kariya, Aichi, Japan; Department of Human and Engineered Environmental Studies, Graduate School of Frontier Sciences, The University of Tokyo, Kashiwa, Chiba, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341242/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18284477612220018266&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "The University of Tokyo;Kindai University;JTEKT Corporation",
        "aff_unique_dep": "Department of Human and Engineered Environmental Studies;Department of Robotics;",
        "aff_unique_url": "https://www.u-tokyo.ac.jp;https://www.kindai.ac.jp;https://www.jtekt.co.jp",
        "aff_unique_abbr": "UTokyo;;",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Kashiwa;Hiroshima;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9341283",
        "title": "Dynamically Constrained Motion Planning Networks for Non-Holonomic Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Reliable real-time planning for robots is essential in today's rapidly expanding automated ecosystem. In such environments, traditional methods that plan by relaxing constraints become unreliable or slow-down for kinematically constrained robots. This paper describes the algorithm Dynamic Motion Planning Networks (Dynamic MPNet), an extension to Motion Planning Networks, for non-holonomic robots that address the challenge of real-time motion planning using a neural planning approach. We propose modifications to the training and planning networks that make it possible for real-time planning while improving the data efficiency of training and trained models' generalizability. We evaluate our model in simulation for planning tasks for a non-holonomic robot. We also demonstrate experimental results for an indoor navigation task using a Dubins car.",
        "primary_area": "",
        "author": "Jacob J. Johnson;Linjun Li;Fei Liu;Ahmed H. Qureshi;Michael C. Yip;Jacob J. Johnson;Linjun Li;Fei Liu;Ahmed H. Qureshi;Michael C. Yip",
        "authorids": "/37086079723;/37088690399;/37088689503;/37086070898;/37085382768;/37086079723;/37088690399;/37088689503;/37086070898;/37085382768",
        "aff": "Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, CA, USA; Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, CA, USA; Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, CA, USA; Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, CA, USA; Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341283/",
        "gs_citation": 36,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6564913600756621862&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of California San Diego",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.ucsd.edu",
        "aff_unique_abbr": "UCSD",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "La Jolla",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341616",
        "title": "Dynamics and Aerial Attitude Control for Rapid Emergency Deployment of the Agile Ground Robot AGRO",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work we present a Four-Wheeled Independent Drive and Steering (4WIDS) robot named AGRO and a method of controlling its orientation while airborne using wheel reaction torques. This is the first documented use of independently steerable wheels to both drive on the ground and achieve aerial attitude control when thrown. Inspired by a cat's self-righting reflex, this capability was developed to allow emergency response personnel to rapidly deploy AGRO by throwing it over walls and fences or through windows without the risk of it landing upside down. It also allows AGRO to drive off of ledges and ensure it lands on all four wheels. We have demonstrated a successful thrown deployment of AGRO.A novel parametrization and singularity analysis of 4WIDS kinematics reveals independent yaw authority with simultaneous adjustment of the ratio between roll and pitch authority. Simple PD controllers allow for stabilization of roll, pitch, and yaw. These controllers were tested in a simulation using derived dynamic equations of motion, then implemented on the AGRO prototype. An experiment comparing a controlled and non-controlled fall was conducted in which AGRO was dropped from a height of 0.85 m with an initial roll and pitch angle of 16 degrees and -23 degrees respectively. With the controller enabled, AGRO can use the reaction torque from its wheels to stabilize its orientation within 402 milliseconds.",
        "primary_area": "",
        "author": "Daniel J. Gonzalez;Mark C. Lesak;Andres H. Rodriguez;Joseph A. Cymerman;Christopher M. Korpela;Daniel J. Gonzalez;Mark C. Lesak;Andres H. Rodriguez;Joseph A. Cymerman;Christopher M. Korpela",
        "authorids": "/37085812023;/37088689702;/37088688981;/37088505629;/37680206300;/37085812023;/37088689702;/37088688981;/37088505629;/37680206300",
        "aff": "United States Military Academy, West Point, NY, USA; United States Military Academy, West Point, NY, USA; United States Military Academy, West Point, NY, USA; United States Military Academy, West Point, NY, USA; United States Military Academy, West Point, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341616/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6715798448923653100&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "United States Military Academy",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.usma.edu",
        "aff_unique_abbr": "USMA",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "West Point",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341757",
        "title": "EAO-SLAM: Monocular Semi-Dense Object SLAM Based on Ensemble Data Association",
        "track": "main",
        "status": "Poster",
        "abstract": "Object-level data association and pose estimation play a fundamental role in semantic SLAM, which remain unsolved due to the lack of robust and accurate algorithms. In this work, we propose an ensemble data associate strategy for integrating the parametric and nonparametric statistic tests. By exploiting the nature of different statistics, our method can effectively aggregate the information of different measurements, and thus significantly improve the robustness and accuracy of data association. We then present an accurate object pose estimation framework, in which an outliers-robust centroid and scale estimation algorithm and an object pose initialization algorithm are developed to help improve the optimality of pose estimation results. Furthermore, we build a SLAM system that can generate semi-dense or lightweight object-oriented maps with a monocular camera. Extensive experiments are conducted on three publicly available datasets and a real scenario. The results show that our approach significantly outperforms state-of-the-art techniques in accuracy and robustness. The source code is available on https://github.com/yanmin-wu/EAO-SLAM.",
        "primary_area": "",
        "author": "Yanmin Wu;Yunzhou Zhang;Delong Zhu;Yonghui Feng;Sonya Coleman;Dermot Kerr;Yanmin Wu;Yunzhou Zhang;Delong Zhu;Yonghui Feng;Sonya Coleman;Dermot Kerr",
        "authorids": "/37088690951;/37310459100;/37086137408;/37088687763;/37269140600;/37295244700;/37088690951;/37310459100;/37086137408;/37088687763;/37269140600;/37295244700",
        "aff": "Faculty of Robot Science and Engineering, Northeastern University, Shenyang, China; College of Information Science and Engineering, Northeastern University, Shenyang, China; Department of Electronic Engineering, The Chinese University of Hong Kong, China; College of Information Science and Engineering, Northeastern University, Shenyang, China; School of Computing and Intelligent Systems, Ulster University, N. Ireland, UK; School of Computing and Intelligent Systems, Ulster University, N. Ireland, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341757/",
        "gs_citation": 121,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11540051749075339566&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;0;2;2",
        "aff_unique_norm": "Northeastern University;The Chinese University of Hong Kong;Ulster University",
        "aff_unique_dep": "Faculty of Robot Science and Engineering;Department of Electronic Engineering;School of Computing and Intelligent Systems",
        "aff_unique_url": "http://www.neu.edu.cn/;https://www.cuhk.edu.hk;https://www.ulster.ac.uk",
        "aff_unique_abbr": "NEU;CUHK;Ulster",
        "aff_campus_unique_index": "0;0;1;0;2;2",
        "aff_campus_unique": "Shenyang;Hong Kong;N. Ireland",
        "aff_country_unique_index": "0;0;0;0;1;1",
        "aff_country_unique": "China;United Kingdom"
    },
    {
        "id": "9341156",
        "title": "EDAN: An EMG-controlled Daily Assistant to Help People With Physical Disabilities",
        "track": "main",
        "status": "Poster",
        "abstract": "Injuries, accidents, strokes, and other diseases can significantly degrade the capabilities to perform even the most simple activities in daily life. A large share of these cases involves neuromuscular diseases, which lead to severely reduced muscle function. However, even though affected people are no longer able to move their limbs, residual muscle function can still be existent. Previous work has shown that this residual muscular activity can suffice to apply an EMG-based user interface. In this paper, we introduce DLR's robotic wheelchair EDAN (EMG-controlled Daily Assistant), which is equipped with a torque-controlled, eight degree-of-freedom light-weight arm and a dexterous, five-fingered robotic hand. Using electromyography, muscular activity of the user is measured, processed and utilized to control both the wheelchair and the robotic manipulator. This EMG-based interface is enhanced with shared control functionality to allow for efficient and safe physical interaction with the environment.",
        "primary_area": "",
        "author": "J\u00f6rn Vogel;Annette Hagengruber;Maged Iskandar;Gabriel Quere;Ulrike Leipscher;Samuel Bustamante;Alexander Dietrich;Hannes H\u00f6ppner;Daniel Leidner;Alin Albu-Sch\u00e4ffer;J\u00f6rn Vogel;Annette Hagengruber;Maged Iskandar;Gabriel Quere;Ulrike Leipscher;Samuel Bustamante;Alexander Dietrich;Hannes H\u00f6ppner;Daniel Leidner;Alin Albu-Sch\u00e4ffer",
        "authorids": "/37602887100;/37086040849;/37086454969;/37086933696;/37088690191;/37088505028;/37970388100;/37947381300;/37586132500;/38270361100;/37602887100;/37086040849;/37086454969;/37086933696;/37088690191;/37088505028;/37970388100;/37947381300;/37586132500;/38270361100",
        "aff": "Institute of Robotics and Mechatronics, German Aerospace Center (DLR); Institute of Robotics and Mechatronics, German Aerospace Center (DLR); Institute of Robotics and Mechatronics, German Aerospace Center (DLR); Institute of Robotics and Mechatronics, German Aerospace Center (DLR); Institute of Robotics and Mechatronics, German Aerospace Center (DLR); Institute of Robotics and Mechatronics, German Aerospace Center (DLR); Institute of Robotics and Mechatronics, German Aerospace Center (DLR); Beuth University of Applied Sciences, Berlin; Institute of Robotics and Mechatronics, German Aerospace Center (DLR); Institute of Robotics and Mechatronics, German Aerospace Center (DLR)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341156/",
        "gs_citation": 45,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2697817510135246219&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 20,
        "aff_unique_index": "0;0;0;0;0;0;0;1;0;0",
        "aff_unique_norm": "German Aerospace Center;Beuth University of Applied Sciences",
        "aff_unique_dep": "Institute of Robotics and Mechatronics;",
        "aff_unique_url": "https://www.dlr.de;https://www.beuth-hochschule.de/",
        "aff_unique_abbr": "DLR;Beuth",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Berlin",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9341160",
        "title": "ETRI-Activity3D: A Large-Scale RGB-D Dataset for Robots to Recognize Daily Activities of the Elderly",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep learning, based on which many modern algorithms operate, is well known to be data-hungry. In particular, the datasets appropriate for the intended application are difficult to obtain. To cope with this situation, we introduce a new dataset called ETRI-Activity3D, focusing on the daily activities of the elderly in robot-view. The major characteristics of the new dataset are as follows: 1) practical action categories that are selected from the close observation of the daily lives of the elderly; 2) realistic data collection, which reflects the robot's working environment and service situations; and 3) a large-scale dataset that overcomes the limitations of the current 3D activity analysis benchmark datasets. The proposed dataset contains 112,620 samples including RGB videos, depth maps, and skeleton sequences. During the data acquisition, 100 subjects were asked to perform 55 daily activities. Additionally, we propose a novel network called four-stream adaptive CNN (FSA-CNN). The proposed FSA-CNN has three main properties: robustness to spatio-temporal variations, input-adaptive activation function, and extension of the conventional two-stream approach. In the experiment section, we confirmed the superiority of the proposed FSA-CNN using NTU RGB+D and ETRI-Activity3D. Further, the domain difference between both groups of age was verified experimentally. Finally, the extension of FSA-CNN to deal with the multimodal data was investigated.",
        "primary_area": "",
        "author": "Jinhyeok Jang;Dohyung Kim;Cheonshu Park;Minsu Jang;Jaeyeon Lee;Jaehong Kim;Jinhyeok Jang;Dohyung Kim;Cheonshu Park;Minsu Jang;Jaeyeon Lee;Jaehong Kim",
        "authorids": "/37085655094;/37068058200;/37291054300;/37288561200;/37292725400;/37293475300;/37085655094;/37068058200;/37291054300;/37288561200;/37292725400;/37293475300",
        "aff": "Human Robot Interaction Research Lab, Electronics and Telecommunications Research Institute, Daejeon, Republic of Korea; Human Robot Interaction Research Lab, Electronics and Telecommunications Research Institute, Daejeon, Republic of Korea; Human Robot Interaction Research Lab, Electronics and Telecommunications Research Institute, Daejeon, Republic of Korea; Human Robot Interaction Research Lab, Electronics and Telecommunications Research Institute, Daejeon, Republic of Korea; Human Robot Interaction Research Lab, Electronics and Telecommunications Research Institute, Daejeon, Republic of Korea; Human Robot Interaction Research Lab, Electronics and Telecommunications Research Institute, Daejeon, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341160/",
        "gs_citation": 100,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7786433061442945432&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Electronics and Telecommunications Research Institute",
        "aff_unique_dep": "Human Robot Interaction Research Lab",
        "aff_unique_url": "http://www.etri.re.kr",
        "aff_unique_abbr": "ETRI",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Daejeon",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9341406",
        "title": "EU Long-term Dataset with Multiple Sensors for Autonomous Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "The field of autonomous driving has grown tremendously over the past few years, along with the rapid progress in sensor technology. One of the major purposes of using sensors is to provide environment perception for vehicle understanding, learning and reasoning, and ultimately interacting with the environment. In this paper, we first introduce a multisensor platform allowing vehicle to perceive its surroundings and locate itself in a more efficient and accurate way. The platform integrates eleven heterogeneous sensors including various cameras and lidars, a radar, an IMU (Inertial Measurement Unit), and a GPS-RTK (Global Positioning System / Real-Time Kinematic), while exploits a ROS (Robot Operating System) based software to process the sensory data. Then, we present a new dataset (https://epan-utbm.github.io/utbm_robocar_dataset/) for autonomous driving captured many new research challenges (e.g. highly dynamic environment), and especially for long-term autonomy (e.g. creating and maintaining maps), collected with our instrumented vehicle, publicly available to the community.",
        "primary_area": "",
        "author": "Zhi Yan;Li Sun;Tom\u00e1\u0161 Krajn\u00edk;Yassine Ruichek;Zhi Yan;Li Sun;Tom\u00e1\u0161 Krajn\u00edk;Yassine Ruichek",
        "authorids": "/37086432956;/37086401506;/38547272600;/37284281500;/37086432956;/37086401506;/38547272600;/37284281500",
        "aff": "CIAD UMR7533, Univ. Bourgogne Franche-Comt, UTBM, Belfort, France; Sheffield Robotics, University of Sheffield, UK; Artificial Intelligence Center, Czech Technical University, Czechia; CIAD UMR7533, Univ. Bourgogne Franche-Comt, UTBM, Belfort, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341406/",
        "gs_citation": 122,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=679412126080947442&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "University Bourgogne Franche-Comt\u00e9;University of Sheffield;Czech Technical University",
        "aff_unique_dep": "CIAD UMR7533;Sheffield Robotics;Artificial Intelligence Center",
        "aff_unique_url": "https://www.ubfc.fr;https://www.sheffield.ac.uk;https://www.cvut.cz",
        "aff_unique_abbr": "UBFC;Sheffield;CTU",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Belfort;Sheffield;",
        "aff_country_unique_index": "0;1;2;0",
        "aff_country_unique": "France;United Kingdom;Czechia"
    },
    {
        "id": "9341486",
        "title": "Edge-based Visual Odometry with Stereo Cameras using Multiple Oriented Quadtrees",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose an efficient edge-based stereo visual odometry (VO) using multiple quadtrees created according to image gradient orientations. To characterize edges, we classify them into eight orientation groups according to their image gradient directions. Using the edge groups, we construct eight quadtrees and set overlapping areas belonging to adjacent quadtrees for robust and efficient matching. For further acceleration, previously visited tree nodes are stored and reused at the next iteration to warm-start. We propose an edge culling method to extract prominent edgelets and prune redundant edges. The camera motion is estimated by minimizing point-to-edge distances within a re-weighted iterative closest points (ICP) framework, and simultaneously, 3-D structures are recovered by static and temporal stereo settings. To analyze the effects of the proposed methods, we conduct extensive simulations with various settings. Quantitative results on public datasets confirm that our approach has competitive performance with state-of-the-art stereo methods. In addition, we demonstrate the practical values of our system in author-collected modern building scenes with curved edges only.",
        "primary_area": "",
        "author": "Changhyeon Kim;Junha Kim;H. Jin Kim;Changhyeon Kim;Junha Kim;H. Jin Kim",
        "authorids": "/37086041943;/37087404753;/37599626400;/37086041943;/37087404753;/37599626400",
        "aff": "Department of Mechanical and Aerospace Engineering, Seoul National University and Automation and Systems Research Institute (ASRI), Seoul, South Korea; Department of Mechanical and Aerospace Engineering, Seoul National University and Automation and Systems Research Institute (ASRI), Seoul, South Korea; Department of Mechanical and Aerospace Engineering, Seoul National University and Automation and Systems Research Institute (ASRI), Seoul, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341486/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14595984881530425198&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Seoul National University",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.snu.ac.kr",
        "aff_unique_abbr": "SNU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9340784",
        "title": "Efficiency and Equity are Both Essential: A Generalized Traffic Signal Controller with Deep Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Traffic signal controllers play an essential role in today's traffic system. However, the majority of them currently is not sufficiently flexible or adaptive to generate optimal traffic schedules. In this paper we present an approach to learn policies for signal controllers using deep reinforcement learning aiming for optimized traffic flow. Our method uses a novel formulation of the reward function that simultaneously considers efficiency and equity. We furthermore present a general approach to find the bound for the proposed equity factor and we introduce the adaptive discounting approach that greatly stabilizes learning and helps to maintain a high flexibility of green light duration. The experimental evaluations on both simulated and real-world data demonstrate that our proposed algorithm achieves state-of-the-art performance (previously held by traditional non-learning methods) on a wide range of traffic situations.",
        "primary_area": "",
        "author": "Shengchao Yan;Jingwei Zhang;Daniel B\u00fcscher;Wolfram Burgard;Shengchao Yan;Jingwei Zhang;Daniel B\u00fcscher;Wolfram Burgard",
        "authorids": "/37088688067;/37086287434;/37086455193;/37270485300;/37088688067;/37086287434;/37086455193;/37270485300",
        "aff": "Department of Computer Science, University of Freiburg, Germany; Department of Computer Science, University of Freiburg, Germany; Department of Computer Science, University of Freiburg, Germany; Toyota Research Institute, Los Altos, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340784/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6792775855440871778&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "University of Freiburg;Toyota Research Institute",
        "aff_unique_dep": "Department of Computer Science;",
        "aff_unique_url": "https://www.uni-freiburg.de;https://www.tri.global",
        "aff_unique_abbr": ";TRI",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Los Altos",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "Germany;United States"
    },
    {
        "id": "9341620",
        "title": "Efficient Exploration in Constrained Environments with Goal-Oriented Reference Path",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we consider the problem of building learning agents that can efficiently learn to navigate in constrained environments. The main goal is to design agents that can efficiently learn to understand and generalize to different environments using high-dimensional inputs (a 2D map), while following feasible paths that avoid obstacles in obstacle-cluttered environment. To achieve this, we make use of traditional path planning algorithms, supervised learning, and reinforcement learning algorithms in a synergistic way. The key idea is to decouple the navigation problem into planning and control, the former of which is achieved by supervised learning whereas the latter is done by reinforcement learning. Specifically, we train a deep convolutional network that can predict collision-free paths based on a map of the environment- this is then used by an reinforcement learning algorithm to learn to closely follow the path. This allows the trained agent to achieve good generalization while learning faster. We test our proposed method in the recently proposed Safety Gym suite that allows testing of safety-constraints during training of learning agents. We compare our proposed method with existing work and show that our method consistently improves the sample efficiency and generalization capability to novel environments.",
        "primary_area": "",
        "author": "Kei Ota;Yoko Sasaki;Devesh K. Jha;Yusuke Yoshiyasu;Asako Kanezaki;Kei Ota;Yoko Sasaki;Devesh K. Jha;Yusuke Yoshiyasu;Asako Kanezaki",
        "authorids": "/37087323962;/37418160900;/37072717800;/37392153300;/37546453800;/37087323962;/37418160900;/37072717800;/37392153300;/37546453800",
        "aff": "National Institute of Advanced Industrial Science and Technology (AIST), Japan; National Institute of Advanced Industrial Science and Technology (AIST), Japan; Mitsubishi Electric Research Labs, Cambridge, MA, USA; National Institute of Advanced Industrial Science and Technology (AIST), Japan; National Institute of Advanced Industrial Science and Technology (AIST), Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341620/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1699712396694318912&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "National Institute of Advanced Industrial Science and Technology;Mitsubishi Electric Research Labs",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.aist.go.jp;https://www.merl.com",
        "aff_unique_abbr": "AIST;MERL",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Cambridge",
        "aff_country_unique_index": "0;0;1;0;0",
        "aff_country_unique": "Japan;United States"
    },
    {
        "id": "9341718",
        "title": "Efficient Multiresolution Scrolling Grid for Stereo Vision-based MAV Obstacle Avoidance",
        "track": "main",
        "status": "Poster",
        "abstract": "Fast, aerial navigation in cluttered environments requires a suitable map representation for path planning. In this paper, we propose the use of an efficient, structured multiresolution representation that expands the sensor range of dense local grids for memory-constrained platforms. While similar data structures have been proposed, we avoid processing redundant occupancy information and use the organization of the grid to improve efficiency. By layering 3D circular buffers that double in resolution at each level, obstacles near the robot are represented at finer resolutions while coarse spatial information is maintained at greater distances. We also introduce a novel method for efficiently calculating the Euclidean distance transform on the multiresolution grid by leveraging its structure. Lastly, we utilize our proposed framework to demonstrate improved stereo camera-based MAV obstacle avoidance with an optimization-based planner in simulation.",
        "primary_area": "",
        "author": "Eric Dexheimer;Joshua G. Mangelson;Sebastian Scherer;Michael Kaess;Eric Dexheimer;Joshua G. Mangelson;Sebastian Scherer;Michael Kaess",
        "authorids": "/37088688319;/37086109836;/37584159000;/37324200400;/37088688319;/37086109836;/37584159000;/37324200400",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341718/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:OUNjwYdaRUwJ:scholar.google.com/&scioq=Efficient+Multiresolution+Scrolling+Grid+for+Stereo+Vision-based+MAV+Obstacle+Avoidance&hl=en&as_sdt=0,5",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340989",
        "title": "Efficient Object Search Through Probability-Based Viewpoint Selection",
        "track": "main",
        "status": "Poster",
        "abstract": "The ability to search for objects is a precondition for various robotic tasks. In this paper, we address the problem of finding objects in partially known indoor environments. Using the knowledge of the floor plan and the mapped objects, we consider object-object and object-room co-occurrences as prior information for identifying promising locations where an unmapped object can be present. We propose an efficient search strategy that determines the best pose of the robot based on the analysis of the candidate locations. We optimize the probability of finding the target object and the distance travelled through a cost function.To evaluate our method, several experiments in simulated and real-world environments were performed. The results show that the robot successfully finds the target object in the environment while covering only a small portion of the search space. The real-world experiments with the TurtleBot 2 mobile robot validate the proposed approach and demonstrate that the method performs well also in real environments.",
        "primary_area": "",
        "author": "Alejandra C. Hernandez;Erik Derner;Clara Gomez;Ramon Barber;Robert Babu\u0161ka;Alejandra C. Hernandez;Erik Derner;Clara Gomez;Ramon Barber;Robert Babu\u0161ka",
        "authorids": "/37086043603;/37086454702;/37086039796;/37301902400;/37270682600;/37086043603;/37086454702;/37086039796;/37301902400;/37270682600",
        "aff": "Robotics Lab, Carlos III University of Madrid, Spain; Department of Control Engineering, Faculty of Electrical Engineering, Czech Technical University in Prague, Czech Republic; Robotics Lab, Carlos III University of Madrid, Spain; Robotics Lab, Carlos III University of Madrid, Spain; Cognitive Robotics, Delft University of Technology, The Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340989/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11188411262612160748&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;2",
        "aff_unique_norm": "Carlos III University of Madrid;Czech Technical University in Prague;Delft University of Technology",
        "aff_unique_dep": "Robotics Lab;Department of Control Engineering;Cognitive Robotics",
        "aff_unique_url": "https://www.uc3m.es;https://www.cvut.cz;https://www.tudelft.nl",
        "aff_unique_abbr": "UC3M;CTU;TUDelft",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Prague",
        "aff_country_unique_index": "0;1;0;0;2",
        "aff_country_unique": "Spain;Czech Republic;Netherlands"
    },
    {
        "id": "9341273",
        "title": "Efficient Trajectory Library Filtering for Quadrotor Flight in Unknown Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Quadrotor flight in cluttered, unknown environments is challenging due to the limited range of perception sensors, challenging obstacles, and limited onboard computation. In this work, we directly address these challenges by proposing an efficient, reactive planning approach. We introduce the Bitwise Trajectory Elimination (BiTE) algorithm for efficiently filtering out in-collision trajectories from a trajectory library by using bitwise operations. Then, we outline a full receding-horizon planning approach for quadrotor flight in unknown environments demonstrated at up to 50 Hz on an onboard computer. This approach is evaluated extensively in simulation and shown to collision check up to 4896 trajectories in under 20\u03bcs, which is the fastest collision checking time for a MAV planner, to the best of the authors' knowledge. Finally, we validate our planner in over 120 minutes of flights in forest-like and urban subterranean environments.",
        "primary_area": "",
        "author": "Vaibhav K. Viswanathan;Eric Dexheimer;Guanrui Li;Giuseppe Loianno;Michael Kaess;Sebastian Scherer;Vaibhav K. Viswanathan;Eric Dexheimer;Guanrui Li;Giuseppe Loianno;Michael Kaess;Sebastian Scherer",
        "authorids": "/37086073355;/37088688319;/37086455447;/37085496544;/37324200400;/37584159000;/37086073355;/37088688319;/37086455447;/37085496544;/37324200400;/37584159000",
        "aff": "The Robotics Institute, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA; The Robotics Institute, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA; The Department of Electrical and Computer Engineering, Tandon School of Engineering, New York University, Brooklyn, NY; The Department of Electrical and Computer Engineering, Tandon School of Engineering, New York University, Brooklyn, NY; The Robotics Institute, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA; The Robotics Institute, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341273/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11932489042621313810&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;1;0;0",
        "aff_unique_norm": "Carnegie Mellon University;New York University",
        "aff_unique_dep": "School of Computer Science;Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.cmu.edu;https://www.nyu.edu",
        "aff_unique_abbr": "CMU;NYU",
        "aff_campus_unique_index": "0;0;1;1;0;0",
        "aff_campus_unique": "Pittsburgh;Brooklyn",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341026",
        "title": "Emergence of Swing-to-Stance Transition from Interlocking Mechanism in Horse Hindlimb",
        "track": "main",
        "status": "Poster",
        "abstract": "The bodies of quadrupeds have very complex muscle-tendon structure. In particular, it is known that in the horse hindlimb, multiple joints in the leg are remarkably interlocked due to the muscle-tendon structure. Although the function of these interlocking mechanisms during standing has been investigated in the field of anatomy, the function related to the emergence of limb trajectory during dynamic walking has not been revealed. To investigate the role of the interlocking mechanism, we developed a robot model imitating the muscle-tendon arrangement and the dynamics of a horse hindlimb. In the walking experiment, the robot autonomously generated a limb trajectory with a smooth transition between the swing phase and the stance phase by simply swinging the hip joint with sinusoidal input. Moreover, we compared the joint angles between successful and failed walking. The compared results indicate that the extension of the fetlock joint after hoof touchdown plays the crucial role in emergence of a function of supporting body.",
        "primary_area": "",
        "author": "Kazuhiro Miyashita;Yoichi Masuda;Megu Gunji;Akira Fukuhara;Kenjiro Tadakuma;Masato Ishikawa;Kazuhiro Miyashita;Yoichi Masuda;Megu Gunji;Akira Fukuhara;Kenjiro Tadakuma;Masato Ishikawa",
        "authorids": "/37088686749;/37086173439;/37088233824;/37086249383;/38534909200;/37276508600;/37088686749;/37086173439;/37088233824;/37086249383;/38534909200;/37276508600",
        "aff": "Department of Mechanical Engineering, Osaka University, Suita, Osaka, Japan; Department of Mechanical Engineering, Osaka University, Suita, Osaka, Japan; National Museum of Nature and Science, Tokyo, Tsukuba-shi, Ibaraki, Japan; Research Institute of Electrical Communication, Tohoku University, Aoba-ku, Sendai, Japan; Graduate School of Information Sciences, Applied Information Sciences, Tohoku University, Sendai-shi, Japan; Department of Mechanical Engineering, Osaka University, Suita, Osaka, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341026/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13796027100382221257&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;2;2;0",
        "aff_unique_norm": "Osaka University;National Museum of Nature and Science;Tohoku University",
        "aff_unique_dep": "Department of Mechanical Engineering;;Research Institute of Electrical Communication",
        "aff_unique_url": "https://www.osaka-u.ac.jp;https://www.nmns.go.jp;https://www.tohoku.ac.jp",
        "aff_unique_abbr": "Osaka U;;Tohoku U",
        "aff_campus_unique_index": "0;0;1;2;3;0",
        "aff_campus_unique": "Suita;Tokyo;Sendai;Sendai-shi",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9341211",
        "title": "Emergent adaptive gait generation through Hebbian sensor-motor maps by morphological probing",
        "track": "main",
        "status": "Poster",
        "abstract": "Gait emergence and adaptation in animals is unmatched in robotic systems. Animals can create and recover locomotive functions \"on-the-fly\" after an injury whereas locomotion controllers for robots lack robustness to morphological changes. In this work, we extend previous research on emergent interlimb coordination of legged robots based on coupled phase oscillators with force feedback terms. We investigate how the coupling weights between these phase oscillators can be extracted from the morphology with a fast and computationally lightweight method based on a combination of twitching and Hebbian learning to form sensor-motor maps. The coefficients of these maps create naturally scaled weights, which not only lead to robust gait limit cycles, but can also adapt to morphological modifications such as sensor loss and limb injuries within a few gait cycles. We demonstrate the approach on a robotic quadruped and hexapod.",
        "primary_area": "",
        "author": "Matthieu Dujany;Simon Hauser;Mehmet Mutlu;Martijn van der Sar;Jonathan Arreguit;Takeshi Kano;Akio Ishiguro;Auke Ijspeert;Matthieu Dujany;Simon Hauser;Mehmet Mutlu;Martijn van der Sar;Jonathan Arreguit;Takeshi Kano;Akio Ishiguro;Auke Ijspeert",
        "authorids": "/37088689141;/38243975000;/37070185700;/37088686076;/37086600379;/37603654600;/37275189900;/37268732300;/37088689141;/38243975000;/37070185700;/37088686076;/37086600379;/37603654600;/37275189900;/37268732300",
        "aff": "Biorobotics Laboratory (BioRob), EPFL, Lausanne, Switzerland; Biorobotics Laboratory (BioRob), EPFL, Lausanne, Switzerland; Computer and Robot Vision Laboratory (Vislab), IST, Lisboa, Portugal; Biorobotics Laboratory (BioRob), EPFL, Lausanne, Switzerland; Biorobotics Laboratory (BioRob), EPFL, Lausanne, Switzerland; Research Institute of Electrical Communication, Tohoku University, Sendai, Miyagi, Japan; Research Institute of Electrical Communication, Tohoku University, Sendai, Miyagi, Japan; Biorobotics Laboratory (BioRob), EPFL, Lausanne, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341211/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13322711072861519640&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;1;0;0;2;2;0",
        "aff_unique_norm": "\u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne;Instituto Superior T\u00e9cnico;Tohoku University",
        "aff_unique_dep": "Biorobotics Laboratory (BioRob);Computer and Robot Vision Laboratory;Research Institute of Electrical Communication",
        "aff_unique_url": "https://www.epfl.ch;https://www.ist.utl.pt;https://www.tohoku.ac.jp",
        "aff_unique_abbr": "EPFL;IST;Tohoku U",
        "aff_campus_unique_index": "0;0;1;0;0;2;2;0",
        "aff_campus_unique": "Lausanne;Lisboa;Sendai",
        "aff_country_unique_index": "0;0;1;0;0;2;2;0",
        "aff_country_unique": "Switzerland;Portugal;Japan"
    },
    {
        "id": "9341113",
        "title": "Enabling Remote Whole-Body Control with 5G Edge Computing",
        "track": "main",
        "status": "Poster",
        "abstract": "Real-world applications require light-weight, energy-efficient, fully autonomous robots. Yet, increasing autonomy is oftentimes synonymous with escalating computational requirements. It might thus be desirable to offload intensive computation\u2014not only sensing and planning, but also low-level whole-body control\u2014to remote servers in order to reduce on-board computational needs. Fifth Generation (5G) wireless cellular technology, with its low latency and high bandwidth capabilities, has the potential to unlock cloud-based high performance control of complex robots. However, state-of-the-art control algorithms for legged robots can only tolerate very low control delays, which even ultra-low latency 5G edge computing can sometimes fail to achieve. In this work, we investigate the problem of cloud-based whole-body control of legged robots over a 5G link. We propose a novel approach that consists of a standard optimization-based controller on the network edge and a local linear, approximately optimal controller that significantly reduces on-board computational needs while increasing robustness to delay and possible loss of communication. Simulation experiments on humanoid balancing and walking tasks that includes a realistic 5G communication model demonstrate significant improvement of the reliability of robot locomotion under jitter and delays likely to be experienced in 5G wireless links.",
        "primary_area": "",
        "author": "Huaijiang Zhu;Manali Sharma;Kai Pfeiffer;Marco Mezzavilla;Jia Shen;Sundeep Rangan;Ludovic Righetti;Huaijiang Zhu;Manali Sharma;Kai Pfeiffer;Marco Mezzavilla;Jia Shen;Sundeep Rangan;Ludovic Righetti",
        "authorids": "/37086330610;/37088489157;/37679306000;/37547125900;/37088687833;/38516986200;/37295828600;/37086330610;/37088489157;/37679306000;/37547125900;/37088687833;/38516986200;/37295828600",
        "aff": "Tandon School of Engineering, New York University, USA; Tandon School of Engineering, New York University, USA; Tandon School of Engineering, New York University, USA; Tandon School of Engineering, New York University, USA; OPPO, China; Tandon School of Engineering, New York University, USA; Max Planck Institute for Intelligent Systems, T\u00fcbingen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341113/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12175274055651340093&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 15,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;1;0;2",
        "aff_unique_norm": "New York University;OPPO;Max Planck Institute for Intelligent Systems",
        "aff_unique_dep": "Tandon School of Engineering;;",
        "aff_unique_url": "https://www.nyu.edu;https://www.oppo.com;https://www.mpi-is.mpg.de",
        "aff_unique_abbr": "NYU;OPPO;MPI-IS",
        "aff_campus_unique_index": "0;0;0;0;0;2",
        "aff_campus_unique": "New York;;T\u00fcbingen",
        "aff_country_unique_index": "0;0;0;0;1;0;2",
        "aff_country_unique": "United States;China;Germany"
    },
    {
        "id": "9340735",
        "title": "Enabling Robot to Assist Human in Collaborative Assembly using Convolutional Neural Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Human-robot collaborative assembly consists of humans and automated robots, who cooperate with each other to accomplish complex assembly tasks, which are difficult for either humans or robots to accomplish alone. There has been some success in statistics-based and optimization-based approaches to realize human-robot collaboration. However, they usually need a set of complex modeling and setup efforts and the robots usually need to be programmed by a well-trained expert. In this paper, we take a new approach by introducing convolutional neural networks (CNN) into the teaching- learning-collaboration (TLC) model for collaborative assembly tasks. The proposed approach can alleviate the need for complex modeling and setup compared to the existing approaches. It can collect and automatically label the data from human demonstrations and then train a CNN-based robot assistance model to make the robot assist humans in the assembly process in real-time. We have experimentally verified our proposed approach on a human-robot collaborative assembly platform and the results suggest that the robot can successfully learn from human demonstrations to automatically generate right actions to assist human in accomplishing assembly tasks.",
        "primary_area": "",
        "author": "Yi Chen;Weitian Wang;Venkat Krovi;Yunyi Jia;Yi Chen;Weitian Wang;Venkat Krovi;Yunyi Jia",
        "authorids": "/37086390367;/37086389914;/37281399700;/37532721400;/37086390367;/37086389914;/37281399700;/37532721400",
        "aff": "Department of Automotive Engineering, Clemson University, Greenville, USA; Department of Computer Science, Montclair State University, NJ, USA; Department of Automotive Engineering, Clemson University, Greenville, USA; Department of Automotive Engineering, Clemson University, Greenville, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340735/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=735319215153317491&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Clemson University;Montclair State University",
        "aff_unique_dep": "Department of Automotive Engineering;Department of Computer Science",
        "aff_unique_url": "https://www.clemson.edu;https://www.montclair.edu",
        "aff_unique_abbr": "Clemson;",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Greenville;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341325",
        "title": "Encoding formulas as deep networks: Reinforcement learning for zero-shot execution of LTL formulas",
        "track": "main",
        "status": "Poster",
        "abstract": "We demonstrate a reinforcement learning agent which uses a compositional recurrent neural network that takes as input an LTL formula and determines satisfying actions. The input LTL formulas have never been seen before, yet the network performs zero-shot generalization to satisfy them. This is a novel form of multi-task learning for RL agents where agents learn from one diverse set of tasks and generalize to a new set of diverse tasks. The formulation of the network enables this capacity to generalize. We demonstrate this ability in two domains. In a symbolic domain, the agent finds a sequence of letters that is accepted. In a Minecraft-like environment, the agent finds a sequence of actions that conform to the formula. While prior work could learn to execute one formula reliably given examples of that formula, we demonstrate how to encode all formulas reliably. This could form the basis of new multitask agents that discover sub-tasks and execute them without any additional training, as well as the agents which follow more complex linguistic commands. The structures required for this generalization are specific to LTL formulas, which opens up an interesting theoretical question: what structures are required in neural networks for zero-shot generalization to different logics?",
        "primary_area": "",
        "author": "Yen-Ling Kuo;Boris Katz;Andrei Barbu;Yen-Ling Kuo;Boris Katz;Andrei Barbu",
        "authorids": "/37086579906;/37086574046;/37086580332;/37086579906;/37086574046;/37086580332",
        "aff": "CSAIL and CBMM, MIT; CSAIL and CBMM, MIT; CSAIL and CBMM, MIT",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341325/",
        "gs_citation": 57,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5828197807103703656&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory (CSAIL)",
        "aff_unique_url": "https://www.csail.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341249",
        "title": "End-to-End 3D Point Cloud Learning for Registration Task Using Virtual Correspondences",
        "track": "main",
        "status": "Poster",
        "abstract": "3D Point cloud registration is still a very challenging topic due to the difficulty in finding the rigid transformation between two point clouds with partial correspondences, and it's even harder in the absence of any initial estimation information. In this paper, we present an end-to-end deep-learning based approach to resolve the point cloud registration problem. Firstly, the revised LPD-Net is introduced to extract features and aggregate them with the graph network. Secondly, the self-attention mechanism is utilized to enhance the structure information in the point cloud and the cross-attention mechanism is designed to enhance the corresponding information between the two input point clouds. Based on which, the virtual corresponding points can be generated by a soft pointer based method, and finally, the point cloud registration problem can be solved by implementing the SVD method. Comparison results in ModelNet40 dataset validate that the proposed approach reaches the state-of-the-art in point cloud registration tasks and experiment resutls in KITTI dataset validate the effectiveness of the proposed approach in real applications.",
        "primary_area": "",
        "author": "Huanshu Wei;Zhijian Qiao;Zhe Liu;Chuanzhe Suo;Peng Yin;Yueling Shen;Haoang Li;Hesheng Wang;Huanshu Wei;Zhijian Qiao;Zhe Liu;Chuanzhe Suo;Peng Yin;Yueling Shen;Haoang Li;Hesheng Wang",
        "authorids": "/37087324321;/37088419070;/38505849700;/37086937363;/37085692390;/37088417698;/37086937885;/37292567100;/37087324321;/37088419070;/38505849700;/37086937363;/37085692390;/37088417698;/37086937885;/37292567100",
        "aff": "Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, T Stone Robotics Institute, Hong Kong; Department of Automation, Shanghai Jiao Tong University, China; Department of Computer Science and Technology, University of Cambridge, United Kingdom; Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, T Stone Robotics Institute, Hong Kong; Carnegie Mellon University; Department of Automation, Shanghai Jiao Tong University, China; Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, T Stone Robotics Institute, Hong Kong; Beijing Advanced Innovation Center for Intelligent Robots and Systems, Beijing Institute of Technology, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341249/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13771956714117756010&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;2;0;3;1;0;4",
        "aff_unique_norm": "The Chinese University of Hong Kong;Shanghai Jiao Tong University;University of Cambridge;Carnegie Mellon University;Beijing Institute of Technology",
        "aff_unique_dep": "Department of Mechanical and Automation Engineering;Department of Automation;Department of Computer Science and Technology;;Advanced Innovation Center for Intelligent Robots and Systems",
        "aff_unique_url": "https://www.cuhk.edu.hk;https://www.sjtu.edu.cn;https://www.cam.ac.uk;https://www.cmu.edu;http://www.bit.edu.cn/",
        "aff_unique_abbr": "CUHK;SJTU;Cambridge;CMU;BIT",
        "aff_campus_unique_index": "0;2;0;0;3",
        "aff_campus_unique": "Hong Kong SAR;;Cambridge;Beijing",
        "aff_country_unique_index": "0;0;1;0;2;0;0;0",
        "aff_country_unique": "China;United Kingdom;United States"
    },
    {
        "id": "9341020",
        "title": "End-to-end Autonomous Driving Perception with Sequential Latent Representation Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Current autonomous driving systems are composed of a perception system and a decision system. Both of them are divided into multiple subsystems built up with lots of human heuristics. An end-to-end approach might clean up the system and avoid huge efforts of human engineering, as well as obtain better performance with increasing data and computation resources. Compared to the decision system, the perception system is more suitable to be designed in an end-to-end framework, since it does not require online driving exploration. In this paper, we propose a novel end-to-end approach for autonomous driving perception. A latent space is introduced to capture all relevant features useful for perception, which is learned through sequential latent representation learning. The learned end-to-end perception model is able to solve the detection, tracking, localization and mapping problems altogether with only minimum human engineering efforts and without storing any maps online. The proposed method is evaluated in a realistic urban driving simulator, with both camera image and lidar point cloud as sensor inputs. The codes and videos of this work are available at our github repo\u2020 and project website\u2021.",
        "primary_area": "",
        "author": "Jianyu Chen;Zhuo Xu;Masayoshi Tomizuka;Jianyu Chen;Zhuo Xu;Masayoshi Tomizuka",
        "authorids": "/37086004703;/37086544987;/37281933000;/37086004703;/37086544987;/37281933000",
        "aff": "Department of Mechanical Engineering, University of California, Berkeley, CA, USA; Department of Mechanical Engineering, University of California, Berkeley, CA, USA; Department of Mechanical Engineering, University of California, Berkeley, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341020/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9694579142441120111&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341392",
        "title": "End-to-end Contextual Perception and Prediction with Interaction Transformer",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we tackle the problem of detecting objects in 3D and forecasting their future motion in the context of self-driving. Towards this goal, we design a novel approach that explicitly takes into account the interactions between actors. To capture their spatial-temporal dependencies, we propose a recurrent neural network with a novel Transformer [1] architecture, which we call the Interaction Transformer. Importantly, our model can be trained end-to-end, and runs in real-time. We validate our approach on two challenging real-world datasets: ATG4D [2] and nuScenes [3]. We show that our approach can outperform the state-of-the-art on both datasets. In particular, we significantly improve the social compliance between the estimated future trajectories, resulting in far fewer collisions between the predicted actors.",
        "primary_area": "",
        "author": "Lingyun Luke Li;Bin Yang;Ming Liang;Wenyuan Zeng;Mengye Ren;Sean Segal;Raquel Urtasun;Lingyun Luke Li;Bin Yang;Ming Liang;Wenyuan Zeng;Mengye Ren;Sean Segal;Raquel Urtasun",
        "authorids": "/37088690286;/37399884400;/37087231216;/37087234351;/37086213738;/37088686947;/37269502900;/37088690286;/37399884400;/37087231216;/37087234351;/37086213738;/37088686947;/37269502900",
        "aff": "Uber Advanced Technologies Group; University of Toronto; Uber Advanced Technologies Group; University of Toronto; University of Toronto; University of Toronto; University of Toronto",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341392/",
        "gs_citation": 148,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16978773415451289009&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;0;1;1;1;1",
        "aff_unique_norm": "Uber;University of Toronto",
        "aff_unique_dep": "Advanced Technologies Group;",
        "aff_unique_url": "https://www.uber.com;https://www.utoronto.ca",
        "aff_unique_abbr": "Uber ATG;U of T",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0;1;1;1;1",
        "aff_country_unique": "United States;Canada"
    },
    {
        "id": "9340692",
        "title": "Endoscopic Navigation Based on Three-dimensional Structure Registration",
        "track": "main",
        "status": "Poster",
        "abstract": "Surgical navigation is challenging on complicated multi-branch structures such as intrarenal collecting systems or bronchi. The objective of this work is to help surgeons quickly establish the corresponding relationship between intraoperative endoscopic images and preoperative CT data. An endoscopic navigation method is proposed based on three-dimensional structure registration. It mainly includes three sections. First, a reconstruction method is presented to obtain three-dimensional information of porous structures from endoscopic images. It combines image enhancement, structure-from-motion and template matching. Second, a hole search strategy based on slicing is given for detecting and extracting three-dimensional porous structures from CT data. Third, a similarity measurement algorithm is developed for registering endoscopic images to CT data. The performance of this work is evaluated on the data from the ureteroscopic holmium laser lithotripsy and the results show its accuracy, robustness and time cost.",
        "primary_area": "",
        "author": "Minghui Han;Yu Dai;Jianxun Zhang;Minghui Han;Yu Dai;Jianxun Zhang",
        "authorids": "/37088688897;/37085562045;/37281461800;/37088688897;/37085562045;/37281461800",
        "aff": "College of Artificial Intelligence, Nankai University, Tianjin, China; College of Artificial Intelligence, Nankai University, Tianjin, China; College of Artificial Intelligence, Nankai University, Tianjin, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340692/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2121407338451674482&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Nankai University",
        "aff_unique_dep": "College of Artificial Intelligence",
        "aff_unique_url": "http://www.nankai.edu.cn",
        "aff_unique_abbr": "Nankai",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Tianjin",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9341455",
        "title": "Energy Autonomy for Resource-Constrained Multi Robot Missions",
        "track": "main",
        "status": "Poster",
        "abstract": "One of the key factors for extended autonomy and resilience of multi-robot systems, especially when robots operate on batteries, is their ability to maintain energy sufficiency by recharging when needed. In situations with limited access to charging facilities, robots need to be able to share and coordinate recharging activities, with guarantees that no robot will run out of energy. In this work, we present an approach based on Control Barrier Functions (CBFs) to enforce both energy sufficiency (assuring that no robot runs out of battery) and coordination constraints (guaranteeing mutual exclusive use of an available charging station), all in a mission agnostic fashion. Moreover, we investigate the system capacity in terms of the relation between feasible requirements of charging cycles and individual robot properties. We show simulation results, using a physics-based simulator and real robot experiments to demonstrate the effectiveness of the proposed approach.",
        "primary_area": "",
        "author": "Hassan Fouad;Giovanni Beltrame;Hassan Fouad;Giovanni Beltrame",
        "authorids": "/37089051363;/37295768000;/37089051363;/37295768000",
        "aff": "Computer and Software Engineering department, Ecole polytechnique de Montreal; Computer and Software Engineering department, Ecole polytechnique de Montreal",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341455/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8836906208572578516&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Ecole polytechnique de Montreal",
        "aff_unique_dep": "Computer and Software Engineering department",
        "aff_unique_url": "https://www.polymtl.ca",
        "aff_unique_abbr": "Polytechnique Montreal",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Montreal",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9340761",
        "title": "Energy-Efficient Motion Planning for Multi-Modal Hybrid Locomotion",
        "track": "main",
        "status": "Poster",
        "abstract": "Hybrid locomotion, which combines multiple modalities of locomotion within a single robot, enables robots to carry out complex tasks in diverse environments. This paper presents a novel method for planning multi-modal locomotion trajectories using approximate dynamic programming. We formulate this problem as a shortest-path search through a state-space graph, where the edge cost is assigned as optimal transport cost along each segment. This cost is approximated from batches of offline trajectory optimizations, which allows the complex effects of vehicle under-actuation and dynamic constraints to be approximately captured in a tractable way. Our method is illustrated on a hybrid double-integrator, an amphibious robot, and a flying-driving drone, showing the practicality of the approach.",
        "primary_area": "",
        "author": "H. J. Terry Suh;Xiaobin Xiong;Andrew Singletary;Aaron D. Ames;Joel W. Burdick;H. J. Terry Suh;Xiaobin Xiong;Andrew Singletary;Aaron D. Ames;Joel W. Burdick",
        "authorids": "/37088687957;/37086275102;/37086449553;/37300877900;/37265975700;/37088687957;/37086275102;/37086449553;/37300877900;/37265975700",
        "aff": "Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA; Deptartment of Mechanical and Civil Engineering, California Institute of Technology, Pasadena, CA, USA; Deptartment of Mechanical and Civil Engineering, California Institute of Technology, Pasadena, CA, USA; Deptartment of Mechanical and Civil Engineering, California Institute of Technology, Pasadena, CA, USA; Deptartment of Mechanical and Civil Engineering, California Institute of Technology, Pasadena, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340761/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11341042896849572150&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;1",
        "aff_unique_norm": "Massachusetts Institute of Technology;California Institute of Technology",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory;Department of Mechanical and Civil Engineering",
        "aff_unique_url": "https://www.mit.edu;https://www.caltech.edu",
        "aff_unique_abbr": "MIT;Caltech",
        "aff_campus_unique_index": "0;1;1;1;1",
        "aff_campus_unique": "Cambridge;Pasadena",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341538",
        "title": "Enhanced Transfer Learning for Autonomous Driving with Systematic Accident Simulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Simulation data can be utilized to extend real-world driving data in order to cover edge cases, such as vehicle accidents. The importance of handling edge cases can be observed in the high societal costs in handling car accidents, as well as potential dangers to human drivers. In order to cover a wide and diverse range of all edge cases, we systemically parameterize and simulate the most common accident scenarios. By applying this data to autonomous driving models, we show that transfer learning on simulated data sets provide better generalization and collision avoidance, as compared to random initialization methods. Our results illustrate that information from a model trained on simulated data can be inferred to a model trained on real-world data, indicating the potential influence of simulation data in real world models and advancements in handling of anomalous driving scenarios.",
        "primary_area": "",
        "author": "Shivam Akhauri;Laura Y. Zheng;Ming C. Lin;Shivam Akhauri;Laura Y. Zheng;Ming C. Lin",
        "authorids": "/37088688854;/37088690660;/37278387400;/37088688854;/37088690660;/37278387400",
        "aff": "University of Maryland at College Park; University of Maryland at College Park; University of Maryland at College Park",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341538/",
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2783442466736593199&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Maryland",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www/umd.edu",
        "aff_unique_abbr": "UMD",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "College Park",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341642",
        "title": "Enhanced tracking wall: A real-time computing method for needle injection on haptic simulators",
        "track": "main",
        "status": "Poster",
        "abstract": "Haptic simulators can help medical students to train and improve their skills before practicing with a real patient. However, the vast majority of needle insertion haptic simulators are based on sophisticated models that are accurate but highly demanding in computing resources. Most of them do not provide haptic feedback and/or are not suitable for haptic control due to their computing time. In this paper, we presented a new low computing consuming method that aims to provide a realistic needle insertion experience to the student. A description of the proposed solution is provided, and it is illustrated by experimental results to highlight its performance.",
        "primary_area": "",
        "author": "Ma. Alamilla-Daniel;Richard Moreau;Redarce Tanneguy;Ma. Alamilla-Daniel;Richard Moreau;Redarce Tanneguy",
        "authorids": "/37088688497;/37589578400;/37088478446;/37088688497;/37589578400;/37088478446",
        "aff": "CNRS Amp\u00e8re, University of Lyon, INSA Lyon, Villeurbanne, France; CNRS Amp\u00e8re, University of Lyon, INSA Lyon, Villeurbanne, France; CNRS Amp\u00e8re, University of Lyon, INSA Lyon, Villeurbanne, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341642/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13128530901701921791&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "CNRS Amp\u00e8re",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9340689",
        "title": "Environment-Aware Grasp Strategy Planning in Clutter for a Variable Stiffness Hand",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper deals with the problem of planning grasp strategies on constrained and cluttered scenarios. The planner sequences the objects for grasping by considering multiple factors: (i) possible environmental constraints that can be exploited to grasp an object, (ii) object neighborhood, (iii) capability of the arm, and (iv) confidence score of the vision algorithm. To successfully exploit the environmental constraints, this work uses the CLASH hand, a compliant hand that can vary its passive stiffness. The hand can be softened such that it can comply with the object shape, or it can be stiffened to pierce between the objects in clutter. A stiffness decision tree is introduced to choose the best stiffness setting for each particular scenario. In highly cluttered scenarios, a finger position planner is used to find a suitable orientation for the hand such that the fingers can slide in the free regions around the object. Thus, the grasp strategy planner predicts not only the sequence in which the objects can be grasped, but also the required stiffness of the end effector, and the appropriate positions for the fingers around the object. Different experiments are carried out in the context of grocery handling to test the performance of the planner in scenarios that require different grasping strategies.",
        "primary_area": "",
        "author": "Ashok M. Sundaram;Werner Friedl;M\u00e1ximo A. Roa;Ashok M. Sundaram;Werner Friedl;M\u00e1ximo A. Roa",
        "authorids": "/37086134571;/37295467000;/37628512100;/37086134571;/37295467000;/37628512100",
        "aff": "Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Wessling, Germany; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Wessling, Germany; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Wessling, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340689/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14329069503618709934&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "German Aerospace Center (DLR)",
        "aff_unique_dep": "Institute of Robotics and Mechatronics",
        "aff_unique_url": "https://www.dlr.de",
        "aff_unique_abbr": "DLR",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Wessling",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9341112",
        "title": "Estimating An Object\u2019s Inertial Parameters By Robotic Pushing: A Data-Driven Approach",
        "track": "main",
        "status": "Poster",
        "abstract": "Estimating the inertial properties of an object can make robotic manipulations more efficient, especially in extreme environments. This paper presents a novel method of estimating the 2D inertial parameters of an object, by having a robot applying a push on it. We draw inspiration from previous analyses on quasi-static pushing mechanics, and introduce a data-driven model that can accurately represent these mechanics and provide a prediction for the object's inertial parameters. We evaluate the model with two datasets. For the first dataset, we set up a V-REP simulation of seven robots pushing objects with large range of inertial parameters, acquiring 48000 pushes in total. For the second dataset, we use the object pushes from the MIT M-Cube lab pushing dataset. We extract features from force, moment and velocity measurements of the pushes, and train a Multi-Output Regression Random Forest. The experimental results show that we can accurately predict the 2D inertial parameters from a single push, and that our method retains this robust performance under various surface types.",
        "primary_area": "",
        "author": "Nikos Mavrakis;Amir M. Ghalamzan E.;Rustam Stolkin;Nikos Mavrakis;Amir M. Ghalamzan E.;Rustam Stolkin",
        "authorids": "/37086057013;/37086051585;/37424300500;/37086057013;/37086051585;/37424300500",
        "aff": "STAR Lab, Surrey Space Centre, University of Surrey, UK; Intelligent Manipulation Lab, University of Lincoln, UK; Extreme Robotics Lab, University of Birmingham, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341112/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1541846044068441044&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "University of Surrey;University of Lincoln;University of Birmingham",
        "aff_unique_dep": "Surrey Space Centre;Intelligent Manipulation Lab;Extreme Robotics Lab",
        "aff_unique_url": "https://www.surrey.ac.uk;https://www.lincoln.ac.uk;https://www.birmingham.ac.uk",
        "aff_unique_abbr": "UniS;;",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Guildford;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9341065",
        "title": "Estimating Motion Codes from Demonstration Videos",
        "track": "main",
        "status": "Poster",
        "abstract": "A motion taxonomy can encode manipulations as a binary-encoded representation, which we refer to as motion codes. These motion codes innately represent a manipulation action in an embedded space that describes the motion\u2019s mechanical features, including contact and trajectory type. The key advantage of using motion codes for embedding is that motions can be more appropriately defined with robotic-relevant features, and their distances can be more reasonably measured using these motion features. In this paper, we develop a deep learning pipeline to extract motion codes from demonstration videos in an unsupervised manner so that knowledge from these videos can be properly represented and used for robots. Our evaluations show that motion codes can be extracted from demonstrations of action in the EPIC-KITCHENS dataset.",
        "primary_area": "",
        "author": "Maxat Alibayev;David Paulius;Yu Sun;Maxat Alibayev;David Paulius;Yu Sun",
        "authorids": "/37088690090;/37086208693;/37291603500;/37088690090;/37086208693;/37291603500",
        "aff": "Department of Computer Science & Engineering, University of South Florida, Tampa, FL, USA; Department of Computer Science & Engineering, University of South Florida, Tampa, FL, USA; Department of Computer Science & Engineering, University of South Florida, Tampa, FL, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341065/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17730869225738489308&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of South Florida",
        "aff_unique_dep": "Department of Computer Science & Engineering",
        "aff_unique_url": "https://www.usf.edu",
        "aff_unique_abbr": "USF",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Tampa",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341745",
        "title": "Estimating Pedestrian Crossing States Based on Single 2D Body Pose",
        "track": "main",
        "status": "Poster",
        "abstract": "The Crossing or Not-Crossing (C/NC) problem is important to autonomous vehicles (AVs) for safe vehicle/pedestrian interactions. However, this problem setup often ignores pedestrians walking along the direction of the vehicles' movement (LONG). To enhance the AVs' awareness of pedestrian behavior, we make the first step towards extending the C/NC to the C/NC/LONG problem and recognize them based on single body pose. In contrast, previous C/NC state classifiers depend on multiple poses or contextual information. Our proposed shallow neural network classifier aims to recognize these three states swiftly. We tested it on the JAAD dataset and reported an average 81.23% accuracy.",
        "primary_area": "",
        "author": "Zixing Wang;Nikolaos Papanikolopoulos;Zixing Wang;Nikolaos Papanikolopoulos",
        "authorids": "/37088689387;/37278578300;/37088689387;/37278578300",
        "aff": "Department of Computer Science and Engineering, University of Minnesota, Minneapolis, MN, USA; Faculty of the Department of Computer Science and Engineering, University of Minnesota, Minneapolis, MN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341745/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7665113217052528398&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Minnesota",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.umn.edu",
        "aff_unique_abbr": "UMN",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Minneapolis",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340771",
        "title": "Estimation of object class and orientation from multiple viewpoints and relative camera orientation constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "In this research, we propose a method of estimating object class and orientation given multiple input images assuming the relative camera orientations are known. Input images are transformed to descriptors on 2-D manifolds defined for each class of object through a CNN, and the object class and orientation that minimize the distance between input descriptors and the descriptors associated with the estimated object class and orientation are selected. The object orientation is further optimized by interpolating the viewpoints in the database.The usefulness of the proposed method is demonstrated by comparative evaluation with other methods using publicly available datasets. The usefulness of the proposed method is also demonstrated by recognizing images taken from the cameras on our humanoid robot using our own dataset.",
        "primary_area": "",
        "author": "Koichi Ogawara;Keita Iseki;Koichi Ogawara;Keita Iseki",
        "authorids": "/37339602900;/37088690748;/37339602900;/37088690748",
        "aff": "Faculty of Systems Engineering, Wakayama University, Wakayama-shi, Wakayama, Japan; Graduate School of Systems Engineering, Wakayama University, Wakayama-shi, Wakayama, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340771/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16765518454124439432&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Wakayama University",
        "aff_unique_dep": "Faculty of Systems Engineering",
        "aff_unique_url": "https://www.wakayama-u.ac.jp",
        "aff_unique_abbr": "Wakayama U",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Wakayama",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9341263",
        "title": "Evaluating the Efficacy of Parallel Elastic Actuators on High-Speed, Variable Stiffness Running",
        "track": "main",
        "status": "Poster",
        "abstract": "Although they take many forms, legged robots rely upon springs to achieve high speed, dynamic locomotion. In this paper we examine the effect of adding parallel springs to robots that rely on virtual compliance. Specifically, we consider the trade-off between energetic efficiency and leg versatility that comes while using Parallel Elastic Actuators (PEAs). To do this, we vary the ratio of physical to virtual compliance for legged systems using a) a modified SLIP model, b) a single legged hopping robot, and c) a multibody simulation of the quadruped robot LLAMA. In each case we show that having a small physical compliance significantly improves the efficiency while also maintaining the robot's versatility.",
        "primary_area": "",
        "author": "John V. Nicholson;Sean Gart;Jason Pusey;Jonathan E. Clark;John V. Nicholson;Sean Gart;Jason Pusey;Jonathan E. Clark",
        "authorids": "/37086353968;/37088691457;/37085864714;/37533408500;/37086353968;/37088691457;/37085864714;/37533408500",
        "aff": "Mechanical Engineering, Florida A&M University-Florida State University; Army Research Laboratory; Army Research Laboratory; Mechanical Engineering, Florida A&M University-Florida State University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341263/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13148219429197516915&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "Florida A&M University-Florida State University;Army Research Laboratory",
        "aff_unique_dep": "Mechanical Engineering;",
        "aff_unique_url": "https://www.famu.fsu.edu;https://www.arl.army.mil",
        "aff_unique_abbr": "FAMU-FSU;ARL",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340861",
        "title": "Event-based PID controller fully realized in neuromorphic hardware: a one DoF study",
        "track": "main",
        "status": "Poster",
        "abstract": "Spiking Neuronal Networks (SNNs) realized in neuromorphic hardware lead to low-power and low-latency neuronal computing architectures. Neuromorphic computing systems are most efficient when all of perception, decision making, and motor control are seamlessly integrated into a single neuronal architecture that can be realized on the neuromorphic hardware. Many neuronal network architectures address the perception tasks, while work on neuronal motor controllers is scarce. Here, we present an improved implementation of a neuromorphic PID controller. The controller was realized on Intel's neuromorphic research chip Loihi and its performance tested on a drone, constrained to rotate on a single axis. The SNN controller is built using neuronal populations, in which a single spike carries information about sensed and control signals. Neuronal arrays perform computation on such sparse representations to calculate the proportional, derivative, and integral terms. The SNN PID controller is compared to a PID controller, implemented in software, and achieves a comparable performance, paving the way to a fully neuromorphic system in which perception, planning, and control are realized in an on-chip SNN.",
        "primary_area": "",
        "author": "Rasmus Karn\u00f8e Stagsted;Antonio Vitale;Alpha Renner;Leon Bonde Larsen;Anders Lyhne Christensen;Yulia Sandamirskaya;Rasmus Karn\u00f8e Stagsted;Antonio Vitale;Alpha Renner;Leon Bonde Larsen;Anders Lyhne Christensen;Yulia Sandamirskaya",
        "authorids": "/37088686186;/37528489200;/37086575464;/37087889952;/37580650400;/38498075300;/37088686186;/37528489200;/37086575464;/37087889952;/37580650400;/38498075300",
        "aff": "SDU; Department of Mechanical Engineering, ETH, Zurich, Switzerland; Institute of Neuroinformatics, University of Zurich and ETH, Zurich, Switzerland; SDU; SDU; Neuromorphic Computing Lab, Intel Labs, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340861/",
        "gs_citation": 38,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11841196923009303710&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;0;0;3",
        "aff_unique_norm": "Shandong University;ETH Zurich;University of Zurich;Intel Labs",
        "aff_unique_dep": ";Department of Mechanical Engineering;Institute of Neuroinformatics;Neuromorphic Computing Lab",
        "aff_unique_url": "http://www.sdu.edu.cn;https://www.ethz.ch;https://www.neuro.ethz.ch/;https://www.intel.de",
        "aff_unique_abbr": "SDU;ETH;UZH;Intel",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Zurich",
        "aff_country_unique_index": "0;1;1;0;0;2",
        "aff_country_unique": "China;Switzerland;Germany"
    },
    {
        "id": "9341614",
        "title": "Examination of Screen-Indicated Methods of Gait Training System with Real-time Audiovisual Feedback Function of Ground Reaction Force",
        "track": "main",
        "status": "Poster",
        "abstract": "In gait training for walking rehabilitation of patients with stroke hemiplegia or bone joint conditions such as fractures, it is important to recognize the load of the affected lower limbs for improving gait ability and avoiding risks such as re-fractures. A weight scale is used at the actual rehabilitation site to recognize the load. However, in this situation, the trainee must look down to verify whether the scale and their walking posture are correct. In addition, the trainee generally cannot read the load value accurately. Therefore, we have developed a system that can show the load in real time on an eye-level display. By using this system, we expect the patients to be able to perform gait training smoothly while recognizing the state of walking. In this paper, we have reported the results of a clinical trial held at a rehabilitation hospital and an examination of the screen-indicated methods.",
        "primary_area": "",
        "author": "Kei Fukuyama;Ichiro Kurose;Hidetaka Ikeuchi;Kei Fukuyama;Ichiro Kurose;Hidetaka Ikeuchi",
        "authorids": "/37086185835;/37088688616;/37564324600;/37086185835;/37088688616;/37564324600",
        "aff": "Graduate School of Oita University, Oita, JAPAN; Physical Therapist of Beppu Rehabilitation Center, Oita, JAPAN; Faculty of Engineering, Oita University, Oita, JAPAN",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341614/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9605330904492401142&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Oita University;Beppu Rehabilitation Center",
        "aff_unique_dep": "Graduate School;Physical Therapy",
        "aff_unique_url": "https://www.rgu.ac.jp/english/index.html;",
        "aff_unique_abbr": "OU;",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Oita;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9341510",
        "title": "Exceeding the Maximum Speed Limit of the Joint Angle for the Redundant Tendon-driven Structures of Musculoskeletal Humanoids",
        "track": "main",
        "status": "Poster",
        "abstract": "The musculoskeletal humanoid has various biomimetic benefits, and the redundant muscle arrangement is one of its most important characteristics. This redundancy can achieve fail-safe redundant actuation and variable stiffness control. However, there is a problem that the maximum joint angle velocity is limited by the slowest muscle among the redundant muscles. In this study, we propose two methods that can exceed the limited maximum joint angle velocity, and verify the effectiveness with actual robot experiments.",
        "primary_area": "",
        "author": "Kento Kawaharazuka;Yuya Koga;Kei Tsuzuki;Moritaka Onitsuka;Yuki Asano;Kei Okada;Koji Kawasaki;Masayuki Inaba;Kento Kawaharazuka;Yuya Koga;Kei Tsuzuki;Moritaka Onitsuka;Yuki Asano;Kei Okada;Koji Kawasaki;Masayuki Inaba",
        "authorids": "/37086101930;/37088339856;/37086598284;/37086573419;/38238750500;/37280639000;/37085684621;/37286658200;/37086101930;/37088339856;/37086598284;/37086573419;/38238750500;/37280639000;/37085684621;/37286658200",
        "aff": "Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; TOYOTA MOTOR CORPORATION; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341510/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9885192396102856456&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;0;1;0",
        "aff_unique_norm": "The University of Tokyo;Toyota Motor Corporation",
        "aff_unique_dep": "Department of Mechano-Informatics;",
        "aff_unique_url": "https://www.u-tokyo.ac.jp;https://www.toyota-global.com",
        "aff_unique_abbr": "UTokyo;Toyota",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Tokyo;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9341395",
        "title": "Expedited Multi-Target Search with Guaranteed Performance via Multi-fidelity Gaussian Processes",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider a scenario in which an autonomous vehicle equipped with a downward facing camera operates in a 3D environment and is tasked with searching for an unknown number of stationary targets on the 2D floor of the environment. The key challenge is to minimize the search time while ensuring a high detection accuracy. We model the sensing field using a multi-fidelity Gaussian process that systematically describes the sensing information available at different altitudes from the floor. Based on the sensing model, we design a novel algorithm called Expedited Multi-Target Search (EMTS) that (i) addresses the coverage-accuracy trade-off: sampling at locations farther from the floor provides wider field of view but less accurate measurements, (ii) computes an occupancy map of the floor within a prescribed accuracy and quickly eliminates unoccupied regions from the search space, and (iii) travels efficiently to collect the required samples for target detection. We rigorously analyze the algorithm and establish formal guarantees on the target detection accuracy and the detection time. We illustrate the algorithm using a simulated multi-target search scenario.",
        "primary_area": "",
        "author": "Lai Wei;Xiaobo Tan;Vaibhav Srivastava;Lai Wei;Xiaobo Tan;Vaibhav Srivastava",
        "authorids": "/37086432252;/37420481400;/37085506787;/37086432252;/37420481400;/37085506787",
        "aff": "Department of Electrical and Computer Engineering, Michigan State University, East Lansing, MI, USA; Department of Electrical and Computer Engineering, Michigan State University, East Lansing, MI, USA; Department of Electrical and Computer Engineering, Michigan State University, East Lansing, MI, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341395/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15033601619599122545&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Michigan State University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.msu.edu",
        "aff_unique_abbr": "MSU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "East Lansing",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340867",
        "title": "Experience-Based Prediction of Unknown Environments for Enhanced Belief Space Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous navigation missions require online decision making abilities, in order to choose from a given set of candidate actions an action that will lead to the best outcome. In a partially observable setting, decision making under uncertainty, also known as belief space planning (BSP), involves reasoning about belief evolution considering realizations of future observations. Yet, when candidate actions lead the robot to an unknown environment the decision making mission becomes a very challenging problem since without a map it is hard to foresee future observations. In this paper we develop a data-driven approach for predicting a distribution over an unexplored map, generating future observations, and combining these observations within BSP. We examine our approach and compare it to existing BSP methods in a Gazebo simulation, and demonstrate it often yields improved performance.",
        "primary_area": "",
        "author": "Omri Asraf;Vadim Indelman;Omri Asraf;Vadim Indelman",
        "authorids": "/37088403119;/37541538000;/37088403119;/37541538000",
        "aff": "",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340867/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6079223497939793497&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4
    },
    {
        "id": "9340911",
        "title": "Experimental Evaluation of 3D-LIDAR Camera Extrinsic Calibration",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper we perform an extensive experimental evaluation of three planar target based 3D-LIDAR camera calibration algorithms, on a sensor suite consisting multiple 3D-LIDARs and cameras, assessing their robustness to random initialization and by using metrics like Mean Line Re-projection Error (MLRE) and Factory Stereo Calibration Error. We briefly describe each method and provide insights into practical aspects like ease of data collection. We also show the effect of noisy sensor on the calibration result and conclude with a note on which calibration algorithm should be used under what circumstances.",
        "primary_area": "",
        "author": "Subodh Mishra;Philip R. Osteen;Gaurav Pandey;Srikanth Saripalli;Subodh Mishra;Philip R. Osteen;Gaurav Pandey;Srikanth Saripalli",
        "authorids": "/37088635827;/38251856000;/37084693200;/37278939200;/37088635827;/38251856000;/37084693200;/37278939200",
        "aff": "Department of Mechanical Engineering, Texas A&M University; Army Reasearch Lab, USA; Ford Motor Company, USA; Department of Mechanical Engineering, Texas A&M University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340911/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8775815824329331683&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "Texas A&M University;Army Research Lab;Ford Motor Company",
        "aff_unique_dep": "Department of Mechanical Engineering;;",
        "aff_unique_url": "https://www.tamu.edu;;https://www.ford.com",
        "aff_unique_abbr": "TAMU;;Ford",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341553",
        "title": "Experimental Verification of Vibratory Conveyor System Based on Frequency Entrainment of Limit Cycle Walker",
        "track": "main",
        "status": "Poster",
        "abstract": "The authors have investigated underactuated locomotion robots with an inner wobbling mass, it is discovered that the wobbling mass controls the gait speed by entrainment. Supplying the wobbling from outside, outer wobbling entrains load objects and controls the transferring speed. In this paper, we propose a vibratory conveyor system based on the frequency entrainment of a limit cycle walker. The conveyance plate is vibrated by an active rimless wheel, and the system conveys a passive rimless wheel which is defined as a load object. The vibration entrains transferring of the passive rimless and controls the conveyance speed. First, we introduce the prototype experimental system and its mathematical model. Second, we report basic behavior of the passive rimless with regards to the outer vibration and results of frequency analysis through the numerical simulation. Third, we experimentally verify the results of the numerical simulation. The active rimless wheel entrains the walking frequency of the passive rimless wheel in both the simulations and the experiments.",
        "primary_area": "",
        "author": "Kento Mitsuhashi;Masatsugu Nishihara;Fumihiko Asano;Kento Mitsuhashi;Masatsugu Nishihara;Fumihiko Asano",
        "authorids": "/37088687118;/37086151296;/37278753600;/37088687118;/37086151296;/37278753600",
        "aff": "School of Information Science, Japan Advanced Institute of Science and Technology, Nomi, Ishikawa, Japan; School of Information Science, Japan Advanced Institute of Science and Technology, Nomi, Ishikawa, Japan; School of Information Science, Japan Advanced Institute of Science and Technology, Nomi, Ishikawa, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341553/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8627861367738026527&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Japan Advanced Institute of Science and Technology",
        "aff_unique_dep": "School of Information Science",
        "aff_unique_url": "https://www.jaist.ac.jp",
        "aff_unique_abbr": "JAIST",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Nomi",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9341408",
        "title": "Experimental flights of adaptive patterns for cloud exploration with UAVs",
        "track": "main",
        "status": "Poster",
        "abstract": "This work presents the deployment of UAVs for the exploration of clouds, from the system architecture and simulation tests to a real-flight campaign and trajectory analyzes. Thanks to their small size and low altitude, light UAVs have proven to be adapted for in-situ cloud data collection. The short life time of the clouds and limited endurance of the planes require to focus on the area of maximum interest to gather relevant data. Based on previous work on cloud adaptive sampling, the article focuses on the overall system architecture, the improvements made to the system based on preliminary tests and simulations, and finally the results of a field campaign. The Barbados experimental flight campaign confirmed the capacity of the system to map clouds and to collect relevant data in dynamic environment, and highlighted areas for improvement.",
        "primary_area": "",
        "author": "Titouan Verdu;Nicolas Maury;Pierre Narvor;Florian Seguin;Gregory Roberts;Fleur Couvreux;Gr\u00e9goire Cayez;Murat Bronz;Gautier Hattenberger;Simon Lacroix;Titouan Verdu;Nicolas Maury;Pierre Narvor;Florian Seguin;Gregory Roberts;Fleur Couvreux;Gr\u00e9goire Cayez;Murat Bronz;Gautier Hattenberger;Simon Lacroix",
        "authorids": "/37086945569;/37088141110;/37086092970;/37088686624;/37088688966;/37088688257;/37088691370;/37937624200;/37550179100;/37278650100;/37086945569;/37088141110;/37086092970;/37088686624;/37088688966;/37088688257;/37088691370;/37937624200;/37550179100;/37278650100",
        "aff": "LAAS-CNRS, Universit\u00e9 de Toulouse, CNRS, Toulouse, France; METEO-FRANCE Toulouse, France; LAAS-CNRS, Universit\u00e9 de Toulouse, CNRS, Toulouse, France; LAAS-CNRS, Universit\u00e9 de Toulouse, CNRS, Toulouse, France; METEO-FRANCE Toulouse, France; METEO-FRANCE Toulouse, France; METEO-FRANCE Toulouse, France; ENAC, Universit\u00e9 de Toulouse, Toulouse, France; ENAC, Universit\u00e9 de Toulouse, Toulouse, France; LAAS-CNRS, Universit\u00e9 de Toulouse, CNRS, Toulouse, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341408/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15520400227174826308&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 20,
        "aff_unique_index": "0;1;0;0;1;1;1;2;2;0",
        "aff_unique_norm": "LAAS-CNRS;M\u00e9t\u00e9o-France;Universit\u00e9 de Toulouse",
        "aff_unique_dep": ";;ENAC",
        "aff_unique_url": "https://www.laas.fr/;https://www.meteofrance.fr;https://www.enac.fr",
        "aff_unique_abbr": "LAAS-CNRS;M\u00e9t\u00e9o-France;ENAC",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Toulouse",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9341638",
        "title": "Experiments on whole-body control of a dual-arm mobile robot with the Set-Based Task-Priority Inverse Kinematics algorithm",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper an experimental study of set-based task-priority kinematic control for a dual-arm mobile robot is developed. The control strategy for the coordination of the two manipulators and the mobile base relies on the definition of a set of elementary tasks to be properly handled depending on their functional role. In particular, the tasks have been grouped into three categories: safety, operational and optimization tasks. The effectiveness of the resulting task hierarchy has been validated through experiments on a Kinova Movo robot, in a domestic use case scenario.",
        "primary_area": "",
        "author": "Paolo Di Lillo;Francesco Pierri;Fabrizio Caccavale;Gianluca Antonelli;Paolo Di Lillo;Francesco Pierri;Fabrizio Caccavale;Gianluca Antonelli",
        "authorids": "/37086181378;/37419558900;/37283127200;/37281306400;/37086181378;/37419558900;/37283127200;/37281306400",
        "aff": "Department of Electrical and Information Engineering, University of Cassino and Southern Lazio, Cassino (FR), Italy; School of Engineering, University of Basilicata, Potenza (PZ), Italy; School of Engineering, University of Basilicata, Potenza (PZ), Italy; Department of Electrical and Information Engineering, University of Cassino and Southern Lazio, Cassino (FR), Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341638/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15849549053445031294&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "University of Cassino and Southern Lazio;University of Basilicata",
        "aff_unique_dep": "Department of Electrical and Information Engineering;School of Engineering",
        "aff_unique_url": "https://www.unicas.it;https://www.unibas.it",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Cassino;Potenza",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9341036",
        "title": "Expert-Emulating Excavation Trajectory Planning for Autonomous Robotic Industrial Excavator",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a novel excavation (i.e., digging) trajectory planning framework for industrial autonomous robotic excavators, which emulates the strategies of human expert operators to optimize the excavation of (complex/unmodellable) soils while also upholding robustness and safety in practice. First, we encode the trajectory with dynamic movement primitives (DMP), which is known to robustly preserve qualitative shape of the trajectory and attraction to (variable) end-points (i.e., start-points of swing/dumping), while also being data-efficient due to its structure, thus, suitable for our purpose, where expert data collection is expensive. We further shape this DMPbased trajectory to be expert-emulating, by learning the shaping force of the DMP-dynamics from the real expert excavation data via a neural network (i.e., MLP (multi-layer perceptron)). To cope with (possibly dangerous) underground uncertainties (e.g., pipes, rocks), we also real-time modulate the expert-emulating (nominal) trajectory to prevent excessive build-up of excavation force by using the feedback of its online estimation. The proposed framework is then validated/demonstrated by using an industrial-scale autonomous robotic excavator, with the associated data also presented here.",
        "primary_area": "",
        "author": "Bukun Son;ChangU Kim;Changmuk Kim;Dongjun Lee;Bukun Son;ChangU Kim;Changmuk Kim;Dongjun Lee",
        "authorids": "/37088689870;/37085744783;/37088687905;/37077171500;/37088689870;/37085744783;/37088687905;/37077171500",
        "aff": "Department of Mechanical & Aerospace Engineering and IAMD, Seoul National University, Seoul, South Korea; Department of Mechanical & Aerospace Engineering and IAMD, Seoul National University, Seoul, South Korea; Doosan Infracoore, Seoul, South Koera; Department of Mechanical & Aerospace Engineering and IAMD, Seoul National University, Seoul, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341036/",
        "gs_citation": 38,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8213478174161375355&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Seoul National University;Doosan Infracore",
        "aff_unique_dep": "Department of Mechanical & Aerospace Engineering;",
        "aff_unique_url": "https://www.snu.ac.kr;https://www.doosaninfracore.com",
        "aff_unique_abbr": "SNU;Doosan Infracore",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9340846",
        "title": "Explainable and Efficient Sequential Correlation Network for 3D Single Person Concurrent Activity Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "We present the sequential correlation network (SCN) to improve concurrent activity detection. SCN combines a recurrent neural network and a correlation model hierarchically to model the complex correlations and temporal dynamics of concurrent activities. SCN has several advantages that enable effective learning even from a small dataset for real-world deployment. Unlike the majority of approaches assuming that each subject performs one activity at a time, SCN is end-to- end trainable, i.e., it can automatically learn the inclusive or exclusive relations of concurrent activities. SCN is lightweight in design using only a small set of learnable parameters to model the spatio-temporal correlations of activities. This also enhances the explainability of the learned parameters. Furthermore, the learning of SCN can benefit from the initialization using semantically meaningful priors. We evaluate the proposed method against the state-of-the-art method on two benchmark datasets with human skeletal data, SCN achieves comparable performance to the SOTA but with much faster inference speed and less memory usage.",
        "primary_area": "",
        "author": "Yi Wei;Wenbo Li;Ming-Ching Chang;Hongxia Jin;Siwei Lyu;Yi Wei;Wenbo Li;Ming-Ching Chang;Hongxia Jin;Siwei Lyu",
        "authorids": "/37086214376;/37537031800;/37855934600;/37085779121;/37430715900;/37086214376;/37537031800;/37855934600;/37085779121;/37430715900",
        "aff": "University at Albany, State University of New York, USA; Samsung Research America AI Center, USA; University at Albany, State University of New York, USA; Samsung Research America AI Center, USA; University at Albany, State University of New York, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340846/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9031945516504902699&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;1;0",
        "aff_unique_norm": "State University of New York at Albany;Samsung Research America",
        "aff_unique_dep": ";AI Center",
        "aff_unique_url": "https://www.albany.edu;https://www.samsung.com/us/research/",
        "aff_unique_abbr": "SUNY Albany;SRA",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Albany;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340845",
        "title": "Exploiting Semantic and Public Prior Information in MonoSLAM",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a method to use semantic information to improve the use of map priors in a sparse, feature-based MonoSLAM system. To incorporate the priors, the features in the prior and SLAM maps must be associated with one another. Most existing systems build a map using SLAM and then align it with the prior map. However, this approach assumes that the local map is accurate, and the majority of the features within it can be constrained by the prior. We use the intuition that many prior maps are created to provide semantic information. Therefore, valid associations only exist if the features in the SLAM map arise from the same kind of semantic object as the prior map. Using this intuition, we extend ORB-SLAM2 using an open source pre-trained semantic segmentation network (DeepLabV3+) to incorporate prior information from Open Street Map building footprint data. We show that the amount of drift, before loop closing, is significantly smaller than that for original ORB-SLAM2. Furthermore, we show that when ORB-SLAM2 is used as a prior-aided visual odometry system, the tracking accuracy is equal to or better than the full ORB-SLAM2 system without the need for global mapping or loop closure.",
        "primary_area": "",
        "author": "Chenxi Ye;Yiduo Wang;Ziwen Lu;Igor Gilitschenski;Martin Parsley;Simon J. Julier;Chenxi Ye;Yiduo Wang;Ziwen Lu;Igor Gilitschenski;Martin Parsley;Simon J. Julier",
        "authorids": "/37088691376;/37088689824;/37088687455;/38469566100;/37594413600;/37264968900;/37088691376;/37088689824;/37088687455;/38469566100;/37594413600;/37264968900",
        "aff": "Carried out while at the Department of Computer Science, University College London; Oxford Robotics Institute, University of Oxford; Department of Computer Science, University College London; Computer Science and Artificial Intelligence Lab, MIT; Mo-Sys Engineering Ltd.; Department of Computer Science, University College London",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340845/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15760359570786533249&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;2;3;0",
        "aff_unique_norm": "University College London;University of Oxford;Massachusetts Institute of Technology;Mo-Sys Engineering",
        "aff_unique_dep": "Department of Computer Science;Oxford Robotics Institute;Computer Science and Artificial Intelligence Lab;",
        "aff_unique_url": "https://www.ucl.ac.uk;https://www.ox.ac.uk;https://www.csail.mit.edu;https://www.mo-sys.com",
        "aff_unique_abbr": "UCL;Oxford;MIT;",
        "aff_campus_unique_index": "0;1;0;2;0",
        "aff_campus_unique": "London;Oxford;Cambridge;",
        "aff_country_unique_index": "0;0;0;1;0;0",
        "aff_country_unique": "United Kingdom;United States"
    },
    {
        "id": "9341692",
        "title": "Exploiting the Morphology of a Shape Memory Spring as the Active Backbone of a Highly Dexterous Tendril Robot (ATBR)",
        "track": "main",
        "status": "Poster",
        "abstract": "Tendrils are common stable structures in nature and are used for sensing, actuation, and geometrical stiffness modulation. In this paper, for the first time we exploit the helical geometry of a shape memory alloy (SMA) tendril as a simple to fabricate highly dexterous robotic continuum tentacle that we called Active Tendril-Backbone Robot (ATBR). This is achieved via partial (120 deg) activation of single helix turns resulting in backbone directional bendings. A 141.5 mm prototype (130 mm when fully compressed) has been fabricated and a simple theoretical framework is proposed and experimentally validated for modeling of the tentacle configuration. The manipulator has five 2-DOF joints capable of reaching bending angles of up to 54.5 deg and angular speed of up to 6.8 deg/s. The dexterity of the manipulator is showcased empirically in reaching complex configurations and simple navigation through confined space of a curving path.",
        "primary_area": "",
        "author": "Kayode Sonaike;S. M. Hadi Sadati;Christos Bergeles;Ian D. Walker;Kayode Sonaike;S. M. Hadi Sadati;Christos Bergeles;Ian D. Walker",
        "authorids": "/37088686005;/37085802200;/37399073100;/37276152000;/37088686005;/37085802200;/37399073100;/37276152000",
        "aff": "University of Bristol, Bristol, UK; Robotics and Vision in Medicine (RViM) Lab, School of Biomedical Engineering & Imaging Sciences, King\u2019s College London, London, UK; Robotics and Vision in Medicine (RViM) Lab, School of Biomedical Engineering & Imaging Sciences, King\u2019s College London, London, UK; Department of Electrical and Computer Engineering, Clemson University, Clemson, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341692/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6796461082489691951&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;2",
        "aff_unique_norm": "University of Bristol;King\u2019s College London;Clemson University",
        "aff_unique_dep": ";School of Biomedical Engineering & Imaging Sciences;Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.bristol.ac.uk;https://www.kcl.ac.uk;https://www.clemson.edu",
        "aff_unique_abbr": "UoB;KCL;Clemson",
        "aff_campus_unique_index": "0;1;1;2",
        "aff_campus_unique": "Bristol;London;Clemson",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "United Kingdom;United States"
    },
    {
        "id": "9341014",
        "title": "Exploration Strategy based on Validity of Actions in Deep Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "How to explore environments is one of the most critical factors for the performance of an agent in reinforcement learning. Conventional exploration strategies such as \u03b5-greedy algorithm and Gaussian exploration noise simply depend on pure randomness. However, it is required for an agent to consider its training progress and long-term usefulness of actions to efficiently explore complex environments, which remains a major challenge in reinforcement learning. To address this challenge, we propose a novel exploration method that selects actions based on their validity. The key idea behind our method is to estimate the validity of actions by leveraging zero avoiding property of kullback-leibler divergence to comprehensively evaluate actions in terms of both exploration and exploitation. We also introduce a framework that allows an agent to explore efficiently in environments where reward is sparse or cannot be defined intuitively. The framework uses expert demonstrations to guide an agent to visit task-relevant state space by combining our exploration strategy with imitation learning. We demonstrate our exploration strategy on several tasks ranging from classical control tasks to high-dimensional urban autonomous driving scenarios at roundabout. The results show that our exploration strategy encourages an agent to visit task-relevant state space to enhance validity of actions, outperforming several previous methods.",
        "primary_area": "",
        "author": "Hyung-Suk Yoon;Sang-Hyun Lee;Seung-Woo Seo;Hyung-Suk Yoon;Sang-Hyun Lee;Seung-Woo Seo",
        "authorids": "/37088689634;/37086021818;/37271925900;/37088689634;/37086021818;/37271925900",
        "aff": "Department of Electrical and Computer Engineering, Seoul National University, Korea; Department of Electrical and Computer Engineering, Seoul National University, Korea; Department of Electrical and Computer Engineering, Seoul National University, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341014/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14745345139661373466&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Seoul National University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.snu.ac.kr",
        "aff_unique_abbr": "SNU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9340993",
        "title": "Exploration of unknown environments with a tethered mobile robot",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a tangle-free frontier based exploration algorithm for planar mobile robots equipped with limited length and anchored tethers. After planning a path to the closest point in the frontier between free and unknown space, the robot computes an estimate of the future length of its tether and decides, by comparing the anticipated length with the minimum possible tether length, whether the path should be followed or not. If the anticipated tether is longer than the minimum tether by a function of the expected radius of the obstacles, a path planner with homotopic constraints is used to plan a path that brings the robot tether to the same homotopy class of the shortest tether. This behavior will not only limit the tether length but also will prevent tether entangling on the obstacles of the environment. We evaluate our method in different simulated environments and illustrate the approach with an actual tethered robot.",
        "primary_area": "",
        "author": "Danylo Shapovalov;Guilherme A. S. Pereira;Danylo Shapovalov;Guilherme A. S. Pereira",
        "authorids": "/37088688226;/37287384300;/37088688226;/37287384300",
        "aff": "Department of Mechanical and Aerospace Engineering, West Virginia University, Morgantown, WV; Department of Mechanical and Aerospace Engineering, West Virginia University, Morgantown, WV",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340993/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7220890722305370540&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "West Virginia University",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.wvu.edu",
        "aff_unique_abbr": "WVU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Morgantown",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341610",
        "title": "Explore Bravely: Wheeled-Legged Robots Traverse in Unknown Rough Environment",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper addressed a challenging problem of wheeled-legged robots with high degrees of freedom exploring in unknown rough environments. The proposed method works as a pipeline to achieve prioritized exploration comprising three primary modules: traversability analysis, frontier-based exploration and hybrid locomotion planning. Traversability analysis provides robots an evaluation about surrounding terrain according to various criteria ( roughness, slope etc.) and other semantic information (small step, stair, bridge etc.), while novel gravity point frontier-based exploration algorithm can effectively decide which direction to go even in unknown environments based on robots' current pose and desired one. Given all these information, hybrid locomotion planner will generate a path with motion mode (driving or walking) encoded by optimizing among different objectives and constraints. Lastly, our approach was well verified in both simulation and experiment on a wheeled quadrupedal robot Pholus.",
        "primary_area": "",
        "author": "Garen Haddeler;Jianle Chan;Yangwei You;Saurab Verma;Albertus H. Adiwahono;Chee Meng Chew;Garen Haddeler;Jianle Chan;Yangwei You;Saurab Verma;Albertus H. Adiwahono;Chee Meng Chew",
        "authorids": "/37088690155;/37088686902;/37085753674;/37085628589;/37546317700;/37088689060;/37088690155;/37088686902;/37085753674;/37085628589;/37546317700;/37088689060",
        "aff": "Institute for Infocomm Research, Agency for Science, Technology and Research, Singapore; Institute for Infocomm Research, Agency for Science, Technology and Research, Singapore; Institute for Infocomm Research, Agency for Science, Technology and Research, Singapore; Institute for Infocomm Research, Agency for Science, Technology and Research, Singapore; Institute for Infocomm Research, Agency for Science, Technology and Research, Singapore; Department of Mechanical Engineering, National University of Singapore, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341610/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10567989655815160397&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;1",
        "aff_unique_norm": "Agency for Science, Technology and Research;National University of Singapore",
        "aff_unique_dep": "Institute for Infocomm Research;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.a-star.edu.sg;https://www.nus.edu.sg",
        "aff_unique_abbr": "A*STAR;NUS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "9341772",
        "title": "Exponentially Stabilizing and Time-Varying Virtual Constraint Controllers for Dynamic Quadrupedal Bounding",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper aims to develop time-varying virtual constraint controllers that allow stable and agile bounding gaits for full-order hybrid dynamical models of quadrupedal locomotion. As opposed to state-based nonlinear controllers, time-varying controllers can initiate locomotion from zero velocity. Motivated by this property, we investigate the stability guarantees that can be provided by the time-varying approach. In particular, we systematically establish necessary and sufficient conditions that guarantee exponential stability of periodic orbits for time-varying hybrid dynamical systems utilizing the Poincar\u00e9 return map. Leveraging the results of the presented proof, we develop time-varying virtual constraint controllers to stabilize bounding gaits of a 14 degree of freedom planar quadrupedal robot, Minitaur. A framework for choosing the parameters of virtual constraint controllers to achieve exponential stability is shown, and the feasibility of the analytical results is numerically validated in full-order simulation models of Minitaur.",
        "primary_area": "",
        "author": "Joseph B. Martin V;Vinay R. Kamidi;Abhishek Pandala;Randall T. Fawcett;Kaveh Akbari Hamed;Joseph B. Martin V;Vinay R. Kamidi;Abhishek Pandala;Randall T. Fawcett;Kaveh Akbari Hamed",
        "authorids": "/37088690606;/37086318455;/37086914371;/37088687180;/37086043463;/37088690606;/37086318455;/37086914371;/37088687180;/37086043463",
        "aff": "Department of Mechanical Engineering, Virginia Tech, Blacksburg, VA, USA; Department of Mechanical Engineering, Virginia Tech, Blacksburg, VA, USA; Department of Mechanical Engineering, Virginia Tech, Blacksburg, VA, USA; Department of Mechanical Engineering, Virginia Tech, Blacksburg, VA, USA; Department of Mechanical Engineering, Virginia Tech, Blacksburg, VA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341772/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2995792104833706913&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Virginia Tech",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.vt.edu",
        "aff_unique_abbr": "VT",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Blacksburg",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341371",
        "title": "Expressing Diverse Human Driving Behavior with Probabilistic Rewards and Online Inference",
        "track": "main",
        "status": "Poster",
        "abstract": "In human-robot interaction (HRI) systems, such as autonomous vehicles, understanding and representing human behavior are important. Human behavior is naturally rich and diverse. Cost/reward learning, as an efficient way to learn and represent human behavior, has been successfully applied in many domains. Most of traditional inverse reinforcement learning (IRL) algorithms, however, cannot adequately capture the diversity of human behavior since they assume that all behavior in a given dataset is generated by a single cost function. In this paper, we propose a probabilistic IRL framework that directly learns a distribution of cost functions in continuous domain. Evaluations on both synthetic data and real human driving data are conducted. Both the quantitative and subjective results show that our proposed framework can better express diverse human driving behaviors, as well as extracting different driving styles that match what human participants interpret in our user study.",
        "primary_area": "",
        "author": "Liting Sun;Zheng Wu;Hengbo Ma;Masayoshi Tomizuka;Liting Sun;Zheng Wu;Hengbo Ma;Masayoshi Tomizuka",
        "authorids": "/37085425729;/37088444305;/37086547315;/37281933000;/37085425729;/37088444305;/37086547315;/37281933000",
        "aff": "Department of Mechanical Engineering, University of California, Berkeley, USA; Department of Mechanical Engineering, University of California, Berkeley, USA; Department of Mechanical Engineering, University of California, Berkeley, USA; Department of Mechanical Engineering, University of California, Berkeley, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341371/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6134099093146435087&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341582",
        "title": "Extended Performance Guarantees for Receding Horizon Search with Terminal Cost",
        "track": "main",
        "status": "Poster",
        "abstract": "The computational difficulty of planning search paths that seek to maximize a general deterministic value function increases dramatically as desired path lengths increase. Mobile search agents with limited computational resources often utilize receding horizon methods to address the path planning problem. Unfortunately, receding horizon planners may perform poorly due to myopic planning horizons. We provide methods of incorporating terminal costs in the construction of receding horizon paths that provide a theoretical lower bound on the performance of the search paths produced. The results presented in this paper are of particular value in subsea search applications. We present results from simulated subsea search missions that use real-world data acquired by an autonomous underwater vehicle during a subsea survey of Boston Harbor.",
        "primary_area": "",
        "author": "Benjamin Biggs;Daniel J. Stilwell;James McMahon;Benjamin Biggs;Daniel J. Stilwell;James McMahon",
        "authorids": "/37087324207;/37283170000;/37085353635;/37087324207;/37283170000;/37085353635",
        "aff": "Bradley Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA, USA; Bradley Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA, USA; US Naval Research Laboratory, Washington D.C., USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341582/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5327280354457288939&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Virginia Tech;US Naval Research Laboratory",
        "aff_unique_dep": "Bradley Department of Electrical and Computer Engineering;",
        "aff_unique_url": "https://www.vt.edu;https://www.nrl.navy.mil",
        "aff_unique_abbr": "VT;NRL",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Blacksburg;Washington D.C.",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341715",
        "title": "Extrinsic and Temporal Calibration of Automotive Radar and 3D LiDAR",
        "track": "main",
        "status": "Poster",
        "abstract": "While automotive radars are widely used in most assisted and autonomous driving systems, only a few works were proposed to tackle the calibration problems of automotive radars with other perception sensors. One of the key calibration challenges of automotive planar radars with other sensors is the missing elevation angle in 3D space. In this paper, extrinsic calibration is accomplished based on the observation that the radar cross section (RCS) measurements have different value distributions across radar's vertical field of view. An approach to accurately and efficiently estimate the time delay between radars and LiDARs based on spatial-temporal relationships of calibration target positions is proposed. In addition, a localization method for calibration target detection and localization in pre-built maps is proposed to tackle insufficient LiDAR measurements on calibration targets. The experimental results show the feasibility and effectiveness of the proposed Radar-LiDAR extrinsic and temporal calibration approaches.",
        "primary_area": "",
        "author": "Chia-Le Lee;Yu-Han Hsueh;Chieh-Chih Wang;Wen-Chieh Lin;Chia-Le Lee;Yu-Han Hsueh;Chieh-Chih Wang;Wen-Chieh Lin",
        "authorids": "/37088691151;/37088691102;/37088493330;/37291223500;/37088691151;/37088691102;/37088493330;/37291223500",
        "aff": "Institute of Electrical and Computer Engineering, National Chiao Tung University, Hsinchu, Taiwan; Institute of Electrical and Control Engineering, National Chiao Tung University, Hsinchu, Taiwan; Mechanical and Mechatronics Systems Research Laboratories, Industrial Technology Research Institute, Hsinchu, Taiwan; Department of Computer Science, National Chiao Tung University, Hsinchu, Taiwan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341715/",
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10857118904557428610&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "National Chiao Tung University;Industrial Technology Research Institute",
        "aff_unique_dep": "Institute of Electrical and Computer Engineering;Mechanical and Mechatronics Systems Research Laboratories",
        "aff_unique_url": "https://www.nctu.edu.tw;https://www.itri.org.tw",
        "aff_unique_abbr": "NCTU;ITRI",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Taiwan",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9341120",
        "title": "F-Siamese Tracker: A Frustum-based Double Siamese Network for 3D Single Object Tracking",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents F-Siamese Tracker, a novel approach for single object tracking prominently characterized by more robustly integrating 2D and 3D information to reduce redundant search space. A main challenge in 3D single object tracking is how to reduce search space for generating appropriate 3D candidates. Instead of solely relying on 3D proposals, firstly, our method leverages the Siamese network applied on RGB images to produce 2D region proposals which are then extruded into 3D viewing frustums. Besides, we perform an on-line accuracy validation on the 3D frustum to generate refined point cloud searching space, which can be embedded directly into the existing 3D tracking backbone. For efficiency, our approach gains better performance with fewer candidates by reducing search space. In addition, benefited from introducing the online accuracy validation, for occasional cases with strong occlusions or very sparse points, our approach can still achieve high precision, even when the 2D Siamese tracker loses the target. This approach allows us to set a new state-of-the-art in 3D single object tracking by a significant margin on a sparse outdoor dataset (KITTI tracking). Moreover, experiments on 2D single object tracking show that our framework boosts 2D tracking performance as well.",
        "primary_area": "",
        "author": "Hao Zou;Jinhao Cui;Xin Kong;Chujuan Zhang;Yong Liu;Feng Wen;Wanlong Li;Hao Zou;Jinhao Cui;Xin Kong;Chujuan Zhang;Yong Liu;Feng Wen;Wanlong Li",
        "authorids": "/37088690615;/37088688571;/37087322070;/37088689834;/37066946100;/37088690190;/37088687641;/37088690615;/37088688571;/37087322070;/37088689834;/37066946100;/37088690190;/37088687641",
        "aff": "Institute of Cyber-Systems and Control, Zhejiang University, Zhejiang, China; Institute of Cyber-Systems and Control, Zhejiang University, Zhejiang, China; Institute of Cyber-Systems and Control, Zhejiang University, Zhejiang, China; Institute of Cyber-Systems and Control, Zhejiang University, Zhejiang, China; State Key Laboratory of Industrial Control Technology and Institute of Cyber-Systems and Control, Zhejiang University, Zhejiang, China; Huawei Noah\u2019s Ark lab; Huawei Noah\u2019s Ark lab",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341120/",
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4604530112087860352&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;1;1",
        "aff_unique_norm": "Zhejiang University;Huawei",
        "aff_unique_dep": "Institute of Cyber-Systems and Control;Noah\u2019s Ark lab",
        "aff_unique_url": "http://www.zju.edu.cn;https://www.huawei.com",
        "aff_unique_abbr": "ZJU;Huawei",
        "aff_campus_unique_index": "0;0;0;0;1",
        "aff_campus_unique": "Zhejiang;Hangzhou;",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9340932",
        "title": "Factor Graph based 3D Multi-Object Tracking in Point Clouds",
        "track": "main",
        "status": "Poster",
        "abstract": "Accurate and reliable tracking of multiple moving objects in 3D space is an essential component of urban scene understanding. This is a challenging task because it requires the assignment of detections in the current frame to the predicted objects from the previous one. Existing filter-based approaches tend to struggle if this initial assignment is not correct, which can happen easily.We propose a novel optimization-based approach that does not rely on explicit and fixed assignments. Instead, we represent the result of an off-the-shelf 3D object detector as Gaussian mixture model, which is incorporated in a factor graph framework. This gives us the flexibility to assign all detections to all objects simultaneously. As a result, the assignment problem is solved implicitly and jointly with the 3D spatial multi-object state estimation using non-linear least squares optimization.Despite its simplicity, the proposed algorithm achieves robust and reliable tracking results and can be applied for offline as well as online tracking. We demonstrate its performance on the real world KITTI tracking dataset and achieve better results than many state-of-the-art algorithms. Especially the consistency of the estimated tracks is superior offline as well as online.",
        "primary_area": "",
        "author": "Johannes P\u00f6schmann;Tim Pfeifer;Peter Protzel;Johannes P\u00f6schmann;Tim Pfeifer;Peter Protzel",
        "authorids": "/37086238558;/37085904954;/37330206000;/37086238558;/37085904954;/37330206000",
        "aff": "Dept. of Electrical Engineering and Information Technology, TU Chemnitz, Germany; Dept. of Electrical Engineering and Information Technology, TU Chemnitz, Germany; Dept. of Electrical Engineering and Information Technology, TU Chemnitz, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340932/",
        "gs_citation": 40,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3973257946841014283&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Technische Universit\u00e4t Chemnitz",
        "aff_unique_dep": "Dept. of Electrical Engineering and Information Technology",
        "aff_unique_url": "https://www.tu-chemnitz.de",
        "aff_unique_abbr": "TU Chemnitz",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9341438",
        "title": "Fast Global Motion Planning for Dynamic Legged Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "This work presents a motion planning algorithm for legged robots capable of constructing long-horizon dynamic plans in real-time. Many existing methods use models that prohibit flight phases or even require static stability, while those that permit these dynamics often plan over short horizons or take minutes to compute. The algorithm presented here resolves these issues through a reduced-order dynamical model that handles motion primitives with stance and flight phases and supports an RRT-Connect framework for rapid exploration. Kinematic and dynamic constraint approximations are computed efficiently and validated with a whole-body trajectory optimization. The algorithm is tested over challenging terrain requiring long planning horizons and dynamic motions in seconds - an order of magnitude faster than existing methods. The speed and global nature of the planner offer a new level of autonomy for legged robot applications.",
        "primary_area": "",
        "author": "Joseph Norby;Aaron M. Johnson;Joseph Norby;Aaron M. Johnson",
        "authorids": "/37088690157;/37589025300;/37088690157;/37589025300",
        "aff": "Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341438/",
        "gs_citation": 39,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10349858524912971858&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341352",
        "title": "Fast LTL-Based Flexible Planning for Dual-Arm Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a method for automatically generating object handling actions based on simple action definitions. The need to replace workers by robots is increasing, and, in fact, many research projects on robots have worked with simple motion definitions. Many applications are for mobile robots such as drones, however, and if such methods are applied directly to object handling, like a pick and place operation, it is necessary for humans to give detailed instructions. Hence, our contribution is to propose a model that simulates the real world with an augmented hybrid system that includes the states of objects. Then, it becomes possible to automatically generate robot motions with simple motion definitions and calculate them within a reasonable time. We demonstrate through computer simulation with a dual-arm robot that robot motions can be generated by simple definitions even if the environment changes to a certain degree.",
        "primary_area": "",
        "author": "Mizuho Katayama;Shumpei Tokuda;Masaki Yamakita;Hiroyuki Oyama;Mizuho Katayama;Shumpei Tokuda;Masaki Yamakita;Hiroyuki Oyama",
        "authorids": "/37088691090;/37087031509;/37279385100;/37085392095;/37088691090;/37087031509;/37279385100;/37085392095",
        "aff": "Department of Systems and Control Engineering, Tokyo Institute of Technology, Tokyo, Japan; Department of Systems and Control Engineering, Tokyo Institute of Technology, Tokyo, Japan; Department of Systems and Control Engineering, Tokyo Institute of Technology, Tokyo, Japan; Biometrics Research Laboratories, NEC Corporation now",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341352/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16848459951294859060&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Tokyo Institute of Technology;NEC Corporation",
        "aff_unique_dep": "Department of Systems and Control Engineering;Biometrics Research Laboratories",
        "aff_unique_url": "https://www.titech.ac.jp;https://www.nec.com",
        "aff_unique_abbr": "Titech;NEC",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Tokyo;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9340759",
        "title": "Fast Model Predictive Image-Based Visual Servoing for Quadrotors",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper studies the problem of Image-Based Visual Servo Control (IBVS) for quadrotors. Although the control of quadrotors has been extensively studied in the last decades, combining the IBVS module with the quadrotor's dynamics is still hard, mainly due to the under-actuation issues related to the quadrotor control as opposed to the 6 DoF control outputs generated by the IBVS modules. We propose an alternative formulation to solve this problem, by particularly using linear Model Predictive Control (MPC), that allows us to relax the UAVs under-actuation issues. Stability guarantees of the proposed scheme are presented. The proposed model is validated with synthetic data and tested in a real UAV's setup.",
        "primary_area": "",
        "author": "Pedro Roque;Elisa Bin;Pedro Miraldo;Dimos V. Dimarogonas;Pedro Roque;Elisa Bin;Pedro Miraldo;Dimos V. Dimarogonas",
        "authorids": "/37086198375;/37088689303;/38241727500;/37282084700;/37086198375;/37088689303;/38241727500;/37282084700",
        "aff": "Division of Decision and Control Systems, KTH Royal institute of Technology, Stockholm, Sweden; Division of Decision and Control Systems, KTH Royal institute of Technology, Stockholm, Sweden; Instituto Superior T\u00e9cnico, Institute for Systems and Robotics (LARSyS), Lisboa, Portugal; Division of Decision and Control Systems, KTH Royal institute of Technology, Stockholm, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340759/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5834908308614619235&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "KTH Royal Institute of Technology;Instituto Superior T\u00e9cnico",
        "aff_unique_dep": "Division of Decision and Control Systems;Institute for Systems and Robotics (LARSyS)",
        "aff_unique_url": "https://www.kth.se;https://www.ist.utl.pt",
        "aff_unique_abbr": "KTH;IST",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Stockholm;Lisboa",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "Sweden;Portugal"
    },
    {
        "id": "9341462",
        "title": "Fast Online Adaptation in Robotics through Meta-Learning Embeddings of Simulated Priors",
        "track": "main",
        "status": "Poster",
        "abstract": "Meta-learning algorithms can accelerate the model-based reinforcement learning (MBRL) algorithms by finding an initial set of parameters for the dynamical model such that the model can be trained to match the actual dynamics of the system with only a few data-points. However, in the real world, a robot might encounter any situation starting from motor failures to finding itself in a rocky terrain where the dynamics of the robot can be significantly different from one another. In this paper, first, we show that when meta-training situations (the prior situations) have such diverse dynamics, using a single set of meta-trained parameters as a starting point still requires a large number of observations from the real system to learn a useful model of the dynamics. Second, we propose an algorithm called FAMLE that mitigates this limitation by meta-training several initial starting points (i.e., initial parameters) for training the model and allows robots to select the most suitable starting point to adapt the model to the current situation with only a few gradient steps. We compare FAMLE to MBRL, MBRL with a meta-trained model with MAML, and model-free policy search algorithm PPO for various simulated and real robotic tasks, and show that FAMLE allows robots to adapt to novel damages in significantly fewer time-steps than the baselines.",
        "primary_area": "",
        "author": "Rituraj Kaushik;Timoth\u00e9e Anne;Jean-Baptiste Mouret;Rituraj Kaushik;Timoth\u00e9e Anne;Jean-Baptiste Mouret",
        "authorids": "/37086321821;/37088691039;/37586421200;/37086321821;/37088691039;/37586421200",
        "aff": "Inria, CNRS, Universit\u00e9 de Lorraine, Nancy, France; Inria, CNRS, Universit\u00e9 de Lorraine, Nancy, France; Inria, CNRS, Universit\u00e9 de Lorraine, Nancy, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341462/",
        "gs_citation": 73,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2792164179318860935&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Inria",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.inria.fr",
        "aff_unique_abbr": "Inria",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9340644",
        "title": "Fast Sequence Rejection for Multi-Goal Planning with Dubins Vehicle",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-goal curvature-constrained planning such as the Dubins Traveling Salesman Problem (DTSP) combines NP-hard combinatorial routing with continuous optimization to determine the optimal vehicle heading angle for each target location. The problem can be addressed as combinatorial routing using a finite set of heading samples at target locations. In such a case, optimal heading samples can be determined for a sequence of targets in polynomial time, and the DTSP can be solved as searching for a sequence with the minimal cost. However, the examination of sequences can be computationally demanding for high numbers of heading samples and target locations. A fast rejection schema is proposed to quickly examine unfavorable sequences using lower bound estimation of Dubins tour cost based on windowing technique that evaluates short subtours of the sequences. Furthermore, the computation using small problem instances can benefit from reusing stored results and thus speed up the search. The reported results indicate that the computational burden is decreased about two orders of magnitude, and the proposed approach supports finding high-quality solutions of routing problems with Dubins vehicle.",
        "primary_area": "",
        "author": "Jan Faigl;Petr V\u00e1\u0148a;Jan Drchal;Jan Faigl;Petr V\u00e1\u0148a;Jan Drchal",
        "authorids": "/37540566100;/37085751648;/38075840600;/37540566100;/37085751648;/38075840600",
        "aff": "Faculty of Electrical Engineering, Czech Technical University, Prague, Czech Republic; Faculty of Electrical Engineering, Czech Technical University, Prague, Czech Republic; Faculty of Electrical Engineering, Czech Technical University, Prague, Czech Republic",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340644/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1441729675209367782&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Czech Technical University",
        "aff_unique_dep": "Faculty of Electrical Engineering",
        "aff_unique_url": "https://www.cvut.cz",
        "aff_unique_abbr": "CTU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Prague",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Czech Republic"
    },
    {
        "id": "9341796",
        "title": "Fast Tennis Swing Motion by Ball Trajectory Prediction and Joint Trajectory Modification in Standalone Humanoid Robot Real-time System",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we propose a system for humanoid robot fast motions. When a humanoid robot performs a motion such as a tennis forehand stroke motion, a whole-body fast motion in reaction to visual information is required. There are three problems to tackle. (1) Motion is desired to be quick. (2) Real-time visual processing considering visual noises is needed. (3) Real-time joint angle modification with balance keeping is needed. To solve the problem (1), we used an offline optimization system to enhance the motion speed. To solve the problem (2), we implement a ball trajectory prediction algorithm using the Extended Kalman Filter (EKF). To solve the trade-off between (1) and (3), we propose an offline optimization condition with an estimated balance margin. By using these methods, we achieved a non-step tennis forehand stroke motion with a humanoid robot by predicting a ball's trajectory with stereo cameras on the robot's head.",
        "primary_area": "",
        "author": "Mirai Hattori;Kunio Kojima;Shintaro Noda;Fumihito Sugai;Yohei Kakiuchi;Kei Okada;Masayuki Inaba;Mirai Hattori;Kunio Kojima;Shintaro Noda;Fumihito Sugai;Yohei Kakiuchi;Kei Okada;Masayuki Inaba",
        "authorids": "/37088688261;/37085360901;/37085354213;/37085651948;/38242437800;/37280639000;/37286658200;/37088688261;/37085360901;/37085354213;/37085651948;/38242437800;/37280639000;/37286658200",
        "aff": "JSK Laboratory, The University of Tokyo, Tokyo, Japan; JSK Laboratory, The University of Tokyo, Tokyo, Japan; JSK Laboratory, The University of Tokyo, Tokyo, Japan; JSK Laboratory, The University of Tokyo, Tokyo, Japan; JSK Laboratory, The University of Tokyo, Tokyo, Japan; JSK Laboratory, The University of Tokyo, Tokyo, Japan; JSK Laboratory, The University of Tokyo, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341796/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3515445602442473154&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "The University of Tokyo",
        "aff_unique_dep": "JSK Laboratory",
        "aff_unique_url": "https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "UTokyo",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9340693",
        "title": "Fast Texture Classification Using Tactile Neural Coding and Spiking Neural Network",
        "track": "main",
        "status": "Poster",
        "abstract": "Touch is arguably the most important sensing modality in physical interactions. However, tactile sensing has been largely under-explored in robotics applications owing to the complexity in making perceptual inferences until the recent advancements in machine learning or deep learning in particular. Touch perception is strongly influenced by both its temporal dimension similar to audition and its spatial dimension similar to vision. While spatial cues can be learned episodically, temporal cues compete against the system\u2019s re-sponse/reaction time to provide accurate inferences. In this paper, we propose a fast tactile-based texture classification framework which makes use of the spiking neural network to learn from the neural coding of the conventional tactile sensor readings. The framework is implemented and tested on two independent tactile datasets collected in sliding motion on 20 material textures. Our results show that the framework is able to make much more accurate inferences ahead of time as compared to that by the state-of-the-art learning approaches.",
        "primary_area": "",
        "author": "Tasbolat Taunyazov;Yansong Chua;Ruihan Gao;Harold Soh;Yan Wu;Tasbolat Taunyazov;Yansong Chua;Ruihan Gao;Harold Soh;Yan Wu",
        "authorids": "/37085673647;/37086479092;/37086880837;/37684942300;/37085344977;/37085673647;/37086479092;/37086880837;/37684942300;/37085344977",
        "aff": "School of Computing, National University of Singapore, Singapore; Central Research Institute, Huawei Technologies Co., Ltd, Shenzhen, China; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Computing, National University of Singapore, Singapore; Robotics & Autonomous Systems Department, A*STAR Institute for Infocomm Research, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340693/",
        "gs_citation": 35,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15947119598291048976&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;0;3",
        "aff_unique_norm": "National University of Singapore;Huawei Technologies Co., Ltd;Nanyang Technological University;A*STAR Institute for Infocomm Research",
        "aff_unique_dep": "School of Computing;Central Research Institute;School of Electrical and Electronic Engineering;Robotics & Autonomous Systems Department",
        "aff_unique_url": "https://www.nus.edu.sg;https://www.huawei.com;https://www.ntu.edu.sg;https://www.a-star.edu.sg",
        "aff_unique_abbr": "NUS;Huawei;NTU;A*STAR I2R",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";Shenzhen;Singapore",
        "aff_country_unique_index": "0;1;0;0;0",
        "aff_country_unique": "Singapore;China"
    },
    {
        "id": "9340963",
        "title": "Fast Uncertainty Estimation for Deep Learning Based Optical Flow",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a novel approach to reduce the processing time required to derive the estimation uncertainty map in deep learning-based optical flow determination methods. Without uncertainty aware reasoning, the optical flow model, especially when it is used for mission critical fields such as robotics and aerospace, can cause catastrophic failures. Although several approaches such as the ones based on Bayesian neural networks have been proposed to handle this issue, they are computationally expensive. Thus, to speed up the processing time, our approach applies a generative model, which is trained by input images and an uncertainty map derived through a Bayesian approach. By using synthetically generated images of spacecraft, we demonstrate that the trained generative model can produce the uncertainty map 100\u223c700 times faster than the conventional uncertainty estimation method used for training the generative model itself. We also show that the quality of uncertainty map derived by the generative model is close to that of the original uncertainty map. By applying the proposed approach, the deep learning model operated in real-time can avoid disastrous failures by considering the uncertainty as well as achieving better performance removing uncertain portions of the prediction result.",
        "primary_area": "",
        "author": "Serin Lee;Vincenzo Capuano;Alexei Harvard;Soon-Jo Chung;Serin Lee;Vincenzo Capuano;Alexei Harvard;Soon-Jo Chung",
        "authorids": "/37090058828;/37086075008;/37086959764;/37309487700;/37090058828;/37086075008;/37086959764;/37309487700",
        "aff": "Graduate Aerospace Laboratories (GALCIT), California Institute of Technology, Pasadena, CA, USA; Graduate Aerospace Laboratories (GALCIT), California Institute of Technology, Pasadena, CA, USA; Graduate Aerospace Laboratories (GALCIT), California Institute of Technology, Pasadena, CA, USA; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340963/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4307295895980867087&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "California Institute of Technology",
        "aff_unique_dep": "Graduate Aerospace Laboratories (GALCIT)",
        "aff_unique_url": "https://www.caltech.edu",
        "aff_unique_abbr": "Caltech",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Pasadena",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341483",
        "title": "Faster Healthcare Time Series Classification for Boosting Mortality Early Warning System",
        "track": "main",
        "status": "Poster",
        "abstract": "Electronic Health Record (EHR) and healthcare claim data provide rich clinical information for time series analysis. In this work, we provide a different angle of solving healthcare multivariate time series classification by turning it into a computer vision problem. We propose a Convolutional Feature Engineering (CFE) methodology, that can effectively extract long sequence dependency time series features. Combined with LightGBM, it can achieve the state-of-the-art results with 35X speed acceleration compared with LSTM based approaches on MIMIC-III In Hospital Mortality benchmark task. We deploy CFE based LightGBM into our Mortality Early Warning System at Humana, and train it on 1 million member samples. The offline metrics shows that this new approach generates better-quality predictions than previous LSTM based approach, and meanwhile greatly decrease the training and inference time.",
        "primary_area": "",
        "author": "Yanke Hu;Raj Subramanian;Wangpeng An;Na Zhao;Weili Wu;Yanke Hu;Raj Subramanian;Wangpeng An;Na Zhao;Weili Wu",
        "authorids": "/37088690780;/37088687124;/37086342741;/37088690971;/37280427400;/37088690780;/37088687124;/37086342741;/37088690971;/37280427400",
        "aff": "Humana, Irving, TX, USA; Humana, Irving, TX, USA; Tsinghua University, Beijing, China; School and Hospital of Stomatology, Peking University, Beijing, China; Faculty of Computer Science Department, University of Texas at Dallas, Richardson, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341483/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15758306278191155861&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;2;3",
        "aff_unique_norm": "Humana;Tsinghua University;Peking University;University of Texas at Dallas",
        "aff_unique_dep": ";;School and Hospital of Stomatology;Faculty of Computer Science Department",
        "aff_unique_url": "https://www.humana.com;https://www.tsinghua.edu.cn;http://www.pku.edu.cn;https://www.utdallas.edu",
        "aff_unique_abbr": ";THU;Peking University;UT Dallas",
        "aff_campus_unique_index": "0;0;1;1;2",
        "aff_campus_unique": "Irving;Beijing;Richardson",
        "aff_country_unique_index": "0;0;1;1;0",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "9340851",
        "title": "Faster than FAST: GPU-Accelerated Frontend for High-Speed VIO",
        "track": "main",
        "status": "Poster",
        "abstract": "The recent introduction of powerful embedded graphics processing units (GPUs) has allowed for unforeseen improvements in real-time computer vision applications. It has enabled algorithms to run onboard, well above the standard video rates, yielding not only higher information processing capability, but also reduced latency. This work focuses on the applicability of efficient low-level, GPU hardware-specific instructions to improve on existing computer vision algorithms in the field of visual-inertial odometry (VIO). While most steps of a VIO pipeline work on visual features, they rely on image data for detection and tracking, of which both steps are well suited for parallelization. Especially non-maxima suppression and the subsequent feature selection are prominent contributors to the overall image processing latency. Our work first revisits the problem of non-maxima suppression for feature detection specifically on GPUs, and proposes a solution that selects local response maxima, imposes spatial feature distribution, and extracts features simultaneously. Our second contribution introduces an enhanced FAST feature detector that applies the aforementioned non-maxima suppression method. Finally, we compare our method to other state-of-the-art CPU and GPU implementations, where we always outperform all of them in feature tracking and detection, resulting in over 1000fps throughput on an embedded Jetson TX2 platform. Additionally, we demonstrate our work integrated into a VIO pipeline achieving a metric state estimation at ~200fps.Code available at: https://github.com/uzh-rpg/vilib.",
        "primary_area": "",
        "author": "Bal\u00e1zs Nagy;Philipp Foehn;Davide Scaramuzza;Bal\u00e1zs Nagy;Philipp Foehn;Davide Scaramuzza",
        "authorids": "/37967177600;/37086455548;/37397688400;/37967177600;/37086455548;/37397688400",
        "aff": "Dep. of Neuroinformatics, University of Zurich and ETH Zurich, Switzerland; Dep. of Neuroinformatics, University of Zurich and ETH Zurich, Switzerland; Dep. of Neuroinformatics, University of Zurich and ETH Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340851/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13143830888781283501&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Zurich",
        "aff_unique_dep": "Department of Neuroinformatics",
        "aff_unique_url": "https://www.unizh.ch",
        "aff_unique_abbr": "UZH",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9340951",
        "title": "Feedback Enhanced Motion Planning for Autonomous Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we address the motion planning problem for autonomous vehicles through a new lattice planning approach, called Feedback Enhanced Lattice Planner (FELP). Existing lattice planners have two major limitations, namely the high dimensionality of the lattice and the lack of modeling of agent vehicle behaviors. We propose to apply the Intelligent Driver Model (IDM) [1] as a speed feedback policy to address both of these limitations. IDM both enables the responsive behavior of the agents, and uniquely determines the acceleration and speed profile of the ego vehicle on a given path. Therefore, only a spatial lattice is needed, while discretization of higher order dimensions is no longer required. Additionally, we propose a directed-graph map representation to support the implementation and execution of lattice planners. The map can reflect local geometric structure, embed the traffic rules adhering to the road, and is efficient to construct and update. We show that FELP is more efficient compared to other existing lattice planners through runtime complexity analysis, and we propose two variants of FELP to further reduce the complexity to polynomial time. We demonstrate the improvement by comparing FELP with an existing spatiotemporal lattice planner using simulations of a merging scenario and continuous highway traffic. We also study the performance of FELP under different traffic densities.",
        "primary_area": "",
        "author": "Ke Sun;Brent Schlotfeldt;Stephen Chaves;Paul Martin;Gulshan Mandhyan;Vijay Kumar;Ke Sun;Brent Schlotfeldt;Stephen Chaves;Paul Martin;Gulshan Mandhyan;Vijay Kumar",
        "authorids": "/37086192986;/37086113948;/37085502862;/37088686044;/37087007760;/37280341400;/37086192986;/37086113948;/37085502862;/37088686044;/37087007760;/37280341400",
        "aff": "GRASP Lab, University of Pennsylvania, Philadelphia, PA, USA; GRASP Lab, University of Pennsylvania, Philadelphia, PA, USA; Qualcomm Technologies Inc., Philadelphia, PA, USA; Qualcomm Technologies Inc., Philadelphia, PA, USA; Qualcomm Technologies Inc., Philadelphia, PA, USA; GRASP Lab, University of Pennsylvania, Philadelphia, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340951/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3800535691638789302&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;1;1;0",
        "aff_unique_norm": "University of Pennsylvania;Qualcomm Technologies Inc.",
        "aff_unique_dep": "GRASP Lab;",
        "aff_unique_url": "https://www.upenn.edu;https://www.qualcomm.com",
        "aff_unique_abbr": "UPenn;QTI",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Philadelphia",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341197",
        "title": "Feedback Whole-Body Control of Wheeled Inverted Pendulum Humanoids Using Operational Space",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a hierarchical framework for trajectory optimization and optimal feedback whole-body control of wheeled inverted pendulum (WIP) humanoid robot. The framework extends rapidly exponentially stabilizing control Lyapunov functions (RES-CLF) to operational space for controlling WIP humanoid robots while utilizing a hierarchical framework to compute an optimal policy. The upper level of the hierarchy encodes locomotion tasks, while the lower level incorporates the full system dynamics, including manipulation tasks to be performed. The framework computes an optimal policy directly in the operational space. Thus it avoids computing inverse kinematics or inverse dynamics explicitly. The framework can handle torque and task constraints while guaranteeing exponential convergence and min-norm control from RES-CLF. The efficacy of the framework is demonstrated on 18 degrees of freedom (DoF) WIP humanoid robot, Golem Krang, and 7 DoF planar WIP humanoid robot.",
        "primary_area": "",
        "author": "Muhammad Ali Murtaza;Vahid Azimi;Seth Hutchinson;Muhammad Ali Murtaza;Vahid Azimi;Seth Hutchinson",
        "authorids": "/37088316016;/38507757500;/37282386200;/37088316016;/38507757500;/37282386200",
        "aff": "Institute of Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA, USA; Institute of Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA, USA; Institute of Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341197/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2214670263572820302&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Georgia Institute of Technology",
        "aff_unique_dep": "Institute of Robotics and Intelligent Machines",
        "aff_unique_url": "https://www.gatech.edu",
        "aff_unique_abbr": "Georgia Tech",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Atlanta",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341778",
        "title": "Feeling the True Force in Haptic Telepresence for Flying Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Haptic feedback in teleoperation of flying robots can enable safe flight in unknown and densely cluttered environments. It is typically part of the robot's control scheme and used to aid navigation and collision avoidance via artificial force fields displayed to the operator. However, to achieve fully immersive embodiment in this context, high fidelity force feedback is needed. In this paper we present a telepresence scheme that provides haptic feedback of the external forces or wind acting on the robot, leveraging the ability of a state-of-the-art flying robot to estimate these values online. As a result, we achieve true force feedback telepresence in flying robots by rendering the actual forces acting on the system. To the authors' knowledge, this is the first telepresence scheme for flying robots that is able to feedback real contact forces and does not depend on their representations. The proposed event-based teleoperation scheme is stable under varying latency conditions. Secondly, we present a haptic interface design such that any haptic interface with at least as many force-sensitive and active degrees of freedom as the flying robot can implement this telepresence architecture. The approach is validated experimentally using a Skydio R1 autonomous flying robot in combination with a ForceDimension sigma.7 and a Franka Emika Panda as haptic devices.",
        "primary_area": "",
        "author": "Alexander Moortgat-Pick;Anna Adamczyk;Teodor Tomi\u0107;Sami Haddadin;Alexander Moortgat-Pick;Anna Adamczyk;Teodor Tomi\u0107;Sami Haddadin",
        "authorids": "/37088691333;/37088687867;/37085395330;/37542865300;/37088691333;/37088687867;/37085395330;/37542865300",
        "aff": "Chair of Robotics and Systems Intelligence, Technical University of Munich (TUM), Munich, Germany; Chair of Robotics and Systems Intelligence, Technical University of Munich (TUM), Munich, Germany; Skydio, Redwood City, CA, USA; Chair of Robotics and Systems Intelligence, Technical University of Munich (TUM), Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341778/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7129149706307052829&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Technical University of Munich;Skydio",
        "aff_unique_dep": "Chair of Robotics and Systems Intelligence;",
        "aff_unique_url": "https://www.tum.de;https://www.skydio.com",
        "aff_unique_abbr": "TUM;",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Munich;Redwood City",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "Germany;United States"
    },
    {
        "id": "9340933",
        "title": "Few-Shot Relation Learning with Attention for EEG-based Motor Imagery Classification",
        "track": "main",
        "status": "Poster",
        "abstract": "Brain-Computer Interfaces (BCI) based on Electroencephalography (EEG) signals, in particular motor imagery (MI) data have received a lot of attention and show the potential towards the design of key technologies both in healthcare and other industries. MI data is generated when a subject imagines movement of limbs and can be used to aid rehabilitation as well as in autonomous driving scenarios. Thus, classification of MI signals is vital for EEG-based BCI systems. Recently, MI EEG classification techniques using deep learning have shown improved performance over conventional techniques. However, due to inter-subject variability, the scarcity of unseen subject data, and low signal-to-noise ratio, extracting robust features and improving accuracy is still challenging. In this context, we propose a novel two-way few shot network that is able to efficiently learn how to learn representative features of unseen subject categories and how to classify them with limited MI EEG data. The pipeline includes an embedding module that learns feature representations from a set of samples, an attention mechanism for key signal feature discovery, and a relation module for final classification based on relation scores between a support set and a query signal. In addition to the unified learning of feature similarity and a few shot classifier, our method leads to emphasize informative features in support data relevant to the query data, which generalizes better on unseen subjects. For evaluation, we used the BCI competition IV 2b dataset and achieved an 9.3% accuracy improvement in the 20-shot classification task with state-of-the-art performance. Experimental results demonstrate the effectiveness of employing attention and the overall generality of our method.",
        "primary_area": "",
        "author": "Sion An;Soopil Kim;Philip Chikontwe;Sang Hyun Park;Sion An;Soopil Kim;Philip Chikontwe;Sang Hyun Park",
        "authorids": "/37088687262;/37088690223;/37086507952;/37072759300;/37088687262;/37088690223;/37086507952;/37072759300",
        "aff": "Department of Robotics Engineering, DGIST, Daegu, South Korea; Department of Robotics Engineering, DGIST, Daegu, South Korea; Department of Robotics Engineering, DGIST, Daegu, South Korea; Department of Robotics Engineering, DGIST, Daegu, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340933/",
        "gs_citation": 55,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14942285297819571885&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Daegu Gyeongbuk Institute of Science and Technology",
        "aff_unique_dep": "Department of Robotics Engineering",
        "aff_unique_url": "https://www.dgist.ac.kr",
        "aff_unique_abbr": "DGIST",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Daegu",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9340973",
        "title": "Fingertip Non-Contact Optoacoustic Sensor for Near-Distance Ranging and Thickness Differentiation for Robotic Grasping",
        "track": "main",
        "status": "Poster",
        "abstract": "We report the feasibility study of a new optoacoustic sensor for both near-distance ranging and material thickness classification for robotic grasping. It is based on the optoacoustic effect where focused laser pulses are used to generate wideband ultrasound signals in the target. With a much smaller optical focal spot, the optoacoustic sensor achieves a lateral resolution of 93 \u03bcm, which is six times higher than ultrasound pulse-echo ranging under the same condition. A new multi-mode wideband PZT (lead zirconate titanate) transducer is built to properly receive the wideband optoacoustic signal. The ability to receive both low- and high-frequency components of the optoacoustic signal enhances the material sensing capability, which makes it promising to determine not only material type but also the sub-surface structures. For demonstration, optoacoustic spectra are collected from hard and soft materials with different thickness. A Bag-of-SFA-Symbols (BOSS) classifier is designed to perform primary material and then thickness classification based on the optoacoustic spectra. The accuracy of material / thickness classification reaches \u2265 99% and \u2265 94%, respectively, which shows the feasibility of differentiating solid materials with different thickness by the optoacoustic sensor.",
        "primary_area": "",
        "author": "Cheng Fang;Di Wang;Dezhen Song;Jun Zou;Cheng Fang;Di Wang;Dezhen Song;Jun Zou",
        "authorids": "/37085893142;/37086453325;/37275586600;/37576103200;/37085893142;/37086453325;/37275586600;/37576103200",
        "aff": "Electrical and Computer Engineering Department, Texas A&M University, College Station, TX, USA; Computer Science and Engineering Department, Texas A&M University, College Station, TX, USA; Computer Science and Engineering Department, Texas A&M University, College Station, TX, USA; Electrical and Computer Engineering Department, Texas A&M University, College Station, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340973/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5509510432612837922&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Texas A&M University",
        "aff_unique_dep": "Electrical and Computer Engineering Department",
        "aff_unique_url": "https://www.tamu.edu",
        "aff_unique_abbr": "TAMU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "College Station",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341116",
        "title": "FireAnt3D: a 3D self-climbing robot towards non-latticed robotic self-assembly",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic self-assembly allows robots to join to form useful, on-demand structures. Unfortunately, the methods employed by most self-assembling robotic swarms compromise this promise of adaptability through their use of fixed docking locations, which impair a swarm's ability to handle imperfections in the structural lattice resulting from load deflection or imperfect robot manufacture; these concerns worsen as swarm size increases. Inspired by the amorphous structures built by cells and social insects, FireAnt3D uses a novel docking mechanism, the 3D continuous dock, to attach to like robots regardless of alignment. FireAnt3D demonstrates the use of the 3D continuous docks, as well as how a robot can use such docks to connect to like robots and locomote over arbitrary 3D arrangements of its peers. The research outlined in this paper presents a profoundly different approach to docking and locomotion during self-assembly and addresses longstanding challenges in the field of robotic self-assembly.",
        "primary_area": "",
        "author": "Petras Swissler;Michael Rubenstein;Petras Swissler;Michael Rubenstein",
        "authorids": "/37086454659;/37282496500;/37086454659;/37282496500",
        "aff": "Department of Mechanical Engineering, Northwestern University, Evanston, IL, USA; Department of Mechanical Engineering, Northwestern University, Evanston, IL, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341116/",
        "gs_citation": 34,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15972892244612412037&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Northwestern University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.northwestern.edu",
        "aff_unique_abbr": "NU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Evanston",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340737",
        "title": "First Steps: Latent-Space Control with Semantic Constraints for Quadruped Locomotion",
        "track": "main",
        "status": "Poster",
        "abstract": "Traditional approaches to quadruped control frequently employ simplified, hand-derived models. This significantly reduces the capability of the robot since its effective kinematic range is curtailed. In addition, kinodynamic constraints are often non-differentiable and difficult to implement in an optimisation approach. In this work, these challenges are addressed by framing quadruped control as optimisation in a structured latent space. A deep generative model captures a statistical representation of feasible joint configurations, whilst complex dynamic and terminal constraints are expressed via high-level, semantic indicators and represented by learned classifiers operating upon the latent space. As a consequence, complex constraints are rendered differentiable and evaluated an order of magnitude faster than analytical approaches. We validate the feasibility of locomotion trajectories optimised using our approach both in simulation and on a real-world ANY-mal quadruped. Our results demonstrate that this approach is capable of generating smooth and realisable trajectories. To the best of our knowledge, this is the first time latent space control has been successfully applied to a complex, real robot platform.",
        "primary_area": "",
        "author": "Alexander L. Mitchell;Martin Engelcke;Oiwi Parker Jones;David Surovik;Siddhant Gangapurwala;Oliwier Melon;Ioannis Havoutis;Ingmar Posner;Alexander L. Mitchell;Martin Engelcke;Oiwi Parker Jones;David Surovik;Siddhant Gangapurwala;Oliwier Melon;Ioannis Havoutis;Ingmar Posner",
        "authorids": "/37088357300;/37086139639;/37088690104;/37086580632;/37088356748;/37088506627;/37542879900;/37601368300;/37088357300;/37086139639;/37088690104;/37086580632;/37088356748;/37088506627;/37542879900;/37601368300",
        "aff": "Dynamic Robot Systems (DRS) Oxford Robotics Institute (ORI), University of Oxford; Applied AI Lab (A2I); Applied AI Lab (A2I); Dynamic Robot Systems (DRS) Oxford Robotics Institute (ORI), University of Oxford; Dynamic Robot Systems (DRS) Oxford Robotics Institute (ORI), University of Oxford; Dynamic Robot Systems (DRS) Oxford Robotics Institute (ORI), University of Oxford; Dynamic Robot Systems (DRS) Oxford Robotics Institute (ORI), University of Oxford; Applied AI Lab (A2I)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340737/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17832530738289564927&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;1;0;0;0;0;1",
        "aff_unique_norm": "University of Oxford;Applied AI Lab",
        "aff_unique_dep": "Oxford Robotics Institute;AI Lab",
        "aff_unique_url": "https://www.ox.ac.uk;",
        "aff_unique_abbr": "Oxford;A2I",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Oxford;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United Kingdom;"
    },
    {
        "id": "9340716",
        "title": "FlexiVision: Teleporting the Surgeon\u2019s Eyes via Robotic Flexible Endoscope and Head-Mounted Display",
        "track": "main",
        "status": "Poster",
        "abstract": "A flexible endoscope introduces more dexterity to the image capturing in endoscopic surgery. However, manual control or automatic control based on instrument tracking does not handle the misorientation between the endoscopic video and the surgeon. We propose an automatic flexible endoscope control method that tracks the surgeon's head with respect to the object in the surgical scene. The robotic flexible endoscope is actuated so that it captures the surgical scene from the same perspective as the surgeon. The surgeon wears a head-mounted display to observe the endoscopic video. The frustum of the flexible endoscope is rendered as an augmented reality overlay to provide surgical guidance. We developed the prototype, FlexiVision, integrating a 6-DOF robotic flexible endoscope based on the da Vinci Research Kit and Microsoft HoloLens. We evaluated the proposed automatic control method via a lesion observation task, and evaluated the AR surgical guidance in a lesion targeting task. The multi-user study results demonstrated that, for both tasks, FlexiVision significantly reduced the completion time (by 59% and 58%), number of errors (by 75% and 95%) and subjective task load level. With FlexiVision, the flexible endoscope could act as the surgeon's eyes teleported into the abdominal cavity of the patient.",
        "primary_area": "",
        "author": "Long Qian;Chengzhi Song;Yiwei Jiang;Qi Luo;Xin Ma;Philip Waiyan Chiu;Zheng Li;Peter Kazanzides;Long Qian;Chengzhi Song;Yiwei Jiang;Qi Luo;Xin Ma;Philip Waiyan Chiu;Zheng Li;Peter Kazanzides",
        "authorids": "/37085687628;/37085847198;/37088689378;/37088690862;/37085857304;/37085379340;/38469473900;/37375173500;/37085687628;/37085847198;/37088689378;/37088690862;/37085857304;/37085379340;/38469473900;/37375173500",
        "aff": "Laboratory for Computational Robotics and Sensing (LCSR), Johns Hopkins University, Maryland, United States; Department of Surgery, The Chinese University of Hong Kong, HKSAR, China; Laboratory for Computational Robotics and Sensing (LCSR), Johns Hopkins University, Maryland, United States; Pacific Lutheran University, Washington, United States; Purdue University, Indiana, United States; Department of Surgery, The Chinese University of Hong Kong, HKSAR, China; Department of Surgery, The Chinese University of Hong Kong, HKSAR, China; Laboratory for Computational Robotics and Sensing (LCSR), Johns Hopkins University, Maryland, United States",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340716/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14402048325165735544&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;0;2;3;1;1;0",
        "aff_unique_norm": "Johns Hopkins University;The Chinese University of Hong Kong;Pacific Lutheran University;Purdue University",
        "aff_unique_dep": "Laboratory for Computational Robotics and Sensing;Department of Surgery;;",
        "aff_unique_url": "https://www.jhu.edu;https://www.cuhk.edu.hk;https://www.plu.edu;https://www.purdue.edu",
        "aff_unique_abbr": "JHU;CUHK;PLU;Purdue",
        "aff_campus_unique_index": "0;0;2;0",
        "aff_campus_unique": "Maryland;;Indiana",
        "aff_country_unique_index": "0;1;0;0;0;1;1;0",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "9340694",
        "title": "Flight Control of Sliding Arm Quadcopter with Dynamic Structural Parameters",
        "track": "main",
        "status": "Poster",
        "abstract": "The conceptual design and flight controller of a novel kind of quadcopter are presented. This design is capable of morphing the shape of the UAV during flight to achieve position and attitude control. We consider a dynamic center of gravity (CoG) which causes continuous variation in a moment of inertia (MoI) parameters of the UAV. These dynamic structural parameters play a vital role in the stability and control of the system. The length of quadcopter arms is a variable parameter, and it is actuated using attitude feedback-based control law. The MoI parameters are computed in real-time and incorporated in the equations of motion of the system. The UAV utilizes the angular motion of propellers and variable quadcopter arm lengths for position and navigation control. The movement space of the CoG is a design parameter and it is bounded by actuator limitations and stability requirements of the system. A detailed information on equations of motion, flight controller design and possible applications of this system are provided. Further, the proposed shape-changing UAV system is evaluated by comparative numerical simulations for way point navigation mission and complex trajectory tracking.",
        "primary_area": "",
        "author": "Rumit Kumar;Aditya M. Deshpande;James Z. Wells;Manish Kumar;Rumit Kumar;Aditya M. Deshpande;James Z. Wells;Manish Kumar",
        "authorids": "/37086276448;/37086424029;/37088690961;/37289852700;/37086276448;/37086424029;/37088690961;/37289852700",
        "aff": "Cooperative Distributed Systems Lab, University of Cincinnati, Ohio, USA; Cooperative Distributed Systems Lab, University of Cincinnati, Ohio, USA; Cooperative Distributed Systems Lab, University of Cincinnati, Ohio, USA; Department of Mechanical and Materials Engineering, University of Cincinnati, Ohio, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340694/",
        "gs_citation": 37,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1591453721952542716&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Cincinnati",
        "aff_unique_dep": "Cooperative Distributed Systems Lab",
        "aff_unique_url": "https://www.uc.edu",
        "aff_unique_abbr": "UC",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Cincinnati",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340942",
        "title": "FlowControl: Optical Flow Based Visual Servoing",
        "track": "main",
        "status": "Poster",
        "abstract": "One-shot imitation is the vision of robot programming from a single demonstration, rather than by tedious construction of computer code. We present a practical method for realizing one-shot imitation for manipulation tasks, exploiting modern learning-based optical flow to perform real-time visual servoing. Our approach, which we call FlowControl, continuously tracks a demonstration video, using a specified foreground mask to attend to an object of interest. Using RGB-D observations, FlowControl requires no 3D object models, and is easy to set up. FlowControl inherits great robustness to visual appearance from decades of work in optical flow. We exhibit FlowControl on a range of problems, including ones requiring very precise motions, and ones requiring the ability to generalize.",
        "primary_area": "",
        "author": "Max Argus;Lukas Hermann;Jon Long;Thomas Brox;Max Argus;Lukas Hermann;Jon Long;Thomas Brox",
        "authorids": "/38252090800;/37088504270;/37088691202;/37541664500;/38252090800;/37088504270;/37088691202;/37541664500",
        "aff": "Computer Science, University of Freiburg, Germany; Computer Science, University of Freiburg, Germany; Symbio Robotics, Emeryville, USA; Computer Science, University of Freiburg, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340942/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15479167207927029216&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "University of Freiburg;Symbio Robotics",
        "aff_unique_dep": "Computer Science;",
        "aff_unique_url": "https://www.uni-freiburg.de;",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Emeryville",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "Germany;United States"
    },
    {
        "id": "9340698",
        "title": "Formalization of Robot Skills with Descriptive and Operational Models",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a formal language to specify robot skills, i.e. the elementary behaviours or functions provided by the robot platform in order to perform an autonomous mission. The advantage of the language we propose is that it integrates a wide range of elements that allows to define and provide automatic translation both to operational models, used online to control the skill execution, and descriptive models, allowing to reason about the expected skill execution, and then apply automated planning or model-checking taking skill models into account.",
        "primary_area": "",
        "author": "Charles Lesire;David Doose;Christophe Grand;Charles Lesire;David Doose;Christophe Grand",
        "authorids": "/38275129600;/38072337700;/38335131900;/38275129600;/38072337700;/38335131900",
        "aff": "ONERA/DTIS, University of Toulouse, Toulouse, France; ONERA/DTIS, University of Toulouse, Toulouse, France; ONERA/DTIS, University of Toulouse, Toulouse, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340698/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15965476600162445296&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Toulouse",
        "aff_unique_dep": "ONERA/DTIS",
        "aff_unique_url": "https://www.univ-toulouse.fr",
        "aff_unique_abbr": "UT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Toulouse",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9341129",
        "title": "FreeBOT: A Freeform Modular Self-reconfigurable Robot with Arbitrary Connection Point - Design and Implementation",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a novel modular selfreconfigurable robot (MSRR) \"FreeBOT\", which can be connected freely at any point on other robots. FreeBOT is mainly composed of two parts: a spherical ferromagnetic shell and an internal magnet. The connection between the modules is genderless and instant, since the internal magnet can freely attract other FreeBOT spherical ferromagnetic shells, and not need to be precisely aligned with the specified connector. This connection method has fewer physical constraints, so the FreeBOT system can be extended to more configurations to meet more functional requirements. FreeBOT can accomplish multiple tasks although it only has two motors: module independent movement, connector management and system reconfiguration. FreeBOT can move independently on the plane, and even climb on ferromagnetic walls; a group of FreeBOTs can traverse complex terrain. Numerous experiments have been conducted to test its function, which shows that the FreeBOT system has great potential to realize a freeform robotic system.",
        "primary_area": "",
        "author": "Guanqi Liang;Haobo Luo;Ming Li;Huihuan Qian;Tin Lun Lam;Guanqi Liang;Haobo Luo;Ming Li;Huihuan Qian;Tin Lun Lam",
        "authorids": "/37088687610;/37088686275;/37089459196;/37549401900;/37571111600;/37088687610;/37088686275;/37089459196;/37549401900;/37571111600",
        "aff": "The Shenzhen Institute of Artificial Intelligence and Robotics for Society; The Shenzhen Institute of Artificial Intelligence and Robotics for Society; The Shenzhen Institute of Artificial Intelligence and Robotics for Society; The Shenzhen Institute of Artificial Intelligence and Robotics for Society; The Shenzhen Institute of Artificial Intelligence and Robotics for Society",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341129/",
        "gs_citation": 99,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12861215106439657975&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Shenzhen Institute of Artificial Intelligence and Robotics for Society",
        "aff_unique_dep": "",
        "aff_unique_url": "http://www.siarfs.org",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9341593",
        "title": "Friction Identification in a Pneumatic Gripper",
        "track": "main",
        "status": "Poster",
        "abstract": "Mechanical systems are typically composed of a number of contacting surfaces that move against each other. Such surfaces are subject to friction forces. These dissipate part of the actuation energy and cause an undesired effect on the overall system functioning. Therefore, a suitable model of friction is needed to elide its action. The choice of such a model is not always straightforward, as it is influenced by the system properties and dynamics. In this paper, we show the identification of different friction models and evaluate their prediction capability on an experimental dataset. Despite being state-of-the-art models, some modifications were introduced to improve their performance. A pneumatic gripper was used to collect the data for the models evaluation. Two experimental setups were mounted to execute the experiments: information from two pressure sensors, a load cell and a position sensor was employed for the identification. During the experiments, the gripper was actuated at different constant velocities. Results indicate that all the identified models offer a proper prediction of the real friction force.",
        "primary_area": "",
        "author": "Rocco A. Romeo;Marco Maggiali;Daniele Pucci;Luca Fiorio;Rocco A. Romeo;Marco Maggiali;Daniele Pucci;Luca Fiorio",
        "authorids": "/37085705883;/37295800800;/37706167200;/37085446877;/37085705883;/37295800800;/37706167200;/37085446877",
        "aff": "iCub Tech, Istituto Italiano di Tecnologia, Genoa, Italy; iCub Tech, Istituto Italiano di Tecnologia, Genoa, Italy; iCub Tech, Istituto Italiano di Tecnologia, Genoa, Italy; iCub Tech, Istituto Italiano di Tecnologia, Genoa, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341593/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14847709623126722433&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Istituto Italiano di Tecnologia",
        "aff_unique_dep": "iCub Tech",
        "aff_unique_url": "https://www.iit.it",
        "aff_unique_abbr": "IIT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Genoa",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9340706",
        "title": "From Human to Robot Everyday Activity",
        "track": "main",
        "status": "Poster",
        "abstract": "The Everyday Activities Science and Engineering (EASE) Collaborative Research Consortium\u2019s mission to enhance the performance of cognition-enabled robots establishes its foundation in the EASE Human Activities Data Analysis Pipeline. Through collection of diverse human activity information resources, enrichment with contextually relevant annotations, and subsequent multimodal analysis of the combined data sources, the pipeline described will provide a rich resource for robot planning researchers, through incorporation in the OpenEASE cloud platform.",
        "primary_area": "",
        "author": "Celeste Mason;Konrad Gadzicki;Moritz Meier;Florian Ahrens;Thorsten Kluss;Jaime Maldonado;Felix Putze;Thorsten Fehr;Christoph Zetzsche;Manfred Herrmann;Kerstin Schill;Tanja Schultz;Celeste Mason;Konrad Gadzicki;Moritz Meier;Florian Ahrens;Thorsten Kluss;Jaime Maldonado;Felix Putze;Thorsten Fehr;Christoph Zetzsche;Manfred Herrmann;Kerstin Schill;Tanja Schultz",
        "authorids": "/37088687482;/37088501408;/37087027345;/37088686346;/37088398809;/37088421016;/38186298900;/38503945400;/37351789500;/37088690730;/37352670300;/37284937900;/37088687482;/37088501408;/37087027345;/37088686346;/37088398809;/37088421016;/38186298900;/38503945400;/37351789500;/37088690730;/37352670300;/37284937900",
        "aff": "Cognitive Systems Lab, University of Bremen, Germany; Cognitive Neuroinformatics, University of Bremen, Germany; Cognitive Systems Lab, University of Bremen, Germany; Neuropsychology and Behavioral Neurobiology, University of Bremen, Germany; Cognitive Neuroinformatics, University of Bremen, Germany; Cognitive Neuroinformatics, University of Bremen, Germany; Cognitive Systems Lab, University of Bremen, Germany; Neuropsychology and Behavioral Neurobiology, University of Bremen, Germany; Cognitive Neuroinformatics, University of Bremen, Germany; Neuropsychology and Behavioral Neurobiology, University of Bremen, Germany; Cognitive Neuroinformatics, University of Bremen, Germany; Cognitive Systems Lab, University of Bremen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340706/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15988906548576146623&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 24,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "University of Bremen",
        "aff_unique_dep": "Cognitive Systems Lab",
        "aff_unique_url": "https://www.uni-bremen.de",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9340805",
        "title": "From Points to Planes - Adding Planar Constraints to Monocular SLAM Factor Graphs",
        "track": "main",
        "status": "Poster",
        "abstract": "Planar structures are common in man-made environments. Their addition to monocular SLAM algorithms is of relevance in order to achieve more complete and higher- level scene representations. Also, the additional constraints they introduce might reduce the estimation errors in certain situations. In this paper we present a novel formulation to incorporate plane landmarks and planar constraints to feature- based monocular SLAM. Specifically, we enforce in-plane points to lie exactly in the plane they belong to, propagating such information to the rest of the states. Our formulation, differently from the state of the art, allows us to incorporate general planes, independently of depth information or CNN segmentation being available (although we could also use them). We evaluate our method in several sequences of public databases, showing accurate plane estimations and pose accuracy on par with state- of-the-art point-only monocular SLAM.",
        "primary_area": "",
        "author": "Charlotte Arndt;Reza Sabzevari;Javier Civera;Charlotte Arndt;Reza Sabzevari;Javier Civera",
        "authorids": "/37088687088;/37870790500;/37579561700;/37088687088;/37870790500;/37579561700",
        "aff": "Instituto de Investigaci\u00f3n en Ingenier\u00eda de Arag\u00f3n (I3A), Universidad de Zaragoza, Zaragoza, Spain; CV-Lab, Coorporate Research, Robert Bosch GmbH, Hildesheim, Germany; Instituto de Investigaci\u00f3n en Ingenier\u00eda de Arag\u00f3n (I3A), Universidad de Zaragoza, Zaragoza, Spain",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340805/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7721978159402887705&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Universidad de Zaragoza;Robert Bosch GmbH",
        "aff_unique_dep": "Instituto de Investigaci\u00f3n en Ingenier\u00eda de Arag\u00f3n (I3A);Coorporate Research",
        "aff_unique_url": "https://www.unizar.es;https://www.bosch.com",
        "aff_unique_abbr": "UniZar;Bosch",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Zaragoza;Hildesheim",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Spain;Germany"
    },
    {
        "id": "9341735",
        "title": "Frontier Detection and Reachability Analysis for Efficient 2D Graph-SLAM Based Active Exploration",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose an integrated approach to active exploration by exploiting the Cartographer method as the base SLAM module for submap creation and performing efficient frontier detection in the geometrically co-aligned submaps induced by graph optimization. We also carry out analysis on the reachability of frontiers and their clusters to ensure that the detected frontier can be reached by robot. Our method is tested on a mobile robot in real indoor scene to demonstrate the effectiveness and efficiency of our approach.",
        "primary_area": "",
        "author": "Zezhou Sun;Banghe Wu;Cheng-Zhong Xu;Sanjay E. Sarma;Jian Yang;Hui Kong;Zezhou Sun;Banghe Wu;Cheng-Zhong Xu;Sanjay E. Sarma;Jian Yang;Hui Kong",
        "authorids": "/37086934230;/37088686871;/37278305300;/37410318300;/37280205100;/37061510500;/37086934230;/37088686871;/37278305300;/37410318300;/37280205100;/37061510500",
        "aff": "School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, Jiangsu, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, Jiangsu, China; Department of Computer Science, University of Macau, Macau; Department of Mechanical Engineering, MIT, Cambridge, MA; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, Jiangsu, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, Jiangsu, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341735/",
        "gs_citation": 37,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17166283268427022116&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;2;0;0",
        "aff_unique_norm": "Nanjing University of Science and Technology;University of Macau;Massachusetts Institute of Technology",
        "aff_unique_dep": "School of Computer Science and Engineering;Department of Computer Science;Department of Mechanical Engineering",
        "aff_unique_url": "http://www.nust.edu.cn;https://www.um.edu.mo;https://web.mit.edu",
        "aff_unique_abbr": "NUST;UM;MIT",
        "aff_campus_unique_index": "0;0;1;2;0;0",
        "aff_campus_unique": "Nanjing;Macau SAR;Cambridge",
        "aff_country_unique_index": "0;0;0;1;0;0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9340955",
        "title": "Fruit quality control by surface analysis using a bio-inspired soft tactile sensor",
        "track": "main",
        "status": "Poster",
        "abstract": "The growing consumer demand for large volumes of high quality fruit has generated an increasing need for auto-mated fruit quality control during production. Optical methods have been proved successful in a few cases, but with limitations related to the variability of fruit colors and lighting conditions during tests. Tactile sensing provides a valuable alternative, although it comes with the need of a physical interaction that could damage the fruit. To overcome these limitations, we propose the usage of a recently developed soft tactile sensor for non-invasive fruit quality control. The ability of the sensor to detect very small forces and to finely analyze surfaces allows the collection of relevant information about the fruit by performing a very delicate physical interaction, that does not cause any damage. We report experiments in which such information is used to determine whether apples and strawberries are ripe or senescent. We test different configurations of the sensor and different classification algorithms, achieving very good accuracy for both apples (96%) and strawberries (83%).",
        "primary_area": "",
        "author": "Pedro Ribeiro;Susana Cardoso;Alexandre Bernardino;Lorenzo Jamone;Pedro Ribeiro;Susana Cardoso;Alexandre Bernardino;Lorenzo Jamone",
        "authorids": "/37086026015;/37266515500;/37442087500;/37295474600;/37086026015;/37266515500;/37442087500;/37295474600",
        "aff": "ARQ, School of Electronic Engineering and Computer Science, Queen Mary University of London, London, United Kingdom; Department of Physics, Instituto Superior Tecnico, University of Lisbon, Portugal; Institute for Systems and Robotics, Lisbon, Portugal; ARQ, School of Electronic Engineering and Computer Science, Queen Mary University of London, London, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340955/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7485874262584821097&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "Queen Mary University of London;University of Lisbon;Institute for Systems and Robotics",
        "aff_unique_dep": "School of Electronic Engineering and Computer Science;Department of Physics;",
        "aff_unique_url": "https://www.qmul.ac.uk;https://www IST Lisbon;",
        "aff_unique_abbr": "QMUL;IST;",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "London;Lisbon",
        "aff_country_unique_index": "0;1;1;0",
        "aff_country_unique": "United Kingdom;Portugal"
    },
    {
        "id": "9341550",
        "title": "Fully Convolutional Geometric Features for Category-level Object Alignment",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper focuses on pose registration of different object instances from the same category. This is required in online object mapping because object instances detected at test time usually differ from the training instances. Our approach transforms instances of the same category to a normalized canonical coordinate frame and uses metric learning to train fully convolutional geometric features. The resulting model is able to generate pairs of matching points between the instances, allowing category-level registration. Evaluation on both synthetic and real-world data shows that our method provides robust features, leading to accurate alignment of instances with different shapes.",
        "primary_area": "",
        "author": "Qiaojun Feng;Nikolay Atanasov;Qiaojun Feng;Nikolay Atanasov",
        "authorids": "/37087322298;/37670511000;/37087322298;/37670511000",
        "aff": "Department of Electrical and Computer Engineering, University of California, San Diego, La Jolla, CA, USA; Department of Electrical and Computer Engineering, University of California, San Diego, La Jolla, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341550/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1285839292473025109&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of California, San Diego",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.ucsd.edu",
        "aff_unique_abbr": "UCSD",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "La Jolla",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341766",
        "title": "Functionally Divided Manipulation Synergy for Controlling Multi-fingered Hands",
        "track": "main",
        "status": "Poster",
        "abstract": "Synergy provides a practical approach for expressing various postures of a multi-fingered hand. However, a conventional synergy defined for reproducing grasping postures cannot perform in-hand manipulation, e.g., tasks that involve simultaneously grasping and manipulating an object. Locking the position of particular fingers of a multi-fingered hand is essential for in-hand manipulation tasks either to hold an object or to fix unnecessary fingers. When using conventional synergy based control to manipulate an object, which requires locking some fingers, the coordination of joints is heavily restricted, decreasing the dexterity of the hand. We propose a functionally divided manipulation synergy (FDMS) method, which provides a synergy-based control to achieves both dimensionality reduction and in-hand manipulation. In FDMS, first, we define the function of each finger of the hand as either \"manipulation\" or \"fixed.\" Then, we apply synergy control only to the fingers having the manipulation function, so that dexterous manipulations can be realized with a few control inputs. Furthermore, we propose the Synergy Switching Framework as a method for applying a finely defined FDMS to sequential task changes. The effectiveness of our method is experimentally verified.",
        "primary_area": "",
        "author": "Kazuki Higashi;Keisuke Koyama;Ryuta Ozawa;Kazuyuki Nagata;Weiwei Wan;Kensuke Harada;Kazuki Higashi;Keisuke Koyama;Ryuta Ozawa;Kazuyuki Nagata;Weiwei Wan;Kensuke Harada",
        "authorids": "/37088685921;/37085489789;/37273966600;/37357506600;/37085689483;/37277067400;/37088685921;/37085489789;/37273966600;/37357506600;/37085689483;/37277067400",
        "aff": "Graduate School of Engineering Science, Osaka University, Osaka, JAPAN; Graduate School of Engineering Science, Osaka University, Osaka, JAPAN; School of Science and Technology, Meiji University; National Institute of Advanced Industrial Science and Technology; National Institute of Advanced Industrial Science and Technology; National Institute of Advanced Industrial Science and Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341766/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9475575242970552140&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;2;2;2",
        "aff_unique_norm": "Osaka University;Meiji University;National Institute of Advanced Industrial Science and Technology",
        "aff_unique_dep": "Graduate School of Engineering Science;School of Science and Technology;",
        "aff_unique_url": "https://www.osaka-u.ac.jp;https://www.meiji.ac.jp;https://www.aist.go.jp",
        "aff_unique_abbr": "Osaka U;Meiji;AIST",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Osaka;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9340995",
        "title": "Fusing Concurrent Orthogonal Wide-aperture Sonar Images for Dense Underwater 3D Reconstruction",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a novel approach to handling the ambiguity in elevation angle associated with the observations of a forward looking multi-beam imaging sonar, and the challenges it poses for performing an accurate 3D reconstruction. We utilize a pair of sonars with orthogonal axes of uncertainty to independently observe the same points in the environment from two different perspectives, and associate these observations. Using these concurrent observations, we can create a dense, fully defined point cloud at every time-step to aid in reconstructing the 3D geometry of underwater scenes. We will evaluate our method in the context of the current state of the art, for which strong assumptions on object geometry limit applicability to generalized 3D scenes. We will discuss results from laboratory tests that quantitatively benchmark our algorithm's reconstruction capabilities, and results from a real-world, tidal river basin which qualitatively demonstrate our ability to reconstruct a cluttered field of underwater objects.",
        "primary_area": "",
        "author": "John McConnell;John D. Martin;Brendan Englot;John McConnell;John D. Martin;Brendan Englot",
        "authorids": "/37827503600;/37088688605;/37601539900;/37827503600;/37088688605;/37601539900",
        "aff": "Department of Mechanical Engineering, Stevens Institute of Technology, Hoboken, NJ, USA; Department of Mechanical Engineering, Stevens Institute of Technology, Hoboken, NJ, USA; Department of Mechanical Engineering, Stevens Institute of Technology, Hoboken, NJ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340995/",
        "gs_citation": 43,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4721238712619182873&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Stevens Institute of Technology",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.stevens.edu",
        "aff_unique_abbr": "SIT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Hoboken",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341299",
        "title": "GOSMatch: Graph-of-Semantics Matching for Detecting Loop Closures in 3D LiDAR data",
        "track": "main",
        "status": "Poster",
        "abstract": "Detecting loop closures in 3D Light Detection and Ranging (LiDAR) data is a challenging task since point-level methods always suffer from instability. This paper presents a semantic-level approach named GOSMatch to perform reliable place recognition. Our method leverages novel descriptors, which are generated from the spatial relationship between semantics, to perform frame description and data association. We also propose a coarse-to-fine strategy to efficiently search for loop closures. Besides, GOSMatch can give an accurate 6-DOF initial pose estimation once a loop closure is confirmed. Extensive experiments have been conducted on the KITTI odometry dataset and the results show that GOSMatch can achieve robust loop closure detection performance and outperform existing methods.",
        "primary_area": "",
        "author": "Yachen Zhu;Yanyang Ma;Long Chen;Cong Liu;Maosheng Ye;Lingxi Li;Yachen Zhu;Yanyang Ma;Long Chen;Cong Liu;Maosheng Ye;Lingxi Li",
        "authorids": "/37088691013;/37088686646;/37085668482;/37086287776;/37088556081;/37293042500;/37088691013;/37088686646;/37085668482;/37086287776;/37088556081;/37293042500",
        "aff": "School of Data and Computer Science, Sun Yat-sen University, China; School of Data and Computer Science, Sun Yat-sen University, China; School of Data and Computer Science, Sun Yat-sen University, China; School of Data and Computer Science, Sun Yat-sen University, China; School of Geodesy and Geomatics, Wuhan University, China; Dept. of Electrical and Computer Engineering, Purdue School of Engineering and Technology, Indiana University-Purdue University, Indianapolis, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341299/",
        "gs_citation": 74,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15011740985943621754&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;2",
        "aff_unique_norm": "Sun Yat-sen University;Wuhan University;Indiana University-Purdue University Indianapolis",
        "aff_unique_dep": "School of Data and Computer Science;School of Geodesy and Geomatics;Dept. of Electrical and Computer Engineering",
        "aff_unique_url": "http://www.sysu.edu.cn/;http://en.whu.edu.cn/;https://www.iupui.edu",
        "aff_unique_abbr": "SYSU;WHU;IUPUI",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";Wuhan;Indianapolis",
        "aff_country_unique_index": "0;0;0;0;0;1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9341028",
        "title": "GP-SLAM+: real-time 3D lidar SLAM based on improved regionalized Gaussian process map reconstruction",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a 3D lidar SLAM system based on improved regionalized Gaussian process (GP) map reconstruction to provide both low-drift state estimation and mapping in real-time for robotics applications. We utilize spatial GP regression to model the environment. This tool enables us to recover surfaces including those in sparsely scanned areas and obtain uniform samples with uncertainty. Those properties facilitate robust data association and map updating in our scan-to-map registration scheme, especially when working with sparse range data. Compared with previous GP-SLAM, this work overcomes the prohibitive computational complexity of GP and redesigns the registration strategy to meet the accuracy requirements in 3D scenarios. For large-scale tasks, a two-thread framework is employed to suppress the drift further. Aerial and ground-based experiments demonstrate that our method allows robust odometry and precise mapping in real-time. It also outperforms the state-of-the-art lidar SLAM systems in our tests with light-weight sensors.",
        "primary_area": "",
        "author": "Jianyuan Ruan;Bo Li;Yinqiang Wang;Zhou Fang;Jianyuan Ruan;Bo Li;Yinqiang Wang;Zhou Fang",
        "authorids": "/37087881153;/37087888427;/37088689253;/37534262800;/37087881153;/37087888427;/37088689253;/37534262800",
        "aff": "School of Aeronautics and Astronautics, Zhejiang University, China; School of Aeronautics and Astronautics, Zhejiang University, China; School of Aeronautics and Astronautics, Zhejiang University, China; School of Aeronautics and Astronautics, Zhejiang University, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341028/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6389670038085167245&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Zhejiang University",
        "aff_unique_dep": "School of Aeronautics and Astronautics",
        "aff_unique_url": "http://www.zju.edu.cn",
        "aff_unique_abbr": "ZJU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9341641",
        "title": "GP-based Runtime Planning, Learning, and Recovery for Safe UAV Operations under Unforeseen Disturbances",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous vehicles are typically developed and trained to work under certain system and environmental conditions defined at design time and can fail or perform poorly if unforeseen conditions such as disturbances or changes in model dynamics appear at runtime. In this work, we present a fast online planning, learning, and recovery approach for safe autonomous operations under unknown runtime disturbances. Our approach estimates the behavior of the system with an unknown model and provides safe plans at runtime under previously unseen disturbances by leveraging Gaussian Process regression theory in which a model is continuously trained and adapted using data collected during the autonomous operation. A recovery procedure is event-triggered any time a safety constraint is violated to guarantee safety and enable learning and replanning. The proposed framework is applied and validated both in simulation and experiment on an unmanned aerial vehicle (UAV) delivery case study in which the UAV is tasked to carry an a priori unknown payload to a goal location in a cluttered/constrained environment.",
        "primary_area": "",
        "author": "Esen Yel;Nicola Bezzo;Esen Yel;Nicola Bezzo",
        "authorids": "/37086422921;/37546843800;/37086422921;/37546843800",
        "aff": "Departments of Engineering Systems and Environment and Electrical and Computer Engineering, University of Virginia, Charlottesville, VA, USA; Departments of Engineering Systems and Environment and Electrical and Computer Engineering, University of Virginia, Charlottesville, VA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341641/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2930170203377931143&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Virginia",
        "aff_unique_dep": "Departments of Engineering Systems and Environment, Electrical and Computer Engineering",
        "aff_unique_url": "https://www.virginia.edu",
        "aff_unique_abbr": "UVA",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Charlottesville",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341411",
        "title": "GPU Parallelization of Policy Iteration RRT#",
        "track": "main",
        "status": "Poster",
        "abstract": "Sampling-based planning has become a de facto standard for complex robots given its superior ability to rapidly explore high-dimensional configuration spaces. Most existing optimal sampling-based planning algorithms are sequential in nature and cannot take advantage of wide parallelism available on modern computer hardware. Further, tight synchronization of exploration and exploitation phases in these algorithms limits sample throughput and planner performance. Policy Iteration RRT# (PI-RRT#) exposes fine-grained parallelism during the exploitation phase, but this parallelism has not yet been evaluated using a concrete implementation. We first present a novel GPU implementation of PI-RRT#'s exploitation phase and discuss data structure considerations to maximize parallel performance. Our implementation achieves 3-4\u00d7 speedup over a serial PI-RRT# implementation for a 77.9% decrease in overall planning time on average. As a second contribution, we introduce the Batched-Extension RRT# algorithm, which loosens the synchronization present in PI-RRT# to realize independent 12.97\u00d7 and 12.54\u00d7 speedups under serial and parallel exploitation, respectively.",
        "primary_area": "",
        "author": "R. Connor Lawson;Linda Wills;Panagiotis Tsiotras;R. Connor Lawson;Linda Wills;Panagiotis Tsiotras",
        "authorids": "/37086423978;/37282843900;/37330609800;/37086423978;/37282843900;/37330609800",
        "aff": "School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA; School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA; Daniel Guggenheim School of Aerospace Engineering, Institute for Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341411/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13243415497291785024&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Georgia Institute of Technology",
        "aff_unique_dep": "School of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.gatech.edu",
        "aff_unique_abbr": "Georgia Tech",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Atlanta",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341387",
        "title": "GR-SLAM: Vision-Based Sensor Fusion SLAM for Ground Robots on Complex Terrain",
        "track": "main",
        "status": "Poster",
        "abstract": "In recent years, many excellent SLAM methods based on cameras, especially the camera-IMU fusion (VIO), have emerged, which has greatly improved the accuracy and robustness of SLAM. However, we find through experiments that most of the existing VIO methods perform well on drones or drone datasets, but for ground robots on complex terrain, they cannot continuously provide accurate and robust localization results. Some researchers have proposed methods for ground robots, but most of them have limited applications due to the assumption of plane motion. Therefore, this paper proposes GR-SLAM for the localization of ground robots on complex terrain, which can fuse camera, IMU, and encoder data in a tightly coupled scheme to provide accurate and robust state estimation for robots. First, an odometer increment model is proposed, which can fuse the encoder and IMU data to calculate the robot pose increment on manifold, and calculate the frame constraints through the pre-integrated increment. Then we propose an evaluation algorithm for multi-sensor measurements, which can detect abnormal data and adjust its optimization weight. Finally, we implement a complete factor graph optimization framework based on sliding window, which can tightly couple camera, IMU, and encoder data to perform state estimation. Extensive experiments are conducted based on a real ground robot and the results show that GR-SLAM can provide accurate and robust state estimation for ground robots.",
        "primary_area": "",
        "author": "Yun Su;Ting Wang;Chen Yao;Shiliang Shao;Zhidong Wang;Yun Su;Ting Wang;Chen Yao;Shiliang Shao;Zhidong Wang",
        "authorids": "/37087235421;/37089656404;/37687111800;/37088689417;/37279258300;/37087235421;/37089656404;/37687111800;/37088689417;/37279258300",
        "aff": "University of Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Robotics, Shenyang Institute of Automation, Institutes for Robotics and Intelligent Manufacturing, Chinese Academy of Sciences, Shenyang, China; State Key Laboratory of Robotics, Shenyang Institute of Automation, Institutes for Robotics and Intelligent Manufacturing, Chinese Academy of Sciences, Shenyang, China; State Key Laboratory of Robotics, Shenyang Institute of Automation, Institutes for Robotics and Intelligent Manufacturing, Chinese Academy of Sciences, Shenyang, China; Department of Advanced Robotics, Chiba Institute of Technology, Chiba, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341387/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15298871909995140990&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;2",
        "aff_unique_norm": "University of Chinese Academy of Sciences;Chinese Academy of Sciences;Chiba Institute of Technology",
        "aff_unique_dep": ";State Key Laboratory of Robotics;Department of Advanced Robotics",
        "aff_unique_url": "http://www.ucas.ac.cn;http://www.cas.cn;https://www.chibatech.ac.jp",
        "aff_unique_abbr": "UCAS;CAS;",
        "aff_campus_unique_index": "0;1;1;1;2",
        "aff_campus_unique": "Beijing;Shenyang;Chiba",
        "aff_country_unique_index": "0;0;0;0;1",
        "aff_country_unique": "China;Japan"
    },
    {
        "id": "9341177",
        "title": "GRIF Net: Gated Region of Interest Fusion Network for Robust 3D Object Detection from Radar Point Cloud and Monocular Image",
        "track": "main",
        "status": "Poster",
        "abstract": "Robust and accurate scene representation is essential for advanced driver assistance systems (ADAS) such as automated driving. The radar and camera are two widely used sensors for commercial vehicles due to their low-cost, high-reliability, and low-maintenance. Despite their strengths, radar and camera have very limited performance when used individually. In this paper, we propose a low-level sensor fusion 3D object detector that combines two Region of Interest (RoI) from radar and camera feature maps by a Gated RoI Fusion (GRIF) to perform robust vehicle detection. To take advantage of sensors and utilize a sparse radar point cloud, we design a GRIF that employs the explicit gating mechanism to adaptively select the appropriate data when one of the sensors is abnormal. Our experimental evaluations on nuScenes show that our fusion method GRIF not only has significant performance improvement over single radar and image method but achieves comparable performance to the LiDAR detection method. We also observe that the proposed GRIF achieve higher recall than mean or concatenation fusion operation when points are sparse.",
        "primary_area": "",
        "author": "Youngseok Kim;Jun Won Choi;Dongsuk Kum;Youngseok Kim;Jun Won Choi;Dongsuk Kum",
        "authorids": "/37086964519;/37405961800;/37967151300;/37086964519;/37405961800;/37967151300",
        "aff": "Graduate School for Green Transportation, KAIST, Daejeon, Republic of Korea; Dept. of Electrical Engineering, Hanyang University, Seoul, Republic of Korea; Graduate School for Green Transportation, KAIST, Daejeon, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341177/",
        "gs_citation": 63,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3979849928617871914&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "KAIST;Hanyang University",
        "aff_unique_dep": "Graduate School for Green Transportation;Dept. of Electrical Engineering",
        "aff_unique_url": "https://www.kaist.ac.kr;http://www.hanyang.ac.kr",
        "aff_unique_abbr": "KAIST;HYU",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Daejeon;Seoul",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9340949",
        "title": "Gain Scheduled Controller Design for Balancing an Autonomous Bicycle",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, the gain scheduling technique is applied to design a balance controller for an autonomous bicycle with an inertia wheel. Previously, two different balance controllers are needed depending on whether the bicycle is stationary or dynamic. The switch between the two different controllers may cause the instability of the autonomous bicycle. Our proposed gain scheduled controller can balance the autonomous bicycle in both stationary and dynamic cases. A physical system is built and experiments are carried out to demonstrate the effectiveness of the gain scheduled controller.",
        "primary_area": "",
        "author": "Shuai Wang;Leilei Cui;Jie Lai;Sicheng Yang;Xiangyu Chen;Yu Zheng;Zhengyou Zhang;Zhong-Ping Jiang;Shuai Wang;Leilei Cui;Jie Lai;Sicheng Yang;Xiangyu Chen;Yu Zheng;Zhengyou Zhang;Zhong-Ping Jiang",
        "authorids": "/37088687660;/37088689192;/37088688811;/37088687616;/37088686410;/37086993722;/37088690693;/37279935100;/37088687660;/37088689192;/37088688811;/37088687616;/37088686410;/37086993722;/37088690693;/37279935100",
        "aff": "Tencent Robotics X, Tencent Holdings, Shenzhen, China; Control and Networks Lab, Department of Electrical and Computer Engineering, Tandon School of Engineering, New York University, Brooklyn, NY, USA; Tencent Robotics X, Tencent Holdings, Shenzhen, China; Tencent Robotics X, Tencent Holdings, Shenzhen, China; Tencent Robotics X, Tencent Holdings, Shenzhen, China; Tencent Robotics X, Tencent Holdings, Shenzhen, China; Tencent Robotics X, Tencent Holdings, Shenzhen, China; Control and Networks Lab, Department of Electrical and Computer Engineering, Tandon School of Engineering, New York University, Brooklyn, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340949/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11624570277873843111&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;0;0;0;0;0;1",
        "aff_unique_norm": "Tencent Holdings;New York University",
        "aff_unique_dep": "Tencent Robotics X;Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.tencent.com;https://www.nyu.edu",
        "aff_unique_abbr": "Tencent;NYU",
        "aff_campus_unique_index": "0;1;0;0;0;0;0;1",
        "aff_campus_unique": "Shenzhen;Brooklyn",
        "aff_country_unique_index": "0;1;0;0;0;0;0;1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9341418",
        "title": "Gait Training Robot with Intermittent Force Application based on Prediction of Minimum Toe Clearance",
        "track": "main",
        "status": "Poster",
        "abstract": "Adaptive assistance of gait training robots has been determined to improve gait performance through motion assistance. An important control role during walking is to avoid tripping by controlling minimum toe clearance (MTC), which is an indicator of tripping risk, to avoid its decrease among gait cycles. No conventional gait training robots can adjust assistance timing based on MTC. In this paper, we propose a system that applies force intermittently based on the MTC prediction algorithm to encourage people to avoid lowering the MTC. This prediction algorithm is based on a radial basis function network, the input data of which include the angles, angular velocities, and angular accelerations of the hip, knee, and ankle joints in the sagittal and coronal planes at toe-off. The cable-driven system that can switch between assistance and non-assistance modes applies force when the predicted MTC is lower than the mean value. Nine participants were asked to walk on a treadmill, and we tested the effect of the system. The MTC data before, during, and after the assistance phase were analyzed for 120 s. The results showed that the minimum and first quartile values of MTC could be increased after the assistance phase.",
        "primary_area": "",
        "author": "Tamon Miyake;Masakatsu G Fujie;Shigeki Sugano;Tamon Miyake;Masakatsu G Fujie;Shigeki Sugano",
        "authorids": "/37085875459;/37282474100;/37274050800;/37085875459;/37282474100;/37274050800",
        "aff": "Graduate School of Creative Science and Engineering, Waseda University, Tokyo, Japan; Future Robotics Organization, Waseda University, Tokyo, Japan; Faculty of Science and Engineering, Waseda University, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341418/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5072658037129949987&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Waseda University",
        "aff_unique_dep": "Graduate School of Creative Science and Engineering",
        "aff_unique_url": "https://www.waseda.jp/top",
        "aff_unique_abbr": "Waseda",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9340724",
        "title": "Game Theoretic Formation Design for Probabilistic Barrier Coverage",
        "track": "main",
        "status": "Poster",
        "abstract": "We study strategies to deploy defenders/sensors to detect intruders that approach a targeted region. This scenario is formulated as a barrier coverage, which aims to minimize the number of unseen paths. The problem becomes challenging when the number of defenders is insufficient for a full coverage, requiring us to find the most effective location to deploy them. To this end, we use ideas from game theory to account for various paths that the intruders may take. Specifically, we propose an iterative algorithm to refine the set of candidate defender formations, which uses the payoff matrix to directly evaluate the utility of different formations. Given the set of candidate formations, a mixed Nash equilibrium gives a stochastic policy to deploy the defenders. The efficacy of the proposed strategy is demonstrated by a numerical analysis that compares our method with an existing graph-theoretic method.",
        "primary_area": "",
        "author": "Daigo Shishika;Douglas G. Macharet;Brian M. Sadler;Vijay Kumar;Daigo Shishika;Douglas G. Macharet;Brian M. Sadler;Vijay Kumar",
        "authorids": "/37085516690;/37590114800;/37276988900;/37280341400;/37085516690;/37590114800;/37276988900;/37280341400",
        "aff": "GRASP Lab at the University of Pennsylvania, Philadelphia, USA; Computer Vision and Robotics Laboratory (VeRLab), Department of Computer Science, Universidade Federal de Minas Gerais, Brazil; U.S. Army Research Laboratory, Adelphi, MD, USA; GRASP Lab at the University of Pennsylvania, Philadelphia, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340724/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10063880452856032574&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "University of Pennsylvania;Universidade Federal de Minas Gerais;U.S. Army Research Laboratory",
        "aff_unique_dep": "GRASP Lab;Department of Computer Science;",
        "aff_unique_url": "https://www.upenn.edu;http://www.ufmg.br;https://www.arl.army.mil",
        "aff_unique_abbr": "UPenn;UFMG;ARL",
        "aff_campus_unique_index": "0;2;0",
        "aff_campus_unique": "Philadelphia;;Adelphi",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "United States;Brazil"
    },
    {
        "id": "9341137",
        "title": "Game-Theoretic Planning for Risk-Aware Interactive Agents",
        "track": "main",
        "status": "Poster",
        "abstract": "Modeling the stochastic behavior of interacting agents is key for safe motion planning. In this paper, we study the interaction of risk-aware agents in a game-theoretical framework. Under the entropic risk measure, we derive an iterative algorithm for approximating the intractable feedback Nash equilibria of a risk-sensitive dynamic game. We use an iteratively linearized approximation of the system dynamics and a quadratic approximation of the cost function in solving a backward recursion for finding feedback Nash equilibria. In this respect, the algorithm shares a similar structure with DDP and iLQR methods. We conduct experiments in a set of challenging scenarios such as roundabouts. Compared to ignoring the game interaction or the risk sensitivity, we show that our risk-sensitive game-theoretic framework leads to more timeefficient, intuitive, and safe behaviors when facing underlying risks and uncertainty.",
        "primary_area": "",
        "author": "Mingyu Wang;Negar Mehr;Adrien Gaidon;Mac Schwager;Mingyu Wang;Negar Mehr;Adrien Gaidon;Mac Schwager",
        "authorids": "/37086454215;/37085844571;/37945420900;/37424620600;/37086454215;/37085844571;/37945420900;/37424620600",
        "aff": "Stanford University, Stanford, CA, USA; Stanford University, Stanford, CA, USA; Toyota Research Institute, Los Altos, CA, USA; Stanford University, Stanford, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341137/",
        "gs_citation": 40,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9179800523433099818&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Stanford University;Toyota Research Institute",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.stanford.edu;https://www.tri.global",
        "aff_unique_abbr": "Stanford;TRI",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Stanford;Los Altos",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341667",
        "title": "Gaussian Process Gradient Maps for Loop-Closure Detection in Unstructured Planetary Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "The ability to recognize previously mapped locations is an essential feature for autonomous systems. Unstructured planetary-like environments pose a major challenge to these systems due to the similarity of the terrain. As a result, the ambiguity of the visual appearance makes state-of-the-art visual place recognition approaches less effective than in urban or man-made environments. This paper presents a method to solve the loop closure problem using only spatial information. The key idea is to use a novel continuous and probabilistic representations of terrain elevation maps. Given 3D point clouds of the environment, the proposed approach exploits Gaussian Process (GP) regression with linear operators to generate continuous gradient maps of the terrain elevation information. Traditional image registration techniques are then used to search for potential matches. Loop closures are verified by leveraging both the spatial characteristic of the elevation maps (SE (2) registration) and the probabilistic nature of the GP representation. A submap-based localization and mapping framework is used to demonstrate the validity of the proposed approach. The performance of this pipeline is evaluated and benchmarked using real data from a rover that is equipped with a stereo camera and navigates in challenging, unstructured planetary-like environments in Morocco and on Mt. Etna.",
        "primary_area": "",
        "author": "Cedric Le Gentil;Mallikarjuna Vayugundla;Riccardo Giubilato;Wolfgang St\u00fcrzl;Teresa Vidal-Calleja;Rudolph Triebel;Cedric Le Gentil;Mallikarjuna Vayugundla;Riccardo Giubilato;Wolfgang St\u00fcrzl;Teresa Vidal-Calleja;Rudolph Triebel",
        "authorids": "/37086453208;/37087246489;/37085829294;/37598170500;/37085384801;/37542908700;/37086453208;/37087246489;/37085829294;/37598170500;/37085384801;/37542908700",
        "aff": "Centre for Autonomous Systems at the Faculty of Engineering and IT, University of Technology Sydney; Institute of Robotics and Mechatronics, German Aerospace Center (DLR); Institute of Robotics and Mechatronics, German Aerospace Center (DLR); Institute of Robotics and Mechatronics, German Aerospace Center (DLR); Centre for Autonomous Systems at the Faculty of Engineering and IT, University of Technology Sydney; Department of Computer Science, Technical University of Munich (TUM)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341667/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15208102775611587570&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;1;0;2",
        "aff_unique_norm": "University of Technology Sydney;German Aerospace Center;Technical University of Munich",
        "aff_unique_dep": "Faculty of Engineering and IT;Institute of Robotics and Mechatronics;Department of Computer Science",
        "aff_unique_url": "https://www.uts.edu.au;https://www.dlr.de;https://www.tum.de",
        "aff_unique_abbr": "UTS;DLR;TUM",
        "aff_campus_unique_index": "0;0;2",
        "aff_campus_unique": "Sydney;;Munich",
        "aff_country_unique_index": "0;1;1;1;0;1",
        "aff_country_unique": "Australia;Germany"
    },
    {
        "id": "9341209",
        "title": "Gaze by Semi-Virtual Robotic Heads: Effects of Eye and Head Motion",
        "track": "main",
        "status": "Poster",
        "abstract": "We study human perception of gaze rendered by popular semi-virtual robotic heads, which use a screen to render a robot's face. It is known that when these heads are stationary, the screen may induce the Mona Lisa gaze effect, which widens the robot's apparent cone of direct gaze. But how do people perceive gaze when the head can move as well? To study this question, we conducted a laboratory experiment that investigated human perception of robot gaze when a semi-virtual platform looked in different directions. We varied the way in which the robot conveyed gaze, using several behaviors involving 2D eye and head motion. Our results suggest that the interplay between these motions can regulate how wide users perceive the robot's cone of direct gaze. Also, our findings suggest that the location of observers can affect the perception of gaze by semi-virtual robotic heads. We discuss the implications of our findings for social interaction.",
        "primary_area": "",
        "author": "Marynel V\u00e1zquez;Yofti Milkessa;Michelle M. Li;Neha Govil;Marynel V\u00e1zquez;Yofti Milkessa;Michelle M. Li;Neha Govil",
        "authorids": "/37707834500;/37088687868;/37088689008;/37088687847;/37707834500;/37088687868;/37088689008;/37088687847",
        "aff": "Yale University, New Haven, CT, USA; Yale University, New Haven, CT, USA; Yale University, New Haven, CT, USA; Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341209/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2384900728324458046&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Yale University;Massachusetts Institute of Technology",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.yale.edu;https://www.mit.edu",
        "aff_unique_abbr": "Yale;MIT",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "New Haven;Cambridge",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340881",
        "title": "GelTip: A Finger-shaped Optical Tactile Sensor for Robotic Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Sensing contacts throughout the fingers is an essential capability for a robot to perform manipulation tasks in cluttered environments. However, existing tactile sensors either only have a flat sensing surface or a compliant tip with a limited sensing area. In this paper, we propose a novel optical tactile sensor, the GelTip, that is shaped as a finger and can sense contacts on any location of its surface. The sensor captures high-resolution and color-invariant tactile image that can be exploited to extract detailed information about the end-effector\u2019s interactions against manipulated objects. Our extensive experiments show that the GelTip sensor can effectively localise the contacts on different locations its finger-shaped body, with a small localisation error of approximately 5 mm, on average, and under 1 mm in the best cases. The obtained results show the potential of the GelTip sensor in facilitating dynamic manipulation tasks with its all-round tactile sensing capability. The sensor models and further information about the GelTip sensor can be found at http://danfergo.github.io/geltip.",
        "primary_area": "",
        "author": "Daniel Fernandes Gomes;Zhonglin Lin;Shan Luo;Daniel Fernandes Gomes;Zhonglin Lin;Shan Luo",
        "authorids": "/37088689978;/37088686685;/37085478830;/37088689978;/37088686685;/37085478830",
        "aff": "smARTLab, Department of Computer Science, University of Liverpool, Liverpool, United Kingdom; School of Mechanical Engineering and Automation, Fuzhou University, Fuzhou, China; smARTLab, Department of Computer Science, University of Liverpool, Liverpool, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340881/",
        "gs_citation": 112,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10803826487913170022&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Liverpool;Fuzhou University",
        "aff_unique_dep": "Department of Computer Science;School of Mechanical Engineering and Automation",
        "aff_unique_url": "https://www.liverpool.ac.uk;https://www.fznu.edu.cn",
        "aff_unique_abbr": "UoL;",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Liverpool;Fuzhou",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "United Kingdom;China"
    },
    {
        "id": "9340739",
        "title": "Generalizing Learned Manipulation Skills in Practice",
        "track": "main",
        "status": "Poster",
        "abstract": "Robots should be able to learn and perform a manipulation task across different settings. This paper presents an approach that learns an RNN-based manipulation skill model from demonstrations and then generalizes the learned skill in new settings. The manipulation skill model learned from demonstrations in an initial set of setting performs well in those settings and similar ones. However, the model may perform poorly in a novel setting that is significantly different from the learned settings. Therefore a novel approach called generalization in practice (GiP) is developed to tackle this critical problem. In this approach, the robot practices in the new setting to obtain new training data and refine the learned skill using the new data to gradually improve the learned skill model. The proposed approach has been implemented for one type of manipulation task \u2013 pouring that is the most performed manipulation in cooking applications. The presented approach enables a pouring robot to pour gracefully like a person in terms of speed and accuracy in learned setups and gradually improve the pouring performance in novel setups after several practices.",
        "primary_area": "",
        "author": "Juan Wilches;Yongqiang Huang;Yu Sun;Juan Wilches;Yongqiang Huang;Yu Sun",
        "authorids": "/37088686808;/37085721329;/37291603500;/37088686808;/37085721329;/37291603500",
        "aff": "Department of Computer Science & Engineering, University of South Florida, Tampa, FL, USA; Department of Computer Science & Engineering, University of South Florida, Tampa, FL, USA; Department of Computer Science & Engineering, University of South Florida, Tampa, FL, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340739/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17021722499254154374&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of South Florida",
        "aff_unique_dep": "Department of Computer Science & Engineering",
        "aff_unique_url": "https://www.usf.edu",
        "aff_unique_abbr": "USF",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Tampa",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341588",
        "title": "Generating Alerts to Assist With Task Assignments in Human-Supervised Multi-Robot Teams Operating in Challenging Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "In a mission with considerable uncertainty due to intermittent communications, degraded information flow, and failures, humans need to assess both the current and expected future states, and update task assignments to robots as quickly as possible. We present a forward simulation-based alert system that proactively notifies the human supervisor of possible, negatively-impactful events, which provides an opportunity for the human to retask agents to avoid undesirable scenarios. We propose methods for speeding up mission simulations and extracting alerts from simulation data in order to enable real-time alert generation suitable for time-critical missions. We present the results from a user trial and verify our hypothesis that the decision making performance of human supervisors can be improved by introducing forward simulation-based alerts.",
        "primary_area": "",
        "author": "Sarah Al-Hussaini;Jason M. Gregory;Yuxiang Guan;Satyandra K. Gupta;Sarah Al-Hussaini;Jason M. Gregory;Yuxiang Guan;Satyandra K. Gupta",
        "authorids": "/37086460660;/37086090183;/37088690507;/37878971100;/37086460660;/37086090183;/37088690507;/37878971100",
        "aff": "Viterbi School of Engineering, University of Southern California, CA, USA; CCDC Army Research Laboratory, Adelphi, MD, USA; Viterbi School of Engineering, University of Southern California, CA, USA; Viterbi School of Engineering, University of Southern California, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341588/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8223180745460577987&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "University of Southern California;CCDC Army Research Laboratory",
        "aff_unique_dep": "Viterbi School of Engineering;",
        "aff_unique_url": "https://www.usc.edu;",
        "aff_unique_abbr": "USC;",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Los Angeles;Adelphi",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341794",
        "title": "Generating Minimum-Snap Quadrotor Trajectories Really Fast",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose an algorithm for generating minimum-snap trajectories for quadrotors with linear computational complexity with respect to the number of segments in the spline trajectory. Our algorithm is numerically stable for large numbers of segments and is able to generate trajectories of more than 500, 000 segments. The computational speed and numerical stability of our algorithm makes it suitable for real-time generation of very large scale trajectories. We demonstrate the performance of our algorithm and compare it to existing methods, in which it is both faster and able to calculate larger trajectories than state-of-the-art. We also show the feasibility of the trajectories experimentally with a long quadrotor flight.",
        "primary_area": "",
        "author": "Declan Burke;Airlie Chapman;Iman Shames;Declan Burke;Airlie Chapman;Iman Shames",
        "authorids": "/37088336503;/37544843500;/37400016300;/37088336503;/37544843500;/37400016300",
        "aff": "Department of Mechanical Engineering and third with the Department of Electrical and Electronic Engineering, The University of Melbourne, VIC, Australia; Department of Mechanical Engineering and third with the Department of Electrical and Electronic Engineering, The University of Melbourne, VIC, Australia; Department of Mechanical Engineering and third with the Department of Electrical and Electronic Engineering, The University of Melbourne, VIC, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341794/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2955419807873610854&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "The University of Melbourne",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.unimelb.edu.au",
        "aff_unique_abbr": "UniMelb",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Melbourne",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "9340937",
        "title": "Generating New Lower Abstract Task Operator using Grid-TLI",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a method of subdividing robot tasks into new lower abstract tasks. The description of robot tasks in an abstract manner is effective for motion planning for complex tasks and teaching robot movements in various environments. However, a more efficient task description may be obtained by using a lower abstraction according to the work environment. We argue that a higher abstract task can be expressed as a new lower abstract subtasks by applying Grid-based Signal Temporal Inference (Grid-TLI). We show that a new task can be completed using the Signal Temporal Logic formula for each cluster. We demonstrated the efficiency of our method through computer simulations using a 2-D security robot task.",
        "primary_area": "",
        "author": "Shumpei Tokuda;Mizuho Katayama;Masaki Yamakita;Hiroyuki Oyama;Shumpei Tokuda;Mizuho Katayama;Masaki Yamakita;Hiroyuki Oyama",
        "authorids": "/37087031509;/37088691090;/37279385100;/37085392095;/37087031509;/37088691090;/37279385100;/37085392095",
        "aff": "Department of Systems and Control Engineering, Tokyo Institute of Technology, Meguro, Japan; Department of Systems and Control Engineering, Tokyo Institute of Technology, Meguro, Japan; Department of Systems and Control Engineering, Tokyo Institute of Technology, Meguro, Japan; Data Science Research Laboratories, NEC Corporation, Kawasaki, Kanagawa, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340937/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8672857481792537900&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Tokyo Institute of Technology;NEC Corporation",
        "aff_unique_dep": "Department of Systems and Control Engineering;Data Science Research Laboratories",
        "aff_unique_url": "https://www.titech.ac.jp;https://www.nec.com",
        "aff_unique_abbr": "Titech;NEC",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "Meguro;Kawasaki",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9340808",
        "title": "Generating Reactive Approach Motions Towards Allowable Manifolds using Generalized Trajectories from Demonstrations",
        "track": "main",
        "status": "Poster",
        "abstract": "There is a high cost associated to the time and expertise required to program complex robot applications with high variability. This is one of the main barriers that inhibit the entry of robotic automation in small and medium-sized enterprises. To tackle the high level of task uncertainty associated with changing conditions of the environment, we propose a framework that leverages a combination between learning from demonstration (LfD) and constraint-based task specification and control. This synergy enables our framework to use LfD to generalize reactive approach motions (RAMo) towards not only a single pose but towards an allowable manifold defined with respect to the object to interact with. As a result, the robot executes the task by following a feasible approach motion gen-eralized from the learned information. This approach motion is generated based on an initial representation of the environment, and it can be reactively adapted in function of current updates of the environment using sensor information. The proposed framework enables the system to deal with applications that involve a high level of uncertainty, increasing the flexibility and robustness, compared to traditional sense-plan-act paradigms.",
        "primary_area": "",
        "author": "Cristian Vergara;Santiago Iregui;Joris De Schutter;Erwin Aertbeli\u00ebn;Cristian Vergara;Santiago Iregui;Joris De Schutter;Erwin Aertbeli\u00ebn",
        "authorids": "/37086588756;/37088690101;/37283056500;/37449455800;/37086588756;/37088690101;/37283056500;/37449455800",
        "aff": "Core Lab ROB, Flanders Make@KU Leuven; Core Lab ROB, Flanders Make@KU Leuven; Core Lab ROB, Flanders Make@KU Leuven; Core Lab ROB, Flanders Make@KU Leuven",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340808/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17462347764552176310&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "KU Leuven",
        "aff_unique_dep": "Core Lab ROB",
        "aff_unique_url": "https://www.kuleuven.be",
        "aff_unique_abbr": "KU Leuven",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Belgium"
    },
    {
        "id": "9340690",
        "title": "Geometrical Interpretation and Detection of Multiple Task Conflicts using a Coordinate Invariant Index",
        "track": "main",
        "status": "Poster",
        "abstract": "Modern robots act in dynamic and partially unknown environments where path replanning can be mandatory if changes in the environment are observed. Task-prioritized control strategies are well known and effective solutions to ensure local adaptation of robot behaviour. The highest priority in a stack of tasks is typically given to the management of correct robot operation or safe interaction with the environment such as obstacles or joint limits avoidance, that we can consider as constraints. If a constraint makes impossible achieving a certain task, such as tracking a Cartesian trajectory, a local control algorithm partially sacrifices the latter which is only accomplished to the best of the robot's ability to generate internal motions. In this control framework, problems may occur in some applications, like in the surgical domain, where it is not safe that some tasks are simply sacrificed without prior notice. The contribution of this work is to introduce a coordinate invariant index, that is used to provide a geometrical interpretation of task conflicts in a task-priority control framework and to develop a method for on-line detection of algorithmic singularities, with the goal of increasing safety and performances during robot operations.",
        "primary_area": "",
        "author": "Vincenzo Schettino;Mario D. Fiore;Claudia Pecorella;Fanny Ficuciello;Felix Allmendinger;Johannes Lachner;Stefano Stramigioli;Bruno Siciliano;Vincenzo Schettino;Mario D. Fiore;Claudia Pecorella;Fanny Ficuciello;Felix Allmendinger;Johannes Lachner;Stefano Stramigioli;Bruno Siciliano",
        "authorids": "/37086407184;/37087471549;/37088689352;/37594404000;/37087472275;/37088691248;/37282439300;/37282449100;/37086407184;/37087471549;/37088689352;/37594404000;/37087472275;/37088691248;/37282439300;/37282449100",
        "aff": "KUKA Deutschland GmbH, Augsburg, DE; KUKA Deutschland GmbH, Augsburg, DE; Department of Electrical Engineering and Information Technology, PRISMA Lab, University of Naples Federico II, Naples, IT; Department of Electrical Engineering and Information Technology, PRISMA Lab, University of Naples Federico II, Naples, IT; KUKA Deutschland GmbH, Augsburg, DE; Faculty of Electrical Engineering, Mathematics and Computer Science, University of Twente, Enschede, The Netherlands; Faculty of Electrical Engineering, Mathematics and Computer Science, University of Twente, Enschede, The Netherlands; Department of Electrical Engineering and Information Technology, PRISMA Lab, University of Naples Federico II, Naples, IT",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340690/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16672487346169947047&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;1;1;0;2;2;1",
        "aff_unique_norm": "KUKA Deutschland GmbH;University of Naples Federico II;University of Twente",
        "aff_unique_dep": ";Department of Electrical Engineering and Information Technology;Faculty of Electrical Engineering, Mathematics and Computer Science",
        "aff_unique_url": "https://www.kuka.com;https://www.unina.it;https://www.utwente.nl",
        "aff_unique_abbr": "KUKA;UNINA;UT",
        "aff_campus_unique_index": "0;0;1;1;0;2;2;1",
        "aff_campus_unique": "Augsburg;Naples;Enschede",
        "aff_country_unique_index": "0;0;1;1;0;2;2;1",
        "aff_country_unique": "Germany;Italy;Netherlands"
    },
    {
        "id": "9341354",
        "title": "Geomorphological Analysis Using Unpiloted Aircraft Systems, Structure from Motion, and Deep Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a pipeline for geomorphological analysis that uses structure from motion (SfM) and deep learning on close-range aerial imagery to estimate spatial distributions of rock traits (size, roundness, and orientation) along a tectonic fault scarp. The properties of the rocks on the fault scarp derive from the combination of initial volcanic fracturing and subsequent tectonic and geomorphic fracturing, and our pipeline allows scientists to leverage UAS-based imagery to gain a better understanding of such surface processes. We start by using SfM on aerial imagery to produce georeferenced orthomosaics and digital elevation models (DEM). A human expert then annotates rocks on a set of image tiles sampled from the orthomosaics, and these annotations are used to train a deep neural network to detect and segment individual rocks in the entire site. The extracted semantic information (rock masks) on large volumes of unlabeled, high-resolution SfM products allows subsequent structural analysis and shape descriptors to estimate rock size, roundness, and orientation. We present results of two experiments conducted along a fault scarp in the Volcanic Tablelands near Bishop, California. We conducted the first, proof-of-concept experiment with a DJI Phantom 4 Pro equipped with an RGB camera and inspected if elevation information assisted instance segmentation from RGB channels. Rock-trait histograms along and across the fault scarp were obtained with the neural network inference. In the second experiment, we deployed a hexrotor and a multispectral camera to produce a DEM and five spectral orthomosaics in red, green, blue, red edge, and near infrared. We focused on examining the effectiveness of different combinations of input channels in instance segmentation.",
        "primary_area": "",
        "author": "Zhiang Chen;Tyler R. Scott;Sarah Bearman;Harish Anand;Devin Keating;Chelsea Scott;J Ram\u00f3n Arrowsmith;Jnaneshwar Das;Zhiang Chen;Tyler R. Scott;Sarah Bearman;Harish Anand;Devin Keating;Chelsea Scott;J Ram\u00f3n Arrowsmith;Jnaneshwar Das",
        "authorids": "/37089267670;/37088691344;/37088686182;/37088689301;/37088686093;/37088688844;/37088686517;/37529624800;/37089267670;/37088691344;/37088686182;/37088689301;/37088686093;/37088688844;/37088686517;/37529624800",
        "aff": "School of Earth and Space Exploration, Arizona State University, Tempe, AZ, USA; School of Earth and Space Exploration, Arizona State University, Tempe, AZ, USA; School of Earth and Space Exploration, Arizona State University, Tempe, AZ, USA; School of Earth and Space Exploration, Arizona State University, Tempe, AZ, USA; School of Earth and Space Exploration, Arizona State University, Tempe, AZ, USA; School of Earth and Space Exploration, Arizona State University, Tempe, AZ, USA; School of Earth and Space Exploration, Arizona State University, Tempe, AZ, USA; School of Earth and Space Exploration, Arizona State University, Tempe, AZ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341354/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8674249300253097470&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Arizona State University",
        "aff_unique_dep": "School of Earth and Space Exploration",
        "aff_unique_url": "https://www.asu.edu",
        "aff_unique_abbr": "ASU",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Tempe",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340736",
        "title": "Getting to Know One Another: Calibrating Intent, Capabilities and Trust for Human-Robot Collaboration",
        "track": "main",
        "status": "Poster",
        "abstract": "Common experience suggests that agents who know each other well are better able to work together. In this work, we address the problem of calibrating intention and capabilities in human-robot collaboration. In particular, we focus on scenarios where the robot is attempting to assist a human who is unable to directly communicate her intent. Moreover, both agents may have differing capabilities that are unknown to one another. We adopt a decision-theoretic approach and propose the TICC-POMDP for modeling this setting, with an associated online solver. Experiments show our approach leads to better team performance both in simulation and in a real-world study with human subjects.",
        "primary_area": "",
        "author": "Joshua Lee;Jeffrey Fong;Bing Cai Kok;Harold Soh;Joshua Lee;Jeffrey Fong;Bing Cai Kok;Harold Soh",
        "authorids": "/37088691542;/37088689592;/37088691134;/37684942300;/37088691542;/37088689592;/37088691134;/37684942300",
        "aff": "Dept. of Computer Science, National University of Singapore; Dept. of Computer Science, National University of Singapore; Dept. of Computer Science, National University of Singapore; Dept. of Computer Science, National University of Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340736/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6448811876131227435&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "National University of Singapore",
        "aff_unique_dep": "Dept. of Computer Science",
        "aff_unique_url": "https://www.nus.edu.sg",
        "aff_unique_abbr": "NUS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "9341699",
        "title": "Gimme Signals: Discriminative signal encoding for multimodal activity recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a simple, yet effective and flexible method for action recognition supporting multiple sensor modalities. Multivariate signal sequences are encoded in an image and are then classified using a recently proposed EfficientNet CNN architecture. Our focus was to find an approach that generalizes well across different sensor modalities without specific adaptions while still achieving good results. We apply our method to 4 action recognition datasets containing skeleton sequences, inertial and motion capturing measurements as well as Wi-Fi fingerprints that range up to 120 action classes. Our method defines the current best CNN-based approach on the NTU RGB+D 120 dataset, lifts the state of the art on the ARIL Wi-Fi dataset by +6.8%, improves the UTD-MHAD inertial baseline by +14.4%, the UTD-MHAD skeleton baseline by +0.5% and achieves 96.1% on the Simitate motion capturing data (80/20 split). We further demonstrate experiments on both, modality fusion on a signal level and signal reduction to prevent the representation from overloading.",
        "primary_area": "",
        "author": "Raphael Memmesheimer;Nick Theisen;Dietrich Paulus;Raphael Memmesheimer;Nick Theisen;Dietrich Paulus",
        "authorids": "/37085706250;/37088405291;/37297934300;/37085706250;/37088405291;/37297934300",
        "aff": "Active Vision Group, Institute for Computational Visualistics, University of Koblenz-Landau, Germany; Active Vision Group, Institute for Computational Visualistics, University of Koblenz-Landau, Germany; Active Vision Group, Institute for Computational Visualistics, University of Koblenz-Landau, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341699/",
        "gs_citation": 65,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6264705801254769518&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Koblenz-Landau",
        "aff_unique_dep": "Institute for Computational Visualistics",
        "aff_unique_url": "https://www.uni-koblenz-landau.de",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9340642",
        "title": "Global Localization Over 2D Floor Plans with Free-Space Density Based on Depth Information",
        "track": "main",
        "status": "Poster",
        "abstract": "Many applications with mobile robots require self-localization in indoor maps. While such maps can be previously generated by SLAM strategies, there are various localization approaches that use 2D floor plans as reference input. In this paper, we present a localization strategy using floor plan as map, which is based on spatial density information computed from dense depth data of RGB-D cameras. We propose an interval-based model, called Interval Free-Space Density, that bounds the uncertainty of observations and minimizes the effects of movable objects in the environment. Our model was applied in a Monte Carlo Localization strategy and compared with traditional observation models. The results of experiments showed the robustness of the proposed method in single-camera and multi-camera experiments in home environments.",
        "primary_area": "",
        "author": "Renan Maffei;Diego Pittol;Mathias Mantelli;Edson Prestes;Mariana Kolberg;Renan Maffei;Diego Pittol;Mathias Mantelli;Edson Prestes;Mariana Kolberg",
        "authorids": "/38517935400;/37087009442;/37086185972;/37329961700;/37085470377;/38517935400;/37087009442;/37086185972;/37329961700;/37085470377",
        "aff": "Institute of Informatics, Universidade Federal do Rio Grande do Sul, Porto Alegre, Brazil; Institute of Informatics, Universidade Federal do Rio Grande do Sul, Porto Alegre, Brazil; Institute of Informatics, Universidade Federal do Rio Grande do Sul, Porto Alegre, Brazil; Institute of Informatics, Universidade Federal do Rio Grande do Sul, Porto Alegre, Brazil; Institute of Informatics, Universidade Federal do Rio Grande do Sul, Porto Alegre, Brazil",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340642/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15050262139737226313&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Universidade Federal do Rio Grande do Sul",
        "aff_unique_dep": "Institute of Informatics",
        "aff_unique_url": "https://www.ufrgs.br",
        "aff_unique_abbr": "UFRGS",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Porto Alegre",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Brazil"
    },
    {
        "id": "9340715",
        "title": "Globally optimal consensus maximization for robust visual inertial localization in point and line map",
        "track": "main",
        "status": "Poster",
        "abstract": "Map based visual inertial localization is a crucial step to reduce the drift in state estimation of mobile robots. The underlying problem for localization is to estimate the pose from a set of 3D-2D feature correspondences, of which the main challenge is the presence of outliers, especially in changing environment. In this paper, we propose a robust solution based on efficient global optimization of the consensus maximization problem, which is insensitive to high percentage of outliers. We first introduce translation invariant measurements (TIMs) for both points and lines to decouple the consensus maximization problem into rotation and translation subproblems, allowing for a two-stage solver with reduced search space. Then we show that (i) the rotation can be estimated by minimizing TIMs using only 1-dimensional branch-and-bound (BnB), (ii) the translation can be estimated by running 1-dimensional search for each of the three axes with prioritized progressive voting. Compared with the popular randomized solver, our solver achieves deterministic global convergence without requiring an initial value. Furthermore, ours is exponentially faster compared with existing BnB based methods. Finally, our experiments on both simulation and real-world datasets demonstrate that the proposed method gives accurate pose estimation even in the presence of 90% outliers (only 2 inliers).",
        "primary_area": "",
        "author": "Yanmei Jiao;Yue Wang;Bo Fu;Qimeng Tan;Lei Chen;Minhang Wang;Shoudong Huang;Rong Xiong;Yanmei Jiao;Yue Wang;Bo Fu;Qimeng Tan;Lei Chen;Minhang Wang;Shoudong Huang;Rong Xiong",
        "authorids": "/37086475262;/37072299700;/37087325170;/37086355678;/37087325307;/37088662584;/37421307400;/37271511300;/37086475262;/37072299700;/37087325170;/37086355678;/37087325307;/37088662584;/37421307400;/37271511300",
        "aff": "State Key Laboratory of Industrial Control and Technology, Zhejiang University, Hangzhou, P.R. China; State Key Laboratory of Industrial Control and Technology, Zhejiang University, Hangzhou, P.R. China; State Key Laboratory of Industrial Control and Technology, Zhejiang University, Hangzhou, P.R. China; Beijing Key Laboratory of Intelligent Space Robotic System Technology and Applications, Beijing Institute of Spacecraft System Engineering, Beijing, P.R. China; Beijing Key Laboratory of Intelligent Space Robotic System Technology and Applications, Beijing Institute of Spacecraft System Engineering, Beijing, P.R. China; Minhang Wang is with the Application Lab, Huawei Incorporated Company, P.R. China; Shoudong Huang is with the Center for Autonomous Systems (CAS), the University of Technology, Sydney, Australia; State Key Laboratory of Industrial Control and Technology, Zhejiang University, Hangzhou, P.R. China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340715/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8645342105646266911&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;1;1;2;3;0",
        "aff_unique_norm": "Zhejiang University;Beijing Institute of Spacecraft System Engineering;Huawei Incorporated Company;University of Technology, Sydney",
        "aff_unique_dep": "State Key Laboratory of Industrial Control and Technology;Beijing Key Laboratory of Intelligent Space Robotic System Technology and Applications;Application Lab;Center for Autonomous Systems (CAS)",
        "aff_unique_url": "http://www.zju.edu.cn;;https://www.huawei.com;https://www.uts.edu.au",
        "aff_unique_abbr": "ZJU;;Huawei;UTS",
        "aff_campus_unique_index": "0;0;0;1;1;3;0",
        "aff_campus_unique": "Hangzhou;Beijing;;Sydney",
        "aff_country_unique_index": "0;0;0;0;0;0;1;0",
        "aff_country_unique": "China;Australia"
    },
    {
        "id": "9340979",
        "title": "GndNet: Fast Ground Plane Estimation and Point Cloud Segmentation for Autonomous Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "Ground plane estimation and ground point segmentation is a crucial precursor for many applications in robotics and intelligent vehicles like navigable space detection and occupancy grid generation, 3D object detection, point cloud matching for localization and registration for mapping. In this paper, we present GndNet, a novel end-to-end approach that estimates the ground plane elevation information in a grid-based representation and segments the ground points simultaneously in real-time. GndNet uses PointNet and Pillar Feature Encoding network to extract features and regresses ground height for each cell of the grid. We augment the SemanticKITTI dataset to train our network. We demonstrate qualitative and quantitative evaluation of our results for ground elevation estimation and semantic segmentation of point cloud. GndNet establishes a new state-of-the-art, achieves a run-time of 55Hz for ground plane estimation and ground point segmentation.",
        "primary_area": "",
        "author": "Anshul Paigwar;\u00d6zg\u00fcr Erkent;David Sierra-Gonzalez;Christian Laugier;Anshul Paigwar;\u00d6zg\u00fcr Erkent;David Sierra-Gonzalez;Christian Laugier",
        "authorids": "/37085996873;/38132645500;/37088636930;/37273327000;/37085996873;/38132645500;/37088636930;/37273327000",
        "aff": "Univ. Grenoble Alpes, Inria, Grenoble, France; Univ. Grenoble Alpes, Inria, Grenoble, France; Univ. Grenoble Alpes, Inria, Grenoble, France; Univ. Grenoble Alpes, Inria, Grenoble, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340979/",
        "gs_citation": 102,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6309216954226953597&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Universite Grenoble Alpes",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.univ-grenoble-alpes.fr",
        "aff_unique_abbr": "UGA",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Grenoble",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9341770",
        "title": "Go-CHART: A miniature remotely accessible self-driving car robot",
        "track": "main",
        "status": "Poster",
        "abstract": "The Go-CHART is a four-wheel, skid-steer robot that resembles a 1:28 scale standard commercial sedan. It is equipped with an onboard sensor suite and both onboard and external computers that replicate many of the sensing and computation capabilities of a full-size autonomous vehicle. The Go-CHART can autonomously navigate a small-scale traffic testbed, responding to its sensor input wiwithth programmed controllers. Alternatively, it can be remotely driven by a user who views the testbed through the robot's four camera feeds, which facilitates safe, controlled experiments on driver interactions with driverless vehicles. We demonstrate the Go-CHART's ability to perform lane tracking and detection of traffic signs, traffic signals, and other Go-CHARTs in real-time, utilizing an external GPU that runs computationally intensive computer vision and deep learning algorithms.",
        "primary_area": "",
        "author": "Shenbagaraj Kannapiran;Spring Berman;Shenbagaraj Kannapiran;Spring Berman",
        "authorids": "/37088690274;/37583148200;/37088690274;/37583148200",
        "aff": "Transport and Energy, School for Engineering of Matter, Arizona State University (ASU), Tempe, AZ, USA; Transport and Energy, School for Engineering of Matter, Arizona State University (ASU), Tempe, AZ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341770/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16379131357443155948&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Arizona State University",
        "aff_unique_dep": "School for Engineering of Matter, Transport and Energy",
        "aff_unique_url": "https://www.asu.edu",
        "aff_unique_abbr": "ASU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Tempe",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341722",
        "title": "Goal-driven variable admittance control for robot manual guidance",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper we address variable admittance control for human-robot physical interaction in manual guidance applications. In the proposed solution, the parameters of the admittance filter can change not only as a function of the current state of motion (i.e. whether the human guiding the robot ia accelerating or decelerating) but also with reference to a predefined goal position. The human is in fact gently guided towards the goal along some curved paths, where the damping is conveniently scaled in order to accommodate the motion towards the goal position. The algorithm also allows the human to reach goals that he/she cannot directly see because for example the transported object is bulky and obstructs the worker view. The performance of the proposed controller are evaluated by means of point to point cooperative motions with multiple volunteers using an ABB IRB140 robot.",
        "primary_area": "",
        "author": "Davide Bazzi;Miriam Lapertosa;Andrea Maria Zanchettin;Paolo Rocco;Davide Bazzi;Miriam Lapertosa;Andrea Maria Zanchettin;Paolo Rocco",
        "authorids": "/37086937228;/37088690906;/37546427600;/37274178600;/37086937228;/37088690906;/37546427600;/37274178600",
        "aff": "Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milano, Italy; Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milano, Italy; Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milano, Italy; Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milano, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341722/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6153111461491247216&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Politecnico di Milano",
        "aff_unique_dep": "Dipartimento di Elettronica, Informazione e Bioingegneria",
        "aff_unique_url": "https://www.polimi.it",
        "aff_unique_abbr": "Politecnico di Milano",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Milano",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9340863",
        "title": "Going Cognitive: A Demonstration of the Utility of Task-General Cognitive Architectures for Adaptive Robotic Task Performance",
        "track": "main",
        "status": "Poster",
        "abstract": "It has been claimed that a main advantage of cognitive architectures (compared to other types of specialized robotic architectures) is that they are task-general and can thus learn to perform any task as long as they have the right perceptual and action primitives. In this paper, we provide empirical evidence for this claim by directly comparing a high-performing custom robotic architecture developed for the standardized robotic \"FetchIt!\" challenge task to a hybrid cognitive robotic architecture that allows for online one-shot task learning and task modifications through natural language instructions. The results show that there is no disadvantage of running the hybrid architecture (i.e., no significant difference in overall performance or computational overhead compared to the custom architecture) while adding the flexibility of online one-shot task instruction and modification not available in the custom architecture.",
        "primary_area": "",
        "author": "Tyler Frasca;Zhao Han;Jordan Allspaw;Holly Yanco;Matthias Scheutz;Tyler Frasca;Zhao Han;Jordan Allspaw;Holly Yanco;Matthias Scheutz",
        "authorids": "/37088689869;/37086803826;/37085757128;/37282462100;/37269589600;/37088689869;/37086803826;/37085757128;/37282462100;/37269589600",
        "aff": "Tufts University, Boston, MA, USA; University of Massachusetts Lowell, Lowell, MA, USA; University of Massachusetts Lowell, Lowell, MA, USA; University of Massachusetts Lowell, Lowell, MA, USA; Tufts University, Boston, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340863/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1122087161083557140&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;0",
        "aff_unique_norm": "Tufts University;University of Massachusetts Lowell",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.tufts.edu;https://www.uml.edu",
        "aff_unique_abbr": "Tufts;UMass Lowell",
        "aff_campus_unique_index": "0;1;1;1;0",
        "aff_campus_unique": "Boston;Lowell",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341237",
        "title": "Graduated Assignment Graph Matching for Realtime Matching of Image Wireframes",
        "track": "main",
        "status": "Poster",
        "abstract": "We present an algorithm for the realtime matching of wireframe extractions in pairs of images. Here we treat extracted wireframes as graphs and propose a simplified Graduated Assignment algorithm to use with this problem. Using this algorithm we achieve a 30% accuracy improvement over the baseline method. We show that, for this problem, the simplified Graduated Assignment algorithm can achieve realtime performance without a significant drop in accuracy as compared to the standard Graduated Assignment algorithm. We further demonstrate a method of utilizing this simplified Graduated Assignment algorithm for achieving a similar real-time improvement in the matching quality of standard features without wireframe detection.",
        "primary_area": "",
        "author": "Joseph Menke;Allen Y. Yang;Joseph Menke;Allen Y. Yang",
        "authorids": "/37085615319;/37273113500;/37085615319;/37273113500",
        "aff": "",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341237/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=659145957925925693&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4
    },
    {
        "id": "9341668",
        "title": "Graph Neural Networks for Decentralized Multi-Robot Path Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Effective communication is key to successful, decentralized, multi-robot path planning. Yet, it is far from obvious what information is crucial to the task at hand, and how and when it must be shared among robots. To side-step these issues and move beyond hand-crafted heuristics, we propose a combined model that automatically synthesizes local communication and decision-making policies for robots navigating in constrained workspaces. Our architecture is composed of a convolutional neural network (CNN) that extracts adequate features from local observations, and a graph neural network (GNN) that communicates these features among robots. We train the model to imitate an expert algorithm, and use the resulting model online in decentralized planning involving only local communication and local observations. We evaluate our method in simulations by navigating teams of robots to their destinations in 2D cluttered workspaces. We measure the success rates and sum of costs over the planned paths. The results show a performance close to that of our expert algorithm, demonstrating the validity of our approach. In particular, we show our model's capability to generalize to previously unseen cases (involving larger environments and larger robot teams).",
        "primary_area": "",
        "author": "Qingbiao Li;Fernando Gama;Alejandro Ribeiro;Amanda Prorok;Qingbiao Li;Fernando Gama;Alejandro Ribeiro;Amanda Prorok",
        "authorids": "/37088524830;/38666302800;/37266493600;/37542741000;/37088524830;/38666302800;/37266493600;/37542741000",
        "aff": "Department of Computer Science and Technology, University of Cambridge, Cambridge, United Kingdom; Department of Electrical and Systems Engineering, University of Pennsylvania, Philadelphia, USA; Department of Electrical and Systems Engineering, University of Pennsylvania, Philadelphia, USA; Department of Computer Science and Technology, University of Cambridge, Cambridge, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341668/",
        "gs_citation": 330,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2744586364283666076&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "University of Cambridge;University of Pennsylvania",
        "aff_unique_dep": "Department of Computer Science and Technology;Department of Electrical and Systems Engineering",
        "aff_unique_url": "https://www.cam.ac.uk;https://www.upenn.edu",
        "aff_unique_abbr": "Cambridge;UPenn",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Cambridge;Philadelphia",
        "aff_country_unique_index": "0;1;1;0",
        "aff_country_unique": "United Kingdom;United States"
    },
    {
        "id": "9340843",
        "title": "Graph-based Hierarchical Knowledge Representation for Robot Task Transfer from Virtual to Physical World",
        "track": "main",
        "status": "Poster",
        "abstract": "We study the hierarchical knowledge transfer problem using a cloth-folding task, wherein the agent is first given a set of human demonstrations in the virtual world using an Oculus Headset, and later transferred and validated on a physical Baxter robot. We argue that such an intricate robot task transfer across different embodiments is only realizable if an abstract and hierarchical knowledge representation is formed to facilitate the process, in contrast to prior literature of sim2real in a reinforcement learning setting. Specifically, the knowledge in both the virtual and physical worlds are measured by information entropy built on top of a graph-based representation, so that the problem of task transfer becomes the minimization of the relative entropy between the two worlds. An And-Or-Graph (AOG) is introduced to represent the knowledge, induced from the human demonstrations performed across six virtual scenarios inside the Virtual Reality (VR). During the transfer, the success of a physical Baxter robot platform across all six tasks demonstrates the efficacy of the graph-based hierarchical knowledge representation.",
        "primary_area": "",
        "author": "Zhenliang Zhang;Yixin Zhu;Song-Chun Zhu;Zhenliang Zhang;Yixin Zhu;Song-Chun Zhu",
        "authorids": "/37086007743;/37086172463;/37281407500;/37086007743;/37086172463;/37281407500",
        "aff": "Tencent; Statistics Department, UCLA Center for Vision, Cognition, Learning, and Autonomy (VCLA); Statistics Department, UCLA Center for Vision, Cognition, Learning, and Autonomy (VCLA)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340843/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7281979090760692197&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Tencent Holdings Limited;University of California, Los Angeles",
        "aff_unique_dep": ";Statistics Department",
        "aff_unique_url": "https://www.tencent.com;https://www.ucla.edu",
        "aff_unique_abbr": "Tencent;UCLA",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Los Angeles",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9341056",
        "title": "Grasping Detection Network with Uncertainty Estimation for Confidence-Driven Semi-Supervised Domain Adaptation",
        "track": "main",
        "status": "Poster",
        "abstract": "Data-efficient domain adaptation with only a few labelled data is desired for many robotic applications, e.g., in grasping detection, the inference skill learned from a grasping dataset is not universal enough to directly apply on various other daily/industrial applications. This paper presents an approach enabling the easy domain adaptation through a novel grasping detection network with confidence-driven semi-supervised learning, where these two components deeply interact with each other. The proposed grasping detection network specially provides a prediction uncertainty estimation mechanism by leveraging on Feature Pyramid Network (FPN), and the mean-teacher semi-supervised learning utilizes such uncertainty information to emphasizing the consistency loss only for those unlabelled data with high confidence, which we referred it as the confidence-driven mean teacher. This approach largely prevents the student model to learn the incorrect/harmful information from the consistency loss, which speeds up the learning progress and improves the model accuracy. Our results show that the proposed network can achieve high success rate on the Cornell grasping dataset, and for domain adaptation with very limited data, the confidence- driven mean teacher outperforms the original mean teacher and direct training by more than 10% in evaluation loss especially for avoiding the overfitting and model diverging.",
        "primary_area": "",
        "author": "Haiyue Zhu;Yiting Li;Fengjun Bai;Wenjie Chen;Xiaocong Li;Jun Ma;Chek Sing Teo;Pey Yuen Tao;Wei Lin;Haiyue Zhu;Yiting Li;Fengjun Bai;Wenjie Chen;Xiaocong Li;Jun Ma;Chek Sing Teo;Pey Yuen Tao;Wei Lin",
        "authorids": "/37085409877;/37088689764;/37088689229;/37421822700;/37085473002;/37085728817;/37288627000;/37088690577;/37278115500;/37085409877;/37088689764;/37088689229;/37421822700;/37085473002;/37085728817;/37288627000;/37088690577;/37278115500",
        "aff": "Agency for Science, Technology and Research, Mechatronics Group, Singapore Institute of Manufacturing Technology (SIMTech), Singapore; Department of Electrical and Computer Engineering, National University of Singapore, Singapore; Agency for Science, Technology and Research, Advanced Robotics Application Group, Advanced Remanufacturing and Technology Centre (ARTC), Singapore; School of Electrical Engineering and Automation, Anhui University, Hefei, China; Agency for Science, Technology and Research, Mechatronics Group, Singapore Institute of Manufacturing Technology (SIMTech), Singapore; Department of Electrical and Computer Engineering, National University of Singapore, Singapore; Agency for Science, Technology and Research, Mechatronics Group, Singapore Institute of Manufacturing Technology (SIMTech), Singapore; Agency for Science, Technology and Research, Mechatronics Group, Singapore Institute of Manufacturing Technology (SIMTech), Singapore; Agency for Science, Technology and Research, Mechatronics Group, Singapore Institute of Manufacturing Technology (SIMTech), Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341056/",
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1493245587534439941&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;1;0;2;0;1;0;0;0",
        "aff_unique_norm": "Agency for Science, Technology and Research;National University of Singapore;Anhui University",
        "aff_unique_dep": "Mechatronics Group;Department of Electrical and Computer Engineering;School of Electrical Engineering and Automation",
        "aff_unique_url": "https://www.a-star.edu.sg;https://www.nus.edu.sg;http://www.ahu.edu.cn",
        "aff_unique_abbr": "A*STAR;NUS;AHU",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Hefei",
        "aff_country_unique_index": "0;0;0;1;0;0;0;0;0",
        "aff_country_unique": "Singapore;China"
    },
    {
        "id": "9341373",
        "title": "Gripping a Kitchen Knife on the Cutting Board",
        "track": "main",
        "status": "Poster",
        "abstract": "Despite more than three decades of grasping research, many tools in our everyday life still pose a serious challenge for a robotic hand to grip. The level of dexterity for such a maneuver is surprisingly \"high\" that its execution may require a combination of closed loop controls and finger gaits. This paper studies the task of an anthropomorphic hand driven by a robotic arm to pick up and firmly hold a kitchen knife initially resting on the cutting board. In the first phase, the hand grasps the knife's handle at two antipodal points and then pivots it about the knife's point in contact with the board to leverage the latter's support. Desired contact forces exerted by the two holding soft fingers are calculated and used for dynamic control of both the hand and the arm. In the second phase, a sequence of gaits for all the five fingers is performed quasi-statically to reach a power grasp on the knife's handle, which remains still during the period. Simulation has been performed using models of the Shadow Hand and the UR10 Arm.",
        "primary_area": "",
        "author": "Yuechuan Xue;Yan-Bin Jia;Yuechuan Xue;Yan-Bin Jia",
        "authorids": "/37086455176;/37273296400;/37086455176;/37273296400",
        "aff": "Department of Computer Science, Iowa State University, IA, USA; Department of Computer Science, Iowa State University, IA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341373/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18050532465700709572&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Iowa State University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.iastate.edu",
        "aff_unique_abbr": "ISU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340996",
        "title": "Ground Texture Based Localization: Do We Need to Detect Keypoints?",
        "track": "main",
        "status": "Poster",
        "abstract": "Localization using ground texture images recorded with a downward-facing camera is a promising approach to achieve reliable high-accuracy vehicle positioning. A common way to accomplish the task is to focus on prominent features of the ground texture such as stones and cracks. Our results indicate that with an approximately known camera pose it is sufficient to use arbitrary ground regions, i.e. extracting features at random positions without significant loss in localization performance. Additionally, we propose a real-time capable CPU-only localization method based on this idea, and suggest possible improvements for further research.",
        "primary_area": "",
        "author": "Jan Fabian Schmid;Stephan F. Simon;Rudolf Mester;Jan Fabian Schmid;Stephan F. Simon;Rudolf Mester",
        "authorids": "/37088507186;/37342166200;/37266486000;/37088507186;/37342166200;/37266486000",
        "aff": "CS Dept., VSI Lab, Goethe University, Frankfurt am Main, Germany; Robert Bosch GmbH, Hildesheim, Germany; CS Dept., Norwegian Open AI Lab, NTNU, Trondheim, Norway",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340996/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1381838798642064199&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Goethe University;Robert Bosch GmbH;Norwegian University of Science and Technology",
        "aff_unique_dep": "CS Dept.;;Department of Computer Science",
        "aff_unique_url": "https://www.uni-frankfurt.de;https://www.bosch.com;https://www.ntnu.edu",
        "aff_unique_abbr": "Goethe U;Bosch;NTNU",
        "aff_campus_unique_index": "0;2",
        "aff_campus_unique": "Frankfurt am Main;;Trondheim",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "Germany;Norway"
    },
    {
        "id": "9341115",
        "title": "Guaranteed Parameter Estimation of Hunt-Crossley Model with Chebyshev Polynomial Approximation for Teleoperation",
        "track": "main",
        "status": "Poster",
        "abstract": "In haptic time delayed teleoperation as the time delay from the communication channel increases, teleoperation system stability and performance degrade. To increase performance and provide better stability margins, various estimation methods and observers have been implemented in literature to more accurately capture the force exerted by the remote system. Previously, solutions focused on environment force estimation methods that primarily rely on linearization of the Hunt-Crossley (HC) contact model, which has limiting assumptions for use. This work addresses the shortcomings of the aforementioned methods by investigating alternative HC parameter estimation techniques. A new application of Chebyshev polynomial approximation for adaptive parameter estimation of the HC model is proposed. This approximation is compared to current linearization methods as well as nonlinear estimation methods that are not well covered in literature. Moreover, the Chebyshev approximation is used in a new estimation approach that provides control via backstepping with adaptive parameter estimation using Lyapunov methods. This method reduces excitation requirements by using nonlinear swapping and the data accumulation concept to guarantee parameter convergence. A simulated full teleoperation system with time delay demonstrates the effectiveness of this approach.",
        "primary_area": "",
        "author": "Daniel Budolak;Alexander Leonessa;Daniel Budolak;Alexander Leonessa",
        "authorids": "/37088690722;/37333074000;/37088690722;/37333074000",
        "aff": "Department of Mechanical Engineering, Virginia Tech, Blacksburg, VA, USA; Department of Mechanical Engineering, Virginia Tech, Blacksburg, VA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341115/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17480754201818949374&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Virginia Tech",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.vt.edu",
        "aff_unique_abbr": "VT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Blacksburg",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340987",
        "title": "HAMLET: A Hierarchical Multimodal Attention-based Human Activity Recognition Algorithm",
        "track": "main",
        "status": "Poster",
        "abstract": "To fluently collaborate with people, robots need the ability to recognize human activities accurately. Although modern robots are equipped with various sensors, robust human activity recognition (HAR) still remains a challenging task for robots due to difficulties related to multimodal data fusion. To address these challenges, in this work, we introduce a deep neural network-based multimodal HAR algorithm, HAMLET. HAMLET incorporates a hierarchical architecture, where the lower layer encodes spatio-temporal features from unimodal data by adopting a multi-head self-attention mechanism. We develop a novel multimodal attention mechanism for disentangling and fusing the salient unimodal features to compute the multimodal features in the upper layer. Finally, multimodal features are used in a fully connect neural-network to recognize human activities. We evaluated our algorithm by comparing its performance to several state-of-the-art activity recognition algorithms on three human activity datasets. The results suggest that HAMLET outperformed all other evaluated baselines across all datasets and metrics tested, with the highest top-1 accuracy of 95.12% and 97.45% on the UTD-MHAD [1] and the UT-Kinect [2] datasets respectively, and F1-score of 81.52% on the UCSD-MIT [3] dataset. We further visualize the unimodal and multimodal attention maps, which provide us with a tool to interpret the impact of attention mechanisms concerning HAR.",
        "primary_area": "",
        "author": "Md Mofijul Islam;Tariq Iqbal;Md Mofijul Islam;Tariq Iqbal",
        "authorids": "/37089261522;/37399391100;/37089261522;/37399391100",
        "aff": "Dept. of Engineering Systems and Environment, Univ. of Virginia, USA; Dept. of Engineering Systems and Environment, Univ. of Virginia, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340987/",
        "gs_citation": 104,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4603326722837262103&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Virginia",
        "aff_unique_dep": "Department of Engineering Systems and Environment",
        "aff_unique_url": "https://www.virginia.edu",
        "aff_unique_abbr": "UVA",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340757",
        "title": "HD Map Change Detection with Cross-Domain Deep Metric Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "High-definition (HD) maps are emerging as an essential tool for autonomous driving since they provide high-precision semantic information about the physical environment. To function as a reliable source of map information, HD maps must be constantly updated with changes that occur to the state of the road. In this paper, we propose a novel framework for HD map change detection that can be used to maintain an up-to-date HD map. More specifically, we design our HD map change detection algorithm based on deep metric learning, providing a unified framework that directly maps an input image to estimated probabilities of HD map changes. To reduce the discrepancy between input domains, i.e., camera image and HD map, we propose an effective learning scheme for metric space based on adversarial learning. Finally, we augment our framework with a pixel-level local change detector that specifies the region of changes in the image. We verify the effectiveness of our framework by evaluating it on a city-scale urban HD map dataset. Experimental results show that our method can robustly detect changes against noises due to dynamic objects and error in vehicle poses.",
        "primary_area": "",
        "author": "Minhyeok Heo;Jiwon Kim;Sujung Kim;Minhyeok Heo;Jiwon Kim;Sujung Kim",
        "authorids": "/37086074861;/37088688416;/37088657904;/37086074861;/37088688416;/37088657904",
        "aff": "Autonomous Driving Group, NAVER LABS; Autonomous Driving Group, NAVER LABS; Autonomous Driving Group, NAVER LABS",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340757/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17969354464035545035&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "NAVER LABS",
        "aff_unique_dep": "Autonomous Driving Group",
        "aff_unique_url": "https://www.naverlabs.com",
        "aff_unique_abbr": "NAVER LABS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9341316",
        "title": "Hand-Object Contact Force Synthesis for Manipulating Objects by Exploiting Environment",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we study the problem of computing grasping forces for quasi-static manipulation of large and heavy objects, by exploiting object-environment contacts. We present a general formulation of this problem as a Second-Order Cone Program (SOCP) that considers (i) contact friction constraints at the object-manipulator contacts and object-environment contacts, (ii) force/moment equilibrium constraints, and (iii) manipulator joint torque constraints. The SOCP formulation implies that the optimal grasping forces for manipulating objects with the help of the environment can be computed efficiently. Different optimization objectives like minimizing contact forces at the object-manipulator contacts or minimizing joint torques of manipulators can be considered. We evaluated our method by simulations of single-handed and dual-handed manipulation scenarios.",
        "primary_area": "",
        "author": "Aditya Patankar;Amin Fakhari;Nilanjan Chakraborty;Aditya Patankar;Amin Fakhari;Nilanjan Chakraborty",
        "authorids": "/312854643498475;/37088377881;/37314871600;/312854643498475;/37088377881;/37314871600",
        "aff": "Department of Mechanical Engineering, Stony Brook University, Stony Brook, NY, USA; Department of Mechanical Engineering, Stony Brook University, Stony Brook, NY, USA; Department of Mechanical Engineering, Stony Brook University, Stony Brook, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341316/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15038224064397567942&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Stony Brook University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.stonybrook.edu",
        "aff_unique_abbr": "SBU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Stony Brook",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340770",
        "title": "Haptic Knowledge Transfer Between Heterogeneous Robots using Kernel Manifold Alignment",
        "track": "main",
        "status": "Poster",
        "abstract": "Humans learn about object properties using multiple modes of perception. Recent advances show that robots can use non-visual sensory modalities (i.e., haptic and tactile sensory data) coupled with exploratory behaviors (i.e., grasping, lifting, pushing, dropping, etc.) for learning objects' properties such as shape, weight, material and affordances. However, non-visual sensory representations cannot be easily transferred from one robot to another, as different robots have different bodies and sensors. Therefore, each robot needs to learn its task-specific sensory models from scratch. To address this challenge, we propose a framework for knowledge transfer using kernel manifold alignment (KEMA) that enables source robots to transfer haptic knowledge about objects to a target robot. The idea behind our approach is to learn a common latent space from multiple robots' feature spaces produced by respective sensory data while interacting with objects. To test the method, we used a dataset in which 3 simulated robots interacted with 25 objects and showed that our framework speeds up haptic object recognition and allows novel object recognition.",
        "primary_area": "",
        "author": "Gyan Tatiya;Yash Shukla;Michael Edegware;Jivko Sinapov;Gyan Tatiya;Yash Shukla;Michael Edegware;Jivko Sinapov",
        "authorids": "/37086934223;/37088490538;/37088690538;/37546531000;/37086934223;/37088490538;/37088690538;/37546531000",
        "aff": "Department of Computer Science, Tufts University; Department of Computer Science, Tufts University; Department of Computer Science, Tufts University; Department of Computer Science, Tufts University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340770/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9966780063835210244&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Tufts University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.tufts.edu",
        "aff_unique_abbr": "Tufts",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341128",
        "title": "Haptic Sequential Monte Carlo Localization for Quadrupedal Locomotion in Vision-Denied Scenarios",
        "track": "main",
        "status": "Poster",
        "abstract": "Continuous robot operation in extreme scenarios such as underground mines or sewers is difficult because exteroceptive sensors may fail due to fog, darkness, dirt or malfunction. So as to enable autonomous navigation in these kinds of situations, we have developed a type of proprioceptive localization which exploits the foot contacts made by a quadruped robot to localize against a prior map of an environment, without the help of any camera or LIDAR sensor. The proposed method enables the robot to accurately re-localize itself after making a sequence of contact events over a terrain feature. The method is based on Sequential Monte Carlo and can support both 2.5D and 3D prior map representations. We have tested the approach online and onboard the ANYmal quadruped robot in two different scenarios: the traversal of a custom built wooden terrain course and a wall probing and following task. In both scenarios, the robot is able to effectively achieve a localization match and to execute a desired pre-planned path. The method keeps the localization error down to 10 cm on feature rich terrain by only using its feet, kinematic and inertial sensing.",
        "primary_area": "",
        "author": "Russell Buchanan;Marco Camurri;Maurice Fallon;Russell Buchanan;Marco Camurri;Maurice Fallon",
        "authorids": "/37086700722;/37085638130;/37540365100;/37086700722;/37085638130;/37540365100",
        "aff": "Oxford Robotics Institute, University of Oxford, United Kingdom; Oxford Robotics Institute, University of Oxford, United Kingdom; Oxford Robotics Institute, University of Oxford, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341128/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4119917344080214814&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Oxford",
        "aff_unique_dep": "Oxford Robotics Institute",
        "aff_unique_url": "https://www.ox.ac.uk",
        "aff_unique_abbr": "Oxford",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Oxford",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9341192",
        "title": "HeatNet: Bridging the Day-Night Domain Gap in Semantic Segmentation with Thermal Images",
        "track": "main",
        "status": "Poster",
        "abstract": "The majority of learning-based semantic segmentation methods are optimized for daytime scenarios and favorable lighting conditions. Real-world driving scenarios, however, entail adverse environmental conditions such as nighttime illumination or glare which remain a challenge for existing approaches. In this work, we propose a multimodal semantic segmentation model that can be applied during daytime and nighttime. To this end, besides RGB images, we leverage thermal images, making our network significantly more robust. We avoid the expensive annotation of nighttime images by leveraging an existing daytime RGB-dataset and propose a teacher-student training approach that transfers the dataset's knowledge to the nighttime domain. We further adopt a domain adaptation method to align the learned feature spaces across the domains and propose a novel two-stage training scheme. Furthermore, due to a lack of thermal data for autonomous driving, we present a new dataset comprising over 20,000 time-synchronized and aligned RGB-thermal image pairs. In this context, we also present a novel target-less calibration method that allows for automatic robust extrinsic and intrinsic thermal camera calibration. Among others, we use our new dataset to show state-of-the-art results for nighttime semantic segmentation.",
        "primary_area": "",
        "author": "Johan Vertens;Jannik Z\u00fcrn;Wolfram Burgard;Johan Vertens;Jannik Z\u00fcrn;Wolfram Burgard",
        "authorids": "/37086088311;/37088687209;/37270485300;/37086088311;/37088687209;/37270485300",
        "aff": "University of Freiburg, Germany; University of Freiburg, Germany; Toyota Research Institute, Los Altos, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341192/",
        "gs_citation": 81,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11822779000034137185&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "University of Freiburg;Toyota Research Institute",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.uni-freiburg.de;https://www.tri.global",
        "aff_unique_abbr": "UoF;TRI",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Los Altos",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "Germany;United States"
    },
    {
        "id": "9341433",
        "title": "Heterogeneous Vehicle Routing and Teaming with Gaussian Distributed Energy Uncertainty",
        "track": "main",
        "status": "Poster",
        "abstract": "For robot swarms operating on complex missions in an uncertain environment, it is important that the decision-making algorithm considers both heterogeneity and uncertainty. This paper presents a stochastic programming framework for the vehicle routing problem with stochastic travel energy costs and heterogeneous vehicles and tasks. We represent the heterogeneity as linear constraints, estimate the uncertain energy cost through Gaussian process regression, formulate this stochasticity as chance constraints or stochastic recourse costs, and then solve the stochastic programs using branch and cut algorithms to minimize the expected energy cost. The performance and practicality are demonstrated through extensive computational experiments and a practical test case.",
        "primary_area": "",
        "author": "Bo Fu;William Smith;Denise Rizzo;Matthew Castanier;Kira Barton;Bo Fu;William Smith;Denise Rizzo;Matthew Castanier;Kira Barton",
        "authorids": "/37088689227;/37086013837;/37086013111;/37086006463;/37393918000;/37088689227;/37086013837;/37086013111;/37086006463;/37393918000",
        "aff": "University of Michigan, Ann Arbor, MI, USA; US Army CCDC Ground Vehicle Systems Center, Warren, MI, USA; US Army CCDC Ground Vehicle Systems Center, Warren, MI, USA; US Army CCDC Ground Vehicle Systems Center, Warren, MI, USA; University of Michigan, Ann Arbor, MI, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341433/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1207247621740352436&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;0",
        "aff_unique_norm": "University of Michigan;US Army CCDC Ground Vehicle Systems Center",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.umich.edu;",
        "aff_unique_abbr": "UM;",
        "aff_campus_unique_index": "0;1;1;1;0",
        "aff_campus_unique": "Ann Arbor;Warren",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341496",
        "title": "Hierarchical Reinforcement Learning Method for Autonomous Vehicle Behavior Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Behavioral decision making is an important aspect of autonomous vehicles (AV). In this work, we propose a behavior planning structure based on hierarchical reinforcement learning (HRL) which is capable of performing autonomous vehicle planning tasks in simulated environments with multiple sub-goals. In this hierarchical structure, the network is capable of 1) learning one task with multiple sub-goals simultaneously; 2) extracting attentions of states according to changing sub-goals during the learning process; 3) reusing the well-trained network of sub-goals for other tasks with the same sub-goals. A hybrid reward mechanism is designed for different hierarchical layers in the proposed HRL structure. Compared to traditional RL methods, our algorithm is more sample-efficient, since its modular design allows reusing the policies of sub-goals across similar tasks for various transportation scenarios. The results show that the proposed method converges to an optimal policy faster than traditional RL methods.",
        "primary_area": "",
        "author": "Zhiqian Qiao;Zachariah Tyree;Priyantha Mudalige;Jeff Schneider;John M. Dolan;Zhiqian Qiao;Zachariah Tyree;Priyantha Mudalige;Jeff Schneider;John M. Dolan",
        "authorids": "/37086488404;/37086812031;/37299435400;/37281084800;/37283756800;/37086488404;/37086812031;/37299435400;/37281084800;/37283756800",
        "aff": "Electrical and Computer Engineering, Carnegie Mellon University, Pittsburgh, USA; Research & Development, General Motors; Research & Development, General Motors; Faculties of The Robotics Institute, Carnegie Mellon University; Faculties of The Robotics Institute, Carnegie Mellon University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341496/",
        "gs_citation": 42,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15285618907338639593&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;0;0",
        "aff_unique_norm": "Carnegie Mellon University;General Motors",
        "aff_unique_dep": "Electrical and Computer Engineering;Research & Development",
        "aff_unique_url": "https://www.cmu.edu;https://www.gm.com",
        "aff_unique_abbr": "CMU;GM",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Pittsburgh;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341389",
        "title": "Hierarchical optimization Control of Redundant Manipulator for Robot-assisted Minimally Invasive Surgery",
        "track": "main",
        "status": "Poster",
        "abstract": "For the time varying optimization problem, the tracking error cannot converge to zero at the finite time because of the optimal solution changing over time. This paper proposes a novel varying parameter recurrent neural network (VPRNN) based hierarchical optimization of a 7-DoF surgical manipulator for Robot-Assisted Minimally Invasive Surgery (RAMIS), which guarantees task tracking, Remote Center of Motion (RCM) and manipulability index optimization. A theoretically grounded hierarchical optimization framework based is introduced to control multiple tasks based on their priority. Finally, the effectiveness of the proposed control strategy is demonstrated with both simulation and experimental results. The results show that the proposed VPRNN-based method can optimal three tasks at the same time and have better performance than previous work.",
        "primary_area": "",
        "author": "Yingbai Hu;Hang Su;Guang Chen;Giancarlo Ferrigno;Elena De Momi;Alois Knoll;Yingbai Hu;Hang Su;Guang Chen;Giancarlo Ferrigno;Elena De Momi;Alois Knoll",
        "authorids": "/37085749138;/37086423278;/38251904000;/37294130300;/37947344300;/37276234100;/37085749138;/37086423278;/38251904000;/37294130300;/37947344300;/37276234100",
        "aff": "Department of Informatics, Technical University of Munich, Munich, Germany; Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milano, Italy; College of Automotive Engineering, Tongji University, Shanghai, China; Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milano, Italy; Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milano, Italy; Department of Informatics, Technical University of Munich, Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341389/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11531885051631379926&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;1;1;0",
        "aff_unique_norm": "Technical University of Munich;Politecnico di Milano;Tongji University",
        "aff_unique_dep": "Department of Informatics;Dipartimento di Elettronica, Informazione e Bioingegneria;College of Automotive Engineering",
        "aff_unique_url": "https://www.tum.de;https://www.polimi.it;https://www.tongji.edu.cn",
        "aff_unique_abbr": "TUM;Politecnico di Milano;Tongji",
        "aff_campus_unique_index": "0;1;2;1;1;0",
        "aff_campus_unique": "Munich;Milano;Shanghai",
        "aff_country_unique_index": "0;1;2;1;1;0",
        "aff_country_unique": "Germany;Italy;China"
    },
    {
        "id": "9340968",
        "title": "High-Speed Catching by Multi-Vision Robot Hand",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose the \"multi-vision hand\", in which a number of small high-speed cameras are mounted on the robot hand of a common 7 degrees-of-freedom robot. Also, we propose visual-servoing control by using a multi-vision system that combines the multi-vision hand and external fixed high-speed cameras. The target task was ball catching motion, which requires high-speed operation. In the proposed catching control, the catch position of the ball, which is estimated by the external fixed high-speed cameras, is corrected by the multivision hand in real-time. In experiments, the catch operation was successfully implemented by correcting the catch position, thus confirming the effectiveness of the multi-vision hand system.",
        "primary_area": "",
        "author": "Masaki Sato;Akira Takahashi;Akio Namiki;Masaki Sato;Akira Takahashi;Akio Namiki",
        "authorids": "/37088686192;/37088686818;/37273962400;/37088686192;/37088686818;/37273962400",
        "aff": "Graduate School of Engineering, Chiba University, Chiba, Japan; Graduate School of Engineering, Chiba University, Chiba, Japan; Graduate School of Engineering, Chiba University, Chiba, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340968/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17323917686348361932&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Chiba University",
        "aff_unique_dep": "Graduate School of Engineering",
        "aff_unique_url": "https://www.chiba-u.ac.jp",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Chiba",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9341175",
        "title": "High-speed Hitting Grasping with Magripper, a Highly Backdrivable Gripper using Magnetic Gear and Plastic Deformation Control",
        "track": "main",
        "status": "Poster",
        "abstract": "In this study, Magripper, a highly backdrivable gripper, is developed to achieve high-speed hitting grasping executed seamlessly from reaching. The gripper is designed to achieve both high speed and environmental adaptability. The key element is backdrivability in terms of both hardware and control. In Magripper, a magnetic gear is introduced to passively absorb shock in the moment of contact as a means of hardware backdrivability, and backdrive control is implemented based on the Zener model. After developing a hitting grasping framework, high-speed hitting grasping tasks with a wood block, a wood cylinder, and a plastic coin are conducted using only servo control without sensors, such as cameras and tactile sensors. In particular, coin grasping with high-speed movement is very difficult because collisions with environmental objects such as the floor and desk, are likely, which may break a robot.",
        "primary_area": "",
        "author": "Satoshi Tanaka;Keisuke Koyama;Taku Senoo;Makoto Shimojo;Masatoshi Ishikawa;Satoshi Tanaka;Keisuke Koyama;Taku Senoo;Makoto Shimojo;Masatoshi Ishikawa",
        "authorids": "/37087104187;/37085489789;/37281649900;/37339828100;/37276508700;/37087104187;/37085489789;/37281649900;/37339828100;/37276508700",
        "aff": "Dept. of Information Physics and Computing, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Dept. of Systems Innovation, Graduate School of Engineering Science, Osaka University, Osaka, Japan; Dept. of Information Physics and Computing, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Dept. of Information Physics and Computing, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Dept. of Information Physics and Computing, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341175/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10131639613343688364&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "The University of Tokyo;Osaka University",
        "aff_unique_dep": "Dept. of Information Physics and Computing;Dept. of Systems Innovation, Graduate School of Engineering Science",
        "aff_unique_url": "https://www.u-tokyo.ac.jp;https://www.osaka-u.ac.jp",
        "aff_unique_abbr": "UTokyo;Osaka U",
        "aff_campus_unique_index": "0;1;0;0;0",
        "aff_campus_unique": "Tokyo;Osaka",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9341103",
        "title": "Highly Underactuated Radial Gripper for Automated Planar Grasping and Part Fixturing",
        "track": "main",
        "status": "Poster",
        "abstract": "Grasping can be conceptualized as the ability of an end-effector to temporarily attach or fixture an object to a manipulator-constraining all motion of the workpiece with respect to the end-effector's base frame. This seemingly simplistic action often requires excessive sensing, computation, or control to achieve with multi-fingered hands, which can be mitigated with underactuated mechanisms. In this work, we present the analysis of radial graspers for automated part fixturing and grasping in the plane with a design implementation of a single-actuator, 8-finger gripper. By leveraging a passively adaptable mechanism that is under-constrained pre-contact, the gripper conforms to arbitrary object geometries and locks post-contact as to provide form closure around the object. We also justify that 8 radially symmetric fingers with passive locking are sufficient to create robust form closure grasps on arbitrary planar objects. The underlying mechanism of the gripper is described in detail, with analysis of its highly underactuated nature, and the resulting form closure ability. We show with a wide variety of objects that the gripper is able to acquire robust grasps on all of them, and maintain maximal quality form closure on most objects, with each finger exerting equal grasp force within \u00b12.48 N.",
        "primary_area": "",
        "author": "Vatsal V. Patel;Andrew S. Morgan;Aaron M. Dollar;Vatsal V. Patel;Andrew S. Morgan;Aaron M. Dollar",
        "authorids": "/37086366220;/37086455182;/37604732600;/37086366220;/37086455182;/37604732600",
        "aff": "Department of Mechanical Engineering and Materials Science, Yale University, USA; Department of Mechanical Engineering and Materials Science, Yale University, USA; Department of Mechanical Engineering and Materials Science, Yale University, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341103/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17837919609427719385&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Yale University",
        "aff_unique_dep": "Department of Mechanical Engineering and Materials Science",
        "aff_unique_url": "https://www.yale.edu",
        "aff_unique_abbr": "Yale",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341491",
        "title": "Hindsight for Foresight: Unsupervised Structured Dynamics Models from Physical Interaction",
        "track": "main",
        "status": "Poster",
        "abstract": "A key challenge for an agent learning to interact with the world is to reason about physical properties of objects and to foresee their dynamics under the effect of applied forces. In order to scale learning through interaction to many objects and scenes, robots should be able to improve their own performance from real-world experience without requiring human supervision. To this end, we propose a novel approach for modeling the dynamics of a robot's interactions directly from unlabeled 3D point clouds and images. Unlike previous approaches, our method does not require ground-truth data associations provided by a tracker or any pre-trained perception network. To learn from unlabeled real-world interaction data, we enforce consistency of estimated 3D clouds, actions and 2D images with observed ones. Our joint forward and inverse network learns to segment a scene into salient object parts and predicts their 3D motion under the effect of applied actions. Moreover, our object-centric model outputs action-conditioned 3D scene flow, object masks and 2D optical flow as emergent properties. Our extensive evaluation both in simulation and with real-world data demonstrates that our formulation leads to effective, interpretable models that can be used for visuomotor control and planning. Videos, code and dataset are available at http://hind4sight.cs.uni-freiburg.de.",
        "primary_area": "",
        "author": "Iman Nematollahi;Oier Mees;Lukas Hermann;Wolfram Burgard;Iman Nematollahi;Oier Mees;Lukas Hermann;Wolfram Burgard",
        "authorids": "/37086495410;/37086205346;/37088504270;/37270485300;/37086495410;/37086205346;/37088504270;/37270485300",
        "aff": "Toyota Research Institute, Los Altos, USA; Toyota Research Institute, Los Altos, USA; Toyota Research Institute, Los Altos, USA; Toyota Research Institute, Los Altos, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341491/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8875662101127708836&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Toyota Research Institute",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.tri.global",
        "aff_unique_abbr": "TRI",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Los Altos",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341284",
        "title": "HouseExpo: A Large-scale 2D Indoor Layout Dataset for Learning-based Algorithms on Mobile Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "As one of the most promising areas, mobile robots draw much attention these years. Current work in this field is often evaluated in a few manually designed scenarios, due to the lack of a common experimental platform. Meanwhile, with the recent development of deep learning techniques, some researchers attempt to apply learning-based methods to mobile robot tasks, which requires a substantial amount of data. To satisfy the underlying demand, in this paper we build HouseExpo, a large-scale indoor layout dataset containing 35, 126 2D floor plans including 252, 550 rooms in total. Together we develop PseudoSLAM, a lightweight and efficient simulation platform to accelerate the data generation procedure, thereby speeding up the training process. In our experiments, we build models to tackle obstacle avoidance and autonomous exploration from a learning perspective in simulation as well as real-world experiments to verify the effectiveness of our simulator and dataset. All the data and codes are available online and we hope HouseExpo and PseudoSLAM can feed the need for data and benefit the whole community.",
        "primary_area": "",
        "author": "Tingguang Li;Danny Ho;Chenming Li;Delong Zhu;Chaoqun Wang;Max Q.-H. Meng;Tingguang Li;Danny Ho;Chenming Li;Delong Zhu;Chaoqun Wang;Max Q.-H. Meng",
        "authorids": "/37086353859;/37086452950;/37087243125;/37086137408;/37085492449;/37274117000;/37086353859;/37086452950;/37087243125;/37086137408;/37085492449;/37274117000",
        "aff": "Department of Electronic Engineering, The Chinese University of Hong Kong, Hong Kong SAR, China; Department of Electronic Engineering, The Chinese University of Hong Kong, Hong Kong SAR, China; Department of Electronic Engineering, The Chinese University of Hong Kong, Hong Kong SAR, China; Department of Electronic Engineering, The Chinese University of Hong Kong, Hong Kong SAR, China; Department of Electronic Engineering, The Chinese University of Hong Kong, Hong Kong SAR, China; Department of Electronic Engineering, The Chinese University of Hong Kong, Hong Kong SAR, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341284/",
        "gs_citation": 85,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7498466833765746326&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "The Chinese University of Hong Kong",
        "aff_unique_dep": "Department of Electronic Engineering",
        "aff_unique_url": "https://www.cuhk.edu.hk",
        "aff_unique_abbr": "CUHK",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9341380",
        "title": "Human Gait Phase Recognition using a Hidden Markov Model Framework",
        "track": "main",
        "status": "Poster",
        "abstract": "Analysis of human daily living activities, particularly walking activity, is essential for health-care applications such as fall prevention, physical rehabilitation exercises, and gait monitoring. Studying the evolution of the gait cycle using wearable sensors is beneficial for the detection of any abnormal walking pattern. This paper proposes a novel discrete/continuous unsupervised Hidden Markov Model method that is able to recognize six gait phases of a typical human walking cycle through the use of two wearable Inertial Measurement Units (IMUs) mounted at both feet of the subject. The results obtained with the proposed approach were compared to those of well-known supervised and unsupervised segmentation approaches. The obtained results show the efficiency of the proposed approach in accurately recognizing the different gait phases of a human gait cycle. The proposed model allows the consideration of the sequential aspect of the walking gait phases while operating in an unsupervised context that avoids the process of data labeling, which is often tedious and time-consuming, particularly within a massive-data context.",
        "primary_area": "",
        "author": "Ferhat Attal;Yacine Amirat;Abdelghani Chibani;Samer Mohammed;Ferhat Attal;Yacine Amirat;Abdelghani Chibani;Samer Mohammed",
        "authorids": "/37085385706;/37274109900;/37409311900;/38580067500;/37085385706;/37274109900;/37409311900;/38580067500",
        "aff": "LISSI, University Paris-Est Cr\u00e9teil (UPEC), Vitry-Sur-Seine, France; LISSI, University Paris-Est Cr\u00e9teil (UPEC), Vitry-Sur-Seine, France; LISSI, University Paris-Est Cr\u00e9teil (UPEC), Vitry-Sur-Seine, France; LISSI, University Paris-Est Cr\u00e9teil (UPEC), Vitry-Sur-Seine, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341380/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=926641381217090506&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University Paris-Est Cr\u00e9teil",
        "aff_unique_dep": "LISSI",
        "aff_unique_url": "https://www.u-pec.fr",
        "aff_unique_abbr": "UPEC",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Vitry-Sur-Seine",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9341004",
        "title": "Human Grasp Classification for Reactive Human-to-Robot Handovers",
        "track": "main",
        "status": "Poster",
        "abstract": "Transfer of objects between humans and robots is a critical capability for collaborative robots. Although there has been a recent surge of interest in human-robot handovers, most prior research focus on robot-to-human handovers. Further, work on the equally critical human-to-robot handovers often assumes humans can place the object in the robot\u2019s gripper. In this paper, we propose an approach for human-to-robot handovers in which the robot meets the human halfway, by classifying the human\u2019s grasp of the object and quickly planning a trajectory accordingly to take the object from the human\u2019s hand according to their intent. To do this, we collect a human grasp dataset which covers typical ways of holding objects with various hand shapes and poses, and learn a deep model on this dataset to classify the hand grasps into one of these categories. We present a planning and execution approach that takes the object from the human hand according to the detected grasp and hand position, and replans as necessary when the handover is interrupted. Through a systematic evaluation, we demonstrate that our system results in more fluent handovers versus two baselines. We also present findings from a user study (N = 9) demonstrating the effectiveness and usability of our approach with naive users in different scenarios. More information can be found at http://wyang.me/handovers.",
        "primary_area": "",
        "author": "Wei Yang;Chris Paxton;Maya Cakmak;Dieter Fox;Wei Yang;Chris Paxton;Maya Cakmak;Dieter Fox",
        "authorids": "/37069403600;/37085403975;/37409159800;/37284329000;/37069403600;/37085403975;/37409159800;/37284329000",
        "aff": "NVIDIA, USA; NVIDIA, USA; University of Washington, USA; University of Washington, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341004/",
        "gs_citation": 69,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13061052832520004652&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;1",
        "aff_unique_norm": "NVIDIA;University of Washington",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.nvidia.com;https://www.washington.edu",
        "aff_unique_abbr": "NV;UW",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341416",
        "title": "Human Preference-Based Learning for High-dimensional Optimization of Exoskeleton Walking Gaits",
        "track": "main",
        "status": "Poster",
        "abstract": "Optimizing lower-body exoskeleton walking gaits for user comfort requires understanding users' preferences over a high-dimensional gait parameter space. However, existing preference-based learning methods have only explored low-dimensional domains due to computational limitations. To learn user preferences in high dimensions, this work presents LINECOSPAR, a human-in-the-loop preference-based framework that enables optimization over many parameters by iteratively exploring one-dimensional subspaces. Additionally, this work identifies gait attributes that characterize broader preferences across users. In simulations and human trials, we empirically verify that LINECOSPAR is a sample-efficient approach for high-dimensional preference optimization. Our analysis of the experimental data reveals a correspondence between human preferences and objective measures of dynamicity, while also highlighting differences in the utility functions underlying individual users' gait preferences. This result has implications for exoskeleton gait synthesis, an active field with applications to clinical use and patient rehabilitation.",
        "primary_area": "",
        "author": "Maegan Tucker;Myra Cheng;Ellen Novoseller;Richard Cheng;Yisong Yue;Joel W. Burdick;Aaron D. Ames;Maegan Tucker;Myra Cheng;Ellen Novoseller;Richard Cheng;Yisong Yue;Joel W. Burdick;Aaron D. Ames",
        "authorids": "/37087122493;/37088690548;/37088507027;/37086493605;/37085390468;/37265975700;/37300877900;/37087122493;/37088690548;/37088507027;/37086493605;/37085390468;/37265975700;/37300877900",
        "aff": "Department of Mechanical and Civil Engineering, California Institute of Technology, Pasadena, CA; Department of Computing and Mathematical Sciences, California Institute of Technology, Pasadena, CA; Department of Computing and Mathematical Sciences, California Institute of Technology, Pasadena, CA; Department of Mechanical and Civil Engineering, California Institute of Technology, Pasadena, CA; Department of Computing and Mathematical Sciences, California Institute of Technology, Pasadena, CA; Department of Computing and Mathematical Sciences, California Institute of Technology, Pasadena, CA; Department of Computing and Mathematical Sciences, California Institute of Technology, Pasadena, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341416/",
        "gs_citation": 48,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11275868104045399719&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "California Institute of Technology",
        "aff_unique_dep": "Department of Mechanical and Civil Engineering",
        "aff_unique_url": "https://www.caltech.edu",
        "aff_unique_abbr": "Caltech",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Pasadena",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340776",
        "title": "Human-Aware Robot Navigation by Long-Term Movement Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "Foresighted, human-aware navigation is a prerequisite for service robots acting in indoor environments. In this paper, we present a novel human-aware navigation approach that relies on long-term prediction of human movements. In particular, we consider the problem of finding a path from the robot's current position to the initially unknown navigation goal of a moving user to provide timely assistance there. The navigation strategy has to minimize the robot's arrival time and at the same time comply with the user's comfort during the movement. Our solution predicts the user's navigation goal based on the robot's observations and prior knowledge about typical human transitions between objects. Based on the motion prediction, we then compute a time-dependent cost map that encodes the belief about the user's positions at future time steps. Using this map, we solve the time-dependent shortest path problem to find an efficient path for the robot, which still abides by the rules of human comfort. To identify robot navigation actions that are perceived as uncomfortable by humans, we performed user surveys and defined the corresponding constraints. We thoroughly evaluated our navigation system in simulation as well as in real-world experiments. As the results show, our system outperforms existing approaches in terms of human comfort, while still minimizing arrival times of the robot.",
        "primary_area": "",
        "author": "Lilli Bruckschen;Kira Bungert;Nils Dengler;Maren Bennewitz;Lilli Bruckschen;Kira Bungert;Nils Dengler;Maren Bennewitz",
        "authorids": "/37087048248;/37088529258;/37087049550;/37324765000;/37087048248;/37088529258;/37087049550;/37324765000",
        "aff": "University of Bonn, Germany; University of Bonn, Germany; University of Bonn, Germany; University of Bonn, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340776/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10464079325714250105&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Bonn",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.uni-bonn.de",
        "aff_unique_abbr": "UBonn",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9340726",
        "title": "Human-Drone Interaction for Aerially Manipulated Drilling using Haptic Feedback",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a concept for haptic-based human-in-the-loop aerial manipulation for drilling. The concept serves as a case study for designing the human-drone interface to remotely drill with a mobile-manipulating drone. The notion of the work stems from using drones to perform dangerous tasks like material assembly, sensor insertion while being vertically elevated from bridge, wind turbine, and power line. Presented is the aerial manipulator, the customized haptic drill press, the gantry-based test-and-evaluation platform design, material drilling results in the gantry, and validation-and-verification results for indoor flight trials.",
        "primary_area": "",
        "author": "Dongbin Kim;Paul Y. Oh;Dongbin Kim;Paul Y. Oh",
        "authorids": "/37086357522;/37266607600;/37086357522;/37266607600",
        "aff": "Mechanical Engineering Department, University of Nevada, Las Vegas (UNLV); Mechanical Engineering Department, University of Nevada, Las Vegas (UNLV)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340726/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6323217202199948905&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Nevada, Las Vegas",
        "aff_unique_dep": "Mechanical Engineering Department",
        "aff_unique_url": "https://www.unlv.edu",
        "aff_unique_abbr": "UNLV",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Las Vegas",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340781",
        "title": "Human-Robot Interaction in a Shared Augmented Reality Workspace",
        "track": "main",
        "status": "Poster",
        "abstract": "We design and develop a new shared Augmented Reality (AR) workspace for Human-Robot Interaction (HRI), which establishes a bi-directional communication between human agents and robots. In a prototype system, the shared AR workspace enables a shared perception, so that a physical robot not only perceives the virtual elements in its own view but also infers the utility of the human agent-the cost needed to perceive and interact in AR-by sensing the human agent's gaze and pose. Such a new HRI design also affords a shared manipulation, wherein the physical robot can control and alter virtual objects in AR as an active agent; crucially, a robot can proactively interact with human agents, instead of purely passively executing received commands. In experiments, we design a resource collection game that qualitatively demonstrates how a robot perceives, processes, and manipulates in AR and quantitatively evaluates the efficacy of HRI using the shared AR workspace. We further discuss how the system can potentially benefit future HRI studies that are otherwise challenging.",
        "primary_area": "",
        "author": "Shuwen Qiu;Hangxin Liu;Zeyu Zhang;Yixin Zhu;Song-Chun Zhu;Shuwen Qiu;Hangxin Liu;Zeyu Zhang;Yixin Zhu;Song-Chun Zhu",
        "authorids": "/37088690619;/37086274715;/37086938580;/37086172463;/37281407500;/37088690619;/37086274715;/37086938580;/37086172463;/37281407500",
        "aff": "Statistics Department, UCLA Center for Vision, Cognition, Learning, and Autonomy (VCLA); Statistics Department, UCLA Center for Vision, Cognition, Learning, and Autonomy (VCLA); Statistics Department, UCLA Center for Vision, Cognition, Learning, and Autonomy (VCLA); Statistics Department, UCLA Center for Vision, Cognition, Learning, and Autonomy (VCLA); Statistics Department, UCLA Center for Vision, Cognition, Learning, and Autonomy (VCLA)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340781/",
        "gs_citation": 39,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8638097258263028662&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of California, Los Angeles",
        "aff_unique_dep": "Statistics Department",
        "aff_unique_url": "https://www.ucla.edu",
        "aff_unique_abbr": "UCLA",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341267",
        "title": "Human-Robot Trust Assessment Using Motion Tracking & Galvanic Skin Response",
        "track": "main",
        "status": "Poster",
        "abstract": "In this study we set out to design a computer vision-based system to assess human-robot trust in real time during close-proximity human-robot collaboration. This paper presents the setup and hardware for an augmented reality-enabled human-robot collaboration cell as well as a method of measuring operator proximity using an infrared camera. We tested this setup as a tool for assessing trust through physical apprehension signals in a collaborative drawing task, where participants hold a piece of paper on a table while the robot draws between their hands. Midway through the test we attempt to induce a decrease in trust with an unexpected change in robot speed and evaluate subject motions along with self-reported trust and emotional arousal through galvanic skin response. After performing the experiment with forty participants, we found that reported trust was significantly affected when robot movement speed was increased. The galvanic skin response measurement were not significantly different between the test conditions. The motion tracking method used in this study did not suggest that subjects' motions were significantly affected by the decrease in trust.",
        "primary_area": "",
        "author": "Kasper Hald;Matthias Rehmn;Thomas B. Moeslund;Kasper Hald;Matthias Rehmn;Thomas B. Moeslund",
        "authorids": "/37073571900;/37088688131;/37299539100;/37073571900;/37088688131;/37299539100",
        "aff": "Department of Architecture, Design & Media Technology, Aalborg University, Aalborg, Denmark; Department of Architecture, Design & Media Technology, Aalborg University, Aalborg, Denmark; Department of Architecture, Design & Media Technology, Aalborg University, Aalborg, Denmark",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341267/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4340655706584328161&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Aalborg University",
        "aff_unique_dep": "Department of Architecture, Design & Media Technology",
        "aff_unique_url": "https://www.aau.dk",
        "aff_unique_abbr": "AAU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Aalborg",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Denmark"
    },
    {
        "id": "9341577",
        "title": "Hybrid aerial-ground locomotion with a single passive wheel",
        "track": "main",
        "status": "Poster",
        "abstract": "Exploiting contacts with environment structures provides extra force support to a UAV, often reducing the power consumption and hence extending the mission time. This paper investigates one such way to exploit flat surfaces in the environment by a novel aerial-ground hybrid locomotion. Our design is a single passive wheel integrated at the UAV bottom, serving a minimal design to date. We present the principle and implementation of such a simple design as well as its control. Flight experiments are conducted to verify the feasibility and the power saving caused by the ground locomotion. Results show that our minimal design allows successful aerial-ground hybrid locomotion even with a less-controllable bi-copter UAV. The ground locomotion saves up to 77% battery without much tuning effort.",
        "primary_area": "",
        "author": "Youming Qin;Yihang Li;Xu Wei;Fu Zhang;Youming Qin;Yihang Li;Xu Wei;Fu Zhang",
        "authorids": "/37088233728;/37088459381;/37088689331;/38245883800;/37088233728;/37088459381;/37088689331;/38245883800",
        "aff": "Department of Mechanical Engineering, University of Hong Kong; Department of Mechanical Engineering, University of Hong Kong; Department of Mechanical Engineering, University of Hong Kong; Department of Mechanical Engineering, University of Hong Kong",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341577/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=134365178581515595&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Hong Kong",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.hku.hk",
        "aff_unique_abbr": "HKU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9340731",
        "title": "Hybrid fluidic actuation for a foam-based soft actuator",
        "track": "main",
        "status": "Poster",
        "abstract": "Actuation means for soft robotic structures are manifold: despite actuation mechanisms such as tendon-driven manipulators or shape memory alloys, the majority of soft robotic actuators are fluidically actuated - either purely by positive or negative air pressure or by hydraulic actuation only. This paper presents the novel idea of employing hybrid fluidic - hydraulic and pneumatic - actuation for soft robotic systems. The concept and design of the hybrid actuation system as well as the fabrication of the soft actuator are presented: Polyvinyl Alcohol (PVA) foam is embedded inside a casted, reinforced silicone chamber. A hydraulic and pneumatic robotic syringe pump are connected to the base and top of the soft actuator. We found that a higher percentage of hydraulics resulted in a higher output force. Hydraulic actuation further is able to change displacements at a higher rate compared to pneumatic actuation. Changing between Hydraulic:Pneumatic (HP) ratios shows how stiffness properties of a soft actuator can be varied.",
        "primary_area": "",
        "author": "Jan Peters;Bani Anvari;Cheng Chen;Zara Lim;Helge A Wurdemann;Jan Peters;Bani Anvari;Cheng Chen;Zara Lim;Helge A Wurdemann",
        "authorids": "/37086356454;/37086351668;/37088689827;/37088337770;/37991827000;/37086356454;/37086351668;/37088689827;/37088337770;/37991827000",
        "aff": "Department of Civil, Environmental and Geomatic Engineering, University College London, UK; Department of Civil, Environmental and Geomatic Engineering, University College London, UK; Department of Mechanical Engineering, University College London, UK; Department of Mechanical Engineering, University College London, UK; Department of Mechanical Engineering, University College London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340731/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7986410055243343183&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University College London",
        "aff_unique_dep": "Department of Civil, Environmental and Geomatic Engineering",
        "aff_unique_url": "https://www.ucl.ac.uk",
        "aff_unique_abbr": "UCL",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "London;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9340891",
        "title": "Hypothesis-Driven Skill Discovery for Hierarchical Deep Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep reinforcement learning (DRL) is capable of learning high-performing policies on a variety of complex high-dimensional tasks, ranging from video games to robotic manipulation. However, standard DRL methods often suffer from poor sample efficiency, partially because they aim to be entirely problem-agnostic. In this work, we introduce a novel approach to exploration and hierarchical skill learning that derives its sample efficiency from intuitive assumptions it makes about the behavior of objects both in the physical world and simulations which mimic physics. Specifically, we propose the Hypothesis Proposal and Evaluation (HyPE) algorithm, which discovers objects from raw pixel data, generates hypotheses about the controllability of observed changes in object state, and learns a hierarchy of skills to test these hypotheses. We demonstrate that HyPE can dramatically improve the sample efficiency of policy learning in two different domains: a simulated robotic blockpushing domain, and a popular benchmark task: Breakout. In these domains, HyPE learns high-scoring policies an order of magnitude faster than several state-of-the-art reinforcement learning methods.",
        "primary_area": "",
        "author": "Caleb Chuck;Supawit Chockchowwat;Scott Niekum;Caleb Chuck;Supawit Chockchowwat;Scott Niekum",
        "authorids": "/37085907116;/37088690500;/37395003900;/37085907116;/37088690500;/37395003900",
        "aff": "The University of Texas at Austin Personal Robotics and Automation Lab.; The University of Texas at Austin Personal Robotics and Automation Lab.; The University of Texas at Austin Personal Robotics and Automation Lab.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340891/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14669425298380422474&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "The University of Texas at Austin",
        "aff_unique_dep": "Personal Robotics and Automation Lab",
        "aff_unique_url": "https://www.utexas.edu",
        "aff_unique_abbr": "UT Austin",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Austin",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341752",
        "title": "H\u221e-Optimal Tracking Controller for Three-Wheeled Omnidirectional Mobile Robots with Uncertain Dynamics",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present an optimal control approach using Linear Matrix Inequalities (LMIs) for trajectory tracking control of a three-wheeled omnidirectional mobile robot in the presence of external disturbances on the robot's actuators and noise in the robot's sensor measurements. First, a state-space representation of the omnidirectional robot dynamics is derived using a point-mass dynamic model. Then, we propose an LMI-based full-state feedback H\u221e-optimal controller for the tracking problem. The robot's tracking performance with the H\u221e-optimal controller is compared to its performance with a classical full-state feedback tracking controller in simulations with circular and bowtie-shaped reference trajectories. In order to evaluate our proposed controller in practice, we also implement the H\u221e-optimal and classical controllers for these reference trajectories on a three-wheeled omnidirectional robot. The H\u221e-optimal controller guarantees stabilization of the robot motion and attenuates the effects of frictional disturbances and measurement noise on the robot's tracking performance. Using the H\u221e-optimal controller, the robot is able to track the reference trajectories with up to a 47.8% and 45.8% decrease in the maximum pose and twist errors, respectively, over a full cycle of the trajectory compared to the classical controller. The simulation and experimental results show that our LMI-based H\u221e-optimal controller is robust to undesired effects of disturbances and noise on the dynamic behavior of the robot during trajectory tracking and can outperform the classical controller in attenuating their effects.",
        "primary_area": "",
        "author": "Amir Salimi Lafmejani;Hamed Farivarnejad;Spring Berman;Amir Salimi Lafmejani;Hamed Farivarnejad;Spring Berman",
        "authorids": "/37085690518;/37086115360;/37583148200;/37085690518;/37086115360;/37583148200",
        "aff": "School of Electrical, Computer and Energy Engineering, Arizona State University (ASU), Tempe, AZ; School for Engineering of Matter, Transport and Energy, ASU, Tempe, AZ; School for Engineering of Matter, Transport and Energy, ASU, Tempe, AZ",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341752/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2421620410422734625&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Arizona State University",
        "aff_unique_dep": "School of Electrical, Computer and Energy Engineering",
        "aff_unique_url": "https://www.asu.edu",
        "aff_unique_abbr": "ASU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Tempe",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341457",
        "title": "IAN: Multi-Behavior Navigation Planning for Robots in Real, Crowded Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "State-of-the-art approaches for robot navigation among humans are typically restricted to planar movement actions. This work addresses the question of whether it can be beneficial to use interaction actions, such as saying, touching, and gesturing, for the sake of allowing robots to navigate in unstructured, crowded environments. To do so, we first identify challenging scenarios to traditional motion planning methods. Based on the hypothesis that the variation in modality for these scenarios calls for significantly different planning policies, we design specific navigation behaviors as interaction planners for actuated, mobile robots. We further propose a high level planning algorithm for multi-behavior navigation, named Interaction Actions for Navigation (IAN). Through both real-world and simulated experiments, we validate the selected behaviors and the high-level planning algorithm, and discuss the impact of our obtained results on our stated assumptions.",
        "primary_area": "",
        "author": "Daniel Dugas;Juan Nieto;Roland Siegwart;Jen Jen Chung;Daniel Dugas;Juan Nieto;Roland Siegwart;Jen Jen Chung",
        "authorids": "/37086030360;/37085778635;/37281398300;/37085668354;/37086030360;/37085778635;/37281398300;/37085668354",
        "aff": "Autonomous Systems Lab, ETH Z\u00fcrich, Z\u00fcrich, Switzerland; Autonomous Systems Lab, ETH Z\u00fcrich, Z\u00fcrich, Switzerland; Autonomous Systems Lab, ETH Z\u00fcrich, Z\u00fcrich, Switzerland; Autonomous Systems Lab, ETH Z\u00fcrich, Z\u00fcrich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341457/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6931471560632494845&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "ETH Z\u00fcrich",
        "aff_unique_dep": "Autonomous Systems Lab",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETH",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Z\u00fcrich",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9341208",
        "title": "IDOL: A Framework for IMU-DVS Odometry using Lines",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we introduce IDOL, an optimization-based framework for IMU-DVS Odometry using Lines. Event cameras, also called Dynamic Vision Sensors (DVSs), generate highly asynchronous streams of events triggered upon illumination changes for each individual pixel. This novel paradigm presents advantages in low illumination conditions and high-speed motions. Nonetheless, this unconventional sensing modality brings new challenges to perform scene reconstruction or motion estimation. The proposed method offers to leverage a continuous-time representation of the inertial readings to associate each event with timely accurate inertial data. The method's front-end extracts event clusters that belong to line segments in the environment whereas the back-end estimates the system's trajectory alongside the lines' 3D position by minimizing point-to-line distances between individual events and the lines' projection in the image space. A novel attraction/repulsion mechanism is presented to accurately estimate the lines' extremities, avoiding their explicit detection in the event data. The proposed method is benchmarked against a state-of-the-art frame-based visual-inertial odometry framework using public datasets. The results show that IDOL performs at the same order of magnitude on most datasets and even shows better orientation estimates. These findings can have a great impact on new algorithms for DVS.",
        "primary_area": "",
        "author": "Cedric Le Gentil;Florian Tschopp;Ignacio Alzugaray;Teresa Vidal-Calleja;Roland Siegwart;Juan Nieto;Cedric Le Gentil;Florian Tschopp;Ignacio Alzugaray;Teresa Vidal-Calleja;Roland Siegwart;Juan Nieto",
        "authorids": "/37086453208;/37086688697;/37086016139;/37085384801;/37281398300;/37085778635;/37086453208;/37086688697;/37086016139;/37085384801;/37281398300;/37085778635",
        "aff": "Centre for Autonomous Systems, School of Mechanical and Mechatronic Engineering, University of Technology Sydney, Sydney, New South Wales, Australia; Autonomous Systems Lab, ETH Zurich, Switzerland; Vision for Robotics Lab, ETH Zurich, Switzerland; Centre for Autonomous Systems, School of Mechanical and Mechatronic Engineering, University of Technology Sydney, Sydney, New South Wales, Australia; Autonomous Systems Lab, ETH Zurich, Switzerland; Autonomous Systems Lab, ETH Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341208/",
        "gs_citation": 52,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=183995628349382759&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;0;1;1",
        "aff_unique_norm": "University of Technology Sydney;ETH Zurich",
        "aff_unique_dep": "School of Mechanical and Mechatronic Engineering;Autonomous Systems Lab",
        "aff_unique_url": "https://www.uts.edu.au;https://www.ethz.ch",
        "aff_unique_abbr": "UTS;ETHZ",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Sydney;",
        "aff_country_unique_index": "0;1;1;0;1;1",
        "aff_country_unique": "Australia;Switzerland"
    },
    {
        "id": "9341649",
        "title": "IMU-based Deep Neural Networks for Locomotor Intention Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper focuses on the design and comparison of different deep neural networks for the real-time prediction of locomotor intentions by using data from inertial measurement units. The deep neural network architectures are convolutional neural networks, recurrent neural networks, and convolutional recurrent neural networks. The input to the architectures are features in the time domain, which have been derived either from one inertial measurement unit placed on the upper right leg of ten healthy subjects, or two inertial measurement units placed on both the upper and lower right leg of ten healthy subjects. The study shows that a WaveNet, i.e., a full convolutional neural network, achieves a peak F1-score of 87.17% in the case of one IMU, and a peak of 97.88% in the case of two IMUs, with a 5-fold cross-validation.",
        "primary_area": "",
        "author": "Huaitian Lu;Lambert R.B. Schomaker;Raffaella Carloni;Huaitian Lu;Lambert R.B. Schomaker;Raffaella Carloni",
        "authorids": "/37088686496;/37270051900;/37283689000;/37088686496;/37270051900;/37283689000",
        "aff": "Faculty of Science and Engineering, Bernoulli Institute for Mathematics, Computer Science and Artificial Intelligence, University of Groningen, The Netherlands; Faculty of Science and Engineering, Bernoulli Institute for Mathematics, Computer Science and Artificial Intelligence, University of Groningen, The Netherlands; Faculty of Science and Engineering, Bernoulli Institute for Mathematics, Computer Science and Artificial Intelligence, University of Groningen, The Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341649/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13029355569465237275&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Groningen",
        "aff_unique_dep": "Bernoulli Institute for Mathematics, Computer Science and Artificial Intelligence",
        "aff_unique_url": "https://www.rug.nl",
        "aff_unique_abbr": "RUG",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Netherlands"
    },
    {
        "id": "9341136",
        "title": "IMU-based Parameter Identification and Position Estimation in Twisted String Actuators",
        "track": "main",
        "status": "Poster",
        "abstract": "This study proposes a technique to estimate the output state of twisted string actuators (TSAs) based on payload's acceleration measurements. We outline differential kinematics relationships of the actuator, re-formulate these into a nonlinear parameter identification problem and then apply linearization techniques to efficiently solve it as a quadratic program. Using accurate estimates of string parameters obtained with the proposed method, we can predict TSA position with sub-millimeter accuracy via conventional kinematic relationships. In addition, the proposed method supports accurate estimation under varying operating conditions, unpredictable perturbations, and poorly-excited trajectories. This technique can be employed to improve the accuracy of trajectory tracking when the use of direct position measurements is challenging, with the list of potential applications including flexible and soft robots, long-span cable robots, multi-DOF joints and others.",
        "primary_area": "",
        "author": "Simeon Nedelchev;Daniil Kirsanov;Igor Gaponov;Simeon Nedelchev;Daniil Kirsanov;Igor Gaponov",
        "authorids": "/37086580950;/37086568418;/37691627300;/37086580950;/37086568418;/37691627300",
        "aff": "Institute of Robotics and Computer Vision, Innopolis University, Innopolis, Russia; Institute of Robotics and Computer Vision, Innopolis University, Innopolis, Russia; Institute of Robotics and Computer Vision, Innopolis University, Innopolis, Russia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341136/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:mkyNw5_GI2EJ:scholar.google.com/&scioq=IMU-based+Parameter+Identification+and+Position+Estimation+in+Twisted+String+Actuators&hl=en&as_sdt=0,33",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Innopolis University",
        "aff_unique_dep": "Institute of Robotics and Computer Vision",
        "aff_unique_url": "https://www.innopolis.ru/en",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Innopolis",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Russia"
    },
    {
        "id": "9341195",
        "title": "Identification of Dynamic Parameters for Rigid Robots based on Polynomial Approximation",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper an approach for the identification of the dynamic parameters, i.e. base parameters, of rigid robots is presented. By using the polynomial approximation operator, an equation is obtained for the identification of the parameters which solely depends on measurable signals and thereby contains no equation error. The resulting expressions can be evaluated online or offline by filtering the measurable signals with FIR filters. In order to identify the parameters on the basis of measurements, an algorithm is presented to calculate the parameters numerically stable, even if the data is obtained sequentially, without a singular value decomposition. The parameters can be determined meaningfully by considering box constraints in order to ensure physical feasibility. The presented methods are finally used to identify the dynamic parameters of a delta robot and compared to the standard approach.",
        "primary_area": "",
        "author": "Alexander Lomakin;Joachim Deutscher;Alexander Lomakin;Joachim Deutscher",
        "authorids": "/37088505347;/37299228700;/37088505347;/37299228700",
        "aff": "Lehrstuhl f\u00fcr Regelungstechnik, Friedrich-Alexander-Universit\u00e4t, Erlangen-N\u00fcrnberg, Germany; Institut f\u00fcr Mess-, Regel- und Mikrotechnik, Universit\u00e4t, Ulm, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341195/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18364116780477741425&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Friedrich-Alexander-Universit\u00e4t Erlangen-N\u00fcrnberg;Universit\u00e4t Ulm",
        "aff_unique_dep": "Lehrstuhl f\u00fcr Regelungstechnik;Institut f\u00fcr Mess-, Regel- und Mikrotechnik",
        "aff_unique_url": "https://www fau.de;https://www.uni-ulm.de",
        "aff_unique_abbr": "FAU;",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Erlangen-N\u00fcrnberg;Ulm",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9341708",
        "title": "Identification of Effective Motion Primitives for Ground Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "Understanding the kinematics of a ground robot is essential for efficient navigation. Based on the kinematic model of a robot, its full motion capabilities can be represented by theoretical motion primitives. However, depending on the environment and/or human preferences, not all of those theoretical motion primitives are desirable and/or achievable. This work presents a method to identify effective motion primitives (eMP) from continuous trajectories for autonomous ground robots. The pipeline efficiently performs segmentation, representation and reconstruction of the motion primitives, using initial human-driving behaviour as a guide to create a motion primitive library. Hence, this strategy incorporates how the environment affects the robot operation regarding accelerations, speed, braking, and steering behaviours.The method is thoroughly tested on an autonomous car-like electric vehicle, and the results show excellent generalisation of the theoretical motion primitive distribution to real vehicle. The experiments are carried out on large site with very diverse characteristics, illustrating the applicability of the method.",
        "primary_area": "",
        "author": "Tobias L\u00f6w;Tirthankar Bandyopadhyay;Paulo V. K. Borges;Tobias L\u00f6w;Tirthankar Bandyopadhyay;Paulo V. K. Borges",
        "authorids": "/37088690914;/37562167000;/37546547800;/37088690914;/37562167000;/37546547800",
        "aff": "Multi-Scale Robotics Lab, ETH Zurich, Zurich, Switzerland; Robotics and Autonomous Systems Group, CSIRO, Australia; Robotics and Autonomous Systems Group, CSIRO, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341708/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1402262943126230373&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "ETH Zurich;CSIRO",
        "aff_unique_dep": "Multi-Scale Robotics Lab;Robotics and Autonomous Systems Group",
        "aff_unique_url": "https://www.ethz.ch;https://www.csiro.au",
        "aff_unique_abbr": "ETHZ;CSIRO",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Zurich;",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "Switzerland;Australia"
    },
    {
        "id": "9340928",
        "title": "Identification of a Human Hand Kinematics by Measuring and Merging of Nail-Based Finger Motions",
        "track": "main",
        "status": "Poster",
        "abstract": "A method to identify the kinematics model of a human hand that less suffers from the skin artifact is proposed based on a fact that the movements of nails with respect to the corresponding fingertip bones are much smaller than that of skin. It consists of two stages. In the first (individual) stage, the most likely combination of joint assignments and angles of each finger is identified through a dual-phase least squares method (LSM), where the joint angles are estimated in the inner LSM and the joint assignments in the outer LSM, from the movement of the hand dorsum with respect to the base coordinate frame attached to each nail. In the second (merging) stage, kinematic models of each finger are merged so as to compromise the estimated movements of the hand dorsum by them also through the dual-phase LSM. It is shown that the identified joint assignments have an advantage over several existing anthropomorphic robot hands based on the distribution of pinchability (DOP), which is also proposed in this paper as a novel index to evaluate the ability of in-hand manipulation.",
        "primary_area": "",
        "author": "Hidenori Tani;Ryo Nozawa;Tomomichi Sugihara;Hidenori Tani;Ryo Nozawa;Tomomichi Sugihara",
        "authorids": "/37088688093;/37088686640;/37288884300;/37088688093;/37088686640;/37288884300",
        "aff": "Kawasaki Heavy Industry, Osaka University, Japan; Kawasaki Heavy Industry, Osaka University, Japan; Preferred Networks, Inc., Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340928/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14817384700716431457&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Osaka University;Preferred Networks, Inc.",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.osaka-u.ac.jp;https://www.preferred-networks.com",
        "aff_unique_abbr": "Osaka U;",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Osaka;Tokyo",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9341035",
        "title": "ImitationFlow: Learning Deep Stable Stochastic Dynamic Systems by Normalizing Flows",
        "track": "main",
        "status": "Poster",
        "abstract": "We introduce ImitationFlow, a novel Deep generative model that allows learning complex globally stable, stochastic, nonlinear dynamics. Our approach extends the Normalizing Flows framework to learn stable Stochastic Differential Equations. We prove the Lyapunov stability for a class of Stochastic Differential Equations and we propose a learning algorithm to learn them from a set of demonstrated trajectories. Our model extends the set of stable dynamical systems that can be represented by state-of-the-art approaches, eliminates the Gaussian assumption on the demonstrations, and outperforms the previous algorithms in terms of representation accuracy. We show the effectiveness of our method with both standard datasets and a real robot experiment.",
        "primary_area": "",
        "author": "Julen Urain;Michele Ginesi;Davide Tateo;Jan Peters;Julen Urain;Michele Ginesi;Davide Tateo;Jan Peters",
        "authorids": "/37086435541;/37087469596;/37086271891;/37533077600;/37086435541;/37087469596;/37086271891;/37533077600",
        "aff": "Intelligent Autonomous Systems, TU Darmstadt; Department of Computer Science, University of Verona; Intelligent Autonomous Systems, TU Darmstadt; MPI for Intelligent Systems, Tuebingen",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341035/",
        "gs_citation": 59,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15270651567325696004&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;2",
        "aff_unique_norm": "Technische Universit\u00e4t Darmstadt;University of Verona;Max Planck Institute for Intelligent Systems",
        "aff_unique_dep": "Intelligent Autonomous Systems;Department of Computer Science;",
        "aff_unique_url": "https://www.tu-darmstadt.de;https://www.univr.it;https://www.mpituebingen.mpg.de",
        "aff_unique_abbr": "TU Darmstadt;;MPI-IS",
        "aff_campus_unique_index": "0;0;2",
        "aff_campus_unique": "Darmstadt;;Tuebingen",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "Germany;Italy"
    },
    {
        "id": "9340799",
        "title": "Impedance Control of Humanoid Walking on Uneven Terrain With Centroidal Momentum Dynamics Using Quadratic Programming",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose the stabilization strategy for a soft landing in a biped walking using impedance control and the optimization-based whole-body control framework. Even though proper contact forces and desired trajectories of the robot are given, the robot can be unstable easily if unexpected forces are applied to the robot or impulsive contact force is produced in the landing state while the robot is walking. Therefore, the impedance control approach using contact forces is performed to obtain the modified references that regulate the modified desired position, velocity and acceleration of the swing foot, and improves the walking stability. Moreover, we perform a whole-body control using quadratic programming (QP) that tracks the modified trajectories constrained with the centroidal momentum dynamics. To validate the algorithm, a walking task on uneven terrain using a humanoid robot is shown.",
        "primary_area": "",
        "author": "Joonhee Jo;Yonghwan Oh;Joonhee Jo;Yonghwan Oh",
        "authorids": "/38242649600;/37289677900;/38242649600;/37289677900",
        "aff": "Department of HCI & Robotics, University of Science and Technology(UST), Daejeon, Korea; Department of HCI & Robotics, University of Science and Technology(UST), Daejeon, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340799/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13934797006540569396&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Science and Technology",
        "aff_unique_dep": "Department of HCI & Robotics",
        "aff_unique_url": "https://www.ust.ac.kr",
        "aff_unique_abbr": "UST",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Daejeon",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9340912",
        "title": "Improving Autonomous Rover Guidance in Round-Trip Missions Using a Dynamic Cost Map",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous round trip missions arise as an interesting topic since ESA and NASA agreed to bring soil samples from Mars. This work proposes a new method to improve autonomous rover guidance for this kind of missions. It is focused on the use of dynamically updated cost maps that are used to plan the rover path for a round-trip. The main advantage of the proposed method is the use of gathered information by the rover during the traverse. So, the cost map is updated in two ways, the first one, related to the encountered obstacles, which are included within the cost map; and the second one that uses terrain features to assign different costs to different patches of a segmented terrain. The generated cost map is then used to plan the return path based on the previously obtained information from the rover. The proposed method has been validated first in a simulation environment with Software in the Loop. The implementation is finally validated by in-field testing in a Mars-like environment. Results show the return traverse is improved by means of the proposed method.",
        "primary_area": "",
        "author": "G.J. Paz-Delgado;M. Azkarate;J. R. S\u00e1nchez-Ib\u00e1\u00f1ez;C.J. P\u00e9rez-del-Pulgar;L. Gerdes;A.J. Garc\u00eda-Cerezo;G.J. Paz-Delgado;M. Azkarate;J. R. S\u00e1nchez-Ib\u00e1\u00f1ez;C.J. P\u00e9rez-del-Pulgar;L. Gerdes;A.J. Garc\u00eda-Cerezo",
        "authorids": "/37088687109;/37086132616;/37088688510;/37085353262;/37088505993;/38273546700;/37088687109;/37086132616;/37088688510;/37085353262;/37088505993;/38273546700",
        "aff": "Department of Systems Engineering and Automation, Space Robotics Laboratory, Universidad de M\u00e1laga, M\u00e1laga, Spain; Robotics and Automation Section, European Space Agency, Noordwijk, The Netherlands; Department of Systems Engineering and Automation, Space Robotics Laboratory, Universidad de M\u00e1laga, M\u00e1laga, Spain; Department of Systems Engineering and Automation, Space Robotics Laboratory, Universidad de M\u00e1laga, M\u00e1laga, Spain; Robotics and Automation Section, European Space Agency, Noordwijk, The Netherlands; Department of Systems Engineering and Automation, Space Robotics Laboratory, Universidad de M\u00e1laga, M\u00e1laga, Spain",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340912/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13838308888127953879&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;0;1;0",
        "aff_unique_norm": "Universidad de M\u00e1laga;European Space Agency",
        "aff_unique_dep": "Department of Systems Engineering and Automation;Robotics and Automation Section",
        "aff_unique_url": "https://www.uma.es;https://www.esa.int",
        "aff_unique_abbr": "UMA;ESA",
        "aff_campus_unique_index": "0;1;0;0;1;0",
        "aff_campus_unique": "M\u00e1laga;Noordwijk",
        "aff_country_unique_index": "0;1;0;0;1;0",
        "aff_country_unique": "Spain;Netherlands"
    },
    {
        "id": "9341033",
        "title": "Improving Disturbance Rejection and Dynamics of Cable Driven Parallel Robots with On-board Propellers",
        "track": "main",
        "status": "Poster",
        "abstract": "This work studies redundant actuation for both trajectory tracking and disturbance rejection on flexible cable-driven parallel robots (CDPR). High dynamics/bandwidth unidirectional force generators, like air propellers, are used in combination with conventional but slower cable winding winches. To optimally balance the action of the two types of actuation within their saturation constraints, a model predictive controller is used. Experiments show the added value of on-board propulsion units with respect to winch-only control in order to improve the overall CDPR dynamic behavior.",
        "primary_area": "",
        "author": "Imane Khayour;Lo\u00efc Cuvillon;C\u00f4me Butin;Arda Yi\u011fit;Sylvain Durand;Jacques Gangloff;Imane Khayour;Lo\u00efc Cuvillon;C\u00f4me Butin;Arda Yi\u011fit;Sylvain Durand;Jacques Gangloff",
        "authorids": "/37086937620;/37563879500;/37088690634;/37088507420;/37411970500;/37283578200;/37086937620;/37563879500;/37088690634;/37088507420;/37411970500;/37283578200",
        "aff": "ICube Laboratory, Strasbourg University, Strasbourg, France; ICube Laboratory, Strasbourg University, Strasbourg, France; ICube Laboratory, Strasbourg University, Strasbourg, France; ICube Laboratory, Strasbourg University, Strasbourg, France; ICube Laboratory, Strasbourg University, Strasbourg, France; ICube Laboratory, Strasbourg University, Strasbourg, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341033/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11876123477224128595&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Strasbourg University",
        "aff_unique_dep": "ICube Laboratory",
        "aff_unique_url": "https://www.unistra.fr",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Strasbourg",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9340900",
        "title": "Improving Low-Level Control of the Exoskeleton Atalante in Single Support by Compensating Joint Flexibility",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper describes a novel low-level controller for the lower-limb exoskeleton Atalante. The controller implemented on the commercialized product Atalante works under the assumption of full rigidity, performing position control through decentralized joint PIDs. However, this controller is unable to tackle the presence of flexibilities in the system, which cause static errors and undesired oscillations. We modify this controller by leveraging estimations of the position and velocity of the flexibilities, readily available on Atalante through the use of strapdown IMUs. Instead of considering feedback on the motor position only, we perform feedback on both the joint position and the flexibility angle, keeping a decentralized approach. This enables compensation of both the static error present at rest, and rapid damping of the oscillations. To tune the gains of the proposed controller, we use a linearized model of an elastic joint to which we apply a steady-state LQR, which creates desirable robustness to the flexible model. The proposed controller is experimentally validated through various single support experiments on Atalante, either empty or with a user. In all cases, the proposed controller outperforms the state-of- the-art controller, providing improved trajectory tracking and disturbance rejection.",
        "primary_area": "",
        "author": "Matthieu Vigne;Antonio El Khoury;Florent Di Meglio;Nicolas Petit;Matthieu Vigne;Antonio El Khoury;Florent Di Meglio;Nicolas Petit",
        "authorids": "/37086592432;/37086596576;/37546922100;/37299796200;/37086592432;/37086596576;/37546922100;/37299796200",
        "aff": "Centre Automatique et Syst\u00e8mes, MINES ParisTech, PSL Research University, France; Control-Command team, Wandercraft, Paris, France; Centre Automatique et Syst\u00e8mes, MINES ParisTech, PSL Research University, France; Centre Automatique et Syst\u00e8mes, MINES ParisTech, PSL Research University, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340900/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4772492664864102108&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "MINES ParisTech;Wandercraft",
        "aff_unique_dep": "Centre Automatique et Syst\u00e8mes;Control-Command team",
        "aff_unique_url": "https://www.minesparistech.fr;",
        "aff_unique_abbr": "MINES ParisTech;",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Paris",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9341302",
        "title": "Improving Motion Planning for Surgical Robot with Active Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, an improved motion planning scheme is proposed for surgical robot control with multiple active constraints, including joint constraints, joint velocity constraints and remote center of motion constraints. It introduces an improved recurrent neural network (RNN) to optimize the online motion planning respect to multiple constraints. The demonstrated surgical operation trajectory is derived using teaching by demonstration. An improved motion planning scheme using the novel recurrent neural network is then designed to achieve the accurate task tracking under the multiple constraints. The general quadratic performance index is adopted to represent the constraints. Finally, the effectiveness of the proposed algorithm is demonstrated using KUKA LWR4+ robot in a lab setup environment.",
        "primary_area": "",
        "author": "Hang Su;Yingbai Hu;Jiehao Li;Jing Guo;Yuan Liu;Mengyao Li;Alois Knoll;Giancarlo Ferrigno;Elena De Momi;Hang Su;Yingbai Hu;Jiehao Li;Jing Guo;Yuan Liu;Mengyao Li;Alois Knoll;Giancarlo Ferrigno;Elena De Momi",
        "authorids": "/37086423278;/37085749138;/37087890868;/37896663300;/37089444105;/37086593959;/37276234100;/37294130300;/37947344300;/37086423278;/37085749138;/37087890868;/37896663300;/37089444105;/37086593959;/37276234100;/37294130300;/37947344300",
        "aff": "Department of Electronics, Information and Bioengineering, Politecnico di Milano, Milan, Italy; Department of Informatics, Technical University of Munich, Munich, Germany; Department of Electronics, Information and Bioengineering, Politecnico di Milano, Milan, Italy; School of Automation, Guangdong University of Technology, Guangzhou, China; School of Automation, Guangdong University of Technology, Guangzhou, China; Shenzhen Institutes of Advanced Technology, Chinese Academy Sciences, Shenzhen, China; Department of Informatics, Technical University of Munich, Munich, Germany; Department of Electronics, Information and Bioengineering, Politecnico di Milano, Milan, Italy; Department of Electronics, Information and Bioengineering, Politecnico di Milano, Milan, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341302/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=72953353345061451&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;1;0;2;2;3;1;0;0",
        "aff_unique_norm": "Politecnico di Milano;Technical University of Munich;Guangdong University of Technology;Shenzhen Institutes of Advanced Technology",
        "aff_unique_dep": "Department of Electronics, Information and Bioengineering;Department of Informatics;School of Automation;",
        "aff_unique_url": "https://www.polimi.it;https://www.tum.de;;http://www.siat.cas.cn",
        "aff_unique_abbr": "Politecnico di Milano;TUM;;SIAT",
        "aff_campus_unique_index": "0;1;0;2;2;3;1;0;0",
        "aff_campus_unique": "Milan;Munich;Guangzhou;Shenzhen",
        "aff_country_unique_index": "0;1;0;2;2;2;1;0;0",
        "aff_country_unique": "Italy;Germany;China"
    },
    {
        "id": "9341029",
        "title": "Improving Unimodal Object Recognition with Multimodal Contrastive Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Robots perceive their environment using various sensor modalities, e.g., vision, depth, sound or touch. Each modality provides complementary information for perception. However, while it can be assumed that all modalities are available for training, when deploying the robot in real-world scenarios the sensor setup often varies. In order to gain flexibility with respect to the deployed sensor setup we propose a new multimodal approach within the framework of contrastive learning. In particular, we consider the case of learning from RGB-D images while testing with one modality available, i.e., exclusively RGB or depth. We leverage contrastive learning to capture high-level information between different modalities in a compact feature embedding. We extensively evaluate our multimodal contrastive learning method on the Falling Things dataset and learn representations that outperform prior methods for RGB-D object recognition on the NYU-D dataset. Our code and details on the used datasets are available at: https://github.com/meyerjo/MultiModalContrastiveLearning.",
        "primary_area": "",
        "author": "Johannes Meyer;Andreas Eitel;Thomas Brox;Wolfram Burgard;Johannes Meyer;Andreas Eitel;Thomas Brox;Wolfram Burgard",
        "authorids": "/37085504780;/37085450155;/37541664500;/37270485300;/37085504780;/37085450155;/37541664500;/37270485300",
        "aff": "Department of Computer Science, University of Freiburg, Germany; Department of Computer Science, University of Freiburg, Germany; Department of Computer Science, University of Freiburg, Germany; Toyota Research Institute, Los Altos, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341029/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15823129992316869483&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "University of Freiburg;Toyota Research Institute",
        "aff_unique_dep": "Department of Computer Science;",
        "aff_unique_url": "https://www.uni-freiburg.de;https://www.tri.global",
        "aff_unique_abbr": ";TRI",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Los Altos",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "Germany;United States"
    },
    {
        "id": "9341451",
        "title": "Improving Visual SLAM in Car-Navigated Urban Environments with Appearance Maps",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper describes a method that corrects errors of a VSLAM-estimated trajectory for cars driving in GPS-denied environments, by applying constraints from public databases of geo-tagged images (Google Street View, Mapillary, etc). The method, dubbed Appearance-based Geo-Alignment for Simultaneous Localisation and Mapping (AGA-SLAM), encodes the available image database as an appearance map, which represents the space with a compact holistic descriptor for each image plus its associated geo-tag. The VSLAM trajectory is corrected on-line by incorporating constraints from the recognized places along the trajectory into a position-based optimization framework. The paper presents a seamless formulation to combine local and absolute metric observations with associations from Visual Place Recognition. The robustness of the holistic image descriptor to changes due to weather or illumination variations ensures a long-term consistent method to improve car localization. The proposed method has been extensively evaluated on more than 70 sequences from 4 different datasets, proving out its effectiveness and endurance to appearance challenges.",
        "primary_area": "",
        "author": "Alberto Jaenal;David Zu\u00f1iga-N\u00f6el;Ruben Gomez-Ojeda;Javier Gonzalez-Jimenez;Alberto Jaenal;David Zu\u00f1iga-N\u00f6el;Ruben Gomez-Ojeda;Javier Gonzalez-Jimenez",
        "authorids": "/37086995525;/37086853705;/37085583645;/38467356700;/37086995525;/37086853705;/37085583645;/38467356700",
        "aff": "Machine Perception and Intelligent Robotics (MAPIR) Group, Department of Systems Engineering, University of Malaga, Malaga, Spain; Machine Perception and Intelligent Robotics (MAPIR) Group, Department of Systems Engineering, University of Malaga, Malaga, Spain; Machine Perception and Intelligent Robotics (MAPIR) Group, Department of Systems Engineering, University of Malaga, Malaga, Spain; Machine Perception and Intelligent Robotics (MAPIR) Group, Department of Systems Engineering, University of Malaga, Malaga, Spain",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341451/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17039028164103826690&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Malaga",
        "aff_unique_dep": "Department of Systems Engineering",
        "aff_unique_url": "https://www.um.es",
        "aff_unique_abbr": "UMA",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Malaga",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Spain"
    },
    {
        "id": "9341025",
        "title": "In-flight Efficient Controller Auto-tuning using a Pair of UAVs",
        "track": "main",
        "status": "Poster",
        "abstract": "In the paper, a pair of auto-tuning methods for fixed-parameter controllers is presented, in application to multirotor unmanned aerial vehicles (UAVs) control. In both cases, the automatized process of searching the best altitude controller parameters is carried out with the use of a modified golden-search method, for a selected cost function, during the flight of a pair of UAVs. All the calculations are performed in real-time in the iterative manner using only basic sensory information available concerning current altitude information for a pair of UAVs. The auto-tuning process of the controller is characterized by neglectfully low computational demand, and the parameters are obtained rapidly with no dynamic model of a UAV needed. In both methods, by using a pair of UAVs in tuning process, the level of control performance can be increased, what has been proved by means of multiple outdoor experiments. The first method increases precision of the obtained controller parameters by averaging sensory information over a pair of UAVs, whereas in the second, by exchanging measurement information between the units, the search space is explored faster. The latter is of special importance when seeking the best controller parameters, what is especially expected when a limited experiment duration of multirotor UAVs is taken into account.",
        "primary_area": "",
        "author": "Wojciech Giernacki;Dariusz Horla;Martin Saska;Wojciech Giernacki;Dariusz Horla;Martin Saska",
        "authorids": "/38529213200;/37564795600;/37298817800;/38529213200;/37564795600;/37298817800",
        "aff": "Faculty of Control, Robotics and Electrical Engineering, Institute of Robotics and Machine Intelligence, Poznan University of Technology, Poznan, Poland; Faculty of Control, Robotics and Electrical Engineering, Institute of Robotics and Machine Intelligence, Poznan University of Technology, Poznan, Poland; Faculty of Electrical Engineering, Czech Technical University in Prague, Prague 6, Czech Republic",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341025/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4528704369808017753&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Poznan University of Technology;Czech Technical University in Prague",
        "aff_unique_dep": "Faculty of Control, Robotics and Electrical Engineering;Faculty of Electrical Engineering",
        "aff_unique_url": "https://www.put.poznan.pl/;https://www.cvut.cz",
        "aff_unique_abbr": "PUT;CTU",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Poznan;Prague 6",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "Poland;Czech Republic"
    },
    {
        "id": "9340762",
        "title": "In-flight range optimization of multicopters using multivariable extremum seeking with adaptive step size",
        "track": "main",
        "status": "Poster",
        "abstract": "Limited flight range is a common problem for multicopters. To alleviate this problem, we propose a method for finding the optimal speed and heading of a multicopter when flying a given path to achieve the longest flight range. Based on a novel multivariable extremum seeking controller with adaptive step size, the method (a) does not require any power consumption model of the vehicle, (b) can adapt to unknown disturbances, (c) can be executed online, and (d) converges faster than the standard extremum seeking controller with constant step size. We conducted indoor experiments to validate the effectiveness of this method under different payloads and initial conditions, and showed that it is able to converge more than 30% faster than the standard extremum seeking controller. This method is especially useful for applications such as package delivery, where the size and weight of the payload differ for different deliveries and the power consumption of the vehicle is hard to model.",
        "primary_area": "",
        "author": "Xiangyu Wu;Mark W. Mueller;Xiangyu Wu;Mark W. Mueller",
        "authorids": "/37086448421;/37086448968;/37086448421;/37086448968",
        "aff": "Department of Mechanical Engineering, High Performance Robotics Laboratory (HiPeR-Lab), UC Berkeley; Department of Mechanical Engineering, High Performance Robotics Laboratory (HiPeR-Lab), UC Berkeley",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340762/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10645142816673152987&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341013",
        "title": "Incorporating Spatial Constraints into a Bayesian Tracking Framework for Improved Localisation in Agricultural Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Global navigation satellite system (GNSS) has been considered as a panacea for positioning and tracking since the last decade. However, it suffers from severe limitations in terms of accuracy, particularly in highly cluttered and indoor environments. Though real-time kinematics (RTK) supported GNSS promises extremely accurate localisation, employing such services are expensive, fail in occluded environments and are unavailable in areas where cellular base stations are not accessible. It is, therefore, necessary that the GNSS data is to be filtered if high accuracy is required. Thus, this article presents a GNSS-based particle filter that exploits the spatial constraints imposed by the environment. In the proposed setup, the state prediction of the sample set follows a restricted motion according to the topological map of the environment. This results in the transition of the samples getting confined between specific discrete points, called the topological nodes, defined by a topological map. This is followed by a refinement stage where the full set of predicted samples goes through weighting and resampling, where the weight is proportional to the predicted particle's proximity with the GNSS measurement. Thus, a discrete space continuous-time Bayesian filter is proposed, called the Topological Particle Filter (TPF).The proposed TPF is put to test by localising and tracking fruit pickers inside polytunnels. Fruit pickers inside polytunnels can only follow specific paths according to the topology of the tunnel. These paths are defined in the topological map of the polytunnels and are fed to TPF to tracks fruit pickers. Extensive datasets are collected to demonstrate the improved discrete tracking of strawberry pickers inside polytunnels thanks to the exploitation of the environmental constraints.",
        "primary_area": "",
        "author": "Muhammad W. Khan;Gautham P. Das;Marc Hanheide;Grzegorz Cielniak;Muhammad W. Khan;Gautham P. Das;Marc Hanheide;Grzegorz Cielniak",
        "authorids": "/37089733502;/38242544200;/37270387300;/37550177700;/37089733502;/38242544200;/37270387300;/37550177700",
        "aff": "Lincoln Centre for Autonomous Systems at the School of Computer Science of University of Lincoln, United Kingdom; Lincoln Centre for Autonomous Systems at the School of Computer Science of University of Lincoln, United Kingdom; Lincoln Centre for Autonomous Systems at the School of Computer Science of University of Lincoln, United Kingdom; Lincoln Centre for Autonomous Systems at the School of Computer Science of University of Lincoln, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341013/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17050192038856363209&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Lincoln",
        "aff_unique_dep": "School of Computer Science",
        "aff_unique_url": "https://www.lincoln.ac.uk",
        "aff_unique_abbr": "UoL",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Lincoln",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9341163",
        "title": "Indirect Object-to-Robot Pose Estimation from an External Monocular RGB Camera",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a robotic grasping system that uses a single external monocular RGB camera as input. The object-to-robot pose is computed indirectly by combining the output of two neural networks: one that estimates the object-to-camera pose, and another that estimates the robot-to-camera pose. Both networks are trained entirely on synthetic data, relying on domain randomization to bridge the sim-to-real gap. Because the latter network performs online camera calibration, the camera can be moved freely during execution without affecting the quality of the grasp. Experimental results analyze the effect of camera placement, image resolution, and pose refinement in the context of grasping several household objects. We also present results on a new set of 28 textured household toy grocery objects, which have been selected to be accessible to other researchers. To aid reproducibility of the research, we offer 3D scanned textured models, along with pre-trained weights for pose estimation.",
        "primary_area": "",
        "author": "Jonathan Tremblay;Stephen Tyree;Terry Mosier;Stan Birchfield;Jonathan Tremblay;Stephen Tyree;Terry Mosier;Stan Birchfield",
        "authorids": "/37086455314;/37074894100;/37088504181;/37371627300;/37086455314;/37074894100;/37088504181;/37371627300",
        "aff": "NVIDIA; NVIDIA; NVIDIA; NVIDIA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341163/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9944302473370349202&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "NVIDIA Corporation",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.nvidia.com",
        "aff_unique_abbr": "NVIDIA",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341580",
        "title": "Indoor Scene Recognition in 3D",
        "track": "main",
        "status": "Poster",
        "abstract": "Recognising in what type of environment one is located is an important perception task. For instance, for a robot operating indoors it is helpful to be aware whether it is in a kitchen, a hallway or a bedroom. Existing approaches attempt to classify the scene based on 2D images or 2.5D range images. Here, we study scene recognition from 3D point cloud (or voxel) data, and show that it greatly outperforms methods based on 2D birds-eye views. Moreover, we advocate multi-task learning as a way to improve scene recognition, building on the fact that the scene type is highly correlated with the objects in the scene, and therefore with its semantic segmentation into different object classes. In a series of ablation studies, we show that successful scene recognition is not just the recognition of individual objects unique to some scene type (such as a bathtub), but depends on several different cues, including coarse 3D geometry, colour, and the (implicit) distribution of object categories. Moreover, we demonstrate that surprisingly sparse 3D data is sufficient to classify indoor scenes with good accuracy.",
        "primary_area": "",
        "author": "Shengyu Huang;Mikhail Usvyatsov;Konrad Schindler;Shengyu Huang;Mikhail Usvyatsov;Konrad Schindler",
        "authorids": "/37088690166;/37086937348;/37267277500;/37088690166;/37086937348;/37267277500",
        "aff": "Photogrammetry and Remote Sensing group, ETH Zurich, Zurich, Switzerland; Photogrammetry and Remote Sensing group, ETH Zurich, Zurich, Switzerland; Photogrammetry and Remote Sensing group, ETH Zurich, Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341580/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7314012919691511323&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Photogrammetry and Remote Sensing group",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Zurich",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9341633",
        "title": "Inertia-Decoupled Equations for Hardware-in-the-Loop Simulation of an Orbital Robot with External Forces",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose three novel Hardware-in-the-loop simulation (HLS) methods for a fully-actuated orbital robot in the presence of external interactions using On-Ground Facility Manipulators (OGFM). In particular, a fixed-base and a vehicle-driven manipulator are considered in the analyses. The key idea is to describe the orbital robot's dynamics using the Lagrange-Poincar\u00e9(LP) equations, which reveal a block-diagonalized inertia. The resulting advantage is that noisy joint acceleration/torque measurements are avoided in the computation of the spacecraft motion due to manipulator interaction even while considering external forces. The proposed methods are a consequence of two facilitating theorems, which are proved herein. These theorems result in two actuation maps between the simulated orbital robot and the physical OGFM. The chief advantage of the proposed methods is physical consistency without level-set assumptions on the momentum map. We validate this through experiments on both types of OGFM in the presence of external forces. Finally, the effectiveness of our approach is validated through a HLS of a fully-actuated orbital robot while interacting with the environment.",
        "primary_area": "",
        "author": "Hrishik Mishra;Alessandro M. Giordano;Marco De Stefano;Roberto Lampariello;Christian Ott;Hrishik Mishra;Alessandro M. Giordano;Marco De Stefano;Roberto Lampariello;Christian Ott",
        "authorids": "/37086428941;/37085390315;/37085376264;/37448956500;/37282440400;/37086428941;/37085390315;/37085376264;/37448956500;/37282440400",
        "aff": "Institute of Robotics and Mechatronics, German Aerospace Center (DLR), We\u00dfling, Germany; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), We\u00dfling, Germany; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), We\u00dfling, Germany; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), We\u00dfling, Germany; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), We\u00dfling, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341633/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=501753499167723644&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "German Aerospace Center",
        "aff_unique_dep": "Institute of Robotics and Mechatronics",
        "aff_unique_url": "https://www.dlr.de",
        "aff_unique_abbr": "DLR",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "We\u00dfling",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9340772",
        "title": "Inertial Velocity Estimation for Indoor Navigation Through Magnetic Gradient-based EKF and LSTM Learning Model",
        "track": "main",
        "status": "Poster",
        "abstract": "",
        "primary_area": "",
        "author": "Makia Zmitri;Hassen Fourati;Christophe Prieur;Makia Zmitri;Hassen Fourati;Christophe Prieur",
        "authorids": "/37087105759;/37594574500;/37300735600;/37087105759;/37594574500;/37300735600",
        "aff": "",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340772/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3255040925696446096&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6
    },
    {
        "id": "9340798",
        "title": "Inferring Spatial Uncertainty in Object Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "The availability of real-world datasets is the prerequisite for developing object detection methods for autonomous driving. While ambiguity exists in object labels due to error-prone annotation process or sensor observation noises, current object detection datasets only provide deterministic annotations without considering their uncertainty. This precludes an in-depth evaluation among different object detection methods, especially for those that explicitly model predictive probability. In this work, we propose a generative model to estimate bounding box label uncertainties from LiDAR point clouds, and define a new representation of the probabilistic bounding box through spatial distribution. Comprehensive experiments show that the proposed model represents uncertainties commonly seen in driving scenarios. Based on the spatial distribution, we further propose an extension of IoU, called the Jaccard IoU (JIoU), as a new evaluation metric that incorporates label uncertainty. Experiments on the KITTI and the Waymo Open Datasets show that JIoU is superior to IoU when evaluating probabilistic object detectors.",
        "primary_area": "",
        "author": "Zining Wang;Di Feng;Yiyang Zhou;Lars Rosenbaum;Fabian Timm;Klaus Dietmayer;Masayoshi Tomizuka;Wei Zhan;Zining Wang;Di Feng;Yiyang Zhou;Lars Rosenbaum;Fabian Timm;Klaus Dietmayer;Masayoshi Tomizuka;Wei Zhan",
        "authorids": "/38559797700;/37086544464;/37088504087;/37086546688;/38192362600;/37283417900;/37281933000;/37067099600;/38559797700;/37086544464;/37088504087;/37086546688;/38192362600;/37283417900;/37281933000;/37067099600",
        "aff": "Department of Mechanical Engineering, University of California, Berkeley, CA, USA; Institute of Measurement, Control and Microtechnology, Ulm University, Ulm, Germany; Department of Mechanical Engineering, University of California, Berkeley, CA, USA; Robert Bosch GmbH, Corporate Research, Driver Assistance Systems and Automated Driving, Renningen, Germany; Robert Bosch GmbH, Corporate Research, Driver Assistance Systems and Automated Driving, Renningen, Germany; Institute of Measurement, Control and Microtechnology, Ulm University, Ulm, Germany; Department of Mechanical Engineering, University of California, Berkeley, CA, USA; Department of Mechanical Engineering, University of California, Berkeley, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340798/",
        "gs_citation": 34,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2958847684121796833&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;0;2;2;1;0;0",
        "aff_unique_norm": "University of California, Berkeley;Ulm University;Robert Bosch GmbH",
        "aff_unique_dep": "Department of Mechanical Engineering;Institute of Measurement, Control and Microtechnology;Corporate Research, Driver Assistance Systems and Automated Driving",
        "aff_unique_url": "https://www.berkeley.edu;https://www.uni-ulm.de;https://www.bosch.com",
        "aff_unique_abbr": "UC Berkeley;Ulm U;Bosch",
        "aff_campus_unique_index": "0;1;0;1;0;0",
        "aff_campus_unique": "Berkeley;Ulm;",
        "aff_country_unique_index": "0;1;0;1;1;1;0;0",
        "aff_country_unique": "United States;Germany"
    },
    {
        "id": "9341612",
        "title": "Information Driven Self-Calibration for Lidar-Inertial Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-modal estimation systems have the advantage of increased accuracy and robustness. To achieve accurate sensor fusion with these types of systems, a reliable extrinsic calibration between each sensor pair is critical. This paper presents a novel self-calibration framework for lidar-inertial systems. The key idea of this work is to use an informative path planner to find the admissible path that produces the most accurate calibration of such systems in an unknown environment within a given time budget. This is embedded into a simultaneous localization, mapping and calibration lidar-inertial system, which involves challenges in dealing with agile motions for excitation and large amount of data. Our approach has two stages: firstly, the environment is explored and mapped following a pre-defined path; secondly, the map is exploited to find a continuous and differentiable path that maximises the information gain within a sampling-based planner. We evaluate the proposed self-calibration method in a simulated environment and benchmark it with standard predefined paths to show its performance.",
        "primary_area": "",
        "author": "Mitchell Usayiwevu;Cedric Le Gentil;Jasprabhjit Mehami;Chanyeol Yoo;Robert Fitch;Teresa Vidal-Calleja;Mitchell Usayiwevu;Cedric Le Gentil;Jasprabhjit Mehami;Chanyeol Yoo;Robert Fitch;Teresa Vidal-Calleja",
        "authorids": "/37088688007;/37086453208;/37088540389;/37086933786;/38466367800;/37085384801;/37088688007;/37086453208;/37088540389;/37086933786;/38466367800;/37085384801",
        "aff": "School for Mechanical and Mechatronics Engineering, University of Technology Sydney, Ultimo, NSW, Australia; School for Mechanical and Mechatronics Engineering, University of Technology Sydney, Ultimo, NSW, Australia; School for Mechanical and Mechatronics Engineering, University of Technology Sydney, Ultimo, NSW, Australia; School for Mechanical and Mechatronics Engineering, University of Technology Sydney, Ultimo, NSW, Australia; School for Mechanical and Mechatronics Engineering, University of Technology Sydney, Ultimo, NSW, Australia; School for Mechanical and Mechatronics Engineering, University of Technology Sydney, Ultimo, NSW, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341612/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9551031673977531467&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of Technology Sydney",
        "aff_unique_dep": "School for Mechanical and Mechatronics Engineering",
        "aff_unique_url": "https://www.uts.edu.au",
        "aff_unique_abbr": "UTS",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Ultimo",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "9341781",
        "title": "Informative Path Planning for Gas Distribution Mapping in Cluttered Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Mobile robotic gas distribution mapping (GDM) is a useful tool for hazardous scene assessment where a quick and accurate representation of gas concentration levels is required throughout a staging area. However, research in robotic path planning for GDM has primarily focused on mapping in open spaces or estimating the source term in dispersion models. Whilst this may be appropriate for environment monitoring in general, the vast majority of GDM applications involve obstacles, and path planning for autonomous robots must account for this. This paper aims to tackle this challenge by integrating a GDM function with an informative path planning framework. Several GDM methods are explored for their suitability in cluttered environments and the GMRF method is chosen due to its ability to account for obstacle interactions within the plume. Based on the outputs of the GMRF, several reward functions are proposed for the informative path planner. These functions are compared to a lawnmower sweep in a high fidelity simulation, where the RMSE of the modelled gas distribution is recorded over time. It is found that informing the robot with uncertainty, normalised concentration and time cost, significantly reduces the time required for a single robot to achieve an accurate map in a large-scale, urban environment. In the context of a hazardous gas release scenario, this time reduction could save lives as well as further gas ingress.",
        "primary_area": "",
        "author": "Callum Rhodes;Cunjia Liu;Wen-Hua Chen;Callum Rhodes;Cunjia Liu;Wen-Hua Chen",
        "authorids": "/37088687600;/38195632200;/37279192700;/37088687600;/38195632200;/37279192700",
        "aff": "Department of Aeronautical and Automotive Engineering, Loughborough University, UK; Department of Aeronautical and Automotive Engineering, Loughborough University, UK; Department of Aeronautical and Automotive Engineering, Loughborough University, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341781/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5027569173820693965&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Loughborough University",
        "aff_unique_dep": "Department of Aeronautical and Automotive Engineering",
        "aff_unique_url": "https://www.lboro.ac.uk",
        "aff_unique_abbr": "Loughborough",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9341499",
        "title": "Infusing Reachability-Based Safety into Planning and Control for Multi-agent Interactions",
        "track": "main",
        "status": "Poster",
        "abstract": "Within a robot autonomy stack, the planner and controller are typically designed separately, and serve different purposes. As such, there is often a diffusion of responsibilities when it comes to ensuring safety for the robot. We propose that a planner and controller should share the same interpretation of safety but apply this knowledge in a different yet complementary way. To achieve this, we use Hamilton-Jacobi (HJ) reachability theory at the planning level to provide the robot planner with the foresight to avoid entering regions with possible inevitable collision. However, this alone does not guarantee safety. In conjunction with this HJ reachability-infused planner, we propose a minimally-interventional multi-agent safety-preserving controller also derived via HJ-reachability theory. The safety controller maintains safety for the robot without unduly impacting planner performance. We demonstrate the benefits of our proposed approach in a multi-agent highway scenario where a robot car is rewarded to navigate through traffic as fast as possible, and we show that our approach provides strong safety assurances yet achieves the highest performance compared to other safety controllers.",
        "primary_area": "",
        "author": "Xinrui Wang;Karen Leung;Marco Pavone;Xinrui Wang;Karen Leung;Marco Pavone",
        "authorids": "/37088691008;/37086453267;/37307912900;/37088691008;/37086453267;/37307912900",
        "aff": "Department of Mechanical Engineering, Stanford University, Stanford, CA; Department of Aeronautics and Astronautics, Stanford University, Stanford, CA; Department of Aeronautics and Astronautics, Stanford University, Stanford, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341499/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12966266662888585577&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341017",
        "title": "Inner-Approximation of Manipulable and Reachable Regions using Bilinear Matrix Inequalities",
        "track": "main",
        "status": "Poster",
        "abstract": "Given an articulated robot arm, we present a method to identify two regions with non-empty interiors. The first region is a subset of the configuration space where every point in the region is manipulable. The second region is a subset of the workspace where every point in the region is reachable by the end-effector. Our method expresses the kinematic state of the robot arm using the maximal coordinates, so that the kinematic constraints take polynomial forms. We then reformulate the optimization-based inverse kinematics (IK) algorithm as gradient flows. Finally, we use sum-of-squares (SOS) programming to certify the convergence of each gradient flow. Our main result shows that the feasibility of an SOS programming problem is a sufficient condition for the manipulability and reachability of the sublevel sets of polynomial functions. Our method can be used to certify manipulable or reachable regions by solving a set of linear matrix inequalities (LMIs) or to maximize the volume of a region by solving a set of bilinear matrix inequalities (BMIs). These identified regions can then be used in various motion planning problems as hard safety constraints.",
        "primary_area": "",
        "author": "Zherong Pan;Liang He;Xifeng Gao;Zherong Pan;Liang He;Xifeng Gao",
        "authorids": "/37086067204;/37085756943;/37088506715;/37086067204;/37085756943;/37088506715",
        "aff": "Department of Computer Science, University of North Carolina, Chapel Hill; Department of Computer Science, University of North Carolina, Chapel Hill; Department of Computer Science, Florida State University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341017/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2501455337685036516&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "University of North Carolina;Florida State University",
        "aff_unique_dep": "Department of Computer Science;Department of Computer Science",
        "aff_unique_url": "https://www.unc.edu;https://www.fsu.edu",
        "aff_unique_abbr": "UNC;FSU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Chapel Hill;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341397",
        "title": "Inspection-on-the-fly using Hybrid Physical Interaction Control for Aerial Manipulators",
        "track": "main",
        "status": "Poster",
        "abstract": "Inspection for structural properties (surface stiffness and coefficient of restitution) is crucial for understanding and performing aerial manipulations in unknown environments, with little to no prior knowledge on their state. Inspection-on-the-fly is the uncanny ability of humans to infer states during manipulation, reducing the necessity to perform inspection and manipulation separately. This paper presents an infrastructure for inspection-on-the-fly method for aerial manipulators using hybrid physical interaction control. With the proposed method, structural properties (surface stiffness and coefficient of restitution) can be estimated during physical interactions. A three-stage hybrid physical interaction control paradigm is presented to robustly approach, acquire and impart a desired force signature onto a surface. This is achieved by combining a hybrid force/motion controller with a model-based feed-forward impact control as intermediate phase. The proposed controller ensures a steady transition from unconstrained motion control to constrained force control, while reducing the lag associated with the force control phase. And an underlying Operational Space dynamic configuration manager permits complex, redundant vehicle/arm combinations. Experiments were carried out in a mock-up of a Dept. of Energy exhaust shaft, to show the effectiveness of the inspection-on-the-fly method to determine the structural properties of the target surface and the performance of the hybrid physical interaction controller in reducing the lag associated with force control phase.",
        "primary_area": "",
        "author": "Abbaraju Praveen;Xin Ma;Harikrishnan Manoj;Vishnunandan LN. Venkatesh;Mo Rastgaar;Richard M. Voyles;Abbaraju Praveen;Xin Ma;Harikrishnan Manoj;Vishnunandan LN. Venkatesh;Mo Rastgaar;Richard M. Voyles",
        "authorids": "/37088598795;/37085857304;/37088687813;/37087235917;/37085355283;/37283531400;/37088598795;/37085857304;/37088687813;/37087235917;/37085355283;/37283531400",
        "aff": "Purdue Polytechnic Institute, Purdue University, IN, USA; School of Engineering Technology, Purdue Polytechnic Institute, Purdue University, IN, USA; Purdue Polytechnic Institute, Purdue University, IN, USA; Purdue Polytechnic Institute, Purdue University, IN, USA; School of Engineering Technology, Purdue Polytechnic Institute, Purdue University, IN, USA; School of Engineering Technology, Purdue Polytechnic Institute, Purdue University, IN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341397/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12114105389057113319&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Purdue University",
        "aff_unique_dep": "Purdue Polytechnic Institute",
        "aff_unique_url": "https://www.purdue.edu",
        "aff_unique_abbr": "Purdue",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "West Lafayette",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340647",
        "title": "Integrated Actuation and Self-Sensing for Twisted-and-Coiled Actuators with Applications to Innervated Soft Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Traditional soft robots require separate sensors and actuators to precisely control their motion. A twisted-and-coiled actuator (TCA) is a new artificial muscle with both actuation and self-sensing capability that can simultaneously serve both as a sensor and an actuator allowing to control the motion of TCAs without external sensors. This paper investigates the integrated sensing and actuation for TCAs, and the self-sensing function is realized by only measuring the TCA's electrical resistance change. The closed-loop control of a single TCA is realized, and an innervated soft finger that can respond to external load without extra sensors is demonstrated. Our results will lay a foundation for integrated sensing and control by directly using the actuator, paving the way for self-contained smart robotic systems (e.g., untethered soft robots).",
        "primary_area": "",
        "author": "Jiefeng Sun;Jianguo Zhao;Jiefeng Sun;Jianguo Zhao",
        "authorids": "/37086575299;/37537638600;/37086575299;/37537638600",
        "aff": "Department of Mechanical Engineering, Colorado State University, Fort Collins, CO, USA; Department of Mechanical Engineering, Colorado State University, Fort Collins, CO, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340647/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5128257542602949205&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Colorado State University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.colostate.edu",
        "aff_unique_abbr": "CSU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Fort Collins",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341677",
        "title": "Integrated Benchmarking and Design for Reproducible and Accessible Evaluation of Robotic Agents",
        "track": "main",
        "status": "Poster",
        "abstract": "As robotics matures and increases in complexity, it is more necessary than ever that robot autonomy research be reproducible. Compared to other sciences, there are specific challenges to benchmarking autonomy, such as the complexity of the software stacks, the variability of the hardware and the reliance on data-driven techniques, amongst others. In this paper, we describe a new concept for reproducible robotics research that integrates development and benchmarking, so that reproducibility is obtained \"by design\" from the beginning of the research/development processes. We first provide the overall conceptual objectives to achieve this goal and then a concrete instance that we have built: the DUCKIENet. One of the central components of this setup is the Duckietown Autolab, a remotely accessible standardized setup that is itself also relatively low-cost and reproducible. When evaluating agents, careful definition of interfaces allows users to choose among local versus remote evaluation using simulation, logs, or remote automated hardware setups. We validate the system by analyzing the repeatability of experiments conducted using the infrastructure and show that there is low variance across different robot hardware and across different remote labs.\u2020",
        "primary_area": "",
        "author": "Jacopo Tani;Andrea F. Daniele;Gianmarco Bernasconi;Amaury Camus;Aleksandar Petrov;Anthony Courchesne;Bhairav Mehta;Rohit Suri;Tomasz Zaluska;Matthew R. Walter;Emilio Frazzoli;Liam Paull;Andrea Censi;Jacopo Tani;Andrea F. Daniele;Gianmarco Bernasconi;Amaury Camus;Aleksandar Petrov;Anthony Courchesne;Bhairav Mehta;Rohit Suri;Tomasz Zaluska;Matthew R. Walter;Emilio Frazzoli;Liam Paull;Andrea Censi",
        "authorids": "/38548446100;/37086513930;/37088687030;/37088691408;/37088507281;/37088688218;/37088689641;/37088507492;/37088686830;/37392432700;/37283368500;/37935956000;/37398994000;/38548446100;/37086513930;/37088687030;/37088691408;/37088507281;/37088688218;/37088689641;/37088507492;/37088686830;/37392432700;/37283368500;/37935956000;/37398994000",
        "aff": "ETH Z\u00fcrich, Switzerland; Toyota Technological Institute at Chicago, Chicago, USA; ETH Z\u00fcrich, Switzerland; ETH Z\u00fcrich, Switzerland; ETH Z\u00fcrich, Switzerland; Mila, Universit\u00e9 de Montr\u00e9al, Montr\u00e9al, Canada; Mila, Universit\u00e9 de Montr\u00e9al, Montr\u00e9al, Canada; ETH Z\u00fcrich, Switzerland; ETH Z\u00fcrich, Switzerland; Toyota Technological Institute at Chicago, Chicago, USA; nuTonomy, an Aptiv company, Boston, USA; Mila, Universit\u00e9 de Montr\u00e9al, Montr\u00e9al, Canada; ETH Z\u00fcrich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341677/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13180066895991018349&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 26,
        "aff_unique_index": "0;1;0;0;0;2;2;0;0;1;3;2;0",
        "aff_unique_norm": "ETH Z\u00fcrich;Toyota Technological Institute at Chicago;Universit\u00e9 de Montr\u00e9al;nuTonomy",
        "aff_unique_dep": ";;Mila;",
        "aff_unique_url": "https://www.ethz.ch;https://www.tti-chicago.org;https://www.umontreal.ca;",
        "aff_unique_abbr": "ETHZ;TTI Chicago;UdeM;",
        "aff_campus_unique_index": "1;2;2;1;3;2",
        "aff_campus_unique": ";Chicago;Montr\u00e9al;Boston",
        "aff_country_unique_index": "0;1;0;0;0;2;2;0;0;1;1;2;0",
        "aff_country_unique": "Switzerland;United States;Canada"
    },
    {
        "id": "9341673",
        "title": "Integrating Model Predictive Control and Dynamic Waypoints Generation for Motion Planning in Surgical Scenario",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper we present a novel strategy for motion planning of autonomous robotic arms in Robotic Minimally Invasive Surgery (R-MIS). We consider a scenario where several laparoscopic tools must move and coordinate in a shared environment. The motion planner is based on a Model Predictive Controller (MPC) that predicts the future behavior of the robots and allows to move them avoiding collisions between the tools and satisfying the velocity limitations. In order to avoid the local minima that could affect the MPC, we propose a strategy for driving it through a sequence of waypoints. The proposed control strategy is validated on a realistic surgical scenario.",
        "primary_area": "",
        "author": "Marco Minelli;Alessio Sozzi;Giacomo De Rossi;Federica Ferraguti;Francesco Setti;Riccardo Muradore;Marcello Bonf\u00e8;Cristian Secchi;Marco Minelli;Alessio Sozzi;Giacomo De Rossi;Federica Ferraguti;Francesco Setti;Riccardo Muradore;Marcello Bonf\u00e8;Cristian Secchi",
        "authorids": "/37086036138;/37087322421;/37085759529;/37075262200;/37887481900;/37299825000;/37300903100;/37300905500;/37086036138;/37087322421;/37085759529;/37075262200;/37887481900;/37299825000;/37300903100;/37300905500",
        "aff": "Dept. of Sciences and Methods of Engineering, University of Modena and Reggio, Emilia, Italy; Dept. of Engineering, University of Ferrara, Italy; Dept. of Computer Science, University of Verona, Italy; Dept. of Sciences and Methods of Engineering, University of Modena and Reggio, Emilia, Italy; Dept. of Computer Science, University of Verona, Italy; Dept. of Computer Science, University of Verona, Italy; Dept. of Engineering, University of Ferrara, Italy; Dept. of Sciences and Methods of Engineering, University of Modena and Reggio, Emilia, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341673/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1593353401080764446&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;2;0;2;2;1;0",
        "aff_unique_norm": "University of Modena and Reggio Emilia;University of Ferrara;University of Verona",
        "aff_unique_dep": "Dept. of Sciences and Methods of Engineering;Dept. of Engineering;Dept. of Computer Science",
        "aff_unique_url": "https://www.unimore.it;https://www.unife.it;https://www.univr.it",
        "aff_unique_abbr": ";;UniVR",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9341525",
        "title": "Intelligent Exploration and Autonomous Navigation in Confined Spaces",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous navigation and exploration in confined spaces are currently setting new challenges for robots. The presence of narrow passages, flammable atmosphere, dust, smoke, and other hazards makes the mapping and navigation tasks extremely difficult. To tackle these challenges, robots need to make intelligent decisions, maximising information while maintaining the safety of the system and their surroundings. In this paper, we present a suite of reasoning mechanisms along with a software architecture for exploration tasks that can be used to underpin the behavior of a broad range of robots operating in confined spaces. We present an autonomous navigation module that allows the robot to safely traverse known areas of the environment and extract features of the unknown frontier regions. An exploration component, by reasoning about these frontiers, provides the robot with the ability to venture into new spaces. From low-level sensory input and contextual information, the robot incrementally builds a semantic network that represents known and unknown parts of the environment and then uses a logic-based, high-level reasoner to interrogate such a network and decide the best course of actions. We evaluate our approach against several mine-like challenging scenarios with different characteristics using a small drone. The experimental results indicate that our method allows the robot to make informed decisions on how to best explore the environment while preserving safety.",
        "primary_area": "",
        "author": "Aliakbar Akbari;Puneet S Chhabra;Ujjar Bhandari;Sara Bernardini;Aliakbar Akbari;Puneet S Chhabra;Ujjar Bhandari;Sara Bernardini",
        "authorids": "/37077002600;/37085881900;/37088688132;/37088477602;/37077002600;/37085881900;/37088688132;/37088477602",
        "aff": "Department of Computer Science, Royal Holloway University of London, Egham, UK; Headlight AI Ltd., London, UK; Headlight AI Ltd., London, UK; Department of Computer Science, Royal Holloway University of London, Egham, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341525/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3041378867627240595&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "Royal Holloway University of London;Headlight AI Ltd.",
        "aff_unique_dep": "Department of Computer Science;",
        "aff_unique_url": "https://www.royalholloway.ac.uk;",
        "aff_unique_abbr": "RHUL;",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Egham;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9341440",
        "title": "Intent-driven Strategic Tactical Planning for Autonomous Site Inspection using Cooperative Drones",
        "track": "main",
        "status": "Poster",
        "abstract": "Realization of industry-scale, goal-driven, autonomous systems with AI planning technology faces several challenges: flexibly specifying planning goal states in varying situations, synthesizing plans in large state spaces, re-planning in dynamic situations, and facilitating humans to supervise, give feedback and intervene. In this paper, we present Intent-driven Strategic Tactical Planning (ISTP) to address these challenges. We demonstrate its efficacy through its application for radio base station inspection across several locations using drones. The inspection task involves capturing images, thermal images or signal measurements - called knowledge-objects - of various components of the base stations for downstream processing. In the ISTP approach, an operator indicates her goals by flying the drone to different components of interest. These goals are generalized to capture the intent of the operator, which are then instantiated in new situations to generate goals dynamically. Towards planning and re-planning in large state spaces to achieve these goals efficiently, we extend the Strategic-Tactical Planning paradigm. All the components of ISTP are integrated in an intuitive UI and demonstrated through a real life use-case built on the UNITY simulator platform.",
        "primary_area": "",
        "author": "Dorian Buksz;Anusha Mujumdar;Marin Orli\u0107;Swarup Mohalik;Marios Daoutis;Ramamurthy Badrinath;Daniele Magazzeni;Michael Cashmore;Aneta Vulgarakis Feljan;Dorian Buksz;Anusha Mujumdar;Marin Orli\u0107;Swarup Mohalik;Marios Daoutis;Ramamurthy Badrinath;Daniele Magazzeni;Michael Cashmore;Aneta Vulgarakis Feljan",
        "authorids": "/37086576137;/37085441108;/37073851000;/37622135000;/37088687598;/37086030310;/37396815200;/37085372002;/37087791653;/37086576137;/37085441108;/37073851000;/37622135000;/37088687598;/37086030310;/37396815200;/37085372002;/37087791653",
        "aff": "King\u2019s College, London; Ericsson Research; Ericsson Research; Ericsson Research; Ericsson Research; Ericsson Research; King\u2019s College, London; King\u2019s College, London; Ericsson Research",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341440/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4085953692665509224&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;1;1;1;1;1;0;0;1",
        "aff_unique_norm": "King's College London;Ericsson",
        "aff_unique_dep": ";Research",
        "aff_unique_url": "https://www.kcl.ac.uk;https://www.ericsson.com/research",
        "aff_unique_abbr": "KCL;Ericsson",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "London;",
        "aff_country_unique_index": "0;1;1;1;1;1;0;0;1",
        "aff_country_unique": "United Kingdom;Sweden"
    },
    {
        "id": "9341227",
        "title": "Inter-Robot Range Measurements in Pose Graph Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "For multiple robots performing exploration in a previously unmapped environment, such as planetary exploration, maintaining accurate localization and building a consistent map are vital. If the robots do not have a map to localize against and do not explore the same area, they may not be able to find visual loop closures to constrain their relative poses, making traditional SLAM impossible. This paper presents a method for using UWB ranging sensors in multi-robot SLAM, which allows the robots to localize and build a map together even without visual loop closures. The ranging measurements are added to the pose graph as edges and used in optimization to estimate the robots' relative poses. This method builds a map using all robots' observations that is consistent and usable. It performs similarly to visual loop closures when they are available, and provides a good map when they are not, which other methods cannot do. The method is demonstrated on PUFFER robots, developed for autonomous planetary exploration, in an unstructured environment.",
        "primary_area": "",
        "author": "Elizabeth R. Boroson;Robert Hewitt;Nora Ayanian;Jean-Pierre de la Croix;Elizabeth R. Boroson;Robert Hewitt;Nora Ayanian;Jean-Pierre de la Croix",
        "authorids": "/37086933573;/37073604800;/37546534600;/37085366579;/37086933573;/37073604800;/37546534600;/37085366579",
        "aff": "Department of Computer Science, University of Southern California, Los Angeles, CA, USA; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, USA; Department of Computer Science, University of Southern California, Los Angeles, CA, USA; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341227/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10435146777597777410&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;1",
        "aff_unique_norm": "University of Southern California;California Institute of Technology",
        "aff_unique_dep": "Department of Computer Science;Jet Propulsion Laboratory",
        "aff_unique_url": "https://www.usc.edu;https://www.caltech.edu",
        "aff_unique_abbr": "USC;Caltech",
        "aff_campus_unique_index": "0;1;0;1",
        "aff_campus_unique": "Los Angeles;Pasadena",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340796",
        "title": "Interacting Multiple Model Navigation System for Quadrotor Micro Aerial Vehicles Subject to Rotor Drag",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents the design of an Interacting Multiple Model (IMM) filter for improved navigation performance of Micro Aerial Vehicles (MAVs). The paper considers a navigation system that incorporates rotor drag dynamics and proposes a strategy to overcome the sensitivity of the system to external wind disturbances. Two error state Kalman filters are incorporated in an IMM filtering framework. The first filter has a model that uses conventional Inertial Navigation System (INS) mechanization equations, while the second filter considers a dynamic model with rotor drag forces of the MAV. In order to support the two error state Kalman filters, the generic IMM algorithm [1] is modified for error state implementation, handle dissimilar state definitions, and adaptive switching during operation. Numerical simulations and experimental validation using the EuRoC dataset are conducted to evaluate the performance of the proposed IMM filter design for changing flight conditions and external wind disturbance scenarios.",
        "primary_area": "",
        "author": "Mahmoud A.K. Gomaa;Oscar De Silva;George K.I. Mann;Raymond G. Gosine;Mahmoud A.K. Gomaa;Oscar De Silva;George K.I. Mann;Raymond G. Gosine",
        "authorids": "/37088487430;/38542316100;/37295686400;/37293905000;/37088487430;/38542316100;/37295686400;/37293905000",
        "aff": "Memorial University of Newfoundland, Canada; Memorial University of Newfoundland, Canada; Memorial University of Newfoundland, Canada; Memorial University of Newfoundland, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340796/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10168972812354622814&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Memorial University of Newfoundland",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.mun.ca",
        "aff_unique_abbr": "MUN",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9341728",
        "title": "Interactive Movement Primitives: Planning to Push Occluding Pieces for Fruit Picking",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic technology is increasingly considered the major mean for fruit picking. However, picking fruits in a dense cluster imposes a challenging research question in terms of motion/path planning as conventional planning approaches may not find collision-free movements for the robot to reach-and-pick a ripe fruit within a dense cluster. In such cases, the robot needs to safely push unripe fruits to reach a ripe one. Nonetheless, existing approaches to planning pushing movements in cluttered environments either are computationally expensive or only deal with 2-D cases and are not suitable for fruit picking, where it needs to compute 3-D pushing movements in a short time. In this work, we present a path planning algorithm for pushing occluding fruits to reach-and-pick a ripe one. Our proposed approach, called Interactive Probabilistic Movement Primitives (I-ProMP), is not computationally expensive (its computation time is in the order of 100 milliseconds) and is readily used for 3-D problems. We demonstrate the efficiency of our approach with pushing unripe strawberries in a simulated polytunnel. Our experimental results confirm I-ProMP successfully pushes table top grown strawberries and reaches a ripe one.",
        "primary_area": "",
        "author": "Sariah Mghames;Marc Hanheide;Amir Ghalamzan E.;Sariah Mghames;Marc Hanheide;Amir Ghalamzan E.",
        "authorids": "/37086176884;/37270387300;/37086051585;/37086176884;/37270387300;/37086051585",
        "aff": "Centre for Autonomous Systems (L-CAS), University of Lincoln, UK; Centre for Autonomous Systems (L-CAS), University of Lincoln, UK; Centre for Autonomous Systems (L-CAS), University of Lincoln, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341728/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4580413905917779068&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Lincoln",
        "aff_unique_dep": "Centre for Autonomous Systems (L-CAS)",
        "aff_unique_url": "https://www.lincoln.ac.uk",
        "aff_unique_abbr": "UoL",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9340800",
        "title": "Interactive Planning and Supervised Execution for High-Risk, High-Latency Teleoperation",
        "track": "main",
        "status": "Poster",
        "abstract": "Ground-based teleoperation of robot manipulators for on-orbit servicing of spacecraft represents an example of high-payoff, high-risk operations that are challenging to perform due to high latency communications, with telemetry time delays of several seconds. In these scenarios, confidence of operating without failure is paramount. We report the development of an Interactive Planning and Supervised Execution (IPSE) system that takes advantage of accurate 3D reconstruction of the remote environment to enable operators to plan motions in the virtual world, evaluate and adjust the plan, and then supervise execution with the ability to pause and return to the planning environment at any time. We report the results of an experimental evaluation of a representative on-orbit telerobotic servicing task from NASA's upcoming OSAM-1 mission to refuel a satellite in low earth orbit; specifically, to change the robot tool to acquire the fuel supply line and then to insert it into the satellite fill/drain valve. Results of a pilot study show that the operators preferred, and were more successful with, the IPSE system when compared to a conventional teleoperation implementation.",
        "primary_area": "",
        "author": "Will Pryor;Balazs P. Vagvolgyi;Anton Deguet;Simon Leonard;Louis L. Whitcomb;Peter Kazanzides;Will Pryor;Balazs P. Vagvolgyi;Anton Deguet;Simon Leonard;Louis L. Whitcomb;Peter Kazanzides",
        "authorids": "/37086104864;/37568674700;/37427184100;/37269567400;/37283591700;/37375173500;/37086104864;/37568674700;/37427184100;/37269567400;/37283591700;/37375173500",
        "aff": "Johns Hopkins University, Baltimore, MD, USA; Johns Hopkins University, Baltimore, MD, USA; Johns Hopkins University, Baltimore, MD, USA; Johns Hopkins University, Baltimore, MD, USA; Johns Hopkins University, Baltimore, MD, USA; Johns Hopkins University, Baltimore, MD, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340800/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13165174804386024942&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Johns Hopkins University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.jhu.edu",
        "aff_unique_abbr": "JHU",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Baltimore",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341795",
        "title": "Interactive Tactile Perception for Classification of Novel Object Instances",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a novel approach for classification of unseen object instances from interactive tactile feedback. Furthermore, we demonstrate the utility of a low resolution tactile sensor array for tactile perception that can potentially close the gap between vision and physical contact for manipulation. We contrast our sensor to high-resolution camera-based tactile sensors. Our proposed approach interactively learns a one-class classification model using 3D tactile descriptors, and thus demonstrates an advantage over the existing approaches, which require pre-training on objects. We describe how we derive 3D features from the tactile sensor inputs, and exploit them for learning one-class classifiers. In addition, since our proposed method uses unsupervised learning, we do not require ground truth labels. This makes our proposed method flexible and more practical for deployment on robotic systems. We validate our proposed method on a set of household objects and results indicate good classification performance in real-world experiments.",
        "primary_area": "",
        "author": "Radu Corcodel;Siddarth Jain;Jeroen van Baar;Radu Corcodel;Siddarth Jain;Jeroen van Baar",
        "authorids": "/37088340287;/37088688017;/37324479700;/37088340287;/37088688017;/37324479700",
        "aff": "Mitsubishi Electric Research Laboratories (MERL), Cambridge, MA, USA; Mitsubishi Electric Research Laboratories (MERL), Cambridge, MA, USA; Mitsubishi Electric Research Laboratories (MERL), Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341795/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17239308788538724006&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Mitsubishi Electric Research Laboratories",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.merl.com",
        "aff_unique_abbr": "MERL",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340819",
        "title": "Intermittent Insertion Control Method with Fine Needle for Adapting Lung Deformation due to Breathing Motion",
        "track": "main",
        "status": "Poster",
        "abstract": "Fine needle insertions into a lung are challenging in terms of the needle deflection due to the breathing motion. Although previous related works neglected the effect for the needle deflection due to the breathing motion by patients stopping the breath during the insertion, they have to suffer from the discomfort. This paper proposes the intermittent insertion control method to decrease needle deflection adapting the lung deformation due to the breathing motion. The novelty of this method is to allow for accurate needle insertion without stopping the breath, which will contribute to decreasing the discomfort and the amount of radiation exposure for patients. The intermittent insertion is to move forward the fine needle during a certain time frame that the needle deflection barely occurs since the lung is not deformed by the diaphragm motion. The feasibility of the proposed method was validated through a polyvinyl chloride (PVC) phantom and ex vivo experiments. The results showed that the deflection can be suppressed up to 1.3 mm and 3.9 mm in the PVC phantom and ex vivo experiments, respectively.",
        "primary_area": "",
        "author": "Ryosuke Tsumura;Kaoru Kakima;Hiroyasu Iwata;Ryosuke Tsumura;Kaoru Kakima;Hiroyasu Iwata",
        "authorids": "/37085879374;/37088689566;/37326645800;/37085879374;/37088689566;/37326645800",
        "aff": "Global Robot Academia Laboratory, Waseda University, Tokyo, Japan; School of Creative Science and Engineering, Waseda University, Tokyo, Japan; Faculty of Science and Engineering, Waseda University, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340819/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14030767882792849936&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Waseda University",
        "aff_unique_dep": "Global Robot Academia Laboratory",
        "aff_unique_url": "https://www.waseda.jp/top",
        "aff_unique_abbr": "Waseda",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9341252",
        "title": "Introduction to 7-DoF CoSMo-Arm: High Torque Density Manipulator based on CoSMoA and E-CoSMo",
        "track": "main",
        "status": "Poster",
        "abstract": "This study proposes a novel 7-DOF robotic manipulator called CoSMo-Arm for high torque density multi-link robotic platform based on a concentrically stacked modular actuator (CoSMoA) and an extended coaxial spherical joint module (E-CoSMo) introduced in previous researches. The CoSMoA is an actuator module designed to improve thermal characteristics by stacking the motor actuator parts to share the heat dissipation device of the adjacent actuator module, thereby theoretically amplifying motor performance by approximately 3.2 times. The E-CoSMo is a parallel joint mechanism connected to the end of the CoSMoA to create point-centered rotational four degrees of freedom. This joint module has a large range of motion in specific rotational directions and maximum output of approximately up to four times to the actuator output in the specific workspace. The CoSMo-Arm is designed to take advantages of these novel concept modules, having a higher payload than its own weight. To verify the benefits of the proposed mechanism, we performed kinematic analysis and dynamics simulations. From experimental verifications of the real prototype, the feasibility and validity are confirmed as a multi-DOF robotic manipulator.",
        "primary_area": "",
        "author": "Jaeho Noh;Jaeyong Lee;Seyoung Cheon;Woosung Yang;Jaeho Noh;Jaeyong Lee;Seyoung Cheon;Woosung Yang",
        "authorids": "/37086070089;/37086580696;/37089138390;/37556518300;/37086070089;/37086580696;/37089138390;/37556518300",
        "aff": "Kwangwoon University, Seoul, Republic of Korea; Kwangwoon University, Seoul, Republic of Korea; Kwangwoon University, Seoul, Republic of Korea; Kwangwoon University, Seoul, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341252/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=614491263218451704&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Kwangwoon University",
        "aff_unique_dep": "",
        "aff_unique_url": "http://www.kwangwoon.ac.kr",
        "aff_unique_abbr": "KWU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9341332",
        "title": "Invisible Marker: Automatic Annotation of Segmentation Masks for Object Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a method to annotate segmentation masks accurately and automatically using invisible marker for object manipulation. Invisible marker is invisible under visible (regular) light conditions, but becomes visible under invisible light, such as ultraviolet (UV) light. By painting objects with the invisible marker, and by capturing images while alternately switching between regular and UV light at high speed, massive annotated datasets are created quickly and inexpensively. We show a comparison between our proposed method and manual annotations. We demonstrate semantic segmentation for deformable objects including clothes, liquids, and powders under controlled environmental light conditions. In addition, we show demonstrations of liquid pouring tasks under uncontrolled environmental light conditions in complex environments such as inside the office, house, and outdoors. Furthermore, it is possible to capture data while the camera is in motion so it becomes easier to capture large datasets, as shown in our demonstration.",
        "primary_area": "",
        "author": "Kuniyuki Takahashi;Kenta Yonekura;Kuniyuki Takahashi;Kenta Yonekura",
        "authorids": "/37086937050;/37088687045;/37086937050;/37088687045",
        "aff": "associated with Preferred Networks, Inc.; associated with Preferred Networks, Inc.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341332/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8287837541815823892&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Preferred Networks, Inc.",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.preferred-networks.jp",
        "aff_unique_abbr": "PFN",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9341635",
        "title": "JRMOT: A Real-Time 3D Multi-Object Tracker and a New Large-Scale Dataset",
        "track": "main",
        "status": "Poster",
        "abstract": "Robots navigating autonomously need to perceive and track the motion of objects and other agents in its surroundings. This information enables planning and executing robust and safe trajectories. To facilitate these processes, the motion should be perceived in 3D Cartesian space. However, most recent multi-object tracking (MOT) research has focused on tracking people and moving objects in 2D RGB video sequences. In this work we present JRMOT, a novel 3D MOT system that integrates information from RGB images and 3D point clouds to achieve real-time, state-of-the-art tracking performance. Our system is built with recent neural networks for re-identification, 2D and 3D detection and track description, combined into a joint probabilistic data-association framework within a multi-modal recursive Kalman architecture. As part of our work, we release the JRDB dataset, a novel large scale 2D+3D dataset and benchmark, annotated with over 2 million boxes and 3500 time consistent 2D+3D trajectories across 54 indoor and outdoor scenes. JRDB contains over 60 minutes of data including 360o cylindrical RGB video and 3D pointclouds in social settings that we use to develop, train and evaluate JRMOT. The presented 3D MOT system demonstrates state-of-the-art performance against competing methods on the popular 2D tracking KITTI benchmark and serves as first 3D tracking solution for our benchmark. Real-robot tests on our social robot JackRabbot indicate that the system is capable of tracking multiple pedestrians fast and reliably. We provide the ROS code of our tracker at https://sites.google.com/view/jrmot.",
        "primary_area": "",
        "author": "Abhijeet Shenoi;Mihir Patel;JunYoung Gwak;Patrick Goebel;Amir Sadeghian;Hamid Rezatofighi;Roberto Mart\u00edn-Mart\u00edn;Silvio Savarese;Abhijeet Shenoi;Mihir Patel;JunYoung Gwak;Patrick Goebel;Amir Sadeghian;Hamid Rezatofighi;Roberto Mart\u00edn-Mart\u00edn;Silvio Savarese",
        "authorids": "/37086527257;/37088686381;/37085703158;/37086575569;/37086284079;/37087010759;/37085788640;/37298502600;/37086527257;/37088686381;/37085703158;/37086575569;/37086284079;/37087010759;/37085788640;/37298502600",
        "aff": "Stanford Vision and Learning Laboratory, Stanford University, USA; Stanford Vision and Learning Laboratory, Stanford University, USA; Stanford Vision and Learning Laboratory, Stanford University, USA; Stanford Vision and Learning Laboratory, Stanford University, USA; Stanford Vision and Learning Laboratory, Stanford University, USA; Stanford Vision and Learning Laboratory, Stanford University, USA; Stanford Vision and Learning Laboratory, Stanford University, USA; Stanford Vision and Learning Laboratory, Stanford University, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341635/",
        "gs_citation": 106,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17103687485751894945&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "Stanford Vision and Learning Laboratory",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341654",
        "title": "Joint Feature Selection and Time Optimal Path Parametrization for High Speed Vision-Aided Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "We study a problem in vision-aided navigation in which an autonomous agent has to traverse a specified path in minimal time while ensuring extraction of a steady stream of visual percepts with low latency. Vision-aided robots extract motion estimates from the sequence of images of their on-board cameras by registering the change in bearing to landmarks in their environment. The computational burden of the latter procedure grows with the range of apparent motion undertaken by the projections of the landmarks, incurring a lag in pose estimates that should be minimized while navigating at high speeds. This paper addresses the problem of selecting a desired number of landmarks in the environment, together with the time parametrization of the path, to allow the agent execute it in minimal time while both (i) ensuring the computational burden of extracting motion estimates stays below a set threshold and (ii) respecting the actuation constraints of the agent. We provide two efficient approximation algorithms for addressing the aforementioned problem. Also, we show how it can be reduced to a mixed integer linear program for which there exist well-developed optimization packages. Ultimately, we illustrate the performance of our algorithms in experiments using a quadrotor.",
        "primary_area": "",
        "author": "Igor Spasojevic;Varun Murali;Sertac Karaman;Igor Spasojevic;Varun Murali;Sertac Karaman",
        "authorids": "/37086856146;/37086855117;/37304113000;/37086856146;/37086855117;/37304113000",
        "aff": "Department of Aeronautics and Astronautics and the Laboratory for Information and Decision Systems, Massachusetts Institute of Technology (MIT), Cambridge, MA, USA; Department of Aeronautics and Astronautics and the Laboratory for Information and Decision Systems, Massachusetts Institute of Technology (MIT), Cambridge, MA, USA; Department of Aeronautics and Astronautics and the Laboratory for Information and Decision Systems, Massachusetts Institute of Technology (MIT), Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341654/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5129750334446232972&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Department of Aeronautics and Astronautics",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340700",
        "title": "Joint-Level Control of the DLR Lightweight Robot SARA",
        "track": "main",
        "status": "Poster",
        "abstract": "Lightweight robots are known to be intrinsically elastic in their joints. The established classical approaches to control such systems are mostly based on motor-side coordinates since the joints are comparatively stiff. However, that inevitably introduces errors in the coordinates that actually matter: the ones on the link side. Here we present a new joint-torque controller that uses feedback of the link-side positions. Passivity during interaction with the environment is formally shown as well as asymptotic stability of the desired equilibrium in the regulation case. The performance of the control approach is experimentally validated on DLR's new generation of lightweight robots, namely the SARA robot, which enables this step from motor-side-based to link-sided-based control due to sensors with higher resolution and improved sampling rate.",
        "primary_area": "",
        "author": "Maged Iskandar;Christian Ott;Oliver Eiberger;Manuel Keppler;Alin Albu-Sch\u00e4ffer;Alexander Dietrich;Maged Iskandar;Christian Ott;Oliver Eiberger;Manuel Keppler;Alin Albu-Sch\u00e4ffer;Alexander Dietrich",
        "authorids": "/37086454969;/37282440400;/37295473300;/37085817503;/38270361100;/37970388100;/37086454969;/37282440400;/37295473300;/37085817503;/38270361100;/37970388100",
        "aff": "DLR - German Aerospace Center, Robotics and Mechatronics Center, Institute of Robotics and Mechatronics, Wessling, Germany; DLR - German Aerospace Center, Robotics and Mechatronics Center, Institute of Robotics and Mechatronics, Wessling, Germany; DLR - German Aerospace Center, Robotics and Mechatronics Center, Institute of Robotics and Mechatronics, Wessling, Germany; DLR - German Aerospace Center, Robotics and Mechatronics Center, Institute of Robotics and Mechatronics, Wessling, Germany; DLR - German Aerospace Center, Robotics and Mechatronics Center, Institute of Robotics and Mechatronics, Wessling, Germany; DLR - German Aerospace Center, Robotics and Mechatronics Center, Institute of Robotics and Mechatronics, Wessling, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340700/",
        "gs_citation": 38,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4412161506125613983&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "German Aerospace Center",
        "aff_unique_dep": "Robotics and Mechatronics Center, Institute of Robotics and Mechatronics",
        "aff_unique_url": "https://www.dlr.de",
        "aff_unique_abbr": "DLR",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9341094",
        "title": "Joints-Space Metrics for Automatic Robotic Surgical Gestures Classification",
        "track": "main",
        "status": "Poster",
        "abstract": "Automated surgical gestures classification and recognition are important precursors for achieving the goal of objective evaluation of surgical skills. Many works have been done to discover and validate metrics based on the motion of instruments that can be used as features for automatic classification of surgical gestures. In this work, we present a series of angular metrics that can be used together with Cartesian-based metrics to better describe different surgical gestures. These metrics can be calculated both in Cartesian and joint space, and they are used in this work as features for automatic classification of surgical gestures. To evaluate the proposed metrics, we introduce a novel surgical dataset that contains both Cartesian and joint spaces data acquired with da Vinci Research Kit (dVRK) while a single expert operator is performing 40 subsequent suturing exercises. The obtained results confirm that the application of metrics in the joint space improves the accuracy of automatic gesture classification.",
        "primary_area": "",
        "author": "Marco Bombieri;Diego Dall'Alba;Sanat Ramesh;Giovanni Menegozzo;Caitlin Schneider;Paolo Fiorini;Marco Bombieri;Diego Dall'Alba;Sanat Ramesh;Giovanni Menegozzo;Caitlin Schneider;Paolo Fiorini",
        "authorids": "/37088690192;/38540860700;/37088688190;/37086834254;/38667285200;/37279139000;/37088690192;/38540860700;/37088688190;/37086834254;/38667285200;/37279139000",
        "aff": "Department of Computer Science, University of Verona, Verona, Italy; Department of Computer Science, University of Verona, Verona, Italy; Department of Computer Science, University of Verona, Verona, Italy; Department of Computer Science, University of Verona, Verona, Italy; Electrical and Computer Engineering Department, University of British Columbia, Vancouver, Canada; Department of Computer Science, University of Verona, Verona, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341094/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7451631593612020303&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;0",
        "aff_unique_norm": "University of Verona;University of British Columbia",
        "aff_unique_dep": "Department of Computer Science;Electrical and Computer Engineering Department",
        "aff_unique_url": "https://www.univr.it;https://www.ubc.ca",
        "aff_unique_abbr": ";UBC",
        "aff_campus_unique_index": "0;0;0;0;1;0",
        "aff_campus_unique": "Verona;Vancouver",
        "aff_country_unique_index": "0;0;0;0;1;0",
        "aff_country_unique": "Italy;Canada"
    },
    {
        "id": "9341665",
        "title": "Jumping Motion Generation for Humanoid Robot Using Arm Swing Effectively and Changing in Foot Contact Status",
        "track": "main",
        "status": "Poster",
        "abstract": "Human jumping involves not only lower limbs but also whole-body coordination. During jumping, the effect of sinking the center of mass for recoil and arm swing are significant, and they can cause changes in the jump height. However, upper body movements during jumping movements of humanoid robots have not been studied adequately. When jumping involves only the lower limbs, the burden on the lower limbs increases and it is difficult to jump as high as humans do. Also, if the sole is in contact with the ground during jumping movements, we cannot make good use of the ankle joint. Humans raise their heels during jumping movements, but there are few cases where humanoid robots achieve these movements. Therefore, we thought that jumping with recoil motion by the sinking, arm swing, and changing in foot contact status could result in a higher jump height higher than that possible with only lower limb movements. Hence, in this study, we generated jumping motion using sinking, arm swing and changing foot posture. First, a center of mass trajectory was generated by planning the entire jumping motion, and at the same time, the angular momentum was determined for stability. Next, the joint trajectory was calculated using these two parameters. At that time, arm trajectory and foot posture were specified in the null space. This generated a jumping motion considering arm swing. During simulations, this method provided a jump height almost four times the jump height that obtained without arm swing.",
        "primary_area": "",
        "author": "H. Mineshita;T. Otani;M. Sakaguchi;Y. Kawakami;H.O. Lim;A. Takanishi;H. Mineshita;T. Otani;M. Sakaguchi;Y. Kawakami;H.O. Lim;A. Takanishi",
        "authorids": "/37088341268;/38251798500;/37085372061;/37085384884;/37272490100;/37280756700;/37088341268;/38251798500;/37085372061;/37085384884;/37272490100;/37280756700",
        "aff": "Graduate School of Modern Mechanical Engineering, Waseda University, Shinjuku-ku, Tokyo, Japan; Humanoid Robotics Institute (HRI), Waseda University; Institute of Sport Science, ASICS Corporation; Faculty of Sport Science, Waseda University; Humanoid Robotics Institute (HRI), Waseda University; Humanoid Robotics Institute (HRI), Waseda University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341665/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=945849033225722621&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;0;0;0",
        "aff_unique_norm": "Waseda University;ASICS Corporation",
        "aff_unique_dep": "Graduate School of Modern Mechanical Engineering;Institute of Sport Science",
        "aff_unique_url": "https://www.waseda.jp/top;https://www.asics.com/",
        "aff_unique_abbr": "Waseda;ASICS",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Tokyo;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9341547",
        "title": "KLIEP-based Density Ratio Estimation for Semantically Consistent Synthetic to Real Images Adaptation in Urban Traffic Scenes",
        "track": "main",
        "status": "Poster",
        "abstract": "Synthetic data has been applied in many deep learning based computer vision tasks. Limited performance of algorithms trained solely on synthetic data has been approached with domain adaptation techniques such as the ones based on generative adversarial framework. We demonstrate how adversarial training alone can introduce semantic inconsistencies in translated images. To tackle this issue we propose density prematching strategy using KLIEP-based density ratio estimation procedure. Finally, we show that aforementioned strategy improves quality of translated images of underlying method and their usability for the semantic segmentation task in the context of autonomous driving.",
        "primary_area": "",
        "author": "Artem Savkin;Federico Tombari;Artem Savkin;Federico Tombari",
        "authorids": "/37086960994;/37593332100;/37086960994;/37593332100",
        "aff": "TUM, BMW; TUM, Google",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341547/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10499339818893769000&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Technische Universit\u00e4t M\u00fcnchen",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.tum.de",
        "aff_unique_abbr": "TUM",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9341370",
        "title": "KOVIS: Keypoint-based Visual Servoing with Zero-Shot Sim-to-Real Transfer for Robotics Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "We present KOVIS, a novel learning-based, calibration-free visual servoing method for fine robotic manipulation tasks with eye-in-hand stereo camera system. We train the deep neural network only in the simulated environment; and the trained model could be directly used for real-world visual servoing tasks. KOVIS consists of two networks. The first keypoint network learns the keypoint representation from the image using with an autoencoder. Then the visual servoing network learns the motion based on keypoints extracted from the camera image. The two networks are trained end-to-end in the simulated environment by self-supervised learning without manual data labeling. After training with data augmentation, domain randomization, and adversarial examples, we are able to achieve zero-shot sim-to-real transfer to real-world robotic manipulation tasks. We demonstrate the effectiveness of the proposed method in both simulated environment and real-world experiment with different robotic manipulation tasks, including grasping, peg-in-hole insertion with 4mm clearance, and M13 screw insertion. The demo video is available at: http://youtube/gfBJBR2tDzA.",
        "primary_area": "",
        "author": "En Yen Puang;Keng Peng Tee;Wei Jing;En Yen Puang;Keng Peng Tee;Wei Jing",
        "authorids": "/37086934313;/37088689983;/37085809046;/37086934313;/37088689983;/37085809046",
        "aff": "A*STAR, Institute for High Performance Computing (IHPC), Singapore; A*STAR, Institute for Infocomm Research (I2R), Singapore; A*STAR, Institute for High Performance Computing (IHPC), Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341370/",
        "gs_citation": 48,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12784465167937188317&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "A*STAR",
        "aff_unique_dep": "Institute for High Performance Computing (IHPC)",
        "aff_unique_url": "https://www.a-star.edu.sg",
        "aff_unique_abbr": "A*STAR",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "9341597",
        "title": "KR-Net: A Dependable Visual Kidnap Recovery Network for Indoor Spaces",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a dependable visual kidnap recovery (KR) framework that pinpoints a unique pose in a given 3D map when a device is turned on. For this framework, we first develop indoor-GeM (i-GeM), which is an extension of GeM [1] but considerably more robust than other global descriptors [2]-[4], including GeM itself. Then, we propose a convolutional neural network (CNN)-based system called KR-Net, which is based on a coarse-to-fine paradigm as in [5] and [6]. To our knowledge, KR-Net is the first network that can pinpoint a wake-up pose with a confidence level near 100% within a 1.0 m translational error boundary. This dependable success rate is enabled not only by i-GeM, but also by a combinatorial pooling approach that uses multiple images around the wake-up spot, whereas previous implementations [5], [6] were constrained to a single image. Experiments were conducted in two challenging datasets: a large-scale (12,557 m2) area with frequent featureless or repetitive places and a place with significant view changes due to a one-year gap between prior modeling and query acquisition. Given 59 test query sets (eight images per pose), KR-Net successfully found all wake-up poses, with average and maximum errors of 0.246 m and 0.983 m, respectively.",
        "primary_area": "",
        "author": "Janghun Hyeon;Dongwoo Kim;Bumchul Jang;Hyunga Choi;Dong Hoon Yi;Kyungho Yoo;Jeongae Choi;Nakju Doh;Janghun Hyeon;Dongwoo Kim;Bumchul Jang;Hyunga Choi;Dong Hoon Yi;Kyungho Yoo;Jeongae Choi;Nakju Doh",
        "authorids": "/37086619216;/37088370869;/37087324697;/37085525873;/37088689964;/37088688831;/37088691475;/37424560400;/37086619216;/37088370869;/37087324697;/37085525873;/37088689964;/37088688831;/37088691475;/37424560400",
        "aff": "School of Electrical Engineering, Korea University, Seoul, Republic of Korea; School of Electrical Engineering, Korea University, Seoul, Republic of Korea; TeeLabs, Seoul, Republic of Korea; School of Electrical Engineering, Korea University, Seoul, Republic of Korea; LG Electronics, Seoul, Republic of Korea; LG Electronics, Seoul, Republic of Korea; LG Electronics, Seoul, Republic of Korea; School of Electrical Engineering, Korea University, Seoul, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341597/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10441752849244843751&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;1;0;2;2;2;0",
        "aff_unique_norm": "Korea University;TeeLabs;LG Electronics",
        "aff_unique_dep": "School of Electrical Engineering;;",
        "aff_unique_url": "http://www.korea.ac.kr;;https://www.lg.com",
        "aff_unique_abbr": "KU;;LG",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Seoul;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9340971",
        "title": "Kalman Filter based Range Estimation and Clock Synchronization for Ultra Wide Band Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents the development of a Kalman filter-based range estimation technique to precisely calculate the inter-node ranges of Ultra Wide Band (UWB) modules. Relative clock tracking filters running between every anchor pair tracks relative clock dynamics while estimating the time of flight as a filter state. Both inbound and outbound message timestamps are used to update the filter to make the time of flight observable in the chosen state space design. A faster relative clock filter convergence has been achieved with the inclusion of the clock offset ratio as a measurement additional to the timestamps. Furthermore, a modified gradient clock synchronization algorithm is used to achieve global clock synchronization throughout the network. A correction term is used in the gradient clock synchronization algorithm to enforce the global clock rate to converge at the average of individual clock rates while achieving asymptotic stability in clock rate error state. Experiments are conducted to evaluate synchronization and ranging accuracy of the proposed range estimation approach.",
        "primary_area": "",
        "author": "Nushen M. Senevirathna;Oscar De Silva;George K. I. Mann;Raymond G. Gosine;Nushen M. Senevirathna;Oscar De Silva;George K. I. Mann;Raymond G. Gosine",
        "authorids": "/37088687162;/38542316100;/37295686400;/37293905000;/37088687162;/38542316100;/37295686400;/37293905000",
        "aff": "Faculty of Engineering and Applied Science, Memorial University of Newfoundland, Canada; Faculty of Engineering and Applied Science, Memorial University of Newfoundland, Canada; Faculty of Engineering and Applied Science, Memorial University of Newfoundland, Canada; Faculty of Engineering and Applied Science, Memorial University of Newfoundland, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340971/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10276136907225806931&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Memorial University of Newfoundland",
        "aff_unique_dep": "Faculty of Engineering and Applied Science",
        "aff_unique_url": "https://www.mun.ca",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9340887",
        "title": "Kinematic Multibody Model Generation of Deformable Linear Objects from Point Clouds",
        "track": "main",
        "status": "Poster",
        "abstract": "Control and localization of deformable linear objects (DLOs) require models to handle their deformation. This paper proposes an approach to automatically generate a model from available visual sensor information. Based on point cloud data obtained from a 3D stereo camera, the kinematics of a multibody model formulation are derived. The approach aims to balance the tradeoff between computational complexity and model accuracy. This is achieved with a geometric error criterion that reduces the introduced degrees of freedom (DOF) of the model to a necessary minimum, representing the continuous shape with as few bodies as possible. The approach is evaluated analytically and validated with an experimental scenario of DLO manipulation.",
        "primary_area": "",
        "author": "Markus Wnuk;Christoph Hinze;Armin Lechler;Alexander Verl;Markus Wnuk;Christoph Hinze;Armin Lechler;Alexander Verl",
        "authorids": "/37086333039;/37085826488;/37085362328;/37370221100;/37086333039;/37085826488;/37085362328;/37370221100",
        "aff": "Institute for Control Engineering of Machine Tools and Manufacturing Units, University of Stuttgart, Stuttgart, Germany; Institute for Control Engineering of Machine Tools and Manufacturing Units, University of Stuttgart, Stuttgart, Germany; Institute for Control Engineering of Machine Tools and Manufacturing Units, University of Stuttgart, Stuttgart, Germany; Institute for Control Engineering of Machine Tools and Manufacturing Units, University of Stuttgart, Stuttgart, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340887/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=314922828511249462&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Stuttgart",
        "aff_unique_dep": "Institute for Control Engineering of Machine Tools and Manufacturing Units",
        "aff_unique_url": "https://www.uni-stuttgart.de",
        "aff_unique_abbr": "Uni Stuttgart",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Stuttgart",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9341640",
        "title": "Kinematic Optimization of an Underactuated Anthropomorphic Prosthetic Hand",
        "track": "main",
        "status": "Poster",
        "abstract": "The human hand serves as an inspiration for robotic grippers. However, the dimensions of the human hand evolved under a different set of constraints and requirements than that of robots today. This paper discusses a method of kinematically optimizing the design of an anthropomorphic robotic hand. We focus on maximizing the workspace intersection of the thumb and the other fingers as well as maximizing the size of the largest graspable object. We perform this optimization and use the resulting dimensions to construct a flexible, underactuated 3D printed prototype. We verify the results of the optimization through experimentation, demonstrating that the optimized hand is capable of grasping objects ranging from less than 1 mm to 12.8 cm in diameter with a high degree of reliability. The hand is lightweight and inexpensive, weighing 333 g and costing less than 175 USD, and strong enough to lift over 1.1 lb (500 g). We demonstrate that the optimized hand outperforms an open-source 3D printed anthropomorphic hand on multiple tasks. Finally, we demonstrate the performance of our hand by employing a classification-based user intent decision system which predicts the grasp type using real-time electromyographic (EMG) activity patterns.",
        "primary_area": "",
        "author": "Ann Marie Votta;Sezen Ya\u011fmur G\u00fcnay;Brian Zylich;Erik Skorina;Raagini Rameshwar;Deniz Erdo\u011fmu\u015f;Cagdas D. Onal;Ann Marie Votta;Sezen Ya\u011fmur G\u00fcnay;Brian Zylich;Erik Skorina;Raagini Rameshwar;Deniz Erdo\u011fmu\u015f;Cagdas D. Onal",
        "authorids": "/37087061267;/37085787952;/37086236569;/37085456150;/37087056688;/37285051800;/37303322200;/37087061267;/37085787952;/37086236569;/37085456150;/37087056688;/37285051800;/37303322200",
        "aff": "Mechanical Engineering Department and Robotics Engineering Program, WPI Soft Robotics Laboratory, Worcester Polytechnic Institute, MA, USA; Department of Electrical and Computer Engineering, Cognitive Systems Lab, Northeastern University, MA, USA; College of Information and Computer Sciences, University of Massachusetts, Amherst, MA, USA; Mechanical Engineering Department and Robotics Engineering Program, WPI Soft Robotics Laboratory, Worcester Polytechnic Institute, MA, USA; Mechanical Engineering Department and Robotics Engineering Program, WPI Soft Robotics Laboratory, Worcester Polytechnic Institute, MA, USA; Department of Electrical and Computer Engineering, Cognitive Systems Lab, Northeastern University, MA, USA; Mechanical Engineering Department and Robotics Engineering Program, WPI Soft Robotics Laboratory, Worcester Polytechnic Institute, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341640/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3949303700345464249&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;2;0;0;1;0",
        "aff_unique_norm": "Worcester Polytechnic Institute;Northeastern University;University of Massachusetts Amherst",
        "aff_unique_dep": "Mechanical Engineering Department and Robotics Engineering Program;Department of Electrical and Computer Engineering;College of Information and Computer Sciences",
        "aff_unique_url": "https://www.wpi.edu;https://www.northeastern.edu;https://www.umass.edu",
        "aff_unique_abbr": "WPI;NU;UMass Amherst",
        "aff_campus_unique_index": "0;1;2;0;0;1;0",
        "aff_campus_unique": "Worcester;MA;Amherst",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341572",
        "title": "Kinodynamic Motion Planning for Multi-Legged Robot Jumping via Mixed-Integer Convex Program",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a kinodynamic motion plan-ning framework for multi-legged robot jumping based on the mixed-integer convex program (MICP), which simultaneously reasons about centroidal motion, contact points, wrench, and gait sequences. This method uniquely combines configuration space discretization and the construction of feasible wrench polytope (FWP) to encode kinematic constraints, actuator limit, friction cone constraint, and gait sequencing into a single MICP. The MICP could be efficiently solved to the global optimum by off-the-shelf numerical solvers and provide highly dynamic jumping motions without requiring initial guesses. Simulation and experimental results demonstrate that the proposed method could find novel and dexterous maneuvers that are directly deployable on the two-legged robot platform to traverse through challenging terrains.",
        "primary_area": "",
        "author": "Yanran Ding;Chuanzheng Li;Hae-Won Park;Yanran Ding;Chuanzheng Li;Hae-Won Park",
        "authorids": "/37086268690;/37086575086;/37086265865;/37086268690;/37086575086;/37086265865",
        "aff": "Department of Mechanical Science and Engineering, University of Illinois at Urbana-Champaign, Urbana, IL, USA; Department of Mechanical Science and Engineering, University of Illinois at Urbana-Champaign, Urbana, IL, USA; Department of Mechanical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341572/",
        "gs_citation": 39,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5016748869134221741&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "University of Illinois at Urbana-Champaign;Korea Advanced Institute of Science and Technology",
        "aff_unique_dep": "Department of Mechanical Science and Engineering;Department of Mechanical Engineering",
        "aff_unique_url": "https://illinois.edu;https://www.kaist.ac.kr",
        "aff_unique_abbr": "UIUC;KAIST",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Urbana;Daejeon",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "United States;South Korea"
    },
    {
        "id": "9340959",
        "title": "Knowledge-Based Grasp Planning Using Dynamic Self-Organizing Network",
        "track": "main",
        "status": "Poster",
        "abstract": "Category-based methods for task-specified grasp planning have recently been proposed in the literature. Such methods, however, are normally time consuming in both training and grasp determination process and lack capabilities to improve grasping skills due to the fixed training data set. This paper presents an improved approach for knowledge-based grasp planning by developing a multi-layer network using self-organizing map. A number of grasp candidates are learned in the experiments and the information that is associated with these grasp candidates is clustered based on different criteria on each network layer. A codebook which is composed of a small number of generalized models and the corresponding task-oriented grasps is generated from the network. In addition, the proposed network is capable of automatically adjusting its size so that the codebook can be continuously updated from each interaction with the novel objects. In order to increase the accuracy and convergence rate of the clustering process, a new initialization method is also proposed. Simulation results present the advantages of the proposed initialization method and the auto-growing algorithm in terms of accuracy and efficiency over some conventional methods. Experimental results demonstrate that novel objects can be successfully grasped in accordance with desired tasks using the proposed approach.",
        "primary_area": "",
        "author": "Shiyi Yang;Soo Jeon;Shiyi Yang;Soo Jeon",
        "authorids": "/37086136654;/37538980300;/37086136654;/37538980300",
        "aff": "Department of Mechanical and Mechatronics Engineering, University of Waterloo, Waterloo, ON, Canada; Department of Mechanical and Mechatronics Engineering, University of Waterloo, Waterloo, ON, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340959/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:qzVnC12j30wJ:scholar.google.com/&scioq=Knowledge-Based+Grasp+Planning+Using+Dynamic+Self-Organizing+Network&hl=en&as_sdt=0,5",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Waterloo",
        "aff_unique_dep": "Department of Mechanical and Mechatronics Engineering",
        "aff_unique_url": "https://uwaterloo.ca",
        "aff_unique_abbr": "UW",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Waterloo",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9341618",
        "title": "Knuckles that buckle: compliant underactuated limbs with joint hysteresis enable minimalist terrestrial robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Underactuated designs of robot limbs can enable these systems to passively adapt their joint configuration in response to external forces. Passive adaptation and reconfiguration can be extremely beneficial in situations where manipulation or locomotion with complex substrates is required. A common design for underactuated systems often involves a single tendon that actuates multiple rotational joints, each with a torsional elastic spring resisting bending. However, a challenge of using those joints for legged locomotion is that limbs typically need to follow a cyclical trajectory so that feet can alternately be engaged in stance and swing phases. Such trajectories present challenges for linearly elastic underactuated limbs. In this paper, we present a new method of underactuated limb design which incorporates hysteretic joints that change their torque response during loading and unloading. A double-jointed underactuated limb with both linear and hysteretic joints can thus be tuned to create a variety of looped trajectories. We fabricate these joints inside a flexible legged robot using a modified laminate based 3D printing method, and the result shows that with passive compliance and a mechanically determined joint sequence, a 2-legged minimalist robot can successfully walk through a confined channel over uneven substrates.",
        "primary_area": "",
        "author": "Mingsong Jiang;Rongzichen Song;Nick Gravish;Mingsong Jiang;Rongzichen Song;Nick Gravish",
        "authorids": "/37086581293;/37088687058;/37085401269;/37086581293;/37088687058;/37085401269",
        "aff": "Department of Mechanical and Aerospace Engineering, University of California San Diego, La Jolla, CA, USA; department of Electrical and Computer Engineering, University of California San Diego, La Jolla, CA, USA; Department of Mechanical and Aerospace Engineering, University of California San Diego, La Jolla, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341618/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8253684218754528403&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California San Diego",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.ucsd.edu",
        "aff_unique_abbr": "UCSD",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "La Jolla",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341519",
        "title": "L2B: Learning to Balance the Safety-Efficiency Trade-off in Interactive Crowd-aware Robot Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "This work presents a deep reinforcement learning framework for interactive navigation in a crowded place. Our proposed Learning to Balance (L2B) framework enables mobile robot agents to steer safely towards their destinations by avoiding collisions with a crowd, while actively clearing a path by asking nearby pedestrians to make room, if necessary, to keep their travel efficient. We observe that the safety and efficiency requirements in crowd-aware navigation have a trade-off in the presence of social dilemmas between the agent and the crowd. On the one hand, intervening in pedestrian paths too much to achieve instant efficiency will result in collapsing a natural crowd flow and may eventually put everyone, including the self, at risk of collisions. On the other hand, keeping in silence to avoid every single collision will lead to the agent's inefficient travel. With this observation, our L2B framework augments the reward function used in learning an interactive navigation policy to penalize frequent active path clearing and passive collision avoidance, which substantially improves the balance of the safety-efficiency trade-off. We evaluate our L2B framework in a challenging crowd simulation and demonstrate its superiority, in terms of both navigation success and collision rate, over a state-of-the-art navigation approach.",
        "primary_area": "",
        "author": "Mai Nishimura;Ryo Yonetani;Mai Nishimura;Ryo Yonetani",
        "authorids": "/37088586917;/37085641524;/37088586917;/37085641524",
        "aff": "OMRON SINIC X Corporation, Bunkyo-ku, Tokyo, Japan; OMRON SINIC X Corporation, Bunkyo-ku, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341519/",
        "gs_citation": 42,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2861988955890188445&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "OMRON SINIC X Corporation",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9341615",
        "title": "LAVAPilot: Lightweight UAV Trajectory Planner with Situational Awareness for Embedded Autonomy to Track and Locate Radio-tags",
        "track": "main",
        "status": "Poster",
        "abstract": "Tracking and locating radio-tagged wildlife is a labor-intensive and time-consuming task necessary in wildlife conservation. In this article, we focus on the problem of achieving embedded autonomy for a resource-limited aerial robot for the task capable of avoiding undesirable disturbances to wildlife. We employ a lightweight sensor system capable of simultaneous (noisy) measurements of radio signal strength information from multiple tags for estimating object locations. We formulate a new lightweight task-based trajectory planning method-LAVAPilot-with a greedy evaluation strategy and a void functional formulation to achieve situational awareness to maintain a safe distance from objects of interest. Conceptually, we embed our intuition of moving closer to reduce the uncertainty of measurements into LAVAPilot instead of employing a computationally intensive information gain based planning strategy. We employ LAVAPilot and the sensor to build a lightweight aerial robot platform with fully embedded autonomy for jointly tracking and planning to track and locate multiple VHF radio collar tags used by conservation biologists. Using extensive Monte Carlo simulation-based experiments, implementations on a single board compute module, and field experiments using an aerial robot platform with multiple VHF radio collar tags, we evaluate our joint planning and tracking algorithms. Further, we compare our method with other information-based planning methods with and without situational awareness to demonstrate the effectiveness of our robot executing LAVAPilot. Our experiments demonstrate that LAVAPilot significantly reduces (by 98.5%) the computational cost of planning to enable real-time planning decisions whilst achieving similar localization accuracy of objects compared to information gain based planning methods, albeit taking a slightly longer time to complete a mission. To support research in the field, and conservation biology, we also open source the complete project. I... Show More",
        "primary_area": "",
        "author": "Hoa Van Nguyen;Fei Chen;Joshua Chesser;Hamid Rezatofighi;Damith Ranasinghe;Hoa Van Nguyen;Fei Chen;Joshua Chesser;Hamid Rezatofighi;Damith Ranasinghe",
        "authorids": "/37087011159;/37088686328;/37088689200;/37087010759;/37294392600;/37087011159;/37088686328;/37088689200;/37087010759;/37294392600",
        "aff": "School of Computer Science, The University of Adelaide, SA, Australia; School of Computer Science, The University of Adelaide, SA, Australia; School of Computer Science, The University of Adelaide, SA, Australia; School of Computer Science, The University of Adelaide, SA, Australia; School of Computer Science, The University of Adelaide, SA, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341615/",
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5768108078559463648&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "The University of Adelaide",
        "aff_unique_dep": "School of Computer Science",
        "aff_unique_url": "https://www.adelaide.edu.au",
        "aff_unique_abbr": "Adelaide",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Adelaide",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "9341556",
        "title": "LC-GAN: Image-to-image Translation Based on Generative Adversarial Network for Endoscopic Images",
        "track": "main",
        "status": "Poster",
        "abstract": "Intelligent vision is appealing in computer-assisted and robotic surgeries. Vision-based analysis with deep learning usually requires large labeled datasets, but manual data labeling is expensive and time-consuming in medical problems. We investigate a novel cross-domain strategy to reduce the need for manual data labeling by proposing an image-to-image translation model live-cadaver GAN (LC-GAN) based on generative adversarial networks (GANs). We consider a situation when a labeled cadaveric surgery dataset is available while the task is instrument segmentation on an unlabeled live surgery dataset. We train LC-GAN to learn the mappings between the cadaveric and live images. For live image segmentation, we first translate the live images to fake-cadaveric images with LC-GAN and then perform segmentation on the fake-cadaveric images with models trained on the real cadaveric dataset. The proposed method fully makes use of the labeled cadaveric dataset for live image segmentation without the need to label the live dataset. LC-GAN has two generators with different architectures that leverage the deep feature representation learned from the cadaveric image based segmentation task. Moreover, we propose the structural similarity loss and segmentation consistency loss to improve the semantic consistency during translation. Our model achieves better image-to-image translation and leads to improved segmentation performance in the proposed cross-domain segmentation task.",
        "primary_area": "",
        "author": "Shan Lin;Fangbo Qin;Yangming Li;Randall A. Bly;Kris S. Moe;Blake Hannaford;Shan Lin;Fangbo Qin;Yangming Li;Randall A. Bly;Kris S. Moe;Blake Hannaford",
        "authorids": "/37088473733;/37085793636;/37086145026;/37088474747;/37088193333;/37272234100;/37088473733;/37085793636;/37086145026;/37088474747;/37088193333;/37272234100",
        "aff": "University of Washington, Seattle, WA, USA; Institute of Automation, Chinese Academy of Sciences, Beijing, China; Rochester Institute of Technology, Rochester, NY, USA; University of Washington, Seattle, WA, USA; University of Washington, Seattle, WA, USA; University of Washington, Seattle, WA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341556/",
        "gs_citation": 44,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16247238754246101802&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;0;0;0",
        "aff_unique_norm": "University of Washington;Chinese Academy of Sciences;Rochester Institute of Technology",
        "aff_unique_dep": ";Institute of Automation;",
        "aff_unique_url": "https://www.washington.edu;http://www.ia.cas.cn;https://www.rit.edu",
        "aff_unique_abbr": "UW;CAS;RIT",
        "aff_campus_unique_index": "0;1;2;0;0;0",
        "aff_campus_unique": "Seattle;Beijing;Rochester",
        "aff_country_unique_index": "0;1;0;0;0;0",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "9340704",
        "title": "LIC-Fusion 2.0: LiDAR-Inertial-Camera Odometry with Sliding-Window Plane-Feature Tracking",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-sensor fusion of multi-modal measurements from commodity inertial, visual and LiDAR sensors to provide robust and accurate 6DOF pose estimation holds great potential in robotics and beyond. In this paper, building upon our prior work (i.e., LIC-Fusion), we develop a sliding-window filter based LiDAR-Inertial-Camera odometry with online spatiotemporal calibration (i.e., LIC-Fusion 2.0), which introduces a novel sliding-window plane-feature tracking for efficiently processing 3D LiDAR point clouds. In particular, after motion compensation for LiDAR points by leveraging IMU data, low-curvature planar points are extracted and tracked across the sliding window. A novel outlier rejection criteria is proposed in the plane-feature tracking for high quality data association. Only the tracked planar points belonging to the same plane will be used for plane initialization, which makes the plane extraction efficient and robust. Moreover, we perform the observability analysis for the IMU-LiDAR subsystem under consideration and report the degenerate cases for spatiotemporal calibration using plane features. While the estimation consistency and identified degenerate motions are validated in Monte-Carlo simulations, different real-world experiments are also conducted to show that the proposed LIC-Fusion 2.0 outperforms its predecessor and other state-of-the-art methods.",
        "primary_area": "",
        "author": "Xingxing Zuo;Yulin Yang;Patrick Geneva;Jiajun Lv;Yong Liu;Guoquan Huang;Marc Pollefeys;Xingxing Zuo;Yulin Yang;Patrick Geneva;Jiajun Lv;Yong Liu;Guoquan Huang;Marc Pollefeys",
        "authorids": "/37086314032;/37085990232;/37086125563;/37086604079;/37066946100;/37077670600;/37271138500;/37086314032;/37085990232;/37086125563;/37086604079;/37066946100;/37077670600;/37271138500",
        "aff": "Institute of Cyber-System and Control, Zhejiang University, Hangzhou, China; Robot Perception and Navigation Group, University of Delaware, Newark, DE, USA; Robot Perception and Navigation Group, University of Delaware, Newark, DE, USA; Institute of Cyber-System and Control, Zhejiang University, Hangzhou, China; Institute of Cyber-System and Control, Zhejiang University, Hangzhou, China; Robot Perception and Navigation Group, University of Delaware, Newark, DE, USA; Microsoft Mixed Reality and Artificial Intelligence Lab, Z\u00fcrich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340704/",
        "gs_citation": 150,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16818019236629991724&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 15,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;1;0;0;1;2",
        "aff_unique_norm": "Zhejiang University;University of Delaware;Microsoft Mixed Reality and Artificial Intelligence Lab",
        "aff_unique_dep": "Institute of Cyber-System and Control;Robot Perception and Navigation Group;Mixed Reality and Artificial Intelligence",
        "aff_unique_url": "http://www.zju.edu.cn;https://www.udel.edu;https://www.microsoft.com/en-us/research/group/mixed-reality-ai-lab",
        "aff_unique_abbr": "ZJU;UD;Microsoft MR&AILab",
        "aff_campus_unique_index": "0;1;1;0;0;1;2",
        "aff_campus_unique": "Hangzhou;Newark;Z\u00fcrich",
        "aff_country_unique_index": "0;1;1;0;0;1;2",
        "aff_country_unique": "China;United States;Switzerland"
    },
    {
        "id": "9341176",
        "title": "LIO-SAM: Tightly-coupled Lidar Inertial Odometry via Smoothing and Mapping",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a framework for tightly-coupled lidar inertial odometry via smoothing and mapping, LIO-SAM, that achieves highly accurate, real-time mobile robot trajectory estimation and map-building. LIO-SAM formulates lidar-inertial odometry atop a factor graph, allowing a multitude of relative and absolute measurements, including loop closures, to be incorporated from different sources as factors into the system. The estimated motion from inertial measurement unit (IMU) pre-integration de-skews point clouds and produces an initial guess for lidar odometry optimization. The obtained lidar odometry solution is used to estimate the bias of the IMU. To ensure high performance in real-time, we marginalize old lidar scans for pose optimization, rather than matching lidar scans to a global map. Scan-matching at a local scale instead of a global scale significantly improves the real-time performance of the system, as does the selective introduction of keyframes, and an efficient sliding window approach that registers a new keyframe to a fixed-size set of prior \"sub-keyframes.\" The proposed method is extensively evaluated on datasets gathered from three platforms over various scales and environments.",
        "primary_area": "",
        "author": "Tixiao Shan;Brendan Englot;Drew Meyers;Wei Wang;Carlo Ratti;Daniela Rus;Tixiao Shan;Brendan Englot;Drew Meyers;Wei Wang;Carlo Ratti;Daniela Rus",
        "authorids": "/37085681623;/37601539900;/37087090649;/37073346500;/37590016800;/37279652300;/37085681623;/37601539900;/37087090649;/37073346500;/37590016800;/37279652300",
        "aff": "Computer Science & Artificial Intelligence Laboratory, Massachusetts Institute of Technology, USA; Department of Mechanical Engineering, Stevens Institute of Technology, USA; Department of Urban Studies and Planning, Massachusetts Institute of Technology, USA; Computer Science & Artificial Intelligence Laboratory, Massachusetts Institute of Technology, USA; Department of Urban Studies and Planning, Massachusetts Institute of Technology, USA; Computer Science & Artificial Intelligence Laboratory, Massachusetts Institute of Technology, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341176/",
        "gs_citation": 1964,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5601890500022500578&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 15,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;Stevens Institute of Technology",
        "aff_unique_dep": "Computer Science & Artificial Intelligence Laboratory;Department of Mechanical Engineering",
        "aff_unique_url": "https://web.mit.edu;https://www.stevens.edu",
        "aff_unique_abbr": "MIT;SIT",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Cambridge;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341492",
        "title": "LLAMA: Design and Control of an Omnidirectional Human Mission Scale Quadrupedal Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper describes the design, control and initial experimental results of the quadruped robot LLAMA. Designed to operate in a human-scale world, this 67kg-class, all-electric robot is capable of rapid motion over a variety of terrains. Thanks to a unique leg configuration and custom high-torque, low gear-ratio motors, it can move omnidirectionally at speeds over 1 m/s. A hierarchical reactive control scheme allows for robust and efficient motion even under variable payloads. This paper describes the structure of the controller and outlines simulation results that probe the performance envelope of the robot suggesting payload capacities up to one third of its body weight. Initial testing shows robust motion over loose debris and a variety of ground slopes. Videos of the robot may be seen at https://tinyurl.com/llama-robot.",
        "primary_area": "",
        "author": "John Nicholson;Jay Jasper;Ara Kourchians;Greg McCutcheon;Max Austin;Mark Gonzalez;Jason Pusey;Sisir Karumanchi;Christian Hubicki;Jonathan Clark;John Nicholson;Jay Jasper;Ara Kourchians;Greg McCutcheon;Max Austin;Mark Gonzalez;Jason Pusey;Sisir Karumanchi;Christian Hubicki;Jonathan Clark",
        "authorids": "/37086353968;/37088686512;/37088688668;/37088686530;/37086355499;/37088689804;/37085864714;/38251608900;/37085380316;/37533408500;/37086353968;/37088686512;/37088688668;/37088686530;/37086355499;/37088689804;/37085864714;/38251608900;/37085380316;/37533408500",
        "aff": "FSU; JPL; JPL; FSU; FSU; GD; ARL; JPL; FSU; FSU",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341492/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17658023965738647993&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 20,
        "aff_unique_index": "0;1;1;0;0;2;3;1;0;0",
        "aff_unique_norm": "Florida State University;Jet Propulsion Laboratory;GD;Army Research Laboratory",
        "aff_unique_dep": ";;;",
        "aff_unique_url": "https://www.fsu.edu;https://www.jpl.nasa.gov;;https://www.arl.army.mil",
        "aff_unique_abbr": "FSU;JPL;;ARL",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States;"
    },
    {
        "id": "9341178",
        "title": "LaNoising: A Data-driven Approach for 903nm ToF LiDAR Performance Modeling under Fog",
        "track": "main",
        "status": "Poster",
        "abstract": "As a critical sensor for high-level autonomous vehicles, LiDAR's limitations in adverse weather (e.g. rain, fog, snow, etc.) impede the deployment of self-driving cars in all weather conditions. In this paper, we model the performance of a popular 903nm ToF LiDAR under various fog conditions based on a LiDAR dataset collected in a well-controlled artificial fog chamber. Specifically, a two-stage data-driven method, called LaNoising (la for laser), is proposed for generating LiDAR measurements under fog conditions. In the first stage, the Gaussian Process Regression (GPR) model is established to predict whether a laser can successfully output a true detection range or not, given certain fog visibility values. If not, then in the second stage, the Mixture Density Network (MDN) is used to provide a probability prediction of the noisy measurement range. The performance of the proposed method has been quantitatively and qualitatively evaluated. Experimental results show that our approach can provide a promising description of 903nm ToF LiDAR performance under fog.",
        "primary_area": "",
        "author": "Tao Yang;You Li;Yassine Ruichek;Zhi Yan;Tao Yang;You Li;Yassine Ruichek;Zhi Yan",
        "authorids": "/37278086100;/37086068403;/37284281500;/37086432956;/37278086100;/37086068403;/37284281500;/37086432956",
        "aff": "CIAD UMR7533, Univ. Bourgogne Franche-Comt\u00e9, UTBM, Belfort, France; Groupe Renault, France; CIAD UMR7533, Univ. Bourgogne Franche-Comt\u00e9, UTBM, Belfort, France; CIAD UMR7533, Univ. Bourgogne Franche-Comt\u00e9, UTBM, Belfort, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341178/",
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7300055003968910545&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "University Bourgogne Franche-Comt\u00e9;Groupe Renault",
        "aff_unique_dep": "CIAD UMR7533;",
        "aff_unique_url": "https://www.ubfc.fr;https://www.groupe-renault.com",
        "aff_unique_abbr": "UBFC;Renault",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Belfort;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9340641",
        "title": "Label Efficient Visual Abstractions for Autonomous Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "It is well known that semantic segmentation can be used as an effective intermediate representation for learning driving policies. However, the task of street scene semantic segmentation requires expensive annotations. Furthermore, segmentation algorithms are often trained irrespective of the actual driving task, using auxiliary image-space loss functions which are not guaranteed to maximize driving metrics such as safety or distance traveled per intervention. In this work, we seek to quantify the impact of reducing segmentation annotation costs on learned behavior cloning agents. We analyze several segmentation-based intermediate representations. We use these visual abstractions to systematically study the trade-off between annotation efficiency and driving performance, i.e., the types of classes labeled, the number of image samples used to learn the visual abstraction model, and their granularity (e.g., object masks vs. 2D bounding boxes). Our analysis uncovers several practical insights into how segmentation-based visual abstractions can be exploited in a more label efficient manner. Surprisingly, we find that state-of-the-art driving performance can be achieved with orders of magnitude reduction in annotation cost. Beyond label efficiency, we find several additional training benefits when leveraging visual abstractions, such as a significant reduction in the variance of the learned policy when compared to state-of-the-art end-to-end driving models.",
        "primary_area": "",
        "author": "Aseem Behl;Kashyap Chitta;Aditya Prakash;Eshed Ohn-Bar;Andreas Geiger;Aseem Behl;Kashyap Chitta;Aditya Prakash;Eshed Ohn-Bar;Andreas Geiger",
        "authorids": "/37085341172;/37086012065;/37088457323;/37073869900;/37393671000;/37085341172;/37086012065;/37088457323;/37073869900;/37393671000",
        "aff": "University of T\u00fcbingen; University of T\u00fcbingen; Max Planck Institute for Intelligent Systems, T\u00fcbingen; Boston University; University of T\u00fcbingen",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340641/",
        "gs_citation": 50,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6375625724446527590&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;2;0",
        "aff_unique_norm": "University of T\u00fcbingen;Max Planck Institute for Intelligent Systems;Boston University",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.uni-tuebingen.de/;https://www.mpi-is.mpg.de;https://www.bu.edu",
        "aff_unique_abbr": "Uni T\u00fcbingen;MPI-IS;BU",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";T\u00fcbingen",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "Germany;United States"
    },
    {
        "id": "9340752",
        "title": "Laminar Jamming Flexure Joints for the Development of Variable Stiffness Robot Grippers and Hands",
        "track": "main",
        "status": "Poster",
        "abstract": "Although soft robots are a good alternative to rigid, traditional robots due to their intrinsic compliance and environmental adaptability, there are several drawbacks that limit their impact, such as low force exertion capability and low resistance to deformation. For this reason, soft structures of variable stiffness have become a popular solution in the field to combine the benefits of both soft and rigid designs. In this paper, we develop laminar jamming flexure joints that facilitate the development of adaptive robot grippers with variable stiffness. Initially, we propose a mathematical model of the laminar jamming structures. Then, the model is experimentally validated through bending tests using different materials, pressures, and number of layers. Finally, the soft, laminar jamming structured are employed to develop variable stiffness flexure joints for two different adaptive robot grippers. Bending profile analysis and grasping tests have demonstrated the benefits of the proposed jamming structures and the capabilities of the designed grippers.",
        "primary_area": "",
        "author": "Lucas Gerez;Geng Gao;Minas Liarokapis;Lucas Gerez;Geng Gao;Minas Liarokapis",
        "authorids": "/37086448935;/37087027460;/38558084100;/37086448935;/37087027460;/38558084100",
        "aff": "Department of Mechanical Engineering, New Dexterity research group, The University of Auckland, New Zealand; Department of Mechanical Engineering, New Dexterity research group, The University of Auckland, New Zealand; Department of Mechanical Engineering, New Dexterity research group, The University of Auckland, New Zealand",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340752/",
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2053328752336630649&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "The University of Auckland",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.auckland.ac.nz",
        "aff_unique_abbr": "UoA",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "New Zealand"
    },
    {
        "id": "9340923",
        "title": "Lane Marking Verification for High Definition Map Maintenance Using Crowdsourced Images",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous vehicles often rely on high-definition (HD) maps to navigate around. However, lane markings (LMs) are not necessarily static objects due to wear & tear from usage and road reconstruction & maintenance. Therefore, the wrong matching between LMs in the HD map and sensor readings may lead to erroneous localization or even cause traffic accidents. It is imperative to keep LMs up-to-date. However, frequently recollecting data with dedicated hardware and specialists to update HD maps is not only cost-prohibitive but also unviable. Here we propose to utilize crowdsourced images from multiple vehicles at different times to help verify LMs for HD map maintenance. We obtain the LM distribution in the image space by considering the camera pose uncertainty in perspective projection. Both LMs in HD map and LMs in the image are treated as observations of LM distributions which allow us to construct posterior conditional distribution (a.k.a Bayesian belief functions) of LMs from either sources. An LM is consistent if belief functions from the map and the image satisfy statistical hypothesis testing. We further extend the Bayesian belief model into a sequential belief update using crowdsourced images. LMs with a higher probability of existence are kept in the HD map whereas those with a lower probability of existence are removed from the HD map. We verify our approach using real data. Experimental results show that our method is capable of verifying and updating LMs in the HD map.",
        "primary_area": "",
        "author": "Binbin Li;Dezhen Song;Aaron Kingery;Dongfang Zheng;Yiliang Xu;Huiwen Guo;Binbin Li;Dezhen Song;Aaron Kingery;Dongfang Zheng;Yiliang Xu;Huiwen Guo",
        "authorids": "/37086575452;/37275586600;/37086455937;/37088689295;/37075975900;/37085339015;/37086575452;/37275586600;/37086455937;/37088689295;/37075975900;/37085339015",
        "aff": "CSE Department, Texas A&M University, College Station, TX, US; CSE Department, Texas A&M University, College Station, TX, US; CSE Department, Texas A&M University, College Station, TX, US; Tencent America, Palo Alto, CA, US; Tencent America, Palo Alto, CA, US; Tencent America, Palo Alto, CA, US",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340923/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7438990786413383875&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;1;1",
        "aff_unique_norm": "Texas A&M University;Tencent America",
        "aff_unique_dep": "CSE Department;",
        "aff_unique_url": "https://www.tamu.edu;https://www.tencent.com/en-us",
        "aff_unique_abbr": "TAMU;Tencent America",
        "aff_campus_unique_index": "0;0;0;1;1;1",
        "aff_campus_unique": "College Station;Palo Alto",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341233",
        "title": "Lane-Attention: Predicting Vehicles\u2019 Moving Trajectories by Learning Their Attention Over Lanes",
        "track": "main",
        "status": "Poster",
        "abstract": "Accurately forecasting the future movements of surrounding vehicles is essential for safe and efficient operations of autonomous driving cars. This task is difficult because a vehicle's moving trajectory is greatly determined by its driver's intention, which is often hard to estimate. By leveraging attention mechanisms along with long short-term memory (LSTM) networks, this work learns the relation between a driver's intention and the vehicle's changing positions relative to road infrastructures, and uses it to guide the prediction. Different from other state-of-the-art solutions, our work treats the on-road lanes as non-Euclidean structures, unfolds the vehicle's moving history to form a spatio-temporal graph, and uses methods from Graph Neural Networks to solve the problem. Not only is our approach a pioneering attempt in using non-Euclidean methods to process static environmental features around a predicted object, our model also outperforms other state-of-the-art models in several metrics. The practicability and interpretability analysis of the model shows great potential for large-scale deployment in various autonomous driving systems in addition to our own.",
        "primary_area": "",
        "author": "Jiacheng Pan;Hongyi Sun;Kecheng Xu;Yifei Jiang;Xiangquan Xiao;Jiangtao Hu;Jinghao Miao;Jiacheng Pan;Hongyi Sun;Kecheng Xu;Yifei Jiang;Xiangquan Xiao;Jiangtao Hu;Jinghao Miao",
        "authorids": "/37088646976;/37087104755;/37087323360;/37088689375;/37087325091;/37087107420;/37088643032;/37088646976;/37087104755;/37087323360;/37088689375;/37087325091;/37087107420;/37088643032",
        "aff": "Google Research; Baidu USA LLC, Sunnyvale, CA, USA; Baidu USA LLC, Sunnyvale, CA, USA; Baidu USA LLC, Sunnyvale, CA, USA; Baidu USA LLC, Sunnyvale, CA, USA; Baidu USA LLC, Sunnyvale, CA, USA; Baidu USA LLC, Sunnyvale, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341233/",
        "gs_citation": 50,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1177865783321986056&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;1;1;1;1;1",
        "aff_unique_norm": "Google;Baidu USA LLC",
        "aff_unique_dep": "Google Research;",
        "aff_unique_url": "https://research.google;https://www.baidu.com",
        "aff_unique_abbr": "Google Research;Baidu USA",
        "aff_campus_unique_index": "0;1;1;1;1;1;1",
        "aff_campus_unique": "Mountain View;Sunnyvale",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340815",
        "title": "Laser2Vec: Similarity-based Retrieval for Robotic Perception Data",
        "track": "main",
        "status": "Poster",
        "abstract": "As mobile robot capabilities improve and deployment times increase, tools to analyze the growing volume of data are becoming necessary. Current state-of-the-art logging, playback, and exploration systems are insufficient for practitioners seeking to discover systemic points of failure in robotic systems. This paper presents a suite of algorithms for similarity-based queries of robotic perception data and implements a system for storing 2D LiDAR data from many deployments cheaply and evaluating top-k queries for complete or partial scans efficiently. We generate compressed representations of laser scans via a convolutional variational autoencoder and store them in a database, where a light-weight dense network for distance function approximation is run at query time. Our query evaluator leverages the local continuity of the embedding space to generate evaluation orders that, in expectation, dominate full linear scans of the database. The accuracy, robustness, scalability, and efficiency of our system is tested on real-world data gathered from dozens of deployments and synthetic data generated by corrupting real data. We find our system accurately and efficiently identifies similar scans across a number of episodes where the robot encountered the same location, or similar indoor structures or objects.",
        "primary_area": "",
        "author": "Samer B. Nashed;Samer B. Nashed",
        "authorids": "/37086198158;/37086198158",
        "aff": "College of Information and Computer Sciences, University of Massachusetts, Amherst, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340815/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5118220948330600351&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 2,
        "aff_unique_index": "0",
        "aff_unique_norm": "University of Massachusetts Amherst",
        "aff_unique_dep": "College of Information and Computer Sciences",
        "aff_unique_url": "https://www.umass.edu",
        "aff_unique_abbr": "UMass Amherst",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Amherst",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341460",
        "title": "Latent Replay for Real-Time Continual Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Training deep neural networks at the edge on light computational devices, embedded systems and robotic platforms is nowadays very challenging. Continual learning techniques, where complex models are incrementally trained on small batches of new data, can make the learning problem tractable even for CPU-only embedded devices enabling remarkable levels of adaptiveness and autonomy. However, a number of practical problems need to be solved: catastrophic forgetting before anything else. In this paper we introduce an original technique named \"Latent Replay\" where, instead of storing a portion of past data in the input space, we store activations volumes at some intermediate layer. This can significantly reduce the computation and storage required by native rehearsal. To keep the representation stable and the stored activations valid we propose to slow-down learning at all the layers below the latent replay one, leaving the layers above free to learn at full pace. In our experiments we show that Latent Replay, combined with existing continual learning techniques, achieves state-of-the-art performance on complex video benchmarks such as CORe50 NICv2 (with nearly 400 small and highly non-i.i.d. batches) and OpenLORIS. Finally, we demonstrate the feasibility of nearly real-time continual learning on the edge through the deployment of the proposed technique on a smartphone device.",
        "primary_area": "",
        "author": "Lorenzo Pellegrini;Gabriele Graffieti;Vincenzo Lomonaco;Davide Maltoni;Lorenzo Pellegrini;Gabriele Graffieti;Vincenzo Lomonaco;Davide Maltoni",
        "authorids": "/37088418314;/37088417727;/37086022478;/37267343500;/37088418314;/37088417727;/37086022478;/37267343500",
        "aff": "Department of Computer Science and Engineering (DISI), University of Bologna, Cesena FC, Italy; Department of Computer Science and Engineering (DISI), University of Bologna, Cesena FC, Italy; Department of Computer Science and Engineering (DISI), University of Bologna, Cesena FC, Italy; Department of Computer Science and Engineering (DISI), University of Bologna, Cesena FC, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341460/",
        "gs_citation": 201,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5927280660132339349&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Bologna",
        "aff_unique_dep": "Department of Computer Science and Engineering (DISI)",
        "aff_unique_url": "https://www.unibo.it",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Cesena",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9340764",
        "title": "Latent Space Roadmap for Visual Action Planning of Deformable and Rigid Object Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a framework for visual action planning of complex manipulation tasks with high-dimensional state spaces such as manipulation of deformable objects. Planning is performed in a low-dimensional latent state space that embeds images. We define and implement a Latent Space Roadmap (LSR) which is a graph-based structure that globally captures the latent system dynamics. Our framework consists of two main components: a Visual Foresight Module (VFM) that generates a visual plan as a sequence of images, and an Action Proposal Network (APN) that predicts the actions between them. We show the effectiveness of the method on a simulated box stacking task as well as a T-shirt folding task performed with a real robot.",
        "primary_area": "",
        "author": "Martina Lippi;Petra Poklukar;Michael C. Welle;Anastasiia Varava;Hang Yin;Alessandro Marino;Danica Kragic;Martina Lippi;Petra Poklukar;Michael C. Welle;Anastasiia Varava;Hang Yin;Alessandro Marino;Danica Kragic",
        "authorids": "/37086443839;/37088686149;/38202265300;/37086619259;/37088353838;/37390952800;/37281296000;/37086443839;/37088686149;/38202265300;/37086619259;/37088353838;/37390952800;/37281296000",
        "aff": "University of Salerno, Salerno, Italy; KTH Royal Institute of Technology, Stockholm, Sweden; KTH Royal Institute of Technology, Stockholm, Sweden; KTH Royal Institute of Technology, Stockholm, Sweden; KTH Royal Institute of Technology, Stockholm, Sweden; University of Cassino and Southern Lazio, Cassino, Italy; KTH Royal Institute of Technology, Stockholm, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340764/",
        "gs_citation": 70,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14590135833859348961&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;1;1;1;2;1",
        "aff_unique_norm": "University of Salerno;KTH Royal Institute of Technology;University of Cassino and Southern Lazio",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.unisalento.it;https://www.kth.se;https://www.unicas.it",
        "aff_unique_abbr": ";KTH;",
        "aff_campus_unique_index": "0;1;1;1;1;2;1",
        "aff_campus_unique": "Salerno;Stockholm;Cassino",
        "aff_country_unique_index": "0;1;1;1;1;0;1",
        "aff_country_unique": "Italy;Sweden"
    },
    {
        "id": "9340691",
        "title": "Learn by Observation: Imitation Learning for Drone Patrolling from Videos of A Human Navigator",
        "track": "main",
        "status": "Poster",
        "abstract": "We present an imitation learning method for autonomous drone patrolling based only on raw videos. Different from previous methods, we propose to let the drone learn patrolling in the air by observing and imitating how a human navigator does it on the ground. The observation process enables the automatic collection and annotation of data using inter-frame geometric consistency, resulting in less manual effort and high accuracy. Then a newly designed neural network is trained based on the annotated data to predict appropriate directions and translations for the drone to patrol in a lane-keeping manner as humans. Our method allows the drone to fly at a high altitude with a broad view and low risk. It can also detect all accessible directions at crossroads and further carry out the integration of available user instructions and autonomous patrolling control commands. Extensive experiments are conducted to demonstrate the accuracy of the proposed imitating learning process as well as the reliability of the holistic system for autonomous drone navigation. The codes, datasets as well as video demonstrations are available at https://vsislab.github.io/uavpatrol.",
        "primary_area": "",
        "author": "Yue Fan;Shilei Chu;Wei Zhang;Ran Song;Yibin Li;Yue Fan;Shilei Chu;Wei Zhang;Ran Song;Yibin Li",
        "authorids": "/37088690000;/37088687206;/37085379581;/37546859100;/37279897500;/37088690000;/37088687206;/37085379581;/37546859100;/37279897500",
        "aff": "Laboratory for Computational Sensing and Robotics, Johns Hopkins University, Baltimore, Maryland, USA; School of Control Science and Engineering, Shandong University, Jinan, China; School of Control Science and Engineering, Shandong University, Jinan, China; School of Control Science and Engineering, Shandong University, Jinan, China; School of Control Science and Engineering, Shandong University, Jinan, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340691/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3937392085366149867&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;1",
        "aff_unique_norm": "Johns Hopkins University;Shandong University",
        "aff_unique_dep": "Laboratory for Computational Sensing and Robotics;School of Control Science and Engineering",
        "aff_unique_url": "https://www.jhu.edu;http://www.sdu.edu.cn",
        "aff_unique_abbr": "JHU;SDU",
        "aff_campus_unique_index": "0;1;1;1;1",
        "aff_campus_unique": "Baltimore;Jinan",
        "aff_country_unique_index": "0;1;1;1;1",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "9341157",
        "title": "Learning Accurate and Human-Like Driving using Semantic Maps and Attention",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper investigates how end-to-end driving models can be improved to drive more accurately and human-like. To tackle the first issue we exploit semantic and visual maps from HERE Technologies and augment the existing Drive360 dataset with such. The maps are used in an attention mechanism that promotes segmentation confidence masks, thus focusing the network on semantic classes in the image that are important for the current driving situation. Human-like driving is achieved using adversarial learning, by not only minimizing the imitation loss with respect to the human driver but by further defining a discriminator, that forces the driving model to produce action sequences that are human-like. Our models are trained and evaluated on the Drive360 + HERE dataset, which features 60 hours and 3000 km of real-world driving data. Extensive experiments show that our driving models are more accurate and behave more human-like than previous methods.",
        "primary_area": "",
        "author": "Simon Hecker;Dengxin Dai;Alexander Liniger;Martin Hahner;Luc Van Gool;Simon Hecker;Dengxin Dai;Alexander Liniger;Martin Hahner;Luc Van Gool",
        "authorids": "/37089142976;/37531409100;/37085702116;/37087104734;/37277167600;/37089142976;/37531409100;/37085702116;/37087104734;/37277167600",
        "aff": "CVL, ETH Zurich; CVL, ETH Zurich; CVL, ETH Zurich; CVL, ETH Zurich; ESAT-PSI, KU Leuven",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341157/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18065169416307660292&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "ETH Zurich;KU Leuven",
        "aff_unique_dep": "Computer Vision Laboratory;ESAT-PSI",
        "aff_unique_url": "https://www.ethz.ch;https://www.kuleuven.be",
        "aff_unique_abbr": "ETHZ;KU Leuven",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;1",
        "aff_country_unique": "Switzerland;Belgium"
    },
    {
        "id": "9341777",
        "title": "Learning Agile Locomotion via Adversarial Training",
        "track": "main",
        "status": "Poster",
        "abstract": "Developing controllers for agile locomotion is a long-standing challenge for legged robots. Reinforcement learning (RL) and Evolution Strategy (ES) hold the promise of automating the design process of such controllers. However, dedicated and careful human effort is required to design training environments to promote agility. In this paper, we present a multi-agent learning system, in which a quadruped robot (protagonist) learns to chase another robot (adversary) while the latter learns to escape. We find that this adversarial training process not only encourages agile behaviors but also effectively alleviates the laborious environment design effort. In contrast to prior works that used only one adversary, we find that training an ensemble of adversaries, each of which specializes in a different escaping strategy, is essential for the protagonist to master agility. Through extensive experiments, we show that the locomotion controller learned with adversarial training significantly outperforms carefully designed baselines.",
        "primary_area": "",
        "author": "Yujin Tang;Jie Tan;Tatsuya Harada;Yujin Tang;Jie Tan;Tatsuya Harada",
        "authorids": "/37088691066;/37086455820;/37274148900;/37088691066;/37086455820;/37274148900",
        "aff": "Google Brain, Tokyo, Japan; Google Brain, Mountain View, United States; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341777/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18118166095775038353&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Google Brain;Google;The University of Tokyo",
        "aff_unique_dep": "Google Brain;Google Brain;Department of Mechano-Informatics, Graduate School of Information Science and Technology",
        "aff_unique_url": "https://brain.google.com;https://brain.google.com;https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "Google Brain;Google Brain;UTokyo",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Tokyo;Mountain View",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Japan;United States"
    },
    {
        "id": "9341420",
        "title": "Learning Bayes Filter Models for Tactile Localization",
        "track": "main",
        "status": "Poster",
        "abstract": "Localizing and tracking the pose of robotic grippers are necessary skills for manipulation tasks. However, the manipulators with imprecise kinematic models (e.g. low-cost arms) or manipulators with unknown world coordinates (e.g. poor camera-arm calibration) cannot locate the gripper with respect to the world. In these circumstances, we can leverage tactile feedback between the gripper and the environment. In this paper, we present learnable Bayes filter models that can localize robotic grippers using tactile feedback. We propose a novel observation model that conditions the tactile feedback on visual maps of the environment along with a motion model to recursively estimate the gripper's location. Our models are trained in simulation with self-supervision and transferred to the real world. Our method is evaluated on a tabletop localization task in which the gripper interacts with objects. We report results in simulation and on a real robot, generalizing over different sizes, shapes, and configurations of the objects.",
        "primary_area": "",
        "author": "Tar\u0131k Kele\u015ftemur;Colin Keil;John P. Whitney;Robert Platt;Ta\u015fk\u0131n Pad\u0131r;Tar\u0131k Kele\u015ftemur;Colin Keil;John P. Whitney;Robert Platt;Ta\u015fk\u0131n Pad\u0131r",
        "authorids": "/37086935384;/37088688648;/37409281700;/37273991200;/38496444600;/37086935384;/37088688648;/37409281700;/37273991200;/38496444600",
        "aff": "College of Engineering, Northeastern University, Boston, Massauchusetts, USA; Khoury College of Computer Sciences, Northeastern University, Boston, Massauchusetts, USA; College of Engineering, Northeastern University, Boston, Massauchusetts, USA; Khoury College of Computer Sciences, Northeastern University, Boston, Massauchusetts, USA; College of Engineering, Northeastern University, Boston, Massauchusetts, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341420/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6139598937744456799&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Northeastern University",
        "aff_unique_dep": "College of Engineering",
        "aff_unique_url": "https://www.northeastern.edu",
        "aff_unique_abbr": "NEU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Boston",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340954",
        "title": "Learning Consistency Pursued Correlation Filters for Real-Time UAV Tracking",
        "track": "main",
        "status": "Poster",
        "abstract": "Correlation filter (CF)-based methods have demonstrated exceptional performance in visual object tracking for unmanned aerial vehicle (UAV) applications, but suffer from the undesirable boundary effect. To solve this issue, spatially regularized correlation filters (SRDCF) proposes the spatial regularization to penalize filter coefficients, thereby significantly improving the tracking performance. However, the temporal information hidden in the response maps is not considered in SRDCF, which limits the discriminative power and the robustness for accurate tracking. This work proposes a novel approach with dynamic consistency pursued correlation filters, i.e., the CPCF tracker. Specifically, through a correlation operation between adjacent response maps, a practical consistency map is generated to represent the consistency level across frames. By minimizing the difference between the practical and the scheduled ideal consistency map, the consistency level is constrained to maintain temporal smoothness, and rich temporal information contained in response maps is introduced. Besides, a dynamic constraint strategy is proposed to further improve the adaptability of the proposed tracker in complex situations. Comprehensive experiments are conducted on three challenging UAV benchmarks, i.e., UAV123@10FPS, UAVDT, and DTB70. Based on the experimental results, the proposed tracker favorably surpasses the other 25 state-of-the-art trackers with real-time running speed (~43FPS) on a single CPU.",
        "primary_area": "",
        "author": "Changhong Fu;Xiaoxiao Yang;Fan Li;Juntao Xu;Changjing Liu;Peng Lu;Changhong Fu;Xiaoxiao Yang;Fan Li;Juntao Xu;Changjing Liu;Peng Lu",
        "authorids": "/37086797986;/37088687438;/37088505558;/37088563954;/37088688440;/37087243038;/37086797986;/37088687438;/37088505558;/37088563954;/37088688440;/37087243038",
        "aff": "School of Mechanical Engineering, Tongji University, Shanghai, China; School of Electronics and Information Engineering, Tongji University, Shanghai, China; School of Mechanical Engineering, Tongji University, Shanghai, China; School of Mechanical Engineering, Tongji University, Shanghai, China; School of Mechanical Engineering, Tongji University, Shanghai, China; Adaptive Robotic Controls Lab (ArcLab), Hong Kong Polytechnic University (PolyU), Hong Kong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340954/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17928988808227106100&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;1",
        "aff_unique_norm": "Tongji University;Hong Kong Polytechnic University",
        "aff_unique_dep": "School of Mechanical Engineering;Adaptive Robotic Controls Lab (ArcLab)",
        "aff_unique_url": "https://www.tongji.edu.cn;https://www.polyu.edu.hk",
        "aff_unique_abbr": "Tongji;PolyU",
        "aff_campus_unique_index": "0;0;0;0;0;1",
        "aff_campus_unique": "Shanghai;Hong Kong",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9341765",
        "title": "Learning Continuous Object Representations from Point Cloud Data",
        "track": "main",
        "status": "Poster",
        "abstract": "Continuous representations of objects have always been used in robotics in the form of geometric primitives and surface models. Recently, learning techniques have emerged which allow more complex continuous representations to be learned from data, but these learning techniques require training data in the form of watertight meshes which restricts their application as meshes of this form are difficult to obtain from real data. This paper proposes a modification to existing methods that allows real world point cloud data to be used for training these surface representations allowing the techniques to be used in broader applications. The modification is evaluated on ModelNet10 to quantify the difference between the existing and the proposed methods as well as on a novel precision agriculture dataset that has been released publicly to show the modification's applicability to new areas. The proposed method enables obtaining training data from real world sensors that produce point clouds rather than requiring an expensive meshing step which may not be possible for some applications. This opens the possibility of using techniques like this for complex shapes in areas like grasping and agricultural data collection.",
        "primary_area": "",
        "author": "Henry J. Nelson;Nikolaos Papanikolopoulos;Henry J. Nelson;Nikolaos Papanikolopoulos",
        "authorids": "/37089779778;/37278578300;/37089779778;/37278578300",
        "aff": "Department of Computer Science and Engineering, University of Minnesota; Department of Computer Science and Engineering, University of Minnesota",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341765/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6031869932313204846&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Minnesota",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.umn.edu",
        "aff_unique_abbr": "UMN",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341019",
        "title": "Learning Domain Randomization Distributions for Training Robust Locomotion Policies",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper considers the problem of learning behaviors in simulation without knowledge of the precise dynamical properties of the target robot platform(s). In this context, our learning goal is to mutually maximize task efficacy on each environment considered and generalization across the widest possible range of environmental conditions. The physical parameters of the simulator are modified by a component of our technique that learns the Domain Randomization (DR) that is appropriate at each learning epoch to maximally challenge the current behavior policy, without being overly challenging, which can hinder learning progress. This so-called sweet spot distribution is a selection of simulated domains with the following properties: 1) The trained policy should be successful in environments sampled from the domain randomization distribution; and 2) The DR distribution made as wide as possible, to increase variability in the environments. These properties aim to ensure the trajectories encountered in the target system are close to those observed during training, as existing methods in machine learning are better suited for interpolation than extrapolation. We show how adapting the DR distribution while training context-conditioned policies results in improvements on jump-start and asymptotic performance when transferring a learned policy to the target environment1.",
        "primary_area": "",
        "author": "Melissa Mozian;Juan Camilo Gamboa Higuera;David Meger;Gregory Dudek;Melissa Mozian;Juan Camilo Gamboa Higuera;David Meger;Gregory Dudek",
        "authorids": "/37088690067;/37088691230;/37542891800;/37274057100;/37088690067;/37088691230;/37542891800;/37274057100",
        "aff": "Montreal Institute of Learning Algorithms (MILA), and the Mobile Robotics Lab (MRL) at the School of Computer Science, McGill University, Montreal, Canada; Montreal Institute of Learning Algorithms (MILA), and the Mobile Robotics Lab (MRL) at the School of Computer Science, McGill University, Montreal, Canada; Montreal Institute of Learning Algorithms (MILA), and the Mobile Robotics Lab (MRL) at the School of Computer Science, McGill University, Montreal, Canada; Montreal Institute of Learning Algorithms (MILA), and the Mobile Robotics Lab (MRL) at the School of Computer Science, McGill University, Montreal, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341019/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8034798371673406954&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "McGill University",
        "aff_unique_dep": "School of Computer Science",
        "aff_unique_url": "https://www.mcgill.ca",
        "aff_unique_abbr": "McGill",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Montreal",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9341335",
        "title": "Learning Hierarchical Acquisition Functions for Bayesian Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning control policies in robotic tasks requires a large number of interactions due to small learning rates, bounds on the updates or unknown constraints. In contrast humans can infer protective and safe solutions after a single failure or unexpected observation. In order to reach similar performance, we developed a hierarchical Bayesian optimization algorithm that replicates the cognitive inference and memorization process for avoiding failures in motor control tasks. A Gaussian Process implements the modeling and the sampling of the acquisition function. This enables rapid learning with large learning rates while a mental replay phase ensures that policy regions that led to failures are inhibited during the sampling process. The features of the hierarchical Bayesian optimization method are evaluated in a simulated and physiological humanoid postural balancing task. The method out- performs standard optimization techniques, such as Bayesian Optimization, in the number of interactions to solve the task, in the computational demands and in the frequency of observed failures. Further, we show that our method performs similar to humans for learning the postural balancing task by comparing our simulation results with real human data.",
        "primary_area": "",
        "author": "Nils Rottmann;Tja\u0161a Kunavar;Jan Babi\u010d;Jan Peters;Elmar Rueckert;Nils Rottmann;Tja\u0161a Kunavar;Jan Babi\u010d;Jan Peters;Elmar Rueckert",
        "authorids": "/37087048833;/37088687313;/37705712100;/37533077600;/37085389924;/37087048833;/37088687313;/37705712100;/37533077600;/37085389924",
        "aff": "Institute for Robotics and Cognitive Systems, University of Luebeck, Luebeck, Germany; Neuromechanics and Biorobotics Lab, Jo\u017eef Stefan Institute, Slovenia; Neuromechanics and Biorobotics Lab, Jo\u017eef Stefan Institute, Slovenia; Robot Learning Group, Max-Planck Institute for Intelligent Systems, Tuebingen, Germany; Institute for Robotics and Cognitive Systems, University of Luebeck, Luebeck, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341335/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:zmZlY2fHNhEJ:scholar.google.com/&scioq=Learning+Hierarchical+Acquisition+Functions+for+Bayesian+Optimization&hl=en&as_sdt=0,5",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;2;0",
        "aff_unique_norm": "University of Luebeck;Jo\u017eef Stefan Institute;Max-Planck Institute for Intelligent Systems",
        "aff_unique_dep": "Institute for Robotics and Cognitive Systems;Neuromechanics and Biorobotics Lab;Robot Learning Group",
        "aff_unique_url": "https://www.uni-luebeck.de;https://www.ijs.si;https://www.mpi-is.mpg.de",
        "aff_unique_abbr": ";;MPI-IS",
        "aff_campus_unique_index": "0;2;0",
        "aff_campus_unique": "Luebeck;;Tuebingen",
        "aff_country_unique_index": "0;1;1;0;0",
        "aff_country_unique": "Germany;Slovenia"
    },
    {
        "id": "9340823",
        "title": "Learning High-Level Policies for Model Predictive Control",
        "track": "main",
        "status": "Poster",
        "abstract": "The combination of policy search and deep neural networks holds the promise of automating a variety of decision-making tasks. Model Predictive Control (MPC) provides robust solutions to robot control tasks by making use of a dynamical model of the system and solving an optimization problem online over a short planning horizon. In this work, we leverage probabilistic decision-making approaches and the generalization capability of artificial neural networks to the powerful online optimization by learning a deep high-level policy for the MPC (High-MPC). Conditioning on robot's local observations, the trained neural network policy is capable of adaptively selecting high-level decision variables for the low-level MPC controller, which then generates optimal control commands for the robot. First, we formulate the search of high-level decision variables for MPC as a policy search problem, specifically, a probabilistic inference problem. The problem can be solved in a closed-form solution. Second, we propose a self-supervised learning algorithm for learning a neural network high-level policy, which is useful for online hyperparameter adaptations in highly dynamic environments. We demonstrate the importance of incorporating the online adaption into autonomous robots by using the proposed method to solve a challenging control problem, where the task is to control a simulated quadrotor to fly through a swinging gate. We show that our approach can handle situations that are difficult for standard MPC.",
        "primary_area": "",
        "author": "Yunlong Song;Davide Scaramuzza;Yunlong Song;Davide Scaramuzza",
        "authorids": "/37088688858;/37397688400;/37088688858;/37397688400",
        "aff": "Dep. of Neuroinformatics, University of Zurich and ETH Zurich, Switzerland; Dep. of Neuroinformatics, University of Zurich and ETH Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340823/",
        "gs_citation": 42,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1212138458818179811&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Zurich",
        "aff_unique_dep": "Department of Neuroinformatics",
        "aff_unique_url": "https://www.unizh.ch",
        "aff_unique_abbr": "UZH",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9341038",
        "title": "Learning Human Navigation Behavior Using Measured Human Trajectories in Crowded Spaces",
        "track": "main",
        "status": "Poster",
        "abstract": "As humans and mobile robots increasingly coexist in public spaces, their close proximity demands that robots navigate following navigation strategies similar to those exhibited by humans. This could be achieved by learning directly from human demonstration trajectories in a machine learning framework. In this paper, we present a method to learn human navigation behaviors using an imitation learning approach based on generative adversarial imitation learning (GAIL), which has the ability of directly extracting navigation policy. Specifically, we use a large open human trajectory dataset that was experimentally collected in a crowded public space. We then recreate these human trajectories in a 3D robotic simulator, and generate demonstration data using a LIDAR sensor onboard a robot with the robot following the measured human trajectories. We then propose a GAIL based algorithm, which uses occupancy maps generated using LIDAR data as the input, and outputs the navigation policy for robot navigation. Simulation experiments are conducted, and performance evaluation shows that the learned navigation policy generates trajectories qualitatively and quantitatively similar to human trajectories. Compared with existing works using analytical models (such as social force model) to generate human demonstration trajectories, our method learns directly from intrinsic human trajectories, thus exhibits more human-like navigation behaviors.",
        "primary_area": "",
        "author": "Muhammad Fahad;Guang Yang;Yi Guo;Muhammad Fahad;Guang Yang;Yi Guo",
        "authorids": "/37089144128;/38022877800;/37277883500;/37089144128;/38022877800;/37277883500",
        "aff": "Department of Robotics and New Product Development, National Oilwell Varco, Houston, TX, USA; Department of Electrical and Computer Engineering, Stevens Institute of Technology, Hoboken, NJ, USA; Department of Electrical and Computer Engineering, Stevens Institute of Technology, Hoboken, NJ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341038/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18178037575525554114&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "National Oilwell Varco;Stevens Institute of Technology",
        "aff_unique_dep": "Department of Robotics and New Product Development;Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.nov.com;https://www.stevens.edu",
        "aff_unique_abbr": "NOV;SIT",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Houston;Hoboken",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340865",
        "title": "Learning Human-Aware Robot Navigation from Physical Interaction via Inverse Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous systems, such as delivery robots, are increasingly employed in indoor spaces to carry out activities alongside humans. This development poses the question of how robots can carry out their tasks while, at the same time, behaving in a socially compliant manner. Further, humans need to be able to communicate their preferences in a simple and intuitive way, and robots should adapt their behavior accordingly. This paper investigates force control as a natural means to interact with a mobile robot by pushing it along the desired trajectory. We employ inverse reinforcement learning (IRL) to learn from human interaction and adapt the robot behavior to its users' preferences, thereby eliminating the need to program the desired behavior manually. We evaluate our approach in a real-world experiment where test subjects interact with an autonomously navigating robot in close proximity. The results suggest that force control presents an intuitive means to interact with a mobile robot and show that our robot can quickly adapt to the test subjects' personal preferences.",
        "primary_area": "",
        "author": "Marina Kollmitz;Torsten Koller;Joschka Boedecker;Wolfram Burgard;Marina Kollmitz;Torsten Koller;Joschka Boedecker;Wolfram Burgard",
        "authorids": "/37085652457;/37086594235;/37888921900;/37270485300;/37085652457;/37086594235;/37888921900;/37270485300",
        "aff": "Department of Computer Science, University of Freiburg, Germany; Department of Computer Science, University of Freiburg, Germany; Department of Computer Science, University of Freiburg, Germany; Toyota Research Institute, Los Altos, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340865/",
        "gs_citation": 44,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9537061969411086335&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "University of Freiburg;Toyota Research Institute",
        "aff_unique_dep": "Department of Computer Science;",
        "aff_unique_url": "https://www.uni-freiburg.de;https://www.tri.global",
        "aff_unique_abbr": ";TRI",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Los Altos",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "Germany;United States"
    },
    {
        "id": "9340749",
        "title": "Learning Hybrid Object Kinematics for Efficient Hierarchical Planning Under Uncertainty",
        "track": "main",
        "status": "Poster",
        "abstract": "Sudden changes in the dynamics of robotic tasks, such as contact with an object or the latching of a door, are often viewed as inconvenient discontinuities that make manipulation difficult. However, when these transitions are well-understood, they can be leveraged to reduce uncertainty or aid manipulation-for example, wiggling a screw to determine if it is fully inserted or not. Current model-free reinforcement learning approaches require large amounts of data to learn to leverage such dynamics, scale poorly as problem complexity grows, and do not transfer well to significantly different problems. By contrast, hierarchical POMDP planning-based methods scale well via plan decomposition, work well on novel problems, and directly consider uncertainty, but often rely on precise hand-specified models and task decompositions. To combine the advantages of these opposing paradigms, we propose a new method, MICAH, which given unsegmented data of an object's motion under applied actions, (1) detects changepoints in the object motion model using action-conditional inference, (2) estimates the individual local motion models with their parameters, and (3) converts them into a hybrid automaton that is compatible with hierarchical POMDP planning. We show that model learning under MICAH is more accurate and robust to noise than prior approaches. Further, we combine MICAH with a hierarchical POMDP planner to demonstrate that the learned models are rich enough to be used for performing manipulation tasks under uncertainty that require the objects to be used in novel ways not encountered during training.",
        "primary_area": "",
        "author": "Ajinkya Jain;Scott Niekum;Ajinkya Jain;Scott Niekum",
        "authorids": "/37088686012;/37395003900;/37088686012;/37395003900",
        "aff": "Personal Autonomous Robotics Lab (PeARL), The University of Texas, Austin; Personal Autonomous Robotics Lab (PeARL), The University of Texas, Austin",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340749/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10249855936058168703&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "The University of Texas at Austin",
        "aff_unique_dep": "Personal Autonomous Robotics Lab (PeARL)",
        "aff_unique_url": "https://www.utexas.edu",
        "aff_unique_abbr": "UT Austin",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Austin",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341783",
        "title": "Learning Local Planners for Human-aware Navigation in Indoor Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Established indoor robot navigation frameworks build on the separation between global and local planners. Whereas global planners rely on traditional graph search algorithms, local planners are expected to handle driving dynamics and resolve minor conflicts. We present a system to train neural-network policies for such a local planner component, explicitly accounting for humans navigating the space. DRL-agents are trained in randomized virtual 2D environments with simulated human interaction. The trained agents can be deployed as a drop-in replacement for other local planners and significantly improve on traditional implementations. Performance is demonstrated on a MiR-100 transport robot.",
        "primary_area": "",
        "author": "Ronja Guldenring;Michael G\u00f6rner;Norman Hendrich;Niels Jul Jacobsen;Jianwei Zhang;Ronja Guldenring;Michael G\u00f6rner;Norman Hendrich;Niels Jul Jacobsen;Jianwei Zhang",
        "authorids": "/37088687358;/37086574844;/37449613700;/37088689012;/37281460600;/37088687358;/37086574844;/37449613700;/37088689012;/37281460600",
        "aff": "MiR Mobile Industrial Robots A/S, Odense S\u00d8, Denmark; Department of Informatics, University of Hamburg, Germany; Department of Informatics, University of Hamburg, Germany; MiR Mobile Industrial Robots A/S, Odense S\u00d8, Denmark; Department of Informatics, University of Hamburg, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341783/",
        "gs_citation": 89,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9843744584240937493&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;0;1",
        "aff_unique_norm": "Mobile Industrial Robots A/S;University of Hamburg",
        "aff_unique_dep": ";Department of Informatics",
        "aff_unique_url": "https://www.mobileindustrialrobots.com;https://www.uni-hamburg.de",
        "aff_unique_abbr": "MiR;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;1;0;1",
        "aff_country_unique": "Denmark;Germany"
    },
    {
        "id": "9341458",
        "title": "Learning Motion Parameterizations of Mobile Pick and Place Actions from Observing Humans in Virtual Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present an approach and an implemented pipeline for transferring data acquired from observing humans in virtual environments onto robots acting in the real world, and adapting the data accordingly to achieve successful task execution. We demonstrate our pipeline by inferring seven different symbolic and subsymbolic motion parameters of mobile pick and place actions, which allows the robot to set a simple breakfast table. We propose an approach to learn general motion parameter models and discuss, which parameters can be learned at which abstraction level.",
        "primary_area": "",
        "author": "Gayane Kazhoyan;Alina Hawkin;Sebastian Koralewski;Andrei Haidu;Michael Beetz;Gayane Kazhoyan;Alina Hawkin;Sebastian Koralewski;Andrei Haidu;Michael Beetz",
        "authorids": "/37086314230;/37088686263;/37086026637;/37085583787;/37279125900;/37086314230;/37088686263;/37086026637;/37085583787;/37279125900",
        "aff": "Institute for Artificial Intelligence, University of Bremen, Germany; Institute for Artificial Intelligence, University of Bremen, Germany; Institute for Artificial Intelligence, University of Bremen, Germany; Institute for Artificial Intelligence, University of Bremen, Germany; Institute for Artificial Intelligence, University of Bremen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341458/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7865358796120040173&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Bremen",
        "aff_unique_dep": "Institute for Artificial Intelligence",
        "aff_unique_url": "https://www.uni-bremen.de",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Bremen",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9340824",
        "title": "Learning Object Attributes with Category-Free Grounded Language from Deep Featurization",
        "track": "main",
        "status": "Poster",
        "abstract": "While grounded language learning, or learning the meaning of language with respect to the physical world in which a robot operates, is a major area in human-robot interaction studies, most research occurs in closed worlds or domain-constrained settings. We present a system in which language is grounded in visual percepts without using categorical constraints by combining CNN-based visual featurization with natural language labels. We demonstrate results comparable to those achieved using handcrafted features for specific traits, a step towards moving language grounding into the space of fully open world recognition.",
        "primary_area": "",
        "author": "Luke E. Richards;Kasra Darvish;Cynthia Matuszek;Luke E. Richards;Kasra Darvish;Cynthia Matuszek",
        "authorids": "/37088686329;/37088686876;/37402735100;/37088686329;/37088686876;/37402735100",
        "aff": "Booz Allen Hamilton; University of Maryland, Baltimore County; University of Maryland, Baltimore County",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340824/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4568981743530016037&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Booz Allen Hamilton;University of Maryland, Baltimore County",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.boozallen.com;https://www.umbc.edu",
        "aff_unique_abbr": "BAH;UMBC",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Baltimore County",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340966",
        "title": "Learning Object Manipulation with Dexterous Hand-Arm Systems from Human Demonstration",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a novel learning and control framework that combines artificial neural networks with online trajectory optimization to learn dexterous manipulation skills from human demonstration and to transfer the learned behaviors to real robots. Humans can perform the demonstrations with their own hands and with real objects. An instrumented glove is used to record motions and tactile data. Our system learns neural control policies that generalize to modified object poses directly from limited amounts of demonstration data. Outputs from the neural policy network are combined at runtime with kinematic and dynamic safety and feasibility constraints as well as a learned regularizer to obtain commands for a real robot through online trajectory optimization. We test our approach on multiple tasks and robots.",
        "primary_area": "",
        "author": "Philipp Ruppel;Jianwei Zhang;Philipp Ruppel;Jianwei Zhang",
        "authorids": "/37086456160;/37281460600;/37086456160;/37281460600",
        "aff": "Department of Informatics, University of Hamburg; Department of Informatics, University of Hamburg",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340966/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11456845892196561070&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Hamburg",
        "aff_unique_dep": "Department of Informatics",
        "aff_unique_url": "https://www.uni-hamburg.de",
        "aff_unique_abbr": "UHH",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9340773",
        "title": "Learning Optimized Human Motion via Phase Space Analysis",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a dynamic system based learning from demonstration approach to teach a robot activities of daily living. The approach takes inspiration from human movement literature to formulate trajectory learning as an optimal control problem. We assume a weighted combination of basis objective functions is the true objective function for a demonstrated motion. We derive basis objective functions analogous to those in human movement literature to optimize the robot's motion. This method aims to naturally adapt the learned motion in different situations. To validate our approach, we learn motions from two categories: 1) commonly prescribed therapeutic exercises and 2) tea making. We show the reproduction accuracy of our method and compare torque requirements to the dynamic motion primitive for each motion, with and without an added load.",
        "primary_area": "",
        "author": "Paul Gesel;Francesco Mikulis-Borsoi;Dain LaRoche;Sajay Arthanat;Momotaz Begum;Paul Gesel;Francesco Mikulis-Borsoi;Dain LaRoche;Sajay Arthanat;Momotaz Begum",
        "authorids": "/37086936045;/37088688544;/37088690465;/37088691474;/37293898900;/37086936045;/37088688544;/37088690465;/37088691474;/37293898900",
        "aff": "Department of Computer Science, University of New Hampshire, USA; Department of Computer Science, University of New Hampshire, USA; Department of Kinesiology, University of New Hampshire, Dain, USA; Department of Occupational Therapy, University of New Hampshire, USA; Department of Computer Science, University of New Hampshire, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340773/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15485680040299071775&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of New Hampshire",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.unh.edu",
        "aff_unique_abbr": "UNH",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340860",
        "title": "Learning Orientation Distributions for Object Pose Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "For robots to operate robustly in the real world, they should be aware of their uncertainty. However, most methods for object pose estimation return a single point estimate of the object's pose. In this work, we propose two learned methods for estimating a distribution over an object's orientation. Our methods take into account both the inaccuracies in the pose estimation as well as the object symmetries. Our first method, which regresses from deep learned features to an isotropic Bingham distribution, gives the best performance for orientation distribution estimation for non-symmetric objects. Our second method learns to compare deep features and generates a non-parameteric histogram distribution. This method gives the best performance on objects with unknown symmetries, accurately modeling both symmetric and non-symmetric objects, without any requirement of symmetry annotation. We show that both of these methods can be used to augment an existing pose estimator. Our evaluation compares our methods to a large number of baseline approaches for uncertainty estimation across a variety of different types of objects. Code available at https://bokorn.github.io/orientation-distributions/.",
        "primary_area": "",
        "author": "Brian Okorn;Mengyun Xu;Martial Hebert;David Held;Brian Okorn;Mengyun Xu;Martial Hebert;David Held",
        "authorids": "/37393124300;/37086365939;/37271437400;/37408101800;/37393124300;/37086365939;/37271437400;/37408101800",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340860/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18114132788154473018&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341475",
        "title": "Learning Skills to Patch Plans Based on Inaccurate Models",
        "track": "main",
        "status": "Poster",
        "abstract": "Planners using accurate models can be effective for accomplishing manipulation tasks in the real world, but are typically highly specialized and require significant fine-tuning to be reliable. Meanwhile, learning is useful for adaptation, but can require a substantial amount of data collection. In this paper, we propose a method that improves the efficiency of sub-optimal planners with approximate but simple and fast models by switching to a model-free policy when unexpected transitions are observed. Unlike previous work, our method specifically addresses when the planner fails due to transition model error by patching with a local policy only where needed. First, we use a sub-optimal model-based planner to perform a task until model failure is detected. Next, we learn a local model-free policy from expert demonstrations to complete the task in regions where the model failed. To show the efficacy of our method, we perform experiments with a shape insertion puzzle and compare our results to both pure planning and imitation learning approaches. We then apply our method to a door opening task. Our experiments demonstrate that our patch-enhanced planner performs more reliably than pure planning and with lower overall sample complexity than pure imitation learning.",
        "primary_area": "",
        "author": "Alex Lagrassa;Steven Lee;Oliver Kroemer;Alex Lagrassa;Steven Lee;Oliver Kroemer",
        "authorids": "/37088689868;/37088688444;/37593222300;/37088689868;/37088688444;/37593222300",
        "aff": "Robotics Institute, School of Computer Science, Carnegie Mel-lon University, Pittsburgh, PA, USA; Robotics Institute, School of Computer Science, Carnegie Mel-lon University, Pittsburgh, PA, USA; Robotics Institute, School of Computer Science, Carnegie Mel-lon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341475/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13763629403534465982&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute, School of Computer Science",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341504",
        "title": "Learning Soft Robotic Assembly Strategies from Successful and Failed Demonstrations",
        "track": "main",
        "status": "Poster",
        "abstract": "Physically soft robots are promising for robotic assembly tasks as they allow stable contacts with the environment. In this study, we propose a novel learning system for soft robotic assembly strategies. We formulate this problem as a reinforcement learning task and design the reward function from human demonstrations. Our key insight is that the failed demonstrations can be used as constraints to avoid failed behaviors. To this end, we developed a teaching device with which humans can intuitively provide various demonstrations. Moreover, we leverage Physically-Consistent Gaussian Mixture Models to clearly assign Gaussian components to the successful and failed trials. We then create the reference trajectories via Gaussian Mixture Regressions, which fit the successful demonstrations while considering the failed ones. Finally, we apply a sample- efficient deep model-based reinforcement learning method to obtain robust strategies with a few interactions. To validate our method, we developed a real-robot experimental system composed of a rigid collaborative robot arm with a compliant wrist and the teaching device. Our results demonstrated that our method learned the assembly strategies with a higher success rate than when using only successful demonstrations.",
        "primary_area": "",
        "author": "Masashi Hamaya;Felix von Drigalski;Takamitsu Matsubara;Kazutoshi Tanaka;Robert Lee;Chisato Nakashima;Yoshiya Shibata;Yoshihisa Ijiri;Masashi Hamaya;Felix von Drigalski;Takamitsu Matsubara;Kazutoshi Tanaka;Robert Lee;Chisato Nakashima;Yoshiya Shibata;Yoshihisa Ijiri",
        "authorids": "/37085532024;/37086063905;/37533262700;/37088507484;/37088507437;/37088507122;/37088505999;/37085621887;/37085532024;/37086063905;/37533262700;/37088507484;/37088507437;/37088507122;/37088505999;/37085621887",
        "aff": "OMRON SINIC X Corporation, Tokyo, Japan; OMRON SINIC X Corporation, Tokyo, Japan; Graduate School of Science and Technology, Nara Institute of Science and Technology, Nara, Japan; OMRON SINIC X Corporation, Tokyo, Japan; Australian Center for Robotic Vision at Queensland, University of Technology, Brisbane, Australia; OMRON Corporation, Tokyo, Japan; OMRON Corporation, Tokyo, Japan; OMRON Corporation, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341504/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10728298957408666412&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;1;0;2;3;3;3",
        "aff_unique_norm": "OMRON SINIC X Corporation;Nara Institute of Science and Technology;Queensland University of Technology;OMRON Corporation",
        "aff_unique_dep": ";Graduate School of Science and Technology;Australian Center for Robotic Vision;",
        "aff_unique_url": ";https://www.nist.go.jp;https://www.qut.edu.au;https://www.omron.com",
        "aff_unique_abbr": ";NIST;QUT;OMRON",
        "aff_campus_unique_index": "0;0;1;0;2;0;0;0",
        "aff_campus_unique": "Tokyo;Nara;Brisbane",
        "aff_country_unique_index": "0;0;0;0;1;0;0;0",
        "aff_country_unique": "Japan;Australia"
    },
    {
        "id": "9341701",
        "title": "Learning State-Dependent Losses for Inverse Dynamics Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Being able to quickly adapt to changes in dynamics is paramount in model-based control for object manipulation tasks. In order to influence fast adaptation of the inverse dynamics model's parameters, data efficiency is crucial. Given observed data, a key element to how an optimizer updates model parameters is the loss function. In this work, we propose to apply meta-learning to learn structured, state-dependent loss functions during a meta-training phase. We then replace standard losses with our learned losses during online adaptation tasks. We evaluate our proposed approach on inverse dynamics learning tasks, both in simulation and on real hardware data. In both settings, the structured and state-dependent learned losses improve online adaptation speed, when compared to standard, state-independent loss functions.",
        "primary_area": "",
        "author": "Kristen Morse;Neha Das;Yixin Lin;Austin S. Wang;Akshara Rai;Franziska Meier;Kristen Morse;Neha Das;Yixin Lin;Austin S. Wang;Akshara Rai;Franziska Meier",
        "authorids": "/37088688917;/37088688713;/37088688938;/37086934263;/37085480350;/38227805500;/37088688917;/37088688713;/37088688938;/37086934263;/37085480350;/38227805500",
        "aff": "Facebook AI Research; Facebook AI Research; Facebook AI Research; Facebook AI Research; Facebook AI Research; Facebook AI Research",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341701/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11289875708748393306&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Facebook",
        "aff_unique_dep": "Facebook AI Research",
        "aff_unique_url": "https://research.facebook.com",
        "aff_unique_abbr": "FAIR",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341330",
        "title": "Learning Topological Motion Primitives for Knot Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we approach the challenging problem of motion planning for knot tying. We propose a hierarchical approach in which the top layer produces a topological plan and the bottom layer translates this plan into continuous robot motion. The top layer decomposes a knotting task into sequences of abstract topological actions based on knot theory. The bottom layer translates each of these abstract actions into robot motion trajectories through learned topological motion primitives. To adapt each topological action to the specific rope geometry, the motion primitives take the observed rope configuration as input. We train the motion primitives by imitating human demonstrations and reinforcement learning in simulation. To generalize human demonstrations of simple knots into more complex knots, we observe similarities in the motion strategies of different topological actions and design the neural network structure to exploit such similarities. We demonstrate that our learned motion primitives can be used to efficiently generate motion plans for tying the overhand knot. The motion plan can then be executed on a real robot using visual tracking and Model Predictive Control. We also demonstrate that our learned motion primitives can be composed to tie a more complex pentagram-like knot despite being only trained on human demonstrations of simpler knots.",
        "primary_area": "",
        "author": "Mengyuan Yan;Gen Li;Yilin Zhu;Jeannette Bohg;Mengyuan Yan;Gen Li;Yilin Zhu;Jeannette Bohg",
        "authorids": "/37086937276;/37088690202;/37088070515;/37591153900;/37086937276;/37088690202;/37088070515;/37591153900",
        "aff": "School of Engineering, Stanford University, CA, USA; Department of Computer Science and Technology, Tsinghua University, Beijing, China; School of Engineering, Stanford University, CA, USA; School of Engineering, Stanford University, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341330/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13656202344604076248&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Stanford University;Tsinghua University",
        "aff_unique_dep": "School of Engineering;Department of Computer Science and Technology",
        "aff_unique_url": "https://www.stanford.edu;https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "Stanford;THU",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Stanford;Beijing",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "9340809",
        "title": "Learning Transition Models with Time-delayed Causal Relations",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper introduces an algorithm for discovering implicit and delayed causal relations between events observed by a robot at arbitrary times, with the objective of improving data-efficiency and interpretability of model- based reinforcement learning (RL) techniques. The proposed algorithm initially predicts observations with the Markov assumption, and incrementally introduces new hidden variables to explain and reduce the stochasticity of the observations. The hidden variables are memory units that keep track of pertinent past events. Such events are systematically identified by their information gains. The learned transition and reward models are then used for planning. Experiments on simulated and real robotic tasks show that this method significantly improves over current RL techniques.",
        "primary_area": "",
        "author": "Junchi Liang;Abdeslam Boularias;Junchi Liang;Abdeslam Boularias",
        "authorids": "/37088689223;/37542596800;/37088689223;/37542596800",
        "aff": "Department of Computer Science, Rutgers University, Piscataway, New Jersey, USA; Department of Computer Science, Rutgers University, Piscataway, New Jersey, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340809/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5951005977506265645&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Rutgers University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.rutgers.edu",
        "aff_unique_abbr": "Rutgers",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Piscataway",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340909",
        "title": "Learning User-Preferred Mappings for Intuitive Robot Control",
        "track": "main",
        "status": "Poster",
        "abstract": "When humans control drones, cars, and robots, we often have some preconceived notion of how our inputs should make the system behave. Existing approaches to teleoperation typically assume a one-size-fits-all approach, where the designers pre-define a mapping between human inputs and robot actions, and every user must adapt to this mapping over repeated interactions. Instead, we propose a personalized method for learning the human's preferred or preconceived mapping from a few robot queries. Given a robot controller, we identify an alignment model that transforms the human's inputs so that the controller's output matches their expectations. We make this approach data-efficient by recognizing that human mappings have strong priors: we expect the input space to be proportional, reversable, and consistent. Incorporating these priors ensures that the robot learns an intuitive mapping from few examples. We test our learning approach in robot manipulation tasks inspired by assistive settings, where each user has different personal preferences and physical capabilities for teleoperating the robot arm. Our simulated and experimental results suggest that learning the mapping between inputs and robot actions improves objective and subjective performance when compared to manually defined alignments or learned alignments without intuitive priors. The supplementary video showing these user studies can be found at: https://youtu.be/rKHka0_48-Q.",
        "primary_area": "",
        "author": "Mengxi Li;Dylan P. Losey;Jeannette Bohg;Dorsa Sadigh;Mengxi Li;Dylan P. Losey;Jeannette Bohg;Dorsa Sadigh",
        "authorids": "/37088689162;/37085812055;/37591153900;/38234464200;/37088689162;/37085812055;/37591153900;/38234464200",
        "aff": "Computer Science Department, Stanford University, Stanford, CA; Computer Science Department, Stanford University, Stanford, CA; Computer Science Department, Stanford University, Stanford, CA; Computer Science Department, Stanford University, Stanford, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340909/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9597224046707222043&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "Computer Science Department",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341675",
        "title": "Learning Vision-Based Physics Intuition Models for Non-Disruptive Object Extraction",
        "track": "main",
        "status": "Poster",
        "abstract": "Robots operating in human environments must be careful, when executing their manipulation skills, not to disturb nearby objects. This requires robots to reason about the effect of their manipulation choices by accounting for the support relationships among objects in the scene. Humans do this in part by visually assessing their surroundings and using physics intuition for how likely it is that a particular object can be safely manipulated (i.e., cause no disruption in the rest of the scene). Existing work has shown that deep convolutional neural networks can learn intuitive physics over images generated in simulation and determine the stability of a scene in the real world. In this paper, we extend these physics intuition models to the task of assessing safe object extraction by conditioning the visual images on specific objects in the scene. Our results, in both simulation and real-world settings, show that with our proposed method, physics intuition models can be used to inform a robot of which objects can be safely extracted and from which direction to extract them.",
        "primary_area": "",
        "author": "Sarthak Ahuja;Henny Admoni;Aaron Steinfeld;Sarthak Ahuja;Henny Admoni;Aaron Steinfeld",
        "authorids": "/37088687743;/38570430500;/37284961500;/37088687743;/38570430500;/37284961500",
        "aff": "Carnegie Mellon University; Carnegie Mellon University; Carnegie Mellon University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341675/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12543046539712514824&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341049",
        "title": "Learning Visuomotor Policies for Aerial Navigation Using Cross-Modal Representations",
        "track": "main",
        "status": "Poster",
        "abstract": "Machines are a long way from robustly solving open-world perception-control tasks, such as first-person view (FPV) aerial navigation. While recent advances in end-to- end Machine Learning, especially Imitation Learning and Reinforcement appear promising, they are constrained by the need of large amounts of difficult-to-collect labeled real- world data. Simulated data, on the other hand, is easy to generate, but generally does not render safe behaviors in diverse real-life scenarios. In this work we propose a novel method for learning robust visuomotor policies for real-world deployment which can be trained purely with simulated data. We develop rich state representations that combine supervised and unsupervised environment data. Our approach takes a cross-modal perspective, where separate modalities correspond to the raw camera data and the system states relevant to the task, such as the relative pose of gates to the drone in the case of drone racing. We feed both data modalities into a novel factored architecture, which learns a joint lowdimensional embedding via Variational Auto Encoders. This compact representation is then fed into a control policy, which we trained using imitation learning with expert trajectories in a simulator. We analyze the rich latent spaces learned with our proposed representations, and show that the use of our cross-modal architecture significantly improves control policy performance as compared to end-to-end learning or purely unsupervised feature extractors. We also present real-world results for drone navigation through gates in different track configurations and environmental conditions. Our proposed method, which runs fully onboard, can successfully generalize the learned representations and policies across simulation and reality, significantly outperforming baseline approaches.",
        "primary_area": "",
        "author": "Rogerio Bonatti;Ratnesh Madaan;Vibhav Vineet;Sebastian Scherer;Ashish Kapoor;Rogerio Bonatti;Ratnesh Madaan;Vibhav Vineet;Sebastian Scherer;Ashish Kapoor",
        "authorids": "/37086934741;/37086298161;/38094245300;/37584159000;/37397699500;/37086934741;/37086298161;/38094245300;/37584159000;/37397699500",
        "aff": "The Robotics Institute, Carnegie Mellon University, Pittsburgh, PA; Microsoft Corporation, Redmond, WA; Microsoft Corporation, Redmond, WA; The Robotics Institute, Carnegie Mellon University, Pittsburgh, PA; Microsoft Corporation, Redmond, WA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341049/",
        "gs_citation": 61,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4911180050027370044&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;0;1",
        "aff_unique_norm": "Carnegie Mellon University;Microsoft Corporation",
        "aff_unique_dep": "The Robotics Institute;",
        "aff_unique_url": "https://www.cmu.edu;https://www.microsoft.com",
        "aff_unique_abbr": "CMU;Microsoft",
        "aff_campus_unique_index": "0;1;1;0;1",
        "aff_campus_unique": "Pittsburgh;Redmond",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341511",
        "title": "Learning Your Way Without Map or Compass: Panoramic Target Driven Visual Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a robot navigation system that uses an imitation learning framework to successfully navigate in complex environments. Our framework takes a pre-built 3D scan of a real environment and trains an agent from pre-generated expert trajectories to navigate to any position given a panoramic view of the goal and the current visual input without relying on map, compass, odometry, or relative position of the target at runtime. Our end-to-end trained agent uses RGB and depth (RGBD) information and can handle large environments (up to 1031m2) across multiple rooms (up to 40) and generalizes to unseen targets. We show that when compared to several baselines our method (1) requires fewer training examples and less training time, (2) reaches the goal location with higher accuracy, and (3) produces better solutions with shorter paths for long-range navigation tasks.",
        "primary_area": "",
        "author": "David Watkins-Valls;Jingxi Xu;Nicholas Waytowich;Peter Allen;David Watkins-Valls;Jingxi Xu;Nicholas Waytowich;Peter Allen",
        "authorids": "/37086934216;/37088507340;/37586656400;/37280851400;/37086934216;/37088507340;/37586656400;/37280851400",
        "aff": "Department of Computer Science, Columbia University, New York, NY, USA; Department of Computer Science, Columbia University, New York, NY, USA; U.S. Army Research Laboratory, Baltimore, MD, USA; Department of Computer Science, Columbia University, New York, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341511/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10722182019907746560&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Columbia University;U.S. Army Research Laboratory",
        "aff_unique_dep": "Department of Computer Science;",
        "aff_unique_url": "https://www.columbia.edu;https://www.arl.army.mil",
        "aff_unique_abbr": "Columbia;ARL",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "New York;Baltimore",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341245",
        "title": "Learning an Optimal Sampling Distribution for Efficient Motion Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Sampling-based motion planners (SBMP) are commonly used to generate motion plans by incrementally constructing a search tree through a robot's configuration space. For high degree-of-freedom systems, sampling is often done in a lower-dimensional space, with a steering function responsible for local planning in the higher-dimensional configuration space. However, for highly-redundant systems with complex kinematics, this approach is problematic due to the high computational cost of evaluating the steering function, especially in cluttered environments. Therefore, having an efficient, informed sampler becomes critical to online robot operation. In this study, we develop a learning-based approach with policy improvement to compute an optimal sampling distribution for use in SBMPs. Motivated by the challenge of whole-body planning for a 31 degree-of-freedom mobile robot built by the Toyota Research Institute, we combine our learning-based approach with classical graph-search to obtain a constrained sampling distribution. Over multiple learning iterations, the algorithm learns a probability distribution weighting areas of low-cost and high probability of success, which a graph search algorithm then uses to obtain an optimal sampling distribution for the robot. On challenging motion planning tasks for the robot, we observe significant computational speed-up, fewer edge evaluations, and more efficient paths with minimal computational overhead. We show the efficacy of our approach with a number of experiments in whole-body motion planning.",
        "primary_area": "",
        "author": "Richard Cheng;Krishna Shankar;Joel W. Burdick;Richard Cheng;Krishna Shankar;Joel W. Burdick",
        "authorids": "/37086493605;/37085401404;/37265975700;/37086493605;/37085401404;/37265975700",
        "aff": "California Institute of Technology; Toyota Research Institute; California Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341245/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11829100830974942104&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "California Institute of Technology;Toyota Research Institute",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.caltech.edu;https://www.tri.global",
        "aff_unique_abbr": "Caltech;TRI",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Pasadena;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340769",
        "title": "Learning an Overlap-based Observation Model for 3D LiDAR Localization",
        "track": "main",
        "status": "Poster",
        "abstract": "Localization is a crucial capability for mobile robots and autonomous cars. In this paper, we address learning an observation model for Monte-Carlo localization using 3D LiDAR data. We propose a novel, neural network-based observation model that computes the expected overlap of two 3D LiDAR scans. The model predicts the overlap and yaw angle offset between the current sensor reading and virtual frames generated from a pre-built map. We integrate this observation model into a Monte-Carlo localization framework and tested it on urban datasets collected with a car in different seasons. The experiments presented in this paper illustrate that our method can reliably localize a vehicle in typical urban environments. We furthermore provide comparisons to a beam-endpoint and a histogram-based method indicating a superior global localization performance of our method with fewer particles.",
        "primary_area": "",
        "author": "Xieyuanli Chen;Thomas L\u00e4be;Lorenzo Nardi;Jens Behley;Cyrill Stachniss;Xieyuanli Chen;Thomas L\u00e4be;Lorenzo Nardi;Jens Behley;Cyrill Stachniss",
        "authorids": "/37086247697;/37086411637;/37085701067;/37593243900;/37329668600;/37086247697;/37086411637;/37085701067;/37593243900;/37329668600",
        "aff": "University of Bonn, Germany; University of Bonn, Germany; University of Bonn, Germany; University of Bonn, Germany; University of Bonn, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340769/",
        "gs_citation": 58,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4206143651161065863&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Bonn",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.uni-bonn.de",
        "aff_unique_abbr": "UBonn",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9341623",
        "title": "Learning an Uncertainty-Aware Object Detector for Autonomous Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "The capability to detect objects is a core part of autonomous driving. Due to sensor noise and incomplete data, perfectly detecting and localizing every object is infeasible. Therefore, it is important for a detector to provide the amount of uncertainty in each prediction. Providing the autonomous system with reliable uncertainties enables the vehicle to react differently based on the level of uncertainty. Previous work has estimated the uncertainty in a detection by predicting a probability distribution over object bounding boxes. In this work, we propose a method to improve the ability to learn the probability distribution by considering the potential noise in the ground-truth labeled data. Our proposed approach improves not only the accuracy of the learned distribution but also the object detection performance.",
        "primary_area": "",
        "author": "Gregory P. Meyer;Niranjan Thakurdesai;Gregory P. Meyer;Niranjan Thakurdesai",
        "authorids": "/37087232268;/37088688123;/37087232268;/37088688123",
        "aff": "Uber Advanced Technologies Group; Georgia Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341623/",
        "gs_citation": 69,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5623321425833840749&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Uber;Georgia Institute of Technology",
        "aff_unique_dep": "Advanced Technologies Group;",
        "aff_unique_url": "https://www.uber.com;https://www.gatech.edu",
        "aff_unique_abbr": "Uber ATG;Georgia Tech",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341570",
        "title": "Learning and Sequencing of Object-Centric Manipulation Skills for Industrial Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "Enabling robots to quickly learn manipulation skills is an important, yet challenging problem. Such manipulation skills should be flexible, e.g., be able adapt to the current workspace configuration. Furthermore, to accomplish complex manipulation tasks, robots should be able to sequence several skills and adapt them to changing situations. In this work, we propose a rapid robot skill-sequencing algorithm, where the skills are encoded by object-centric hidden semi-Markov models. The learned skill models can encode multimodal (temporal and spatial) trajectory distributions. This approach significantly reduces manual modeling efforts, while ensuring a high degree of flexibility and re-usability of learned skills. Given a task goal and a set of generic skills, our framework computes smooth transitions between skill instances. To compute the corresponding optimal end-effector trajectory in task space we rely on Riemannian optimal controller. We demonstrate this approach on a 7 DoF robot arm for industrial assembly tasks.",
        "primary_area": "",
        "author": "Leonel Rozo;Meng Guo;Andras G. Kupcsik;Marco Todescato;Philipp Schillinger;Markus Giftthaler;Matthias Ochs;Markus Spies;Nicolai Waniek;Patrick Kesper;Mathias Burger;Leonel Rozo;Meng Guo;Andras G. Kupcsik;Marco Todescato;Philipp Schillinger;Markus Giftthaler;Matthias Ochs;Markus Spies;Nicolai Waniek;Patrick Kesper;Mathias Burger",
        "authorids": "/38228060200;/38237113400;/37086548878;/37085560964;/37085798192;/37085791761;/37085659659;/37086300067;/37085665479;/37088231397;/37528853600;/38228060200;/38237113400;/37086548878;/37085560964;/37085798192;/37085791761;/37085659659;/37086300067;/37085665479;/37088231397;/37528853600",
        "aff": "Bosch Center for Artificial Intelligence, Renningen, Germany; Bosch Center for Artificial Intelligence, Renningen, Germany; Bosch Center for Artificial Intelligence, Renningen, Germany; Bosch Center for Artificial Intelligence, Renningen, Germany; Bosch Center for Artificial Intelligence, Renningen, Germany; Bosch Center for Artificial Intelligence, Renningen, Germany; Bosch Center for Artificial Intelligence, Renningen, Germany; Bosch Center for Artificial Intelligence, Renningen, Germany; Bosch Center for Artificial Intelligence, Renningen, Germany; Bosch Center for Artificial Intelligence, Renningen, Germany; Bosch Center for Artificial Intelligence, Renningen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341570/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7589689230627186283&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 22,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Bosch Center for Artificial Intelligence",
        "aff_unique_dep": "Artificial Intelligence",
        "aff_unique_url": "https://www.bosch-ai.com",
        "aff_unique_abbr": "BCAI",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Renningen",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9341535",
        "title": "Learning constraint-based planning models from demonstrations",
        "track": "main",
        "status": "Poster",
        "abstract": "How can we learn representations for planning that are both efficient and flexible? Task and motion planning models are a good candidate, having been very successful in long-horizon planning tasks-however, they've proved challenging for learning, relying mostly on hand-coded representations. We present a framework for learning constraint-based task and motion planning models using gradient descent. Our model observes expert demonstrations of a task and decomposes them into modes-segments which specify a set of constraints on a trajectory optimization problem. We show that our model learns these modes from few demonstrations, that modes can be used to plan flexibly in different environments and to achieve different types of goals, and that the model can recombine these modes in novel ways.",
        "primary_area": "",
        "author": "Jo\u00e3o Loula;Kelsey Allen;Tom Silver;Josh Tenenbaum;Jo\u00e3o Loula;Kelsey Allen;Tom Silver;Josh Tenenbaum",
        "authorids": "/37088687625;/37088690940;/37088687048;/37622583000;/37088687625;/37088690940;/37088687048;/37622583000",
        "aff": "Department of Brain and Cognitive Sciences, MIT, Cambridge, MA, USA; Department of Brain and Cognitive Sciences, MIT, Cambridge, MA, USA; Department of Electrical Engineering and Computer Science, MIT, Cambridge, MA, USA; Department of Brain and Cognitive Sciences, MIT, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341535/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1186439370152575923&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Department of Brain and Cognitive Sciences",
        "aff_unique_url": "https://www.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341647",
        "title": "Learning hierarchical behavior and motion planning for autonomous driving",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning-based driving solution, a new branch for autonomous driving, is expected to simplify the modeling of driving by learning the underlying mechanisms from data. To improve the tactical decision-making for learning-based driving solution, we introduce hierarchical behavior and motion planning (HBMP) to explicitly model the behavior in learning-based solution. Due to the coupled action space of behavior and motion, it is challenging to solve HBMP problem using reinforcement learning (RL) for long-horizon driving tasks. We transform HBMP problem by integrating a classical sampling-based motion planner, of which the optimal cost is regarded as the rewards for high-level behavior learning. As a result, this formulation reduces action space and diversifies the rewards without losing the optimality of HBMP. In addition, we propose a sharable representation for input sensory data across simulation platforms and real-world environment, so that models trained in a fast event-based simulator, SUMO, can be used to initialize and accelerate the RL training in a dynamics based simulator, CARLA. Experimental results demonstrate the effectiveness of the method. Besides, the model is successfully transferred to the real-world, validating the generalization capability.",
        "primary_area": "",
        "author": "Jingke Wang;Yue Wang;Dongkun Zhang;Yezhou Yang;Rong Xiong;Jingke Wang;Yue Wang;Dongkun Zhang;Yezhou Yang;Rong Xiong",
        "authorids": "/37088687291;/37072299700;/37087886680;/37086004333;/37271511300;/37088687291;/37072299700;/37087886680;/37086004333;/37271511300",
        "aff": "State Key Laboratory of Industrial Control and Technology, Zhejiang University, Hangzhou, P.R. China; State Key Laboratory of Industrial Control and Technology, Zhejiang University, Hangzhou, P.R. China; State Key Laboratory of Industrial Control and Technology, Zhejiang University, Hangzhou, P.R. China; State Key Laboratory of Industrial Control and Technology, Zhejiang University, Hangzhou, P.R. China; State Key Laboratory of Industrial Control and Technology, Zhejiang University, Hangzhou, P.R. China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341647/",
        "gs_citation": 48,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=184511221168628241&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Zhejiang University",
        "aff_unique_dep": "State Key Laboratory of Industrial Control and Technology",
        "aff_unique_url": "http://www.zju.edu.cn",
        "aff_unique_abbr": "ZJU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Hangzhou",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9341803",
        "title": "Learning of Tool Force Adjustment Skills by a Life-sized Humanoid using Deep Reinforcement Learning and Active Teaching Request",
        "track": "main",
        "status": "Poster",
        "abstract": "The purpose of this study is to make life-sized humanoid robots acquire tool manipulation skills that require complicated force adjustment. The difficulty in acquisition of tool manipulation skills comes from the hardship in physical modeling. Recent research have revealed that deep reinforcement learning (DRL), a model-free approach, performs superior in such tasks. However, DRL in general has a drawback in sample efficiency, and this becomes critical in robot learning especially in life-sized humanoid robots. In this study, we propose an integrated system incorporating DRL method and active learning. Our method also leverages a variety of previous studies on life-sized humanoid robots to overcome the sample efficiency issue. We demonstrated the effectiveness of our proposed system through a hacksaw skill acquisition and a Japanese planer (Kanna) skill acquisition by a life-sized humanoid robot.",
        "primary_area": "",
        "author": "Yoichiro Kawamura;Masaki Murooka;Naoki Hiraoka;Hideaki Ito;Kei Okada;Masayuki Inaba;Yoichiro Kawamura;Masaki Murooka;Naoki Hiraoka;Hideaki Ito;Kei Okada;Masayuki Inaba",
        "authorids": "/37088170182;/37085365946;/37087325306;/37087324463;/37280639000;/37286658200;/37088170182;/37085365946;/37087325306;/37087324463;/37280639000;/37286658200",
        "aff": "Department of Mechano-Informatics, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, The University of Tokyo, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341803/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1889729879292529907&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "The University of Tokyo",
        "aff_unique_dep": "Department of Mechano-Informatics",
        "aff_unique_url": "https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "UTokyo",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9364328",
        "title": "Learning robust manipulation tasks involving contact using trajectory parameterized probabilistic principal component analysis",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we aim to expedite the deployment of challenging manipulation tasks involving both motion and contact wrenches (forces and moments). To this end, we acquire motion and wrench signals from a small set of demonstrations using passive observation. To learn these tasks, we introduce Trajectory parameterized Probabilistic Principal Component Analysis (traPPCA) which compactly re-parameterizes the acquired signals using trajectory information and encodes the signal correlations using Probabilistic Principal Component Analysis (PPCA). Finally, the task is transferred to a robot setup by specifying the robot behavior using a constraint-based task specification and control approach. This framework results in increased robustness of the system against different sources of uncertainty: imprecise sensors, adaptation of the tool, and changes in the execution speed.",
        "primary_area": "",
        "author": "Cristian Vergara Perico;Joris de Schutter;Erwin Aertbeli\u00ebn;Cristian Vergara Perico;Joris de Schutter;Erwin Aertbeli\u00ebn",
        "authorids": "/37086695539;/37283056500;/37449455800;/37086695539;/37283056500;/37449455800",
        "aff": "PMA Division, Robotics Research Group, KU Leuven, Core Lab Flanders Make, Belgium; PMA Division, Robotics Research Group, KU Leuven, Core Lab Flanders Make, Belgium; PMA Division, Robotics Research Group, KU Leuven, Core Lab Flanders Make, Belgium",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9364328/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1032759171554883590&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "KU Leuven",
        "aff_unique_dep": "PMA Division, Robotics Research Group, Core Lab Flanders Make",
        "aff_unique_url": "https://www.kuleuven.be",
        "aff_unique_abbr": "KU Leuven",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Belgium"
    },
    {
        "id": "9341446",
        "title": "Learning the Latent Space of Robot Dynamics for Cutting Interaction Inference",
        "track": "main",
        "status": "Poster",
        "abstract": "Utilization of latent space to capture a lower-dimensional representation of a complex dynamics model is explored in this work. The targeted application is of a robotic manipulator executing a complex environment interaction task, in particular, cutting a wooden object. We train two flavours of Variational Autoencoders-standard and Vector-Quantised-to learn the latent space which is then used to infer certain properties of the cutting operation, such as whether the robot is cutting or not, as well as, material and geometry of the object being cut. The two VAE models are evaluated with reconstruction, prediction and a combined reconstruction/prediction decoders. The results demonstrate the expressiveness of the latent space for robotic interaction inference and the competitive prediction performance against recurrent neural networks.",
        "primary_area": "",
        "author": "Sahand Rezaei-Shoshtari;David Meger;Inna Sharf;Sahand Rezaei-Shoshtari;David Meger;Inna Sharf",
        "authorids": "/37087323637;/37542891800;/37283633500;/37087323637;/37542891800;/37283633500",
        "aff": "Mila Quebec AI Institute, Montreal, Canada; Mila Quebec AI Institute, Montreal, Canada; Department of Mechanical Engineering, McGill University, Montreal, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341446/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10000150467109206847&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Mila Quebec AI Institute;McGill University",
        "aff_unique_dep": "AI Institute;Department of Mechanical Engineering",
        "aff_unique_url": "https://mila.quebec;https://www.mcgill.ca",
        "aff_unique_abbr": "Mila;McGill",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Montreal",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9341285",
        "title": "Learning the sense of touch in simulation: a sim-to-real strategy for vision-based tactile sensing",
        "track": "main",
        "status": "Poster",
        "abstract": "Data-driven approaches to tactile sensing aim to overcome the complexity of accurately modeling contact with soft materials. However, their widespread adoption is impaired by concerns about data efficiency and the capability to generalize when applied to various tasks. This paper focuses on both these aspects with regard to a vision-based tactile sensor, which aims to reconstruct the distribution of the three- dimensional contact forces applied on its soft surface. Accurate models for the soft materials and the camera projection, derived via state-of-the-art techniques in the respective domains, are employed to generate a dataset in simulation. A strategy is proposed to train a tailored deep neural network entirely from the simulation data. The resulting learning architecture is directly transferable across multiple tactile sensors without further training and yields accurate predictions on real data, while showing promising generalization capabilities to unseen contact conditions.",
        "primary_area": "",
        "author": "Carmelo Sferrazza;Thomas Bi;Raffaello D\u2019Andrea;Carmelo Sferrazza;Thomas Bi;Raffaello D\u2019Andrea",
        "authorids": "/37085991609;/37088686362;/38525077800;/37085991609;/37088686362;/38525077800",
        "aff": "Institute for Dynamic Systems and Control, ETH Zurich, Switerland; Institute for Dynamic Systems and Control, ETH Zurich, Switerland; Institute for Dynamic Systems and Control, ETH Zurich, Switerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341285/",
        "gs_citation": 44,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7648316098344478534&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Institute for Dynamic Systems and Control",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Zurich",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9340696",
        "title": "Learning to Collide: An Adaptive Safety-Critical Scenarios Generating Method",
        "track": "main",
        "status": "Poster",
        "abstract": "Long-tail and rare event problems become crucial when autonomous driving algorithms are applied in the real world. For the purpose of evaluating systems in challenging settings, we propose a generative framework to create safety-critical scenarios for evaluating specific task algorithms. We first represent the traffic scenarios with a series of autoregressive building blocks and generate diverse scenarios by sampling from the joint distribution of these blocks. We then train the generative model as an agent (or a generator) to search the risky scenario parameters for a given driving algorithm. We treat the driving algorithm as an environment that returns high reward to the agent when a risky scenario is generated. The whole process is optimized by the policy gradient reinforcement learning method. Through the experiments conducted on several scenarios in the simulation, we demonstrate that the proposed framework generates safety-critical scenarios more efficiently than grid search or human design methods. Another advantage of this method is its adaptiveness to the routes and parameters.",
        "primary_area": "",
        "author": "Wenhao Ding;Baiming Chen;Minjun Xu;Ding Zhao;Wenhao Ding;Baiming Chen;Minjun Xu;Ding Zhao",
        "authorids": "/37088505922;/37088689832;/37088690555;/37085680141;/37088505922;/37088689832;/37088690555;/37085680141",
        "aff": "Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Automotive Engineering, Tsinghua University, Beijing, China; Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340696/",
        "gs_citation": 129,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13511052823333088721&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Carnegie Mellon University;Tsinghua University",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Automotive Engineering",
        "aff_unique_url": "https://www.cmu.edu;https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "CMU;THU",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Pittsburgh;Beijing",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "9341565",
        "title": "Learning to Live Life on the Edge: Online Learning for Data-Efficient Tactile Contour Following",
        "track": "main",
        "status": "Poster",
        "abstract": "Tactile sensing has been used for a variety of robotic exploration and manipulation tasks but a common constraint is a requirement for a large amount of training data. This paper addresses the issue of data-efficiency by proposing a novel method for online learning based on a Gaussian Process Latent Variable Model (GP-LVM), whereby the robot learns from tactile data whilst performing a contour following task thus enabling generalisation to a wide variety of tactile stimuli. The results show that contour following is successful with comparatively little data and is robust to novel stimuli. This work highlights that even with a simple learning architecture there are significant advantages to be gained in efficient and robust task performance by using latent variable models and online learning for tactile sensing tasks. This paves the way for a new generation of robust, fast, and data-efficient tactile systems.",
        "primary_area": "",
        "author": "Elizabeth A. Stone;Nathan F. Lepora;David A.W. Barton;Elizabeth A. Stone;Nathan F. Lepora;David A.W. Barton",
        "authorids": "/37088687837;/37399610200;/37086455530;/37088687837;/37399610200;/37086455530",
        "aff": "EPSRC Centre for Doctoral Training in Future Autonomous and Robotic Systems (FARSCOPE), Bristol Robotics Laboratory; Dept. of Engineering Maths and Bristol Robotics Laboratory, University of Bristol, UK; Dept. of Engineering Maths, University of Bristol, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341565/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8135497112697975195&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Bristol Robotics Laboratory;University of Bristol",
        "aff_unique_dep": "EPSRC Centre for Doctoral Training in Future Autonomous and Robotic Systems (FARSCOPE);Dept. of Engineering Maths and Bristol Robotics Laboratory",
        "aff_unique_url": "https://www.brl.ac.uk;https://www.bristol.ac.uk",
        "aff_unique_abbr": ";UoB",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9340763",
        "title": "Learning to Locomote with Artificial Neural-Network and CPG-based Control in a Soft Snake Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a new locomotion control method for soft robot snakes. Inspired by biological snakes, our control architecture is composed of two key modules: A reinforcement learning (RL) module for achieving adaptive goal-tracking behaviors with changing goals, and a central pattern generator (CPG) system with Matsuoka oscillators for generating stable and diverse locomotion patterns. The two modules are interconnected into a closed-loop system: The RL module, analogizing the locomotion region located in the midbrain of vertebrate animals, regulates the input to the CPG system given state feedback from the robot. The output of the CPG system is then translated into pressure inputs to pneumatic actuators of the soft snake robot. Based on the fact that the oscillation frequency and wave amplitude of the Matsuoka oscillator can be independently controlled under different time scales, we further adapt the option-critic framework to improve the learning performance measured by optimality and data efficiency. The performance of the proposed controller is experimentally validated with both simulated and real soft snake robots.",
        "primary_area": "",
        "author": "Xuan Liu;Renato Gasoto;Ziyi Jiang;Cagdas Onal;Jie Fu;Xuan Liu;Renato Gasoto;Ziyi Jiang;Cagdas Onal;Jie Fu",
        "authorids": "/37086936781;/37086937301;/37088686425;/37303322200;/37085509060;/37086936781;/37086937301;/37088686425;/37303322200;/37085509060",
        "aff": "Robotics Engineering program, Worcester Polytechnic Institute; NVIDIA; Electronic Engineering program, Xidian University; Robotics Engineering program, Worcester Polytechnic Institute; Robotics Engineering program, Worcester Polytechnic Institute",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340763/",
        "gs_citation": 43,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3173050102889728682&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;0;0",
        "aff_unique_norm": "Worcester Polytechnic Institute;NVIDIA Corporation;Xidian University",
        "aff_unique_dep": "Robotics Engineering;;Electronic Engineering",
        "aff_unique_url": "https://www.wpi.edu;https://www.nvidia.com;http://www.xidian.edu.cn/",
        "aff_unique_abbr": "WPI;NVIDIA;Xidian",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Worcester;",
        "aff_country_unique_index": "0;0;1;0;0",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "9341756",
        "title": "Learning to Switch CNNs with Model Agnostic Meta Learning for Fine Precision Visual Servoing",
        "track": "main",
        "status": "Poster",
        "abstract": "Convolutional Neural Networks (CNNs) have been successfully applied for relative camera pose estimation from labeled image-pair data, without requiring any handengineered features, camera intrinsic parameters or depth information. The trained CNN can be utilized for performing pose based visual servo control (PBVS). One of the ways to improve the quality of visual servo output is to improve the accuracy of the CNN for estimating the relative pose estimation. With a given state-of-the-art CNN for relative pose regression, how can we achieve an improved performance for visual servo control? In this paper, we explore switching of CNNs to improve the precision of visual servo control. The idea of switching a CNN is due to the fact that the dataset for training a relative camera pose regressor for visual servo control must contain variations in relative pose ranging from a very small scale to eventually a larger scale. We found that, training two different instances of the CNN, one for large-scale-displacements (LSD) and another for small-scale-displacements (SSD) and switching them during the visual servo execution yields better results than training a single CNN with the combined LSD+SSD data. However, it causes extra storage overhead and switching decision is taken by a manually set threshold which may not be optimal for all the scenes. To eliminate these drawbacks, we propose an efficient switching strategy based on model agnostic meta learning (MAML) algorithm. In this, a single model is trained to learn parameters which are simultaneously good for multiple tasks, namely a binary classification for switching decision, a 6DOF pose regression for LSD data and also a 6DOF pose regression for SSD data. The proposed approach performs far better than the naive approach, while storage and run-time overheads are almost negligible.",
        "primary_area": "",
        "author": "Prem Raj;Vinay P. Namboodiri;L. Behera;Prem Raj;Vinay P. Namboodiri;L. Behera",
        "authorids": "/37088820629;/37427828700;/37352203400;/37088820629;/37427828700;/37352203400",
        "aff": "Indian Institute of Technology, Kanpur; University of Bath; TCS Innovation Lab, Noida",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341756/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7810289575354243678&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Indian Institute of Technology Kanpur;University of Bath;Tata Consultancy Services",
        "aff_unique_dep": ";;Innovation Lab",
        "aff_unique_url": "https://www.iitk.ac.in;https://www.bath.ac.uk;https://www.tcs.com",
        "aff_unique_abbr": "IIT Kanpur;Bath;TCS",
        "aff_campus_unique_index": "0;2",
        "aff_campus_unique": "Kanpur;;Noida",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "India;United Kingdom"
    },
    {
        "id": "9341086",
        "title": "Learning to Take Good Pictures of People with a Robot Photographer",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a robotic system capable of navigating autonomously by following a line and taking good quality pictures of people. When a group of people is detected, the robot rotates towards them and then back to line while continuously taking pictures from different angles. Each picture is processed in the cloud where its quality is estimated in a two-stage algorithm. First, features such as the face orientation and likelihood of facial emotions are input to a fully connected neural network to assign a quality score to each face. Second, a representation is extracted by abstracting faces from the image and it is input to a Convolutional Neural Network (CNN) to classify the quality of the overall picture. We collected a dataset in which a picture was labeled as good quality if subjects are well-positioned in the image and oriented towards the camera with a pleasant expression. Our approach detected the quality of pictures with 78.4% accuracy in this dataset and received a better mean user rating (3.71/5) than a heuristic method that uses photographic composition procedures in a study where 97 human judges rated each picture. Statistical analysis against the state-of-the-art verified the quality of the resulting pictures.",
        "primary_area": "",
        "author": "Rhys Newbury;Akansel Cosgun;Mehmet Koseoglu;Tom Drummond;Rhys Newbury;Akansel Cosgun;Mehmet Koseoglu;Tom Drummond",
        "authorids": "/37088528036;/38230493900;/37072375200;/37341144200;/37088528036;/38230493900;/37072375200;/37341144200",
        "aff": "Australian Centre for Robotic Vision Monash University; Australian Centre for Robotic Vision Monash University; Australian Centre for Robotic Vision University of Melbourne; Australian Centre for Robotic Vision Monash University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341086/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13805854411659685268&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Monash University;University of Melbourne",
        "aff_unique_dep": "Australian Centre for Robotic Vision;Australian Centre for Robotic Vision",
        "aff_unique_url": "https://www.monash.edu;https://www.unimelb.edu.au",
        "aff_unique_abbr": "Monash;UniMelb",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Melbourne",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "9341055",
        "title": "Learning to Use Adaptive Motion Primitives in Search-Based Planning for Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "Heuristic-based graph search algorithms like A* are frequently used to solve motion planning problems in many domains. For most practical applications, it is infeasible and unnecessary to pre-compute the graph representing the whole search space. Instead, these algorithms generate the graph incrementally by applying a fixed set of actions (frequently called motion primitives) to find the successors of every node that they need to evaluate. In many domains, it is possible to define actions (called adaptive motion primitives) that are not pre-computed but generated on the fly. The generation and validation of these adaptive motion primitives is usually quite expensive compared to pre-computed motion primitives. However, they have been shown to drastically speed up search if used judiciously. In prior work, ad hoc techniques like fixed thresholds have been used to limit unsuccessful evaluations of these actions. In this paper, we propose a learning-based approach to make more intelligent decisions about when to evaluate them. We do a thorough empirical evaluation of our model on a 3 degree-of-freedom (dof) motion planning problem for navigation using the Reeds-Shepp path as an adaptive motion primitive. Our experiments show that using our approach in conjunction with search algorithms leads to over 2x speedup in planning time.",
        "primary_area": "",
        "author": "Raghav Sood;Shivam Vats;Maxim Likhachev;Raghav Sood;Shivam Vats;Maxim Likhachev",
        "authorids": "/37088689296;/37088690871;/37309318800;/37088689296;/37088690871;/37309318800",
        "aff": "Robotics Institute, School of Computer Science, Carnegie Mellon University, Pittsburgh, Pennsylvania, USA; Robotics Institute, School of Computer Science, Carnegie Mellon University, Pittsburgh, Pennsylvania, USA; Robotics Institute, School of Computer Science, Carnegie Mellon University, Pittsburgh, Pennsylvania, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341055/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5669102135440727159&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute, School of Computer Science",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341750",
        "title": "Learning visual policies for building 3D shape categories",
        "track": "main",
        "status": "Poster",
        "abstract": "Manipulation and assembly tasks require non-trivial planning of actions depending on the environment and the final goal. Previous work in this domain often assembles particular instances of objects from known sets of primitives. In contrast, we aim to handle varying sets of primitives and to construct different objects of a shape category. Given a single object instance of a category, e.g. an arch, and a binary shape classifier, we learn a visual policy to assemble other instances of the same category. In particular, we propose a disassembly procedure and learn a state policy that discovers new object instances and their assembly plans in state space. We then render simulated states in the observation space and learn a heatmap representation to predict alternative actions from a given input image. To validate our approach, we first demonstrate its efficiency for building object categories in state space. We then show the success of our visual policies for building arches from different primitives. Moreover, we demonstrate (i) the reactive ability of our method to re-assemble objects using additional primitives and (ii) the robust performance of our policy for unseen primitives resembling building blocks used during training. Our visual assembly policies are trained with no real images and reach up to 95% success rate when evaluated on a real robot.",
        "primary_area": "",
        "author": "Alexander Pashevich;Igor Kalevatykh;Ivan Laptev;Cordelia Schmid;Alexander Pashevich;Igor Kalevatykh;Ivan Laptev;Cordelia Schmid",
        "authorids": "/37087324837;/37086727020;/37270740700;/37282990700;/37087324837;/37086727020;/37270740700;/37282990700",
        "aff": "University Grenoble Alpes, Inria, CNRS, Grenoble INP, LJK, Grenoble, France; Inria, \u00c9cole normale sup\u00e9rieure, CNRS, PSL Research University, Paris, France; Inria, \u00c9cole normale sup\u00e9rieure, CNRS, PSL Research University, Paris, France; Inria, \u00c9cole normale sup\u00e9rieure, CNRS, PSL Research University, Paris, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341750/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10488321874706187230&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "University Grenoble Alpes;Inria",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.univ-grenoble-alpes.fr;https://www.inria.fr",
        "aff_unique_abbr": "UGA;Inria",
        "aff_campus_unique_index": "0;1;1;1",
        "aff_campus_unique": "Grenoble;Paris",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9340880",
        "title": "Learning-Based Controller Optimization for Repetitive Robotic Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "Dynamic control for robotic automation tasks is traditionally designed and optimized with a model-based approach, and the performance relies heavily upon accurate system modeling. However, modeling the true dynamics of increasingly complex robotic systems is an extremely challenging task and it often renders the automation system to operate in a non-optimal condition. Notably, many industrial robotic applications involve repetitive motions and constantly generate a large amount of motion data under the non-optimal condition. These motion data contain rich information, and therefore an intelligent automation system should be able to learn from these non-optimal motion data to drive the system to operate optimally in a data-driven manner. In this paper, we propose a learning-based controller optimization algorithm for repetitive robotic tasks. To achieve this, a multi-objective cost function is designed to take into consideration both the trajectory tracking accuracy and smoothness, and then a data-driven approach is developed to estimate the gradient and Hessian based on the motion data for optimization without relying on the dynamic model. Experiments based on a magnetically-levitated nanopositioning system are conducted to demonstrate the effectiveness and practical appeals of the proposed algorithm in repetitive robotic automation tasks.",
        "primary_area": "",
        "author": "Xiaocong Li;Haiyue Zhu;Jun Ma;Tat Joo Teo;Chek Sing Teo;Masayoshi Tomizuka;Tong Heng Lee;Xiaocong Li;Haiyue Zhu;Jun Ma;Tat Joo Teo;Chek Sing Teo;Masayoshi Tomizuka;Tong Heng Lee",
        "authorids": "/37085473002;/37085409877;/37085728817;/37423162600;/37088690008;/37281933000;/37277268600;/37085473002;/37085409877;/37085728817;/37423162600;/37088690008;/37281933000;/37277268600",
        "aff": "Singapore Institute of Manufacturing Technology (SIMTech), Mechatronics Group, Agency for Science, Technology and Research (A*STAR), Singapore; Singapore Institute of Manufacturing Technology (SIMTech), Mechatronics Group, Agency for Science, Technology and Research (A*STAR), Singapore; Department of Mechanical Engineering, University of California, Berkeley, CA, USA; Department of Electrical and Computer Engineering, National University of Singapore, Singapore; Singapore Institute of Manufacturing Technology (SIMTech), Mechatronics Group, Agency for Science, Technology and Research (A*STAR), Singapore; Department of Mechanical Engineering, University of California, Berkeley, CA, USA; Department of Electrical and Computer Engineering, National University of Singapore, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340880/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12081080537028839598&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;1;2;0;1;2",
        "aff_unique_norm": "Singapore Institute of Manufacturing Technology;University of California, Berkeley;National University of Singapore",
        "aff_unique_dep": "Mechatronics Group;Department of Mechanical Engineering;Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.a-star.edu.sg/simtech;https://www.berkeley.edu;https://www.nus.edu.sg",
        "aff_unique_abbr": "SIMTech;UC Berkeley;NUS",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Berkeley",
        "aff_country_unique_index": "0;0;1;0;0;1;0",
        "aff_country_unique": "Singapore;United States"
    },
    {
        "id": "9341415",
        "title": "Learning-Based Distributionally Robust Motion Control with Gaussian Processes",
        "track": "main",
        "status": "Poster",
        "abstract": "Safety is a critical issue in learning-based robotic and autonomous systems as learned information about their environments is often unreliable and inaccurate. In this paper, we propose a risk-aware motion control tool that is robust against errors in learned distributional information about obstacles moving with unknown dynamics. The salient feature of our model predictive control (MPC) method is its capability of limiting the risk of unsafety even when the true distribution deviates from the distribution estimated by Gaussian process (GP) regression, within an ambiguity set. Unfortunately, the distributionally robust MPC problem with GP is intractable because the worst-case risk constraint involves an infinite-dimensional optimization problem over the ambiguity set. To remove the infinite-dimensionality issue, we develop a systematic reformulation approach exploiting modern distributionally robust optimization techniques. The performance and utility of our method are demonstrated through simulations using a nonlinear car-like vehicle model for autonomous driving.",
        "primary_area": "",
        "author": "Astghik Hakobyan;Insoon Yang;Astghik Hakobyan;Insoon Yang",
        "authorids": "/37086926675;/37085833849;/37086926675;/37085833849",
        "aff": "Department of Electrical and Computer Engineering, Automation and Systems Research Institute, Seoul National University, Seoul, South Korea; Department of Electrical and Computer Engineering, Automation and Systems Research Institute, Seoul National University, Seoul, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341415/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2351277286195925791&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Seoul National University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.snu.ac.kr",
        "aff_unique_abbr": "SNU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9341678",
        "title": "Learning-based Optimization Algorithms Combining Force Control Strategies for Peg-in-Hole Assembly",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, an approach for automatic peg-in-hole assembly is proposed. The task is divided into two main steps: searching phase and inserting phase. First, a multilayer perceptron network is designed to address the hole search problem and a hybrid force position controller is introduced to ensure a safe and stable interaction with the external environment. Then, for the inserting phase, a variable impedance controller is adopted based on the fuzzy Q-learning algorithm to yield compliant behavior from the robot during the hole insertion process. This approach is a practical and general approach to solve complex peg-in-hole assembly problems by taking advantage of both learning-based algorithms and force control strategies, which can greatly improve the efficiency and safety of the industrial manufacturing process without identifying the unknown contact model and tuning tedious parameters. Finally, the peg-in-hole experimental results for an industrial robot verified the effectiveness and robustness of the proposed approach.",
        "primary_area": "",
        "author": "Peng Zou;Qiuguo Zhu;Jun Wu;Rong Xiong;Peng Zou;Qiuguo Zhu;Jun Wu;Rong Xiong",
        "authorids": "/37087888021;/38238164400;/170654254534521;/37271511300;/37087888021;/38238164400;/170654254534521;/37271511300",
        "aff": "Institute of Cyber-System and Control, Zhejiang University, Hangzhou, P.R. China; Institute of Cyber-System and Control, Zhejiang University, Hangzhou, P.R. China; Institute of Cyber-System and Control, Zhejiang University, Hangzhou, P.R. China; Institute of Cyber-System and Control, Zhejiang University, Hangzhou, P.R. China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341678/",
        "gs_citation": 34,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6170783467251713287&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Zhejiang University",
        "aff_unique_dep": "Institute of Cyber-System and Control",
        "aff_unique_url": "http://www.zju.edu.cn",
        "aff_unique_abbr": "ZJU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Hangzhou",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9341428",
        "title": "LegoBot: Automated Planning for Coordinated Multi-Robot Assembly of LEGO structures",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-functional cells with cooperating teams of robots promise to be flexible, robust, and efficient and, thus, are a key to future factories. However, their programming is tedious and AI-based planning for multiple robots is computationally expensive. In this work, we present a modular and efficient two-layer planning approach for multi-robot assembly. The goal is to generate the program for coordinated teams of robots from an (enriched) 3D model of the target assembly. Although the approach is both motivated and evaluated with LEGO, which is a challenging variant of blocks world, the approach can be customized to different kinds of assembly domains.",
        "primary_area": "",
        "author": "Ludwig N\u00e4gele;Alwin Hoffmann;Andreas Schierl;Wolfgang Reif;Ludwig N\u00e4gele;Alwin Hoffmann;Andreas Schierl;Wolfgang Reif",
        "authorids": "/37085396598;/37594422100;/38196056000;/37274170600;/37085396598;/37594422100;/38196056000;/37274170600",
        "aff": "Institute for Software & Systems Engineering, University of Augsburg, Augsburg, Germany; Institute for Software & Systems Engineering, University of Augsburg, Augsburg, Germany; Institute for Software & Systems Engineering, University of Augsburg, Augsburg, Germany; Institute for Software & Systems Engineering, University of Augsburg, Augsburg, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341428/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9657632305174785397&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Augsburg",
        "aff_unique_dep": "Institute for Software & Systems Engineering",
        "aff_unique_url": "https://www.uni-augsburg.de",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Augsburg",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9341182",
        "title": "Leveraging Multiple Environments for Learning and Decision Making: a Dismantling Use Case",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning is usually performed by observing real robot executions. Physics-based simulators are a good alternative for providing highly valuable information while avoiding costly and potentially destructive robot executions. We present a novel approach for learning the probabilities of symbolic robot action outcomes. This is done leveraging different environments, such as physics-based simulators, in execution time. To this end, we propose MENID (Multiple Environment Noise Indeterministic Deictic) rules, a novel representation able to cope with the inherent uncertainties present in robotic tasks. MENID rules explicitly represent each possible outcomes of an action, keep memory of the source of the experience, and maintain the probability of success of each outcome. We also introduce an algorithm to distribute actions among environments, based on previous experiences and expected gain. Before using physics-based simulations, we propose a methodology for evaluating different simulation settings and determining the least time-consuming model that could be used while still producing coherent results. We demonstrate the validity of the approach in a dismantling use case, using a simulation with reduced quality as simulated system, and a simulation with full resolution where we add noise to the trajectories and some physical parameters as a representation of the real system.",
        "primary_area": "",
        "author": "Alejandro Su\u00e1rez-Hern\u00e1ndez;Thierry Gaugry;Javier Segovia-Aguas;Antonin Bernardin;Carme Torras;Maud Marchal;Guillem Aleny\u00e0;Alejandro Su\u00e1rez-Hern\u00e1ndez;Thierry Gaugry;Javier Segovia-Aguas;Antonin Bernardin;Carme Torras;Maud Marchal;Guillem Aleny\u00e0",
        "authorids": "/37086577897;/37088686091;/37088690038;/37086232760;/37354713800;/38325252000;/37546459500;/37086577897;/37088686091;/37088690038;/37086232760;/37354713800;/38325252000;/37546459500",
        "aff": "CSIC-UPC, Institut de Rob\u00f2tica i Inform\u00e0tica Industrial, Barcelona, Spain; INSA, IRISA, Univ. Rennes, Inria, France; CSIC-UPC, Institut de Rob\u00f2tica i Inform\u00e0tica Industrial, Barcelona, Spain; INSA, IRISA, Univ. Rennes, Inria, France; CSIC-UPC, Institut de Rob\u00f2tica i Inform\u00e0tica Industrial, Barcelona, Spain; INSA, IRISA, Univ. Rennes, Inria, France; CSIC-UPC, Institut de Rob\u00f2tica i Inform\u00e0tica Industrial, Barcelona, Spain",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341182/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2659350805545058709&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 15,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;0;1;0;1;0",
        "aff_unique_norm": "CSIC-UPC;INSA Rennes",
        "aff_unique_dep": "Institut de Rob\u00f2tica i Inform\u00e0tica Industrial;",
        "aff_unique_url": "https://www.csic.es;https://www.insa-rennes.fr",
        "aff_unique_abbr": ";INSA",
        "aff_campus_unique_index": "0;1;0;1;0;1;0",
        "aff_campus_unique": "Barcelona;Rennes",
        "aff_country_unique_index": "0;1;0;1;0;1;0",
        "aff_country_unique": "Spain;France"
    },
    {
        "id": "9341278",
        "title": "Leveraging Planar Regularities for Point Line Visual-Inertial Odometry",
        "track": "main",
        "status": "Poster",
        "abstract": "With monocular Visual-Inertial Odometry (VIO) system, 3D point cloud and camera motion can be estimated simultaneously. Because pure sparse 3D points provide a structureless representation of the environment, generating 3D mesh from sparse points can further model the environment topology and produce dense mapping. To improve the accuracy of 3D mesh generation and localization, we propose a tightly-coupled monocular VIO system, PLP-VIO, which exploits point features and line features as well as plane regularities. The co-planarity constraints are used to leverage additional structure information for the more accurate estimation of 3D points and spatial lines in state estimator. To detect plane and 3D mesh robustly, we combine both the line features with point features in the detection method. The effectiveness of the proposed method is verified on both synthetic data and public datasets and is compared with other state-of-the-art algorithms.",
        "primary_area": "",
        "author": "Xin Li;Yijia He;Jinlong Lin;Xiao Liu;Xin Li;Yijia He;Jinlong Lin;Xiao Liu",
        "authorids": "/37088526395;/37085847838;/37536885500;/37088690042;/37088526395;/37085847838;/37536885500;/37088690042",
        "aff": "Megvii (Face++) Technology Inc., Beijing, China; Megvii (Face++) Technology Inc., Beijing, China; School of Software & Microelectronics, Peking University, Beijing, China; Megvii (Face++) Technology Inc., Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341278/",
        "gs_citation": 43,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12929985992236414681&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0+1;0+1;2;0+1",
        "aff_unique_norm": "Megvii;Technology Inc.;Peking University",
        "aff_unique_dep": ";;School of Software & Microelectronics",
        "aff_unique_url": "https://www.megvii.com;;http://www.pku.edu.cn",
        "aff_unique_abbr": "Megvii;;PKU",
        "aff_campus_unique_index": ";;1;",
        "aff_campus_unique": ";Beijing",
        "aff_country_unique_index": "0+0;0+0;0;0+0",
        "aff_country_unique": "China"
    },
    {
        "id": "9340699",
        "title": "Leveraging Stereo-Camera Data for Real-Time Dynamic Obstacle Detection and Tracking",
        "track": "main",
        "status": "Poster",
        "abstract": "Dynamic obstacle avoidance is one crucial component for compliant navigation in crowded environments. In this paper we present a system for accurate and reliable detection and tracking of dynamic objects using noisy point cloud data generated by stereo cameras. Our solution is real-time capable and specifically designed for the deployment on computationally-constrained unmanned ground vehicles. The proposed approach identifies individual objects in the robot's surroundings and classifies them as either static or dynamic. The dynamic objects are labeled as either a person or a generic dynamic object. We then estimate their velocities to generate a 2D occupancy grid that is suitable for performing obstacle avoidance. We evaluate the system in indoor and outdoor scenarios and achieve real-time performance on a consumergrade computer. On our test-dataset, we reach a MOTP of 0.07 \u00b1 0.07m, and a MOTA of 85.3% for the detection and tracking of dynamic objects. We reach a precision of 96.9% for the detection of static objects.",
        "primary_area": "",
        "author": "Thomas Eppenberger;Gianluca Cesari;Marcin Dymczyk;Roland Siegwart;Renaud Dub\u00e9;Thomas Eppenberger;Gianluca Cesari;Marcin Dymczyk;Roland Siegwart;Renaud Dub\u00e9",
        "authorids": "/37086124401;/37085709740;/37085425643;/37281398300;/37085782572;/37086124401;/37085709740;/37085425643;/37281398300;/37085782572",
        "aff": "Autonomous Systems Lab (ASL), ETH Zurich, Zurich, Switzerland; Sevensense Robotics AG, Zurich, Switzerland; Sevensense Robotics AG, Zurich, Switzerland; Autonomous Systems Lab (ASL), ETH Zurich, Zurich, Switzerland; Sevensense Robotics AG, Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340699/",
        "gs_citation": 66,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10455093162515655438&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;0;1",
        "aff_unique_norm": "ETH Zurich;Sevensense Robotics AG",
        "aff_unique_dep": "Autonomous Systems Lab (ASL);",
        "aff_unique_url": "https://www.ethz.ch;https://www.sevensense.io",
        "aff_unique_abbr": "ETHZ;",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Zurich",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9341010",
        "title": "LiDAR Iris for Loop-Closure Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, a global descriptor for a LiDAR point cloud, called LiDAR Iris, is proposed for fast and accurate loop-closure detection. A binary signature image can be obtained for each point cloud after several LoG-Gabor filtering and thresholding operations on the LiDAR-Iris image representation. Given two point clouds, their similarities can be calculated as the Hamming distance of two corresponding binary signature images extracted from the two point clouds, respectively. Our LiDAR-Iris method can achieve a pose-invariant loop-closure detection at a descriptor level with the Fourier transform of the LiDAR-Iris representation if assuming a 3D (x,y,yaw) pose space, although our method can generally be applied to a 6D pose space by re-aligning point clouds with an additional IMU sensor. Experimental results on five road-scene sequences demonstrate its excellent performance in loop-closure detection.",
        "primary_area": "",
        "author": "Ying Wang;Zezhou Sun;Cheng-Zhong Xu;Sanjay E. Sarma;Jian Yang;Hui Kong;Ying Wang;Zezhou Sun;Cheng-Zhong Xu;Sanjay E. Sarma;Jian Yang;Hui Kong",
        "authorids": "/37086936216;/37086934230;/37278305300;/37410318300;/37280205100;/37061510500;/37086936216;/37086934230;/37278305300;/37410318300;/37280205100;/37061510500",
        "aff": "School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; Department of Computer Science, University of Macau, Macau; Department of Mechanical Engineering, MIT, Cambridge, MA; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341010/",
        "gs_citation": 237,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4190126959124894390&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;2;0;0",
        "aff_unique_norm": "Nanjing University of Science and Technology;University of Macau;Massachusetts Institute of Technology",
        "aff_unique_dep": "School of Computer Science and Engineering;Department of Computer Science;Department of Mechanical Engineering",
        "aff_unique_url": "http://www.nust.edu.cn;https://www.um.edu.mo;https://web.mit.edu",
        "aff_unique_abbr": "NUST;UM;MIT",
        "aff_campus_unique_index": "0;0;1;2;0;0",
        "aff_campus_unique": "Nanjing;Macau SAR;Cambridge",
        "aff_country_unique_index": "0;0;0;1;0;0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9340837",
        "title": "LiDAR Panoptic Segmentation for Autonomous Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "Truly autonomous driving without the need for human intervention can only be attained when self-driving cars fully understand their surroundings. Most of these vehicles rely on a suite of active and passive sensors. LiDAR sensors are a cornerstone in most of these hardware stacks, and leveraging them as a complement to other passive sensors such as RGB cameras is an enticing goal. Understanding the semantic class of each point in a LiDAR sweep is important, as well as knowing to which instance of that class it belongs to. To this end, we present a novel, single-stage, and real-time capable panoptic segmentation approach using a shared encoder with a semantic and instance decoder. We leverage the geometric information of the LiDAR scan to perform a novel, distance- aware tri-linear upsampling, which allows our approach to use larger output strides than using transpose convolutions leading to substantial savings in computation time. Our experimental evaluation and ablation studies for each module show that combining our geometric and semantic embeddings with our learned, variable instance thresholds, a category-specific loss, and the novel trilinear upsampling module leads to higher panoptic quality. We will release the code of our approach in our LiDAR processing library LiDAR-Bonnetal [27].",
        "primary_area": "",
        "author": "Andres Milioto;Jens Behley;Chris McCool;Cyrill Stachniss;Andres Milioto;Jens Behley;Chris McCool;Cyrill Stachniss",
        "authorids": "/37086400161;/37593243900;/38274733400;/37329668600;/37086400161;/37593243900;/38274733400;/37329668600",
        "aff": "University of Bonn, Germany; University of Bonn, Germany; University of Bonn, Germany; University of Bonn, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340837/",
        "gs_citation": 112,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=485406156416168761&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Bonn",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.uni-bonn.de",
        "aff_unique_abbr": "UBonn",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9341465",
        "title": "LiDAR guided Small obstacle Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "Detecting small obstacles on the road is critical for autonomous driving. In this paper, we present a method to reliably detect such obstacles through a multi-modal framework of sparse LiDAR(VLP-16) and Monocular vision. LiDAR is employed to provide additional context in the form of confidence maps to monocular segmentation networks. We show significant performance gains when the context is fed as an additional input to monocular semantic segmentation frameworks. We further present a new semantic segmentation dataset to the community, comprising of over 3000 image frames with corresponding LiDAR observations. The images come with pixel-wise annotations of three classes off-road, road, and small obstacle. We stress that precise calibration between LiDAR and camera is crucial for this task and thus propose a novel Hausdorff distance based calibration refinement method over extrinsic parameters. As a first benchmark over this dataset, we report our results with 73 % instance detection up to a distance of 50 meters on challenging scenarios. Qualitatively by showcasing accurate segmentation of obstacles less than 15 cms at 50m depth and quantitatively through favourable comparisons vis a vis prior art, we vindicate the method's efficacy. Our project and dataset is hosted at https://small-obstacle-dataset.github.io/.",
        "primary_area": "",
        "author": "Aasheesh Singh;Aditya Kamireddypalli;Vineet Gandhi;K Madhava Krishna;Aasheesh Singh;Aditya Kamireddypalli;Vineet Gandhi;K Madhava Krishna",
        "authorids": "/37088689395;/37088688770;/37075471000;/38201465600;/37088689395;/37088688770;/37075471000;/38201465600",
        "aff": "KCIS, International Institute of Information Technology, Hyderabad, India; KCIS, International Institute of Information Technology, Hyderabad, India; KCIS, International Institute of Information Technology, Hyderabad, India; KCIS, International Institute of Information Technology, Hyderabad, India",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341465/",
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14398769394745070480&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "International Institute of Information Technology",
        "aff_unique_dep": "KCIS",
        "aff_unique_url": "https://iiit Hyderabad.ac.in",
        "aff_unique_abbr": "IIIT Hyderabad",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Hyderabad",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "9341341",
        "title": "LiTAMIN: LiDAR-based Tracking And Mapping by Stabilized ICP for Geometry Approximation with Normal Distributions",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a 3D LiDAR simultaneous localization and mapping (SLAM) method that improves accuracy, robustness, and computational efficiency for an iterative closest point (ICP) algorithm employing a locally approximated geometry with clusters of normal distributions. In comparison with previous normal distribution-based ICP methods, such as normal distribution transformation and generalized ICP, our ICP method is simply stabilized with normalization of the cost function by the Frobenius norm and a regularized covariance matrix. The previous methods are stabilized with principal component analysis, whose computational cost is higher than that of our method. Moreover, our SLAM method can reduce the effect of incorrect loop closure constraints. The experimental results show that our SLAM method has advantages over open source state-of-the-art methods, including LOAM, LeGO-LOAM, and hdl_graph_slam.",
        "primary_area": "",
        "author": "Masashi Yokozuka;Kenji Koide;Shuji Oishi;Atsuhiko Banno;Masashi Yokozuka;Kenji Koide;Shuji Oishi;Atsuhiko Banno",
        "authorids": "/38230409400;/37086179385;/37085895378;/37391486400;/38230409400;/37086179385;/37085895378;/37391486400",
        "aff": "Robot Innovation Research Center, National Institute of Advanced Industrial Science and Technology (AIST), Japan; Robot Innovation Research Center, National Institute of Advanced Industrial Science and Technology (AIST), Japan; Robot Innovation Research Center, National Institute of Advanced Industrial Science and Technology (AIST), Japan; Robot Innovation Research Center, National Institute of Advanced Industrial Science and Technology (AIST), Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341341/",
        "gs_citation": 70,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13367091959968890523&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "National Institute of Advanced Industrial Science and Technology",
        "aff_unique_dep": "Robot Innovation Research Center",
        "aff_unique_url": "https://www.aist.go.jp",
        "aff_unique_abbr": "AIST",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9341097",
        "title": "Lidar Essential Beam Model for Accurate Width Estimation of Thin Poles",
        "track": "main",
        "status": "Poster",
        "abstract": "While Lidar beams are often represented as rays, they actually have finite beam width and this width impacts the measured shape and size of objects in the scene. Here we investigate the effects of beam width on measurements of thin objects such as vertical poles. We propose a model for beam divergence and show how this can explain both object dilation and erosion. We develop a calibration method to estimate beam divergence angle. This calibration method uses one or more vertical poles observed from a Lidar on a moving platform. In addition, we derive an incremental method for using the calibrated beam angle to obtain accurate estimates of thin object diameters, observed from a Lidar on a moving platform. Our method achieves significantly more accurate diameter estimates than is obtained when beam divergence is ignored.",
        "primary_area": "",
        "author": "Yunfei Long;Daniel Morris;Yunfei Long;Daniel Morris",
        "authorids": "/37087233875;/37085641369;/37087233875;/37085641369",
        "aff": "Department of Electrical and Computer Engineering, Michigan State University, East Lansing, MI, USA; Department of Electrical and Computer Engineering, Michigan State University, East Lansing, MI, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341097/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2414683310215361963&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Michigan State University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.msu.edu",
        "aff_unique_abbr": "MSU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "East Lansing",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341516",
        "title": "Lifelong update of semantic maps in dynamic environments",
        "track": "main",
        "status": "Poster",
        "abstract": "A robot understands its world through the raw information it senses from its surroundings. This raw information is not suitable as a shared representation between the robot and its user. A semantic map, containing high-level information that both the robot and user understand, is better suited to be a shared representation. We use the semantic map as the user-facing interface on our fleet of floor-cleaning robots. Jitter in the robot's sensed raw map, dynamic objects in the environment, and exploration of new space by the robot are common challenges for robots. Solving these challenges effectively in the context of semantic maps is key to enabling semantic maps for lifelong mapping. First, as a robot senses new changes and alters its raw map in successive runs, the semantics must be updated appropriately. We update the map using a spatial transfer of semantics. Second, it is important to keep semantics and their relative constraints consistent even in the presence of dynamic objects. Inconsistencies are automatically determined and resolved through the introduction of a map layer of meta-semantics. Finally, a discovery phase allows the semantic map to be updated with new semantics whenever the robot uncovers new information. Deployed commercially on thousands of floor-cleaning robots in real homes, our user-facing semantic maps provide a intuitive user experience through a lifelong mapping robot.",
        "primary_area": "",
        "author": "Manjunath Narayana;Andreas Kolling;Lucio Nardelli;Phil Fong;Manjunath Narayana;Andreas Kolling;Lucio Nardelli;Phil Fong",
        "authorids": "/37088689059;/37541684700;/37088687195;/37088689055;/37088689059;/37541684700;/37088687195;/37088689055",
        "aff": "iRobot Corp., Pasadena, USA; iRobot Corp., Pasadena, USA; iRobot Corp., Pasadena, USA; iRobot Corp., Pasadena, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341516/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15746632966970222436&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "iRobot Corp.",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.irobot.com",
        "aff_unique_abbr": "iRobot",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Pasadena",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341480",
        "title": "Lightweight Multi-robot Communication Protocols for Information Synchronization",
        "track": "main",
        "status": "Poster",
        "abstract": "Communication is one of the most popular and efficient means of multi-robot coordination. Due to potential real-world constraints, such as limited bandwidth and contested scenarios, a communication strategy requiring to send, for example, all n bits of an environment representation might not be feasible in situations where the robots' data exchanges are frequent and large. To this end, we propose and implement lightweight, bandwidth-efficient, robot-to-robot communication protocols inspired by communication complexity results for data synchronization without exchanging the originally required n bits. We have tested our proposed approach both in simulation and with real robots. Simulation results show that the proposed method is computationally fast and enables the robots to synchronize the data (near) accurately while exchanging significantly smaller amounts of information (in the order of log n bits). Real-world experiments with two mobile robots show the practical feasibility of our proposed approach.",
        "primary_area": "",
        "author": "Murtadha Alsayegh;Ayan Dutta;Peter Vanegas;Leonardo Bobadilla;Murtadha Alsayegh;Ayan Dutta;Peter Vanegas;Leonardo Bobadilla",
        "authorids": "/37088686476;/37085783239;/37088690860;/37565890400;/37088686476;/37085783239;/37088690860;/37565890400",
        "aff": "School of Computing and Information Sciences, Florida International University, Miami, FL, USA; School of Computing, University of North Florida, Jacksonville, FL, USA; School of Computing and Information Sciences, Florida International University, Miami, FL, USA; School of Computing and Information Sciences, Florida International University, Miami, FL, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341480/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6235681435337255887&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Florida International University;University of North Florida",
        "aff_unique_dep": "School of Computing and Information Sciences;School of Computing",
        "aff_unique_url": "https://www.fiu.edu;https://www.unf.edu",
        "aff_unique_abbr": "FIU;UNF",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Miami;Jacksonville",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341743",
        "title": "Line Walking and Balancing for Legged Robots with Point Feet",
        "track": "main",
        "status": "Poster",
        "abstract": "The ability of legged systems to traverse highly- constrained environments depends by and large on the performance of their motion and balance controllers. This paper presents a controller that excels in a scenario that most state- of-the-art balance controllers have not yet addressed: line walking, or walking on nearly null support regions. Our approach uses a low-dimensional virtual model (2-DoF) to generate balancing actions through a previously derived four- term balance controller and transforms them to the robot through a derived kinematic mapping. The capabilities of this controller are tested in simulation, where we show the 90kg quadruped robot HyQ crossing a bridge of only 6 cm width (compared to its 4 cm diameter spherical foot), by balancing on two feet at any time while moving along a line. Additional simulations are carried to test the performance of the controller and the effect of external disturbances. Lastly, we present our preliminary experimental results showing HyQ balancing on two legs while being disturbed.",
        "primary_area": "",
        "author": "Carlos Gonzalez;Victor Barasuol;Marco Frigerio;Roy Featherstone;Darwin G. Caldwell;Claudio Semini;Carlos Gonzalez;Victor Barasuol;Marco Frigerio;Roy Featherstone;Darwin G. Caldwell;Claudio Semini",
        "authorids": "/37088690943;/37071707300;/38244576000;/37449492400;/37295680400;/37542633100;/37088690943;/37071707300;/38244576000;/37449492400;/37295680400;/37542633100",
        "aff": "Dynamic Legged Systems Lab, Istituto Italiano di Tecnologia, Genoa, Italy; Dynamic Legged Systems Lab, Istituto Italiano di Tecnologia, Genoa, Italy; Department of Mechanical Engineering, KU Leuven, Belgium; Department of Advanced Robotics, Istituto Italiano di Tecnologia, Genoa, Italy; Department of Advanced Robotics, Istituto Italiano di Tecnologia, Genoa, Italy; Dynamic Legged Systems Lab, Istituto Italiano di Tecnologia, Genoa, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341743/",
        "gs_citation": 41,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9702961443023914957&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;0;0;0",
        "aff_unique_norm": "Istituto Italiano di Tecnologia;KU Leuven",
        "aff_unique_dep": "Dynamic Legged Systems Lab;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.iit.it;https://www.kuleuven.be",
        "aff_unique_abbr": "IIT;KU Leuven",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Genoa;",
        "aff_country_unique_index": "0;0;1;0;0;0",
        "aff_country_unique": "Italy;Belgium"
    },
    {
        "id": "9341032",
        "title": "Linear Distributed Clustering Algorithm for Modular Robots Based Programmable Matter",
        "track": "main",
        "status": "Poster",
        "abstract": "Modular robots are defined as autonomous kinematic machines with variable morphology. They are composed of several thousands or even millions of modules which are able to coordinate in order to behave intelligently. Clustering the modules in modular robots has many benefits, including scalability, energy-efficiency, reducing communication delay and improving the self-configuration processes that focuses on finding a sequence of reconfiguration actions to convert robots from an initial configuration to a goal one. The main idea is to divide the nodes in an initial shape into some clusters based on the final goal shape in order to reduce the time complexity and enhance the self-reconfiguration tasks. In this paper, we propose a robust clustering approach based on a distributed density-cut graph algorithm to divide the networks into a pre-defined number of clusters based on the final goal shape. The result is an algorithm with linear complexity that scales to large modular robot systems. We implement and demonstrate our algorithm on a real Blinky Blocks system and evaluate it in simulation on networks of up to 30,000 modules.",
        "primary_area": "",
        "author": "Jad Bassil;Mohamad Moussa;Abdallah Makhoul;Beno\u00eet Piranda;Julien Bourgeois;Jad Bassil;Mohamad Moussa;Abdallah Makhoul;Beno\u00eet Piranda;Julien Bourgeois",
        "authorids": "/37088688543;/37088686534;/37300200900;/38340189300;/37545876400;/37088688543;/37088686534;/37300200900;/38340189300;/37545876400",
        "aff": "FEMTO-ST Institute, CNRS, Univ. Bourgogne Franche-Comt\u00e9, Montb\u00e9liard, France; FEMTO-ST Institute, CNRS, Univ. Bourgogne Franche-Comt\u00e9, Montb\u00e9liard, France; FEMTO-ST Institute, CNRS, Univ. Bourgogne Franche-Comt\u00e9, Montb\u00e9liard, France; FEMTO-ST Institute, CNRS, Univ. Bourgogne Franche-Comt\u00e9, Montb\u00e9liard, France; FEMTO-ST Institute, CNRS, Univ. Bourgogne Franche-Comt\u00e9, Montb\u00e9liard, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341032/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4979900515954699825&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "FEMTO-ST Institute",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Montb\u00e9liard",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9341272",
        "title": "Lloyd-based Approach for Robots Navigation in Human-shared environments",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a Lloyd-based navigation solution for robots that are required to move in a dynamic environment, where static obstacles (e.g, furnitures, parked cars) and unpredicted moving obstacles (e.g., humans, other robots) have to be detected and avoided on the fly. The algorithm can be computed in real-time and falls in the category of the reactive methods. Moreover, we propose an extension to the multi-agent case that deals with cohesion and cooperation between agents. The goodness of the method is proved through extensive simulations and, for the single agent navigation in human-shared environment, also with experiments on a unicycle-like robot.",
        "primary_area": "",
        "author": "Manuel Boldrer;Luigi Palopoli;Daniele Fontanelli;Manuel Boldrer;Luigi Palopoli;Daniele Fontanelli",
        "authorids": "/37088337162;/37268097200;/37398642200;/37088337162;/37268097200;/37398642200",
        "aff": "Manuel Boldrer; Luigi Palopoli; Daniele Fontanelli",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341272/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8700636896713275064&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "",
        "aff_unique_norm": "",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "9341434",
        "title": "Localization Safety Validation for Autonomous Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a method to validate localization safety for a preplanned trajectory in a given environment. Localization safety is defined as integrity risk and quantified as the probability of an undetected localization failure. Integrity risk differs from previously used metrics in robotics in that it accounts for unmodeled faults and evaluates safety under the worst possible combination of faults. The methodology can be applied prior to mission execution and thus can be employed to evaluate the safety of potential trajectories. The work has been formulated for localization via smoothing, which differs from previously reported integrity monitoring methods that rely on Kalman filtering. Simulation and experimental results are analyzed to show that localization safety is effectively quantified.",
        "primary_area": "",
        "author": "Guillermo Duenas Arana;Osama Abdul Hafez;Mathieu Joerger;Matthew Spenko;Guillermo Duenas Arana;Osama Abdul Hafez;Mathieu Joerger;Matthew Spenko",
        "authorids": "/37086936280;/37086937115;/37540706700;/37329477700;/37086936280;/37086937115;/37540706700;/37329477700",
        "aff": "Mechanical, Materials and Aerospace Department, Illinois Institute of Technology, Chicago, IL, USA; Mechanical, Materials and Aerospace Department, Illinois Institute of Technology, Chicago, IL, USA; Department of Aerospace and Ocean Engineering, Virginia Tech, Blacksburg, VA, USA; Mechanical, Materials and Aerospace Department, Illinois Institute of Technology, Chicago, IL, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341434/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8369559901881514432&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Illinois Institute of Technology;Virginia Tech",
        "aff_unique_dep": "Mechanical, Materials and Aerospace Department;Department of Aerospace and Ocean Engineering",
        "aff_unique_url": "https://www.iit.edu;https://www.vt.edu",
        "aff_unique_abbr": "IIT;VT",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Chicago;Blacksburg",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341427",
        "title": "Localization Uncertainty-driven Adaptive Framework for Controlling Ground Vehicle Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Modern localization techniques allow ground vehicle robots to determine their position with centimeter-level accuracy under nominal conditions, enabling them to utilize fixed maps to navigate their environments. However, when localization measurements become unavailable, the position accuracy will drop and uncertainty will increase. While research and development on localization estimation seeks to reduce the severity of these outages, the question of what actions a robot should take under high localization uncertainty is still unresolved, and can vary on a platform-by-platform and mission-by-mission basis. In this paper, we exploit localization uncertainty measures to adapt system control parameters in real time. Offline, we optimize non-linear activation functions whose control parameters and relevant weights are trained and learned using Evolutionary Algorithm (EA). Subsequently, in real time, we apply the optimized adaptation functions to the controller look-ahead distance and intermediate linear and angular velocity commands, which we identify as the most sensitive to localization error. Evolutionary runs are conducted in which a simulated target vehicle is tasked with following a randomly generated path while minimizing cross-track error, with time varying localization uncertainty added. These runs produce situation-dependent weights for parameters to the adaptation functions, which are transferred to the physical platform, a 1:5-scale autonomous vehicle. In simulation, our system was able to reduce cross-track error, which in certain cases exceeds 250 centimeters on non-adapted systems, to below 15 centimeters on average using EA-derived weights and parameters applied to our proposed adaptation system. Evaluation on the physical platform demonstrates that without the adaptation module in place, the platform is unable to successfully follow the path; with the adaptation module, the platform automatically adjusts its velocity and look-ahead distance to compensa... Show More",
        "primary_area": "",
        "author": "Daniel Kent;Philip K. McKinley;Hayder Radha;Daniel Kent;Philip K. McKinley;Hayder Radha",
        "authorids": "/37313202000;/37268891900;/37269513400;/37313202000;/37268891900;/37269513400",
        "aff": "Department of Electrical and Computer Engineering, Michigan State University, East Lansing, Michigan, USA; Department of Computer Science and Engineering, Michigan State University, East Lansing, Michigan, USA; Department of Electrical and Computer Engineering, Michigan State University, East Lansing, Michigan, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341427/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9768133974291326788&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Michigan State University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.msu.edu",
        "aff_unique_abbr": "MSU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "East Lansing",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341281",
        "title": "Localization and Force-Feedback with Soft Magnetic Stickers for Precise Robot Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Tactile sensors are used in robot manipulation to reduce uncertainty regarding hand-object pose estimation. However, existing sensor technologies tend to be bulky and provide signals that are difficult to interpret into actionable changes. Here, we achieve wireless tactile sensing with soft and conformable magnetic stickers that can be easily placed on objects within the robot's workspace. We embed a small magnetometer within the robot's fingertip that can localize to a magnetic sticker with sub-mm accuracy and enable the robot to pick up objects in the same place, in the same way, every time. In addition, we utilize the soft magnets' ability to exhibit magnetic field changes upon contact forces. We demonstrate the localization and force-feedback features with a 7-DOF Franka arm on deformable tool use and a key insertion task for applications in home, medical, and food robotics. By increasing the reliability of interaction with common tools, this approach to object localization and force sensing can improve robot manipulation performance for delicate, high-precision tasks.",
        "primary_area": "",
        "author": "Tess Hellebrekers;Kevin Zhang;Manuela Veloso;Oliver Kroemer;Carmel Majidi;Tess Hellebrekers;Kevin Zhang;Manuela Veloso;Oliver Kroemer;Carmel Majidi",
        "authorids": "/37085635447;/37086574477;/37274032100;/37593222300;/37589572800;/37085635447;/37086574477;/37274032100;/37593222300;/37589572800",
        "aff": "Robotics Institute, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA; Machine Learning Department, Carnegie Mellon University, Pittsburgh, PA; Robotics Institute, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341281/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17012411017834213190&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute, School of Computer Science",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341630",
        "title": "Localizing Against Drawn Maps via Spline-Based Registration",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a method to facilitate robot navigation relative to sketched maps of human environments. Our main contribution centers around using thin plate splines for registering the robot's LIDAR observation with the hand-drawn maps. Thin plate splines are particularly effective for this task because they are able to handle many of the nonrigid deformations commonly seen in sketches of maps, which render traditional rigid transformations inappropriate. Our proposed approach uses a convolutional neural network to efficiently predict the control points which define the spline transform, from which we then compute the pose of the robot on the hand drawn map for navigation purposes. Our systematic evaluations in simulation using a synthetic dataset and real, hand-drawn sketches show that the proposed spline-based registration approach outperforms baseline methods.",
        "primary_area": "",
        "author": "Kevin Chen;Marynel V\u00e1zquez;Silvio Savarese;Kevin Chen;Marynel V\u00e1zquez;Silvio Savarese",
        "authorids": "/37086183500;/37707834500;/37298502600;/37086183500;/37707834500;/37298502600",
        "aff": "Department of Electrical Engineering and Department of Computer Science, Stanford University, Stanford, CA, USA; Department of Computer Science, Yale University, New Haven, CT, USA; Department of Electrical Engineering and Department of Computer Science, Stanford University, Stanford, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341630/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13280775434475554207&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Stanford University;Yale University",
        "aff_unique_dep": "Department of Electrical Engineering;Department of Computer Science",
        "aff_unique_url": "https://www.stanford.edu;https://www.yale.edu",
        "aff_unique_abbr": "Stanford;Yale",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Stanford;New Haven",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340828",
        "title": "Locomotion Performance of a Configurable Paddle-Wheel Robot over Dry Sandy Terrain",
        "track": "main",
        "status": "Poster",
        "abstract": "To access rough terrain and enhance the mobility in sandy terrain, a configurable paddle-wheel robot was pro-posed. This report addresses the paddle terradynamics, and the experimental verification of the locomotion performance of the robot over dry sandy terrain. To study the interactive forces between the paddle and the media, a terradynamic model is built and verified through experiments. To explore the locomotion performance, an indoor platform that allows the paddle-wheel module to move freely in both horizontal and vertical directions is created. Forward locomotion speed, height variant, and specific resistance are evaluated with different con-figurations. The protruding paddles have successfully reduced the slippage so as to increase the locomotion efficiency in sandy terrain. The performance of the whole robot has also been verified in outdoor sandy terrain.",
        "primary_area": "",
        "author": "Yayi Shen;Shugen Ma;Guoteng Zhang;Syuya Inoue;Yayi Shen;Shugen Ma;Guoteng Zhang;Syuya Inoue",
        "authorids": "/37085385571;/37280187400;/37085406403;/37088686334;/37085385571;/37280187400;/37085406403;/37088686334",
        "aff": "School of Engineering, Tokyo Institute of Technology, Tokyo, Japan; Ritsumeikan Global Innovation Research Organization, Ritsumeikan University, Shiga, Japan; School of Control Science and Engineering, Shandong University, Jinan, China; Ritsumeikan Global Innovation Research Organization, Ritsumeikan University, Shiga, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340828/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:kS1WcA2B5eMJ:scholar.google.com/&scioq=Locomotion+Performance+of+a+Configurable+Paddle-Wheel+Robot+over+Dry+Sandy+Terrain&hl=en&as_sdt=0,5",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;1",
        "aff_unique_norm": "Tokyo Institute of Technology;Ritsumeikan University;Shandong University",
        "aff_unique_dep": "School of Engineering;Global Innovation Research Organization;School of Control Science and Engineering",
        "aff_unique_url": "https://www.titech.ac.jp;https://www.ritsumeikan.ac.jp;http://www.sdu.edu.cn",
        "aff_unique_abbr": "Titech;Ritsumeikan;SDU",
        "aff_campus_unique_index": "0;1;2;1",
        "aff_campus_unique": "Tokyo;Shiga;Jinan",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "Japan;China"
    },
    {
        "id": "9341567",
        "title": "Long-Reach Compact Robotic Arm with LMPA Joints for Monitoring of Reactor Interior",
        "track": "main",
        "status": "Poster",
        "abstract": "To reduce the risk of radiation leakages similar to the incident at the Fukushima Daiichi Nuclear Power Station, robots have been employed to remove fuel debris from reactors. To perform this process safely, it is important to monitor the interior of a reactor. A camera and neutron sensors are attached to the end of a robotic arm to monitor the interior of the reactor. The basic design requirement for the monitoring system is that the arm must be highly extendable and rigid. To achieve this, a novel compact long-reach manipulator with a joint structure built using a low-melting-point alloy (LMPA) is proposed. The LMPA enables switching between the free and locked states of the rotational joints of the manipulator. Herein, we first explain the design of the proposed joint structure and verify whether it has adequate mechanical strength. The required maximum torque to be sustained by the structure was calculated using the cantilever model, and the actual breaking torque was measured by the tensile test. Experimental results confirmed that the joint could withstand approximately 1.86 times the required torque. Finally, the effectiveness of induction heating, which is used to switch between the free and locked states of the joints, was evaluated experimentally. The LMPA arm was installed in the coil of the induction heating module, and the time required to melt LMPA was measured. The experimental results confirmed that the induction heating can change the state of the LMPA joint, and the time required for the melting is approximately 30.3 s. Therefore, the findings of this study show that the proposed system is capable of averting nuclear disasters through the prevention of radiation leakages at nuclear plants.",
        "primary_area": "",
        "author": "Akira Seino;Noriaki Seto;Luis Canete;Takayuki Takahashi;Akira Seino;Noriaki Seto;Luis Canete;Takayuki Takahashi",
        "authorids": "/37089937891;/37088689666;/38541009400;/37349183700;/37089937891;/37088689666;/38541009400;/37349183700",
        "aff": "Faculty of Symbiotic Systems, Fukushima University, Fukushima, Japan; Faculty of Symbiotic Systems, Fukushima University, Fukushima, Japan; Department of Computer Engineering, University of San Carlos, Cebu, Philippines; Faculty of Symbiotic Systems, Fukushima University, Fukushima, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341567/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15074765614517312084&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Fukushima University;University of San Carlos",
        "aff_unique_dep": "Faculty of Symbiotic Systems;Department of Computer Engineering",
        "aff_unique_url": "https://www.fukushima-u.ac.jp;https://www.usc.edu.ph",
        "aff_unique_abbr": "Fukushima U;USC",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Fukushima;Cebu",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "Japan;Philippines"
    },
    {
        "id": "9340901",
        "title": "Long-Run Multi-Robot Planning under Uncertain Action Durations for Persistent Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents an approach for multi-robot long-term planning under uncertainty over the duration of actions. The proposed methodology takes advantage of generalized stochastic Petri nets with rewards (GSPNR) to model multi-robot problems. A GSPNR allows for unified modeling of action selection, uncertainty on the duration of action execution, and for goal specification through the use of transition rewards and rewards per time unit. Our approach relies on the interpretation of the GSPNR model as an equivalent embedded Markov reward automaton (MRA). We then build on a state-of-the-art method to compute the long-run average reward over MRAs, extending it to enable the extraction of the optimal policy. We provide an empirical evaluation of the proposed approach on a simulated multi-robot monitoring problem, evaluating its performance and scalability. The results show that the synthesized policy outperforms a policy obtained from an infinite horizon discounted reward formulation as well as a carefully hand-crafted policy.",
        "primary_area": "",
        "author": "Carlos Azevedo;Bruno Lacerda;Nick Hawes;Pedro Lima;Carlos Azevedo;Bruno Lacerda;Nick Hawes;Pedro Lima",
        "authorids": "/38179839400;/38230417200;/37590842900;/37267147500;/38179839400;/38230417200;/37590842900;/37267147500",
        "aff": "Institute For Systems and Robotics, Instituto Superior T\u00e9cnico, University of Lisbon, Portugal; Oxford Robotics Institute, University of Oxford, UK; Oxford Robotics Institute, University of Oxford, UK; Institute For Systems and Robotics, Instituto Superior T\u00e9cnico, University of Lisbon, Portugal",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340901/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14513290062491802597&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "University of Lisbon;University of Oxford",
        "aff_unique_dep": "Institute For Systems and Robotics, Instituto Superior T\u00e9cnico;Oxford Robotics Institute",
        "aff_unique_url": "https://www IST.utl.pt;https://www.ox.ac.uk",
        "aff_unique_abbr": "IST;Oxford",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Lisbon;Oxford",
        "aff_country_unique_index": "0;1;1;0",
        "aff_country_unique": "Portugal;United Kingdom"
    },
    {
        "id": "9468884",
        "title": "Long-Term Localization With Time Series Map Prediction for Mobile Robots in Dynamic Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "In many applications of mobile robot, the environment is constantly changing. How to use historical information to analysis environmental changes and generate a map corresponding with current environment is important to achieve high-precision localization. Inspired by predictive mechanism of brain, this paper presents a long-term localization approach named ArmMPU (ARMA-based Map Prediction and Update) based on time series modeling and prediction. Autoregressive moving average model (ARMA), a kind of time series modeling method, is employed for environmental map modeling and prediction, then predicted map and filtered observation are fused to fix the prediction error. The simulation and experiment results show that the proposed method improves long-term localization performance in dynamic environments.",
        "primary_area": "",
        "author": "Lisai Wang;Weidong Chen;Jingchuan Wang;Lisai Wang;Weidong Chen;Jingchuan Wang",
        "authorids": "/37088907393;/37279187800;/37539010600;/37088907393;/37279187800;/37539010600",
        "aff": "Department of Automation, Institute of Medical Robotics, Shanghai Jiao Tong University, and Key Laboratory of System Control and Information Processing, Ministry of Education, Shanghai, China; Department of Automation, Institute of Medical Robotics, Shanghai Jiao Tong University, and Key Laboratory of System Control and Information Processing, Ministry of Education, Shanghai, China; Department of Automation, Institute of Medical Robotics, Shanghai Jiao Tong University, and Key Laboratory of System Control and Information Processing, Ministry of Education, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9468884/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16712371752513412982&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Shanghai Jiao Tong University",
        "aff_unique_dep": "Department of Automation",
        "aff_unique_url": "https://www.sjtu.edu.cn",
        "aff_unique_abbr": "SJTU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Shanghai",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9341557",
        "title": "Look and Listen: A Multi-modality Late Fusion Approach to Scene Classification for Autonomous Machines",
        "track": "main",
        "status": "Poster",
        "abstract": "The novelty of this study consists in a multi-modality approach to scene classification, where image and audio complement each other in a process of deep late fusion. The approach is demonstrated on a difficult classification problem, consisting of two synchronised and balanced datasets of 16,000 data objects, encompassing 4.4 hours of video of 8 environments with varying degrees of similarity. We first extract video frames and accompanying audio at one second intervals. The image and the audio datasets are first classified independently, using a fine-tuned VGG16 and an evolutionary optimised deep neural network, with accuracies of 89.27% and 93.72%, respectively. This is followed by late fusion of the two neural networks to enable a higher order function, leading to accuracy of 96.81% in this multi-modality classifier with synchronised video frames and audio clips. The tertiary neural network implemented for late fusion outperforms classical state-of-the-art classifiers by around 3% when the two primary networks are considered as feature generators. We show that situations where a single-modality may be confused by anomalous data points are now corrected through an emerging higher order integration. Prominent examples include a water feature in a city misclassified as a river by the audio classifier alone and a densely crowded street misclassified as a forest by the image classifier alone. Both are examples which are correctly classified by our multi-modality approach.",
        "primary_area": "",
        "author": "Jordan J. Bird;Diego R. Faria;Cristiano Premebida;Anik\u00f3 Ek\u00e1rt;George Vogiatzis;Jordan J. Bird;Diego R. Faria;Cristiano Premebida;Anik\u00f3 Ek\u00e1rt;George Vogiatzis",
        "authorids": "/37086831679;/37590292800;/37589826700;/37086044073;/37418687600;/37086831679;/37590292800;/37589826700;/37086044073;/37418687600",
        "aff": "Aston Robotics Vision and Intelligent Systems (ARVIS) Lab; Aston Robotics Vision and Intelligent Systems (ARVIS) Lab; Department of Electrical and Computer Engineering, Institute of Systems and Robotics, University of Coimbra, Coimbra, Portugal; School of Engineering and Applied Science, Aston University, Birmingham, United Kingdom; Aston Robotics Vision and Intelligent Systems (ARVIS) Lab",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341557/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4589012099702582200&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 14,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "Aston University;University of Coimbra",
        "aff_unique_dep": "Robotics Vision and Intelligent Systems;Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.aston.ac.uk;https://www.uc.pt",
        "aff_unique_abbr": "Aston;UC",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";Coimbra;Birmingham",
        "aff_country_unique_index": "0;0;1;0;0",
        "aff_country_unique": "United Kingdom;Portugal"
    },
    {
        "id": "9341435",
        "title": "Low-viewpoint forest depth dataset for sparse rover swarms",
        "track": "main",
        "status": "Poster",
        "abstract": "Rapid progress in embedded computing hardware increasingly enables on-board image processing on small robots. This development opens the path to replacing costly sensors with sophisticated computer vision techniques. A case in point is the prediction of scene depth information from a monocular camera for autonomous navigation. Motivated by the aim to develop a robot swarm suitable for sensing, monitoring, and search applications in forests, we have collected a set of RGB images and corresponding depth maps. Over 100000 RGB/depth image pairs were recorded with a custom rig from the perspective of a small ground rover moving through a forest. Taken under different weather and lighting conditions, the images include scenes with grass, bushes, standing and fallen trees, tree branches, leaves, and dirt. In addition GPS, IMU, and wheel encoder data were recorded. From the calibrated, synchronized, aligned and timestamped frames about 9700 image-depth map pairs were selected for sharpness and variety. We provide this dataset to the community to fill a need identified in our own research and hope it will accelerate progress in robots navigating the challenging forest environment. This paper describes our custom hardware and methodology to collect the data, subsequent processing and quality of the data, and how to access it.",
        "primary_area": "",
        "author": "Chaoyue Niu;Danesh Tarapore;Klaus-Peter Zauner;Chaoyue Niu;Danesh Tarapore;Klaus-Peter Zauner",
        "authorids": "/37088691101;/37086275308;/37303965600;/37088691101;/37086275308;/37303965600",
        "aff": "School of Electronics and Computer Science, University of Southampton, Southampton, U.K.; School of Electronics and Computer Science, University of Southampton, Southampton, U.K.; School of Electronics and Computer Science, University of Southampton, Southampton, U.K.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341435/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9301795400311300347&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Southampton",
        "aff_unique_dep": "School of Electronics and Computer Science",
        "aff_unique_url": "https://www.southampton.ac.uk",
        "aff_unique_abbr": "Southampton",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Southampton",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9341319",
        "title": "Lyapunov-based Approach to Reactive Step Generation for Push Recovery of Biped Robots via Hybrid Tracking Control of DCM",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper addresses reactive generation of step time and location of biped robots for balance recovery against a severe push. Key idea is to reformulate the balance recovery problem into a tracking problem for \"hybrid\" inverted pendulum model of the biped, where taking a new step implicitly yields a discrete jump of the tracking error. This interpretation offers a Lyapunov-based approach to reactive step generation, which is possibly more intuitive and easier to analyze than large-scaled or nonlinear optimization-based approaches. With the continuous error dynamics for the divergent component of motion (DCM), our strategy for step generation is to decrease the \"post-step\" Lyapunov level for DCM error at each walking cycle, until it eventually becomes smaller than a threshold so that no more footstep needs to be adjusted. We show that implementation of this idea while obeying physical constraints can be done by employing a hybrid tracking controller (together with a reference model) as our reactive step generator, consisting of a simple DCM-based continuous controller and a small-sized quadratic programming-based discrete controller. The validity of the proposed scheme is verified by simulation results.",
        "primary_area": "",
        "author": "Gyunghoon Park;Jung Hoon Kim;Joonhee Jo;Yonghwan Oh;Gyunghoon Park;Jung Hoon Kim;Joonhee Jo;Yonghwan Oh",
        "authorids": "/37085453532;/37090058833;/38242649600;/37289677900;/37085453532;/37090058833;/38242649600;/37289677900",
        "aff": "Center for Intelligent and Interactive Robotics, Korea Institute of Science and Technology, Republic of Korea; Department of Electrical Engineering, Pohang University of Science and Technology (POSTECH), Republic of Korea; Department of HCI & Robotics, University of Science and Technology (UST), Daejeon, Republic of Korea; Center for Intelligent and Interactive Robotics, Korea Institute of Science and Technology, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341319/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11819620574594985022&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "Korea Institute of Science and Technology;Pohang University of Science and Technology;University of Science and Technology",
        "aff_unique_dep": "Center for Intelligent and Interactive Robotics;Department of Electrical Engineering;Department of HCI & Robotics",
        "aff_unique_url": "https://www.kist.re.kr;https://www.postech.ac.kr;https://www.ust.ac.kr",
        "aff_unique_abbr": "KIST;POSTECH;UST",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";Pohang;Daejeon",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9340876",
        "title": "MAPPER: Multi-Agent Path Planning with Evolutionary Reinforcement Learning in Mixed Dynamic Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-agent navigation in dynamic environments is of great industrial value when deploying a large scale fleet of robot to real-world applications. This paper proposes a decentralized partially observable multi-agent path planning with evolutionary reinforcement learning (MAPPER) method to learn an effective local planning policy in mixed dynamic environments. Reinforcement learning-based methods usually suffer performance degradation on long-horizon tasks with goal-conditioned sparse rewards, so we decompose the long-range navigation task into many easier sub-tasks under the guidance of a global planner, which increases agents' performance in large environments. Moreover, most existing multi-agent planning approaches assume either perfect information of the surrounding environment or homogeneity of nearby dynamic agents, which may not hold in practice. Our approach models dynamic obstacles' behavior with an image-based representation and trains a policy in mixed dynamic environments without homogeneity assumption. To ensure multi-agent training stability and performance, we propose an evolutionary training approach that can be easily scaled to large and complex environments. Experiments show that MAPPER is able to achieve higher success rates and more stable performance when exposed to a large number of non-cooperative dynamic obstacles compared with traditional reaction-based planner LRA* and the state-of-the-art learning-based method.",
        "primary_area": "",
        "author": "Zuxin Liu;Baiming Chen;Hongyi Zhou;Guru Koushik;Martial Hebert;Ding Zhao;Zuxin Liu;Baiming Chen;Hongyi Zhou;Guru Koushik;Martial Hebert;Ding Zhao",
        "authorids": "/37086936718;/37088689832;/37088686110;/37088687153;/37271437400;/37085680141;/37086936718;/37088689832;/37088686110;/37088687153;/37271437400;/37085680141",
        "aff": "Department of Mechanical Engineering, Carnegie Mellon University, USA; School of Vehicle and Mobility, Tsinghua University, China; Department of Mechanical Engineering, Carnegie Mellon University, USA; Department of Mechanical Engineering, Carnegie Mellon University, USA; The Robotics Institute, Carnegie Mellon University, USA; Department of Mechanical Engineering, Carnegie Mellon University, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340876/",
        "gs_citation": 140,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=359672279105186975&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University;Tsinghua University",
        "aff_unique_dep": "Department of Mechanical Engineering;School of Vehicle and Mobility",
        "aff_unique_url": "https://www.cmu.edu;https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "CMU;Tsinghua",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0;0;0;0",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "9341639",
        "title": "MHYRO: Modular HYbrid RObot for contact inspection and maintenance in oil & gas plants",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a new concept of robot which is hybrid, including aerial and crawling subsystems and an arm, and also modular with interchangeable crawling subsystems for different pipe configurations, since it has been designed to cover most industrial oil & gas end-users' requirements. The robot has the same ability than aerial robots to reach otherwise inaccessible locations, but makes the inspection more efficient, increasing operation time since crawling requires less energy than flying, and achieving better accuracy in the inspection. It also integrates safety-related characteristics for operating in the potentially explosive atmosphere of a refinery, being able to immediately interrupt the inspection if a hazardous situation is detected and carry the sensible parts such as batteries and electronic devices away as soon as possible. The paper presents the design of this platform in detail and shows the feasibility of the whole system performing indoor experiments.",
        "primary_area": "",
        "author": "A. Lopez-Lora;P.J. Sanchez-Cuevas;A. Suarez;A. Garofano-Soldado;A. Ollero;G. Heredia;A. Lopez-Lora;P.J. Sanchez-Cuevas;A. Suarez;A. Garofano-Soldado;A. Ollero;G. Heredia",
        "authorids": "/37088691324;/37086140269;/37085663079;/37088690998;/37265412000;/37355441300;/37088691324;/37086140269;/37085663079;/37088690998;/37265412000;/37355441300",
        "aff": "The GRVC Robotics Lab of Seville, Spain; The GRVC Robotics Lab of Seville, Spain; The GRVC Robotics Lab of Seville, Spain; The GRVC Robotics Lab of Seville, Spain; The GRVC Robotics Lab of Seville, Spain; The GRVC Robotics Lab of Seville, Spain",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341639/",
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10114177695655778499&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of Seville",
        "aff_unique_dep": "GRVC Robotics Lab",
        "aff_unique_url": "https://www.us.es",
        "aff_unique_abbr": "US",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Seville",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Spain"
    },
    {
        "id": "9341254",
        "title": "MLOD: Awareness of Extrinsic Perturbation in Multi-LiDAR 3D Object Detection for Autonomous Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "Extrinsic perturbation always exists in multiple sensors. In this paper, we focus on the extrinsic uncertainty in multi-LiDAR systems for 3D object detection. We first analyze the influence of extrinsic perturbation on geometric tasks with two basic examples. To minimize the detrimental effect of extrinsic perturbation, we propagate an uncertainty prior on each point of input point clouds, and use this information to boost an approach for 3D geometric tasks. Then we extend our findings to propose a multi-LiDAR 3D object detector called MLOD. MLOD is a two-stage network where the multi-LiDAR information is fused through various schemes in stage one, and the extrinsic perturbation is handled in stage two. We conduct extensive experiments on a real-world dataset, and demonstrate both the accuracy and robustness improvement of MLOD. The code, data and supplementary materials are available at: https://ram-lab.com/file/site/mlod.",
        "primary_area": "",
        "author": "Jianhao Jiao;Peng Yun;Lei Tai;Ming Liu;Jianhao Jiao;Peng Yun;Lei Tai;Ming Liu",
        "authorids": "/37086552343;/37086640426;/37086024718;/37085398677;/37086552343;/37086640426;/37086024718;/37085398677",
        "aff": "Robotics Institute, Intelligent Autonomous Driving Center, The Hong Kong University of Science and Technology, Hong Kong SAR, China; Robotics Institute, Intelligent Autonomous Driving Center, The Hong Kong University of Science and Technology, Hong Kong SAR, China; IAS BU, Huawei Technologies; Robotics Institute, Intelligent Autonomous Driving Center, The Hong Kong University of Science and Technology, Hong Kong SAR, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341254/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12070197984045511373&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "The Hong Kong University of Science and Technology;Huawei Technologies",
        "aff_unique_dep": "Robotics Institute, Intelligent Autonomous Driving Center;IAS BU",
        "aff_unique_url": "https://www.ust.hk;https://www.huawei.com",
        "aff_unique_abbr": "HKUST;Huawei",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Hong Kong SAR;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9341400",
        "title": "MOZARD: Multi-Modal Localization for Autonomous Vehicles in Urban Outdoor Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Visually poor scenarios are one of the main sources of failure in visual localization systems in outdoor environments. To address this challenge, we present MOZARD, a multi-modal localization system for urban outdoor environments using vision and LiDAR. By fusing key point based visual multi-session information with semantic data, an improved localization recall can be achieved across vastly different appearance conditions. In particular we focus on the use of curbstone information because of their broad distribution and reliability within urban environments. We present thorough experimental evaluations on several driving kilometers in challenging urban outdoor environments, analyze the recall and accuracy of our localization system and demonstrate in a case study possible failure cases of each subsystem. We demonstrate that MOZARD is able to bridge scenarios where our previous key point based visual approach, VIZARD, fails, hence yielding an increased recall performance, while a similar localization accuracy of 0.2m is achieved.",
        "primary_area": "",
        "author": "Lukas Schaupp;Patrick Pfreundschuh;Mathias B\u00fcrki;Cesar Cadena;Roland Siegwart;Juan Nieto;Lukas Schaupp;Patrick Pfreundschuh;Mathias B\u00fcrki;Cesar Cadena;Roland Siegwart;Juan Nieto",
        "authorids": "/37089136088;/37088687507;/37085496641;/37593590400;/37281398300;/37085778635;/37089136088;/37088687507;/37085496641;/37593590400;/37281398300;/37085778635",
        "aff": "Autonomous Systems Lab, ETH Z\u00fcrich; ETH Zurich; Sevensense Robotics AG; Autonomous Systems Lab, ETH Z\u00fcrich; Autonomous Systems Lab, ETH Z\u00fcrich; Autonomous Systems Lab, ETH Z\u00fcrich",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341400/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16725645439388215560&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;0;0;0",
        "aff_unique_norm": "ETH Z\u00fcrich;ETH Zurich;Sevensense Robotics",
        "aff_unique_dep": "Autonomous Systems Lab;;",
        "aff_unique_url": "https://www.ethz.ch;https://www.ethz.ch;https://www.sevensense.io",
        "aff_unique_abbr": "ETHZ;ETHZ;Sevensense",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9341225",
        "title": "MPC-Graph: Feedback Motion Planning Using Sparse Sampling Based Neighborhood Graph",
        "track": "main",
        "status": "Poster",
        "abstract": "Robust and safe feedback motion planning and navigation is a critical task for autonomous mobile robotic systems considering the highly dynamic and uncertain nature scenarios of modern applications. For these reasons motion planning and navigation algorithms that have deep roots in feedback control theory has been at the center stage of this domain recently. However, the vast majority of such policies still rely on the idea that a motion planner first generates a set of open-loop possibly time-dependent trajectories, and then a set of feedback control policies track these trajectories in closed-loop while providing some error bounds and guarantees around these trajectories. In contrast to trajectory-based approaches, some researchers developed feedback motion planning strategies based on connected obstacle-free regions, where the task of the local control policies is to drive the robot(s) in between these particular connected regions. In this paper, we propose a feedback motion planning algorithm based on sparse random neighborhood graphs and constrained nonlinear Model Predictive Control (MPC). The algorithm first generates a sparse neighborhood graph as a set of connected simple rectangular regions. After that, during navigation, an MPC based online feedback control policy funnels the robot with nonlinear dynamics from one rectangle to the other in the network, ensuring no constraint violation on state and input variables occurs with guaranteed stability. In this framework, we can drive the robot to any goal location provided that the connected region network covers both the initial condition and the goal position. We demonstrate the effectiveness and validity of the algorithm on simulation studies.",
        "primary_area": "",
        "author": "O. Kaan Karagoz;Simay Atasoy;M. Mert Ankarali;O. Kaan Karagoz;Simay Atasoy;M. Mert Ankarali",
        "authorids": "/38466935100;/37088688787;/37085446564;/38466935100;/37088688787;/37085446564",
        "aff": "Department of Electrical and Electronics Engineering, Middle East Technical University, Ankara, Turkey; Department of Electrical and Electronics Engineering, Middle East Technical University, Ankara, Turkey; Department of Electrical and Electronics Engineering, Middle East Technical University, Ankara, Turkey",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341225/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17514186309208087383&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Middle East Technical University",
        "aff_unique_dep": "Department of Electrical and Electronics Engineering",
        "aff_unique_url": "https://www.metu.edu.tr",
        "aff_unique_abbr": "METU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Ankara",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Turkey"
    },
    {
        "id": "9340767",
        "title": "MSDPN: Monocular Depth Prediction with Partial Laser Observation using Multi-stage Neural Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "In this study, a deep-learning-based multi-stage network architecture called Multi-Stage Depth Prediction Network (MSDPN) is proposed to predict a dense depth map using a 2D LiDAR and a monocular camera. Our proposed network consists of a multi-stage encoder-decoder architecture and Cross Stage Feature Aggregation (CSFA). The proposed multi-stage encoder-decoder architecture alleviates the partial observation problem caused by the characteristics of a 2D LiDAR, and CSFA prevents the multi-stage network from diluting the features and allows the network to learn the interspatial relationship between features better. Previous works use sub-sampled data from the ground truth as an input rather than actual 2D LiDAR data. In contrast, our approach trains the model and conducts experiments with a physically-collected 2D LiDAR dataset. To this end, we acquired our own dataset called KAIST RGBD-scan dataset and validated the effectiveness and the robustness of MSDPN under realistic conditions. As verified experimentally, our network yields promising performance against state-of-the-art methods. Additionally, we analyzed the performance of different input methods and confirmed that the reference depth map is robust in untrained scenarios.",
        "primary_area": "",
        "author": "Hyungtae Lim;Hyeonjae Gil;Hyun Myung;Hyungtae Lim;Hyeonjae Gil;Hyun Myung",
        "authorids": "/37086920570;/37088687020;/37424926900;/37086920570;/37088687020;/37424926900",
        "aff": "School of Electrical Engineering, KI-AI, KI-R, KAIST (Korea Advanced Institute of Science and Technology); undergraduate intern of the laboratory at KAIST, Daejeon, South Korea; School of Electrical Engineering, KI-AI, KI-R, KAIST (Korea Advanced Institute of Science and Technology)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340767/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1937368670262953377&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "KAIST (Korea Advanced Institute of Science and Technology);KAIST",
        "aff_unique_dep": "School of Electrical Engineering;laboratory",
        "aff_unique_url": "https://www.kaist.ac.kr;https://www.kaist.ac.kr",
        "aff_unique_abbr": "KAIST;KAIST",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Daejeon",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9341450",
        "title": "MVLidarNet: Real-Time Multi-Class Scene Understanding for Autonomous Driving Using Multiple Views",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous driving requires the inference of actionable information such as detecting and classifying objects, and determining the drivable space. To this end, we present Multi-View LidarNet (MVLidarNet), a two-stage deep neural network for multi-class object detection and drivable space segmentation using multiple views of a single LiDAR point cloud. The first stage processes the point cloud projected onto a perspective view in order to semantically segment the scene. The second stage then processes the point cloud (along with semantic labels from the first stage) projected onto a bird's eye view, to detect and classify objects. Both stages use an encoder-decoder architecture. We show that our multi-view, multi-stage, multi-class approach is able to detect and classify objects while simultaneously determining the drivable space using a single LiDAR scan as input, in challenging scenes with more than one hundred vehicles and pedestrians at a time. The system operates efficiently at 150 fps on an embedded GPU designed for a self-driving car, including a postprocessing step to maintain identities over time. We show results on both KITTI and a much larger internal dataset, thus demonstrating the method's ability to scale by an order of magnitude.",
        "primary_area": "",
        "author": "Ke Chen;Ryan Oldja;Nikolai Smolyanskiy;Stan Birchfield;Alexander Popov;David Wehr;Ibrahim Eden;Joachim Pehserl;Ke Chen;Ryan Oldja;Nikolai Smolyanskiy;Stan Birchfield;Alexander Popov;David Wehr;Ibrahim Eden;Joachim Pehserl",
        "authorids": "/37088689269;/37088687173;/37086317225;/37371627300;/37088689805;/37088686502;/37088687214;/37088689204;/37088689269;/37088687173;/37086317225;/37371627300;/37088689805;/37088686502;/37088687214;/37088689204",
        "aff": "NVIDIA; NVIDIA; NVIDIA; NVIDIA; NVIDIA; NVIDIA; NVIDIA; NVIDIA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341450/",
        "gs_citation": 39,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6740402253873739726&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;0;0;0",
        "aff_unique_norm": "NVIDIA Corporation",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.nvidia.com",
        "aff_unique_abbr": "NVIDIA",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341379",
        "title": "Magnetically Actuated Pick-and-place Operations of Cellular Micro-rings for High-speed Assembly of Micro-scale Biological Tube",
        "track": "main",
        "status": "Poster",
        "abstract": "Tissue engineering is trying to use modular tissue micro-rings to construct artificial biological microtubes as substitute of autologous tissue tubes to alleviate the shortage of donor sources. However, because of the lack of effective assembly strategies, it is still challenging to achieve high-speed fabrication of biological microtubes with high cell density. In this paper, we proposed a robotic-based magnetic assembly strategy to handle this challenge. We first encapsulated magnetic alginate microfibers into micro-rings formed by cell self-assembly to enhance the controllability. Afterwards, a 3D long-stroke manipulator with visual servoing system was designed to achieve magnetic pick-and-place operations of micro-rings for 3D assembly. Moreover, we developed a mathematical model of the motion of micro-ring in solution environments. Based on visual feedback, we analyzed the feasibility of automatic assembly and following response of micro-rings with the moving magnets, which shows our proposed method has great potential to achieve high-speed bio-assembly. Finally, we successfully assembled multi-micro-rings into a biological microtube with high cell density.",
        "primary_area": "",
        "author": "Yang Wu;Tao Sun;Qing Shi;Huaping Wang;Qiang Huang;Toshio Fukuda;Yang Wu;Tao Sun;Qing Shi;Huaping Wang;Qiang Huang;Toshio Fukuda",
        "authorids": "/37088690846;/38022518100;/37593189500;/37964523300;/37279982900;/37279174500;/37088690846;/38022518100;/37593189500;/37964523300;/37279982900;/37279174500",
        "aff": "Intelligent Robotics Institute, Key Laboratory of Biomimetic Robots and system, Ministry of Education, School of Mechatronical Engineering, Beijing Institute of Technology, Beijing, China; Beijing Advanced Innovation Center for Intelligent Robots and Systems, Beijing Institute of Technology, Beijing, China; Intelligent Robotics Institute, Key Laboratory of Biomimetic Robots and system, Ministry of Education, School of Mechatronical Engineering, Beijing Institute of Technology, Beijing, China; Intelligent Robotics Institute, Key Laboratory of Biomimetic Robots and system, Ministry of Education, School of Mechatronical Engineering, Beijing Institute of Technology, Beijing, China; Intelligent Robotics Institute, Key Laboratory of Biomimetic Robots and system, Ministry of Education, School of Mechatronical Engineering, Beijing Institute of Technology, Beijing, China; Intelligent Robotics Institute, Key Laboratory of Biomimetic Robots and system, Ministry of Education, School of Mechatronical Engineering, Beijing Institute of Technology, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341379/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:ze_n09tU9RwJ:scholar.google.com/&scioq=Magnetically+Actuated+Pick-and-place+Operations+of+Cellular+Micro-rings+for+High-speed+Assembly+of+Micro-scale+Biological+Tube&hl=en&as_sdt=0,33",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Beijing Institute of Technology",
        "aff_unique_dep": "School of Mechatronical Engineering",
        "aff_unique_url": "http://www.bit.edu.cn/",
        "aff_unique_abbr": "BIT",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9341022",
        "title": "Magnetically Programmable Cuboids for 2D Locomotion and Collaborative Assembly",
        "track": "main",
        "status": "Poster",
        "abstract": "The modular assembly and actuation of 3D printed milliscale cuboid robots using a globally applied magnetic field is presented. Cuboids are composed of a rectangular resin shell embedded with two spherical permanent magnets that can independently align with any applied magnetic field. Placing cuboids within short distances of each other allows for modular assembly and disassembly by changing magnetic field direction. Assembled cuboids are demonstrated to stably self-propel under sequential field inputs allowing for both rolling and pivot walking motion modes. Swarms of cuboids could be actuated within the working space and exhibit near identical behavior. Specialized `trap robots' were developed to capture objects, transport them within the working space, and subsequently release the payload in a new location. Cuboids with male and female connectors were developed to exhibit the selective mating between cuboids. The results show that cuboids are a diverse and adaptable platform that has the potential to be scaled down to the sub-millimeter regime for use in medical or small-scale assembly applications.",
        "primary_area": "",
        "author": "Louis William Rogowski;Anuruddha Bhattacharjee;Xiao Zhang;Gokhan Kararsiz;Henry C. Fu;Min Jun Kim;Louis William Rogowski;Anuruddha Bhattacharjee;Xiao Zhang;Gokhan Kararsiz;Henry C. Fu;Min Jun Kim",
        "authorids": "/37086020640;/37086937600;/37086024991;/37086524467;/37088198044;/37088506479;/37086020640;/37086937600;/37086024991;/37086524467;/37088198044;/37088506479",
        "aff": "Southern Methodist University, Dallas, TX, USA; Southern Methodist University, Dallas, TX, USA; Southern Methodist University, Dallas, TX, USA; Southern Methodist University, Dallas, TX, USA; University of Utah, Salt Lake City, UT, USA; Southern Methodist University, Dallas, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341022/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2450823563208062783&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;0",
        "aff_unique_norm": "Southern Methodist University;University of Utah",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.smu.edu;https://www.utah.edu",
        "aff_unique_abbr": "SMU;U of U",
        "aff_campus_unique_index": "0;0;0;0;1;0",
        "aff_campus_unique": "Dallas;Salt Lake City",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341167",
        "title": "Magnetized Cell-robot Propelled by Magnetic Field for Cancer Killing",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a magnetized cell-robot using macrophages as templates, which can be controlled under a strong gradient magnetic field, to approach and kill cancer cells in both vitro and vivo environment. Firstly, we establish a magnetic control system using only four coils which can generate gradient field up to 4.14 T/m utilizing the coupled field contributed by multiple electromagnets acting in concert. Most importantly, the cell-robot which is based on the macrophage is proposed, and can be transported to the vicinity of cancer cells precisely using strong gradient magnetic field. Then the cell-robot will actively phagocytose the cancer cells and eventually kill them, achieving the cancer treatment at the cellular level. It has important significance for guiding accurate targeted therapy in vivo for the future, under the premise of zero harm to the human body.",
        "primary_area": "",
        "author": "Yuguo Dai;Yanmin Feng;Lin Feng;Yuanyuan Chen;Xue Bai;Shuzhang Liang;Li Song;Fumihito Arai;Yuguo Dai;Yanmin Feng;Lin Feng;Yuanyuan Chen;Xue Bai;Shuzhang Liang;Li Song;Fumihito Arai",
        "authorids": "/37086561173;/37087124241;/37403324400;/37088553869;/37088554994;/37087246689;/37087124252;/37274069600;/37086561173;/37087124241;/37403324400;/37088553869;/37088554994;/37087246689;/37087124252;/37274069600",
        "aff": "School of Mechanical Engineering & Automation, Beihang University, Beijing, China; School of Mechanical Engineering & Automation, Beihang University; School of Mechanical Engineering & Automation, Beihang University; School of Mechanical Engineering & Automation, Beihang University; School of Mechanical Engineering & Automation, Beihang University, Beijing, China; School of Mechanical Engineering & Automation, Beihang University, Beijing, China; School of Mechanical Engineering & Automation, Beihang University, Beijing, China; Department of Micro-Nano System Engineering, Nagoya University, Nagoya, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341167/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16511618550989176544&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;0;0;1",
        "aff_unique_norm": "Beihang University;Nagoya University",
        "aff_unique_dep": "School of Mechanical Engineering & Automation;Department of Micro-Nano System Engineering",
        "aff_unique_url": "http://www.buaa.edu.cn;https://www.nagoya-u.ac.jp",
        "aff_unique_abbr": "BUAA;Nagoya U",
        "aff_campus_unique_index": "0;0;0;0;2",
        "aff_campus_unique": "Beijing;;Nagoya",
        "aff_country_unique_index": "0;0;0;0;0;0;0;1",
        "aff_country_unique": "China;Japan"
    },
    {
        "id": "9341575",
        "title": "Maintaining stable grasps during highly dynamic robot trajectories",
        "track": "main",
        "status": "Poster",
        "abstract": "One of the key advantages of robots is the high speeds at which they can operate. In industrial settings, increased velocities can lead to higher throughputs and improved efficiency. Some manipulation tasks might require the robot to perform highly dynamic operations such as shaking, or swinging while grasping an object. These fast movements may produce high accelerations and thus give rise to inertial forces that can cause a grasped object to slip. In this paper a method is proposed to determine the inertial forces that arise on a grasped object during a trajectory, find the instances at which the object might slip, and avoid these slippages by changing the trajectory, namely the orientation of the object. To exemplify the usage of this approach, two grasping tasks are realised: a prehensile and a non-prehensile grasp, and strategies to successfully perform these tasks without changing the overall duration of the trajectory are defined and evaluated.",
        "primary_area": "",
        "author": "Giandomenico Martucci;Joao Bimbo;Domenico Prattichizzo;Monica Malvezzi;Giandomenico Martucci;Joao Bimbo;Domenico Prattichizzo;Monica Malvezzi",
        "authorids": "/37088688529;/38502461400;/37276309600;/37550800700;/37088688529;/38502461400;/37276309600;/37550800700",
        "aff": "Dipartimento di Ingegneria dell\u2019Informazione e Scienze Matematiche, Universit\u00e0 degli Studi di Siena, Siena, Italy; Department of Mechanical Engineering and Materials Science, Yale University, New Haven, USA; Dipartimento di Ingegneria dell\u2019Informazione e Scienze Matematiche, Universit\u00e0 degli Studi di Siena, Siena, Italy; Dipartimento di Ingegneria dell\u2019Informazione e Scienze Matematiche, Universit\u00e0 degli Studi di Siena, Siena, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341575/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=636356931921071098&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Universit\u00e0 degli Studi di Siena;Yale University",
        "aff_unique_dep": "Dipartimento di Ingegneria dell\u2019Informazione e Scienze Matematiche;Department of Mechanical Engineering and Materials Science",
        "aff_unique_url": "https://www.unisi.it;https://www.yale.edu",
        "aff_unique_abbr": ";Yale",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Siena;New Haven",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "Italy;United States"
    },
    {
        "id": "9341063",
        "title": "Majorization Minimization Methods for Distributed Pose Graph Optimization with Convergence Guarantees",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we consider the problem of distributed pose graph optimization (PGO) that has extensive applications in multi-robot simultaneous localization and mapping (SLAM). We propose majorization minimization methods for distributed PGO and show that our methods are guaranteed to converge to first-order critical points under mild conditions. Furthermore, since our methods rely a proximal operator of distributed PGO, the convergence rate can be significantly accelerated with Nesterov's method, and more importantly, the acceleration induces no compromise of convergence guarantees. In addition, we also present accelerated majorization minimization methods for the distributed chordal initialization that have a quadratic convergence, which can be used to compute an initial guess for distributed PGO. The efficacy of this work is validated through applications on a number of 2D and 3D SLAM datasets and comparisons with existing state-of-the- art methods, which indicates that our methods have faster convergence and result in better solutions to distributed PGO.",
        "primary_area": "",
        "author": "Taosha Fan;Todd Murphey;Taosha Fan;Todd Murphey",
        "authorids": "/37085741874;/37329499800;/37085741874;/37329499800",
        "aff": "Department of Mechanical Engineering, Northwestern University, Evanston, IL, USA; Department of Mechanical Engineering, Northwestern University, Evanston, IL, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341063/",
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7001996650063294044&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Northwestern University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.northwestern.edu",
        "aff_unique_abbr": "NU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Evanston",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340940",
        "title": "Making Robots Draw A Vivid Portrait In Two Minutes",
        "track": "main",
        "status": "Poster",
        "abstract": "Significant progress has been made with artistic robots. However, existing robots fail to produce high-quality portraits in a short time. In this work, we present a drawing robot, which can automatically transfer a facial picture to a vivid portrait, and then draw it on paper within two minutes averagely. At the heart of our system is a novel portrait synthesis algorithm based on deep learning. Innovatively, we employ a self-consistency loss, which makes the algorithm capable of generating continuous and smooth brush-strokes. Besides, we propose a componential sparsity constraint to reduce the number of brush-strokes over insignificant areas. We also implement a local sketch synthesis algorithm, and several pre- and post-processing techniques to deal with the background and details. The portrait produced by our algorithm successfully captures individual characteristics by using a sparse set of continuous brush-strokes. Finally, the portrait is converted to a sequence of trajectories and reproduced by a 3-degree-of-freedom robotic arm. The whole portrait drawing robotic system is named AiSketcher. Extensive experiments show that AiSketcher can produce considerably high-quality sketches for a wide range of pictures, including faces in-the-wild and universal images of arbitrary content. To our best knowledge, AiSketcher is the first portrait drawing robot that uses neural style transfer techniques. AiSketcher has attended a quite number of exhibitions and shown remarkable performance under diverse circumstances.",
        "primary_area": "",
        "author": "Fei Gao;Jingjie Zhu;Zeyuan Yu;Peng Li;Tao Wang;Fei Gao;Jingjie Zhu;Zeyuan Yu;Peng Li;Tao Wang",
        "authorids": "/37086057940;/37086597376;/37088687268;/38540280300;/37086286575;/37086057940;/37086597376;/37088687268;/38540280300;/37086286575",
        "aff": "School of Computer Science and Technology, Hangzhou Dianzi University, Hangzhou, China; School of Computer Science and Technology, Hangzhou Dianzi University, Hangzhou, China; Intelligent Computing Research Center, Advanced Institute of Information Technology (AIIT), Peking University, Hangzhou, China; Intelligent Computing Research Center, Advanced Institute of Information Technology (AIIT), Peking University, Hangzhou, China; Department of Computer Science and Technology, Peking University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340940/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11464372947347621035&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;1;1",
        "aff_unique_norm": "Hangzhou Dianzi University;Peking University",
        "aff_unique_dep": "School of Computer Science and Technology;Intelligent Computing Research Center, Advanced Institute of Information Technology (AIIT)",
        "aff_unique_url": "http://www.hdu.edu.cn/;http://www.pku.edu.cn",
        "aff_unique_abbr": "HDU;PKU",
        "aff_campus_unique_index": "0;0;0;0;1",
        "aff_campus_unique": "Hangzhou;Beijing",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9341685",
        "title": "Mapping Thigh Motion to Knee Motion: Implications for Motion Planning of Active Prosthetic Knees",
        "track": "main",
        "status": "Poster",
        "abstract": "One of the main challenges of the active assistive devices is how to estimate the motion of the missing/impaired limbs and joints in line with the remaining limbs. To do so, a motion planner is required. This study proposes a motion planner that can be used for active prosthetic/orthotic knees. The aim is to continuously estimate the knee joint positions based on the thigh motion, using as few inputs as possible. Data from thigh-mounted IMU (thigh acceleration and angle) are used as inputs to estimate knee joint positions as outputs. It is aimed to continuously estimate the outputs as opposed to the state-machine approaches which divide the gait cycles into different sections and require switching rules. The performance of the motion planner is investigated for five walking speeds (0.6, 0.9, 1.2, 1.4 and 1.6 m/s). The strengths and limitations of the motion planer are investigated at different scenarios.",
        "primary_area": "",
        "author": "Mahdy Eslamy;Felix Oswald;Arndt Schilling;Mahdy Eslamy;Felix Oswald;Arndt Schilling",
        "authorids": "/37572096600;/37088404017;/37086155660;/37572096600;/37088404017;/37086155660",
        "aff": "Department for Trauma Surgery, Orthopaedics and Plastic Surgery, Applied Rehabilitation Technology ART Lab, Universit\u00e4tsmedizin G\u00f6ttingen (UMG), G\u00f6ttingen, Germany; Department for Trauma Surgery, Orthopaedics and Plastic Surgery, Applied Rehabilitation Technology ART Lab, Universit\u00e4tsmedizin G\u00f6ttingen (UMG), G\u00f6ttingen, Germany; Department for Trauma Surgery, Orthopaedics and Plastic Surgery, Applied Rehabilitation Technology ART Lab, Universit\u00e4tsmedizin G\u00f6ttingen (UMG), G\u00f6ttingen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341685/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6715641049629153000&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Universit\u00e4tsmedizin G\u00f6ttingen",
        "aff_unique_dep": "Department for Trauma Surgery, Orthopaedics and Plastic Surgery",
        "aff_unique_url": "https://www.unigoettingen.de",
        "aff_unique_abbr": "UMG",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "G\u00f6ttingen",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9341589",
        "title": "Markov Decision Processes with Unknown State Feature Values for Safe Exploration using Gaussian Processes",
        "track": "main",
        "status": "Poster",
        "abstract": "When exploring an unknown environment, a mobile robot must decide where to observe next. It must do this whilst minimising the risk of failure, by only exploring areas that it expects to be safe. In this context, safety refers to the robot remaining in regions where critical environment features (e.g. terrain steepness, radiation levels) are within ranges the robot is able to tolerate. More specifically, we consider a setting where a robot explores an environment modelled with a Markov decision process, subject to bounds on the values of one or more environment features which can only be sensed at runtime. We use a Gaussian process to predict the value of the environment feature in unvisited regions, and propose an estimated Markov decision process, a model that integrates the Gaussian process predictions with the environment model transition probabilities. Building on this model, we propose an exploration algorithm that, contrary to previous approaches, considers probabilistic transitions and explicitly reasons about the uncertainty over the Gaussian process predictions. Furthermore, our approach increases the speed of exploration by selecting locations to visit further away from the currently explored area. We evaluate our approach on a real-world gamma radiation dataset, tackling the challenge of a nuclear material inspection robot exploring an a priori unknown area.",
        "primary_area": "",
        "author": "Matthew Budd;Bruno Lacerda;Paul Duckworth;Andrew West;Barry Lennox;Nick Hawes;Matthew Budd;Bruno Lacerda;Paul Duckworth;Andrew West;Barry Lennox;Nick Hawes",
        "authorids": "/37088687755;/38230417200;/37087188849;/37086575157;/37299751200;/37590842900;/37088687755;/38230417200;/37087188849;/37086575157;/37299751200;/37590842900",
        "aff": "Dept. of Engineering Science, University of Oxford; Dept. of Engineering Science, University of Oxford; Dept. of Engineering Science, University of Oxford; Dept. of Electrical and Electronic Engineering, University of Manchester; Dept. of Electrical and Electronic Engineering, University of Manchester; Dept. of Engineering Science, University of Oxford",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341589/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12672323603235737233&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;1;0",
        "aff_unique_norm": "University of Oxford;University of Manchester",
        "aff_unique_dep": "Dept. of Engineering Science;Dept. of Electrical and Electronic Engineering",
        "aff_unique_url": "https://www.ox.ac.uk;https://www.manchester.ac.uk",
        "aff_unique_abbr": "Oxford;UoM",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Oxford;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9341346",
        "title": "Material Mapping in Unknown Environments using Tapping Sound",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose an autonomous exploration and a tapping mechanism-based material mapping system for a mobile robot in unknown environments. The goal of the proposed system is to integrate simultaneous localization and mapping (SLAM) modules and sound-based material classification to enable a mobile robot to explore an unknown environment autonomously and at the same time identify the various objects and materials in the environment. This creates a material map that localizes the various materials in the environment which has potential applications for search and rescue scenarios. A tapping mechanism and tapping audio signal processing based on machine learning techniques are exploited for a robot to identify the objects and materials. We demonstrate the proposed system through experiments using a mobile robot platform installed with Velodyne LiDAR, a linear solenoid, and microphones in an exploration-like scenario with various materials. Experiment results demonstrate that the proposed system can create useful material maps in unknown environments.",
        "primary_area": "",
        "author": "Shyam Sundar Kannan;Wonse Jo;Ramviyas Parasuraman;Byung-Cheol Min;Shyam Sundar Kannan;Wonse Jo;Ramviyas Parasuraman;Byung-Cheol Min",
        "authorids": "/37087246120;/37085517226;/37085653468;/37711040000;/37087246120;/37085517226;/37085653468;/37711040000",
        "aff": "Department of Computer and Information Technology, SMART Lab, Purdue University, West Lafayette, IN, USA; Department of Computer and Information Technology, SMART Lab, Purdue University, West Lafayette, IN, USA; Department of Computer Science, University of Georgia, Athens, GA, USA; Department of Computer and Information Technology, SMART Lab, Purdue University, West Lafayette, IN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341346/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8637053803959442923&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Purdue University;University of Georgia",
        "aff_unique_dep": "Department of Computer and Information Technology;Department of Computer Science",
        "aff_unique_url": "https://www.purdue.edu;https://www.uga.edu",
        "aff_unique_abbr": "Purdue;UGA",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "West Lafayette;Athens",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340853",
        "title": "Max orientation coverage: efficient path planning to avoid collisions in the CNC milling of 3D objects",
        "track": "main",
        "status": "Poster",
        "abstract": "Most path planning algorithms for covering a complex 3D object ignore physical limitations or constraints on a robot's motion. Adhering to such constraints for a given path can slow down the time to cover the path because the motion may need to be adjusted. This work considers a scenario in computer numerical control (CNC) milling applications, where the robot is a cutting tool that needs to cover the surface of a complex 3D object under the following constraint: for every point on the generated path, the robot must be assigned an accessible orientation to avoid collisions between it and other parts of the object. Our proposed approach, which we call max orientation coverage, employs a two-step optimization scheme. It can improve path efficiency with respect to both the length of the path and the cost of dealing with the collision-avoiding constraints. We evaluate our approach through extensive simulation studies on four CAD benchmarks against a state-of-the-art baseline. We show that our proposed approach can improve the efficiency of the path by 29.7% on average compared with the baseline and the improvement goes up to 46.5% for certain complex objects.",
        "primary_area": "",
        "author": "Xin Chen;Thomas M. Tucker;Thomas R. Kurfess;Richard Vuduc;Liting Hu;Xin Chen;Thomas M. Tucker;Thomas R. Kurfess;Richard Vuduc;Liting Hu",
        "authorids": "/37086044255;/37085859326;/37344313200;/37281842800;/37086040621;/37086044255;/37085859326;/37344313200;/37281842800;/37086040621",
        "aff": "Georgia Institute of Technology, Atlanta, GA, USA; Tucker Innovations Inc., Waxhaw, NC, USA; Georgia Institute of Technology, Atlanta, GA, USA; Georgia Institute of Technology, Atlanta, GA, USA; Florida International University, Miami, FL, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340853/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12760518267294210713&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;2",
        "aff_unique_norm": "Georgia Institute of Technology;Tucker Innovations Inc.;Florida International University",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.gatech.edu;;https://www.fiu.edu",
        "aff_unique_abbr": "Georgia Tech;;FIU",
        "aff_campus_unique_index": "0;0;0;2",
        "aff_campus_unique": "Atlanta;;Miami",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341669",
        "title": "Maximizing BCI Human Feedback using Active Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent advancements in Learning from Human Feedback present an effective way to train robot agents via inputs from non-expert humans, without a need for a specially designed reward function. However, this approach needs a human to be present and attentive during robot learning to provide evaluative feedback. In addition, the amount of feedback needed grows with the level of task difficulty and the quality of human feedback might decrease over time because of fatigue. To overcome these limitations and enable learning more robot tasks with higher complexities, there is a need to maximize the quality of expensive feedback received and reduce the amount of human cognitive involvement required. In this work, we present an approach that uses active learning to smartly choose queries for the human supervisor based on the uncertainty of the robot and effectively reduces the amount of feedback needed to learn a given task. We also use a novel multiple buffer system to improve robustness to feedback noise and guard against catastrophic forgetting as the robot learning evolves. This makes it possible to learn tasks with more complexity using lesser amounts of human feedback compared to previous methods. We demonstrate the utility of our proposed method on a robot arm reaching task where the robot learns to reach a location in 3D without colliding with obstacles. Our approach is able to learn this task faster, with less human feedback and cognitive involvement, compared to previous methods that do not use active learning.",
        "primary_area": "",
        "author": "Zizhao Wang;Junyao Shi;Iretiayo Akinola;Peter Allen;Zizhao Wang;Junyao Shi;Iretiayo Akinola;Peter Allen",
        "authorids": "/37088504428;/37088504956;/37086319261;/37280851400;/37088504428;/37088504956;/37086319261;/37280851400",
        "aff": "Department of Computer Science, Columbia University, New York; Department of Computer Science, Columbia University, New York; Department of Computer Science, Columbia University, New York; Department of Computer Science, Columbia University, New York",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341669/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16948939058997834140&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Columbia University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.columbia.edu",
        "aff_unique_abbr": "Columbia",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "New York",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341290",
        "title": "Mechanical Design and Preliminary Performance Evaluation of a Passive Arm-support Exoskeleton",
        "track": "main",
        "status": "Poster",
        "abstract": "In this study, a passive arm-support exoskeleton was designed to provide assistive aid for manufacturing workers. The exoskeleton has two operating states which can be altered using an unique ratchet bar mechanism with two blocks fixed on the ratchet bar. When the upper arm is elevated to the highest poiont, the pawl module will touch the lower block to allow the pawl separated, so that the arm can move freely without any resistance. When the upper arm is depressed to the lowest point, the pawl module will touch the upper block to make the pawl re-engaged, so that the upper arm can be locked at any vertical position. For purpose to improve the ergonomical property, the structural parameters of the exoskeleton were determined by particle swarm optimization. The designed exoskeleton was simulated in the Adams model to investigate its actual performance. A preliminary experimental study was conducted to evaluate the effectiveness of the designed exoskeleton on alleviating users' physical loads in holding heavy tools; the muscular activities on the shoulder muscle groups involved in the weights bearing, elicited by the surface electromyography (EMG) over the shoulder, were significantly reduced from three healthy subjects who carried hand-held tools. The simulation and experiment results show that the designed exoskeleton could effectively relieve the shoulder burden by transferring the bearing load to the waist, where the motion of the arm was not obstructed.",
        "primary_area": "",
        "author": "Zihao Du;Zefeng Yan;Tiantian Huang;Zhengguang Zhang;Ziquan Zhang;Ou Bai;Qin Huang;Bin Han;Zihao Du;Zefeng Yan;Tiantian Huang;Zhengguang Zhang;Ziquan Zhang;Ou Bai;Qin Huang;Bin Han",
        "authorids": "/37086799049;/37086553792;/37086798183;/37088690736;/37088690747;/37275492700;/37088689739;/37086433182;/37086799049;/37086553792;/37086798183;/37088690736;/37088690747;/37275492700;/37088689739;/37086433182",
        "aff": "State Key Laboratory of Digital Manufacturing Equipment and Technology, School of Mechanical Science and Engineering, Huazhong University of Science and Technology, Wuhan, China; State Key Laboratory of Digital Manufacturing Equipment and Technology, School of Mechanical Science and Engineering, Huazhong University of Science and Technology, Wuhan, China; State Key Laboratory of Digital Manufacturing Equipment and Technology, School of Mechanical Science and Engineering, Huazhong University of Science and Technology, Wuhan, China; State Key Laboratory of Digital Manufacturing Equipment and Technology, School of Mechanical Science and Engineering, Huazhong University of Science and Technology, Wuhan, China; State Key Laboratory of Digital Manufacturing Equipment and Technology, School of Mechanical Science and Engineering, Huazhong University of Science and Technology, Wuhan, China; Human Cyber-Physical Systems Laboratory in the Department of Electrical and Computer Engineering, Florida International University, Florida, USA; Department of Rehabilitation Medicine, Union Hospital, Tongji Medical College, Huazhong University of Science and Technology, Wuhan, China; State Key Laboratory of Digital Manufacturing Equipment and Technology, School of Mechanical Science and Engineering, Huazhong University of Science and Technology, Wuhan, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341290/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14316330399028418196&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;1;0;0",
        "aff_unique_norm": "Huazhong University of Science and Technology;Florida International University",
        "aff_unique_dep": "School of Mechanical Science and Engineering;Department of Electrical and Computer Engineering",
        "aff_unique_url": "http://www.hust.edu.cn;https://www.fiu.edu",
        "aff_unique_abbr": "HUST;FIU",
        "aff_campus_unique_index": "0;0;0;0;0;1;0;0",
        "aff_campus_unique": "Wuhan;Florida",
        "aff_country_unique_index": "0;0;0;0;0;1;0;0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9341282",
        "title": "Meta Learning with Differentiable Closed-form Solver for Fast Video Object Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "Video object segmentation plays a vital role to many robotic tasks, beyond the satisfied accuracy, quickly adapt to the new scenario with very limited annotations and conduct a quick inference are also important. In this paper, we are specifically concerned with the task of fast segmenting all pixels of a target object in all frames, given the annotation mask in the first frame. Even when such annotation is available, this remains a challenging problem because of the changing appearance and shape of the object over time. In this paper, we tackle this task by formulating it as a meta-learning problem, where the base learner grasping the semantic scene understanding for a general type of objects, and the meta learner quickly adapting the appearance of the target object with a few examples. Our proposed meta-learning method uses a closed form optimizer, the so-called \"ridge regression\", which has been shown to be conducive for fast and better training convergence. Moreover, we propose a mechanism, named \"block splitting\", to further speed up the training process as well as to reduce the number of learning parameters. In comparison with the state-of-the art methods, our proposed framework achieves significant boost up in processing speed, while having highly comparable performance compared to the best performing methods on the widely used datasets. Video demo can be found here 1.",
        "primary_area": "",
        "author": "Yu Liu;Lingqiao Liu;Haokui Zhang;Hamid Rezatofighi;Qingsen Yan;Ian Reid;Yu Liu;Lingqiao Liu;Haokui Zhang;Hamid Rezatofighi;Qingsen Yan;Ian Reid",
        "authorids": "/37087116089;/37965569400;/37086294592;/37087010759;/37086594228;/37282640200;/37087116089;/37965569400;/37086294592;/37087010759;/37086594228;/37282640200",
        "aff": "School of Computer Science, The University of Adelaide, North Terrace, SA; School of Computer Science, The University of Adelaide, North Terrace, SA; School of Computer Science and Engineering, Northwestern Polytechnical University, Xi\u2019an, China; School of Computer Science, The University of Adelaide, North Terrace, SA; School of Computer Science, The University of Adelaide, North Terrace, SA; School of Computer Science, The University of Adelaide, North Terrace, SA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341282/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9370725473933768493&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;0;0;0",
        "aff_unique_norm": "The University of Adelaide;Northwestern Polytechnical University",
        "aff_unique_dep": "School of Computer Science;School of Computer Science and Engineering",
        "aff_unique_url": "https://www.adelaide.edu.au;http://www.nwpu.edu.cn",
        "aff_unique_abbr": "Adelaide;NPU",
        "aff_campus_unique_index": "0;0;1;0;0;0",
        "aff_campus_unique": "Adelaide;Xi'an",
        "aff_country_unique_index": "0;0;1;0;0;0",
        "aff_country_unique": "Australia;China"
    },
    {
        "id": "9341737",
        "title": "Meta-Learning Deep Visual Words for Fast Video Object Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "Personal robots and driverless cars need to be able to operate in novel environments and thus quickly and efficiently learn to recognise new object classes. We address this problem by considering the task of video object segmentation. Previous accurate methods for this task finetune a model using the first annotated frame, and/or use additional inputs such as optical flow and complex post-processing. In contrast, we develop a fast, causal algorithm that requires no finetuning, auxiliary inputs or post-processing, and segments a variable number of objects in a single forward-pass. We represent an object with clusters, or \"visual words\", in the embedding space, which correspond to object parts in the image space. This allows us to robustly match to the reference objects throughout the video, because although the global appearance of an object changes as it undergoes occlusions and deformations, the appearance of more local parts may stay consistent. We learn these visual words in an unsupervised manner, using meta-learning to ensure that our training objective matches our inference procedure. We achieve comparable accuracy to finetuning based methods (whilst being 1 to 2 orders of magnitude faster), and state-of-the-art in terms of speed/accuracy trade-offs on four video segmentation datasets. Code is available at https://github.com/harkiratbehl/MetaVOS.",
        "primary_area": "",
        "author": "Harkirat Singh Behl;Mohammad Naja;Anurag Arnab;Philip H.S. Torr;Harkirat Singh Behl;Mohammad Naja;Anurag Arnab;Philip H.S. Torr",
        "authorids": "/37088688146;/37088687820;/37086234780;/37371855600;/37088688146;/37088687820;/37086234780;/37371855600",
        "aff": "University of Oxford; University of Oxford; Google Research; University of Oxford",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341737/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8677123609941813270&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "University of Oxford;Google",
        "aff_unique_dep": ";Google Research",
        "aff_unique_url": "https://www.ox.ac.uk;https://research.google",
        "aff_unique_abbr": "Oxford;Google Research",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Mountain View",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "United Kingdom;United States"
    },
    {
        "id": "9340848",
        "title": "Meta-Reinforcement Learning for Robotic Industrial Insertion Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic insertion tasks are characterized by contact and friction mechanics, making them challenging for conventional feedback control methods due to unmodeled physical effects. Reinforcement learning (RL) is a promising approach for learning control policies in such settings. However, RL can be unsafe during exploration and might require a large amount of real-world training data, which is expensive to collect. In this paper, we study how to use meta-reinforcement learning to solve the bulk of the problem in simulation by solving a family of simulated industrial insertion tasks and then adapt policies quickly in the real world. We demonstrate our approach by training an agent to successfully perform challenging real-world insertion tasks using less than 20 trials of real-world experience.",
        "primary_area": "",
        "author": "Gerrit Schoettler;Ashvin Nair;Juan Aparicio Ojea;Sergey Levine;Eugen Solowjow;Gerrit Schoettler;Ashvin Nair;Juan Aparicio Ojea;Sergey Levine;Eugen Solowjow",
        "authorids": "/37088690341;/37086106243;/37086145951;/37085481973;/37947855300;/37088690341;/37086106243;/37086145951;/37085481973;/37947855300",
        "aff": "Siemens; UC Berkeley; Siemens; UC Berkeley; Siemens",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340848/",
        "gs_citation": 104,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3764727159814627497&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;1;0",
        "aff_unique_norm": "Siemens AG;University of California, Berkeley",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.siemens.com;https://www.berkeley.edu",
        "aff_unique_abbr": "Siemens;UC Berkeley",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Berkeley",
        "aff_country_unique_index": "0;1;0;1;0",
        "aff_country_unique": "Germany;United States"
    },
    {
        "id": "9340972",
        "title": "Microdrone-Equipped Mobile Crawler Robot System, DIR-3, for High-Step Climbing and High-Place Inspection",
        "track": "main",
        "status": "Poster",
        "abstract": "Mobile robots of various types have been proposed for infrastructure inspection and disaster investigation. For such mobile robot applications, accessing the areas is of primary importance for missions. Therefore, various locomotive mechanisms have been studied. We introduce a novel mobile robot system, named DIR-3, combining a crawler robot and a microdrone. By rotating its arm back and forth, DIR-3, a very simple, lightweight crawler robot with a single 360-degree rotatable U-shaped arm, can climb up/down an 18 cm high step, 1.5 times its height.Furthermore, to inspect high places, which is considered difficult for conventional mobile robots, a drone mooring system for mobile robots is presented. The tethered microdrone of DIR-3 can be controlled freely as a flying camera by switching operating modes on the graphic user interface. The drone mooring system has a unique tension-controlled winding mechanism that enables stable landing on DIR-3 from any location in the air, in addition to measurement and estimation of relative positions of the drone. We evaluated the landing capability, position estimation accuracy, and following control of the drone using the winding mechanism. Results show the feasibility of the proposed system for inspection of cracks in a 5 m high concrete wall.",
        "primary_area": "",
        "author": "Yuji OGUSU;Kohji TOMITA;Akiya KAMIMURA;Yuji OGUSU;Kohji TOMITA;Akiya KAMIMURA",
        "authorids": "/37088689241;/37323543400;/37427752900;/37088689241;/37323543400;/37427752900",
        "aff": "National Institute of Advanced Industrial Science and Technology (AIST), Ibaraki, Japan; National Institute of Advanced Industrial Science and Technology (AIST), Ibaraki, Japan; National Institute of Advanced Industrial Science and Technology (AIST), Ibaraki, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340972/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13291588323791086212&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "National Institute of Advanced Industrial Science and Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.aist.go.jp",
        "aff_unique_abbr": "AIST",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Ibaraki",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9340733",
        "title": "Minimally Disruptive Connectivity Enhancement for Resilient Multi-Robot Teams",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we focus on developing algorithms to maintain and enhance the connectivity of a multi-robot system with minimal disruption to the primary tasks that the robots are performing. Such algorithms are useful for collaborating robots to be resilient to reduction in connectivity of the communication graph of the robot team when robots can arrive or leave. These algorithms are also useful in a supervisory control setting when an operator wants to enhance the connectivity of the robot team. In contrast to many existing works that can only maintain the current connectivity of the multi-robot graph, we propose a generalized connectivity control framework that allows for reconfiguration of the multi-robot system to provably satisfy any connectivity demand, while minimally disrupting the execution of their original tasks. In particular, we propose a novel k-Connected Minimum Resilient Graph (k-CMRG) algorithm to compute an optimal k-connectivity graph that minimally constrains the robots' original task-related motion, and employ the Finite-Time Convergence Control Barrier Function (FCBF) to enforce the pairwise robot motion constraints defined by the edges of the graph. The original controllers are minimally modified to drive the robots and form the k-CMRG. We demonstrate the effectiveness of our approach via simulations in the presence of multiple tasks and robot failures.",
        "primary_area": "",
        "author": "Wenhao Luo;Nilanjan Chakraborty;Katia Sycara;Wenhao Luo;Nilanjan Chakraborty;Katia Sycara",
        "authorids": "/37085748889;/37314871600;/37268476900;/37085748889;/37314871600;/37268476900",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Mechanical Engineering, Stony Brook University, Stony Brook, New York, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340733/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5448204422089749831&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Carnegie Mellon University;Stony Brook University",
        "aff_unique_dep": "Robotics Institute;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.cmu.edu;https://www.stonybrook.edu",
        "aff_unique_abbr": "CMU;SBU",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Pittsburgh;Stony Brook",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341104",
        "title": "MixGAIL: Autonomous Driving Using Demonstrations with Mixed Qualities",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we consider autonomous driving of a vehicle using imitation learning. Generative adversarial imitation learning (GAIL) is a widely used algorithm for imitation learning. This algorithm leverages positive demonstrations to imitate the behavior of an expert. In this paper, we propose a novel method, called mixed generative adversarial imitation learning (MixGAIL), which incorporates both of expert demonstrations and negative demonstrations, such as vehicle collisions. To this end, the proposed method utilizes an occupancy measure and a constraint function. The occupancy measure is used to follow expert demonstrations and provides a positive feedback. On the other hand, the constraint function is used for negative demonstrations to assert a negative feedback. Experimental results show that the proposed algorithm converges faster than the other baseline methods. Also, hardware experiments using a real-world RC car shows an outstanding performance and faster convergence compared with existing methods.",
        "primary_area": "",
        "author": "Gunmin Lee;Dohyeong Kim;Wooseok Oh;Kyungjae Lee;Songhwai Oh;Gunmin Lee;Dohyeong Kim;Wooseok Oh;Kyungjae Lee;Songhwai Oh",
        "authorids": "/37087323658;/37088687766;/37088689519;/493655068209513;/37068116900;/37087323658;/37088687766;/37088689519;/493655068209513;/37068116900",
        "aff": "Department of Electrical and Computer Engineering and ASRI, Seoul National University, Seoul, Korea; Department of Electrical and Computer Engineering and ASRI, Seoul National University, Seoul, Korea; Department of Electrical and Computer Engineering and ASRI, Seoul National University, Seoul, Korea; Department of Electrical and Computer Engineering and ASRI, Seoul National University, Seoul, Korea; Department of Electrical and Computer Engineering and ASRI, Seoul National University, Seoul, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341104/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15324368278548590096&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Seoul National University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.snu.ac.kr",
        "aff_unique_abbr": "SNU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9340822",
        "title": "Mixed Reality as a Bidirectional Communication Interface for Human-Robot Interaction",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a decision-theoretic model and robot system that interprets multimodal human communication to disambiguate item references by asking questions via a mixed reality (MR) interface. Existing approaches have either chosen to use physical behaviors, like pointing and eye gaze, or virtual behaviors, like mixed reality. However, there is a gap of research on how MR compares to physical actions for reducing robot uncertainty. We test the hypothesis that virtual deictic gestures are better for human-robot interaction (HRI) than physical behaviors. To test this hypothesis, we propose the Physio-Virtual Deixis Partially Observable Markov Decision Process (PVD-POMDP), which interprets multimodal observations (speech, eye gaze, and pointing gestures) from the human and decides when and how to ask questions (either via physical or virtual deictic gestures) in order to recover from failure states and cope with sensor noise. We conducted a between-subjects user study with 80 participants distributed across three conditions of robot communication: no feedback control, physical feedback, and MR feedback. We tested performance of each condition with objective measures (accuracy, time), as well as evaluated user experience with subjective measures (usability, trust, workload). We found the MR feedback condition was 10% more accurate than the physical condition and a speedup of 160%. We also found that the feedback conditions significantly outperformed the no feedback condition in all subjective metrics.",
        "primary_area": "",
        "author": "Eric Rosen;David Whitney;Michael Fishman;Daniel Ullman;Stefanie Tellex;Eric Rosen;David Whitney;Michael Fishman;Daniel Ullman;Stefanie Tellex",
        "authorids": "/37086078687;/37085522398;/37086936239;/38571208100;/37402794800;/37086078687;/37085522398;/37086936239;/38571208100;/37402794800",
        "aff": "Department of Computer Science, Brown University; Department of Computer Science, Brown University; Department of Computer Science, Brown University; Department of Computer Science, Brown University; Department of Computer Science, Brown University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340822/",
        "gs_citation": 63,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16317024040739303269&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Brown University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.brown.edu",
        "aff_unique_abbr": "Brown",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340795",
        "title": "Mobile Robot Localization under Non-Gaussian noise using Correntropy Similarity Metric",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we study the localization problem under non-Gaussian noise. In particular, we consider systems that can be represented by a state transition and a measurement component. The state transition indicates how the system evolves given a control variable. The measurement component compares, for a given state, the received and predicted measurements. Here we consider a radio based range sensor which is the primary source of non-Gaussian noise in the system. We solve the problem using a MHE (Maximum Horizon Estimator) with a correntropy similarity metric. Given a time window, the MHE seeks the best set of states that explains the system for the received measurements. Moreover, the main advantage of a MHE is that it allows the re-estimation of past states. Additionally, the correntropy is a similarity metric that, given the amount of error in the estimation, behaves as L2, L1 or L0 norms and has been successfully used in many applications under non-Gaussian noise. We evaluate our proposed method using both simulated and real data. The results show that correntropy is able to work well in comparison with other methods in presence of impulsive noise.",
        "primary_area": "",
        "author": "Elerson R. S. Santos;Marcos A. M. Vieira;Gaurav S. Sukhatme;Elerson R. S. Santos;Marcos A. M. Vieira;Gaurav S. Sukhatme",
        "authorids": "/37085400812;/38202816900;/37278934100;/37085400812;/38202816900;/37278934100",
        "aff": "Department of Computer Science, Universidade Federal de Minas Gerais, Belo Horizonte, Brazil; Department of Computer Science, Universidade Federal de Minas Gerais, Belo Horizonte, Brazil; Department of Computer Science, University of Southern California, Los Angeles, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340795/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17745068656306503482&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Universidade Federal de Minas Gerais;University of Southern California",
        "aff_unique_dep": "Department of Computer Science;Department of Computer Science",
        "aff_unique_url": "http://www.ufmg.br;https://www.usc.edu",
        "aff_unique_abbr": "UFMG;USC",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Belo Horizonte;Los Angeles",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "Brazil;United States"
    },
    {
        "id": "9340960",
        "title": "Modality-Buffet for Real-Time Object Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Real-time object detection in videos using lightweight hardware is a crucial component of many robotic tasks. Detectors using different modalities and with varying computational complexities offer different trade-offs. One option is to have a very lightweight model that can predict from all modalities at once for each frame. However, in some situations (e.g., in static scenes) it might be better to have a more complex but more accurate model and to extrapolate from previous predictions for the frames coming in at processing time. We formulate this task as a sequential decision making problem and use reinforcement learning (RL) to generate a policy that decides from the RGB input which detector out of a portfolio of different object detectors to take for the next prediction. The objective of the RL agent is to maximize the accuracy of the predictions per image. We evaluate the approach on the Waymo Open Dataset and show that it exceeds the performance of each single detector.",
        "primary_area": "",
        "author": "Nicolai Dorka;Johannes Meyer;Wolfram Burgard;Nicolai Dorka;Johannes Meyer;Wolfram Burgard",
        "authorids": "/37088690494;/37085504780;/37270485300;/37088690494;/37085504780;/37270485300",
        "aff": "Department of Computer Science, University of Freiburg, Germany; Department of Computer Science, University of Freiburg, Germany; Toyota Research Institute, Los Altos, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340960/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12771566093238888565&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "University of Freiburg;Toyota Research Institute",
        "aff_unique_dep": "Department of Computer Science;",
        "aff_unique_url": "https://www.uni-freiburg.de;https://www.tri.global",
        "aff_unique_abbr": ";TRI",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Los Altos",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "Germany;United States"
    },
    {
        "id": "9341142",
        "title": "Model Identification of a Small Omnidirectional Aquatic Surface Vehicle: a Practical Implementation",
        "track": "main",
        "status": "Poster",
        "abstract": "This work presents a practical method of obtaining a dynamic system model for small omnidirectional aquatic vehicles. The models produced can be used to improve vehicle localisation, aid in the design or tuning of control systems and facilitate the development of simulated environments. The use of a dynamic model for onboard real-time velocity prediction is of particular importance for aquatic vehicles because, unlike ground vehicles, fast and direct measurement of velocity using encoders is not possible. Previous work on model identification of aquatic vehicles has focused on large vessels that are typically underactuated and have low controllability in the sway direction. In this paper it is demonstrated that the procedure for identifying the model coefficients can be performed quickly, without specialist equipment and using only onboard sensors. This is of key importance because the dynamic model coefficients will change with the payload. Two different thrust allocation schemes are tested, one of which is a known method and another is proposed here. Validation tests are performed and the models are shown to be suitable for their intended applications. Significant reduction in model error is demonstrated using the novel thrust allocation method that is designed to avoid deadbands in the thruster responses.",
        "primary_area": "",
        "author": "Keir Groves;Marin Dimitrov;Harriet Peel;Ognjen Marjanovic;Barry Lennox;Keir Groves;Marin Dimitrov;Harriet Peel;Ognjen Marjanovic;Barry Lennox",
        "authorids": "/37086497192;/37088691357;/37088689131;/37415789000;/37299751200;/37086497192;/37088691357;/37088689131;/37415789000;/37299751200",
        "aff": "Department of Electrical and Electronic Engineering, University of Manchester, UK; Department of Electrical and Electronic Engineering, University of Manchester, UK; Department of Electrical and Electronic Engineering, University of Manchester, UK; Department of Electrical and Electronic Engineering, University of Manchester, UK; Department of Electrical and Electronic Engineering, University of Manchester, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341142/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6091804629252256215&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Manchester",
        "aff_unique_dep": "Department of Electrical and Electronic Engineering",
        "aff_unique_url": "https://www.manchester.ac.uk",
        "aff_unique_abbr": "UoM",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9341779",
        "title": "Model Identification of a Soft Robotic Neck",
        "track": "main",
        "status": "Poster",
        "abstract": "Soft links and actuators are nowadays emerging technologies aiming to overcome some problems in robotics such as weight, cost or human interaction. However, the nonlinear nature of their elements can make their characterization challenging and hinder the use of standard control engineering tools. In this paper, we explore different state-of-the-art identification methods for the soft neck, in order to find a reliable plant model. Even though the neck has three Degrees of freedom, in this work we only consider the planar deflection of the link as a starting point for future analysis. Given the nonlinear nature of the soft neck, we consider two identification strategies, i.e., set membership, which is a data driven, nonlinear and nonparametric identification strategy, and Recursive Least Squares at selected linearization points. A neural network identification is also given for comparison purposes. Results show that the explored methods offer a suitable alternative to identify the dynamics of the neck that allows their implementation for simulation and future control.",
        "primary_area": "",
        "author": "Fernando Quevedo;Jorge Mu\u00f1oz Ya\u00f1ez-Barnuevo;Juan A. Castano;Concepci\u00f3n A. Monje;Carlos Balaguer;Fernando Quevedo;Jorge Mu\u00f1oz Ya\u00f1ez-Barnuevo;Juan A. Castano;Concepci\u00f3n A. Monje;Carlos Balaguer",
        "authorids": "/37088687871;/37088690725;/37085482370;/37294059000;/37373092600;/37088687871;/37088690725;/37085482370;/37294059000;/37373092600",
        "aff": "Systems Engineering and Automation Dpt., University Carlos III of Madrid, Leganes, Madrid, Spain; Systems Engineering and Automation Dpt., University Carlos III of Madrid, Leganes, Madrid, Spain; Systems Engineering and Automation Dpt., University Carlos III of Madrid, Leganes, Madrid, Spain; Systems Engineering and Automation Dpt., University Carlos III of Madrid, Leganes, Madrid, Spain; Systems Engineering and Automation Dpt., University Carlos III of Madrid, Leganes, Madrid, Spain",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341779/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7910121859325869387&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University Carlos III of Madrid",
        "aff_unique_dep": "Department of Systems Engineering and Automation",
        "aff_unique_url": "https://www.uc3m.es",
        "aff_unique_abbr": "UC3M",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Leganes",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Spain"
    },
    {
        "id": "9341334",
        "title": "Model Predictive Control for a Tendon-Driven Surgical Robot with Safety Constraints in Kinematics and Dynamics",
        "track": "main",
        "status": "Poster",
        "abstract": "In fields such as minimally invasive surgery, effective control strategies are needed to guarantee safety and accuracy of the surgical task. Mechanical designs and actuation schemes have inevitable limitations such as backlash and joint limits. Moreover, surgical robots need to operate in narrow pathways, which may give rise to additional environmental constraints. Therefore, the control strategies must be capable of satisfying the desired motion trajectories and the imposed constraints. Model Predictive Control (MPC) has proven effective for this purpose, allowing to solve an optimal problem by taking into consideration the evolution of the system states, cost function, and constraints over time. The high nonlinearities in tendon-driven systems, adopted in many surgical robots, are difficult to be modelled analytically. In this work, we use a model learning approach for the dynamics of tendon-driven robots. The dynamic model is then employed to impose constraints on the torques of the robot under consideration and solve an optimal constrained control problem for trajectory tracking by using MPC. To assess the capabilities of the proposed framework, both simulated and real world experiments have been conducted.",
        "primary_area": "",
        "author": "Francesco Cursi;Valerio Modugno;Petar Kormushev;Francesco Cursi;Valerio Modugno;Petar Kormushev",
        "authorids": "/37086145777;/37085819568;/37590229500;/37086145777;/37085819568;/37590229500",
        "aff": "Robot Intelligence Lab, Imperial College London, London, UK; Dipartimento di Ingegneria Informatica, Automatica e Gestionale, Sapienza Universit\u00e0 di Roma, Roma, Italy; Robot Intelligence Lab, Imperial College London, London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341334/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2440664980613074536&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Imperial College London;Sapienza Universit\u00e0 di Roma",
        "aff_unique_dep": "Robot Intelligence Lab;Dipartimento di Ingegneria Informatica, Automatica e Gestionale",
        "aff_unique_url": "https://www.imperial.ac.uk;https://www.uniroma1.it",
        "aff_unique_abbr": "ICL;Sapienza",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "London;Roma",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "United Kingdom;Italy"
    },
    {
        "id": "9341168",
        "title": "Model Predictive Position and Force Trajectory Tracking Control for Robot-Environment Interaction",
        "track": "main",
        "status": "Poster",
        "abstract": "The development of modern sensitive lightweight robots allows the use of robot arms in numerous new scenarios. Especially in applications where interaction between the robot and an object is desired, e.g. in assembly, conventional purely position-controlled robots fail. Former research has focused, among others, on control methods that center on robot-environment interaction. However, these methods often consider only separate scenarios, as for example a pure force control scenario. The present paper aims to address this drawback and proposes a control framework for robot-environment interaction that allows a wide range of possible interaction types. At the same time, the approach can be used for setpoint generation of position-controlled robot arms, where no interaction takes place. Thus, switching between different controller types for specific interaction kinds is not necessary. This versatility is achieved by a model predictive control-based framework which allows trajectory following control of joint or end-effector position as well as of forces for compliant or rigid robot-environment interactions. For this purpose, the robot motion is predicted by an approximated dynamic model and the force behavior by an interaction model. The characteristics of the approach are discussed on the basis of two scenarios on a lightweight robot.",
        "primary_area": "",
        "author": "Tobias Gold;Andreas V\u00f6lz;Knut Graichen;Tobias Gold;Andreas V\u00f6lz;Knut Graichen",
        "authorids": "/37088586158;/37085741923;/37299135100;/37088586158;/37085741923;/37299135100",
        "aff": "Chair of Automatic Control, Friedrich-Alexander-Universit\u00e4t Erlangen-N\u00fcrnberg, Erlangen, Germany; Chair of Automatic Control, Friedrich-Alexander-Universit\u00e4t Erlangen-N\u00fcrnberg, Erlangen, Germany; Chair of Automatic Control, Friedrich-Alexander-Universit\u00e4t Erlangen-N\u00fcrnberg, Erlangen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341168/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12213743414605957508&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Friedrich-Alexander-Universit\u00e4t Erlangen-N\u00fcrnberg",
        "aff_unique_dep": "Chair of Automatic Control",
        "aff_unique_url": "https://www fau.de",
        "aff_unique_abbr": "FAU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Erlangen",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9341345",
        "title": "Model Quality Aware RANSAC: A Robust Camera Motion Estimator",
        "track": "main",
        "status": "Poster",
        "abstract": "Robust estimation of camera motion under the presence of outlier noisevision. Despite existing efforts that focus on detecting motion and scene degeneracies, the best existing approach that builds on Random Consensus Sampling (RANSAC) still has non-negligible failure rate. Since a single failure can lead to the failure of the entire visual simultaneous localization and mapping, it is important to further improve the robust estimation algorithm. We propose a new robust camera motion estimator (RCME) by incorporating two main changes: a model-sample consistency test at the model instantiation step and an inlier set quality test that verifies model-inlier consistency using differential entropy. We have implemented our RCME algorithm and tested it under many public datasets. The results have shown a consistent reduction in failure rate when comparing to the RANSAC-based Gold Standard approach and two recent variations of RANSAC methods.",
        "primary_area": "",
        "author": "Shu-Hao Yeh;Yan Lu;Dezhen Song;Shu-Hao Yeh;Yan Lu;Dezhen Song",
        "authorids": "/37085888480;/37086081354;/37275586600;/37085888480;/37086081354;/37275586600",
        "aff": "CSE Department, Texas A&M University, College Station, TX, USA; Google AR/VR team, Mountain View, CA, USA; CSE Department, Texas A&M University, College Station, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341345/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16577446721675193104&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Texas A&M University;Google",
        "aff_unique_dep": "CSE Department;Google AR/VR team",
        "aff_unique_url": "https://www.tamu.edu;https://www.google.com",
        "aff_unique_abbr": "TAMU;Google",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "College Station;Mountain View",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340794",
        "title": "Model-Based Quality-Diversity Search for Efficient Robot Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Despite recent progress in robot learning, it still remains a challenge to program a robot to deal with open-ended object manipulation tasks. One approach that was recently used to autonomously generate a repertoire of diverse skills is a novelty based Quality-Diversity (QD) algorithm. However, as most evolutionary algorithms, QD suffers from sample- inefficiency and, thus, it is challenging to apply it in real-world scenarios. This paper tackles this problem by integrating a neural network that predicts the behavior of the perturbed parameters into a novelty based QD algorithm. In the proposed Model-based Quality-Diversity search (M-QD), the network is trained concurrently to the repertoire and is used to avoid executing unpromising actions in the novelty search process. Furthermore, it is used to adapt the skills of the final repertoire in order to generalize the skills to different scenarios. Our experiments show that enhancing a QD algorithm with such a forward model improves the sample-efficiency and performance of the evolutionary process and the skill adaptation.",
        "primary_area": "",
        "author": "Leon Keller;Daniel Tanneberg;Svenja Stark;Jan Peters;Leon Keller;Daniel Tanneberg;Svenja Stark;Jan Peters",
        "authorids": "/37088687216;/37086139342;/37086308508;/37533077600;/37088687216;/37086139342;/37086308508;/37533077600",
        "aff": "Intelligent Autonomous Systems, Technische Universit\u00e4t Darmstadt; Intelligent Autonomous Systems, Technische Universit\u00e4t Darmstadt; Intelligent Autonomous Systems, Technische Universit\u00e4t Darmstadt; Robot Learning Group, Max-Planck Institute for Intelligent Systems",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340794/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5149383219528472077&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Technische Universit\u00e4t Darmstadt;Max-Planck Institute for Intelligent Systems",
        "aff_unique_dep": "Intelligent Autonomous Systems;Robot Learning Group",
        "aff_unique_url": "https://www.tu-darmstadt.de;https://www.mpi-is.mpg.de",
        "aff_unique_abbr": "TUD;MPI-IS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9340718",
        "title": "Model-Based Specification of Control Architectures for Compliant Interaction with the Environment",
        "track": "main",
        "status": "Poster",
        "abstract": "In recent years the need for manipulation tasks in the industrial as well as in the service robotics domain that require compliant interaction with the environment rose. Since then, an increased number of publications use a model-driven approach to describe these tasks. High-level tasks and sequences of skills are coordinated to achieve a desired motion for e.g., screwing, polishing, or snap mounting. Even though the awareness of the environment, especially in terms of contact situations, is essential for successful task execution, it is too often neglected or considered insufficiently.In this paper, we present a model-based approach, using domain-specific languages (DSL), that enables the explicit modeling of the environment in terms of contact situations. Decoupling the environment model from the skills, fosters exchangeability and allows the adaptation to different environmental situations. This way, an explicit but non-invasive link is established to the skills, enabling the environment model to provide a context to constrain the execution of the skills. Further, we present a synthesis from the modeled contact situations to a real-time component-based control architecture, which executes the skills subject to the active environmental context. A dual arm yoga mat rolling task is used to show the impact of the environment model on the skill execution.",
        "primary_area": "",
        "author": "Dennis Leroy Wigand;Niels Dehio;Sebastian Wrede;Dennis Leroy Wigand;Niels Dehio;Sebastian Wrede",
        "authorids": "/37085989823;/37085760535;/37269166200;/37085989823;/37085760535;/37269166200",
        "aff": "CoR-Lab, Technical Faculty, Bielefeld University, Germany; CNRS-University of Montpellier, LIRMM, France; CoR-Lab, Technical Faculty, Bielefeld University, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340718/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11266234314968304476&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Bielefeld University;University of Montpellier",
        "aff_unique_dep": "Technical Faculty;LIRMM",
        "aff_unique_url": "https://www.uni-bielefeld.de;https://www.univ-montp.fr",
        "aff_unique_abbr": ";UM",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Germany;France"
    },
    {
        "id": "9340952",
        "title": "Model-Free, Vision-Based Object Identification and Contact Force Estimation with a Hyper-Adaptive Robotic Gripper",
        "track": "main",
        "status": "Poster",
        "abstract": "Robots and intelligent industrial systems that focus on sorting or inspection of products require end-effectors that can grasp and manipulate the objects surrounding them. The capability of such systems largely depends on their ability to efficiently identify the objects and estimate the forces exerted on them. This paper presents an underactuated, compliant, and lightweight hyper-adaptive robot gripper that can efficiently discriminate between different everyday life objects and estimate the contact forces exerted on them during a single grasp, using vision-based techniques. The hyper-adaptive mechanism consists of an array of movable steel rods that get reconfigured conforming to the geometry of the grasped object. The proposed object identification and force estimation techniques are model-free and do not rely on time consuming object exploration. A series of experiments have been carried out to discriminate between 12 different everyday life objects and estimate the forces exerted on a dynamometer. During each grasp, a series of images are captured that detect the reconfiguration of the hyper-adaptive grasping mechanism. These images are then used by an image processing algorithm to extract the required information about the gripper reconfiguration, classify the object grasped using a Random Forests (RF) classifier, and estimate the amount of force being exerted. The employed RF classifier gives a prediction accuracy of 100%, while the results of the force estimation techniques (Neural Networks, Random Forests, and 3rd order polynomial) range from 94.7% to 99.1%.",
        "primary_area": "",
        "author": "Waris Hasan;Lucas Gerez;Minas Liarokapis;Waris Hasan;Lucas Gerez;Minas Liarokapis",
        "authorids": "/37086915385;/37086448935;/38558084100;/37086915385;/37086448935;/38558084100",
        "aff": "New Dexterity research group, The University of Auckland, New Zealand; New Dexterity research group, The University of Auckland, New Zealand; New Dexterity research group, The University of Auckland, New Zealand",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340952/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12587025310554312996&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "The University of Auckland",
        "aff_unique_dep": "New Dexterity research group",
        "aff_unique_url": "https://www.auckland.ac.nz",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "New Zealand"
    },
    {
        "id": "9341763",
        "title": "Modeling Cable-Driven Joint Dynamics and Friction: a Bond-Graph Approach",
        "track": "main",
        "status": "Poster",
        "abstract": "Cable-driven joints proved to be an effective solution in a wide variety of applications ranging from medical to industrial fields where light structures, interaction with unstructured and constrained environments and precise motion are required. These requirements are achieved by moving the actuators from joints to the robot chassis. Despite these positive properties a cable-driven robotic arm requires a complex cable routing within the entire structure to transmit motion to all joints. The main effect of this routing is a friction phenomenon which reduces the accuracy of the motion of the robotic device. In this paper a bond-graph approach is presented to model a family of cable-driven joints including a novel friction model that can be easily implemented into a control algorithm to compensate the friction forces induced by the rope sliding into bushings.",
        "primary_area": "",
        "author": "Daniele Ludovico;Paolo Guardiani;Alessandro Pistone;Jinoh Lee;Ferdinando Cannella;Darwin G. Caldwell;Carlo Canali;Daniele Ludovico;Paolo Guardiani;Alessandro Pistone;Jinoh Lee;Ferdinando Cannella;Darwin G. Caldwell;Carlo Canali",
        "authorids": "/37086292940;/37087594606;/37088487808;/37085391573;/37681701900;/37295680400;/37085376637;/37086292940;/37087594606;/37088487808;/37085391573;/37681701900;/37295680400;/37085376637",
        "aff": "Advanced Robotics Department, Istituto Italiano di Tecnologia (IIT), Genoa, GE, Italy; Advanced Robotics Department, Istituto Italiano di Tecnologia (IIT), Genoa, GE, Italy; Advanced Robotics Department, Istituto Italiano di Tecnologia (IIT), Genoa, GE, Italy; Advanced Robotics Department, Istituto Italiano di Tecnologia (IIT), Genoa, Italy; Advanced Robotics Department, Istituto Italiano di Tecnologia (IIT), Genoa, GE, Italy; Advanced Robotics Department, Istituto Italiano di Tecnologia (IIT), Genoa, GE, Italy; Advanced Robotics Department, Istituto Italiano di Tecnologia (IIT), Genoa, GE, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341763/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9871456279674926697&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Istituto Italiano di Tecnologia",
        "aff_unique_dep": "Advanced Robotics Department",
        "aff_unique_url": "https://www.iit.it",
        "aff_unique_abbr": "IIT",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Genoa",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9340892",
        "title": "Modeling a Social Placement Cost to Extend Navigation Among Movable Obstacles (NAMO) Algorithms",
        "track": "main",
        "status": "Poster",
        "abstract": "Current Navigation Among Movable Obstacles (NAMO) algorithms focus on finding a path for the robot that only optimizes the displacement cost of navigating and moving obstacles out of its way. However, in a human environment, this focus may lead the robot to leave the space in a socially inappropriate state that may hamper human activity (i.e. by blocking access to doors, corridors, rooms or objects of interest). In this paper, we tackle this problem of \"Social Placement Choice\" by building a social occupation costmap, built using only geometrical information. We present how existing NAMO algorithms can be extended by exploiting this new cost map. Then, we show the effectiveness of this approach with simulations, and provide additional evaluation criteria to assess the social acceptability of plans.",
        "primary_area": "",
        "author": "Benoit Renault;Jacques Saraydaryan;and Olivier Simonin;Benoit Renault;Jacques Saraydaryan;and Olivier Simonin",
        "authorids": "/37088689324;/37946218600;/37088688222;/37088689324;/37946218600;/37088688222",
        "aff": "CITI Lab and INRIA Chroma Team, INSA Lyon; CITI Lab and INRIA Chroma Team, CPE Lyon; CITI Lab and INRIA Chroma Team, INSA Lyon",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340892/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8415671265454277640&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "INSA Lyon;CPE Lyon",
        "aff_unique_dep": "CITI Lab;CITI Lab",
        "aff_unique_url": "https://www.insa-lyon.fr;https://www.cpe-lyon.fr",
        "aff_unique_abbr": "INSA Lyon;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9341339",
        "title": "Modeling and Control of a Hybrid Wheeled Jumping Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we study a wheeled robot with a prismatic extension joint. This allows the robot to build up momentum to perform jumps over obstacles and to swing up to the upright position after the loss of balance. We propose a template model for the class of such two-wheeled jumping robots. This model can be considered as the simplest wheeled-legged system. We provide an analytical derivation of the system dynamics which we use inside a model predictive controller (MPC). We study the behavior of the model and demonstrate highly dynamic motions such as swing-up and jumping. Furthermore, these motions are discovered through optimization from first principles. We evaluate the controller on a variety of tasks and uneven terrains in a simulator.",
        "primary_area": "",
        "author": "Traiko Dinev;Songyan Xin;Wolfgang Merkt;Vladimir Ivan;Sethu Vijayakumar;Traiko Dinev;Songyan Xin;Wolfgang Merkt;Vladimir Ivan;Sethu Vijayakumar",
        "authorids": "/37088686256;/37086099765;/37086118415;/37085552022;/37295595500;/37088686256;/37086099765;/37086118415;/37085552022;/37295595500",
        "aff": "School of Informatics, The University of Edinburgh, Edinburgh, UK; Shenzhen Institute for Artificial Intelligence and Robotics for Society (AIRS), CUHK-SZ, China; Oxford Robotics Institute, University of Oxford, UK; School of Informatics, The University of Edinburgh, Edinburgh, UK; School of Informatics, The University of Edinburgh, Edinburgh, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341339/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=867664873516465431&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;0;0",
        "aff_unique_norm": "The University of Edinburgh;Shenzhen Institute for Artificial Intelligence and Robotics for Society;University of Oxford",
        "aff_unique_dep": "School of Informatics;Artificial Intelligence and Robotics for Society;Oxford Robotics Institute",
        "aff_unique_url": "https://www.ed.ac.uk;;https://www.ox.ac.uk",
        "aff_unique_abbr": "Edinburgh;AIRS;Oxford",
        "aff_campus_unique_index": "0;1;2;0;0",
        "aff_campus_unique": "Edinburgh;Shenzhen;Oxford",
        "aff_country_unique_index": "0;1;0;0;0",
        "aff_country_unique": "United Kingdom;China"
    },
    {
        "id": "9341133",
        "title": "Modelling social interaction between humans and service robots in large public spaces",
        "track": "main",
        "status": "Poster",
        "abstract": "With the advent of service robots in public places (e.g., in airports and shopping malls), understanding socio-psychological interactions between humans and robots is of paramount importance. On the one hand, traditional robotic navigation systems consider humans and robots as moving obstacles and focus on the problem of real-time collision avoidance in Human-Robot Interaction (HRI) using mathematical models. On the other hand, the behavior of a robot has been determined with respect to a human. Parameters for human-human interaction have been assumed and applied to interactions involving robots. One major limitation is the lack of sufficient data for calibration and validation procedures. This paper models, calibrates and validates the socio-psychological interaction of the human in HRIs among crowds. The mathematical model is an extension of the Social Force Model for crowd modelling. The proposed model is calibrated and validated using open source datasets (including uninstructed human trajectories) from the Asia and Pacific Trade Center shopping mall in Osaka (Japan).In summary, the results of the calibration and validation on the multiple HRIs encountered in the datasets show that humans react to a service robot to a higher extend within a larger distance compared to the interaction range towards another human. This microscopic model, calibration and validation framework can be used to simulate HRI between service robots and humans, predict humans' behavior, conduct comparative studies, and gain insights into safe and comfortable human-robot relationships from the human's perspective.",
        "primary_area": "",
        "author": "Bani Anvari;Helge A Wurdemann;Bani Anvari;Helge A Wurdemann",
        "authorids": "/37086351668;/37991827000;/37086351668;/37991827000",
        "aff": "Department of Civil, Environmental and Geomatic Engineering, Centre for Transport Studies, University College London, UK; Department of Mechanical Engineering, University College London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341133/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5167540372640788182&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University College London",
        "aff_unique_dep": "Department of Civil, Environmental and Geomatic Engineering",
        "aff_unique_url": "https://www.ucl.ac.uk",
        "aff_unique_abbr": "UCL",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "London;",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9341690",
        "title": "Monocular Camera Localization in Prior LiDAR Maps with 2D-3D Line Correspondences",
        "track": "main",
        "status": "Poster",
        "abstract": "Light-weight camera localization in existing maps is essential for vision-based navigation. Currently, visual and visual-inertial odometry (VO&VIO) techniques are well-developed for state estimation but with inevitable accumulated drifts and pose jumps upon loop closure. To overcome these problems, we propose an efficient monocular camera localization method in prior LiDAR maps using direct 2D-3D line correspondences. To handle the appearance differences and modality gaps between LiDAR point clouds and images, geometric 3D lines are extracted offline from LiDAR maps while robust 2D lines are extracted online from video sequences. With the pose prediction from VIO, we can efficiently obtain coarse 2D-3D line correspondences. Then the camera poses and 2D-3D correspondences are iteratively optimized by minimizing the projection error of correspondences and rejecting outliers. Experimental results on the EurocMav dataset and our collected dataset demonstrate that the proposed method can efficiently estimate camera poses without accumulated drifts or pose jumps in structured environments.",
        "primary_area": "",
        "author": "Huai Yu;Weikun Zhen;Wen Yang;Ji Zhang;Sebastian Scherer;Huai Yu;Weikun Zhen;Wen Yang;Ji Zhang;Sebastian Scherer",
        "authorids": "/37086223088;/37086162020;/37290575900;/38541910000;/37584159000;/37086223088;/37086162020;/37290575900;/38541910000;/37584159000",
        "aff": "Electronic Information School, Wuhan University, Wuhan, China; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Electronic Information School, Wuhan University, Wuhan, China; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341690/",
        "gs_citation": 64,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7459953649678935545&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;1;1",
        "aff_unique_norm": "Wuhan University;Carnegie Mellon University",
        "aff_unique_dep": "Electronic Information School;Robotics Institute",
        "aff_unique_url": "http://www.whu.edu.cn/;https://www.cmu.edu",
        "aff_unique_abbr": "WHU;CMU",
        "aff_campus_unique_index": "0;1;0;1;1",
        "aff_campus_unique": "Wuhan;Pittsburgh",
        "aff_country_unique_index": "0;1;0;1;1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9341767",
        "title": "Monocular Depth Prediction through Continuous 3D Loss",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper reports a new continuous 3D loss function for learning depth from monocular images. The dense depth prediction from a monocular image is supervised using sparse LIDAR points, which enables us to leverage available open source datasets with camera-LIDAR sensor suites during training. Currently, accurate and affordable range sensor is not readily available. Stereo cameras and LIDARs measure depth either inaccurately or sparsely/costly. In contrast to the current point-to-point loss evaluation approach, the proposed 3D loss treats point clouds as continuous objects; therefore, it compensates for the lack of dense ground truth depth due to LIDAR's sparsity measurements. We applied the proposed loss in three state-of-the-art monocular depth prediction approaches DORN, BTS, and Monodepth2. Experimental evaluation shows that the proposed loss improves the depth prediction accuracy and produces point-clouds with more consistent 3D geometric structures compared with all tested baselines, implying the benefit of the proposed loss on general depth prediction networks. A video demo of this work is available at https://youtu.be/5HL8BjSAY4Y.",
        "primary_area": "",
        "author": "Minghan Zhu;Maani Ghaffari;Yuanxin Zhong;Pingping Lu;Zhong Cao;Ryan M. Eustice;Huei Peng;Minghan Zhu;Maani Ghaffari;Yuanxin Zhong;Pingping Lu;Zhong Cao;Ryan M. Eustice;Huei Peng",
        "authorids": "/37087996520;/37087056400;/37088637735;/37087995162;/37086351601;/37283587600;/37273793500;/37087996520;/37087056400;/37088637735;/37087995162;/37086351601;/37283587600;/37273793500",
        "aff": "University of Michigan, Ann Arbor, MI, USA; University of Michigan, Ann Arbor, MI, USA; University of Michigan, Ann Arbor, MI, USA; University of Michigan, Ann Arbor, MI, USA; Tsinghua University, Beijing, China; University of Michigan, Ann Arbor, MI, USA; University of Michigan, Ann Arbor, MI, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341767/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8173575225258942158&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;1;0;0",
        "aff_unique_norm": "University of Michigan;Tsinghua University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.umich.edu;https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "UM;THU",
        "aff_campus_unique_index": "0;0;0;0;1;0;0",
        "aff_campus_unique": "Ann Arbor;Beijing",
        "aff_country_unique_index": "0;0;0;0;1;0;0",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "9341003",
        "title": "Monocular Localization in HD Maps by Combining Semantic Segmentation and Distance Transform",
        "track": "main",
        "status": "Poster",
        "abstract": "Easy, yet robust long-term localization is still an open topic in research. Existing approaches require either dense maps, expensive sensors, specialized map features or proprietary detectors.We propose using semantic segmentation on a monocular camera to localize directly in a HD map as used for automated driving. This combines lightweight, yet powerful HD maps with the simplicity of monocular vision and the flexibility of neural networks.The major challenges arising from this combination are data association and robustness against misdetections. Association is solved efficiently by applying distance transform on binary per-class images. This provides not only a fast lookup table for a smooth gradient as needed for pose-graph optimization, but also dynamic association by default.A sliding-window pose graph optimization combines single image detections with vehicle odometry, smoothing results and helping overcome even misclassifications in consecutive frames.Evaluation against a highly accurate 6D visual localization shows that our approach can achieve accuracy levels as required for automated driving, being one of the most lightweight and flexible methods to do so.",
        "primary_area": "",
        "author": "Jan-Hendrik Pauls;K\u00fcrsat Petek;Fabian Poggenhans;Christoph Stiller;Jan-Hendrik Pauls;K\u00fcrsat Petek;Fabian Poggenhans;Christoph Stiller",
        "authorids": "/37086547128;/37088689752;/37085438943;/37284652100;/37086547128;/37088689752;/37085438943;/37284652100",
        "aff": "Institute of Measurement and Control Systems, Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany; Institute of Measurement and Control Systems, Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany; Intelligent Systems and Production Engineering, FZI Research Center for Information Technology, Karlsruhe, Germany; Intelligent Systems and Production Engineering, FZI Research Center for Information Technology, Karlsruhe, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341003/",
        "gs_citation": 38,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6238395450814529652&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;1",
        "aff_unique_norm": "Karlsruhe Institute of Technology;FZI Research Center for Information Technology",
        "aff_unique_dep": "Institute of Measurement and Control Systems;Intelligent Systems and Production Engineering",
        "aff_unique_url": "https://www.kit.edu;https://www.fzi.de",
        "aff_unique_abbr": "KIT;FZI",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Karlsruhe",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9341646",
        "title": "Monocular Visual Shape Tracking and Servoing for Isometrically Deforming Objects",
        "track": "main",
        "status": "Poster",
        "abstract": "We address the monocular visual shape servoing problem. This pushes the challenging visual servoing problem one step further from rigid object manipulation towards deformable object manipulation. Explicitly, it implies deforming the object towards a desired shape in 3D space by robots using monocular 2D vision. We specifically concentrate on a scheme capable of controlling large isometric deformations. Two important open subproblems arise for implementing such a scheme. (P1) Since it is concerned with large deformations, perception requires tracking the deformable object's 3D shape from monocular 2D images which is a severely underconstrained problem. (P2) Since rigid robots have fewer degrees of freedom than a deformable object, the shape control becomes underactuated. We propose a template-based shape servoing scheme in which we solve these two problems. The template allows us to both infer the object's shape using an improved Shape-from-Template algorithm and steer the object's deformation by means of the robots' movements. We validate the scheme via simulations and real experiments.",
        "primary_area": "",
        "author": "Miguel Aranda;Juan Antonio Corrales Ramon;Youcef Mezouar;Adrien Bartoli;Erol \u00d6zg\u00fcr;Miguel Aranda;Juan Antonio Corrales Ramon;Youcef Mezouar;Adrien Bartoli;Erol \u00d6zg\u00fcr",
        "authorids": "/38575293000;/37086842877;/37299713100;/37282923000;/37529038900;/38575293000;/37086842877;/37299713100;/37282923000;/37529038900",
        "aff": "CNRS, SIGMA Clermont, Institut Pascal, Universit\u00e9 Clermont Auvergne, Clermont-Ferrand, France; CNRS, SIGMA Clermont, Institut Pascal, Universit\u00e9 Clermont Auvergne, Clermont-Ferrand, France; CNRS, SIGMA Clermont, Institut Pascal, Universit\u00e9 Clermont Auvergne, Clermont-Ferrand, France; CNRS, SIGMA Clermont, Institut Pascal, Universit\u00e9 Clermont Auvergne, Clermont-Ferrand, France; CNRS, SIGMA Clermont, Institut Pascal, Universit\u00e9 Clermont Auvergne, Clermont-Ferrand, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341646/",
        "gs_citation": 40,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16194795745337482919&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Universit\u00e9 Clermont Auvergne",
        "aff_unique_dep": "SIGMA Clermont, Institut Pascal",
        "aff_unique_url": "https://www.uca.fr",
        "aff_unique_abbr": "UCA",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Clermont-Ferrand",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9341449",
        "title": "Motion Planning for Collision-resilient Mobile Robots in Obstacle-cluttered Unknown Environments with Risk Reward Trade-offs",
        "track": "main",
        "status": "Poster",
        "abstract": "Collision avoidance in unknown obstacle-cluttered environments may not always be feasible. This paper focuses on an emerging paradigm shift in which potential collisions with the environment can be harnessed instead of being avoided altogether. To this end, we introduce a new sampling-based online planning algorithm that can explicitly handle the risk of colliding with the environment and can switch between collision avoidance and collision exploitation. Central to the planner's capabilities is a novel joint optimization function that evaluates the effect of possible collisions using a reflection model. This way, the planner can make deliberate decisions to collide with the environment if such collision is expected to help the robot make progress toward its goal. To make the algorithm online, we present a state expansion pruning technique that significantly reduces the search space while ensuring completeness. The proposed algorithm is evaluated experimentally with a built-in-house holonomic wheeled robot that can withstand collisions. We perform an extensive parametric study to investigate trade-offs between (user-tuned) levels of risk, deliberate collision decision making, and trajectory statistics such as time to reach the goal and path length.",
        "primary_area": "",
        "author": "Zhouyu Lu;Zhichao Liu;Gustavo J. Correa;Konstantinos Karydis;Zhouyu Lu;Zhichao Liu;Gustavo J. Correa;Konstantinos Karydis",
        "authorids": "/37087243079;/37088505148;/37086935355;/38252121900;/37087243079;/37088505148;/37086935355;/38252121900",
        "aff": "Dept. of Electrical and Computer Engineering, University of California, Riverside; Dept. of Electrical and Computer Engineering, University of California, Riverside; Dept. of Electrical and Computer Engineering, University of California, Riverside; Dept. of Electrical and Computer Engineering, University of California, Riverside",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341449/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14476700894244497940&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of California, Riverside",
        "aff_unique_dep": "Dept. of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.ucr.edu",
        "aff_unique_abbr": "UCR",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Riverside",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341326",
        "title": "Motion Planning for Heterogeneous Unmanned Systems under Partial Observation from UAV",
        "track": "main",
        "status": "Poster",
        "abstract": "For heterogeneous unmanned systems composed of unmanned aerial vehicles (UAVs) and unmanned ground vehicles (UGVs), using UAVs serve as eyes to assist UGVs in motion planning is a promising research direction due to the UAVs\u2019 vast view scope. However, its limitations on flight altitude prevent the UAVs from observing the global map. Thus motion planning in the local map becomes a Partially Observable Markov Decision Process (POMDP) problem. This paper proposes a motion planning algorithm for heterogeneous unmanned systems under partial observation from UAV without reconstruction of global maps. Our algorithm consists of two parts designed for perception and decision-making, respectively. For the perception part, we propose the Grid Map Generation Network (GMGN), which is used to perceive scenes from UAV\u2019s perspective and classify the pathways and obstacles. For the decision-making part, we propose the Motion Command Generation Network (MCGN). Due to the addition of the memory mechanism, MCGN has planning and reasoning abilities under partial observation from UAVs. We evaluate our proposed algorithm by comparing it with baseline algorithms. The results show that our method effectively plans the motion of heterogeneous unmanned systems and achieves a relatively high success rate.",
        "primary_area": "",
        "author": "Ci Chen;Yuanfang Wan;Baowei Li;Chen Wang;Guangming Xie;Huanyu Jiang;Ci Chen;Yuanfang Wan;Baowei Li;Chen Wang;Guangming Xie;Huanyu Jiang",
        "authorids": "/37089515536;/37087051673;/37088691118;/37578426800;/37270592800;/37069816500;/37089515536;/37087051673;/37088691118;/37578426800;/37270592800;/37069816500",
        "aff": "College of Biosystems Engineering and Food Science, Zhejiang University, Hangzhou, China; Department of Ocean Science and Engineering, Southern University of Science and Technology, Shenzhen, China; The State Key Laboratory of Turbulence and Complex Systems, Intelligent Biomimetic Design Lab, College of Engineering, Peking University, Beijing, China; The State Key Laboratory of Turbulence and Complex Systems, Intelligent Biomimetic Design Lab, College of Engineering, Peking University, Beijing, China; Peng Cheng Laboratory, Shenzhen, China; College of Biosystems Engineering and Food Science, Zhejiang University, Hangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341326/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17909246667238311043&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;2;3;0",
        "aff_unique_norm": "Zhejiang University;Southern University of Science and Technology;Peking University;Peng Cheng Laboratory",
        "aff_unique_dep": "College of Biosystems Engineering and Food Science;Department of Ocean Science and Engineering;College of Engineering;",
        "aff_unique_url": "http://www.zju.edu.cn;https://www.sustech.edu.cn;http://www.pku.edu.cn;",
        "aff_unique_abbr": "ZJU;SUSTech;PKU;",
        "aff_campus_unique_index": "0;1;2;2;1;0",
        "aff_campus_unique": "Hangzhou;Shenzhen;Beijing",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9341158",
        "title": "Motion Prediction in Visual Object Tracking",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual object tracking (VOT) is an essential component for many applications, such as autonomous driving or assistive robotics. However, recent works tend to develop accurate systems based on more computationally expensive feature extractors for better instance matching. In contrast, this work addresses the importance of motion prediction in VOT. We use an off-the-shelf object detector to obtain instance bounding boxes. Then, a combination of camera motion decouple and Kalman filter is used for state estimation. Although our baseline system is a straightforward combination of standard methods, we obtain state-of-the-art results. Our method establishes new state-of-the-art performance on VOT (VOT-2016 and VOT-2018). Our proposed method improves the EAO on VOT-2016 from 0.472 of prior art to 0.505, from 0.410 to 0.431 on VOT-2018. To show the generalizability, we also test our method on video object segmentation (VOS: DAVIS-2016 and DAVIS-2017) and observe consistent improvement.",
        "primary_area": "",
        "author": "Jianren Wang;Yihui He;Jianren Wang;Yihui He",
        "authorids": "/37087079357;/37087080169;/37087079357;/37087080169",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341158/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5608677653067335191&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340747",
        "title": "Multi-Agent Path Planning Under Observation Schedule Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider the problem of enhanced security of multi-robot systems to prevent cyber-attackers from taking control of one or more robots in the group. We build upon a recently proposed solution that utilizes the physical measurement capabilities of the robots to perform introspection, i.e., detect the malicious actions of compromised agents using other members of the group. In particular, the proposed solution finds multi-agent paths on discrete spaces combined with a set of mutual observations at specific locations to detect robots with significant deviations from the preordained routes. In this paper, we develop a planner that works on continuous configuration spaces while also taking into account similar spatio-temporal constraints. In addition, the planner allows for more general tasks that can be formulated as arbitrary smooth cost functions to be specified. The combination of constraints and objectives considered in this paper are not easily handled by popular path planning algorithms (e.g., sampling-based methods), thus we propose a method based on the Alternating Direction Method of Multipliers (ADMM). ADMM is capable of finding locally optimal solutions to problems involving different kinds of objectives and non-convex temporal and spatial constraints, and allows for infeasible initialization. We benchmark our proposed method on multi-agent map exploration with minimum-uncertainty cost function, obstacles, and observation schedule constraints.",
        "primary_area": "",
        "author": "Ziqi Yang;Roberto Tron;Ziqi Yang;Roberto Tron",
        "authorids": "/37088687309;/37398528900;/37088687309;/37398528900",
        "aff": "Ziqi Yang; Roberto Tron",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340747/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4681291383052219348&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "",
        "aff_unique_norm": "",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "9341169",
        "title": "Multi-Agent Safe Planning with Gaussian Processes",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-agent safe systems have become an increasingly important area of study as we can now easily have multiple AI-powered systems operating together. In such settings, we need to ensure the safety of not only each individual agent, but also the overall system. In this paper, we introduce a novel multi-agent safe learning algorithm that enables decentralized safe navigation when there are multiple different agents in the environment. This algorithm makes mild assumptions about other agents and is trained in a decentralized fashion, i.e. with very little prior knowledge about other agents' policies. Experiments show our algorithm performs well with the robots running other algorithms when optimizing various objectives.",
        "primary_area": "",
        "author": "Zheqing Zhu;Erdem B\u0131y\u0131k;Dorsa Sadigh;Zheqing Zhu;Erdem B\u0131y\u0131k;Dorsa Sadigh",
        "authorids": "/37088691290;/37086082220;/38234464200;/37088691290;/37086082220;/38234464200",
        "aff": "Management Science & Engineering, Stanford University, CA, USA; Electrical Engineering, Stanford University, CA, USA; Computer Science, Stanford University, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341169/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2671983638458357945&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "Management Science & Engineering",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340783",
        "title": "Multi-Fingered Active Grasp Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning-based approaches to grasp planning are preferred over analytical methods due to their ability to better generalize to new, partially observed objects. However, data collection remains one of the biggest bottlenecks for grasp learning methods, particularly for multi-fingered hands. The relatively high dimensional configuration space of the hands coupled with the diversity of objects common in daily life requires a significant number of samples to produce robust and confident grasp success classifiers. In this paper, we present the first active deep learning approach to grasping that searches over the grasp configuration space and classifier confidence in a unified manner. We base our approach on recent success in planning multi-fingered grasps as probabilistic inference with a learned neural network likelihood function. We embed this within a multi-armed bandit formulation of sample selection. We show that our active grasp learning approach uses fewer training samples to produce grasp success rates comparable with the passive supervised learning method trained with grasping data generated by an analytical planner. We additionally show that grasps generated by the active learner have greater qualitative and quantitative diversity in shape.",
        "primary_area": "",
        "author": "Qingkai Lu;Mark Van der Merwe;Tucker Hermans;Qingkai Lu;Mark Van der Merwe;Tucker Hermans",
        "authorids": "/37086617766;/37088417395;/38230909600;/37086617766;/37088417395;/38230909600",
        "aff": "School of Computing and the Robotics Center, University of Utah, Salt Lake City, UT, USA; School of Computing and the Robotics Center, University of Utah, Salt Lake City, UT, USA; NVIDIA, Seattle, WA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340783/",
        "gs_citation": 36,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15365288174180780973&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "University of Utah;NVIDIA",
        "aff_unique_dep": "School of Computing and the Robotics Center;",
        "aff_unique_url": "https://www.utah.edu;https://www.nvidia.com",
        "aff_unique_abbr": "U of U;NV",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Salt Lake City;Seattle",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341185",
        "title": "Multi-Instance Aware Localization for End-to-End Imitation Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Existing architectures for imitation learning using image-to-action policy networks perform poorly when presented with an input image containing multiple instances of the object of interest, especially when the number of expert demonstrations available for training are limited. We show that end-to-end policy networks can be trained in a sample efficient manner by (a) appending the feature map output of the vision layers with an embedding that can indicate instance preference or take advantage of an implicit preference present in the expert demonstrations, and (b) employing an autoregressive action generator network for the control layers. The proposed architecture for localization has improved accuracy and sample efficiency and can generalize to the presence of more instances of objects than seen during training. When used for end-to-end imitation learning to perform reach, push, and pick-and-place tasks on a real robot, training is achieved with as few as 15 expert demonstrations.",
        "primary_area": "",
        "author": "Sagar Gubbi Venkatesh;Raviteja Upadrashta;Shishir Kolathaya;Bharadwaj Amrutur;Sagar Gubbi Venkatesh;Raviteja Upadrashta;Shishir Kolathaya;Bharadwaj Amrutur",
        "authorids": "/37088686305;/37085368187;/37060909000;/37370284100;/37088686305;/37085368187;/37060909000;/37370284100",
        "aff": "Robert Bosch Center for Cyber-Physical Systems, Indian Institute of Science, Bangalore, India; Robert Bosch Center for Cyber-Physical Systems, Indian Institute of Science, Bangalore, India; Robert Bosch Center for Cyber-Physical Systems, Indian Institute of Science, Bangalore, India; Robert Bosch Center for Cyber-Physical Systems, Indian Institute of Science, Bangalore, India",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341185/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14812935442868124029&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Indian Institute of Science",
        "aff_unique_dep": "Robert Bosch Center for Cyber-Physical Systems",
        "aff_unique_url": "https://www.iisc.ac.in",
        "aff_unique_abbr": "IISc",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Bangalore",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "9341555",
        "title": "Multi-Modal Pneumatic Actuator for Twisting, Extension, and Bending",
        "track": "main",
        "status": "Poster",
        "abstract": "Soft pneumatic actuators are commonly used in robotics for creating single-axis compression, extension, or bending motions. If these actuators are composed of compliant materials, they can also have low off-axis stiffnesses, making it difficult to restrict off-axis motions. In this work, we exploit the low off-axis stiffnesses of pneumatic actuators to design a modular actuator system that is capable of multi-modal extension, compression, two-axis bending, and twisting motions. By combining physical constraint mechanisms and motion planning, we demonstrate closed loop control with up to 24 mm of compression, 70 mm of extension, 115 degrees of bending, and 240 degrees of twisting. This actuator system is then used to illustrate several unique applications including twisting for unscrewing bottle caps and peristaltic crawling for locomotion.",
        "primary_area": "",
        "author": "Roman Balak;Yi Chen Mazumdar;Roman Balak;Yi Chen Mazumdar",
        "authorids": "/37088686854;/37087041807;/37088686854;/37087041807",
        "aff": "School of Mechanical Engineering, Georgia Institute of Technology, Atlanta, GA, USA; School of Mechanical Engineering, Georgia Institute of Technology, Atlanta, GA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341555/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17838439538515998356&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Georgia Institute of Technology",
        "aff_unique_dep": "School of Mechanical Engineering",
        "aff_unique_url": "https://www.gatech.edu",
        "aff_unique_abbr": "Georgia Tech",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Atlanta",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341532",
        "title": "Multi-Object Rearrangement with Monte Carlo Tree Search: A Case Study on Planar Nonprehensile Sorting",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we address a planar non-prehensile sorting task. Here, a robot needs to push many densely packed objects belonging to different classes into a configuration where these classes are clearly separated from each other. To achieve this, we propose to employ Monte Carlo tree search equipped with a task-specific heuristic function. We evaluate the algorithm on various simulated and real-world sorting tasks. We observe that the algorithm is capable of reliably sorting large numbers of convex and non-convex objects, as well as convex objects in the presence of immovable obstacles.",
        "primary_area": "",
        "author": "Haoran Song;Joshua A. Haustein;Weihao Yuan;Kaiyu Hang;Michael Yu Wang;Danica Kragic;Johannes A. Stork;Haoran Song;Joshua A. Haustein;Weihao Yuan;Kaiyu Hang;Michael Yu Wang;Danica Kragic;Johannes A. Stork",
        "authorids": "/37086332079;/37085453695;/37086455209;/37085393148;/37280913900;/37281296000;/37544515300;/37086332079;/37085453695;/37086455209;/37085393148;/37280913900;/37281296000;/37544515300",
        "aff": "Robotics Institute, Hong Kong University of Science and Technology, Hong Kong, China; Centre for Autonomous Systems, EECS, KTH Royal Institute of Technology, Stockholm, Sweden; Robotics Institute, Hong Kong University of Science and Technology, Hong Kong, China; Department of Mechanical Engineering and Material Science, Yale University, New Haven, Connecticut, USA; Robotics Institute, Hong Kong University of Science and Technology, Hong Kong, China; Centre for Autonomous Systems, EECS, KTH Royal Institute of Technology, Stockholm, Sweden; Centre for Applied Autonomous Sensor Systems, Orebro University, Orebro, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341532/",
        "gs_citation": 66,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6947525126913045913&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 13,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;0;2;0;1;3",
        "aff_unique_norm": "Hong Kong University of Science and Technology;KTH Royal Institute of Technology;Yale University;Orebro University",
        "aff_unique_dep": "Robotics Institute;EECS;Department of Mechanical Engineering and Material Science;Centre for Applied Autonomous Sensor Systems",
        "aff_unique_url": "https://www.ust.hk;https://www.kth.se;https://www.yale.edu;https://www.oru.se",
        "aff_unique_abbr": "HKUST;KTH;Yale;",
        "aff_campus_unique_index": "0;1;0;2;0;1;3",
        "aff_campus_unique": "Hong Kong;Stockholm;New Haven;Orebro",
        "aff_country_unique_index": "0;1;0;2;0;1;1",
        "aff_country_unique": "China;Sweden;United States"
    },
    {
        "id": "9341073",
        "title": "Multi-Robot Containment and Disablement",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents the multi-robot containment and disablement (CAD) problem. In this problem, a team of (ground or aerial) robots are engaged in a cooperative task of swarm containment and disablement (for example, locust swarm). Each team member is equipped with a tool that can both detect and disable the swarm individuals. The swarm is active in a given physical location, and the goal of the robots is twofold: to contain the swarm members such that the individuals will be prevented from expanding further beyond this area (this is referred to as perfect enclosure), and to fully disable the locust by reducing the size of the contained area (while preserving the perfect enclosure). We determine the minimal number of robots necessary to ensure perfect enclosure, and a placement of the robots about the contained area such that they will be able to guarantee perfect enclosure, as well as a distributed area reduction protocol maintaining perfect enclosure. We then suggest algorithms for handling the case in which there are not enough robots to guarantee perfect enclosure, and describe their performance based on rigorous experiments in the TeamBots simulator.",
        "primary_area": "",
        "author": "Yuval Maymon;Noa Agmon;Yuval Maymon;Noa Agmon",
        "authorids": "/37088686020;/37695468400;/37088686020;/37695468400",
        "aff": "Computer Science Department, Bar-Ilan University, Ramat Gan, Israel; Computer Science Department, Bar-Ilan University, Ramat Gan, Israel",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341073/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12328045819574599181&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Bar-Ilan University",
        "aff_unique_dep": "Computer Science Department",
        "aff_unique_url": "https://www.biu.ac.il",
        "aff_unique_abbr": "BIU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Ramat Gan",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Israel"
    },
    {
        "id": "9341213",
        "title": "Multi-Robot Coordinated Planning in Confined Environments under Kinematic Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "We investigate the problem of multi-robot coordinated planning in environments where the robots may have to operate in close proximity to each other. We seek computationally efficient planners that ensure safe paths and adherence to kinematic constraints. We extend the central planner dRRT* with our variant, fast-dRRT (fdRRT), with the intention being to use in tight environments that lead to a high degree of coupling between robots. Our algorithm is empirically shown to achieve the trade-off between computational time and solution quality, especially in tight environments. We also demonstrate the ability of our algorithm to be adapted to the online planning problem while maintaining computational efficiency. The software implementation is available online at https://github.com/CMangette/Fast-dRRT.",
        "primary_area": "",
        "author": "Clayton Mangette;Pratap Tokekar;Clayton Mangette;Pratap Tokekar",
        "authorids": "/37088688276;/37546532700;/37088688276;/37546532700",
        "aff": "Department of Electrical and Computer Engineering, Virginia Tech, U.S.A.; Department of Computer Science, University of Maryland, U.S.A.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341213/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17555215220856656512&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Virginia Tech;University of Maryland",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Department of Computer Science",
        "aff_unique_url": "https://www.vt.edu;https://www/umd.edu",
        "aff_unique_abbr": "VT;UMD",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341393",
        "title": "Multi-Robot Joint Visual-Inertial Localization and 3-D Moving Object Tracking",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a novel distributed algorithm to track a moving object's state by utilizing a heterogenous mobile robot network in a three-dimensional (3-D) environment, wherein the robots' poses (positions and orientations) are unknown. Each robot is equipped with a monocular camera and an inertial measurement unit (IMU), and has the ability to communicate with its neighbors. Rather than assuming a known common global frame for all the robots (which is often the case in the literature regarding multi-robot systems), we allow each robot to perform motion estimation locally. For localization, we propose a multi-robot visual-inertial navigation systems (VINS) where one robot builds a prior map and then the map is used to bound the long-term drifts of the visual-inertial odometry (VIO) running on the other robots. Moreover, a novel distributed Kalman filter is introduced and employed to cooperatively track the six degree-of-freedom (6-DoF) motion of the object which is represented as a point cloud. Further, the object can be totally invisible to some robots during the tracking period. The proposed algorithm is extensively validated in Monte-Carlo simulations.",
        "primary_area": "",
        "author": "Pengxiang Zhu;Wei Ren;Pengxiang Zhu;Wei Ren",
        "authorids": "/37086958473;/37271980400;/37086958473;/37271980400",
        "aff": "Department of Electrical and Computer Engineering, University of California, Riverside, CA, USA; Department of Electrical and Computer Engineering, University of California, Riverside, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341393/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7844492316353655314&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of California, Riverside",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.ucr.edu",
        "aff_unique_abbr": "UCR",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Riverside",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341247",
        "title": "Multi-Robot Task Allocation with Time Window and Ordering Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "The multi-robot task allocation problem comprises task assignment, coalition formation, task scheduling, and routing. We extend the distributed constraint optimization problem (DCOP) formalism to allocate tasks to a team of robots. The tasks have time window and ordering constraints. Each robot creates a simple temporal network to maintain the tasks in its schedule. The proposed layered framework, called L-DCOP, forms efficient coalitions among robots to accomplish the tasks more efficiently as a result of their collective abilities. We conduct extensive experiments to assess the performance of the proposed algorithm and compare it against a benchmark auction-based approach. The results show that L-DCOP increases the task completion rate and task completion frequency by 1.7% and 10.1%, respectively, and reduces the task execution time by 52.5% on average.",
        "primary_area": "",
        "author": "Elina Suslova;Pooyan Fazli;Elina Suslova;Pooyan Fazli",
        "authorids": "/37088689354;/37586893900;/37088689354;/37586893900",
        "aff": "Department of Computer Science, San Francisco State University, San Francisco, CA, USA; Department of Computer Science, San Francisco State University, San Francisco, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341247/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=720076380468125234&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "San Francisco State University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.sfsu.edu",
        "aff_unique_abbr": "SFSU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "San Francisco",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341506",
        "title": "Multi-Sparse Gaussian Process: Learning based Semi-Parametric Control",
        "track": "main",
        "status": "Poster",
        "abstract": "A key challenge with controlling complex dynamical systems is to accurately model them. However, this requirement is very hard to satisfy in practice. Data-driven approaches such as Gaussian processes (GPs) have proved quite effective by employing regression based methods to capture the unmodeled dynamical effects. However, GPs scale cubically with number of data points n, and it is often a challenge to perform realtime regression. In this paper, we propose a semi-parametric framework exploiting sparsity for learning-based control. We combine the parametric model of the system with multiple sparse GP models to capture any unmodeled dynamics. MultiSparse Gaussian Process (MSGP) uses multiple sparse models with unique hyperparameters for each one, thereby, preserving the richness and uniqueness of each sparse model. For a query point, a weighted sparse posterior prediction is performed based on N neighboring sparse models. Hence, the prediction complexity is significantly reduced from O(n3) to O(Npu2), p and u are data points and pseudo-inputs respectively for each sparse model. We validate MSGP's learning performance for a quadrotor using a geometric controller in simulation. Comparison with GP, sparse GP, and local GP shows that MSGP has higher prediction accuracy than sparse and local GP, with significantly lower time complexity than all three. We also validate MSGP on a real quadrotor setup for unmodeled mass, inertia, and disturbances. The experiment video can be seen at: https://youtu.be/zUk1ISux6ao.",
        "primary_area": "",
        "author": "Mouhyemen Khan;Akash Patel;Abhijit Chatterjee;Mouhyemen Khan;Akash Patel;Abhijit Chatterjee",
        "authorids": "/37088487713;/37088687165;/37273696200;/37088487713;/37088687165;/37273696200",
        "aff": "School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA; Institute of Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA, USA; School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341506/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12692977959128520776&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Georgia Institute of Technology",
        "aff_unique_dep": "School of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.gatech.edu",
        "aff_unique_abbr": "Georgia Tech",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Atlanta",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340870",
        "title": "Multi-Task Deep Learning for Depth-based Person Perception in Mobile Robotics",
        "track": "main",
        "status": "Poster",
        "abstract": "Efficient and robust person perception is one of the most basic skills a mobile robot must have to ensure intuitive human-machine interaction. In addition to person detection, this also includes estimating various attributes, like posture or body orientation, in order to achieve user-adaptive behavior. However, given limited computing and battery capabilities on a mobile robot, it is inefficient to solve all perception tasks separately, especially when using computationally expensive deep neural networks. Therefore, we propose a multi-task system for person perception, comprising of a fast, depth- based region proposal and an efficient, lightweight deep neural network. Using a single network forward pass, the system simultaneously detects persons, classifies their body postures, and estimates the upper body orientations while retaining almost the same computation time as a single-task network. We describe how to handle a real-world multi-task scenario and conduct an extensive series of experiments in order to compare various network architectures and task weightings. We further show that multi-task learning improves the networks' performance compared to their single-task baselines. For training and evaluation, we combine an existing dataset for orientation estimation and a new, self-recorded dataset, consisting of more than 235,000 depth patches that is made publicly available to the research community.",
        "primary_area": "",
        "author": "Daniel Seichter;Benjamin Lewandowski;Dominik H\u00f6chemer;Tim Wengefeld;Horst-Michael Gross;Daniel Seichter;Benjamin Lewandowski;Dominik H\u00f6chemer;Tim Wengefeld;Horst-Michael Gross",
        "authorids": "/37085814238;/37086317277;/37088530949;/37085449849;/37270612700;/37085814238;/37086317277;/37088530949;/37085449849;/37270612700",
        "aff": "Neuroinformatics and Cognitive Robotics Lab, Technische Universit\u00a4at Ilmenau, Ilmenau, Germany; Neuroinformatics and Cognitive Robotics Lab, Technische Universit\u00a4at Ilmenau, Ilmenau, Germany; Neuroinformatics and Cognitive Robotics Lab, Technische Universit\u00a4at Ilmenau, Ilmenau, Germany; Neuroinformatics and Cognitive Robotics Lab, Technische Universit\u00a4at Ilmenau, Ilmenau, Germany; Neuroinformatics and Cognitive Robotics Lab, Technische Universit\u00a4at Ilmenau, Ilmenau, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340870/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7227016118335116127&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Technische Universit\u00e4t Ilmenau",
        "aff_unique_dep": "Neuroinformatics and Cognitive Robotics Lab",
        "aff_unique_url": "https://www.tu-ilmenau.de",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Ilmenau",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9341089",
        "title": "Multi-UAV Coverage Path Planning for the Inspection of Large and Complex Structures",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a multi-UAV Coverage Path Planning (CPP) framework for the inspection of large-scale, complex 3D structures. In the proposed sampling-based coverage path planning method, we formulate the multi-UAV inspection applications as a multi-agent coverage path planning problem. By combining two NP-hard problems: Set Covering Problem (SCP) and Vehicle Routing Problem (VRP), a Set-Covering Vehicle Routing Problem (SC-VRP) is formulated and subsequently solved by a modified Biased Random Key Genetic Algorithm (BRKGA) with novel, efficient encoding strategies and local improvement heuristics. We test our proposed method for several complex 3D structures with the 3D model extracted from OpenStreetMap. The proposed method outperforms previous methods, by reducing the length of the planned inspection path by up to 48%.",
        "primary_area": "",
        "author": "Wei Jing;Di Deng;Yan Wu;Kenji Shimada;Wei Jing;Di Deng;Yan Wu;Kenji Shimada",
        "authorids": "/37085809046;/37086577056;/37085344977;/37324632500;/37085809046;/37086577056;/37085344977;/37324632500",
        "aff": "A*STAR Institute of High Performance Computing (IHPC), Singapore; Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; A*STAR Initiative for Artificial Intelligence and Analytics (AI3), Singapore; Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341089/",
        "gs_citation": 84,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15164239921493888996&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;1",
        "aff_unique_norm": "A*STAR Institute of High Performance Computing;Carnegie Mellon University;A*STAR Initiative for Artificial Intelligence and Analytics",
        "aff_unique_dep": "Institute of High Performance Computing;Department of Mechanical Engineering;AI3",
        "aff_unique_url": "https://www.ihpc.a-star.edu.sg;https://www.cmu.edu;https://www.aistar.edu.sg",
        "aff_unique_abbr": "IHPC;CMU;AI3",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Pittsburgh",
        "aff_country_unique_index": "0;1;0;1",
        "aff_country_unique": "Singapore;United States"
    },
    {
        "id": "9341500",
        "title": "Multi-label Long Short-Term Memory for construction vehicle activity recognition with imbalanced supervision",
        "track": "main",
        "status": "Poster",
        "abstract": "Sensor-based activity recognition for construction vehicles is useful for evaluating the skills of the operator, measuring work efficiency, and many other use cases. Therefore, many researches have explored robust activity-recognition models. However, it remains a challenge to apply the model to many construction sites because of the imbalance of the dataset. While it is natural to employ multi-label representation on imbalanced data with a large number of activity categories, multi-label robust classification for activity recognition has yet to be resolved because of the nature of the time-series property. In this work, we propose a novel multi-label long short-term memory (LSTM) model, which is effective for the sequence multi-labeling problem. The proposed model has connections to the temporal direction and attribute direction, which exploit both the temporal pattern and co-occurrence among attributes. In addition, by providing a bidirectional connection structure in the attribute direction, the model enables us to alleviate the dependency of the chain order in what we call \"classifier chain\", which is a classical approach to multi-label classification. To validate our methods, we conduct experiments using real-world construction-vehicle dataset.",
        "primary_area": "",
        "author": "Haruka Abe;Takuya Hino;Motohide Sugihara;Hiroki Ikeya;Masamichi Shimosaka;Haruka Abe;Takuya Hino;Motohide Sugihara;Hiroki Ikeya;Masamichi Shimosaka",
        "authorids": "/37088687954;/37088688879;/37088686707;/37088686500;/37269729900;/37088687954;/37088688879;/37088686707;/37088686500;/37269729900",
        "aff": "Department of Computer Science, Tokyo Institute of Technology, Tokyo, Japan; Komatsu Corporation, Tokyo, Japan; Komatsu Corporation, Tokyo, Japan; Komatsu Corporation, Tokyo, Japan; Department of Computer Science, Tokyo Institute of Technology, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341500/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:4wltxyLgR-4J:scholar.google.com/&scioq=Multi-label+Long+Short-Term+Memory+for+construction+vehicle+activity+recognition+with+imbalanced+supervision&hl=en&as_sdt=0,5",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;0",
        "aff_unique_norm": "Tokyo Institute of Technology;Komatsu Corporation",
        "aff_unique_dep": "Department of Computer Science;",
        "aff_unique_url": "https://www.titech.ac.jp;https://www.komatsu.com",
        "aff_unique_abbr": "Titech;Komatsu",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Tokyo;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9341246",
        "title": "Multi-mode Trajectory Optimization for Impact-aware Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "The transition from free motion to contact is a challenging problem in robotics, in part due to its hybrid nature. Additionally, disregarding the effects of impacts at the motion planning level often results in intractable impulsive contact forces. In this paper, we introduce an impact-aware multi-mode trajectory optimization (TO) method that combines hybrid dynamics and hybrid control in a coherent fashion. A key concept is the incorporation of an explicit contact force transmission model in the TO method. This allows the simultaneous optimization of the contact forces, contact timings, continuous motion trajectories and compliance, while satisfying task constraints. We compare our method against standard compliance control and an impact-agnostic TO method in physical simulations. Further, we experimentally validate the proposed method with a robot manipulator on the task of halting a large-momentum object.",
        "primary_area": "",
        "author": "Theodoros Stouraitis;Lei Yan;Jo\u00e3o Moura;Michael Gienger;Sethu Vijayakumar;Theodoros Stouraitis;Lei Yan;Jo\u00e3o Moura;Michael Gienger;Sethu Vijayakumar",
        "authorids": "/37086314988;/37085460620;/37086411872;/37277233400;/37295595500;/37086314988;/37085460620;/37086411872;/37277233400;/37295595500",
        "aff": "Honda Research Institute Europe (HRI-EU), Germany; Shenzhen Institute for Artificial Intelligence and Robotics for Society (AIRS), The Chinese University of Hong Kong (Shenzhen), China; School of Informatics, University of Edinburgh, Edinburgh, U.K.; Honda Research Institute Europe (HRI-EU), Germany; School of Informatics, University of Edinburgh, Edinburgh, U.K.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341246/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2883265841259503383&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;0;2",
        "aff_unique_norm": "Honda Research Institute Europe;The Chinese University of Hong Kong (Shenzhen);University of Edinburgh",
        "aff_unique_dep": "Honda Research Institute;Shenzhen Institute for Artificial Intelligence and Robotics for Society (AIRS);School of Informatics",
        "aff_unique_url": "https://www.honda-ri.eu/;https://www.siat.ac.cn;https://www.ed.ac.uk",
        "aff_unique_abbr": "HRI-EU;CUHK(SZ);Edinburgh",
        "aff_campus_unique_index": "1;2;2",
        "aff_campus_unique": ";Shenzhen;Edinburgh",
        "aff_country_unique_index": "0;1;2;0;2",
        "aff_country_unique": "Germany;China;United Kingdom"
    },
    {
        "id": "9341367",
        "title": "Multi-robot Coordination with Agent-Server Architecture for Autonomous Navigation in Partially Unknown Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we present a system architecture to enable autonomous navigation of multiple agents across user-selected global interest points in a partially unknown environment. The system is composed of a server and a team of agents, here small aircrafts. Leveraging this architecture, computation-ally demanding tasks, such as global dense mapping and global path planning can be outsourced to a potentially powerful central server, limiting the onboard computation for each agent to local pose estimation using Visual-Inertial Odometry (VIO) and local path planning for obstacle avoidance. By assigning priorities to the agents, we propose a hierarchical multi-robot global planning pipeline, which avoids collisions amongst the agents and computes their paths towards the respective goals. The resulting global paths are communicated to the agents and serve as reference input to the local planner running onboard each agent. In contrast to previous works, here we relax the common assumption of a previously mapped environment and perfect knowledge about the state, and we show the effectiveness of the proposed approach in photo-realistic simulations with up to four agents operating in an industrial environment.",
        "primary_area": "",
        "author": "Luca Bartolomei;Marco Karrer;Margarita Chli;Luca Bartolomei;Marco Karrer;Margarita Chli",
        "authorids": "/37087322350;/37086206672;/37546501900;/37087322350;/37086206672;/37546501900",
        "aff": "Vision For Robotics Lab, ETH Z\u00fcrich, Switzerland; Vision For Robotics Lab, ETH Z\u00fcrich, Switzerland; Vision For Robotics Lab, ETH Z\u00fcrich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341367/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1967907000661726281&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "ETH Z\u00fcrich",
        "aff_unique_dep": "Vision For Robotics Lab",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETH",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9340965",
        "title": "Multi-task Control for a Quadruped Robot with Changeable Leg Configuration",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a multi-task control strategy for a quadruped robot named THU-QUAD II. The mechanical design of the robot ensures a wide range of motion for all joints, which allows it to stand and walk like a mammal as well as sprawl to the ground and crawl like a reptile. Five basic leg configurations are defined for the robot, including four mammal-type configurations with bidirectional knees and one sprawling-type configuration. A multi-task control framework is developed by combining configuration selection and gait planning. According to the locomotion environments, the robot can nimbly switch between different configurations, which gives it more flexibility when facing different tasks. For the mammal-type configuration, a parametric climbing gait is designed to traverse structural terrain. For the sprawling-type configuration, a crawling gait is designed to achieve robust locomotion on uneven terrain. Simulations and experiments show that the robot is capable to move on multiple challenging terrains, including doorsills, stairs, slopes, sand and stones. This paper demonstrates that even some challenging locomotion tasks can be achieved in a rather simple way without using complicated control algorithms, which suggests us to rethink about the leg configurations in designing quadruped robots.",
        "primary_area": "",
        "author": "Linqi Ye;Houde Liu;Xueqian Wang;Bin Liang;Bo Yuan;Linqi Ye;Houde Liu;Xueqian Wang;Bin Liang;Bo Yuan",
        "authorids": "/37086311678;/37085401214;/37085383477;/37270783900;/37669120900;/37086311678;/37085401214;/37085383477;/37270783900;/37669120900",
        "aff": "Center for Artificial Intelligence and Robotics, Tsinghua Shenzhen International Graduate School, Tsinghua University, Shenzhen, China; Center for Artificial Intelligence and Robotics, Tsinghua Shenzhen International Graduate School, Tsinghua University, Shenzhen, China; Center for Artificial Intelligence and Robotics, Tsinghua Shenzhen International Graduate School, Tsinghua University, Shenzhen, China; Department of Automation, Navigation and Control Research Center, Tsinghua University, Beijing, China; Center for Artificial Intelligence and Robotics, Tsinghua Shenzhen International Graduate School, Tsinghua University, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340965/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8027630246695529211&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Tsinghua University",
        "aff_unique_dep": "Center for Artificial Intelligence and Robotics",
        "aff_unique_url": "https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "Tsinghua",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Shenzhen;Beijing",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9341398",
        "title": "Multimodal Aggregation Approach for Memory Vision-Voice Indoor Navigation with Meta-Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Vision and voice are two vital keys for agents\u2019 interaction and learning. In this paper, we present a novel indoor navigation model called Memory Vision-Voice Indoor Navigation (MVV-IN), which receives voice commands and analyzes multimodal information of visual observation in order to enhance robots\u2019 environment understanding. We make use of single RGB images taken by a rst-view monocular camera. We also apply a self-attention mechanism to keep the agent focusing on key areas. Memory is important for the agent to avoid repeating certain tasks unnecessarily and in order for it to adapt adequately to new scenes, therefore, we make use of meta-learning. We have experimented with various functional features extracted from visual observation. Comparative experiments prove that our methods outperform state-of-the-art baselines.",
        "primary_area": "",
        "author": "Liqi Yan;Dongfang Liu;Yaoxian Song;Changbin Yu;Liqi Yan;Dongfang Liu;Yaoxian Song;Changbin Yu",
        "authorids": "/37088687298;/37086806431;/37087051725;/37291713000;/37088687298;/37086806431;/37087051725;/37291713000",
        "aff": "School of Engineering, Westlake University, China; Department of Computer Graphics Technology, Purdue University, USA; School of Engineering, Westlake University, China; School of Engineering, Westlake University, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341398/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14687265568672902596&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Westlake University;Purdue University",
        "aff_unique_dep": "School of Engineering;Department of Computer Graphics Technology",
        "aff_unique_url": "https://www.westlake.edu.cn;https://www.purdue.edu",
        "aff_unique_abbr": ";Purdue",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9341165",
        "title": "Multimodal Material Classification for Robots using Spectroscopy and High Resolution Texture Imaging",
        "track": "main",
        "status": "Poster",
        "abstract": "Material recognition can help inform robots about how to properly interact with and manipulate real-world objects. In this paper, we present a multimodal sensing technique, leveraging near-infrared spectroscopy and close-range high resolution texture imaging, that enables robots to estimate the materials of household objects. We release a dataset of high resolution texture images and spectral measurements collected from a mobile manipulator that interacted with 144 house-hold objects. We then present a neural network architecture that learns a compact multimodal representation of spectral measurements and texture images. When generalizing material classification to new objects, we show that this multimodal representation enables a robot to recognize materials with greater performance as compared to prior state-of-the-art approaches. Finally, we present how a robot can combine this high resolution local sensing with images from the robot's head-mounted camera to achieve accurate material classification over a scene of objects on a table.",
        "primary_area": "",
        "author": "Zackory Erickson;Eliot Xing;Bharat Srirangam;Sonia Chernova;Charles C. Kemp;Zackory Erickson;Eliot Xing;Bharat Srirangam;Sonia Chernova;Charles C. Kemp",
        "authorids": "/37085785366;/37088689279;/37088688775;/37283184200;/37266709400;/37085785366;/37088689279;/37088688775;/37283184200;/37266709400",
        "aff": "Healthcare Robotics Lab, Georgia Institute of Technology, Atlanta, GA, USA; Healthcare Robotics Lab, Georgia Institute of Technology, Atlanta, GA, USA; Healthcare Robotics Lab, Georgia Institute of Technology, Atlanta, GA, USA; Robot Autonomy and Interactive Learning Lab, Georgia Institute of Technology, Atlanta, GA, USA; Healthcare Robotics Lab, Georgia Institute of Technology, Atlanta, GA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341165/",
        "gs_citation": 51,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17809876659193463401&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Georgia Institute of Technology",
        "aff_unique_dep": "Healthcare Robotics Lab",
        "aff_unique_url": "https://www.gatech.edu",
        "aff_unique_abbr": "Georgia Tech",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Atlanta",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341579",
        "title": "Multimodal Sensor Fusion with Differentiable Filters",
        "track": "main",
        "status": "Poster",
        "abstract": "Leveraging multimodal information with recursive Bayesian filters improves performance and robustness of state estimation, as recursive filters can combine different modalities according to their uncertainties. Prior work has studied how to optimally fuse different sensor modalities with analytical state estimation algorithms. However, deriving the dynamics and measurement models along with their noise profile can be difficult or lead to intractable models. Differentiable filters provide a way to learn these models end-to-end while retaining the algorithmic structure of recursive filters. This can be especially helpful when working with sensor modalities that are high dimensional and have very different characteristics. In contact-rich manipulation, we want to combine visual sensing (which gives us global information) with tactile sensing (which gives us local information). In this paper, we study new differentiable filtering architectures to fuse heterogeneous sensor information. As case studies, we evaluate three tasks: two in planar pushing (simulated and real) and one in manipulating a kinematically constrained door (simulated). In extensive evaluations, we find that differentiable filters that leverage crossmodal sensor information reach comparable accuracies to unstructured LSTM models, while presenting interpretability benefits that may be important for safety-critical systems. We also release an open-source library for creating and training differentiable Bayesian filters in PyTorch, which can be found on our project website: https://sites.google.com/view/multimodalfilter.",
        "primary_area": "",
        "author": "Michelle A. Lee;Brent Yi;Roberto Mart\u00edn-Mart\u00edn;Silvio Savarese;Jeannette Bohg;Michelle A. Lee;Brent Yi;Roberto Mart\u00edn-Mart\u00edn;Silvio Savarese;Jeannette Bohg",
        "authorids": "/37086935666;/37088687522;/37085788640;/37298502600;/37591153900;/37086935666;/37088687522;/37085788640;/37298502600;/37591153900",
        "aff": "Stanford Artificial Intelligence Lab (SAIL), Stanford University; Stanford Artificial Intelligence Lab (SAIL), Stanford University; Stanford Artificial Intelligence Lab (SAIL), Stanford University; Stanford Artificial Intelligence Lab (SAIL), Stanford University; Stanford Artificial Intelligence Lab (SAIL), Stanford University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341579/",
        "gs_citation": 67,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17562021620307016851&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "Stanford Artificial Intelligence Lab (SAIL)",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340688",
        "title": "Multimodal Teleoperation of Heterogeneous Robots within a Construction Environment",
        "track": "main",
        "status": "Poster",
        "abstract": "Automation in construction continues to be a topic of interest for many in industry and academia. However, the dynamic environments presented in construction sites prove these tasks to be difficult to automate reliably. This paper proposes a novel method of teleoperation for multiple heterogeneous robots within a construction environment. The system is achieved by creating a virtual reality interface that allows an operator to control multiple robots both synchronously and asynchronously. Feedback is provided from an array of RGBD cameras, force sensors, and precise odometry data. The DRC-Hubo and Spot robot platforms are used for implementation and experimentation. Experiments include useful tasks for construction including item manipulation and item delivery of tools and components. Results demonstrate the feasibility of implementing the system in a construction environment, including trajectory comparisons, task learning curves, and successful multi-robot collaboration.",
        "primary_area": "",
        "author": "Dylan Wallace;Yu Hang He;Jean Chagas Vaz;Leonardo Georgescu;Paul Y. Oh;Dylan Wallace;Yu Hang He;Jean Chagas Vaz;Leonardo Georgescu;Paul Y. Oh",
        "authorids": "/37086073118;/37088690268;/37086159391;/37086359361;/37266607600;/37086073118;/37088690268;/37086159391;/37086359361;/37266607600",
        "aff": "Electrical and Computer Engineering Department, University of Nevada Las Vegas (UNLV), USA; Mechanical Engineering Department, University of Nevada Las Vegas (UNLV), USA; Mechanical Engineering Department, University of Nevada Las Vegas (UNLV), USA; Mechanical Engineering Department, University of Nevada Las Vegas (UNLV), USA; Faculty of Mechanical Engineering, University of Nevada Las Vegas (UNLV), USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340688/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3953679616678714724&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Nevada Las Vegas",
        "aff_unique_dep": "Electrical and Computer Engineering Department",
        "aff_unique_url": "https://www.unlv.edu",
        "aff_unique_abbr": "UNLV",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Las Vegas",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341327",
        "title": "Multiple Trajectory Prediction with Deep Temporal and Spatial Convolutional Neural Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Automated vehicles need to not only perceive their environment, but also predict the possible future behavior of all detected traffic participants in order to safely navigate in complex scenarios and avoid critical situations, ranging from merging on highways to crossing urban intersections. Due to the availability of datasets with large numbers of recorded trajectories of traffic participants, deep learning based approaches can be used to model the behavior of road users. This paper proposes a convolutional network that operates on rasterized actor-centric images which encode the static and dynamic actor-environment. We predict multiple possible future trajectories for each traffic actor, which include position, velocity, acceleration, orientation, yaw rate and position uncertainty estimates. To make better use of the past movement of the actor, we propose to employ temporal convolutional networks (TCNs) and rely on uncertainties estimated from the previous object tracking stage. We evaluate our approach on the public \"Argoverse Motion Forecasting\" dataset, on which it won the first prize at the Argoverse Motion Forecasting Challenge, as presented on the NeurIPS 2019 workshop on \"Machine Learning for Autonomous Driving\".",
        "primary_area": "",
        "author": "Jan Strohbeck;Vasileios Belagiannis;Johannes M\u00fcller;Marcel Schreiber;Martin Herrmann;Daniel Wolf;Michael Buchholz;Jan Strohbeck;Vasileios Belagiannis;Johannes M\u00fcller;Marcel Schreiber;Martin Herrmann;Daniel Wolf;Michael Buchholz",
        "authorids": "/37087103892;/37085391038;/37086442433;/37086935692;/37086231292;/37088686860;/38180084100;/37087103892;/37085391038;/37086442433;/37086935692;/37086231292;/37088686860;/38180084100",
        "aff": "Institute of Measurement, Control and Mi-crotechnology, Ulm University, Ulm, Germany; Institute of Measurement, Control and Mi-crotechnology, Ulm University, Ulm, Germany; Institute of Measurement, Control and Mi-crotechnology, Ulm University, Ulm, Germany; Institute of Measurement, Control and Mi-crotechnology, Ulm University, Ulm, Germany; Institute of Measurement, Control and Mi-crotechnology, Ulm University, Ulm, Germany; Institute of Measurement, Control and Mi-crotechnology, Ulm University, Ulm, Germany; Institute of Measurement, Control and Mi-crotechnology, Ulm University, Ulm, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341327/",
        "gs_citation": 46,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14526137648968131300&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Ulm University",
        "aff_unique_dep": "Institute of Measurement, Control and Microtechnology",
        "aff_unique_url": "https://www.uni-ulm.de",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Ulm",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9341372",
        "title": "Multiplicative Controller Fusion: Leveraging Algorithmic Priors for Sample-efficient Reinforcement Learning and Safe Sim-To-Real Transfer",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning-based approaches often outperform hand-coded algorithmic solutions for many problems in robotics. However, learning long-horizon tasks on real robot hardware can be intractable, and transferring a learned policy from simulation to reality is still extremely challenging. We present a novel approach to model-free reinforcement learning that can leverage existing sub-optimal solutions as an algorithmic prior during training and deployment. During training, our gated fusion approach enables the prior to guide the initial stages of exploration, increasing sample-efficiency and enabling learning from sparse long-horizon reward signals. Importantly, the policy can learn to improve beyond the performance of the sub-optimal prior since the prior's influence is annealed gradually. During deployment, the policy's uncertainty provides a reliable strategy for transferring a simulation-trained policy to the real world by falling back to the prior controller in uncertain states. We show the efficacy of our Multiplicative Controller Fusion approach on the task of robot navigation and demonstrate safe transfer from simulation to the real world without any fine-tuning. The code for this project is made publicly available at https://sites.google.com/view/mcf-nav/home.",
        "primary_area": "",
        "author": "Krishan Rana;Vibhavari Dasagi;Ben Talbot;Michael Milford;Niko S\u00fcnderhauf;Krishan Rana;Vibhavari Dasagi;Ben Talbot;Michael Milford;Niko S\u00fcnderhauf",
        "authorids": "/37088507024;/37088505194;/37085398028;/37283633100;/37563890800;/37088507024;/37088505194;/37085398028;/37283633100;/37563890800",
        "aff": "Australian Centre for Robotic Vision at Queensland University of Technology (QUT), Brisbane, Australia; Australian Centre for Robotic Vision at Queensland University of Technology (QUT), Brisbane, Australia; Australian Centre for Robotic Vision at Queensland University of Technology (QUT), Brisbane, Australia; Australian Centre for Robotic Vision at Queensland University of Technology (QUT), Brisbane, Australia; Australian Centre for Robotic Vision at Queensland University of Technology (QUT), Brisbane, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341372/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6723836100639975451&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Queensland University of Technology",
        "aff_unique_dep": "Australian Centre for Robotic Vision",
        "aff_unique_url": "https://www.qut.edu.au",
        "aff_unique_abbr": "QUT",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Brisbane",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "9340817",
        "title": "NBVC: A Benchmark for Depth Estimation from Narrow-Baseline Video Clips",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a benchmark for online, video-based depth estimation, a problem that is not covered by the current set of benchmarks for evaluating 3D reconstruction, which focus on offline, batch reconstruction. Online depth estimation from video captured by a moving camera is a key enabling technology for compelling applications in robotics and augmented reality. Inspired by progress in many aspects of robotics due to benchmarks and datasets, we propose a new benchmark called NBVC for evaluating methods for online depth estimation from video. Our benchmark is composed of short video sequences with corresponding high-quality ground truth depth maps, derived from the recent Tanks and Temples dataset. We are hopeful that our work will be instrumental in the development of learning-based algorithms for online depth estimation from video clips, and will also lead to improvements in conventional approaches. In addition to the benchmark, we present a superpixel-based plane sweeping stereo algorithm and use it to investigate various aspects of the problem. The paper contains our initial findings and conclusions.",
        "primary_area": "",
        "author": "Philippos Mordohai;Konstantinos Batsos;Ameesh Makadia;Noah Snavely;Philippos Mordohai;Konstantinos Batsos;Ameesh Makadia;Noah Snavely",
        "authorids": "/38480615300;/37086494454;/37270620600;/37397866800;/38480615300;/37086494454;/37270620600;/37397866800",
        "aff": "Dept. of Computer Science, Stevens Institute of Technology, NJ, USA; Dept. of Computer Science, Stevens Institute of Technology, NJ, USA; Google Research, USA; Computer Science Department, Cornell Tech, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340817/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6454117541573817756&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;2",
        "aff_unique_norm": "Stevens Institute of Technology;Google;Cornell Tech",
        "aff_unique_dep": "Dept. of Computer Science;Google Research;Computer Science Department",
        "aff_unique_url": "https://www.stevens.edu;https://research.google;https://cornelltech.io",
        "aff_unique_abbr": "SIT;Google;Cornell Tech",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";Mountain View;New York",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341672",
        "title": "Natural Criteria for Comparison of Pedestrian Flow Forecasting Models",
        "track": "main",
        "status": "Poster",
        "abstract": "Models of human behaviour, such as pedestrian flows, are beneficial for safe and efficient operation of mobile robots. We present a new methodology for benchmarking of pedestrian flow models based on the afforded safety of robot navigation in human-populated environments. While previous evaluations of pedestrian flow models focused on their predictive capabilities, we assess their ability to support safe path planning and scheduling. Using real-world datasets gathered continuously over several weeks, we benchmark state-of-the-art pedestrian flow models, including both time-averaged and time-sensitive models. In the evaluation, we use the learned models to plan robot trajectories and then observe the number of times when the robot gets too close to humans, using a predefined social distance threshold. The experiments show that while traditional evaluation criteria based on model fidelity differ only marginally, the introduced criteria vary significantly depending on the model used, providing a natural interpretation of the expected safety of the system. For the time-averaged flow models, the number of encounters increases linearly with the percentage operating time of the robot, as might be reasonably expected. By contrast, for the time-sensitive models, the number of encounters grows sublinearly with the percentage operating time, by planning to avoid congested areas and times.",
        "primary_area": "",
        "author": "Tom\u00e1\u0161 Vintr;Zhi Yan;Kerem Eyisoy;Filip Kubi\u0161;Jan Blaha;Ji\u0159\u00ed Ulrich;Chittaranjan S. Swaminathan;Sergi Molina;Tomasz P. Kucner;Martin Magnusson;Gregorz Cielniak;Jan Faigl;Tom Duckett;Achim J. Lilienthal;Tom\u00e1\u0161 Krajn\u00edk;Tom\u00e1\u0161 Vintr;Zhi Yan;Kerem Eyisoy;Filip Kubi\u0161;Jan Blaha;Ji\u0159\u00ed Ulrich;Chittaranjan S. Swaminathan;Sergi Molina;Tomasz P. Kucner;Martin Magnusson;Gregorz Cielniak;Jan Faigl;Tom Duckett;Achim J. Lilienthal;Tom\u00e1\u0161 Krajn\u00edk",
        "authorids": "/38229378200;/37086432956;/37088689219;/37088689023;/37088687294;/37088226912;/37086576260;/37086915285;/37085646558;/37584850000;/37550177700;/37540566100;/37419160900;/37273127300;/38547272600;/38229378200;/37086432956;/37088689219;/37088689023;/37088687294;/37088226912;/37086576260;/37086915285;/37085646558;/37584850000;/37550177700;/37540566100;/37419160900;/37273127300;/38547272600",
        "aff": "Artificial Intelligence Center, Czech Technical University; Distributed Artificial Intelligence and Knowledge Laboratory (CIAD), University of Technology of Belfort-Montbeliard (UTBM), France; Department of Computer Engineering, Faculty of Engineering, Marmara University, Turkey; Artificial Intelligence Center, Czech Technical University; Artificial Intelligence Center, Czech Technical University; Artificial Intelligence Center, Czech Technical University; AASS Mobile Robotics and Olfaction Lab, Orebro University, Sweden; Lincoln Centre for Autonomous Systems (L-CAS), University of Lincoln, UK; AASS Mobile Robotics and Olfaction Lab, Orebro University, Sweden; AASS Mobile Robotics and Olfaction Lab, Orebro University, Sweden; Lincoln Centre for Autonomous Systems (L-CAS), University of Lincoln, UK; Artificial Intelligence Center, Czech Technical University; Lincoln Centre for Autonomous Systems (L-CAS), University of Lincoln, UK; AASS Mobile Robotics and Olfaction Lab, Orebro University, Sweden; Artificial Intelligence Center, Czech Technical University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341672/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18037869970182436218&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 13,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 30,
        "aff_unique_index": "0;1;2;0;0;0;3;4;3;3;4;0;4;3;0",
        "aff_unique_norm": "Czech Technical University;University of Technology of Belfort-Montbeliard;Marmara University;Orebro University;University of Lincoln",
        "aff_unique_dep": "Artificial Intelligence Center;Distributed Artificial Intelligence and Knowledge Laboratory (CIAD);Department of Computer Engineering;AASS Mobile Robotics and Olfaction Lab;Lincoln Centre for Autonomous Systems (L-CAS)",
        "aff_unique_url": "https://www.cvut.cz;;https://www.marmara.edu.tr;https://www.oru.se;https://www.lincoln.ac.uk",
        "aff_unique_abbr": "CTU;UTBM;;;UoL",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;2;0;0;0;3;4;3;3;4;0;4;3;0",
        "aff_country_unique": "Czech Republic;France;Turkey;Sweden;United Kingdom"
    },
    {
        "id": "9341409",
        "title": "Navigation on the Line: Traversability Analysis and Path Planning for Extreme-Terrain Rappelling Rovers",
        "track": "main",
        "status": "Poster",
        "abstract": "Many areas of scientific interest in planetary exploration, such as lunar pits, icy-moon crevasses, and Martian craters, are inaccessible to current wheeled rovers. Rappelling rovers can safely traverse these steep surfaces, but require techniques to navigate their complex terrain. This dynamic navigation is inherently time-critical and communication constraints (e.g. delays and small communication windows) will require planetary systems to have some autonomy.Autonomous navigation for Martian rovers is well studied on moderately sloped and locally planar surfaces, but these methods do not readily transfer to tethered systems in non-planar 3D environments. Rappelling rovers in these situations have additional challenges, including terrain-tether interaction and its effects on rover stability, path planning and control.This paper presents novel traversability analysis and path planning algorithms for rappelling rovers operating on steep terrains that account for terrain-tether interaction and the unique stability and reachability constraints of a rapelling system. The system is evaluated with a series of simulations and an analogue mission. In simulation, the planner was shown to reliably find safe paths down a 55 degree slope when a stable tether-terrain configuration exists and never recommended an unsafe path when one did not. In a planetary analogue mission, elements of the system were used to autonomously navigate Axel, a JPL rappelling rover, down a 30 degree slope with 95% autonomy by distance travelled over 46 meters.",
        "primary_area": "",
        "author": "Michael Paton;Marlin P. Strub;Travis Brown;Rebecca J. Greene;Jacob Lizewski;Vandan Patel;Jonathan D. Gammell;Issa A. D. Nesnas;Michael Paton;Marlin P. Strub;Travis Brown;Rebecca J. Greene;Jacob Lizewski;Vandan Patel;Jonathan D. Gammell;Issa A. D. Nesnas",
        "authorids": "/38252759300;/37088505185;/37086409736;/37088686493;/37088690936;/37088686062;/38667468700;/38311902900;/38252759300;/37088505185;/37086409736;/37088686493;/37088690936;/37088686062;/38667468700;/38311902900",
        "aff": "Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA; Oxford Robotics Institute (ORI), Estimation, Search, and Planning (ESP) research group, University of Oxford, United Kingdom; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA; Oxford Robotics Institute (ORI), Estimation, Search, and Planning (ESP) research group, University of Oxford, United Kingdom; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341409/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18016684763651941595&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;0;0;0;0;1;0",
        "aff_unique_norm": "California Institute of Technology;University of Oxford",
        "aff_unique_dep": "Jet Propulsion Laboratory;Oxford Robotics Institute",
        "aff_unique_url": "https://www.caltech.edu;https://www.ox.ac.uk",
        "aff_unique_abbr": "Caltech;Oxford",
        "aff_campus_unique_index": "0;1;0;0;0;0;1;0",
        "aff_campus_unique": "Pasadena;Oxford",
        "aff_country_unique_index": "0;1;0;0;0;0;1;0",
        "aff_country_unique": "United States;United Kingdom"
    },
    {
        "id": "9340792",
        "title": "Navigation-Assistant Path Planning within a MAV team",
        "track": "main",
        "status": "Poster",
        "abstract": "In micro aerial vehicle (MAV) operations, the success of a mission is highly dependent on navigation performance, which has raised recent interests on navigation-aware path planning. One of the challenges lies in that optimal motions for successful navigation and the designated mission are often different in unknown, unstructured environments, and only sub-optimality may be obtained in each aspect. We aim to organize a two-MAV team that can effectively execute the mission and simultaneously guarantee navigation quality, which consists of a main-agent responsible for mission and a sub-agent for navigation of the team. Especially, this paper focuses on path planning of the sub-agent to provide navigational assistance to the main-agent using a monocular camera. We adopt a graph-based receding horizon planner to find a dynamically feasible path in order for the sub-agent to help the main-agent's navigation. In this process, we present a metric for evaluating the localization performance utilizing the distribution of the features projected to the image plane. We also design a map management strategy and pose-estimation support mechanism in a monocular camera setup, and validate their effectiveness in two scenarios.",
        "primary_area": "",
        "author": "Youngseok Jang;Yunwoo Lee;H. Jin Kim;Youngseok Jang;Yunwoo Lee;H. Jin Kim",
        "authorids": "/37087502351;/37088504927;/37599626400;/37087502351;/37088504927;/37599626400",
        "aff": "The Mechanical and Aerospace Engineering Department, Seoul National University, South Korea; The Mechanical and Aerospace Engineering Department, Seoul National University, South Korea; The Mechanical and Aerospace Engineering Department, Seoul National University, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340792/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12677035997819407133&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Seoul National University",
        "aff_unique_dep": "Mechanical and Aerospace Engineering Department",
        "aff_unique_url": "https://www.snu.ac.kr",
        "aff_unique_abbr": "SNU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9340897",
        "title": "Next-Best-View planning for surface reconstruction of large-scale 3D environments with multiple UAVs",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a novel cluster-based Next-Best-View path planning algorithm to simultaneously explore and inspect large-scale unknown environments with multiple Unmanned Aerial Vehicles (UAVs). In the majority of existing informative path-planning methods, a volumetric criterion is used for the exploration of unknown areas, and the presence of surfaces is only taken into account indirectly. Unfortunately, this approach may lead to inaccurate 3D models, with no guarantee of global surface coverage. To perform accurate 3D reconstructions and minimize runtime, we extend our previous online planner based on TSDF (Truncated Signed Distance Function) mapping, to a fleet of UAVs. Sensor configurations to be visited are directly extracted from the map and assigned greedily to the aerial vehicles, in order to maximize the global utility at the fleet level. The performances of the proposed TSGA (TSP-Greedy Allocation) planner and of a nearest neighbor planner have been compared via realistic numerical experiments in two challenging environments (a power plant and the Statue of Liberty) with up to five quadrotor UAVs equipped with stereo cameras.",
        "primary_area": "",
        "author": "Guillaume Hardouin;Julien Moras;Fabio Morbidi;Julien Marzat;El Mustapha Mouaddib;Guillaume Hardouin;Julien Moras;Fabio Morbidi;Julien Marzat;El Mustapha Mouaddib",
        "authorids": "/37088687128;/37706535000;/37301270800;/37857075800;/37443822900;/37088687128;/37706535000;/37301270800;/37857075800;/37443822900",
        "aff": "MIS laboratory, Universit\u00e9 de Picardie Jules Verne, Amiens, France; DTIS, ONERA, Universit\u00e9 Paris-Saclay, Palaiseau, France; MIS laboratory, Universit\u00e9 de Picardie Jules Verne, Amiens, France; DTIS, ONERA, Universit\u00e9 Paris-Saclay, Palaiseau, France; MIS laboratory, Universit\u00e9 de Picardie Jules Verne, Amiens, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340897/",
        "gs_citation": 54,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11366563214842382116&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;1;0",
        "aff_unique_norm": "Universit\u00e9 de Picardie Jules Verne;ONERA",
        "aff_unique_dep": "MIS laboratory;DTIS",
        "aff_unique_url": "https://www.univ-amiens.fr;https://www.onera.fr",
        "aff_unique_abbr": ";ONERA",
        "aff_campus_unique_index": "0;1;0;1;0",
        "aff_campus_unique": "Amiens;Palaiseau",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9340813",
        "title": "No Map, No Problem: A Local Sensing Approach for Navigation in Human-Made Spaces Using Signs",
        "track": "main",
        "status": "Poster",
        "abstract": "Robot navigation in human spaces today largely relies on the construction of precise geometric maps and a global motion plan. In this work, we navigate with only local sensing by using available signage - as designed for humans - in human-made environments such as airports. We propose a formalization of \"signage\" and define 4 levels of signage that we call complete, fully-specified, consistent and valid. The signage formalization can be used on many space skeletonizations, but we specifically provide an approach for navigation on the medial axis. We prove that we can achieve global completeness guarantees without requiring a global map to plan. We validate with two sets of experiments: (1) with real-world airports and their real signs and (2) real New York City neighborhoods. In (1) we show we can use real-world airport signage to improve on a simple random-walk approach, and we explore augmenting signage to further explore signs' impact on trajectory length. In (2), we navigate in varied sized subsets of New York City to show that, since we only use local sensing, our approach scales linearly with trajectory length rather than freespace area.",
        "primary_area": "",
        "author": "Claire Liang;Ross A. Knepper;Florian T. Pokorny;Claire Liang;Ross A. Knepper;Florian T. Pokorny",
        "authorids": "/37086513789;/37530246600;/37077268000;/37086513789;/37530246600;/37077268000",
        "aff": "Department of Computer Science, Cornell University, Ithaca, NY, USA; Department of Computer Science, Cornell University, Ithaca, NY, USA; Division of Robotics, Perception and Learning, EECS, KTH Royal Institute of Technology, Stockholm, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340813/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2933215806414505925&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Cornell University;KTH Royal Institute of Technology",
        "aff_unique_dep": "Department of Computer Science;Division of Robotics, Perception and Learning",
        "aff_unique_url": "https://www.cornell.edu;https://www.kth.se",
        "aff_unique_abbr": "Cornell;KTH",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Ithaca;Stockholm",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "United States;Sweden"
    },
    {
        "id": "9341123",
        "title": "No-Regret Shannon Entropy Regularized Neural Contextual Bandit Online Learning for Robotic Grasping",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a novel contextual bandit algorithm that employs a neural network as a reward estimator and utilizes Shannon entropy regularization to encourage exploration, which is called Shannon entropy regularized neural contextual bandits (SERN). In many learning-based algorithms for robotic grasping, the lack of the real-world data hampers the generalization performance of a model and makes it difficult to apply a trained model to real-world problems. To handle this issue, the proposed method utilizes the benefit of an online learning. The proposed method trains a neural network to predict the success probability of a given grasp pose based on a depth image, which is called a grasp quality. We theoretically show that the SERN has a no regret property. We empirically demonstrate that the SERN outperforms \u03f5-greedy in terms of sample efficiency.",
        "primary_area": "",
        "author": "Kyungjae Lee;Jaegu Choy;Yunho Choi;Hogun Kee;Songhwai Oh;Kyungjae Lee;Jaegu Choy;Yunho Choi;Hogun Kee;Songhwai Oh",
        "authorids": "/493655068209513;/37088446661;/37086069199;/37088506967;/37068116900;/493655068209513;/37088446661;/37086069199;/37088506967;/37068116900",
        "aff": "Department of Electrical and Computer Engineering and ASRI, Seoul National University, Seoul, Korea; Department of Electrical and Computer Engineering and ASRI, Seoul National University, Seoul, Korea; Department of Electrical and Computer Engineering and ASRI, Seoul National University, Seoul, Korea; Department of Electrical and Computer Engineering and ASRI, Seoul National University, Seoul, Korea; Department of Electrical and Computer Engineering and ASRI, Seoul National University, Seoul, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341123/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10921744313368229491&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Seoul National University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.snu.ac.kr",
        "aff_unique_abbr": "SNU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9341587",
        "title": "Non-Linear Trajectory Optimization for Large Step-Ups: Application to the Humanoid Robot Atlas",
        "track": "main",
        "status": "Poster",
        "abstract": "Performing large step-ups is a challenging task for a humanoid robot. It requires the robot to perform motions at the limit of its reachable workspace while straining to move its body upon the obstacle. This paper presents a non-linear trajectory optimization method for generating step-up motions. We adopt a simplified model of the centroidal dynamics to generate feasible Center of Mass trajectories aimed at reducing the torques required for the step-up motion. The activation and deactivation of contacts at both feet are considered explicitly. The output of the planner is a Center of Mass trajectory plus an optimal duration for each walking phase. These desired values are stabilized by a whole-body controller that determines a set of desired joint torques. We experimentally demonstrate that by using trajectory optimization techniques, the maximum torque required to the full-size humanoid robot Atlas can be reduced up to 20% when performing a step-up motion.",
        "primary_area": "",
        "author": "Stefano Dafarra;Sylvain Bertrand;Robert J. Griffin;Giorgio Metta;Daniele Pucci;Jerry Pratt;Stefano Dafarra;Sylvain Bertrand;Robert J. Griffin;Giorgio Metta;Daniele Pucci;Jerry Pratt",
        "authorids": "/37086168241;/37089144753;/37085631429;/37295477800;/37706167200;/37283041800;/37086168241;/37089144753;/37085631429;/37295477800;/37706167200;/37283041800",
        "aff": "Dynamic Interaction Control, Istituto Italiano di Tecnologia, Genova, Italy; Florida Institute for Human and Machine Cognition, IHMC, Pensacola, Florida, United States; Florida Institute for Human and Machine Cognition, IHMC, Pensacola, Florida, United States; Dynamic Interaction Control, Istituto Italiano di Tecnologia, Genova, Italy; Dynamic Interaction Control, Istituto Italiano di Tecnologia, Genova, Italy; Florida Institute for Human and Machine Cognition, IHMC, Pensacola, Florida, United States",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341587/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9168842982493302292&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;0;0;1",
        "aff_unique_norm": "Istituto Italiano di Tecnologia;Florida Institute for Human and Machine Cognition",
        "aff_unique_dep": "Dynamic Interaction Control;",
        "aff_unique_url": "https://www.iit.it;",
        "aff_unique_abbr": "IIT;IHMC",
        "aff_campus_unique_index": "0;1;1;0;0;1",
        "aff_campus_unique": "Genova;Pensacola",
        "aff_country_unique_index": "0;1;1;0;0;1",
        "aff_country_unique": "Italy;United States"
    },
    {
        "id": "9341712",
        "title": "Non-linear control under state constraints with validated trajectories for a mobile robot towing a trailer",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a set-inversion approach to validate the controller of a nonlinear system that should satisfy some state constraints. We introduce the notion of follow set which corresponds to the set of all output vectors such that the desired dynamics can be followed without violating the state-constraints. This follow set can then be used to choose feasible trajectories that a mobile robot will be able to follow. An illustrative example with a robot towing a trailer is presented. This example is motivated by the safe control of a boat towing a marine magnetic sensor to find wrecks.",
        "primary_area": "",
        "author": "Joris Tillet;Luc Jaulin;Fabrice Le Bars;Joris Tillet;Luc Jaulin;Fabrice Le Bars",
        "authorids": "/37088687897;/37375124900;/37088689470;/37088687897;/37375124900;/37088689470",
        "aff": "ENSTA-Bretagne, Brest, France; ENSTA-Bretagne, Brest, France; ENSTA-Bretagne, Brest, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341712/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7982377022982748933&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "ENSTA-Bretagne",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.ensta-bretagne.fr",
        "aff_unique_abbr": "ENSTA-Bretagne",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Brest",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9340825",
        "title": "Non-overlapping RGB-D Camera Network Calibration with Monocular Visual Odometry",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper describes a calibration method for RGB-D camera networks consisting of not only static overlapping, but also dynamic and non-overlapping cameras. The proposed method consists of two steps: online visual odometry-based calibration and depth image-based calibration refinement. It first estimates the transformations between overlapping cameras using fiducial tags, and bridges non-overlapping camera views through visual odometry that runs on a dynamic monocular camera. Parameters such as poses of the static cameras and tags, as well as dynamic camera trajectory, are estimated in the form of the pose graph-based online landmark SLAM. Then, depth-based ICP and floor constraints are added to the pose graph to compensate for the visual odometry error and refine the calibration result. The proposed method is validated through evaluation in simulated and real environments, and a person tracking experiment is conducted to demonstrate the data integration of static and dynamic cameras.",
        "primary_area": "",
        "author": "Kenji Koide;Emanuele Menegatti;Kenji Koide;Emanuele Menegatti",
        "authorids": "/37086179385;/37317887300;/37086179385;/37317887300",
        "aff": "Department of Information Technology and Human Factors, National Institute of Advanced Industrial Science and Technology, Ibaraki, Japan; Department of Information Engineering, University of Padova, Padova, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340825/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8162765956734867046&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "National Institute of Advanced Industrial Science and Technology;University of Padova",
        "aff_unique_dep": "Department of Information Technology and Human Factors;Department of Information Engineering",
        "aff_unique_url": "https://www.aist.go.jp;https://www.unipd.it",
        "aff_unique_abbr": "AIST;UNIPD",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Ibaraki;Padova",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "Japan;Italy"
    },
    {
        "id": "9341235",
        "title": "Noncontact Estimation of Stiffness Based on Optical Coherence Elastography under Acoustic Radiation Pressure",
        "track": "main",
        "status": "Poster",
        "abstract": "In this study, we propose a method of noncontact elastography, which allows us to investigate stiffness of soft structures by combining optical and acoustic modalities. We use optical coherence tomography (OCT) as a means of detecting internal deformation of a sample appearing in response to a mechanical force applied by acoustic radiation pressure. Unlike most of other stiffness sensing, this method can be performed without any contacts between the sample and actuator that generates pressure. To demonstrate the method, we measure the vibration velocity of a uniform phantom made of polyurethane, and characterize the mechanical parameters. We then confirm that the measured and calculated attenuation of the vibration over the depth agree well, which is inaccessible with a conventional laser Doppler vibrometer. This result paves a way to characterize more complex internal structures of soft materials.",
        "primary_area": "",
        "author": "Yuki Hashimoto;Yasuaki Monnai;Yuki Hashimoto;Yasuaki Monnai",
        "authorids": "/37088689686;/37402697700;/37088689686;/37402697700",
        "aff": "Department of Applied Physics and Physico-Informatics, Keio University, Yokohama, Japan; Japan Science and Technology Agency, PRESTO, Kawaguchi, Saitama, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341235/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9168795391398878203&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Keio University;Japan Science and Technology Agency",
        "aff_unique_dep": "Department of Applied Physics and Physico-Informatics;PRESTO",
        "aff_unique_url": "https://www.keio.ac.jp;https://www.jst.go.jp",
        "aff_unique_abbr": "Keio;JST",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Yokohama;",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9341150",
        "title": "Nonlinear Balance Control of an Unmanned Bicycle: Design and Experiments",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, nonlinear control techniques are exploited to balance an unmanned bicycle with enlarged stability domain. We consider two cases. For the first case when the autonomous bicycle is balanced by the flywheel, the steering angle is set to zero, and the torque of the flywheel is used as the control input. The controller is designed based on the Interconnection and Damping Assignment Passivity Based Control (IDA-PBC) method. For the second case when the bicycle is balanced by the handlebar, the bicycle\u2019s velocity is high, and the flywheel is turned off. The angular velocity of the handlebar is used as the control input and the balance controller is designed based on feedback linearization. In these cases, the global stability of the closed-loop unmanned bicycle is theoretically proved based on Lyapunov theory. The experiments are conducted to validate the efficacy of the proposed nonlinear balance controllers.",
        "primary_area": "",
        "author": "Leilei Cui;Shuai Wang;Jie Lai;Xiangyu Chen;Sicheng Yang;Zhengyou Zhang;Zhong-Ping Jiang;Leilei Cui;Shuai Wang;Jie Lai;Xiangyu Chen;Sicheng Yang;Zhengyou Zhang;Zhong-Ping Jiang",
        "authorids": "/37088689192;/37088687660;/37088688811;/37088686410;/37088687616;/37088690693;/37279935100;/37088689192;/37088687660;/37088688811;/37088686410;/37088687616;/37088690693;/37279935100",
        "aff": "Department of Electrical and Computer Engineering, Tandon School of Engineering, Control and Networks Lab, New York University, Brooklyn, NY, USA; Tencent Robotics X, Tencent Holdings, Shenzhen, China; Tencent Robotics X, Tencent Holdings, Shenzhen, China; Tencent Robotics X, Tencent Holdings, Shenzhen, China; Tencent Robotics X, Tencent Holdings, Shenzhen, China; Tencent Robotics X, Tencent Holdings, Shenzhen, China; Department of Electrical and Computer Engineering, Tandon School of Engineering, Control and Networks Lab, New York University, Brooklyn, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341150/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5554507262215178932&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;1;1;1;1;0",
        "aff_unique_norm": "New York University;Tencent Holdings",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Tencent Robotics X",
        "aff_unique_url": "https://www.nyu.edu;https://www.tencent.com",
        "aff_unique_abbr": "NYU;Tencent",
        "aff_campus_unique_index": "0;1;1;1;1;1;0",
        "aff_campus_unique": "Brooklyn;Shenzhen",
        "aff_country_unique_index": "0;1;1;1;1;1;0",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "9340791",
        "title": "Nonlinear model predictive control of hopping model using approximate step-to-step models for navigation on complex terrain",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider the motion planning problem of a hopper navigating a terrain comprising stepping stones while optimizing an energy metric. The most widely used approach of discrete searches (e.g., A-star) cannot handle boundary conditions (e.g., end path constraints on position, velocity). However, continuous optimizations can easily deal with the boundary value problem but are not widely used in motion planning because they are computationally intensive and possibly non-convex when one considers the terrain. Here we use a continuous optimization approach within a model predictive control framework. First, we generate a library comprising initial states at an instant in the locomotion cycle (e.g., apex), the controls (e.g., foot placement, amplitude of force), and the states at the same instant at the next step. Next, we fit these step-to-step models with low order polynomials (typically 2nd or 3rd order). Finally, the planner uses these low order step-to-step models to preview a fixed distance ahead and plans the optimal steps and controls. Thereafter, we implement the plan for the first step, followed by replanning. This process continues until the hopper reaches the end of the terrain. The main contributions are low-order polynomial models for fast computation and incorporation of the complex terrain as a cost function.",
        "primary_area": "",
        "author": "Ali Zamani;Pranav A. Bhounsule;Ali Zamani;Pranav A. Bhounsule",
        "authorids": "/38546396300;/37085401391;/38546396300;/37085401391",
        "aff": "Dept. of Mechanical and Industrial Engineering, University of Illinois at Chicago, Chicago, IL, USA; Dept. of Mechanical and Industrial Engineering, University of Illinois at Chicago, Chicago, IL, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340791/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16975396264799286906&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Illinois at Chicago",
        "aff_unique_dep": "Dept. of Mechanical and Industrial Engineering",
        "aff_unique_url": "https://www.uic.edu",
        "aff_unique_abbr": "UIC",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Chicago",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341366",
        "title": "Novel Design of a Soft Pump Driven by Super-Coiled Polymer Artificial Muscles",
        "track": "main",
        "status": "Poster",
        "abstract": "The widespread use of fluidic actuation for soft robots creates a high demand for soft pumps and compressors. However, current off-the-shelf pumps are usually rigid, noisy, and cumbersome. As a result, it is hard to integrate most commercial pumps into soft robotic systems, which restricts the autonomy and portability of soft robots. This paper presents the novel design of a soft pump based on bellow structure and super-coiled polymer (SCP) artificial muscles. The pump is flexible, lightweight, modular, scalable, quiet, and low cost. The pumping mechanism and fabrication process of the proposed soft pump is demonstrated. A pump prototype is fabricated to verify the proposed design and characterize its performance. From the characterization results, the pump can reach an output flow rate of up to 54 ml/min and delivers pressure up to 2.63 kPa. The pump has potential applications in untethered soft robots and wearable devices.",
        "primary_area": "",
        "author": "Yu Alexander Tse;Ki Wan Wong;Yang Yang;Michael Yu Wang;Yu Alexander Tse;Ki Wan Wong;Yang Yang;Michael Yu Wang",
        "authorids": "/37086842423;/37088686152;/37085714206;/37280913900;/37086842423;/37088686152;/37085714206;/37280913900",
        "aff": "Department of Mechanical and Aerospace Engineering, Hong Kong University of Science and Technology, Hong Kong, China; Department of Mechanical and Aerospace Engineering, Hong Kong University of Science and Technology, Hong Kong, China; School of Automation, Nanjing University of Information Science and Technology, Nanjing, China; Department of Mechanical and Aerospace Engineering, and Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341366/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10648436155184909613&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Hong Kong University of Science and Technology;Nanjing University of Information Science and Technology",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering;School of Automation",
        "aff_unique_url": "https://www.ust.hk;http://www.nuist.edu.cn",
        "aff_unique_abbr": "HKUST;",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Hong Kong;Nanjing",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9340889",
        "title": "Object-Aware Centroid Voting for Monocular 3D Object Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Monocular 3D object detection aims to detect objects in a 3D physical world from a single camera. However, recent approaches either rely on expensive LiDAR devices, or resort to dense pixel-wise depth estimation that causes prohibitive computational cost. In this paper, we propose an end-to-end trainable monocular 3D object detector without learning the dense depth. Specifically, the grid coordinates of a 2D box are first projected back to 3D space with the pinhole model as 3D centroids proposals. Then, a novel object-aware voting approach is introduced, which considers both the region-wise appearance attention and the geometric projection distribution, to vote the 3D centroid proposals for 3D object localization. With the late fusion and the predicted 3D orientation and dimension, the 3D bounding boxes of objects can be detected from a single RGB image. The method is straightforward yet significantly superior to other monocular-based methods. Extensive experimental results on the challenging KITTI benchmark validate the effectiveness of the proposed method.",
        "primary_area": "",
        "author": "Wentao Bao;Qi Yu;Yu Kong;Wentao Bao;Qi Yu;Yu Kong",
        "authorids": "/37085505192;/37404596400;/37530772500;/37085505192;/37404596400;/37530772500",
        "aff": "Golisano College of Computing and Information Sciences (GCCIS), Rochester Institute of Technology, Rochester, NY, USA; Golisano College of Computing and Information Sciences (GCCIS), Rochester Institute of Technology, Rochester, NY, USA; Golisano College of Computing and Information Sciences (GCCIS), Rochester Institute of Technology, Rochester, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340889/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1382779694783974488&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Rochester Institute of Technology",
        "aff_unique_dep": "Golisano College of Computing and Information Sciences",
        "aff_unique_url": "https://www.rit.edu",
        "aff_unique_abbr": "RIT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Rochester",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341694",
        "title": "Objective Functions of Principal Contact Estimation from Motion Based on the Geometrical Singular Condition",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose objective functions to estimate the principal contact between a unknown manipulated target object and its unknown surroundings from the motion of the object. We derived the objective functions based on the fact that contact involves a pair of geometrical primitives (a point of vertex, a line of edge, and a plane of face) for the singular condition of the calculation for their intersection or their spanned space from the point of view of geometrical algebra. The minimization of the proposed objective functions, which are differential quadratic forms of the Kronecker product of geometrical parameters, efficiently provided us the contact geometries that constrained the object movements. Additionally, the proposed objective functions are fundamentals for identifying contact during compliant manipulation, and we showed that the objective functions provide a clue for contact identification via experiments.",
        "primary_area": "",
        "author": "Seiya Ishikawa;Shouhei Shirafuji;Jun Ota;Seiya Ishikawa;Shouhei Shirafuji;Jun Ota",
        "authorids": "/37088687776;/38228063700;/37274082300;/37088687776;/38228063700;/37274082300",
        "aff": "The Department of Precision Engineering, School of Engineering, The University of Tokyo, Tokyo, Japan; Shouhei Shirafuji and Jun Ota are with Research into Artifacts Center, Center for Engineering, School of Engineering, The University of Tokyo, Tokyo, Japan; Shouhei Shirafuji and Jun Ota are with Research into Artifacts Center, Center for Engineering, School of Engineering, The University of Tokyo, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341694/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1525589991977221718&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "The University of Tokyo",
        "aff_unique_dep": "Department of Precision Engineering",
        "aff_unique_url": "https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "UTokyo",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9340748",
        "title": "Observer-Based Disturbance Control for Small-Scale Collaborative Robotics",
        "track": "main",
        "status": "Poster",
        "abstract": "Collaborative robotics allows merging the best capabilities of humans and robots to perform complex tasks. This allows the user to interact with remote and directly inaccessible environments such as the micro-scale world. This interaction is made possible by the bidirectional exchange of information (displacement - force) between the user and the environment through a haptic interface. The effectiveness of the human/robot interaction is highly dependent on how the human feels the forces. This is a key point to enable humans to make the right decisions in a collaborative task. This paper discusses the design of a dynamic observer to estimate the forces applied by a human operator on a class of parallel pantograph-type haptic interfaces used to control small-scale robotic systems. The objective is to reject disturbances in order to improve the human force perception capability over a wide frequency range. A dynamic pantograph model is proposed and experimentally validated. The observer is designed on the basis of the proposed dynamic model and its efficiency in estimating the applied human force is demonstrated for the first time with pantograph-type interfaces. Experimental validation first shows the effectiveness of the perturbation observer for external human force estimation with a response time of less than 0.2 s and a mean error of less than 7 mN and then the effectiveness of the controller in improving the quality of human sensation of forces down to 10 mN.",
        "primary_area": "",
        "author": "Ahmad Awde;Mokrane Boudaoud;St\u00e9phane R\u00e9gnier;C\u00e9dric Cl\u00e9vy;Ahmad Awde;Mokrane Boudaoud;St\u00e9phane R\u00e9gnier;C\u00e9dric Cl\u00e9vy",
        "authorids": "/37088687143;/37594372000;/37283234800;/37424301600;/37088687143;/37594372000;/37283234800;/37424301600",
        "aff": "UMR 7222, ISIR, Sorbonne Universit\u00e9, Institut des Syst\u00e8mes Intelligents et de Robotique, Paris, France; UMR 7222, ISIR, Sorbonne Universit\u00e9, Institut des Syst\u00e8mes Intelligents et de Robotique, Paris, France; UMR 7222, ISIR, Sorbonne Universit\u00e9, Institut des Syst\u00e8mes Intelligents et de Robotique, Paris, France; FEMTO-ST, UFC/CNRS/ENSMM, Univ. Bourgogne Franche-Comt\u00e9, Besancon, FRANCE",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340748/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17240270507499034228&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Sorbonne Universit\u00e9;FEMTO-ST Institute",
        "aff_unique_dep": "Institut des Syst\u00e8mes Intelligents et de Robotique;",
        "aff_unique_url": "https://www.sorbonne-universite.fr;",
        "aff_unique_abbr": "Sorbonne U;FEMTO-ST",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "Paris;Besancon",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9341785",
        "title": "Observer-based Control of Inflatable Robot with Variable Stiffness",
        "track": "main",
        "status": "Poster",
        "abstract": "In the last decade, soft robots have been at the forefront of a robotic revolution. Due to the flexibility of the soft materials employed, soft robots are equipped with a capability to execute new tasks in new application areas -beyond what can be achieved using classical rigid-link robots. Despite these promising properties, many soft robots nowadays lack the capability to exert sufficient force to perform various real-life tasks. This has led to the development of stiffness-controllable inflatable robots instilled with the ability to modify their stiffness during motion. This new capability, however, poses an even greater challenge for robot control. In this paper, we propose a model-based kinematic control strategy to guide the tip of an inflatable robot arm in its environment. The bending of the robot is modelled using an Euler-Bernoulli beam theory which takes into account the variation of the robot's structural stiffness. The parameters of the model are estimated online using an observer based on the Extended Kalman Filter (EKF). The parameters' estimates are used to approximate the Jacobian matrix online and used to control the robot's tip considering also variations in the robot's stiffness. Simulation results and experiments using a fabric-based planar 3-degree-of-freedom (DOF) inflatable manipulators demonstrate the promising performance of the proposed control algorithm.",
        "primary_area": "",
        "author": "Ahmad Ataka;Taqi Abrar;Fabrizio Putzu;Hareesh Godaba;Kaspar Althoefer;Ahmad Ataka;Taqi Abrar;Fabrizio Putzu;Hareesh Godaba;Kaspar Althoefer",
        "authorids": "/37085781916;/37086477644;/37086478870;/37085735503;/37265264700;/37085781916;/37086477644;/37086478870;/37085735503;/37265264700",
        "aff": "Centre for Advanced Robotics @ Queen Mary (ARQ), Faculty of Science and Engineering, Queen Mary University of London, London, United Kingdom; Centre for Advanced Robotics @ Queen Mary (ARQ), Faculty of Science and Engineering, Queen Mary University of London, London, United Kingdom; Centre for Advanced Robotics @ Queen Mary (ARQ), Faculty of Science and Engineering, Queen Mary University of London, London, United Kingdom; Centre for Advanced Robotics @ Queen Mary (ARQ), Faculty of Science and Engineering, Queen Mary University of London, London, United Kingdom; Centre for Advanced Robotics @ Queen Mary (ARQ), Faculty of Science and Engineering, Queen Mary University of London, London, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341785/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8759769806554037143&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Queen Mary University of London",
        "aff_unique_dep": "Faculty of Science and Engineering",
        "aff_unique_url": "https://www.qmul.ac.uk",
        "aff_unique_abbr": "QMUL",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9341329",
        "title": "Occlusion Handling for Industrial Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Industrial robots contain minimal sensing capability beyond recognition of their internal state. It is critical that an external vision system should cover the designated robot work space with awareness of blind spots and occlusions. This work presents two mechanisms to handle occlusions in an external multi-robot vision system: occlusion-aware optimal sensor positioning, and event-driven occlusion detection. When deploying sensors to the system, various scenarios are considered during optimization to reduce potential occlusions and increase sensor coverage. These methods are tested on a working cell with three industrial robot arms. The experimental results demonstrate the effectiveness of the proposed scenario-based multi-objective optimization for sensor positioning. Once the sensors are deployed, occlusion detection is actively triggered prior to robot path planning.",
        "primary_area": "",
        "author": "Ling Zhu;Meghna Menon;Mario Santillo;Gregory Linkowski;Ling Zhu;Meghna Menon;Mario Santillo;Gregory Linkowski",
        "authorids": "/37088071425;/37088691368;/37300853000;/37088689479;/37088071425;/37088691368;/37300853000;/37088689479",
        "aff": "Ford Motor Company, Research and Advanced Engineering, Dearborn, MI, United States; Ford Motor Company, Research and Advanced Engineering, Dearborn, MI, United States; Ford Motor Company, Research and Advanced Engineering, Dearborn, MI, United States; Ford Motor Company, Research and Advanced Engineering, Dearborn, MI, United States",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341329/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9956361163980686162&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Ford Motor Company",
        "aff_unique_dep": "Research and Advanced Engineering",
        "aff_unique_url": "https://www.ford.com",
        "aff_unique_abbr": "Ford",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Dearborn",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341355",
        "title": "Occlusion-Robust MVO: Multimotion Estimation Through Occlusion Via Motion Closure",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual motion estimation is an integral and well-studied challenge in autonomous navigation. Recent work has focused on addressing multimotion estimation, which is especially challenging in highly dynamic environments. Such environments not only comprise multiple, complex motions but also tend to exhibit significant occlusion.Previous work in object tracking focuses on maintaining the integrity of object tracks but usually relies on specific appearance-based descriptors or constrained motion models. These approaches are very effective in specific applications but do not generalize to the full multimotion estimation problem.This paper presents a pipeline for estimating multiple motions, including the camera egomotion, in the presence of occlusions. This approach uses an expressive motion prior to estimate the SE(3) trajectory of every motion in the scene, even during temporary occlusions, and identify the reappearance of motions through motion closure. The performance of this occlusion-robust multimotion visual odometry (MVO) pipeline is evaluated on real-world data and the Oxford Multimotion Dataset.",
        "primary_area": "",
        "author": "Kevin M. Judd;Jonathan D. Gammell;Kevin M. Judd;Jonathan D. Gammell",
        "authorids": "/37086579055;/38667468700;/37086579055;/38667468700",
        "aff": "Estimation, Search, and Planning (ESP) research group, Oxford Robotics Institute (ORI), University of Oxford, United Kingdom; Estimation, Search, and Planning (ESP) research group, Oxford Robotics Institute (ORI), University of Oxford, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341355/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5884000986879809735&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Oxford",
        "aff_unique_dep": "Oxford Robotics Institute",
        "aff_unique_url": "https://www.ox.ac.uk",
        "aff_unique_abbr": "Oxford",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Oxford",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9341591",
        "title": "OceanVoy: A Hybrid Energy Planning System for Autonomous Sailboat",
        "track": "main",
        "status": "Poster",
        "abstract": "Towards long range and high endurance sailing, energy is of utmost importance. Moreover, benefiting from the dominance of the sailboat itself, it is energy-saving and environment-friendly. Thus, the sailboat with energy planning problem is meaningful. However, until now, the sailboat energy optimization problem has rarely been considered. In this paper, we focus on the energy consumption optimization of an autonomous sailboat. It has been formulated as a Nonlinear Programming problem (NLP). We deal with it with a hybrid control scheme, in which pseudo-spectral (PS) optimal control method is used in heading control, and a model-free framework guided by Extreme Seeking Control (ESC) is used in sail control. The optimal path is generated with the optimal input motor torques in time series. As a result, both simulation and experiments have validated motion planning and energy planning performance. Notably, about 7% of energy is saved on average. Our proposed method can make sailboats sailing longer and sustainable.",
        "primary_area": "",
        "author": "Qinbo Sun;Weimin Qi;Hengli Liu;Zhenglong Sun;Tin Lun Lam;Huihuan Qian;Qinbo Sun;Weimin Qi;Hengli Liu;Zhenglong Sun;Tin Lun Lam;Huihuan Qian",
        "authorids": "/37086608896;/37087243921;/37086607474;/37086799406;/37571111600;/37549401900;/37086608896;/37087243921;/37086607474;/37086799406;/37571111600;/37549401900",
        "aff": "The Chinese University of Hong Kong, Shenzhen; The Chinese University of Hong Kong, Shenzhen; Peng Cheng Laboratory, Shenzhen; The Chinese University of Hong Kong, Shenzhen; The Chinese University of Hong Kong, Shenzhen; The Chinese University of Hong Kong, Shenzhen",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341591/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=362203788008555781&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;0;0;0",
        "aff_unique_norm": "The Chinese University of Hong Kong;Peng Cheng Laboratory",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.cuhk.edu.cn;",
        "aff_unique_abbr": "CUHK;",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Shenzhen;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9340768",
        "title": "On Parameter Estimation of Flexible Space Manipulator Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "Space manipulator systems in orbit are subject to link flexibilities since they are designed to be lightweight and long reaching. Often, their joints are driven by harmonic gear-motor units, which introduce joint flexibility. Both of these types of flexibility may cause structural vibrations. To improve endpoint tracking, advanced control strategies that benefit from the knowledge of system parameters, including those describing link and joint flexibilities, are required. In this paper, first, the equations of motion of space manipulator systems whose manipulators are subject to both link and joint flexibilities are derived. Then, a parameter estimation method is developed, based on the energy balance during the motion of a flexible space manipulator. The method estimates all system parameters including those that describe both link and joint flexibilities and can reconstruct the system full dynamics required for the application of advanced control strategies. The method, developed for spatial systems, is illustrated by a planar example.",
        "primary_area": "",
        "author": "Olga-Orsalia Christidi-Loumpasefski;Kostas Nanos;Evangelos Papadopoulos;Olga-Orsalia Christidi-Loumpasefski;Kostas Nanos;Evangelos Papadopoulos",
        "authorids": "/37087990228;/37563773900;/37273090500;/37087990228;/37563773900;/37273090500",
        "aff": "School of Mechanical Engineering, National Technical University of Athens, Greece; School of Mechanical Engineering, National Technical University of Athens, Greece; School of Mechanical Engineering, National Technical University of Athens, Greece",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340768/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2920548175667832024&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "National Technical University of Athens",
        "aff_unique_dep": "School of Mechanical Engineering",
        "aff_unique_url": "https://www.ntua.gr",
        "aff_unique_abbr": "NTUA",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Greece"
    },
    {
        "id": "9341651",
        "title": "On Screw Linear Interpolation for Point-to-Point Path Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Robot motion is controlled in the joint space whereas the robots have to perform tasks in their task space. Many tasks like carrying a glass of liquid, pouring liquid, opening a drawer requires constraints on the end-effector during the motion. The forward and inverse kinematic mappings between joint space and task space are highly nonlinear and multi-valued (for IK). Consequently, modeling task space constraints like keeping the orientation of the end-effector fixed while changing its position (which is required for carrying a cup of liquid without dropping it) is quite complex in the joint space. In this paper, we show that the use of screw linear interpolation to plan motions in the task space combined with resolved motion rate control to compute the corresponding joint space path, allows one to satisfy many common task space motion constraints in motion planning, without explicitly modeling them. In particular, any motion constraint that forms a subgroup of the group of rigid body motions can be incorporated in our planning scheme, without explicit modeling. We present simulation and experimental results on Baxter robot for different tasks with task space constraints that demonstrates the usefulness of our approach.",
        "primary_area": "",
        "author": "Anik Sarker;Anirban Sinha;Nilanjan Chakraborty;Anik Sarker;Anirban Sinha;Nilanjan Chakraborty",
        "authorids": "/37088687279;/37086936771;/37314871600;/37088687279;/37086936771;/37314871600",
        "aff": "Department of Mechanical Engineering, Stony Brook University, Stony Brook, NY; Department of Mechanical Engineering, Stony Brook University, Stony Brook, NY; Department of Mechanical Engineering, Stony Brook University, Stony Brook, NY",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341651/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16685943777501742941&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Stony Brook University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.stonybrook.edu",
        "aff_unique_abbr": "SBU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Stony Brook",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341721",
        "title": "On a videoing control system based on object detection and tracking",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a camera control system towards occasionally videoing preassigned objects. Based on the technique of real-time visual detection and tracking, using the Kalman filter and re-identification (ReID), we propose continuous composition of lens, based on the atomic rules of shots, and give the trajectory planning of the camera, to generate the PID controller to the pan-tilt. By both simulation and emulation by frame-wise cropping of video clips, we illustrate the efficiency of this method. Based on this model, we design and produce an AI automatic camera for lively photography and clip videoing.",
        "primary_area": "",
        "author": "Yanhao Ren;Yi Wang;Qi Tang;Haijun Jiang;Wenlian Lu;Yanhao Ren;Yi Wang;Qi Tang;Haijun Jiang;Wenlian Lu",
        "authorids": "/37088688500;/37088689236;/37088690624;/37088686170;/37278863700;/37088688500;/37088689236;/37088690624;/37088686170;/37278863700",
        "aff": "Shanghai Center for Mathematical Sciences, Fudan University, Shanghai, China; Fantasy Power (Shanghai) Culture Communication Co., Ltd., Shanghai, China; Fantasy Power (Shanghai) Culture Communication Co., Ltd., Shanghai, China; Fantasy Power (Shanghai) Culture Communication Co., Ltd., Shanghai, China; Shanghai Key Laboratory for Contemporary Applied Mathematics, Fudan University, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341721/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7382301136301502831&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;0",
        "aff_unique_norm": "Fudan University;Fantasy Power (Shanghai) Culture Communication Co., Ltd.",
        "aff_unique_dep": "Shanghai Center for Mathematical Sciences;",
        "aff_unique_url": "https://www.fudan.edu.cn/en/;",
        "aff_unique_abbr": "Fudan;",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Shanghai;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9341679",
        "title": "On the use of (lockable) parallel elasticity in active prosthetic ankles",
        "track": "main",
        "status": "Poster",
        "abstract": "New challenges arise when investigating the use of active prostheses for lower limb replacement, such as high motor power requirements, leading to increased weight and reduced autonomy. Series and parallel elasticity are often explored to reduce the necessary motor power but often the effect on the energy consumption of the prosthesis is not directly investigated, as the mechanical power properties are examined yet the motor and gearbox dynamics and efficiencies are not considered. This paper presents the investigation of a parallel elasticity compared to a series elastic actuation system used in an active ankle prosthesis. Using a matched electromechanical model of the actuator shows that the electrical efficiency can be influenced using parallel elasticity. The optimal configuration depends on the motor characteristics (dynamic behavior) and limitations, which should always be taken into account when designing optimal series and parallel springs. It has been shown that adding parallel elasticity allows to reduce the required gear ratio and thus associated friction and inertial losses. Allowing the parallel elasticity to be lockable can further influence the behavior and allow for a more versatile actuator.",
        "primary_area": "",
        "author": "Joost Geeroms;Louis Flynn;Vincent Ducastel;Bram Vanderborght;Dirk Lefeber;Joost Geeroms;Louis Flynn;Vincent Ducastel;Bram Vanderborght;Dirk Lefeber",
        "authorids": "/37085393388;/37528527900;/37087045315;/37295389300;/37295410400;/37085393388;/37528527900;/37087045315;/37295389300;/37295410400",
        "aff": "R&MM research group, Vrije Universiteit Brussel and Flanders Make, Brussels, Belgium; R&MM research group, Vrije Universiteit Brussel and Flanders Make, Brussels, Belgium; R&MM research group, Vrije Universiteit Brussel and Flanders Make, Brussels, Belgium; R&MM research group, Vrije Universiteit Brussel and Flanders Make, Brussels, Belgium; R&MM research group, Vrije Universiteit Brussel and Flanders Make, Brussels, Belgium",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341679/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14233073842455846095&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Vrije Universiteit Brussel",
        "aff_unique_dep": "R&MM research group",
        "aff_unique_url": "https://www.vub.be",
        "aff_unique_abbr": "VUB",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Brussels",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Belgium"
    },
    {
        "id": "9341336",
        "title": "On-chip integration of ultra-thin glass cantilever for physical property measurement activated by femtosecond laser impulse",
        "track": "main",
        "status": "Poster",
        "abstract": "Under the excitation of acoustic radiation, the amount of energy absorbed and rebounded by cells have the relationship with mechanical properties, e.g. stiffness, shape, weight and so on. In this paper, a femtosecond laser-activated micro-detector is designed to convert this relationship into an electrical signal. First, the acoustic radiation is generated by a femtosecond laser pulse in a microchannel and acts on neighbor cells / beads. Then, an ultra-thin glass sheet (UTGS)-based pressure sensor (cantilever) is fabricated at the bottom of the microfluidic chip to monitor changes in acoustic pressure during detection process. In this detection system, the pressure sensor is fabricated with a 10 \u03bcm UTGS in a shape of rectangular cantilever and functions like a detector to convert acoustic waves into shift response. Based on the amplitude of detected pulses, we can directly analyze the acoustic energy, coming from either femtosecond laser pulse or that remains after penetrating target cells. We have taken experiments on 10 \u03bcm beads and verified the applicability of this micro-detector, and the proposed method has great potential to be applied in label-free cell manipulation (i.e., sorting) as a detection mechanism.",
        "primary_area": "",
        "author": "Tao Tang;Yansheng Hao;Yigang Shen;Yo Tanaka;Ming Huang;Yoichiroh Hosokawa;Ming Li;Yaxiaer Yalikun;Tao Tang;Yansheng Hao;Yigang Shen;Yo Tanaka;Ming Huang;Yoichiroh Hosokawa;Ming Li;Yaxiaer Yalikun",
        "authorids": "/37088691443;/37088690457;/37088687422;/37086047262;/37088688050;/37074003500;/37088689085;/37085644269;/37088691443;/37088690457;/37088687422;/37086047262;/37088688050;/37074003500;/37088689085;/37085644269",
        "aff": "Graduate School of Material Science, Nara Institute of Science and Technology, Nara, JAPAN; Graduate School of Material Science, Nara Institute of Science and Technology, Nara, JAPAN; Center for Biosystems Dynamics Research (BDR), RIKEN, Osaka, Japan; Center for Biosystems Dynamics Research (BDR), RIKEN, Osaka, Japan; Graduate School of Material Science, Nara Institute of Science and Technology, Nara, JAPAN; Graduate School of Material Science, Nara Institute of Science and Technology, Nara, JAPAN; School of Engineering, Macquarie University, Sydney, Australia; Graduate School of Material Science, Nara Institute of Science and Technology, Nara, JAPAN",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341336/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10684782609322571751&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;1;1;0;0;2;0",
        "aff_unique_norm": "Nara Institute of Science and Technology;RIKEN;Macquarie University",
        "aff_unique_dep": "Graduate School of Material Science;Center for Biosystems Dynamics Research (BDR);School of Engineering",
        "aff_unique_url": "https://www.nist.go.jp;https://www.riken.jp;https://www.mq.edu.au",
        "aff_unique_abbr": "NIST;RIKEN;MQ",
        "aff_campus_unique_index": "0;0;1;1;0;0;2;0",
        "aff_campus_unique": "Nara;Osaka;Sydney",
        "aff_country_unique_index": "0;0;0;0;0;0;1;0",
        "aff_country_unique": "Japan;Australia"
    },
    {
        "id": "9340936",
        "title": "On-plate localization and mapping for an inspection robot using ultrasonic guided waves: a proof of concept",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a proof-of-concept for a localization and mapping system for magnetic crawlers performing inspection tasks on structures made of large metal plates. By relying on ultrasonic guided waves reflected from the plate edges, we show that it is possible to recover the plate geometry and robot trajectory to a precision comparable to the signal wavelength. The approach is tested using real acoustic signals acquired on metal plates using lawn-mower paths and random-walks. To the contrary of related works, this paper focuses on the practical details of the localization and mapping algorithm.",
        "primary_area": "",
        "author": "C\u00e9dric Pradalier;Othmane-Latif Ouabi;Pascal Pomarede;Jan Steckel;C\u00e9dric Pradalier;Othmane-Latif Ouabi;Pascal Pomarede;Jan Steckel",
        "authorids": "/37279005400;/37088587191;/37088689973;/37885021400;/37279005400;/37088587191;/37088689973;/37885021400",
        "aff": "GeorgiaTech Lorraine, UMI2958 GT-CNRS in Metz, France; GeorgiaTech Lorraine, UMI2958 GT-CNRS in Metz, France; GeorgiaTech Lorraine, UMI2958 GT-CNRS in Metz, France; Flanders Make Strategic Research Center, Lommel, Belgium",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340936/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6912342685824259734&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Georgia Institute of Technology;Flanders Make Strategic Research Center",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.gatech.edu;",
        "aff_unique_abbr": "GeorgiaTech;",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "Lorraine;Lommel",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "France;Belgium"
    },
    {
        "id": "9340914",
        "title": "One-Shot Informed Robotic Visual Search in the Wild",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider the task of underwater robot navigation for the purpose of collecting scientifically relevant video data for environmental monitoring. The majority of field robots that currently perform monitoring tasks in unstructured natural environments navigate via path-tracking a pre-specified sequence of waypoints. Although this navigation method is often necessary, it is limiting because the robot does not have a model of what the scientist deems to be relevant visual observations. Thus, the robot can neither visually search for particular types of objects, nor focus its attention on parts of the scene that might be more relevant than the pre-specified waypoints and viewpoints. In this paper we propose a method that enables informed visual navigation via a learned visual similarity operator that guides the robot's visual search towards parts of the scene that look like an exemplar image, which is given by the user as a high-level specification for data collection. We propose and evaluate a weakly supervised video representation learning method that outperforms ImageNet embeddings for similarity tasks in the underwater domain. We also demonstrate the deployment of this similarity operator during informed visual navigation in collaborative environmental monitoring scenarios, in large-scale field trials, where the robot and a human scientist collaboratively search for relevant visual content. Code: https://github.com/rvl-lab-utoronto/visual_search_in_the_wild.",
        "primary_area": "",
        "author": "Karim Koreitem;Florian Shkurti;Travis Manderson;Wei-Di Chang;Juan Camilo Gamboa Higuera;Gregory Dudek;Karim Koreitem;Florian Shkurti;Travis Manderson;Wei-Di Chang;Juan Camilo Gamboa Higuera;Gregory Dudek",
        "authorids": "/37086061783;/37706697200;/38491501400;/37087686169;/37085572056;/37274057100;/37086061783;/37706697200;/38491501400;/37087686169;/37085572056;/37274057100",
        "aff": "Department of Computer Science, the Robotics Institute at the University of Toronto, and Vector Institute; Department of Computer Science, the Robotics Institute at the University of Toronto, and Vector Institute; Center for Intelligent Machines, School of Computer Science, McGill University, Montreal; Center for Intelligent Machines, School of Computer Science, McGill University, Montreal; Center for Intelligent Machines, School of Computer Science, McGill University, Montreal; Center for Intelligent Machines, School of Computer Science, McGill University, Montreal",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340914/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2563639500235878035&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;1;1;1",
        "aff_unique_norm": "University of Toronto;McGill University",
        "aff_unique_dep": "Department of Computer Science;School of Computer Science",
        "aff_unique_url": "https://www.utoronto.ca;https://www.mcgill.ca",
        "aff_unique_abbr": "U of T;McGill",
        "aff_campus_unique_index": "0;0;1;1;1;1",
        "aff_campus_unique": "Toronto;Montreal",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9341401",
        "title": "Online BayesSim for Combined Simulator Parameter Inference and Policy Improvement",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent advancements in Bayesian likelihood-free inference enables a probabilistic treatment for the problem of estimating simulation parameters and their uncertainty given sequences of observations. Domain randomization can be performed much more effectively when a posterior distribution provides the correct uncertainty over parameters in a simulated environment. In this paper, we study the integration of simulation parameter inference with both model-free reinforcement learning and model-based control in a novel sequential algorithm that alternates between learning a better estimation of parameters and improving the controller. This approach exploits the interdependence between the two problems to generate computational efficiencies and improved reliability when a black-box simulator is available. Experimental results suggest that both control strategies have better performance when compared to traditional domain randomization methods.",
        "primary_area": "",
        "author": "Rafael Possas;Lucas Barcelos;Rafael Oliveira;Dieter Fox;Fabio Ramos;Rafael Possas;Lucas Barcelos;Rafael Oliveira;Dieter Fox;Fabio Ramos",
        "authorids": "/37088507203;/37088505462;/37086456041;/37284329000;/37285364500;/37088507203;/37088505462;/37086456041;/37284329000;/37285364500",
        "aff": "University of Sydney; University of Sydney; University of Sydney; University of Washington; University of Sydney",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341401/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12072529473629658161&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "University of Sydney;University of Washington",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.sydney.edu.au;https://www.washington.edu",
        "aff_unique_abbr": "USYD;UW",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "Australia;United States"
    },
    {
        "id": "9341453",
        "title": "Online Configuration Selection for Redundant Arrays of Inertial Sensors: Application to Robotic Systems Covered with a Multimodal Artificial Skin",
        "track": "main",
        "status": "Poster",
        "abstract": "",
        "primary_area": "",
        "author": "Quentin Leboutet;Florian Bergner;Gordon Cheng;Quentin Leboutet;Florian Bergner;Gordon Cheng",
        "authorids": "/37086138878;/37085742718;/37276253300;/37086138878;/37085742718;/37276253300",
        "aff": "",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341453/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1040009880565979216&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6
    },
    {
        "id": "9340967",
        "title": "Online Dynamic Motion Planning and Control for Wheeled Biped Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Wheeled-legged robots combine the efficiency of wheeled robots when driving on suitably flat surfaces and versatility of legged robots when stepping over or around obstacles. This paper introduces a planning and control framework to realise dynamic locomotion for wheeled biped robots. We propose the Cart-Linear Inverted Pendulum Model (Cart-LIPM) as a template model for the rolling motion and the under-actuated LIPM for contact changes while walking. The generated motion is then tracked by an inverse dynamic whole-body controller which coordinates all joints, including the wheels. The framework has a hierarchical structure and is implemented in a model predictive control (MPC) fashion. To validate the proposed approach for hybrid motion generation, two scenarios involving different types of obstacles are designed in simulation. To the best of our knowledge, this is the first time that such online dynamic hybrid locomotion has been demonstrated on wheeled biped robots.",
        "primary_area": "",
        "author": "Songyan Xin;Sethu Vijayakumar;Songyan Xin;Sethu Vijayakumar",
        "authorids": "/37086099765;/37295595500;/37086099765;/37295595500",
        "aff": "Shenzhen Institute for Artificial Intelligence and Robotics for Society (AIRS), The Chinese University of Hong Kong (Shenzhen), China; School of Informatics, University of Edinburgh, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340967/",
        "gs_citation": 42,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8906648266911567676&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "The Chinese University of Hong Kong (Shenzhen);University of Edinburgh",
        "aff_unique_dep": "Shenzhen Institute for Artificial Intelligence and Robotics for Society (AIRS);School of Informatics",
        "aff_unique_url": "https://www.siat.ac.cn;https://www.ed.ac.uk",
        "aff_unique_abbr": "CUHK(SZ);Edinburgh",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Shenzhen;Edinburgh",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "China;United Kingdom"
    },
    {
        "id": "9341792",
        "title": "Online Explanation Generation for Planning Tasks in Human-Robot Teaming",
        "track": "main",
        "status": "Poster",
        "abstract": "As AI becomes an integral part of our lives, the development of explainable AI, embodied in the decision-making process of an AI or robotic agent, becomes imperative. For a robotic teammate, the ability to generate explanations to justify its behavior is one of the key requirements of explainable agency. Prior work on explanation generation has been focused on supporting the rationale behind the robot's decision or behavior. These approaches, however, fail to consider the mental demand for understanding the received explanation. In other words, the human teammate is expected to understand an explanation no matter how much information is presented. In this work, we argue that explanations, especially those of a complex nature, should be made in an online fashion during the execution, which helps spread out the information to be explained and thus reduce the mental workload of humans in highly cognitive demanding tasks. However, a challenge here is that the different parts of an explanation may be dependent on each other, which must be taken into account when generating online explanations. To this end, a general formulation of online explanation generation is presented with three variations satisfying different \"online\" properties. The new explanation generation methods are based on a model reconciliation setting introduced in our prior work. We evaluated our methods both with human subjects in a simulated rover domain, using NASA Task Load Index (TLX), and synthetically with ten different problems across two standard IPC domains. Results strongly suggest that our methods generate explanations that are perceived as less cognitively demanding and much preferred over the baselines and are computationally efficient.",
        "primary_area": "",
        "author": "Mehrdad Zakershahrak;Ze Gong;Nikhillesh Sadassivam;Yu Zhang;Mehrdad Zakershahrak;Ze Gong;Nikhillesh Sadassivam;Yu Zhang",
        "authorids": "/37086512489;/37086453818;/37088688024;/37086071738;/37086512489;/37086453818;/37088688024;/37086071738",
        "aff": "School of Computing, Informatics and Decision Systems Engineering, Arizona State University, Tempe, AZ; School of Computing, Informatics and Decision Systems Engineering, Arizona State University, Tempe, AZ; School of Computing, Informatics and Decision Systems Engineering, Arizona State University, Tempe, AZ; School of Computing, Informatics and Decision Systems Engineering, Arizona State University, Tempe, AZ",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341792/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18027592067890402148&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Arizona State University",
        "aff_unique_dep": "School of Computing, Informatics and Decision Systems Engineering",
        "aff_unique_url": "https://www.asu.edu",
        "aff_unique_abbr": "ASU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Tempe",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341170",
        "title": "Online Exploration of Tunnel Networks Leveraging Topological CNN-based World Predictions",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic exploration requires adaptively selecting navigation goals that result in the rapid discovery and mapping of an unknown world. In many real-world environments, subtle structural cues can provide insight about the unexplored world, which may be exploited by a decision maker to improve the speed of exploration. In sparse subterranean tunnel networks, these cues come in the form of topological features, such as loops or dead-ends, that are often common across similar environments. We propose a method for learning these topological features using techniques borrowed from topological image segmentation and image inpainting to learn from a database of worlds. These world predictions then inform a frontier-based exploration policy. Our simulated experiments with a set of real-world mine environments and a database of procedurally-generated artificial tunnel networks demonstrate a substantial increase in the rate of area explored compared to techniques that do not attempt to predict and exploit topological features of the unexplored world.",
        "primary_area": "",
        "author": "Manish Saroya;Graeme Best;Geoffrey A. Hollinger;Manish Saroya;Graeme Best;Geoffrey A. Hollinger",
        "authorids": "/37086179727;/37085672100;/37543482700;/37086179727;/37085672100;/37543482700",
        "aff": "Collaborative Robotics and Intelligent Systems (CoRIS) Institute, Oregon State University, Corvallis, OR, USA; Collaborative Robotics and Intelligent Systems (CoRIS) Institute, Oregon State University, Corvallis, OR, USA; Collaborative Robotics and Intelligent Systems (CoRIS) Institute, Oregon State University, Corvallis, OR, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341170/",
        "gs_citation": 36,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16823555276293848829&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Oregon State University",
        "aff_unique_dep": "Collaborative Robotics and Intelligent Systems (CoRIS) Institute",
        "aff_unique_url": "https://oregonstate.edu",
        "aff_unique_abbr": "OSU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Corvallis",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340793",
        "title": "Online Localization with Imprecise Floor Space Maps using Stochastic Gradient Descent",
        "track": "main",
        "status": "Poster",
        "abstract": "Many indoor spaces have constantly changing layouts and may not be mapped by an autonomous vehicle, yet maps such as floor plans or evacuation maps of these places are common. We propose a method for an autonomous robot to localize itself on such maps with inconsistent scale using Stochastic Gradient Descent (SGD) with scan matching using a 2D LiDAR. We also introduce a new scale state in 2D localization to manage the possible inconsistent scale of the input map. Experiments are conducted in an indoor corridor using three different input maps - a point cloud, a floor plan, and a hand-drawn map. The SGD localization algorithm is bench-marked to Adaptive Monte Carlo Localization (AMCL). In a point cloud mapped environment, our algorithm achieves 0.264m and 5.26\u00b0 average position and heading error respectively. On the hand-drawn map, our SGD localization algorithm remains robust while AMCL fails. The role of the scale state in our SGD localization algorithm is demonstrated in poorly scaled maps.",
        "primary_area": "",
        "author": "Zhikai Li;Marcelo H. Ang;Daniela Rus;Zhikai Li;Marcelo H. Ang;Daniela Rus",
        "authorids": "/37088691256;/37279138700;/37279652300;/37088691256;/37279138700;/37279652300",
        "aff": "Singapore-MIT Alliance for Research and Technology (SMART) Centre, Singapore; National University of Singapore, Singapore; Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340793/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10077616125232600582&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Singapore-MIT Alliance for Research and Technology (SMART) Centre;National University of Singapore;Massachusetts Institute of Technology",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://smart.mit.edu/;https://www.nus.edu.sg;https://www.mit.edu",
        "aff_unique_abbr": "SMART Centre;NUS;MIT",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Cambridge",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "Singapore;United States"
    },
    {
        "id": "9341092",
        "title": "Online Planning in Uncertain and Dynamic Environment in the Presence of Multiple Mobile Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "We investigate the autonomous navigation of a mobile robot in the presence of other moving vehicles under time-varying uncertain environmental disturbances. We first predict the future state distributions of other vehicles to account for their uncertain behaviors affected by the time-varying disturbances. We then construct a dynamic-obstacle-aware reachable space that contains states with high probabilities to be reached by the robot, within which the optimal policy is searched. Since, in general, the dynamics of both the vehicle and the environmental disturbances are nonlinear, we utilize a nonlinear Gaussian filter \u2013 the unscented transform \u2013 to approximate the future state distributions. Finally, the forward reachable space computation and backward policy search are iterated until convergence. Extensive simulation evaluations have revealed significant advantages of this proposed method in terms of computation time, decision accuracy, and planning reliability.",
        "primary_area": "",
        "author": "Junhong Xu;Kai Yin;Lantao Liu;Junhong Xu;Kai Yin;Lantao Liu",
        "authorids": "/37089503523;/37088447981;/37085785167;/37089503523;/37088447981;/37085785167",
        "aff": "Luddy School of Informatics, Computing, and Engineering, Indiana University, Bloomington, IN, USA; Expedia Group; Luddy School of Informatics, Computing, and Engineering, Indiana University, Bloomington, IN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341092/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6981513468267908617&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Indiana University;Expedia Group",
        "aff_unique_dep": "Luddy School of Informatics, Computing, and Engineering;",
        "aff_unique_url": "https://www.indiana.edu;https://www.expediagroup.com",
        "aff_unique_abbr": "IU;Expedia Group",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Bloomington;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341472",
        "title": "Online System for Dynamic Multi-contact Motion with Impact Force Based on Contact Wrench Estimation and Current-Based Torque Control",
        "track": "main",
        "status": "Poster",
        "abstract": "Humanoid robots are expected to play a big role at distress sites and disaster sites. There is a variety of multi-contact locomotion forms other than bipedal walking such as crawling through tightly, getting on the rubble by using its knees and elbows, or jumping in and rolling over the obstacles. If such multi-contact locomotion forms can be achieved, robots can reach environments that are currently unreachable, and be able to conduct tasks required at the environments. To achieve this, it is required for robots to bring various parts of its body into contact with the environment like a human. However, it is difficult for parts without 6-axis force sensors to achieve the target force while adapting to the environment against impact force. It is also difficult to measure contact wrenches without 6-axis force sensors. In this paper, by allowing the error of the contact state, we propose online system for realizing dynamic motion which impact force occurs on the parts of the whole body by contact to the environment. In the proposed system, we applied the current-based torque control for joints to make the whole body parts of the robot adapt to the environment, and we modified motion in real time to stabilize zmp by estimating contact wrenches at the contact positions where force sensors are not mounted. In addition, at the motion planning, we generated more feasible motions for a robot applying torque control by using evolutionary computation which advances the search with the behavior of torque control. We demonstrate that the proposed system is effective by showing experimental results of sitting posture locomotion using a JAXON robot in which impact force occur on the back of the thighs which have no force sensors.",
        "primary_area": "",
        "author": "Kazuki Fukazawa;Naoki Hiraoka;Kunio Kojima;Shintaro Noda;Masahiro Bando;Kei Okada;Masayuki Inaba;Kazuki Fukazawa;Naoki Hiraoka;Kunio Kojima;Shintaro Noda;Masahiro Bando;Kei Okada;Masayuki Inaba",
        "authorids": "/37086851707;/37087325306;/37085360901;/37085354213;/37086302355;/37280639000;/37286658200;/37086851707;/37087325306;/37085360901;/37085354213;/37086302355;/37280639000;/37286658200",
        "aff": "Department of Mechano-Infomatics, The University of Tokyo, Tokyo, Japan; Department of Mechano-Infomatics, The University of Tokyo, Tokyo, Japan; Department of Mechano-Infomatics, The University of Tokyo, Tokyo, Japan; Department of Mechano-Infomatics, The University of Tokyo, Tokyo, Japan; Department of Mechano-Infomatics, The University of Tokyo, Tokyo, Japan; Department of Mechano-Infomatics, The University of Tokyo, Tokyo, Japan; Department of Mechano-Infomatics, The University of Tokyo, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341472/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11768319380019942389&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "The University of Tokyo",
        "aff_unique_dep": "Department of Mechano-Infomatics",
        "aff_unique_url": "https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "UTokyo",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9341703",
        "title": "Online Visual Place Recognition via Saliency Re-identification",
        "track": "main",
        "status": "Poster",
        "abstract": "As an essential component of visual simultaneous localization and mapping (SLAM), place recognition is crucial for robot navigation and autonomous driving. Existing methods often formulate visual place recognition as feature matching, which is computationally expensive for many robotic applications with limited computing power, e.g., autonomous driving and cleaning robot. Inspired by the fact that human beings always recognize a place by remembering salient regions or landmarks that are more attractive or interesting than others, we formulate visual place recognition as saliency reidentification. In the meanwhile, we propose to perform both saliency detection and re-identification in frequency domain, in which all operations become element-wise. The experiments show that our proposed method achieves competitive accuracy and much higher speed than the state-of-the-art feature-based methods. The proposed method is open-sourced and available at https://github.com/wh200720041/SRLCD.git.",
        "primary_area": "",
        "author": "Han Wang;Chen Wang;Lihua Xie;Han Wang;Chen Wang;Lihua Xie",
        "authorids": "/37292552600;/37089398088;/37274139300;/37292552600;/37089398088;/37274139300",
        "aff": "School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341703/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17638494334330753664&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Nanyang Technological University;Carnegie Mellon University",
        "aff_unique_dep": "School of Electrical and Electronic Engineering;Robotics Institute",
        "aff_unique_url": "https://www.ntu.edu.sg;https://www.cmu.edu",
        "aff_unique_abbr": "NTU;CMU",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Singapore;Pittsburgh",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Singapore;United States"
    },
    {
        "id": "9341495",
        "title": "Online Weight-adaptive Nonlinear Model Predictive Control",
        "track": "main",
        "status": "Poster",
        "abstract": "Nonlinear Model Predictive Control (NMPC) is a powerful and widely used technique for nonlinear dynamic process control under constraints. In NMPC, the state and control weights of the corresponding state and control costs are commonly selected based on human-expert knowledge, which usually reflects the acceptable stability in practice. Although broadly used, this approach might not be optimal for the execution of a trajectory with the lowest positional error and sufficiently \"smooth\" changes in the predicted controls. Furthermore, NMPC with an online weight update strategy for fast, agile, and precise unmanned aerial vehicle navigation, has not been studied extensively. To this end, we propose a novel control problem formulation that allows online updates of the state and control weights. As a solution, we present an algorithm that consists of two alternating stages: (i) state and command variable prediction and (ii) weights update. We present a numerical evaluation with a comparison and analysis of different trade-offs for the problem of quadrotor navigation. Our computer simulation results show improvements of up to 70% in the accuracy of the executed trajectory compared to the standard solution of NMPC with fixed weights.",
        "primary_area": "",
        "author": "Dimche Kostadinov;Davide Scaramuzza;Dimche Kostadinov;Davide Scaramuzza",
        "authorids": "/37085626779;/37397688400;/37085626779;/37397688400",
        "aff": "Dept. of Informatics and Neuroinformatics, Robotics and Perception Group, University of Zurich and ETH Zurich, Zurich, Switzerland; Dept. of Informatics and Neuroinformatics, Robotics and Perception Group, University of Zurich and ETH Zurich, Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341495/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15792482737194158784&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 14,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Zurich",
        "aff_unique_dep": "Dept. of Informatics and Neuroinformatics, Robotics and Perception Group",
        "aff_unique_url": "https://www.unizh.ch",
        "aff_unique_abbr": "UZH",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Zurich",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9340830",
        "title": "Online gain setting method for path tracking using CMA-ES: Application to off-road mobile robot control",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a new approach for online control law gains adaptation, through the use of neural networks and the Covariance Matrix Adaptation Evolution Strategy (CMA-ES) algorithm, in order to optimize the behavior of the robot with respect to an objective function. The neural network considered takes as input the current observed state as well as its uncertainty, and provides as output the control law gains. It is trained, using the CMA-ES algorithm, on a simulator reproducing the vehicle dynamics. Then, it is tested in real conditions on an agricultural mobile robot at different speeds. The transferability of this method from simulation to a real system is demonstrated, as well as its robustness to environmental changes, such as GPS signal degradation or ground variation. As a result, path following errors are reduced, while ensuring tracking stability.",
        "primary_area": "",
        "author": "Ashley Hill;Jean Laneurit;Roland Lenain;Eric Lucet;Ashley Hill;Jean Laneurit;Roland Lenain;Eric Lucet",
        "authorids": "/37088687917;/38312164600;/37283367600;/37593493000;/37088687917;/38312164600;/37283367600;/37593493000",
        "aff": "CEA, LIST, Interactive Robotics Laboratory, Gif-sur-Yvette, France; Inrae, UR TSCF, Centre de Clermont-Ferrand, Universit\u00e9 Clermont Auvergne, Aubi\u00e8re, France; Inrae, UR TSCF, Centre de Clermont-Ferrand, Universit\u00e9 Clermont Auvergne, Aubi\u00e8re, France; CEA, LIST, Interactive Robotics Laboratory, Gif-sur-Yvette, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340830/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1610945677443021117&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "CEA;Institut National de Recherche pour l'Agriculture, l'Alimentation et l'Environnement",
        "aff_unique_dep": "Interactive Robotics Laboratory;Unit\u00e9 de Recherche Transdisciplinaire en Sciences du Changement et des Fenomenes Frontaliers",
        "aff_unique_url": "https://www.cea.fr;https://www.inrae.fr",
        "aff_unique_abbr": "CEA;INRAE",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Gif-sur-Yvette;Clermont-Ferrand",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9340961",
        "title": "Online velocity constraint adaptation for safe and efficient human-robot workspace sharing",
        "track": "main",
        "status": "Poster",
        "abstract": "Despite the many advances in collaborative robotics, collaborative robot control laws remain similar to the ones used in more standard industrial robots, significantly reducing the capabilities of the robot when in proximity to a human. Improving the efficiency of collaborative robots requires revising the control approaches and modulating online and in real-time the low-level control of the robot to strictly ensure the safety of the human while guaranteeing efficient task realization. In this work, an openly simple and fast optimization based joint velocity controller is proposed which modulates the joint velocity constraints based on the robot's braking capabilities and the separation distance. The proposed controller is validated on the 7 degrees-of-freedom Franka Emika Panda collaborative robot.",
        "primary_area": "",
        "author": "Lucas Joseph;Joshua K. Pickard;Vincent Padois;David Daney;Lucas Joseph;Joshua K. Pickard;Vincent Padois;David Daney",
        "authorids": "/37086453493;/37085394027;/38534363400;/37273442100;/37086453493;/37085394027;/38534363400;/37273442100",
        "aff": "Auctus, Inria - IMS (Univ. Bordeaux / Bordeaux INP / CNRS UMR 5218), Talence, France; Auctus, Inria - IMS (Univ. Bordeaux / Bordeaux INP / CNRS UMR 5218), Talence, France; Auctus, Inria - IMS (Univ. Bordeaux / Bordeaux INP / CNRS UMR 5218), Talence, France; Auctus, Inria - IMS (Univ. Bordeaux / Bordeaux INP / CNRS UMR 5218), Talence, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340961/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12797900561166454618&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Inria",
        "aff_unique_dep": "IMS",
        "aff_unique_url": "https://www.inria.fr",
        "aff_unique_abbr": "Inria",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Talence",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9341307",
        "title": "Operational Space Formulation and Inverse Kinematics for an Arm Exoskeleton with Scapula Rotation",
        "track": "main",
        "status": "Poster",
        "abstract": "The operational space of an 8-axis arm exoskeleton is partitioned into \"tasks\" based on the human arm motion, and a task priority approach is implemented to perform the inverse kinematics. The tasks are prioritized in the event that singularities or other constraints such as joint limits render the full desired operational space infeasible. The task reconstruction method is used to circumvent singularities in a deterministic manner so that the arm is never physically in a singular configuration. This is especially advantageous when the arm is fully extended because it allows the hand to move smoothly along the workspace boundary. The task priority inverse kinematics approach is also more computationally efficient than full Jacobian inverse methods and naturally manages the motion of the arm in a more anthropomorphic-friendly manner. The new methodology is demonstrated with four operational tasks on the MGA Exoskeleton.",
        "primary_area": "",
        "author": "Craig Carignan;Daniil Gribok;Tuvia Rappaport;Natalie Condzal;Craig Carignan;Daniil Gribok;Tuvia Rappaport;Natalie Condzal",
        "authorids": "/37281602100;/37088687566;/37088689564;/37088689215;/37281602100;/37088687566;/37088689564;/37088689215",
        "aff": "Dept. of Aerospace Engineering, University of Maryland, College Park, Maryland, USA; Department of Aerospace Engineering, University of Maryland, College Park, Maryland, USA; Department of Aerospace Engineering, University of Maryland, College Park, Maryland, USA; Department of Aerospace Engineering, University of Maryland, College Park, Maryland, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341307/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2680414137662742395&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Maryland",
        "aff_unique_dep": "Dept. of Aerospace Engineering",
        "aff_unique_url": "https://wwwumd.edu",
        "aff_unique_abbr": "UMD",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "College Park",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341365",
        "title": "Optimal Design of a Novel Spherical Scissor Linkage Remote Center of Motion Mechanism for Medical Robotics",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, a new remote center of motion (RCM) mechanism is presented whose end-effector is able to move through an entire hemisphere. In general, minimally invasive surgery (MIS) applications, an elliptic cone workspace with vertex angles of 60\u00b0 and 90\u00b0 gives the surgeon enough freedom to operate. Therefore, the majority of the developed RCM mechanisms have such a cone as the workspace. However, there are still situations in which a larger workspace is required, like the breast ultrasound scanning application in which the RCM mechanisms should be able to move over a hemisphere to do the breast scanning. The proposed RCM mechanism is developed based upon a spherical scissor linkage and benefits from the high stiffness characteristics of parallel structures while eliminating the common problem of linkage collision in parallel structures. It has two rotational degrees of freedom that are decoupled from each other. The Jacobian and the stiffness of the mechanism while considering the bending of the links is calculated through the virtual joints method (VJM). The kinemato-static equations and the methodology for calculating stiffness are described in detail. The optimal arc angle of the mechanism's links is found using a multi-objective genetic algorithm optimization. A prototype of the mechanism is built and forward kinematic of the proposed mechanism is examined experimentally. The experiments indicate that the proposed mechanism is able to provide a hemisphere as its workspace while the RCM point of the mechanism is fixed in the space.",
        "primary_area": "",
        "author": "Mehrnoosh Afshar;Jay Carriere;Tyler Meyer;Ron Sloboda;Siraj Husain;Nawaid Usmani;Mahdi Tavakoli;Mehrnoosh Afshar;Jay Carriere;Tyler Meyer;Ron Sloboda;Siraj Husain;Nawaid Usmani;Mahdi Tavakoli",
        "authorids": "/37088649567;/37085472623;/37086831127;/38163120900;/37086832821;/37085409253;/37282400400;/37088649567;/37085472623;/37086831127;/38163120900;/37086832821;/37085409253;/37282400400",
        "aff": "Department of Electrical and Computer Engineering, University of Alberta, AB, Canada; Department of Electrical and Computer Engineering, University of Alberta, AB, Canada; Division of Radiation Oncology, Tom Baker Cancer Centre, Calgary, Alberta; Department of Oncology, Cross Cancer Institute, Edmonton, AB, Canada; Division of Radiation Oncology, Tom Baker Cancer Centre, Calgary, Alberta; Department of Oncology, Cross Cancer Institute, Edmonton, AB, Canada; Department of Electrical and Computer Engineering, University of Alberta, AB, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341365/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11318113032481773348&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;1;2;1;2;0",
        "aff_unique_norm": "University of Alberta;Tom Baker Cancer Centre;Cross Cancer Institute",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Division of Radiation Oncology;Department of Oncology",
        "aff_unique_url": "https://www.ualberta.ca;https://www.tombakercancercentre.ca;",
        "aff_unique_abbr": "UAlberta;;",
        "aff_campus_unique_index": "0;0;1;0;1;0;0",
        "aff_campus_unique": "Edmonton;Calgary",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9340847",
        "title": "Optimal Pose Estimation Method for a Multi-Segment, Programmable Bevel-Tip Steerable Needle",
        "track": "main",
        "status": "Poster",
        "abstract": "Needle pose tracking is fundamental to achieve a precise and safe insertion in minimally-invasive percutaneous interventions. In this work, a method for estimating the full pose of steerable needles is presented, considering a four-segment Programmable Bevel-Tip Needle (PBN) as a case study. The method estimates also the torsion of the needle that can arise during the insertion because of the interaction forces exerted between the needle and the insertion medium. A novel 3D kinematic model of the PBN is developed and used to predict the full needle pose during the insertion through an Extended Kalman Filter. The filter uses the position measurements provided by electromagnetic sensors located at the tip of the PBN segments as measurement data. The feasibility of the proposed solution is verified through ingelatin experiments, demonstrating remarkable performance with small errors in position (RMSE<; 1 mm) and orientation (RMSE<; 3\u00b0) estimation, as well as good accuracy compared to a bespoke geometric pose reconstruction method.",
        "primary_area": "",
        "author": "Alberto Favaro;Riccardo Secoli;Ferdinando Rodriguez y Baena;Elena De Momi;Alberto Favaro;Riccardo Secoli;Ferdinando Rodriguez y Baena;Elena De Momi",
        "authorids": "/37089042477;/37669464200;/37085496644;/37947344300;/37089042477;/37669464200;/37085496644;/37947344300",
        "aff": "NearLab, Department of Electronics, Information and Bioengineering Department (DEIB), Politecnico di Milano, Milan, Italy; Mechatronics In Medicine Laboratory, Mechanical Engineering Department, Imperial College London, U.K; Mechatronics In Medicine Laboratory, Mechanical Engineering Department, Imperial College London, U.K; NearLab, Department of Electronics, Information and Bioengineering Department (DEIB), Politecnico di Milano, Milan, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340847/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9475669214430968974&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "Politecnico di Milano;Imperial College London",
        "aff_unique_dep": "Department of Electronics, Information and Bioengineering Department (DEIB);Mechanical Engineering Department",
        "aff_unique_url": "https://www.polimi.it;https://www.imperial.ac.uk",
        "aff_unique_abbr": "Politecnico di Milano;Imperial College",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Milan;London",
        "aff_country_unique_index": "0;1;1;0",
        "aff_country_unique": "Italy;United Kingdom"
    },
    {
        "id": "9341148",
        "title": "Optimal Robot Motion Planning in Constrained Workspaces Using Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, a novel solution to the optimal motion planning problem is proposed, through a continuous, deterministic and provably correct approach, with guaranteed safety and which is based on a parametrized Artificial Potential Field (APF). In particular, Reinforcement Learning (RL) is applied to adjust appropriately the parameters of the underlying potential field towards minimizing the Hamilton-Jacobi-Bellman (HJB) error. The proposed method, outperforms consistently a Rapidly-exploring Random Trees (RRT*) method and consists a fertile advancement in the optimal motion planning problem.",
        "primary_area": "",
        "author": "Panagiotis Rousseas;Charalampos P. Bechlioulis;Kostas J. Kyriakopoulos;Panagiotis Rousseas;Charalampos P. Bechlioulis;Kostas J. Kyriakopoulos",
        "authorids": "/37088688420;/37396608300;/38181756700;/37088688420;/37396608300;/38181756700",
        "aff": "Control System Lab, School of Mechanical Engineering, National Technical University of Athens, Greece; Control System Lab, School of Mechanical Engineering, National Technical University of Athens, Greece; Control System Lab, School of Mechanical Engineering, National Technical University of Athens, Greece",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341148/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16344425464520862540&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "National Technical University of Athens",
        "aff_unique_dep": "School of Mechanical Engineering",
        "aff_unique_url": "https://www.ntua.gr",
        "aff_unique_abbr": "NTUA",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Greece"
    },
    {
        "id": "9341648",
        "title": "Optimal-power Configurations for Hover Solutions in Mono-spinners",
        "track": "main",
        "status": "Poster",
        "abstract": "Rotary-wing flying machines draw attention within the UAV community for their in-place hovering capability, and recently, holonomic motion over fixed-wings. In this paper, we investigate about the power-optimality in a mono-spinner, i.e., a class of rotary-wing UAVs with one rotor only, whose main body has a streamlined shape for producing additional lift when counter-spinning the rotor. We provide a detailed dynamic model of our mono-spinner. Two configurations are studied: (1) a symmetric configuration, in which the rotor is aligned with the fuselage\u2019s COM, and (2) an asymmetric configuration, in which the rotor is located with an offset from the fuselage\u2019s COM. While the former can generate an in-place hovering flight condition, the latter can achieve trajectory tracking in 3D space by resolving the yaw and precession rates. Furthermore, it is shown that by introducing a tilting angle between the rotor and the fuselage, within the asymmetric design, one can further minimize the power consumption without compromising the overall stability. It is shown that an energy optimal solution can be achieved through the proper aerodynamic design of the mono-spinner for the first time.",
        "primary_area": "",
        "author": "Mojtaba Hedayatpour;Mehran Mehrandezh;Farrokh Janabi-Sharifi;Mojtaba Hedayatpour;Mehran Mehrandezh;Farrokh Janabi-Sharifi",
        "authorids": "/37086329590;/37283215200;/37278157400;/37086329590;/37283215200;/37278157400",
        "aff": "Faculty of Engineering & Applied Science, University of Regina, Regina, Canada; Faculty of Engineering & Applied Science, University of Regina, Regina, Canada; Department of Mechanical & Industrial Engineering, Ryerson University, Toronto, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341648/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=289638591304175523&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "University of Regina;Ryerson University",
        "aff_unique_dep": "Faculty of Engineering & Applied Science;Department of Mechanical & Industrial Engineering",
        "aff_unique_url": "https://www.uregina.ca;https://www.ryerson.ca",
        "aff_unique_abbr": "U of R;Ryerson",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Regina;Toronto",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9341498",
        "title": "Optimisation of Body-ground Contact for Augmenting the Whole-Body Loco-manipulation of Quadruped Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Legged robots have great potential to perform complex loco-manipulation tasks, yet it is challenging to keep the robot balanced while it interacts with the environment. In this paper we investigated the use of additional contact points for maximising the robustness of loco-manipulation motions. Specifically, body-ground contact was studied for its ability to enhance robustness and manipulation capabilities of quadrupedal robots. We proposed equipping the robot with prongs: small legs rigidly attached to the body which create body-ground contact at controllable point-contacts. The effect of these prongs on robustness was quantified by computing the Smallest Unrejectable Force (SUF), a measure of robustness related to Feasible Wrench Polytopes. We applied the SUF to evaluate the robustness of the system, and proposed an effective approximation of the SUF that can be computed at near-real-time speed. We developed a hierarchical quadratic programming based whole-body controller that can control stable interaction when the prongs are in contact with the ground. This novel prong concept and complementary control framework were implemented on hardware to validate their effectiveness by showing increased robustness and newly enabled loco-manipulation tasks, such as obstacle clearance and manipulation of a large object.",
        "primary_area": "",
        "author": "Wouter J. Wolfslag;Christopher McGreavy;Guiyang Xin;Carlo Tiseo;Sethu Vijayakumar;Zhibin Li;Wouter J. Wolfslag;Christopher McGreavy;Guiyang Xin;Carlo Tiseo;Sethu Vijayakumar;Zhibin Li",
        "authorids": "/37085495847;/37086556658;/37085531864;/37085404832;/37295595500;/37857029500;/37085495847;/37086556658;/37085531864;/37085404832;/37295595500;/37857029500",
        "aff": "School of Informatics, University of Edinburgh, UK; School of Informatics, University of Edinburgh, UK; School of Informatics, University of Edinburgh, UK; School of Informatics, University of Edinburgh, UK; School of Informatics, University of Edinburgh, UK; School of Informatics, University of Edinburgh, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341498/",
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3698574528652984787&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of Edinburgh",
        "aff_unique_dep": "School of Informatics",
        "aff_unique_url": "https://www.ed.ac.uk",
        "aff_unique_abbr": "Edinburgh",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Edinburgh",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9341731",
        "title": "Optimization-Based Hierarchical Motion Planning for Autonomous Racing",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper we propose a hierarchical controller for autonomous racing where the same vehicle model is used in a two level optimization framework for motion planning. The high-level controller computes a trajectory that minimizes the lap time, and the low-level nonlinear model predictive path following controller tracks the computed trajectory online. Following a computed optimal trajectory avoids online planning and enables fast computational times. The efficiency is further enhanced by the coupling of the two levels through a terminal constraint, computed in the high-level controller. Including this constraint in the real-time optimization level ensures that the prediction horizon can be shortened, while safety is guaranteed. This proves crucial for the experimental validation of the approach on a full size driverless race car. The vehicle in question won two international student racing competitions using the proposed framework; moreover, our hierarchical controller achieved an improvement of 20% in the lap time compared to the state of the art result achieved using a very similar car and track.",
        "primary_area": "",
        "author": "Jos\u00e9 L. V\u00e1zquez;Marius Br\u00fchlmeier;Alexander Liniger;Alisa Rupenyan;John Lygeros;Jos\u00e9 L. V\u00e1zquez;Marius Br\u00fchlmeier;Alexander Liniger;Alisa Rupenyan;John Lygeros",
        "authorids": "/37088688087;/37088689118;/37085702116;/37088339059;/37301174800;/37088688087;/37088689118;/37085702116;/37088339059;/37301174800",
        "aff": "Automatic Control Lab, ETH, Zurich, Switzerland; Automatic Control Lab, ETH, Zurich, Switzerland; Computer Vision Lab, ETH, Zurich, Switzerland; Automatic Control Lab, ETH, Zurich, Switzerland; Automatic Control Lab, ETH, Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341731/",
        "gs_citation": 87,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2301579452511489698&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Automatic Control Lab",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Zurich",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9341637",
        "title": "Optimization-based Path Planning for Person Following using Following Field",
        "track": "main",
        "status": "Poster",
        "abstract": "Person following is an essential task for a robot to serve a person. In an indoor environment, however, the following task can be failed due to the occlusion of the target by structures, e.g., walls or pillars. To address this problem, we propose a method that helps the robot follow the target well and rapidly re-detect the target after missing. The proposed method is an optimization-based path planning which uses a Following Field that we propose in this paper. The following field consists of two sub-fields: the repulsion field getting the robot out of the occluded area, and the target attraction field pushing the robot toward the target. We introduce how to construct the fields and how to integrate the field into a path optimization process. We show that our method works properly for following the target well in a maze consisting of various in-door features.",
        "primary_area": "",
        "author": "Heechan Shin;Sung-Eui Yoon;Heechan Shin;Sung-Eui Yoon",
        "authorids": "/37086110200;/37066068100;/37086110200;/37066068100",
        "aff": "School of Computing, Korea Advanced Institute of Science and Technology (KAIST); School of Computing, Korea Advanced Institute of Science and Technology (KAIST)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341637/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1260375627824616543&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology",
        "aff_unique_dep": "School of Computing",
        "aff_unique_url": "https://www.kaist.ac.kr",
        "aff_unique_abbr": "KAIST",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9341788",
        "title": "Optimizing Dynamic Trajectories for Robustness to Disturbances Using Polytopic Projections",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper focuses on robustness to disturbance forces and uncertain payloads. We present a novel formulation to optimize the robustness of dynamic trajectories. A straightforward transcription of this formulation into a nonlinear programming problem is not tractable for state-of-the-art solvers, but it is possible to overcome this complication by exploiting the structure induced by the kinematics of the robot. The non-trivial transcription proposed allows trajectory optimization frameworks to converge to highly robust dynamic solutions. We demonstrate the results of our approach using a quadruped robot equipped with a manipulator.",
        "primary_area": "",
        "author": "Henrique Ferrolho;Wolfgang Merkt;Vladimir Ivan;Wouter Wolfslag;Sethu Vijayakumar;Henrique Ferrolho;Wolfgang Merkt;Vladimir Ivan;Wouter Wolfslag;Sethu Vijayakumar",
        "authorids": "/37086190451;/37086118415;/37085552022;/37085495847;/37295595500;/37086190451;/37086118415;/37085552022;/37085495847;/37295595500",
        "aff": "School of Informatics, University of Edinburgh, United Kingdom; Oxford Robotics Institute, University of Oxford, United Kingdom; School of Informatics, University of Edinburgh, United Kingdom; School of Informatics, University of Edinburgh, United Kingdom; School of Informatics, University of Edinburgh, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341788/",
        "gs_citation": 34,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10980757370833621495&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "University of Edinburgh;University of Oxford",
        "aff_unique_dep": "School of Informatics;Oxford Robotics Institute",
        "aff_unique_url": "https://www.ed.ac.uk;https://www.ox.ac.uk",
        "aff_unique_abbr": "Edinburgh;Oxford",
        "aff_campus_unique_index": "0;1;0;0;0",
        "aff_campus_unique": "Edinburgh;Oxford",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9341378",
        "title": "Optimizing a Continuum Manipulator\u2019s Search Policy Through Model-Free Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Continuum robots have long held a great potential for applications in inspection of remote, hard-to-reach environments. In future environments such as the Deep Space Gateway, remote deployment of robotic solutions will require a high level of autonomy due to communication delays and unavailability of human crews. In this work, we explore the application of policy optimization methods through Actor-Critic gradient descent in order to optimize a continuum manipulator\u2019s search method for an unknown object. We show that we can deploy a continuum robot without prior knowledge of a goal object location and converge to a policy that finds the goal and can be reused in future deployments. We also show that the method can be quickly extended for multiple Degrees-of-Freedom and that we can restrict the policy with virtual and physical obstacles. These two scenarios are highlighted using a simulation environment with 15 and 135 unique states, respectively.",
        "primary_area": "",
        "author": "Chase Frazelle;Jonathan Rogers;Ioannis Karamouzas;Ian Walker;Chase Frazelle;Jonathan Rogers;Ioannis Karamouzas;Ian Walker",
        "authorids": "/37085792455;/37088687087;/38111249000;/37276152000;/37085792455;/37088687087;/38111249000;/37276152000",
        "aff": "Dept. of Electrical & Computer Engineering, Clemson University, Clemson, SC; NASA Johnson Space Center, Houston, TX; School of Computing, Clemson University, Clemson, SC; Dept. of Electrical & Computer Engineering, Clemson University, Clemson, SC",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341378/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3552156333331545898&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Clemson University;NASA Johnson Space Center",
        "aff_unique_dep": "Dept. of Electrical & Computer Engineering;",
        "aff_unique_url": "https://www.clemson.edu;https://www.nasa.gov centers johnson",
        "aff_unique_abbr": "Clemson;JSC",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Clemson;Houston",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341476",
        "title": "Optimizing coordinate choice for locomotion systems with toroidal shape spaces",
        "track": "main",
        "status": "Poster",
        "abstract": "In a geometric mechanics framework, the configuration space is decomposed into a shape space and a position space. The internal motion of the system is prescribed by a closed loop in the shape space, which causes net motion in the position space. If the shape space is a simply connected domain in an Euclidean space, then with an optimal choice of the body frame, the displacement in the position space is reasonably approximated by the surface integral of the height function, a functional relationship between the internal shape and position space variables. Our recent work has extended the scope of geometric methods from limbless undulatory system to those with legs; interestingly, the shape space for such systems has a torus structure. However, to the best of our knowledge, the optimal choice of the body frame on the torus shape space was not explored. In this paper, we develop a method to optimally choose the body frame on the torus which results in good approximation of displacement by the integral of the height function. We apply our methods to the centipede locomotion system and observe quantitative agreement of our prediction and experimental results.",
        "primary_area": "",
        "author": "Bo Lin;Baxi Chong;Yasemin Ozkan-Aydin;Enes Aydin;Howie Choset;Daniel I. Goldman;Greg Blekherman;Bo Lin;Baxi Chong;Yasemin Ozkan-Aydin;Enes Aydin;Howie Choset;Daniel I. Goldman;Greg Blekherman",
        "authorids": "/37088690169;/37088489862;/37086842822;/37086843190;/37281322200;/38182137200;/37088690011;/37088690169;/37088489862;/37086842822;/37086843190;/37281322200;/38182137200;/37088690011",
        "aff": "Faculty of School of Mathematics, Georgia Institute of Technology, and Southeast Center for Mathematics and Biology (SCMB), Atlanta, GA, USA; School of Physics, Georgia Institute of Technology, Atlanta, GA, USA; School of Physics, Georgia Institute of Technology, Atlanta, GA, USA; School of Physics, Georgia Institute of Technology, Atlanta, GA, USA; Faculty of the Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Faculty of the School of Physics, Georgia Institute of Technology, and Southeast Center for Mathematics and Biology (SCMB), Atlanta, GA, USA; Faculty of School of Mathematics, Georgia Institute of Technology, and Southeast Center for Mathematics and Biology (SCMB), Atlanta, GA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341476/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13297278025774598471&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;1;0;0",
        "aff_unique_norm": "Georgia Institute of Technology;Carnegie Mellon University",
        "aff_unique_dep": "School of Mathematics;Faculty of the Robotics Institute",
        "aff_unique_url": "https://www.gatech.edu;https://www.cmu.edu",
        "aff_unique_abbr": "Georgia Tech;CMU",
        "aff_campus_unique_index": "0;0;0;0;1;0;0",
        "aff_campus_unique": "Atlanta;Pittsburgh",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341660",
        "title": "OrcVIO: Object residual constrained Visual-Inertial Odometry",
        "track": "main",
        "status": "Poster",
        "abstract": "Introducing object-level semantic information into simultaneous localization and mapping (SLAM) system is critical. It not only improves the performance but also enables tasks specified in terms of meaningful objects. This work presents OrcVIO, for visual-inertial odometry tightly coupled with tracking and optimization over structured object models. OrcVIO differentiates through semantic feature and bounding-box reprojection errors to perform batch optimization over the pose and shape of objects. The estimated object states aid in real-time incremental optimization over the IMU-camera states. The ability of OrcVIO for accurate trajectory estimation and large-scale object-level mapping is evaluated using real data.",
        "primary_area": "",
        "author": "Mo Shan;Qiaojun Feng;Nikolay Atanasov;Mo Shan;Qiaojun Feng;Nikolay Atanasov",
        "authorids": "/37087321802;/37087322298;/37670511000;/37087321802;/37087322298;/37670511000",
        "aff": "Department of Electrical and Computer Engineering, University of California, San Diego, La Jolla, CA, USA; Department of Electrical and Computer Engineering, University of California, San Diego, La Jolla, CA, USA; Department of Electrical and Computer Engineering, University of California, San Diego, La Jolla, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341660/",
        "gs_citation": 46,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15514714041848679723&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California, San Diego",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.ucsd.edu",
        "aff_unique_abbr": "UCSD",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "La Jolla",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340834",
        "title": "Organizing the Internet of Robotic Things: The Effect of Organization Structure on Users\u2019 Evaluation and Compliance toward IoRT Service Platform",
        "track": "main",
        "status": "Poster",
        "abstract": "As robots and robotic things become to have more agency, IoRT which consists of robots and robotic things can be considered as a social organization. Accordingly, social organization structure of IoRT could affect users' behavior and perception of IoRT. In this study, in order to examine the effect of social organization structure on people's acceptance of IoRT, we conducted a 2 (social organization structure: flat vs. hierarchical) within-participants experiment (N=30). In the experiment, a participant was asked to take part in cooking task with the aid of a robot, a robotic measuring cup, and a robotic mixer. We executed a post-experimental survey and counted the duration of participants' following the instruction given by the platform. People gave higher scores of trustworthiness and purchase intention to the platform with flat organization structure than that with hierarchical one. On the contrary, participants were more compliant with the hierarchical IoRT service platform than a flat one. Implications for the theory and design of IoRT are discussed.",
        "primary_area": "",
        "author": "Byeong June Moon;Sonya S. Kwak;JongSuk Choi;Byeong June Moon;Sonya S. Kwak;JongSuk Choi",
        "authorids": "/37088528280;/37398989100;/37292544300;/37088528280;/37398989100;/37292544300",
        "aff": "Department of Sociology, Seoul National University, Seoul, Korea; Center for Intelligent and Interactive Robotics, Korea Institute of Science and Technology, Seoul, Korea; Center for Intelligent and Interactive Robotics, Korea Institute of Science and Technology, Seoul, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340834/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3150723147687175873&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Seoul National University;Korea Institute of Science and Technology",
        "aff_unique_dep": "Department of Sociology;Center for Intelligent and Interactive Robotics",
        "aff_unique_url": "https://www.snu.ac.kr;https://www.kist.re.kr",
        "aff_unique_abbr": "SNU;KIST",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9341292",
        "title": "Ospheel: Design of an Omnidirectional Spherical-sectioned Wheel",
        "track": "main",
        "status": "Poster",
        "abstract": "The holonomic and omnidirectional capabilities imparted to the mobile base platform depends mainly on two factors, i.e., the wheel design and its various arrangements in the platform chassis. This paper reports on the development of a novel omnidirectional spherical sectioned wheel named Ospheel. It is modular, and the spherical sectioned geometry of the wheel is driven using two actuators placed inside the housing above the wheel that rotates it independently about two perpendicular axes. The mechanical drive system for Ospheel consists of two gear trains, namely, internal spur gear and crown gear spatially assembled in orthogonal planes and are driven by two driving pinions. The kinematics of a single Ospheel is described, followed by the kinematic equation of a robot equipped with two Ospheels. Forward and inverse kinematic equations are derived explicitly. Experiments were carried out with the two Ospheels at a fixed inclination assembled with the base to illustrate the holonomic motion. The robustness of the wheel design is experimented with different trajectories and on different terrains.",
        "primary_area": "",
        "author": "A. A. Hayat;Shi Yuyao;K. Elangovan;M. R. Elara;R. E. Abdulkader;A. A. Hayat;Shi Yuyao;K. Elangovan;M. R. Elara;R. E. Abdulkader",
        "authorids": "/37085563101;/37088390440;/37088428727;/37546093700;/37088689606;/37085563101;/37088390440;/37088428727;/37546093700;/37088689606",
        "aff": "SUTD in ROAR Lab; SUTD in ROAR Lab; SUTD in ROAR Lab; Engineering Product Development Pillar, Singapore University of Technology and Design (SUTD); SUTD in ROAR Lab",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341292/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11568696302639784381&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Singapore University of Technology and Design",
        "aff_unique_dep": "ROAR Lab",
        "aff_unique_url": "https://www.sutd.edu.sg",
        "aff_unique_abbr": "SUTD",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "9341132",
        "title": "Output-Only Fault Detection and Mitigation of Networks of Autonomous Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "An autonomous vehicle platoon is a network of autonomous vehicles that communicate together to move in a desired way. One of the greatest threats to the operation of an autonomous vehicle platoon is the failure of either a physical component of a vehicle or a communication link between two vehicles. This failure affects the safety and stability of the autonomous vehicle platoon. Transmissibility-based health monitoring uses available sensor measurements for fault detection under unknown excitation and unknown dynamics of the network. After a fault is detected, a sliding mode controller is used to mitigate the fault. Different fault scenarios are considered including vehicle internal disturbances, cyber attacks, and communication delays. We apply the proposed approach to a bond graph model of the platoon and an experimental setup consisting of three autonomous robots.",
        "primary_area": "",
        "author": "Abdelrahman Khalil;Mohammad Al Janaideh;Khaled F. Aljanaideh;Deepa Kundur;Abdelrahman Khalil;Mohammad Al Janaideh;Khaled F. Aljanaideh;Deepa Kundur",
        "authorids": "/37088482852;/37542671600;/37541125900;/37269460100;/37088482852;/37542671600;/37541125900;/37269460100",
        "aff": "Department of Mechanical Engineering, Memorial University, St. John\u2019s, NL, Canada; Department of Mechanical Engineering, Memorial University, St. John\u2019s, NL, Canada; Department of Aeronautical Engineering, Jordan University of Science and Technology, Irbid, Jordan; Edward S.Rogers Sr. Department of Electrical Computer Engineering, University of Toronto, Toronto, ON, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341132/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4419543829810841352&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;2",
        "aff_unique_norm": "Memorial University;Jordan University of Science and Technology;University of Toronto",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Aeronautical Engineering;Edward S.Rogers Sr. Department of Electrical Computer Engineering",
        "aff_unique_url": "https://www.mun.ca;https://www.just.edu.jo;https://www.utoronto.ca",
        "aff_unique_abbr": "MUN;JUST;U of T",
        "aff_campus_unique_index": "0;0;1;2",
        "aff_campus_unique": "St. John\u2019s;Irbid;Toronto",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "Canada;Jordan"
    },
    {
        "id": "9341776",
        "title": "PBP-Net: Point Projection and Back-Projection Network for 3D Point Cloud Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "Following considerable development in 3D scanning technologies, many studies have recently been proposed with various approaches for 3D vision tasks, including some methods that utilize 2D convolutional neural networks (CNNs). However, even though 2D CNNs have achieved high performance in many 2D vision tasks, existing works have not effectively applied them onto 3D vision tasks. In particular, segmentation has not been well studied because of the difficulty of dense prediction for each point, which requires rich feature representation. In this paper, we propose a simple and efficient architecture named point projection and back-projection network (PBP-Net), which leverages 2D CNNs for the 3D point cloud segmentation. 3 modules are introduced, each of which projects 3D point cloud onto 2D planes, extracts features using a 2D CNN backbone, and back-projects features onto the original 3D point cloud. To demonstrate effective 3D feature extraction using 2D CNN, we perform various experiments including comparison to recent methods. We analyze the proposed modules through ablation studies and perform experiments on object part segmentation (ShapeNet-Part dataset) and indoor scene semantic segmentation (S3DIS dataset). The experimental results show that proposed PBP-Net achieves comparable performance to existing state-of-the-art methods.",
        "primary_area": "",
        "author": "JuYoung Yang;Chanho Lee;Pyunghwan Ahn;Haeil Lee;Eojindl Yi;Junmo Kim;JuYoung Yang;Chanho Lee;Pyunghwan Ahn;Haeil Lee;Eojindl Yi;Junmo Kim",
        "authorids": "/37088688781;/37088691147;/37086533024;/37088691464;/37088689760;/37407301400;/37088688781;/37088691147;/37086533024;/37088691464;/37088689760;/37407301400",
        "aff": "School of Electrical Engineering, Korea Advanced Institute of Science and Technology, Korea; School of Electrical Engineering, Korea Advanced Institute of Science and Technology, Korea; School of Electrical Engineering, Korea Advanced Institute of Science and Technology, Korea; School of Electrical Engineering, Korea Advanced Institute of Science and Technology, Korea; School of Electrical Engineering, Korea Advanced Institute of Science and Technology, Korea; School of Electrical Engineering, Korea Advanced Institute of Science and Technology, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341776/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12793477010926290867&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology",
        "aff_unique_dep": "School of Electrical Engineering",
        "aff_unique_url": "https://www.kaist.ac.kr",
        "aff_unique_abbr": "KAIST",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9340916",
        "title": "PC-NBV: A Point Cloud Based Deep Network for Efficient Next Best View Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "The Next Best View (NBV) problem is important in the active robotic reconstruction. It enables the robot system to perform scanning actions in a reasonable view sequence, and fulfil the reconstruction task in an effective way. Previous works mainly follow the volumetric methods, which convert the point cloud information collected by sensors into a voxel representation space and evaluate candidate views through ray casting simulations to pick the NBV. However, the process of volumetric data transformation and ray casting is often time-consuming. To address this issue, in this paper, we propose a point cloud based deep neural network called PC-NBV to achieve efficient view planning without these computationally expensive operations. The PC-NBV network takes the raw point cloud data and current view selection states as input, and then directly predicts the information gain of all candidate views. By avoiding costly data transformation and ray casting, and utilizing powerful neural network to learn structure priors from point cloud, our method can achieve efficient and effective NBV planning. Experiments on multiple datasets show the proposed method outperforms state-of-the-art NBV methods, giving better views for robot system with much less inference time. Furthermore, we demonstrate the robustness of our method against noise and the ability to extend to multi-view system, making it more applicable for various scenarios.",
        "primary_area": "",
        "author": "Rui Zeng;Wang Zhao;Yong-Jin Liu;Rui Zeng;Wang Zhao;Yong-Jin Liu",
        "authorids": "/37086915187;/37087232745;/37279426700;/37086915187;/37087232745;/37279426700",
        "aff": "Department of Computer Science and Technology, BNRist, MOE-Key Laboratory of Pervasive Computing, Tsinghua University, Beijing, China; Department of Computer Science and Technology, BNRist, MOE-Key Laboratory of Pervasive Computing, Tsinghua University, Beijing, China; Department of Computer Science and Technology, BNRist, MOE-Key Laboratory of Pervasive Computing, Tsinghua University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340916/",
        "gs_citation": 67,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17057130998148725339&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Tsinghua University",
        "aff_unique_dep": "Department of Computer Science and Technology",
        "aff_unique_url": "https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "THU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9341257",
        "title": "PERCH 2.0 : Fast and Accurate GPU-based Perception via Search for Object Pose Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Pose estimation of known objects is fundamental to tasks such as robotic grasping and manipulation. The need for reliable grasping imposes stringent accuracy requirements on pose estimation in cluttered, occluded scenes in dynamic environments. Modern methods employ large sets of training data to learn features in order to find correspondence between 3D models and observed data. However these methods require extensive annotation of ground truth poses. An alternative is to use algorithms that search for the best explanation of the observed scene in a space of possible rendered scenes. A recently developed algorithm, PERCH (PErception Via SeaRCH) does so by using depth data to converge to a globally optimum solution using a search over a specially constructed tree. While PERCH offers strong guarantees on accuracy, the current formulation suffers from low scalability owing to its high runtime. In addition, the sole reliance on depth data for pose estimation restricts the algorithm to scenes where no two objects have the same shape. In this work, we propose PERCH 2.0, a novel perception via search strategy that takes advantage of GPU acceleration and RGB data. We show that our approach can achieve a speedup of 100x over PERCH, as well as better accuracy than the state-of-the-art data-driven approaches on 6-DoF pose estimation without the need for annotating ground truth poses in the training data. Our code and video are available at https://sbpl-cruz.github.io/perception/.",
        "primary_area": "",
        "author": "Aditya Agarwal;Yupeng Han;Maxim Likhachev;Aditya Agarwal;Yupeng Han;Maxim Likhachev",
        "authorids": "/37088691089;/37088689278;/37309318800;/37088691089;/37088689278;/37309318800",
        "aff": "The Robotics Institute, Carnegie Mellon University, PA, USA; The Robotics Institute, Carnegie Mellon University, PA, USA; The Robotics Institute, Carnegie Mellon University, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341257/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4783434647110872372&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "The Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341312",
        "title": "PLRC*: A piecewise linear regression complex for approximating optimal robot motion",
        "track": "main",
        "status": "Poster",
        "abstract": "Discrete graphs are commonly used to approximately represent configuration spaces used in robot motion planning. This paper explores a representation in which the costs of crossing local regions of the configuration space are represented using piecewise linear regression (PLR). We explore a few simple motion planning problems, and show that for these problems, the memory required to store the representation compares favorably to that required for standard discrete vertex-and-edge models, while preserving the quality of paths returned from searches.",
        "primary_area": "",
        "author": "Luyang Zhao;Josiah Putman;Weifu Wang;Devin Balkcom;Luyang Zhao;Josiah Putman;Weifu Wang;Devin Balkcom",
        "authorids": "/37087092371;/37087093275;/37087089834;/37324093200;/37087092371;/37087093275;/37087089834;/37324093200",
        "aff": "Luyang Zhao; Josiah Putman; Weifu Wang; Devin Balkcom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341312/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5967834885992635597&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "1",
        "aff_unique_norm": ";Josiah Putman",
        "aff_unique_dep": ";",
        "aff_unique_url": ";",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "9341274",
        "title": "Pac-Man is Overkill",
        "track": "main",
        "status": "Poster",
        "abstract": "Pursuit-Evasion Game (PEG) consists of a team of pursuers trying to capture one or more evaders. PEG is important due to its application in surveillance, search and rescue, disaster robotics, boundary defense and so on. In general, PEG requires exponential time to compute the minimum number of pursuers to capture an evader. To mitigate this, we have designed a parallel optimal algorithm to minimize the capture time in PEG. Given a discrete topology, this algorithm also outputs the minimum number of pursuers to capture an evader. A classic example of PEG is the popular arcade game, Pac-Man. Although Pac-Man topology has almost 300 nodes, our algorithm can handle this. We show that Pac-Man is overkill, i.e., given the Pac-Man game topology, Pac-Man game contains more pursuers/ghosts (four) than it is necessary (two) to capture evader/Pac-man. We evaluate the proposed algorithm on many different topologies.",
        "primary_area": "",
        "author": "Renato Fernando dos Santos;Ragesh K. Ramachandran;Marcos A. M. Vieira;Gaurav S. Sukhatme;Renato Fernando dos Santos;Ragesh K. Ramachandran;Marcos A. M. Vieira;Gaurav S. Sukhatme",
        "authorids": "/37088689546;/37087324984;/38202816900;/37278934100;/37088689546;/37087324984;/38202816900;/37278934100",
        "aff": "Laboratory of Computer Vision & Robotics, Computer Science Department, Universidade Federal de Minas Gerais, Minas Gerais, Brazil; Robotic Embedded Systems Laboratory, University of Southern California, Los Angeles, CA; Laboratory of Computer Vision & Robotics, Computer Science Department, Universidade Federal de Minas Gerais, Minas Gerais, Brazil; Robotic Embedded Systems Laboratory, University of Southern California, Los Angeles, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341274/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6439763304551370130&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;1",
        "aff_unique_norm": "Universidade Federal de Minas Gerais;University of Southern California",
        "aff_unique_dep": "Computer Science Department;Robotic Embedded Systems Laboratory",
        "aff_unique_url": "https://www.ufmg.br;https://www.usc.edu",
        "aff_unique_abbr": "UFMG;USC",
        "aff_campus_unique_index": "0;1;0;1",
        "aff_campus_unique": "Minas Gerais;Los Angeles",
        "aff_country_unique_index": "0;1;0;1",
        "aff_country_unique": "Brazil;United States"
    },
    {
        "id": "9341676",
        "title": "PaintPath: Defining Path Directionality in Maps for Autonomous Ground Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "Directionality in path planning is essential for efficient autonomous navigation in a number of real-world environments. In many map-based navigation scenarios, the viable path from a given point A to point B is not the same as the viable path from B to A. We present a method that automatically incorporates preferred navigation directionality into a path planning costmap. This `preference' is represented by coloured paths in the costmap. The colourisation is obtained based on an analysis of the driving trajectory generated by the robot as it navigates through the environment. Hence, our method augments this driving trajectory by intelligently colouring it according to the orientation of the robot during the run. Creating an analogy between the vehicle orientation angle and the hue angle in the Hue-Saturation-Value colour space, the method uses the hue, saturation and value components to encode the direction, directionality and scalar cost, respectively, into a costmap image. We describe a costing function to be used by the A* algorithm to incorporate this information to plan direction-aware vehicle paths. Our experiments with LiDAR-based localisation and autonomous driving in real environments illustrate the applicability of the method.",
        "primary_area": "",
        "author": "Riley Bowyer;Thomas Lowe;Paulo Borges;Tirthankar Bandyopadhyay;Tobias L\u00f6w;David Haddon;Riley Bowyer;Thomas Lowe;Paulo Borges;Tirthankar Bandyopadhyay;Tobias L\u00f6w;David Haddon",
        "authorids": "/37088686330;/38028705600;/37546547800;/37562167000;/37088690914;/38017342900;/37088686330;/38028705600;/37546547800;/37562167000;/37088690914;/38017342900",
        "aff": "Robotics and Autonomous Systems Group, Data61, CSIRO, Brisbane, Australia; Robotics and Autonomous Systems Group, Data61, CSIRO, Brisbane, Australia; Robotics and Autonomous Systems Group, Data61, CSIRO, Brisbane, Australia; Robotics and Autonomous Systems Group, Data61, CSIRO, Brisbane, Australia; Multi-Scale Robotics Lab, ETH Z\u00fcrich, Zurich, Switzerland; Robotics and Autonomous Systems Group, Data61, CSIRO, Brisbane, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341676/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:25TrYUFiLfUJ:scholar.google.com/&scioq=PaintPath:+Defining+Path+Directionality+in+Maps+for+Autonomous+Ground+Vehicles&hl=en&as_sdt=0,5",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;0",
        "aff_unique_norm": "CSIRO;ETH Z\u00fcrich",
        "aff_unique_dep": "Robotics and Autonomous Systems Group;Multi-Scale Robotics Lab",
        "aff_unique_url": "https://www.csiro.au;https://www.ethz.ch",
        "aff_unique_abbr": "CSIRO;ETH",
        "aff_campus_unique_index": "0;0;0;0;1;0",
        "aff_campus_unique": "Brisbane;Zurich",
        "aff_country_unique_index": "0;0;0;0;1;0",
        "aff_country_unique": "Australia;Switzerland"
    },
    {
        "id": "9341749",
        "title": "Parameter Identification for an Uncooperative Captured Satellite with Spinning Reaction Wheels",
        "track": "main",
        "status": "Poster",
        "abstract": "A novel identification method is developed which identifies the accumulated angular momentum (AAM) of spinning reaction wheels (RWs) of an uncooperative satellite captured by a robotic servicer. In contrast to other methods that treat captured satellite's RWs as non-spinning, the developed method provides simultaneously accurate estimates of the AAM of the captured satellite's RWs and of the inertial parameters of the entire system consisting of the robotic servicer and of the captured satellite. These estimates render the system free-floating dynamics fully identified and available to model-based control. Three-dimensional simulations demonstrate the method's validity. To show its usefulness, the performance of a model-based controller is evaluated with and without knowledge of the captured satellite's RWs AAM.",
        "primary_area": "",
        "author": "Olga-Orsalia Christidi-Loumpasefski;Evangelos Papadopoulos;Olga-Orsalia Christidi-Loumpasefski;Evangelos Papadopoulos",
        "authorids": "/37087990228;/37273090500;/37087990228;/37273090500",
        "aff": "School of Mechanical Engineering, NTUA, Greece; School of Mechanical Engineering, NTUA, Greece",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341749/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9926955889208618764&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "National Technical University of Athens",
        "aff_unique_dep": "School of Mechanical Engineering",
        "aff_unique_url": "https://www.ntua.gr",
        "aff_unique_abbr": "NTUA",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Greece"
    },
    {
        "id": "9340908",
        "title": "Parts-Based Articulated Object Localization in Clutter Using Belief Propagation",
        "track": "main",
        "status": "Poster",
        "abstract": "Robots working in human environments must be able to perceive and act on challenging objects with articulations, such as a pile of tools. Articulated objects increase the dimensionality of the pose estimation problem, and partial observations under clutter create additional challenges. To address this problem, we present a generative-discriminative parts-based recognition and localization method for articulated objects in clutter. We formulate the problem of articulated object pose estimation as a Markov Random Field (MRF). Hidden nodes in this MRF express the pose of the object parts, and edges express the articulation constraints between parts. Localization is performed within the MRF using an efficient belief propagation method. The method is informed by both part segmentation heatmaps over the observation, generated by a neural network, and the articulation constraints between object parts. Our generative-discriminative approach allows the proposed method to function in cluttered environments by inferring the pose of occluded parts using hypotheses from the visible parts. We demonstrate the efficacy of our methods in a tabletop environment for recognizing and localizing hand tools in uncluttered and cluttered configurations.",
        "primary_area": "",
        "author": "Jana Pavlasek;Stanley Lewis;Karthik Desingh;Odest Chadwicke Jenkins;Jana Pavlasek;Stanley Lewis;Karthik Desingh;Odest Chadwicke Jenkins",
        "authorids": "/37088689981;/37088686540;/37085705546;/37297252400;/37088689981;/37088686540;/37085705546;/37297252400",
        "aff": "Department of Electrical Engineering and Computer Science, Robotics Institute, University of Michigan, Ann Arbor, MI, USA; Department of Electrical Engineering and Computer Science, Robotics Institute, University of Michigan, Ann Arbor, MI, USA; Department of Electrical Engineering and Computer Science, Robotics Institute, University of Michigan, Ann Arbor, MI, USA; Department of Electrical Engineering and Computer Science, Robotics Institute, University of Michigan, Ann Arbor, MI, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340908/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18192513899285091093&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Michigan",
        "aff_unique_dep": "Department of Electrical Engineering and Computer Science",
        "aff_unique_url": "https://www.umich.edu",
        "aff_unique_abbr": "UM",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Ann Arbor",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340758",
        "title": "Passivity Filter for Variable Impedance Control",
        "track": "main",
        "status": "Poster",
        "abstract": "While impedance control is one of the most commonly used strategies for robot interaction control, variable impedance control is a more recent preoccupation. If designing impedance control with varying parameters allows increasing the system flexibility and dexterity, it is still a challenging issue, as it may result in a loss of passivity of the control system. This has an important impact on the stability and therefore on the safety of the interaction. In this paper, we propose methods to design passivity filters that guarantee passivity of the interaction. They aim at either checking whether a desired impedance profile is passive, or modifying it if required.",
        "primary_area": "",
        "author": "Maciej Bednarczyk;Hassan Omran;Bernard Bayle;Maciej Bednarczyk;Hassan Omran;Bernard Bayle",
        "authorids": "/37087237496;/37087238338;/37588627100;/37087237496;/37087238338;/37588627100",
        "aff": "ICube, UMR 7357, University of Strasbourg, CNRS, Strasbourg, France; ICube, UMR 7357, University of Strasbourg, CNRS, Strasbourg, France; ICube, UMR 7357, University of Strasbourg, CNRS, Strasbourg, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340758/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5920541107504446129&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Strasbourg",
        "aff_unique_dep": "ICube, UMR 7357",
        "aff_unique_url": "https://www.unistra.fr",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Strasbourg",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9341305",
        "title": "Path Negotiation for Self-interested Multirobot Vehicles in Shared Space",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper addresses the problem of path negotiation among self-interested multirobot operators in shared space. In conventional multirobot path planning problems, most of the research thus far has focused on the coordination and planning of collision-free paths for multiple robots with some common objectives. On the contrary, the recent progress of technologies in autonomous vehicles, including automated guidance vehicles, unmanned aerial vehicles, and manned autonomous cars, has increased demand for solving coordination and conflict avoidance in these autonomous and self-interested agents that pursue their own objectives. In this research, we tackle this problem from the operator perspective. We assume a problem setting where collisions between robots are avoided based on path reservation and negotiation. Under that circumstance, we propose a task-oriented utility function and a path negotiation algorithm for robot operators to maximize their task utility during path negotiation. The simulation and experiment results demonstrate the effectiveness of our task-based negotiation method over a simple path-based negotiation approach.",
        "primary_area": "",
        "author": "Hiroaki Inotsume;Aayush Aggarwal;Ryota Higa;Shinji Nakadai;Hiroaki Inotsume;Aayush Aggarwal;Ryota Higa;Shinji Nakadai",
        "authorids": "/38235072700;/37088686801;/37088691362;/37086612440;/38235072700;/37088686801;/37088691362;/37086612440",
        "aff": "Artificial Intelligence Research Center, National Institute of Advanced Industrial Science and Technology, Tokyo, Japan; Data Science Research Laboratories, NEC Corp., Kanagawa, Japan; Artificial Intelligence Research Center, National Institute of Advanced Industrial Science and Technology, Tokyo, Japan; Artificial Intelligence Research Center, National Institute of Advanced Industrial Science and Technology, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341305/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11206852547604295800&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "National Institute of Advanced Industrial Science and Technology;NEC Corp.",
        "aff_unique_dep": "Artificial Intelligence Research Center;Data Science Research Laboratories",
        "aff_unique_url": "https://www.aist.go.jp;https://www.nec.com",
        "aff_unique_abbr": "AIST;NEC",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Tokyo;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9341096",
        "title": "Path Planning Under MIMO Network Constraints for Throughput Enhancement in Multi-robot Data Aggregation Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "Under line-of-sight (LOS) network conditions, multi-input multi-output (MIMO) wireless communications can increase the channel capacity between a team of robots and a multi-antenna array at a stationary base station. This increased capacity can result in greater data throughput, shortening the time necessary to complete channel-limited data aggregation tasks. To take advantage of this higher capacity channel, the robots in the team must be positioned to maximize complex channel orthogonality between each robot and receiver antenna. Using geometrically motivated assumptions, we derive transmitter spacing rules that can be easily be added on to existing path plans to improve backhaul throughput for data offloading from the robot team, with minimal impact on other system objectives. We demonstrate the effectiveness of the approach- both in ideal as well as realistic channels outside the domain of our simplifying assumptions-with numerical examples of robot-coordinated path plans in two example environments, achieving up to 42% improvement in task completion times.",
        "primary_area": "",
        "author": "Alexandra Pogue;Samer Hanna;Andy Nichols;Xin Chen;Danijela Cabric;Ankur Mehta;Alexandra Pogue;Samer Hanna;Andy Nichols;Xin Chen;Danijela Cabric;Ankur Mehta",
        "authorids": "/37085443001;/37086365963;/37088689731;/37088686834;/37271490100;/37086302574;/37085443001;/37086365963;/37088689731;/37088686834;/37271490100;/37086302574",
        "aff": "Mechanical Engineering department, University of California Los Angeles; Electrical Engineering department, University of California Los Angeles; Mathematics department, University of California Santa Barbara; Electrical Engineering department, University of Southern California; Electrical Engineering department, University of California Los Angeles; Electrical Engineering department, University of California Los Angeles",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341096/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4665093043941407734&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;2;0;0",
        "aff_unique_norm": "University of California, Los Angeles;University of California, Santa Barbara;University of Southern California",
        "aff_unique_dep": "Mechanical Engineering department;Mathematics department;Electrical Engineering department",
        "aff_unique_url": "https://www.ucla.edu;https://www.ucsb.edu;https://www.usc.edu",
        "aff_unique_abbr": "UCLA;UCSB;USC",
        "aff_campus_unique_index": "0;0;1;0;0;0",
        "aff_campus_unique": "Los Angeles;Santa Barbara",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341403",
        "title": "Path Planning for Nonholonomic Multiple Mobile Robot System with Applications to Robotic Autonomous Luggage Trolley Collection at Airports",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a novel path planning algorithm for the nonholonomic multiple mobile robot system with applications to a robotic autonomous luggage trolley collection system at airports. We consider this path planning algorithm as a Multiple Traveling Salesman Problem (MTSP). Our path planning algorithm consists of three parts. First, we use the Minimum Spanning Tree (MSP) algorithm to divide the MTSP into a number of independent TSPs, which achieves the task assignment for each mobile robot. Secondly, we implement a closed-loop forward control policy based on the kinematic model of the mobile robot to get a feasible and smooth path. The control cost of the path is used as the new metric in solving the TSPs. Finally, in order to adapt to our case, we modify the TSP as an Open Dynamic Traveling Salesman Problem with Fixed Start (ODTSP-FS) and implement an ant colony algorithm to achieve the path planning for each mobile robot. We evaluate our algorithm with simulation experiments and the experimental results demonstrate that our algorithm can quickly generate feasible and smooth paths for each robot while satisfying the nonholonomic constraints.",
        "primary_area": "",
        "author": "Jiankun Wang;Max Q.-H. Meng;Jiankun Wang;Max Q.-H. Meng",
        "authorids": "/37086100720;/37274117000;/37086100720;/37274117000",
        "aff": "Department of Electronic Engineering, The Chinese University of Hong Kong, N.T., China; Shenzhen Research Institute of the Chinese University of Hong Kong in Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341403/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10101859459921397768&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "The Chinese University of Hong Kong;Chinese University of Hong Kong",
        "aff_unique_dep": "Department of Electronic Engineering;Shenzhen Research Institute",
        "aff_unique_url": "https://www.cuhk.edu.hk;https://www.cuhk.edu.hk",
        "aff_unique_abbr": "CUHK;CUHK",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "N.T.;Shenzhen",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9340760",
        "title": "Path planning for mobile manipulator robots under non-holonomic and task constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a path planner, which enables a nonholonomic mobile manipulator to move its end-effector on an observed surface with a constrained orientation, given start and destination points. A partial point cloud of the environment is captured using a vision-based sensor, but no prior knowledge of the surface shape is assumed. We consider the multi-objective optimisation problem of finding robot paths which account for the nonholonomic constraints of the base, maximise the robot's manipulability throughout the motion, while also minimising surface-distance travelled between the two points. This work has application in industrial problems of rough robotic cutting, e.g. demolition of legacy nuclear plants, where dismantling does not require a precise path. We show how our approach embeds the nonholonomic constraints of the mobile platform into an extended Jacobian, while additionally encoding the constraint that the end-effector must remain in contact with the cut surface throughout the motion. We use this constrained Jacobian to plan a time-series of robot configurations. Additionally, we show how our novel cost function is suitable for combining with a variety of well-known path planners, such as RRT*. We present several empirical experiments in different scenarios, where a simulated non-holonomic mobile manipulator follows a trajectory, which is generated on noisy point clouds derived from real depth-camera images of real objects. Our planner (RRT*-CRMM) enables successful task completion by optimising the path over the travelled distance, the manipulability of the arm, and the movements of the mobile base.",
        "primary_area": "",
        "author": "Tommaso Pardi;Vamsikrishna Maddali;Valerio Ortenzi;Rustam Stolkin;Naresh Marturi;Tommaso Pardi;Vamsikrishna Maddali;Valerio Ortenzi;Rustam Stolkin;Naresh Marturi",
        "authorids": "/37086603585;/37088688174;/37085426095;/37424300500;/37085558507;/37086603585;/37088688174;/37085426095;/37424300500;/37085558507",
        "aff": "Extreme Robotics Laboratory, University of Birmingham, Edgbaston, UK; Extreme Robotics Laboratory, University of Birmingham, Edgbaston, UK; Extreme Robotics Laboratory, University of Birmingham, Edgbaston, UK; Extreme Robotics Laboratory, University of Birmingham, Edgbaston, UK; Extreme Robotics Laboratory, University of Birmingham, Edgbaston, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340760/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15645079738450505105&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Birmingham",
        "aff_unique_dep": "Extreme Robotics Laboratory",
        "aff_unique_url": "https://www.birmingham.ac.uk",
        "aff_unique_abbr": "UoB",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Edgbaston",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9340702",
        "title": "Pattern Analysis and Parameters Optimization of Dynamic Movement Primitives for Learning Unknown Trajectories",
        "track": "main",
        "status": "Poster",
        "abstract": "A robot in the future may initially has a good learning capability but an empty library of movements. It gradually enriches its library of movements through human demonstrations. Dynamic Movement Primitives (DMPs) has been proved to be an effective way to represent trajectories. Trajectories are classified into discrete and rhythmic ones, and parameters are set for each demonstrated trajectory. However, what kind of trajectory will be provided by robot users is sometimes unknown to robot developers, so trajectory pattern and the parameters can not be determined in advance. It's also impossible for non-technical robot users to set these parameters and determine the pattern of movements they are going to demonstrate. To make it easier for non-expert robot users to programme their robots by demonstration, this work presents an efficient way to deal with these two problems. The effectiveness of the proposed methodology is proved by teaching a robot to clean the whiteboard in different ways and stack a set of cubic boxes in specific order.",
        "primary_area": "",
        "author": "Mantian Li;Zeguo Yang;Fusheng Zha;Xin Wang;Pengfei Wang;Wei Guo;Darwin Caldwell;Fei Chen;Mantian Li;Zeguo Yang;Fusheng Zha;Xin Wang;Pengfei Wang;Wei Guo;Darwin Caldwell;Fei Chen",
        "authorids": "/37291657000;/37088687194;/37085373305;/37281382000;/37406354200;/37291945900;/37295680400;/37085388569;/37291657000;/37088687194;/37085373305;/37281382000;/37406354200;/37291945900;/37295680400;/37085388569",
        "aff": "State key Laboratory of Robotics and Systems, Harbin Institute of Technology, Harbin, China; State key Laboratory of Robotics and Systems, Harbin Institute of Technology, Harbin, China; Shenzhen Academy of Aerospace Technology, Shenzhen, China; Shenzhen Academy of Aerospace Technology, Shenzhen, China; State key Laboratory of Robotics and Systems, Harbin Institute of Technology, Harbin, China; State key Laboratory of Robotics and Systems, Harbin Institute of Technology, Harbin, China; Department of Advanced Robotics, Active Perception and Robot Interactive Learning Laboratory, Istituto Italiano di Tecnolog\u00eda, Genova, Italy; Department of Advanced Robotics, Active Perception and Robot Interactive Learning Laboratory, Istituto Italiano di Tecnolog\u00eda, Genova, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340702/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12418840326329512688&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;1;1;0;0;2;2",
        "aff_unique_norm": "Harbin Institute of Technology;Shenzhen Academy of Aerospace Technology;Istituto Italiano di Tecnologia",
        "aff_unique_dep": "State key Laboratory of Robotics and Systems;;Department of Advanced Robotics, Active Perception and Robot Interactive Learning Laboratory",
        "aff_unique_url": "http://www.hit.edu.cn/;;https://www.iit.it",
        "aff_unique_abbr": "HIT;;IIT",
        "aff_campus_unique_index": "0;0;1;1;0;0;2;2",
        "aff_campus_unique": "Harbin;Shenzhen;Genova",
        "aff_country_unique_index": "0;0;0;0;0;0;1;1",
        "aff_country_unique": "China;Italy"
    },
    {
        "id": "9341318",
        "title": "Payload optimization of surgical instruments with rolling joint mechanisms",
        "track": "main",
        "status": "Poster",
        "abstract": "Many surgical robots with steerable surgical instruments have been proposed for endoscopic surgery. Surgical instruments should be small in size for insertion into the body and be able to handle large payloads such as tissue. Because the overall diameter and payload parameters are a trade-off, it is difficult to design an instrument with a large payload while reducing its diameter. In this paper, we optimize the payload of a rolling joint mechanism by deriving the moment equilibrium equation and constraints for endoscopic surgery. A scaled-up prototype was fabricated with the design variables obtained from the optimization, and the validity of the method for calculating the payload was confirmed by the experimentally measured payload. By plotting the distribution of payloads obtained from the moment equilibrium equation, we also confirmed that the payload obtained from the optimization is the maximum. In addition, optimizations with different numbers of joints confirm that the payload tends to decrease as the number of joints increases. This payload optimization method could also be extended to minimizing the deflection of the bending section against external forces and minimizing the diameter of the surgical instrument given the minimum required payload.",
        "primary_area": "",
        "author": "Dong-Ho Lee;Minho Hwang;Joonhwan Kim;Dong-Soo Kwon;Dong-Ho Lee;Minho Hwang;Joonhwan Kim;Dong-Soo Kwon",
        "authorids": "/37086933986;/37085406507;/37086836112;/37278487100;/37086933986;/37085406507;/37086836112;/37278487100",
        "aff": "Robotics Program, Korea Advanced Institute of Science and Technology, Daejeon, South Korea; Department of Electrical Engineering and Computer Science, University of California Berkeley, California, USA; Department of Mechanical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, South Korea; CEO of EasyEndo Surgical Inc",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341318/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13788829826952549082&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;2",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology;University of California, Berkeley;EasyEndo Surgical Inc",
        "aff_unique_dep": "Robotics Program;Department of Electrical Engineering and Computer Science;",
        "aff_unique_url": "https://www.kaist.ac.kr;https://www.berkeley.edu;",
        "aff_unique_abbr": "KAIST;UC Berkeley;",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Daejeon;Berkeley;",
        "aff_country_unique_index": "0;1;0;1",
        "aff_country_unique": "South Korea;United States"
    },
    {
        "id": "9341083",
        "title": "Pedestrian Intention Prediction for Autonomous Driving Using a Multiple Stakeholder Perspective Model",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a multiple stakeholder perspective model (MSPM) which predicts the future pedestrian trajectory observed from vehicle's point of view. For the vehicle-pedestrian interaction, the estimation of the pedestrian's intention is a key factor. However, even if this interaction is commonly initiated by both the human (pedestrian) and the agent (driver), current research focuses on developing a neural network trained by the data from driver's perspective only. In this paper, we suggest a multiple stakeholder perspective model (MSPM) and apply this model for pedestrian intention prediction. The model combines the driver (stakeholder 1) and pedestrian (stakeholder 2) by separating the information based on the perspective. The dataset from pedestrian's perspective have been collected from the virtual reality experiment, and a network that can reflect perspectives of both pedestrian and driver is proposed. Our model achieves the best performance in the existing pedestrian intention dataset, while reducing the trajectory prediction error by average of 4.48% in the short-term (0.5s) and middle-term (1.0s) prediction, and 11.14% in the long-term prediction (1.5s) compared to the previous state-of-the-art.",
        "primary_area": "",
        "author": "Kyungdo Kim;Yoon Kyung Lee;Hyemin Ahn;Sowon Hahn;Songhwai Oh;Kyungdo Kim;Yoon Kyung Lee;Hyemin Ahn;Sowon Hahn;Songhwai Oh",
        "authorids": "/37088686363;/37088689063;/37085492273;/37088691447;/37068116900;/37088686363;/37088689063;/37085492273;/37088691447;/37068116900",
        "aff": "Department of Electrical and Computer Engineering and ASRI, Robot Learning Laboratory, Seoul National University; Department of Psychology, Human Factors Psychology Laboratory, Seoul National University; Department of Electrical and Computer Engineering and ASRI, Robot Learning Laboratory, Seoul National University; Department of Psychology, Human Factors Psychology Laboratory, Seoul National University; Department of Electrical and Computer Engineering and ASRI, Robot Learning Laboratory, Seoul National University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341083/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5507201457701122810&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Seoul National University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.snu.ac.kr",
        "aff_unique_abbr": "SNU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9341173",
        "title": "Pedestrian Motion Tracking by Using Inertial Sensors on the Smartphone",
        "track": "main",
        "status": "Poster",
        "abstract": "Inertial Measurement Unit (IMU) has long been a dream for stable and reliable motion estimation, especially in indoor environments where GPS strength limits. In this paper, we propose a novel method for position and orientation estimation of a moving object only from a sequence of IMU signals collected from the phone. Our main observation is that human motion is monotonous and periodic. We adopt the Extended Kalman Filter and use the learning-based method to dynamically update the measurement noise of the filter. Our pedestrian motion tracking system intends to accurately estimate planar position, velocity, heading direction without restricting the phone's daily use. The method is not only tested on the self-collected signals, but also provides accurate position and velocity estimations on the public RIDI dataset, i.e., the absolute transmit error is 1.28m for a 59-second sequence.",
        "primary_area": "",
        "author": "Yingying Wang;Hu Cheng;Max Q.-H. Meng;Yingying Wang;Hu Cheng;Max Q.-H. Meng",
        "authorids": "/37088689053;/37086801643;/37274117000;/37088689053;/37086801643;/37274117000",
        "aff": "Department of Electronic Engineering, Robotics, Perception and Artificial Intelligence Lab, The Chinese University of Hong Kong, N.T., China; Department of Electronic Engineering, Robotics, Perception and Artificial Intelligence Lab, The Chinese University of Hong Kong, N.T., China; Shenzhen Research Institute of the Chinese University of Hong Kong, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341173/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17042374850357477386&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "The Chinese University of Hong Kong;Chinese University of Hong Kong",
        "aff_unique_dep": "Department of Electronic Engineering;Shenzhen Research Institute",
        "aff_unique_url": "https://www.cuhk.edu.hk;https://www.cuhk.edu.hk",
        "aff_unique_abbr": "CUHK;CUHK",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "N.T.;Shenzhen",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9341068",
        "title": "Peg-in-Hole Using 3D Workpiece Reconstruction and CNN-based Hole Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a method to cope with autonomous assembly tasks in the presence of uncertainties. To this aim, a Peg-in-Hole operation is considered, where the target workpiece position is unknown and the peg-hole clearance is small. Deep learning based hole detection and 3D surface reconstruction techniques are combined for accurate workpiece localization. In detail, the hole is detected by using a convolutional neural network (CNN), while the target workpiece surface is reconstructed via 3D-Digital Image Correlation (3D-DIC). Peg insertion is performed via admittance control that confers the suitable compliance to the peg. Experiments on a collaborative manipulator confirm that the proposed approach can be promising for achieving a better degree of autonomy for a class of robotic tasks in partially structured environments.",
        "primary_area": "",
        "author": "Michelangelo Nigro;Monica Sileo;Francesco Pierri;Katia Genovese;Domenico D. Bloisi;Fabrizio Caccavale;Michelangelo Nigro;Monica Sileo;Francesco Pierri;Katia Genovese;Domenico D. Bloisi;Fabrizio Caccavale",
        "authorids": "/37086942484;/37088690861;/37419558900;/37086395533;/38111727700;/37283127200;/37086942484;/37088690861;/37419558900;/37086395533;/38111727700;/37283127200",
        "aff": "School of Engineering; School of Engineering; School of Engineering; School of Engineering; Department of Mathematics, Computer Science, and Economics, University of Basilicata, Potenza, Italy; School of Engineering",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341068/",
        "gs_citation": 34,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18051778146089196759&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;0",
        "aff_unique_norm": "School of Engineering;University of Basilicata",
        "aff_unique_dep": ";Department of Mathematics, Computer Science, and Economics",
        "aff_unique_url": ";https://www.unibas.it",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Potenza",
        "aff_country_unique_index": "1",
        "aff_country_unique": ";Italy"
    },
    {
        "id": "9341429",
        "title": "Perception-Aware Path Finding and Following of Snake Robot in Unknown Environment",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we investigate the perception-aware path finding, planning and following for a class of snake robots autonomously serpentining in an unmodeled and unknown environment. In the work, the onboard LiDAR sensor mounted on the head of the snake robot is utilized to reconstruct the local environment, by which and the modified rapidly-exploring random tree method, a feasible path from the current position of the robot to a local selected target position can be obtained. Next, the parametric cubic spline interpolation path-planning method and potential functions are applied to make the path more smooth so as to prevent the multi-link and elongated robot body from hitting obstacles. To steer, a time-varying line-of-sight control law is designed to ensure that the robot moves to the local target position along the generated path by the perception-aware method. The robot will repeatedly perform the above search-find-move strategy until it reaches the final predefined target point. Simulation and experimental results demonstrate a good performance of the proposed perception-aware approach, that is, the elongated and underactuated snake robot is capable of autonomously navigating in an unknown environment.",
        "primary_area": "",
        "author": "Weixin Yang;Gang Wang;Yantao Shen;Weixin Yang;Gang Wang;Yantao Shen",
        "authorids": "/37086437281;/37085379673;/37274462800;/37086437281;/37085379673;/37274462800",
        "aff": "Department of Electrical & Biomedical Engineering, University of Nevada, Reno, NV, USA; Department of Electrical & Biomedical Engineering, University of Nevada, Reno, NV, USA; Department of Electrical & Biomedical Engineering, University of Nevada, Reno, NV, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341429/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7124239322920291831&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Nevada, Reno",
        "aff_unique_dep": "Department of Electrical & Biomedical Engineering",
        "aff_unique_url": "https://www.unr.edu",
        "aff_unique_abbr": "UNR",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Reno",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341347",
        "title": "Perception-aware Path Planning for UAVs using Semantic Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we present a perception-aware path-planning pipeline for Unmanned Aerial Vehicles (UAVs) for navigation in challenging environments. The objective is to reach a given destination safely and accurately by relying on monocular camera-based state estimators, such as Keyframe-based Visual-Inertial Odometry (VIO) systems. Motivated by the recent advances in semantic segmentation using deep learning, our path-planning architecture takes into consideration the semantic classes of parts of the scene that are perceptually more informative than others. This work proposes a planning strategy capable of avoiding both texture-less regions and problematic areas, such as lakes and oceans, that may cause large drift or failures in the robot's pose estimation, by using the semantic information to compute the next best action with respect to perception quality. We design a hierarchical planner, composed of an A* path-search step followed by B-Spline trajectory optimization. While the A* steers the UAV towards informative areas, the optimizer keeps the most promising landmarks in the camera's field of view. We extensively evaluate our approach in a set of photo-realistic simulations, showing a remarkable improvement with respect to the state-of-the-art in active perception.",
        "primary_area": "",
        "author": "Luca Bartolomei;Lucas Teixeira;Margarita Chli;Luca Bartolomei;Lucas Teixeira;Margarita Chli",
        "authorids": "/37087322350;/37086010655;/37546501900;/37087322350;/37086010655;/37546501900",
        "aff": "Vision For Robotics Lab, ETH Z\u00fcrich, Switzerland; Vision For Robotics Lab, ETH Z\u00fcrich, Switzerland; Vision For Robotics Lab, ETH Z\u00fcrich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341347/",
        "gs_citation": 68,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=434539748616633298&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "ETH Z\u00fcrich",
        "aff_unique_dep": "Vision For Robotics Lab",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETH",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9340730",
        "title": "Performance Characterization of an Algorithm to Estimate the Search Skill of a Human or Robot Agent",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper characterizes an algorithm that estimates searcher skill level to support planning for search activities involving heterogeneous robot and human/robot teams. Specifically, we use Monte-Carlo simulations to determine the empirical accuracy of the estimator, to assess the quality of its predicted distribution (nonparametric) of agent skill levels, and the convergence rate of the estimate. The simulation study suggests that a single challenging search task can be used to estimate searcher skill within about 10%; however, the quality of the estimate is higher when searcher skill is high.",
        "primary_area": "",
        "author": "Audrey Balaska;Jason H. Rife;Audrey Balaska;Jason H. Rife",
        "authorids": "/37088685916;/37267924800;/37088685916;/37267924800",
        "aff": "School of Engineering, Tufts University, Medford, MA, USA; School of Engineering, Tufts University, Medford, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340730/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8703073961654374773&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Tufts University",
        "aff_unique_dep": "School of Engineering",
        "aff_unique_url": "https://www.tufts.edu",
        "aff_unique_abbr": "Tufts",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Medford",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341662",
        "title": "Persistent Connected Power Constrained Surveillance with Unmanned Aerial Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "Persistent surveillance with aerial vehicles (drones) subject to connectivity and power constraints is a relatively uncharted domain of research. To reduce the complexity of multi-drone motion planning, most state-of-the-art solutions ignore network connectivity and assume unlimited battery power. Motivated by this and advances in optimization and constraint satisfaction techniques, we introduce a new persistent surveillance motion planning problem for multiple drones that incorporates connectivity and power consumption constraints. We use a recently developed constrained optimization tool (Satisfiability Modulo Convex Optimization (SMC)) that has the expressivity needed for this problem. We show how to express the new persistent surveillance problem in the SMC framework. Our analysis of the formulation based on a set of simulation experiments illustrates that we can generate the desired motion planning solution within a couple of minutes for small teams of drones (up to 5) confined to a 7 \u00d7 7 \u00d7 1 grid-space.",
        "primary_area": "",
        "author": "Pradipta Ghosh;Paulo Tabuada;Ramesh Govindan;Gaurav S. Sukhatme;Pradipta Ghosh;Paulo Tabuada;Ramesh Govindan;Gaurav S. Sukhatme",
        "authorids": "/37085556500;/37300854400;/37279228000;/37278934100;/37085556500;/37300854400;/37279228000;/37278934100",
        "aff": "Department of Computer Science, University of Southern California, Los Angeles, CA, USA; Department of Electrical and Computer Engineering, University of California at Los Angeles, Los Angeles, CA, USA; Department of Computer Science, University of Southern California, Los Angeles, CA, USA; Department of Computer Science, University of Southern California, Los Angeles, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341662/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:YSWlXtt9kb4J:scholar.google.com/&scioq=Persistent+Connected+Power+Constrained+Surveillance+with+Unmanned+Aerial+Vehicles&hl=en&as_sdt=0,5",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "University of Southern California;University of California, Los Angeles",
        "aff_unique_dep": "Department of Computer Science;Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.usc.edu;https://www.ucla.edu",
        "aff_unique_abbr": "USC;UCLA",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341632",
        "title": "Personalized Online Learning with Pseudo-Ground Truth",
        "track": "main",
        "status": "Poster",
        "abstract": "Personalized online machine learning allows a very accurate modelling of individual behavior and demands. In particular, a system that dynamically adapts during runtime can initiate a continuous collaboration with its user where both alternately adjust to each other to maximize the system's utility. However, in application scenarios based on supervised learning it is often unclear how to obtain the required ground truth for such dynamic systems. In this paper, we focus on applications where a real-time classification of sequential data is crucial. Concretely, we propose to adapt an online personalized model solely based on pseudo-ground-truth information which is provided by another machine learning model. This model has the advantage to classify sequences in retrospective with a small delay and thus is able to achieve a higher performance than real-time systems. In particular, it is a pre-trained offline model, which means that no ground-truth information is necessary during runtime. We apply the proposal on the task of online action classification, for which the benefits of personalization have been recently emphasized.",
        "primary_area": "",
        "author": "Viktor Losing;Martina Hasenj\u00e4ger;Taizo Yoshikawa;Viktor Losing;Martina Hasenj\u00e4ger;Taizo Yoshikawa",
        "authorids": "/37085733484;/37561031300;/37086933583;/37085733484;/37561031300;/37086933583",
        "aff": "HONDA Research Institute Europe, Offenbach am Main, Germany; HONDA Research Institute Europe, Offenbach am Main, Germany; HONDA R&D Co., Ltd., Saitama, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341632/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4239884654294954819&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Honda Research Institute Europe;Honda R&D Co., Ltd.",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.honda-ri.de;https://www.honda.com/",
        "aff_unique_abbr": "HRI-Europe;Honda R&D",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Offenbach am Main;",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "Germany;Japan"
    },
    {
        "id": "9341053",
        "title": "Physical Human-Robot Interaction with Real Active Surfaces using Haptic Rendering on Point Clouds",
        "track": "main",
        "status": "Poster",
        "abstract": "During robot-assisted therapy of hemiplegic patients, interaction with the patient must be intrinsically safe. Straight-forward collision avoidance solutions can provide this safety requirement with conservative margins. These margins heavily reduce the robot's workspace and make interaction with the patient's unguided body parts impossible. However, interaction with the own body is highly beneficial from a therapeutic point of view. We tackle this problem by combining haptic rendering techniques with classical computer vision methods. Our proposed solution consists of a pipeline that builds collision objects from point clouds in real-time and a controller that renders haptic interaction. The raw sensor data is processed to overcome noise and occlusion problems. Our proposed approach is validated on the 6 DoF exoskeleton ANYexo for direct impacts, sliding scenarios, and dynamic collision surfaces. The results show that this method has the potential to successfully prevent collisions and allow haptic interaction for highly dynamic environments. We believe that this work significantly adds to the usability of current exoskeletons by enabling virtual haptic interaction with the patient's body parts in human-robot therapy.",
        "primary_area": "",
        "author": "Michael Sommerhalder;Yves Zimmermann;Burak Cizmeci;Robert Riener;Marco Hutter;Michael Sommerhalder;Yves Zimmermann;Burak Cizmeci;Robert Riener;Marco Hutter",
        "authorids": "/37088687217;/37089133835;/37569333500;/37281610400;/37545251000;/37088687217;/37089133835;/37569333500;/37281610400;/37545251000",
        "aff": "",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341053/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14250355010662535137&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10
    },
    {
        "id": "9340947",
        "title": "Physics-Based Dexterous Manipulations with Estimated Hand Poses and Residual Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Dexterous manipulation of objects in virtual environments with our bare hands, by using only a depth sensor and a state-of-the-art 3D hand pose estimator (HPE), is challenging. While virtual environments are ruled by physics, e.g. object weights and surface frictions, the absence of force feedback makes the task challenging, as even slight inaccuracies on finger tips or contact points from HPE may make the interactions fail. Prior arts simply generate contact forces in the direction of the fingers' closures, when finger joints penetrate virtual objects. Although useful for simple grasping scenarios, they cannot be applied to dexterous manipulations such as inhand manipulation. Existing reinforcement learning (RL) and imitation learning (IL) approaches train agents that learn skills by using task-specific rewards, without considering any online user input. In this work, we propose to learn a model that maps noisy input hand poses to target virtual poses, which introduces the needed contacts to accomplish the tasks on a physics simulator. The agent is trained in a residual setting by using a model-free hybrid RL+IL approach. A 3D hand pose estimation reward is introduced leading to an improvement on HPE accuracy when the physics-guided corrected target poses are remapped to the input space. As the model corrects HPE errors by applying minor but crucial joint displacements for contacts, this helps to keep the generated motion visually close to the user input. Since HPE sequences performing successful virtual interactions do not exist, a data generation scheme to train and evaluate the system is proposed. We test our framework in two applications that use hand pose estimates for dexterous manipulations: hand-object interactions in VR and hand-object motion reconstruction in-the-wild. Experiments show that the proposed method outperforms various RL/IL baselines and the simple prior art of enforcing hand closure, both in task success and hand pose accuracy. Show More",
        "primary_area": "",
        "author": "Guillermo Garcia-Hernando;Edward Johns;Tae-Kyun Kim;Guillermo Garcia-Hernando;Edward Johns;Tae-Kyun Kim",
        "authorids": "/37085396272;/37602799000;/37280613000;/37085396272;/37602799000;/37280613000",
        "aff": "Niantic, Inc., United Kingdom; Imperial College London, United Kingdom; KAIST, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340947/",
        "gs_citation": 62,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3041556176264543781&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Niantic, Inc.;Imperial College London;Korea Advanced Institute of Science and Technology",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.nianticlabs.com;https://www.imperial.ac.uk;https://www.kaist.ac.kr",
        "aff_unique_abbr": "Niantic;ICL;KAIST",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "United Kingdom;South Korea"
    },
    {
        "id": "9340931",
        "title": "PillarFlow: End-to-end Birds-eye-view Flow Estimation for Autonomous Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "In autonomous driving, accurately estimating the state of surrounding obstacles is critical for safe and robust path planning. However, this perception task is difficult, particularly for generic obstacles/objects, due to appearance and occlusion changes. To tackle this problem, we propose an end-to-end deep learning framework for LIDAR-based flow estimation in bird's eye view (BeV). Our method takes consecutive point cloud pairs as input and produces a 2-D BeV flow grid describing the dynamic state of each cell. The experimental results show that the proposed method not only estimates 2-D BeV flow accurately but also improves tracking performance of both dynamic and static objects.",
        "primary_area": "",
        "author": "Kuan-Hui Lee;Matthew Kliemann;Adrien Gaidon;Jie Li;Chao Fang;Sudeep Pillai;Wolfram Burgard;Kuan-Hui Lee;Matthew Kliemann;Adrien Gaidon;Jie Li;Chao Fang;Sudeep Pillai;Wolfram Burgard",
        "authorids": "/37072359700;/37088687943;/37945420900;/37085348265;/37088457928;/37086936518;/37270485300;/37072359700;/37088687943;/37945420900;/37085348265;/37088457928;/37086936518;/37270485300",
        "aff": "Toyota Research Institute, USA; Toyota Research Institute, USA; Toyota Research Institute, USA; Toyota Research Institute, USA; Toyota Research Institute, USA; Toyota Research Institute, USA; Toyota Research Institute, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340931/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4685105263998787213&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Toyota Research Institute",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.tri.global",
        "aff_unique_abbr": "TRI",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341002",
        "title": "PillarFlowNet: A Real-time Deep Multitask Network for LiDAR-based 3D Object Detection and Scene Flow Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Mobile robotic platforms require a precise understanding about other agents in their surroundings as well as their respective motion in order to operate safely. Scene flow in combination with object detection can be used to achieve this understanding. Together, they provide valuable cues for behavior prediction of other agents and thus ultimately are a good basis for the ego-vehicle's behavior planning algorithms. Traditionally, scene flow estimation and object detection are handled by separate deep networks requiring immense computational resources. In this work, we propose PillarFlowNet, a novel method for simultaneous LiDAR scene flow estimation and object detection with low latency and high precision based on a single network. In our experiments on the KITTI dataset, PillarFlowNet achieves a 16.3 percentage points higher average precision score as well as a 21.4 % reduction in average endpoint error for scene flow compared to the state-of-the-art in multitask LiDAR object detection and scene flow estimation. Furthermore, our method is significantly faster than previous methods, making it the first to be applicable for real-time systems.",
        "primary_area": "",
        "author": "Fabian Duffhauss;Stefan A. Baur;Fabian Duffhauss;Stefan A. Baur",
        "authorids": "/37088687289;/37086956990;/37088687289;/37086956990",
        "aff": "Bosch Center for Artificial Intelligence, Renningen, Germany; Mercedes-Benz AG, Stuttgart, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341002/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10733872112715804068&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Bosch Center for Artificial Intelligence;Mercedes-Benz AG",
        "aff_unique_dep": "Artificial Intelligence;",
        "aff_unique_url": "https://www.bosch-ai.com;https://www.mercedes-benz.com",
        "aff_unique_abbr": "BCAI;MB AG",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Renningen;Stuttgart",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9340924",
        "title": "Pit30M: A Benchmark for Global Localization in the Age of Self-Driving Cars",
        "track": "main",
        "status": "Poster",
        "abstract": "We are interested in understanding whether retrieval-based localization approaches are good enough in the context of self-driving vehicles. Towards this goal, we introduce Pit30M, a new image and LiDAR dataset with over 30 million frames, which is 10 to 100 times larger than those used in previous work. Pit30M is captured under diverse conditions (i.e., season, weather, time of the day, traffic), and provides accurate localization ground truth. We also automatically annotate our dataset with historical weather and astronomical data, as well as with image and LiDAR semantic segmentation as a proxy measure for occlusion. We benchmark multiple existing methods for image and LiDAR retrieval and, in the process, introduce a simple, yet effective convolutional network-based LiDAR retrieval method that is competitive with the state of the art. Our work provides, for the first time, a benchmark for sub-metre retrieval-based localization at city scale.The dataset, additional experimental results, as well as more information about the sensors, calibration, and metadata, are available on the project website: https://uber.com/atg/datasets/pit30m.",
        "primary_area": "",
        "author": "Julieta Martinez;Sasha Doubov;Jack Fan;loan Andrei B\u00e2rsan;Shenlong Wang;Gell\u00e9rt M\u00e1ttyus;Raquel Urtasun;Julieta Martinez;Sasha Doubov;Jack Fan;loan Andrei B\u00e2rsan;Shenlong Wang;Gell\u00e9rt M\u00e1ttyus;Raquel Urtasun",
        "authorids": "/37087230753;/37088686297;/37088687680;/37088688402;/37085699650;/37085564132;/37269502900;/37087230753;/37088686297;/37088687680;/37088688402;/37085699650;/37085564132;/37269502900",
        "aff": "Uber Advanced Technologies Group; University of Waterloo; Uber Advanced Technologies Group; University of Toronto; University of Toronto; Uber Advanced Technologies Group; University of Toronto",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340924/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4869204875867602873&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;0;2;2;0;2",
        "aff_unique_norm": "Uber;University of Waterloo;University of Toronto",
        "aff_unique_dep": "Advanced Technologies Group;;",
        "aff_unique_url": "https://www.uber.com;https://uwaterloo.ca;https://www.utoronto.ca",
        "aff_unique_abbr": "Uber ATG;UW;U of T",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0;1;1;0;1",
        "aff_country_unique": "United States;Canada"
    },
    {
        "id": "9340873",
        "title": "PlaNet of the Bayesians: Reconsidering and Improving Deep Planning Network by Incorporating Bayesian Inference",
        "track": "main",
        "status": "Poster",
        "abstract": "In the present paper, we propose an extension of the Deep Planning Network (PlaNet), also referred to as PlaNet of the Bayesians (PlaNet-Bayes). There has been a growing demand in model predictive control (MPC) in partially observable environments in which complete information is unavailable because of, for example, lack of expensive sensors. PlaNet is a promising solution to realize such latent MPC, as it is used to train state-space models via model-based reinforcement learning (MBRL) and to conduct planning in the latent space. However, recent state-of-the-art strategies mentioned in MBRR literature, such as involving uncertainty into training and planning, have not been considered, significantly suppressing the training performance. The proposed extension is to make PlaNet uncertainty-aware on the basis of Bayesian inference, in which both model and action uncertainty are incorporated. Uncertainty in latent models is represented using a neural network ensemble to approximately infer model posteriors. The ensemble of optimal action candidates is also employed to capture multimodal uncertainty in the optimality. The concept of the action ensemble relies on a general variational inference MPC (VI-MPC) framework and its instance, probabilistic action ensemble with trajectory sampling (PaETS). In this paper, we extend VI-MPC and PaETS, which have been originally introduced in previous literature, to address partially observable cases. We experimentally compare the performances on continuous control tasks, and conclude that our method can consistently improve the asymptotic performance compared with PlaNet.",
        "primary_area": "",
        "author": "Masashi Okada;Norio Kosaka;Tadahiro Taniguchi;Masashi Okada;Norio Kosaka;Tadahiro Taniguchi",
        "authorids": "/37086454122;/37088691492;/37273806600;/37086454122;/37088691492;/37273806600",
        "aff": "AI Solutions Center, Business Innovation Division, Panasonic Corporation, Japan; AI Solutions Center, Business Innovation Division, Panasonic Corporation, Japan; College of Information Science and Engineering, Ritsumeikan University, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340873/",
        "gs_citation": 43,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14066454880239359981&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Panasonic Corporation;Ritsumeikan University",
        "aff_unique_dep": "AI Solutions Center, Business Innovation Division;College of Information Science and Engineering",
        "aff_unique_url": "https://www.panasonic.com;https://www.ritsumei.ac.jp",
        "aff_unique_abbr": "Panasonic;Ritsumeikan",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9341031",
        "title": "Planning for robust visibility-based pursuit-evasion",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper addresses the problem of planning for visibility-based pursuit evasion, in contexts where the pursuer robot may experience some positioning errors as it moves in search of the evader. Specifically, we consider the case in which a pursuer with an omnidirectional sensor searches a known environment to locate an evader that may move arbitrarily quickly. Known algorithms for this problem are based on decompositions of the environment into regions, followed by a search for a sequence of those regions through which the pursuer should pass. In this paper, we note that these regions can be arbitrarily small, and thus that the movement accuracy required of the pursuer may be arbitrarily high. To resolve this limitation, we introduce the notion of an \u03b5-robust solution strategy, in which \u03b5 is an upper bound on the positioning error that the pursuer may experience. We establish sufficient conditions under which a solution strategy is \u03b5-robust, and introduce an algorithm that determines, for a given environment, the largest value of \u03b5 for which a solution strategy satisfying those sufficient conditions exists. We de-scribe an implementation and show simulated results demonstrating the effectiveness of the approach.",
        "primary_area": "",
        "author": "Nicholas M. Stiffler;Jason M. O\u2019Kane;Nicholas M. Stiffler;Jason M. O\u2019Kane",
        "authorids": "/37947254000;/37279835400;/37947254000;/37279835400",
        "aff": "Department of Computer Science and Engineering, University of South Carolina, Columbia, SC, USA; Department of Computer Science and Engineering, University of South Carolina, Columbia, SC, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341031/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15030079301514143135&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of South Carolina",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.sc.edu",
        "aff_unique_abbr": "USC",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Columbia",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340636",
        "title": "Planning on the fast lane: Learning to interact using attention mechanisms in path integral inverse reinforcement learning",
        "track": "main",
        "status": "Poster",
        "abstract": "General-purpose trajectory planning algorithms for automated driving utilize complex reward functions to perform a combined optimization of strategic, behavioral, and kinematic features. The specification and tuning of a single reward function is a tedious task and does not generalize over a large set of traffic situations. Deep learning approaches based on path integral inverse reinforcement learning have been successfully applied to predict local situation-dependent reward functions using features of a set of sampled driving policies. Sample-based trajectory planning algorithms are able to approximate a spatio-temporal subspace of feasible driving policies that can be used to encode the context of a situation. However, the interaction with dynamic objects requires an extended planning horizon, which depends on sequential context modeling. In this work, we are concerned with the sequential reward prediction over an extended time horizon. We present a neural network architecture that uses a policy attention mechanism to generate a low-dimensional context vector by concentrating on trajectories with a human-like driving style. Apart from this, we propose a temporal attention mechanism to identify context switches and allow for stable adaptation of rewards. We evaluate our results on complex simulated driving situations, including other moving vehicles. Our evaluation shows that our policy attention mechanism learns to focus on collision-free policies in the configuration space. Furthermore, the temporal attention mechanism learns persistent interaction with other vehicles over an extended planning horizon.",
        "primary_area": "",
        "author": "Sascha Rosbach;Xing Li;Simon Gro\u00dfjohann;Silviu Homoceanu;Stefan Roth;Sascha Rosbach;Xing Li;Simon Gro\u00dfjohann;Silviu Homoceanu;Stefan Roth",
        "authorids": "/37087324291;/37088506773;/37087323047;/37889212600;/37282906600;/37087324291;/37088506773;/37087323047;/37889212600;/37282906600",
        "aff": "Department of Computer Science, Visual Inference Lab, Technische Universit\u00e4t Darmstadt, 64289, Germany; Volkswagen AG, Wolfsburg, Germany; Volkswagen AG, Wolfsburg, Germany; Volkswagen AG, Wolfsburg, Germany; Department of Computer Science, Visual Inference Lab, Technische Universit\u00e4t Darmstadt, 64289, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340636/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12428062350330489823&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;0",
        "aff_unique_norm": "Technische Universit\u00e4t Darmstadt;Volkswagen AG",
        "aff_unique_dep": "Department of Computer Science;",
        "aff_unique_url": "https://www.tu-darmstadt.de;https://www.volkswagenag.com",
        "aff_unique_abbr": "TUD;VW",
        "aff_campus_unique_index": "1;1;1",
        "aff_campus_unique": ";Wolfsburg",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9341611",
        "title": "Plug-and-Play SLAM: A Unified SLAM Architecture for Modularity and Ease of Use",
        "track": "main",
        "status": "Poster",
        "abstract": "Simultaneous Localization and Mapping (SLAM) is considered a mature research field with numerous applications and publicly available open-source systems. Despite this maturity, existing SLAM systems often rely on ad-hoc implementations or are tailored to predefined sensor setups. In this work, we tackle these issues, proposing a novel unified SLAM architecture specifically designed to standardize the SLAM problem and to address heterogeneous sensor configurations. Thanks to its modularity and design patterns, the presented framework is easy to extend, maximizes code reuse and improves computational efficiency. We show in our experiments with a variety of typical sensor configurations that these advantages come without compromising state-of-the-art SLAM performance. The result demonstrates the architecture's relevance for facilitating further research in (multi-sensor) SLAM and its transfer into practical applications.",
        "primary_area": "",
        "author": "Mirco Colosi;Irvin Aloise;Tiziano Guadagnino;Dominik Schlegel;Bartolomeo Della Corte;Kai O. Arras;Giorgio Grisetti;Mirco Colosi;Irvin Aloise;Tiziano Guadagnino;Dominik Schlegel;Bartolomeo Della Corte;Kai O. Arras;Giorgio Grisetti",
        "authorids": "/37086455775;/37086847602;/37087324270;/37086203780;/37085797612;/37276687700;/37324134600;/37086455775;/37086847602;/37087324270;/37086203780;/37085797612;/37276687700;/37324134600",
        "aff": "Robert Bosch Corporate Research, Stuttgart, Germany; Department of Computer, Control, and Management Engineering \u2019\u2019Antonio Ruberti\", Sapienza University of Rome, Rome, Italy; Department of Computer, Control, and Management Engineering \u2019\u2019Antonio Ruberti\", Sapienza University of Rome, Rome, Italy; Department of Computer, Control, and Management Engineering \u2019\u2019Antonio Ruberti\", Sapienza University of Rome, Rome, Italy; Department of Computer, Control, and Management Engineering \u2019\u2019Antonio Ruberti\", Sapienza University of Rome, Rome, Italy; Robert Bosch Corporate Research, Stuttgart, Germany; Department of Computer, Control, and Management Engineering \u2019\u2019Antonio Ruberti\", Sapienza University of Rome, Rome, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341611/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13087004005790073563&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;1;1;1;0;1",
        "aff_unique_norm": "Robert Bosch Corporate Research;Sapienza University of Rome",
        "aff_unique_dep": ";Department of Computer, Control, and Management Engineering \u2018Antonio Ruberti\u2019",
        "aff_unique_url": "https://research.bosch.com;https://www.uniroma1.it",
        "aff_unique_abbr": "Bosch Research;Sapienza",
        "aff_campus_unique_index": "0;1;1;1;1;0;1",
        "aff_campus_unique": "Stuttgart;Rome",
        "aff_country_unique_index": "0;1;1;1;1;0;1",
        "aff_country_unique": "Germany;Italy"
    },
    {
        "id": "9340751",
        "title": "PnuGrip: An Active Two-Phase Gripper for Dexterous Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "We present the design of an active two-phase finger for mechanically mediated dexterous manipulation. The finger enables re-orientation of a grasped object by using a pneumatic braking mechanism to transition between free-rotating and fixed (i.e., braked) phases. Our design allows controlled high-bandwidth (5 Hz) phase transitions independent of the grasping force for manipulation of a variety of objects. Moreover, its thin profile (1 cm) facilitates picking and placing in clutter. Finally, the design features a sensor for measuring fingertip rotation to support feedback control. We experimentally characterize the finger's load handling capacity in the brake phase and rotational resistance in the free phase. We also demonstrate several pick-and-place manipulations common to industrial and laboratory automation settings that are simplified by our design.",
        "primary_area": "",
        "author": "Ian H. Taylor;Nikhil Chavan-Dafle;Godric Li;Neel Doshi;Alberto Rodriguez;Ian H. Taylor;Nikhil Chavan-Dafle;Godric Li;Neel Doshi;Alberto Rodriguez",
        "authorids": "/37087390549;/37085487604;/37088690181;/37085537968;/38194796600;/37087390549;/37085487604;/37088690181;/37085537968;/38194796600",
        "aff": "Dept. of Mechanical Engineering, Massachusetts Institute of Technology; Dept. of Mechanical Engineering, Massachusetts Institute of Technology; Dept. of Mechanical Engineering, Massachusetts Institute of Technology; Intelligence Community Postdoctoral Research Fellowship Program, Massachusetts Institute of Technology, Cambridge, MA; Dept. of Mechanical Engineering, Massachusetts Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340751/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3223176034087403211&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Dept. of Mechanical Engineering",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341771",
        "title": "Point Cloud Based Reinforcement Learning for Sim-to-Real and Partial Observability in Visual Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "Reinforcement Learning (RL), among other learning-based methods, represents powerful tools to solve complex robotic tasks (e.g., actuation, manipulation, navigation, etc.), with the need for real-world data to train these systems as one of its most important limitations. The use of simulators is one way to address this issue, yet knowledge acquired in simulations does not work directly in the real-world, which is known as the sim-to-real transfer problem. While previous works focus on the nature of the images used as observations (e.g., textures and lighting), which has proven useful for a sim-to-sim transfer, they neglect other concerns regarding said observations, such as precise geometrical meanings, failing at robot-to-robot, and thus in sim-to-real transfers. We propose a method that learns on an observation space constructed by point clouds and environment randomization, generalizing among robots and simulators to achieve sim-to-real, while also addressing partial observability. We demonstrate the benefits of our methodology on the point goal navigation task, in which our method proves to be highly unaffected to unseen scenarios produced by robot-to-robot transfer, outperforms image-based baselines in robot-randomized experiments, and presents high performances in sim-to-sim conditions. Finally, we perform several experiments to validate the sim-to-real transfer to a physical domestic robot platform, confirming the out-of-the-box performance of our system.",
        "primary_area": "",
        "author": "Kenzo Lobos-Tsunekawa;Tatsuya Harada;Kenzo Lobos-Tsunekawa;Tatsuya Harada",
        "authorids": "/37086417885;/37274148900;/37086417885;/37274148900",
        "aff": "Graduate School of Information Science and Technology, The University of Tokyo, Japan; RIKEN Center for Advanced Intelligence Project (RIKEN AIP), Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341771/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=367410074056228032&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "The University of Tokyo;RIKEN Center for Advanced Intelligence Project",
        "aff_unique_dep": "Graduate School of Information Science and Technology;Advanced Intelligence Project",
        "aff_unique_url": "https://www.u-tokyo.ac.jp;https://www.riken.jp/en/research/labs/aip/",
        "aff_unique_abbr": "UTokyo;RIKEN AIP",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9340862",
        "title": "Point Cloud Completion by Learning Shape Priors",
        "track": "main",
        "status": "Poster",
        "abstract": "In view of the difficulty in reconstructing object details in point cloud completion, we propose a shape prior learning method for object completion. The shape priors include geometric information in both complete and the partial point clouds. We design a feature alignment strategy to learn the shape prior from complete points, and a coarse to fine strategy to incorporate partial prior in the fine stage. To learn the complete objects prior, we first train a point cloud auto-encoder to extract the latent embeddings from complete points. Then we learn a mapping to transfer the point features from partial points to that of the complete points by optimizing feature alignment losses. The feature alignment losses consist of a L2 distance and an adversarial loss obtained by Maximum Mean Discrepancy Generative Adversarial Network (MMD-GAN). The L2 distance optimizes the partial features towards the complete ones in the feature space, and MMD-GAN decreases the statistical distance of two point features in a Reproducing Kernel Hilbert Space. We achieve state-of-the-art performances on the point cloud completion task. Our code is available at https://github.com/xiaogangw/point-cloud-completion-shape-prior.",
        "primary_area": "",
        "author": "Xiaogang Wang;Marcelo H Ang;Gim Hee Lee;Xiaogang Wang;Marcelo H Ang;Gim Hee Lee",
        "authorids": "/37281375500;/37279138700;/37088505845;/37281375500;/37279138700;/37088505845",
        "aff": "Department of Mechanical Engineering, National University of Singapore; Department of Mechanical Engineering, National University of Singapore; Computer Vision and Robotic Perception (CVRP) Lab, Department of Computer Science, National University of Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340862/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16445768814917240508&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "National University of Singapore",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.nus.edu.sg",
        "aff_unique_abbr": "NUS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "9341742",
        "title": "Polygonal Perception for Mobile Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Geometric primitives are a compact and versatile representation of the environment and the objects within. From a motion planning perspective, the geometric structure can be leveraged in order to implement potentially faster and smoother motion control algorithms than it has been possible with grid-based occupancy maps so far. In this paper, we introduce a novel perception pipeline that efficiently processes the point cloud obtained from an RGB-D sensor in order to produce a floor-projected 2D map in the field-of-view of the robot where obstacles are represented as polygons rather than cells. These polygons can then be processed by path planning algorithms and obstacle avoidance controllers. Our pipeline includes a ground floor plane detector that performs significantly faster than other contemporary solutions and a grid segmentation algorithm that uses image processing techniques to identify the contours of obstacles in order to convert them to polygons. We demonstrate the performance of our approach in experiments with a wheeled and a humanoid robot and show that our polygonal perception pipeline works robustly even in the presence of the disturbances caused by the shaking of a walking robot.",
        "primary_area": "",
        "author": "Marcell Missura;Arindam Roychoudhury;Maren Bennewitz;Marcell Missura;Arindam Roychoudhury;Maren Bennewitz",
        "authorids": "/37947347600;/37088690601;/37324765000;/37947347600;/37088690601;/37324765000",
        "aff": "Humanoid Robots Lab, University of Bonn, Germany; Humanoid Robots Lab, University of Bonn, Germany; Humanoid Robots Lab, University of Bonn, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341742/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15033903319281762604&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Bonn",
        "aff_unique_dep": "Humanoid Robots Lab",
        "aff_unique_url": "https://www.uni-bonn.de",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9340720",
        "title": "Practical Verification of Neural Network Enabled State Estimation System for Robotics",
        "track": "main",
        "status": "Poster",
        "abstract": "We study for the first time the verification problem on learning-enabled state estimation systems for robotics, which use Bayes filter for localisation, and use deep neural network to process sensory input into observations for the Bayes filter. Specifically, we are interested in a robustness property of the systems: given a certain ability to an adversary for it to attack the neural network without being noticed, whether or not the state estimation system is able to function with only minor loss of localisation precision? For verification purposes, we reduce the state estimation systems to a novel class of labelled transition systems with payoffs and partial order relations, and formally express the robustness property as a constrained optimisation objective. Based on this, practical verification algorithms are developed. As a major case study, we work with a real-world dynamic tracking system that uses a Kalman filter (a special case of the Bayes filter) to localise and track a ground vehicle. Its perception system, based on convolutional neural networks, processes a high-resolution Wide Area Motion Imagery (WAMI) data stream. Experimental results show that our algorithms can not only verify the robustness of the WAMI tracking system but also provide useful counterexamples.",
        "primary_area": "",
        "author": "Wei Huang;Yifan Zhou;Youcheng Sun;James Sharp;Simon Maskell;Xiaowei Huang;Wei Huang;Yifan Zhou;Youcheng Sun;James Sharp;Simon Maskell;Xiaowei Huang",
        "authorids": "/37088689668;/37086025543;/37086279943;/37086941163;/37268735800;/37086944121;/37088689668;/37086025543;/37086279943;/37086941163;/37268735800;/37086944121",
        "aff": "school of Electrical Engineering, Electronics and Computer Science (EEECS), University of Liverpool, UK; school of Electrical Engineering, Electronics and Computer Science (EEECS), University of Liverpool, UK; School of Electronics, Electrical Engineering and Computer Science, Queen\u2019s University, Belfast, UK; Defence Science and Technology Laboratory, UK; school of Electrical Engineering, Electronics and Computer Science (EEECS), University of Liverpool, UK; school of Electrical Engineering, Electronics and Computer Science (EEECS), University of Liverpool, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340720/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15034288950437258118&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;2;0;0",
        "aff_unique_norm": "University of Liverpool;Queen\u2019s University Belfast;Defence Science and Technology Laboratory",
        "aff_unique_dep": "school of Electrical Engineering, Electronics and Computer Science (EEECS);School of Electronics, Electrical Engineering and Computer Science;",
        "aff_unique_url": "https://www.liverpool.ac.uk;https://www.qub.ac.uk;https://www dstl.gov.uk",
        "aff_unique_abbr": "Liv Uni;QUB;DSTL",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Belfast",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9341301",
        "title": "Predicting the human behaviour in human-robot co-assemblies: an approach based on suffix trees",
        "track": "main",
        "status": "Poster",
        "abstract": "Prediction of the human behaviour is essential for allowing an efficient human-robot collaboration. This was confirmed recently showing how scheduling approaches can significantly increase the productivity of a robotic cell by planning the robotic actions in a way as much as possible compliant with the human predicted behaviour. This work proposes an innovative approach for human activity prediction, exploiting both a-priori information and knowledge revealed during operation. The resulting approach is proved to achieve good performance through both off-line simulated sequences and in a realistic co-assembly involving a human operator and a dual arm collaborative robot.",
        "primary_area": "",
        "author": "Andrea Casalino;Nicola Massarenti;Andrea Maria Zanchettin;Paolo Rocco;Andrea Casalino;Nicola Massarenti;Andrea Maria Zanchettin;Paolo Rocco",
        "authorids": "/37086208346;/37088687245;/37546427600;/37274178600;/37086208346;/37088687245;/37546427600;/37274178600",
        "aff": "Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milano, Italy; Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milano, Italy; Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milano, Italy; Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milano, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341301/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13838425800841677776&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Politecnico di Milano",
        "aff_unique_dep": "Dipartimento di Elettronica, Informazione e Bioingegneria",
        "aff_unique_url": "https://www.polimi.it",
        "aff_unique_abbr": "Politecnico di Milano",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Milano",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9340697",
        "title": "Prediction of Backhoe Loading Motion via the Beta-Process Hidden Markov Model",
        "track": "main",
        "status": "Poster",
        "abstract": "Backhoe loads sediment onto the bed of dump trucks during earthmoving work. The prediction of backhoe loading time is essential for ensuring safe cooperation between the backhoe and dump trucks. However, it is difficult to predict the instant at which the backhoe is ready to load sediment, because of the similarity in motions observed during gathering sediment. Moreover, since operators have different skill levels, the prediction requires a unique model for each operator. In this study, we attempt to predict the instant at which the backhoe is ready to load sediment into the dump truck. For this purpose, the beta-process hidden Markov model (BP-HMM) is employed to build a backhoe motion model for a specific operator. Time series data of backhoe loading motions for crushed rocks and wood chips, which were measured using 6-axis inertial measurement unit (IMU) sensors equipped at the cab, boom, and arm of the backhoe, were used for modeling with the BP-HMM. Several primitive motions of the backhoe, which occur at the completion of preparation before the loading process begins, were discovered as a result of the motion modeling based on the BP-HMM. We developed the prediction of the instant using three primitive motions. At best, the proposed method could predict the instant with a probability of 67% and 100%, at 6.0 s and 0.7 s before the loading motions began, respectively. This phased prediction can be used to reduce the idle time and risk for dump trucks during earthmoving work with the backhoe.",
        "primary_area": "",
        "author": "Kento Yamada;Kazunori Ohno;Ryunosuke Hamada;Thomas Westfechtel;Ranulfo Plutarco Bezerra Neto;Naoto Miyamoto;Taro Suzuki;Takahiro Suzuki;Keiji Nagatani;Yukinori Shibata;Kimitaka Asano;Tomohiro Komatsu;Satoshi Tadokoro;Kento Yamada;Kazunori Ohno;Ryunosuke Hamada;Thomas Westfechtel;Ranulfo Plutarco Bezerra Neto;Naoto Miyamoto;Taro Suzuki;Takahiro Suzuki;Keiji Nagatani;Yukinori Shibata;Kimitaka Asano;Tomohiro Komatsu;Satoshi Tadokoro",
        "authorids": "/37362929700;/37285220400;/37086050152;/37086057782;/37088688422;/37274290200;/37087323760;/37086052857;/37283174900;/37088691328;/37088377363;/37088375745;/37296054300;/37362929700;/37285220400;/37086050152;/37086057782;/37088688422;/37274290200;/37087323760;/37086052857;/37283174900;/37088691328;/37088377363;/37088375745;/37296054300",
        "aff": "Tohoku University, Japan; RIKEN Center for Advanced Intelligence Project; Tohoku University, Japan; Tohoku University, Japan; Tohoku University, Japan; Tohoku University, Japan; Chiba Institute University, Japan; Tohoku University, Japan; Tokyo University, Japan; Sato komuten Co., Japan; Sanyo-Technics Co., Japan; KOWATECH co., Japan; Tohoku University, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340697/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9747058645004556206&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 26,
        "aff_unique_index": "0;1;0;0;0;0;2;0;3;4;5;6;0",
        "aff_unique_norm": "Tohoku University;RIKEN;Chiba Institute University;University of Tokyo;Sato komuten Co.;Sanyo-Technics Co.;KOWATECH",
        "aff_unique_dep": ";Center for Advanced Intelligence Project;;;;;",
        "aff_unique_url": "https://www.tohoku.ac.jp;https://www.riken.jp/en/;https://www.chiba-u.ac.jp;https://www.u-tokyo.ac.jp;;;",
        "aff_unique_abbr": "Tohoku U;RIKEN;;UTokyo;;;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9341139",
        "title": "Predictive Control of Connected Mixed Traffic under Random Communication Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "Fully connected and automated vehicles have been envisioned to help improve the driving safety and efficiency of the transportation system. However, human-driven vehicles will still be present in the near future, which will lead to connected mixed traffic instead of fully connected and automated traffic. This is challenging because of the complexity of human-driving vehicles and the potential communication constraints in the connectivity. To address this issue, this paper models the connected mixed traffic and proposes model predictive control approaches with various prediction approaches including a new inverse model predictive control (IMPC) based approach to handle random communication delays and packet losses in connectivity. The human-in-the-loop experimental results for connected mixed traffic demonstrated the effectiveness and advantages of the proposed approaches, especially the predictive control with IMPC in handling communication constraints in mixed traffic.",
        "primary_area": "",
        "author": "Longxiang Guo;Yunyi Jia;Longxiang Guo;Yunyi Jia",
        "authorids": "/37086350606;/37532721400;/37086350606;/37532721400",
        "aff": "Department of Automotive Engineering, Clemson University, Greenville, SC, USA; Department of Automotive Engineering, Clemson University, Greenville, SC, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341139/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2703208139789656056&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Clemson University",
        "aff_unique_dep": "Department of Automotive Engineering",
        "aff_unique_url": "https://www.clemson.edu",
        "aff_unique_abbr": "Clemson",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Greenville",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340755",
        "title": "Predictive Runtime Monitoring of Vehicle Models Using Bayesian Estimation and Reachability Analysis",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a predictive runtime monitoring technique for estimating future vehicle positions and the probability of collisions with obstacles. Vehicle dynamics model how the position and velocity change over time as a function of external inputs. They are commonly described by discrete-time stochastic models. Whereas positions and velocities can be measured, the inputs (steering and throttle) are not directly measurable in these models. In our paper, we apply Bayesian inference techniques for real-time estimation, given prior distribution over the unknowns and noisy state measurements. Next, we pre-compute the set-valued reachability analysis to approximate future positions of a vehicle. The pre-computed reachability sets are combined with the posterior probabilities computed through Bayesian estimation to provided a predictive verification framework that can be used to detect impending collisions with obstacles. Our approach is evaluated using the coordinated-turn vehicle model for a UAV using on-board measurement data obtained from a flight test of a Talon UAV. We also compare the results with sampling-based approaches. We find that precomputed reachability analysis can provide accurate warnings up to 6 seconds in advance and the accuracy of the warnings improve as the time horizon is narrowed from 6 to 2 seconds. The approach also outperforms sampling in terms of on-board computation cost and accuracy measures.",
        "primary_area": "",
        "author": "Yi Chou;Hansol Yoon;Sriram Sankaranarayanan;Yi Chou;Hansol Yoon;Sriram Sankaranarayanan",
        "authorids": "/37088688112;/37088689636;/37409120700;/37088688112;/37088689636;/37409120700",
        "aff": "University of Colorado, Boulder, USA; University of Colorado, Boulder, USA; University of Colorado, Boulder, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340755/",
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7752328723398949829&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Colorado Boulder",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.colorado.edu",
        "aff_unique_abbr": "CU Boulder",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Boulder",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341474",
        "title": "PresSense: Passive Respiration Sensing via Ambient WiFi Signals in Noisy Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Passive sensing with ambient WiFi signals is a promising technique that will enable new types of human-robot interactions while preserving users' privacy. Here, we present PresSense, a system for human respiration sensing in noisy environments. Unlike existing WiFi-based respiration sensors, we employ a human presence detector, improving the robustness in scenarios where no human is present in an Area Of Interest (AOI). We also integrate our novel feature, Peak Distance Histogram (PDH), with other classic WiFi features to achieve better accuracy when someone is present in the AOI. We tested our system using commodity WiFi devices in an office room. Our PresSense outperforms the state of the arts in both respiration rate estimation and presence detection.",
        "primary_area": "",
        "author": "Yi Tian Xu;Xi Chen;Xue Liu;David Meger;Gregory Dudek;Yi Tian Xu;Xi Chen;Xue Liu;David Meger;Gregory Dudek",
        "authorids": "/37088686369;/37088686539;/37292951400;/37542891800;/37274057100;/37088686369;/37088686539;/37292951400;/37542891800;/37274057100",
        "aff": "Samsung AI Center, Montreal, Quebec, Canada; Samsung AI Center, Montreal, Quebec, Canada; Samsung AI Center, Montreal, Quebec, Canada; Samsung AI Center, Montreal, Quebec, Canada; Samsung AI Center, Montreal, Quebec, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341474/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1393808043727760955&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Samsung AI Center",
        "aff_unique_dep": "AI Center",
        "aff_unique_url": "https://www.samsung.com/global/innovation/ai-research/",
        "aff_unique_abbr": "Samsung AI",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Montreal",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9341681",
        "title": "Proactive Estimation of Occlusions and Scene Coverage for Planning Next Best Views in an Unstructured Representation",
        "track": "main",
        "status": "Poster",
        "abstract": "The process of planning views to observe a scene is known as the Next Best View (NBV) problem. Approaches often aim to obtain high-quality scene observations while reducing the number of views, travel distance and computational cost. Considering occlusions and scene coverage can significantly reduce the number of views and travel distance required to obtain an observation. Structured representations (e.g., a voxel grid or surface mesh) typically use raycasting to evaluate the visibility of represented structures but this is often computationally expensive. Unstructured representations (e.g., point density) avoid the computational overhead of maintaining and raycasting a structure imposed on the scene but as a result do not proactively predict the success of future measurements. This paper presents proactive solutions for handling occlusions and considering scene coverage with an unstructured representation. Their performance is evaluated by extending the density-based Surface Edge Explorer (SEE). Experiments show that these techniques allow an unstructured representation to observe scenes with fewer views and shorter distances while retaining high observation quality and low computational cost.",
        "primary_area": "",
        "author": "Rowan Border;Jonathan D. Gammell;Rowan Border;Jonathan D. Gammell",
        "authorids": "/37086453268;/38667468700;/37086453268;/38667468700",
        "aff": "Department of Engineering Science, Estimation, Search, and Planning (ESP) Research Group, Oxford Robotics Institute (ORI), University of Oxford, Oxford, United Kingdom; Department of Engineering Science, Estimation, Search, and Planning (ESP) Research Group, Oxford Robotics Institute (ORI), University of Oxford, Oxford, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341681/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12729018462493051757&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Oxford",
        "aff_unique_dep": "Department of Engineering Science",
        "aff_unique_url": "https://www.ox.ac.uk",
        "aff_unique_abbr": "Oxford",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Oxford",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9341034",
        "title": "Probabilistic Multi-modal Trajectory Prediction with Lane Attention for Autonomous Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "Trajectory prediction is crucial for autonomous vehicles. The planning system not only needs to know the current state of the surrounding objects but also their possible states in the future. As for vehicles, their trajectories are significantly influenced by the lane geometry and how to effectively use the lane information is of active interest. Most of the existing works use rasterized maps to explore road information, which does not distinguish different lanes. In this paper, we propose a novel instance-aware representation for lane representation. By integrating the lane features and trajectory features, a goal-oriented lane attention module is proposed to predict the future locations of the vehicle. We show that the proposed lane representation together with the lane attention module can be integrated into the widely used encoder-decoder framework to generate diverse predictions. Most importantly, each generated trajectory is associated with a probability to handle the uncertainty. Our method does not suffer from collapsing to one behavior modal and can cover diverse possibilities. Extensive experiments and ablation studies on the benchmark datasets corroborate the effectiveness of our proposed method. Notably, our proposed method ranks third place in the Argoverse motion forecasting competition at NeurIPS 2019 1.",
        "primary_area": "",
        "author": "Chenxu Luo;Lin Sun;Dariush Dabiri;Alan Yuille;Chenxu Luo;Lin Sun;Dariush Dabiri;Alan Yuille",
        "authorids": "/37087234928;/37088688133;/37088689589;/37282960000;/37087234928;/37088688133;/37088689589;/37282960000",
        "aff": "Samsung Strategy and Innovation Center, Samsung, Inc., San Jose, CA; Samsung Strategy and Innovation Center, Samsung, Inc., San Jose, CA; Samsung Strategy and Innovation Center, Samsung, Inc., San Jose, CA; Department of Computer Science, Johns Hopkins University, Baltimore, MD",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341034/",
        "gs_citation": 98,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16395497324525829788&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Samsung;Johns Hopkins University",
        "aff_unique_dep": "Strategy and Innovation Center;Department of Computer Science",
        "aff_unique_url": "https://www.samsung.com/us/;https://www.jhu.edu",
        "aff_unique_abbr": "Samsung;JHU",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "San Jose;Baltimore",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341269",
        "title": "Probabilistic Qualitative Localization and Mapping",
        "track": "main",
        "status": "Poster",
        "abstract": "Simultaneous localization and mapping (SLAM) is essential in numerous robotics applications such as autonomous navigation. Traditional SLAM approaches infer the metric state of the robot along with a metric map of the environment. While existing algorithms exhibit good results, they are still sensitive to measurement noise, sensors quality, data association and are still computationally expensive. Alternatively, we note that some navigation and mapping missions can be achieved using only qualitative geometric information, an approach known as qualitative spatial reasoning (QSR). In this work we contribute a novel probabilistic qualitative localization and mapping approach, which extends the state of the art by inferring also the qualitative state of the camera poses (localization), as well as incorporating probabilistic connections between views (in time and in space). Our method is in particular appealing in scenarios with a small number of salient landmarks and sparse landmark tracks. We evaluate our approach in simulation and in a real-world dataset, and show its superior performance and low complexity compared to state of the art.",
        "primary_area": "",
        "author": "Roee Mor;Vadim Indelman;Roee Mor;Vadim Indelman",
        "authorids": "/37088688168;/37541538000;/37088688168;/37541538000",
        "aff": "Department of Computer Science, Technion - Israel Institute of Technology, Haifa, Israel; Department of Aerospace Engineering, Technion - Israel Institute of Technology, Haifa, Israel",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341269/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16967286028666577934&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Technion - Israel Institute of Technology",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.technion.ac.il",
        "aff_unique_abbr": "Technion",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Haifa",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Israel"
    },
    {
        "id": "9341738",
        "title": "Probabilistic Semantic Mapping for Urban Autonomous Driving Applications",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent advancements in statistical learning and computational abilities have enabled autonomous vehicle technology to develop at a much faster rate. While many of the architectures previously introduced are capable of operating under highly dynamic environments, many of these are constrained to smaller-scale deployments, require constant maintenance due to the associated scalability cost with highdefinition (HD) maps, and involve tedious manual labeling. As an attempt to tackle this problem, we propose to fuse image and pre-built point cloud map information to perform automatic and accurate labeling of static landmarks such as roads, sidewalks, crosswalks, and lanes. The method performs semantic segmentation on 2D images, associates the semantic labels with point cloud maps to accurately localize them in the world, and leverages the confusion matrix formulation to construct a probabilistic semantic map in bird\u2019s eye view from semantic point clouds. Experiments from data collected in an urban environment show that this model is able to predict most road features and can be extended for automatically incorporating road features into HD maps with potential future work directions.",
        "primary_area": "",
        "author": "David Paz;Hengyuan Zhang;Qinru Li;Hao Xiang;Henrik I. Christensen;David Paz;Hengyuan Zhang;Qinru Li;Hao Xiang;Henrik I. Christensen",
        "authorids": "/37088688508;/37088688369;/37088688482;/37089006777;/37281307400;/37088688508;/37088688369;/37088688482;/37089006777;/37281307400",
        "aff": "Contextual Robotics Institute, University of California, San Diego, La Jolla, CA; Contextual Robotics Institute, University of California, San Diego, La Jolla, CA; Contextual Robotics Institute, University of California, San Diego, La Jolla, CA; Contextual Robotics Institute, University of California, San Diego, La Jolla, CA; Contextual Robotics Institute, University of California, San Diego, La Jolla, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341738/",
        "gs_citation": 53,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11888925658687260638&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of California, San Diego",
        "aff_unique_dep": "Contextual Robotics Institute",
        "aff_unique_url": "https://www.ucsd.edu",
        "aff_unique_abbr": "UCSD",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "La Jolla",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341374",
        "title": "Progressive automation of periodic tasks on planar surfaces of unknown pose with hybrid force/position control",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a teaching by demonstration method for contact tasks with periodic movement on planar surfaces of unknown pose. To learn the motion on the plane, we utilize frequency oscillators with periodic movement primitives and we propose modified adaptation rules along with an extraction method of the task\u2019s fundamental frequency by automatically discarding near-zero frequency components. Additionally, we utilize an online estimate of the normal vector to the plane, so that the robot is able to quickly adapt to rotated hinged surfaces such as a window or a door. Using the framework of progressive automation for compliance adaptation, the robot transitions seamlessly and bi-directionally between hand guidance and autonomous operation within few repetitions of the task. While the level of automation increases, a hybrid force/position controller is progressively engaged for the autonomous operation of the robot. Our methodology is verified experimentally in surfaces of different orientation, with the robot being able to adapt to surface orientation perturbations.",
        "primary_area": "",
        "author": "Fotios Dimeas;Zoe Doulgeri;Fotios Dimeas;Zoe Doulgeri",
        "authorids": "/37085442111;/37274011500;/37085442111;/37274011500",
        "aff": "Dept. of Electrical & Computer Engineering, Automation & Robotics Lab, Aristotle University of Thessaloniki, Greece; Dept. of Electrical & Computer Engineering, Automation & Robotics Lab, Aristotle University of Thessaloniki, Greece",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341374/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17186183370453824946&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Aristotle University of Thessaloniki",
        "aff_unique_dep": "Dept. of Electrical & Computer Engineering",
        "aff_unique_url": "http://www.auth.gr",
        "aff_unique_abbr": "AUTH",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Thessaloniki",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Greece"
    },
    {
        "id": "9341521",
        "title": "Proprioceptive Sensor Fusion for Quadruped Robot State Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Estimation of a quadruped's state is fundamentally important to its operation. In this paper we develop a low-level state estimator for quadrupedal robots that includes attitude, odometry, ground reaction forces, and contact detection. The state estimator is divided into three parts. First, a nonlinear observer estimates attitude by fusing inertial measurements. The attitude estimator is globally exponentially stable and is able to initialize with large errors in the initial state estimates whereas a state-of-the-art EKF would diverge. This is practical for situations when the robot has fallen over and needs to start from its side. Second, leg odometry is calculated with encoders, force sensors, and torque sensors in the robot's joints. Lastly, the leg odometry and inertial measurements are fused to obtain linear position and velocity. We experimentally validate the state estimator using a novel dataset from the HyQ robot. For the entirety of the experiment the estimated attitude matched the ground truth data and had a root mean square error (RMSE) of [2 1 5] deg, the velocity estimates has a RMSE of [0.11 0.15 0.04] m/s, and the position estimates, which are unobservable, drifted on average [2 1 8] mm/s.",
        "primary_area": "",
        "author": "Geoff Fink;Claudio Semini;Geoff Fink;Claudio Semini",
        "authorids": "/37088358150;/37542633100;/37088358150;/37542633100",
        "aff": "Dynamic Legged Systems (DLS) Lab, Istituto Italiano di Tecnologia (IIT), Genova, Italy; Dynamic Legged Systems (DLS) Lab, Istituto Italiano di Tecnologia (IIT), Genova, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341521/",
        "gs_citation": 37,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4577524201235634751&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Istituto Italiano di Tecnologia",
        "aff_unique_dep": "Dynamic Legged Systems (DLS) Lab",
        "aff_unique_url": "https://www.iit.it",
        "aff_unique_abbr": "IIT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Genova",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9341193",
        "title": "Provably Safe Trajectory Optimization in the Presence of Uncertain Convex Obstacles",
        "track": "main",
        "status": "Poster",
        "abstract": "Real-world environments are inherently uncertain, and to operate safely in these environments robots must be able to plan around this uncertainty. In the context of motion planning, we desire systems that can maintain an acceptable level of safety as the robot moves, even when the exact locations of nearby obstacles are not known. In this paper, we solve this chance-constrained motion planning problem using a sequential convex optimization framework. To constrain the risk of collision incurred by planned movements, we employ geometric objects called \u03b5-shadows to compute upper bounds on the risk of collision between the robot and uncertain obstacles. We use these \u03b5-shadow-based estimates as constraints in a nonlinear trajectory optimization problem, which we then solve by iteratively linearizing the non-convex risk constraints. This sequential optimization approach quickly finds trajectories that accomplish the desired motion while maintaining a user-specified limit on collision risk. Our method can be applied to robots and environments with arbitrary convex geometry; even in complex environments, it runs in less than a second and provides provable guarantees on the safety of planned trajectories, enabling fast, reactive, and safe robot motion in realistic environments.",
        "primary_area": "",
        "author": "Charles Dawson;Ashkan Jasour;Andreas Hofmann;Brian Williams;Charles Dawson;Ashkan Jasour;Andreas Hofmann;Brian Williams",
        "authorids": "/37088688620;/37078643400;/37284500000;/37274902300;/37088688620;/37078643400;/37284500000;/37274902300",
        "aff": "Model-Based Embedded and Robotic Systems Lab, the Massachusetts Institute of Technology, Cambridge, MA, USA; Model-Based Embedded and Robotic Systems Lab, the Massachusetts Institute of Technology, Cambridge, MA, USA; Model-Based Embedded and Robotic Systems Lab, the Massachusetts Institute of Technology, Cambridge, MA, USA; Model-Based Embedded and Robotic Systems Lab, the Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341193/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6636582544270943664&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Model-Based Embedded and Robotic Systems Lab",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340710",
        "title": "ProxEmo: Gait-based Emotion Learning and Multi-view Proxemic Fusion for Socially-Aware Robot Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "We present ProxEmo, a novel end-to-end emotion prediction algorithm for socially aware robot navigation among pedestrians. Our approach predicts the perceived emotions of a pedestrian from walking gaits, which is then used for emotion-guided navigation taking into account social and proxemic constraints. To classify emotions, we propose a multi-view skeleton graph convolution-based model that works on a commodity camera mounted onto a moving robot. Our emotion recognition is integrated into a mapless navigation scheme and makes no assumptions about the environment of pedestrian motion. It achieves a mean average emotion prediction precision of 82.47% on the Emotion-Gait benchmark dataset. We outperform current state-of-art algorithms for emotion recognition from 3D gaits. We highlight its benefits in terms of navigation in indoor scenes using a Clearpath Jackal robot.",
        "primary_area": "",
        "author": "Venkatraman Narayanan;Bala Murali Manoghar;Vishnu Sashank Dorbala;Dinesh Manocha;Aniket Bera;Venkatraman Narayanan;Bala Murali Manoghar;Vishnu Sashank Dorbala;Dinesh Manocha;Aniket Bera",
        "authorids": "/37089405415;/37088686456;/37088687295;/37267825600;/37085393882;/37089405415;/37088686456;/37088687295;/37267825600;/37085393882",
        "aff": "University of Maryland, College Park, USA; University of Maryland, College Park, USA; University of Maryland, College Park, USA; University of Maryland, College Park, USA; University of Maryland, College Park, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340710/",
        "gs_citation": 93,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=798700989718436680&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Maryland",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www/umd.edu",
        "aff_unique_abbr": "UMD",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "College Park",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341559",
        "title": "Proximal Deterministic Policy Gradient",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper introduces two simple techniques to improve off-policy Reinforcement Learning (RL) algorithms. First, we formulate off-policy RL as a stochastic proximal point iteration. The target network plays the role of the variable of optimization and the value network computes the proximal operator. Second, we exploits the two value functions commonly employed in state-of-the-art off-policy algorithms to provide an improved action value estimate through bootstrapping with limited increase of computational resources. Further, we demonstrate significant performance improvement over state-of-the-art algorithms on standard continuous-control RL benchmarks.",
        "primary_area": "",
        "author": "Marco Maggipinto;Gian Antonio Susto;Pratik Chaudhari;Marco Maggipinto;Gian Antonio Susto;Pratik Chaudhari",
        "authorids": "/37086127328;/38246358900;/38113795600;/37086127328;/38246358900;/38113795600",
        "aff": "Department of Information Engineering, University of Padova, Padova, Italy; Department of Information Engineering, University of Padova, Padova, Italy; Electrical and Systems Engineering Department, University of Pennsylvania, Philadelphia, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341559/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4042286869797367831&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "University of Padova;University of Pennsylvania",
        "aff_unique_dep": "Department of Information Engineering;Electrical and Systems Engineering Department",
        "aff_unique_url": "https://www.unipd.it;https://www.upenn.edu",
        "aff_unique_abbr": "UNIPD;UPenn",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Padova;Philadelphia",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "Italy;United States"
    },
    {
        "id": "9341088",
        "title": "PufferBot: Actuated Expandable Structures for Aerial Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "We present PufferBot, an aerial robot with an expandable structure that may expand to protect a drone's propellers when the robot is close to obstacles or collocated humans. PufferBot is made of a custom 3D-printed expandable scissor structure, which utilizes a one degree of freedom actuator with rack and pinion mechanism. We propose four designs for the expandable structure, each with unique characterizations for different situations. Finally, we present three motivating scenarios in which PufferBot may extend the utility of existing static propeller guard structures.",
        "primary_area": "",
        "author": "Hooman Hedayati;Ryo Suzuki;Daniel Leithinger;Daniel Szafir;Hooman Hedayati;Ryo Suzuki;Daniel Leithinger;Daniel Szafir",
        "authorids": "/37086804419;/37086092004;/37946453000;/37086231248;/37086804419;/37086092004;/37946453000;/37086231248",
        "aff": "Department of Computer Science, University of Colorado Boulder; Department of Computer Science, University of Calgary; Department of Computer Science and ATLAS Institute, University of Colorado Boulder; Department of Computer Science and ATLAS Institute, University of Colorado Boulder",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341088/",
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16304146397925214029&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "University of Colorado Boulder;University of Calgary",
        "aff_unique_dep": "Department of Computer Science;Department of Computer Science",
        "aff_unique_url": "https://www.colorado.edu;https://www.ucalgary.ca",
        "aff_unique_abbr": "CU Boulder;U of C",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Boulder;",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "United States;Canada"
    },
    {
        "id": "9341452",
        "title": "QSRNet: Estimating Qualitative Spatial Representations from RGB-D Images",
        "track": "main",
        "status": "Poster",
        "abstract": "Humans perceive and describe their surroundings with qualitative statements (e.g., \"Alice's hand is in contact with a bottle.\"), rather than quantitative values (e.g., 6-D poses of Alice's hand and a bottle). Qualitative spatial representation (QSR) is a framework that represents the spatial information of objects in a qualitative manner. Region connection calculus (RCC), qualitative trajectory calculus (QTC), and qualitative distance calculus (QDC) are some popular QSR calculi. With the recent development of computer vision, it is important to compute QSR calculi from the visual inputs (e.g., RGB-D images). In fact, many QSR application domains (e.g., human activity recognition (HAR) in robotics) involve visual inputs. We propose a qualitative spatial representation network (QSRNet) that computes the three QSR calculi (i.e., RCC, QTC, and QDC) from the RGB-D images. QSRNet has the following novel contributions. First, QSRNet models the dependencies among the three QSR calculi. We introduce the dependencies as kinematics for QSR because they are analogous to the kinematics in classical mechanics. Second, QSRNet applies the 3-D point cloud instance segmentation to compute the QSR calculi. The experimental results show that QSRNet improves the accuracy in comparison to the other state-of-the-art techniques.",
        "primary_area": "",
        "author": "Sang Uk Lee;Sungkweon Hong;Andreas Hofmann;Brian Williams;Sang Uk Lee;Sungkweon Hong;Andreas Hofmann;Brian Williams",
        "authorids": "/37085778048;/37088997042;/37284500000;/37274902300;/37085778048;/37088997042;/37284500000;/37274902300",
        "aff": "MIT CSAIL, Massachusetts Institute of Technology, Cambridge, MA, USA; MIT CSAIL, Massachusetts Institute of Technology, Cambridge, MA, USA; MIT CSAIL, Massachusetts Institute of Technology, Cambridge, MA, USA; MIT CSAIL, Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341452/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17894399557205754802&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory (CSAIL)",
        "aff_unique_url": "https://www.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341081",
        "title": "Quadrotor-Enabled Autonomous Parking Occupancy Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Large special-events parking involves various parking scenarios, e.g., temporary parking and on-street parking. Their occupancy detection is challenging as it is unrealistic to construct gates/stations for temporary parking areas or build a sensor-based detection system to cover every single street. To address this issue, this study develops a quadrotor-enabled autonomous parking occupancy detection system. A camera-equipped quadrotor is flying over the parking lot first; then the images are captured by the on-board camera of the quadrotor and transferred to the ground station; finally, the ground station will process and release the occupancy information to the driver's mobile devices. The decision tree learning algorithm is adopted to determine the optimal flying speed for the quadrotor to balance the trade-off between the detection efficiency and accuracy. In order to tackle the complex environment in real-life parking, a convolutional neural network (CNN)-based vehicle detection model has been trained and implemented, where the realistic factors, e.g., passing pedestrians and tree blocking, are considered. Experiments are conducted to illustrate the effectiveness of the proposed system.",
        "primary_area": "",
        "author": "Yafeng Wang;Beibei Ren;Yafeng Wang;Beibei Ren",
        "authorids": "/37086960317;/37300724200;/37086960317;/37300724200",
        "aff": "Department of Mechanical Engineering, Texas Tech University, Lubbock, TX, USA; Department of Mechanical Engineering, Texas Tech University, Lubbock, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341081/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=753751771280656079&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Texas Tech University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.ttu.edu",
        "aff_unique_abbr": "TTU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Lubbock",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341181",
        "title": "Quadrupedal Robotic Walking on Sloped Terrains via Exact Decomposition into Coupled Bipedal Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Can we design motion primitives for complex legged systems uniformly for different terrain types without neglecting modeling details? This paper presents a method for rapidly generating quadrupedal locomotion on sloped terrains-from modeling to gait generation, to hardware demonstration. At the core of this approach is the observation that a quadrupedal robot can be exactly decomposed into coupled bipedal robots. Formally, this is represented through the framework of coupled control systems, wherein isolated subsystems interact through coupling constraints. We demonstrate this concept in the context of quadrupeds and use it to reduce the gait planning problem for uneven terrains to bipedal walking generation via hybrid zero dynamics. This reduction method allows for the formulation of a nonlinear optimization problem that leverages low-dimensional bipedal representations to generate dynamic walking gaits on slopes for the full-order quadrupedal robot dynamics. The result is the ability to rapidly generate quadrupedal walking gaits on a variety of slopes. We demonstrate these walking behaviors on the Vision 60 quadrupedal robot; in simulation, via walking on a range of sloped terrains of 13\u00b0, 15\u00b0, 20\u00b0, 25\u00b0, and, experimentally, through the successful locomotion of 13\u00b0 and 20\u00b0 ~ 25\u00b0 sloped outdoor grasslands.",
        "primary_area": "",
        "author": "Wen-Loong Ma;Noel Csomay-Shanklin;Aaron D. Ames;Wen-Loong Ma;Noel Csomay-Shanklin;Aaron D. Ames",
        "authorids": "/37085547381;/37086862522;/37300877900;/37085547381;/37086862522;/37300877900",
        "aff": "Department of Mechanical Engineering, California Institute of Technology, Pasadena, CA, USA; Department of Control+Dynamical Systems, California Institute of Technology, Pasadena, CA, USA; Department of Control+Dynamical Systems, California Institute of Technology, Pasadena, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341181/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12728080631955211496&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1+0;1+0",
        "aff_unique_norm": "California Institute of Technology;Control Department",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Control",
        "aff_unique_url": "https://www.caltech.edu;",
        "aff_unique_abbr": "Caltech;",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pasadena;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States;"
    },
    {
        "id": "9341135",
        "title": "Quantitative Operator Strategy Comparisons across Human Supervisory Control Scenarios",
        "track": "main",
        "status": "Poster",
        "abstract": "Human-automation collaborations, like automated driving assistance and piloting drones, have become prevalent as these technologies become more commonplace. Designers need tools that help them understand how and why design interventions may change the strategies of operators in such complex human supervisory control systems. To this end, we demonstrate that when the divergence metric is applied to Hidden Markov Model (HMM) comparisons, it can accurately capture statistical differences between operator strategies for interfaces that embody different tasks. However, the use of such an approach is problematic when used to compare HMM strategy models with non-equivalent observations. To address this limitation, we developed an observation reduction approach and conducted a sensitivity analysis to assess the impact of this approach. Our results show that when comparing two non-equivalent interfaces, our observation reduction approach does not fundamentally change the divergence metric, thus allowing for direct model comparison. The results further show that HMMs from different interfaces produce a much higher divergence metric than model comparison from the same people who repeatedly use the same interface. Future work will examine if this method can detect differences in models with different tasks or modified interfaces.",
        "primary_area": "",
        "author": "Haibei Zhu;Rong Xu;Mary L. Cummings;Haibei Zhu;Rong Xu;Mary L. Cummings",
        "authorids": "/37086184572;/37088691454;/37268062500;/37086184572;/37088691454;/37268062500",
        "aff": "Department of Electrical and Computer Engineering, Duke University, Durham, NC, USA; Department of Electrical and Computer Engineering, Duke University, Durham, NC, USA; Department of Electrical and Computer Engineering, Duke University, Durham, NC, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341135/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12751497605908776862&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Duke University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.duke.edu",
        "aff_unique_abbr": "Duke",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Durham",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340708",
        "title": "REFORM: Recognizing F-formations for Social Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Recognizing and understanding conversational groups, or F-formations, is a critical task for situated agents designed to interact with humans. F-formations contain complex structures and dynamics, yet are used intuitively by people in everyday face-to-face conversations. Prior research exploring ways of identifying F-formations has largely relied on heuristic algorithms that may not capture the rich dynamic behaviors employed by humans. We introduce REFORM (REcognize F-FORmations with Machine learning), a data-driven approach for detecting F-formations given human and agent positions and orientations. REFORM decomposes the scene into all possible pairs and then reconstructs F-formations with a voting-based scheme. We evaluated our approach across three datasets: the SALSA dataset, a newly collected human-only dataset, and a new set of acted human-robot scenarios, and found that REFORM yielded improved accuracy over a state-of-the-art F-formation detection algorithm. We also introduce symmetry and tightness as quantitative measures to characterize F-formations.",
        "primary_area": "",
        "author": "Hooman Hedayati;Annika Muehlbradt;Daniel J. Szafir;Sean Andrist;Hooman Hedayati;Annika Muehlbradt;Daniel J. Szafir;Sean Andrist",
        "authorids": "/37086804419;/37088687424;/37086231248;/38578752500;/37086804419;/37088687424;/37086231248;/38578752500",
        "aff": "Department of Computer Science and ATLAS Institute, University of Colorado Boulder; Department of Computer Science and ATLAS Institute, University of Colorado Boulder; Department of Computer Science and ATLAS Institute, University of Colorado Boulder; Microsoft Research, Redmond",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340708/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8634113358262699222&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "University of Colorado Boulder;Microsoft Research",
        "aff_unique_dep": "Department of Computer Science and ATLAS Institute;",
        "aff_unique_url": "https://www.colorado.edu;https://www.microsoft.com/en-us/research",
        "aff_unique_abbr": "CU Boulder;MSR",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "Boulder;Redmond",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340977",
        "title": "ROS-lite: ROS Framework for NoC-Based Embedded Many-Core Platform",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes ROS-lite, a robot operating system (ROS) development framework for embedded many- core platforms based on network-on-chip (NoC) technology. Many-core platforms support the high processing capacity and low power consumption requirement of embedded systems. In this study, a self-driving software platform module is parallelized to run on many-core processors to demonstrate the practicality of embedded many-core platforms. The experimental results show that the proposed framework and the parallelized applications have met the deadline for low-speed self-driving systems.",
        "primary_area": "",
        "author": "Takuya Azumi;Yuya Maruyama;Shinpei Kato;Takuya Azumi;Yuya Maruyama;Shinpei Kato",
        "authorids": "/37689139600;/37085789086;/37537228700;/37689139600;/37085789086;/37537228700",
        "aff": "Graduate School of Science and Engineering, Saitama University; Graduate School of Engineering Science, Osaka University; Graduate School of Information Science and Technology, the University of Tokyo",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340977/",
        "gs_citation": 40,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5288047214026298696&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Saitama University;Osaka University;University of Tokyo",
        "aff_unique_dep": "Graduate School of Science and Engineering;Graduate School of Engineering Science;Graduate School of Information Science and Technology",
        "aff_unique_url": "https://www.saitama-u.ac.jp;https://www.osaka-u.ac.jp;https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": ";Osaka U;UTokyo",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";Osaka;Tokyo",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9341653",
        "title": "ROSflight: A Lean Open-Source Research Autopilot",
        "track": "main",
        "status": "Poster",
        "abstract": "ROSflight is a lean, open-source autopilot system developed with the primary goal of supporting the needs of researchers working with micro aerial vehicle systems. The project consists of firmware designed to run on low-cost, readily available flight controller boards, as well as ROS packages for interfacing between the flight controller and application code and for simulation. The core objectives of the project are as follows: maintain a small, easy-to-understand code base; provide high-bandwidth, low-latency communication between the flight controller and application code; provide a straightforward interface to research application code; allow for robust safety pilot integration; and enable true software-in-the-loop simulation capability.",
        "primary_area": "",
        "author": "James Jackson;Daniel Koch;Trey Henrichsen;Tim McLain;James Jackson;Daniel Koch;Trey Henrichsen;Tim McLain",
        "authorids": "/37085787181;/37085780887;/37088691489;/37294472600;/37085787181;/37085780887;/37088691489;/37294472600",
        "aff": "Multiple Agent Intelligent Coordination and Control (MAG-ICC) Lab, Brigham Young University, Provo, UT, USA; Multiple Agent Intelligent Coordination and Control (MAG-ICC) Lab, Brigham Young University, Provo, UT, USA; Multiple Agent Intelligent Coordination and Control (MAG-ICC) Lab, Brigham Young University, Provo, UT, USA; Multiple Agent Intelligent Coordination and Control (MAG-ICC) Lab, Brigham Young University, Provo, UT, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341653/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8111059067121768892&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Brigham Young University",
        "aff_unique_dep": "Multiple Agent Intelligent Coordination and Control (MAG-ICC) Lab",
        "aff_unique_url": "https://www.byu.edu",
        "aff_unique_abbr": "BYU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Provo",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341287",
        "title": "RadarSLAM: Radar based Large-Scale SLAM in All Weathers",
        "track": "main",
        "status": "Poster",
        "abstract": "Numerous Simultaneous Localization and Mapping (SLAM) algorithms have been presented in last decade using different sensor modalities. However, robust SLAM in extreme weather conditions is still an open research problem. In this paper, RadarSLAM, a full radar based graph SLAM system, is proposed for reliable localization and mapping in large-scale environments. It is composed of pose tracking, local mapping, loop closure detection and pose graph optimization, enhanced by novel feature matching and probabilistic point cloud generation on radar images. Extensive experiments are conducted on a public radar dataset and several self-collected radar sequences, demonstrating the state-of-the-art reliability and localization accuracy in various adverse weather conditions, such as dark night, dense fog and heavy snowfall.",
        "primary_area": "",
        "author": "Ziyang Hong;Yvan Petillot;Sen Wang;Ziyang Hong;Yvan Petillot;Sen Wang",
        "authorids": "/37088217691;/37282015500;/37086278300;/37088217691;/37282015500;/37086278300",
        "aff": "Edinburgh Centre for Robotics, Heriot-Watt University, Edinburgh, UK; Edinburgh Centre for Robotics, Heriot-Watt University, Edinburgh, UK; Edinburgh Centre for Robotics, Heriot-Watt University, Edinburgh, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341287/",
        "gs_citation": 159,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13877802409409870684&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Heriot-Watt University",
        "aff_unique_dep": "Edinburgh Centre for Robotics",
        "aff_unique_url": "https://www.hw.ac.uk",
        "aff_unique_abbr": "HWU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Edinburgh",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9341564",
        "title": "Rapid Autonomous Semantic Mapping",
        "track": "main",
        "status": "Poster",
        "abstract": "A semantic understanding of the environment is needed to enable high level autonomy in robotic systems. Recent results have demonstrated rapid progress in underlying technology areas, but few results have been reported on end-to-end systems that enable effective autonomous perception in complex environments. In this paper, we describe an approach for rapidly and autonomously mapping unknown environments with integrated semantic and geometric information. We use surfel-based RGB-D SLAM techniques, with incremental object segmentation and classification methods to update the map in realtime. Information theoretic and heuristic measures are used to quickly plan sensor motion and drive down map uncertainty. Preliminary experimental results in simple and cluttered environments are reported.",
        "primary_area": "",
        "author": "Anup Parikh;Mark W. Koch;Timothy J. Blada;Stephen P. Buerger;Anup Parikh;Mark W. Koch;Timothy J. Blada;Stephen P. Buerger",
        "authorids": "/37085389823;/37378018500;/37085482394;/37294845300;/37085389823;/37378018500;/37085482394;/37294845300",
        "aff": "Robotics and Counter Robotics Research and Development group, Sandia National Laboratories, Albuquerque, NM, USA; Robotics and Counter Robotics Research and Development group, Sandia National Laboratories, Albuquerque, NM, USA; Robotics and Counter Robotics Research and Development group, Sandia National Laboratories, Albuquerque, NM, USA; Robotics and Counter Robotics Research and Development group, Sandia National Laboratories, Albuquerque, NM, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341564/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6868764174196444949&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Sandia National Laboratories",
        "aff_unique_dep": "Robotics and Counter Robotics Research and Development group",
        "aff_unique_url": "https://www.sandia.gov",
        "aff_unique_abbr": "SNL",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Albuquerque",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341586",
        "title": "Rapid Bipedal Gait Optimization in CasADi",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper shows how CasADi\u2019s state-of-the-art implementation of algorithmic differentiation can be leveraged to formulate and efficiently solve gait optimization problems, enabling rapid gait design for high-dimensional biped robots. Comparative studies on a 7-DOF planar biped show that CasADi generates optimal gaits 4 times faster than another existing advanced optimization package. The framework is also applied to simultaneously generate a gait and a feedback controller for 2 spatial bipeds: a 12-DOF model and a 20DOF model. Results suggest that CasADi\u2019s unprecedented efficiency could provide a practical path toward real-time gait optimization for high-dimensional biped robots.",
        "primary_area": "",
        "author": "Martin Fevre;Patrick M. Wensing;James P. Schmiedeler;Martin Fevre;Patrick M. Wensing;James P. Schmiedeler",
        "authorids": "/37086345471;/37946046300;/37282121600;/37086345471;/37946046300;/37282121600",
        "aff": "Department of Aerospace & Mechanical Engineering, University of Notre Dame, USA; Department of Aerospace & Mechanical Engineering, University of Notre Dame, USA; Department of Aerospace & Mechanical Engineering, University of Notre Dame, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341586/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17573277382737691031&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Notre Dame",
        "aff_unique_dep": "Department of Aerospace & Mechanical Engineering",
        "aff_unique_url": "https://www.nd.edu",
        "aff_unique_abbr": "Notre Dame",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341571",
        "title": "Rapidly Adaptable Legged Robots via Evolutionary Meta-Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning adaptable policies is crucial for robots to operate autonomously in our complex and quickly changing world. In this work, we present a new meta-learning method that allows robots to quickly adapt to changes in dynamics. In contrast to gradient-based meta-learning algorithms that rely on second-order gradient estimation, we introduce a more noise-tolerant Batch Hill-Climbing adaptation operator and combine it with meta-learning based on evolutionary strategies. Our method significantly improves adaptation to changes in dynamics in high noise settings, which are common in robotics applications. We validate our approach on a quadruped robot that learns to walk while subject to changes in dynamics. We observe that our method significantly outperforms prior gradient-based approaches, enabling the robot to adapt its policy to changes based on less than 3 minutes of real data.",
        "primary_area": "",
        "author": "Xingyou Song;Yuxiang Yang;Krzysztof Choromanski;Ken Caluwaerts;Wenbo Gao;Chelsea Finn;Jie Tan;Xingyou Song;Yuxiang Yang;Krzysztof Choromanski;Ken Caluwaerts;Wenbo Gao;Chelsea Finn;Jie Tan",
        "authorids": "/37088688873;/37085581322;/37086453239;/37586652300;/37088686507;/37085523464;/37086455820;/37088688873;/37085581322;/37086453239;/37586652300;/37088686507;/37085523464;/37086455820",
        "aff": "Robotics at Google; Robotics at Google; Robotics at Google; Robotics at Google; Columbia University; Robotics at Google; Robotics at Google",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341571/",
        "gs_citation": 96,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1516965156439707657&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;1;0;0",
        "aff_unique_norm": "Google;Columbia University",
        "aff_unique_dep": "Robotics;",
        "aff_unique_url": "https://www.google.com;https://www.columbia.edu",
        "aff_unique_abbr": "Google Robotics;Columbia",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Mountain View;",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341122",
        "title": "ReachFlow: An Online Safety Assurance Framework for Waypoint-Following of Self-driving Cars",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning-enabled components have been widely deployed in autonomous systems. However, due to the weak interpretability and the prohibitively high complexity of large-scale machine learning models such as neural networks, reliability has been a crucial concern for safety-critical autonomous systems. This work proposes an online monitor called Reach-Flow for fault prevention of waypoint-following tasks for self-driving cars. It mainly consists of two components: (a) an online verification tool which conservatively checks the safety of the system behavior in the near future, and (b) a fallback controller which steers the system back to a desired state when the system is potentially unsafe. We implement ReachFlow in a self-driving racing car governed by a reinforcement learning-based controller. We demonstrate the effectiveness by rigorously verifying a safe waypoint-following control and providing a fallback control for an unsafe situation in which a large deviation from the planned path is predicted.",
        "primary_area": "",
        "author": "Qin Lin;Xin Chen;Aman Khurana;John M. Dolan;Qin Lin;Xin Chen;Aman Khurana;John M. Dolan",
        "authorids": "/37086031992;/37087137640;/37086226365;/37283756800;/37086031992;/37087137640;/37086226365;/37283756800",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Computer Science, University of Dayton, Dayton, OH, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341122/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5333416487391571528&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Carnegie Mellon University;University of Dayton",
        "aff_unique_dep": "Robotics Institute;Department of Computer Science",
        "aff_unique_url": "https://www.cmu.edu;https://www.udayton.edu",
        "aff_unique_abbr": "CMU;UD",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Pittsburgh;Dayton",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341306",
        "title": "Reactive Receding Horizon Planning and Control for Quadrotors with Limited On-Board Sensing",
        "track": "main",
        "status": "Poster",
        "abstract": "The paper presents a receding horizon planning strategy for a quadrotor-type mav to navigate through an unknown cluttered environment at high speed. Utilizing a lightweight on-board short-range sensor that generates point-clouds within a narrow Field of View (FOV), the reported approach generates safe and dynamically feasible trajectories within the fov of the sensor, which the mav uses to navigate without relying on any global planner or prior information about the environment. The effectiveness of this planner-controller combination is demonstrated in both indoor and outdoor tests featuring speeds of up to of 3.5 m/s. With minor adjustments, the local motion planner can be utilized for interception and tracking of a moving target; evidence to this effect are provided in the form of numerical (Gazebo) simulations. Given the absence of any global information about the robot's workspace, the extent to which the local planner can provide convergence guarantees is limited; when complemented by a global planner and/or target tracker, the reported lower-level, sensor-driven reactive motion control strategy completes the autonomous mav navigation stack, enabling navigation in dynamic, uncertain, and partially-known environments with guaranteed convergence to any static or dynamic target.",
        "primary_area": "",
        "author": "Indrajeet Yadav;Herbert G. Tanner;Indrajeet Yadav;Herbert G. Tanner",
        "authorids": "/37086016284;/37267233400;/37086016284;/37267233400",
        "aff": "Department of Mechanical Engineering, University of Delaware; Department of Mechanical Engineering, University of Delaware",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341306/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=972751142454116514&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Delaware",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.udel.edu",
        "aff_unique_abbr": "UD",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341447",
        "title": "Real-Time Constrained Nonlinear Model Predictive Control on SO(3) for Dynamic Legged Locomotion",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a constrained nonlinear model predictive control (NMPC) framework for legged locomotion. The framework assumes a legged robot as a floating base single rigid body with contact forces being applied to the body as external forces. With consideration of orientation dynamics evolving on the rotation manifold SO(3), analytic Jacobians which are necessary for constructing the gradient and the Gauss-Newton Hessian approximation of the objective function are derived. This procedure also includes the reparameterization of the robot orientation on SO(3) to orientation error in the tangent space of that manifold. Obtained gradient and Gauss-Newton Hessian approximation are utilized to solve nonlinear least squares problems formulated from NMPC in a computationally efficient manner. The proposed algorithm is verified on various types of legged robots and gaits in a simulation environment.",
        "primary_area": "",
        "author": "Seungwoo Hong;Joon-Ha Kim;Hae-Won Park;Seungwoo Hong;Joon-Ha Kim;Hae-Won Park",
        "authorids": "/37086581983;/37087322590;/37086265865;/37086581983;/37087322590;/37086265865",
        "aff": "Department of Mechanical Engineering, Humanoid Robot Research Center, School of Mechanical, Aerospace & Systems Engineering, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea; Department of Mechanical Engineering, Humanoid Robot Research Center, School of Mechanical, Aerospace & Systems Engineering, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea; Department of Mechanical Engineering, Humanoid Robot Research Center, School of Mechanical, Aerospace & Systems Engineering, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341447/",
        "gs_citation": 45,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9332787859127616512&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.kaist.ac.kr",
        "aff_unique_abbr": "KAIST",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Daejeon",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9340646",
        "title": "Real-Time Multi-SLAM System for Agent Localization and 3D Mapping in Dynamic Scenarios",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper introduces a Wearable SLAM system that performs indoor and outdoor SLAM in real time. The related project is part of the MALIN challenge which aims at creating a system to track emergency response agents in complex scenarios (such as dark environments, smoked rooms, repetitive patterns, building floor transitions and doorway crossing problems), where GPS technology is insufficient or inoperative. The proposed system fuses different SLAM technologies to compensate the lack of robustness of each, while estimating the pose individually. LiDAR and visual SLAM are fused with an inertial sensor in such a way that the system is able to maintain GPS coordinates that are sent via radio to a ground station, for real-time tracking. More specifically, LiDAR and monocular vision technologies are tested in dynamic scenarios where the main advantages of each have been evaluated and compared. Finally, 3D reconstruction up to three levels of details is performed.",
        "primary_area": "",
        "author": "Pierre Alliez;Fabien Bonardi;Samia Bouchafa;Jean-Yves Didier;Hicham Hadj-Abdelkader;Fernando Ireta Mu\u00f1oz;Viachaslau Kachurka;Bastien Rault;Maxime Robin;David Roussel;Pierre Alliez;Fabien Bonardi;Samia Bouchafa;Jean-Yves Didier;Hicham Hadj-Abdelkader;Fernando Ireta Mu\u00f1oz;Viachaslau Kachurka;Bastien Rault;Maxime Robin;David Roussel",
        "authorids": "/37449235700;/37086226518;/37282431900;/37337514500;/38275517500;/37088493657;/37085750250;/37088492526;/37088491436;/37283671900;/37449235700;/37086226518;/37282431900;/37337514500;/38275517500;/37088493657;/37085750250;/37088492526;/37088491436;/37283671900",
        "aff": "TITANE Project-Team, Sophia Antipolis M\u00e9diterrann\u00e9e, France; IBISC, Univ Evry, Universit\u00e9 Paris-Saclay, Evry, France; IBISC, Univ Evry, Universit\u00e9 Paris-Saclay, Evry, France; IBISC, Univ Evry, Universit\u00e9 Paris-Saclay, Evry, France; IBISC, Univ Evry, Universit\u00e9 Paris-Saclay, Evry, France; TITANE Project-Team, Sophia Antipolis M\u00e9diterrann\u00e9e, France; IBISC, Univ Evry, Universit\u00e9 Paris-Saclay, Evry, France; INNODURA TB, Villeurbanne, France; INNODURA TB, Villeurbanne, France; IBISC, Univ Evry, Universit\u00e9 Paris-Saclay, Evry, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340646/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17608874732962426071&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 20,
        "aff_unique_index": "0;1;1;1;1;0;1;2;2;1",
        "aff_unique_norm": "Sophia Antipolis M\u00e9diterrann\u00e9e;Universit\u00e9 Paris-Saclay;INNODURA TB",
        "aff_unique_dep": "TITANE Project-Team;IBISC;",
        "aff_unique_url": ";https://www.universite-paris-saclay.fr;",
        "aff_unique_abbr": ";Univ Paris-Saclay;",
        "aff_campus_unique_index": "0;1;1;1;1;0;1;1",
        "aff_campus_unique": "Sophia Antipolis;Evry;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9341760",
        "title": "Real-Time Robot End-Effector Pose Estimation with Deep Network",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a novel algorithm that estimates the pose of the robot end effector using depth vision. The input to our system is the segmented robot hand point cloud from a depth sensor. Then a neural network takes a point cloud as input and outputs the position and orientation of the robot end effector in the camera frame. The estimated pose can serve as the input of the controller of the robot to reach a specific pose in the camera frame. The training process of the neural network takes the simulated rendered point cloud generated from different poses of the robot hand mesh. At test time, one estimation of a single robot hand pose is reduced to 10ms on gpu and 14ms on cpu, which makes it suitable for close loop robot control system that requires to estimate hand pose in an online fashion. We design a robot hand pose estimation experiment to validate the effectiveness of our algorithm working in the real situation. The platform we used includes a Kinova Jaco 2 robot arm and a Kinect v2 depth sensor. We describe all the processes that use vision to improve the accuracy of pose estimation of the robot end-effector. We demonstrate the possibility of using point cloud to directly estimate the robot's end-effector pose and incorporate the estimated pose into the controller design of the robot arm.",
        "primary_area": "",
        "author": "Hu Cheng;Yingying Wang;Max Q.-H. Meng;Hu Cheng;Yingying Wang;Max Q.-H. Meng",
        "authorids": "/37086801643;/37088689053;/37274117000;/37086801643;/37088689053;/37274117000",
        "aff": "Robotics, Perception and Artificial Intelligence Lab in the Department of Electronic Engineering, The Chinese University of Hong Kong, Hong Kong; Robotics, Perception and Artificial Intelligence Lab in the Department of Electronic Engineering, The Chinese University of Hong Kong, Hong Kong; Shenzhen Research Institute of the Chinese University of Hong Kong in Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341760/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=866447810769744537&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "The Chinese University of Hong Kong;Chinese University of Hong Kong",
        "aff_unique_dep": "Department of Electronic Engineering;Shenzhen Research Institute",
        "aff_unique_url": "https://www.cuhk.edu.hk;https://www.cuhk.edu.hk",
        "aff_unique_abbr": "CUHK;CUHK",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Hong Kong SAR;Shenzhen",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9341071",
        "title": "Real-Time Spatio-Temporal LiDAR Point Cloud Compression",
        "track": "main",
        "status": "Poster",
        "abstract": "Compressing massive LiDAR point clouds in real-time is critical to autonomous machines such as drones and self-driving cars. While most of the recent prior work has focused on compressing individual point cloud frames, this paper proposes a novel system that effectively compresses a sequence of point clouds. The idea to exploit both the spatial and temporal redundancies in a sequence of point cloud frames. We first identify a key frame in a point cloud sequence and spatially encode the key frame by iterative plane fitting. We then exploit the fact that consecutive point clouds have large overlaps in the physical space, and thus spatially encoded data can be (re-)used to encode the temporal stream. Temporal encoding by reusing spatial encoding data not only improves the compression rate, but also avoids redundant computations, which significantly improves the compression speed. Experiments show that our compression system achieves 40\u00d7 to 90\u00d7 compression rate, significantly higher than the MPEG's LiDAR point cloud compression standard, while retaining high end-to-end application accuracies. Meanwhile, our compression system has a compression speed that matches the point cloud generation rate by today LiDARs and out-performs existing compression systems, enabling real-time point cloud transmission.",
        "primary_area": "",
        "author": "Yu Feng;Shaoshan Liu;Yuhao Zhu;Yu Feng;Shaoshan Liu;Yuhao Zhu",
        "authorids": "/37088552839;/37406041000;/37086433612;/37088552839;/37406041000;/37086433612",
        "aff": "Department of Computer Science, University of Rochester, Rochester, NY, USA; PerceptIn, Inc., Santa Clara, CA, USA; Department of Computer Science, University of Rochester, Rochester, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341071/",
        "gs_citation": 50,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18039928707774192053&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Rochester;PerceptIn, Inc.",
        "aff_unique_dep": "Department of Computer Science;",
        "aff_unique_url": "https://www.rochester.edu;",
        "aff_unique_abbr": "U of R;",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Rochester;Santa Clara",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341473",
        "title": "Real-World Human-Robot Collaborative Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "The intuitive collaboration of humans and intelligent robots (embodied AI) in the real-world is an essential objective for many desirable applications of robotics. Whilst there is much research regarding explicit communication, we focus on how humans and robots interact implicitly, on motor adaptation level. We present a real-world setup of a human-robot collaborative maze game, designed to be non-trivial and only solvable through collaboration, by limiting the actions to rotations of two orthogonal axes, and assigning each axes to one player. This results in neither the human nor the agent being able to solve the game on their own. We use deep reinforcement learning for the control of the robotic agent, and achieve results within 30 minutes of real-world play, without any type of pre-training. We then use this setup to perform systematic experiments on human/agent behaviour and adaptation when co-learning a policy for the collaborative game. We present results on how co-policy learning occurs over time between the human and the robotic agent resulting in each participant's agent serving as a representation of how they would play the game. This allows us to relate a person's success when playing with different agents than their own, by comparing the policy of the agent with that of their own agent.",
        "primary_area": "",
        "author": "Ali Shafti;Jonas Tjomsland;William Dudley;A. Aldo Faisal;Ali Shafti;Jonas Tjomsland;William Dudley;A. Aldo Faisal",
        "authorids": "/37085616628;/37088688578;/37088686796;/37073114200;/37085616628;/37088688578;/37088686796;/37073114200",
        "aff": "Dept. of Bioengineering and Dept. of Computing, Brain and Behaviour Lab, Imperial College London, London, UK; Dept. of Bioengineering and Dept. of Computing, Brain and Behaviour Lab, Imperial College London, London, UK; Dept. of Bioengineering and Dept. of Computing, Brain and Behaviour Lab, Imperial College London, London, UK; Dept. of Bioengineering and Dept. of Computing, Brain and Behaviour Lab, Imperial College London, London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341473/",
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7485245826936999108&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Imperial College London",
        "aff_unique_dep": "Dept. of Bioengineering",
        "aff_unique_url": "https://www.imperial.ac.uk",
        "aff_unique_abbr": "Imperial",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9340921",
        "title": "Real-time Detection of Distracted Driving using Dual Cameras",
        "track": "main",
        "status": "Poster",
        "abstract": "Distracted driving is one of the main contributors to traffic accidents. This paper proposes a deep learning approach to detecting multiple distracted driving behaviors. In order to obtain more accurate detection results, a synchronized image recognition system based on two cameras is designed, by which the body movements and face of the driver are monitored respectively. The images captured from driver's body and face areas are fed to two Convolutional Neural Networks (CNNs) simultaneously to ensure the performance of classification. The data collection and validation processes of the proposed distraction detection approach were conducted on a laboratory-based assisted driving testbed to provide near-realistic driving experiences. Our dataset includes distracted and safe driving images of the drivers. Furthermore, we developed a meaningful and practical application of a voice-alert system that alerts the distracted driver to focus on the driving task. We evaluated VGG-16, ResNet, and MobileNet-v2 networks for the proposed approach. Experimental results show that by using two cameras and VGG-16 networks, we can achieve a recognition accuracy of 96.7% with a computation speed of 8 fps.",
        "primary_area": "",
        "author": "Duy Tran;Ha Manh Do;Jiaxing Lu;Weihua Sheng;Duy Tran;Ha Manh Do;Jiaxing Lu;Weihua Sheng",
        "authorids": "/37085343634;/37085459952;/37088690371;/37276312200;/37085343634;/37085459952;/37088690371;/37276312200",
        "aff": "School of Electrical and Computer Engineering, Stillwater, OK, USA; Communities to Build Active STEM Engagement (CBASE) and the Department of Engineering, Colorado State University-Pueblo, Pueblo, CO, USA; School of Electrical and Computer Engineering, Stillwater, OK, USA; School of Electrical and Computer Engineering, Stillwater, OK, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340921/",
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15195380886172086644&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Oklahoma State University;Colorado State University-Pueblo",
        "aff_unique_dep": "School of Electrical and Computer Engineering;Department of Engineering",
        "aff_unique_url": "https://www.okstate.edu;https://www.colostate-pueblo.edu",
        "aff_unique_abbr": "OSU;CSU-Pueblo",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Stillwater;Pueblo",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341523",
        "title": "Real-time Virtual Coach using LSTM for Assisting Physical Therapists with End-effector-based Robot-assisted Gait Training",
        "track": "main",
        "status": "Poster",
        "abstract": "With the development of robotic technology, the demand for state-of-the-art technology in the field of rehabilitation is rapidly increasing for the elderly and people with disabilities. In this paper, we propose a real-time virtual coach to assist physical therapists with the end-effector-based robot-assisted gait training for stroke survivors using Long Short-Term Memory (LSTM) networks. Our proposed virtual coach consists of the sensor module for data gathering and dataset generation, real-time classification of the pathologic patient gait during the training using LSTM networks, and delivery of the coaching recommendations in an audiovisual form. Our preliminary study determined the selection of coaching recommendations. LSTM networks are trained to provide the selected coaching recommendations. The performance of the proposed virtual coach is verified using classification simulation of an able-bodied person on the rehabilitation robot, G-EO System. The usability was verified through a satisfaction survey of five professional physical therapists.",
        "primary_area": "",
        "author": "Yeongsik Seo;Eunkyeong Lee;Suncheol Kwon;Won-Kyung Song;Yeongsik Seo;Eunkyeong Lee;Suncheol Kwon;Won-Kyung Song",
        "authorids": "/37088688211;/37088688566;/37537523300;/37957585600;/37088688211;/37088688566;/37537523300;/37957585600",
        "aff": "Department of Rehabilitative and Assistive Technology, National Rehabilitation Center, National Rehabilitation Research Institute, Seoul, Republic of Korea; Department of Rehabilitative and Assistive Technology, National Rehabilitation Center, National Rehabilitation Research Institute, Seoul, Republic of Korea; Department of Rehabilitative and Assistive Technology, National Rehabilitation Center, National Rehabilitation Research Institute, Seoul, Republic of Korea; Department of Rehabilitative and Assistive Technology, National Rehabilitation Center, National Rehabilitation Research Institute, Seoul, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341523/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7445353223253955452&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "National Rehabilitation Center",
        "aff_unique_dep": "Department of Rehabilitative and Assistive Technology",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9341381",
        "title": "Real-time detection of broccoli crops in 3D point clouds for autonomous robotic harvesting",
        "track": "main",
        "status": "Poster",
        "abstract": "Real-time 3D perception of the environment is crucial for the adoption and deployment of reliable autonomous harvesting robots in agriculture. Using data collected with RGB-D cameras under farm field conditions, we present two methods for processing 3D data that reliably detect mature broccoli heads. The proposed systems are efficient and enable real-time detection on depth data of broccoli crops using the organised structure of the point clouds delivered by a depth sensor. The systems are tested with datasets of two broccoli varieties collected in planted fields from two different countries. Our evaluation shows the new methods outperform state-of-the-art approaches for broccoli detection based on both 2D vision-based segmentation techniques and depth clustering using the Euclidean proximity of neighbouring points. The results show the systems are capable of accurately detecting the 3D locations of broccoli heads relative to the vehicle at high frame rates.",
        "primary_area": "",
        "author": "Hector A. Montes;Justin Le Louedec;Grzegorz Cielniak;Tom Duckett;Hector A. Montes;Justin Le Louedec;Grzegorz Cielniak;Tom Duckett",
        "authorids": "/37340935900;/37088687879;/37550177700;/37419160900;/37340935900;/37088687879;/37550177700;/37419160900",
        "aff": "University of Lincoln, UK; University of Lincoln, UK; University of Lincoln, UK; University of Lincoln, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341381/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14245514819180991269&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Lincoln",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.lincoln.ac.uk",
        "aff_unique_abbr": "UoL",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9340640",
        "title": "Real-time optimal control of an autonomous RC car with minimum-time maneuvers and a novel kineto-dynamical model",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a real-time non-linear model-predictive control (NMPC) framework to perform minimum-time motion planning for autonomous racing cars. We introduce an innovative kineto-dynamical vehicle model, able to accurately predict non-linear longitudinal and lateral vehicle dynamics. The main parameters of this vehicle model can be tuned with only experimental or simulated maneuvers, aimed to identify the handling diagram and the maximum performance G-G envelope. The kineto-dynamical model is adopted to generate on-line minimum time trajectories with an indirect optimal control method. The motion planning framework is applied to control an autonomous 1:8 RC vehicle near the limits of handling along a test circuit. Finally, the effectiveness of the proposed algorithms is illustrated by comparing the experimental results with the solution of an off-line minimum-time optimal control problem.",
        "primary_area": "",
        "author": "Edoardo Pagot;Mattia Piccinini;Francesco Biral;Edoardo Pagot;Mattia Piccinini;Francesco Biral",
        "authorids": "/37087117423;/37088688696;/37396375100;/37087117423;/37088688696;/37396375100",
        "aff": "Department of Industrial Engineering, University of Trento, Trento, Italy; Department of Industrial Engineering, University of Trento, Trento, Italy; Department of Industrial Engineering, University of Trento, Trento, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340640/",
        "gs_citation": 39,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5549963552520302242&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Trento",
        "aff_unique_dep": "Department of Industrial Engineering",
        "aff_unique_url": "https://www.unitn.it",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Trento",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9341297",
        "title": "Realistic and Interactive Robot Gaze",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper describes the development of a system for lifelike gaze in human-robot interactions using a humanoid Audio-Animatronics\u00ae bust. Previous work examining mutual gaze between robots and humans has focused on technical implementation. We present a general architecture that seeks not only to create gaze interactions from a technological standpoint, but also through the lens of character animation where the fidelity and believability of motion is paramount; that is, we seek to create an interaction which demonstrates the illusion of life. A complete system is described that perceives persons in the environment, identifies persons-of-interest based on salient actions, selects an appropriate gaze behavior, and executes high fidelity motions to respond to the stimuli. We use mechanisms that mimic motor and attention behaviors analogous to those observed in biological systems including attention habituation, saccades, and differences in motion bandwidth for actuators. Additionally, a subsumption architecture allows layering of simple motor movements to create increasingly complex behaviors which are able to interactively and realistically react to salient stimuli in the environment through subsuming lower levels of behavior. The result of this system is an interactive human-robot experience capable of human-like gaze behaviors.",
        "primary_area": "",
        "author": "Matthew K.X.J. Pan;Sungjoon Choi;James Kennedy;Kyna McIntosh;Daniel Campos Zamora;G\u00fcnter Niemeyer;Joohyung Kim;Alexis Wieland;David Christensen;Matthew K.X.J. Pan;Sungjoon Choi;James Kennedy;Kyna McIntosh;Daniel Campos Zamora;G\u00fcnter Niemeyer;Joohyung Kim;Alexis Wieland;David Christensen",
        "authorids": "/37085376434;/37085405040;/38573017100;/37088687773;/37086841981;/37283232500;/37085576403;/37088686615;/37070012800;/37085376434;/37085405040;/38573017100;/37088687773;/37086841981;/37283232500;/37085576403;/37088686615;/37070012800",
        "aff": "Disney Research, Glendale, California, USA; Disney Research, Glendale, California, USA; Disney Research, Glendale, California, USA; Disney Research, Glendale, California, USA; Disney Research, Glendale, California, USA; California Institute of Technology, Pasadena, California, USA; University of Illinois at Urbana-Champaign, Urbana, Illinois, USA; Walt Disney Imagineering - Advanced Development, Glendale, California, USA; Disney Research, Glendale, California, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341297/",
        "gs_citation": 34,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8607822090225513467&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;0;0;1;2;3;0",
        "aff_unique_norm": "Disney Research;California Institute of Technology;University of Illinois at Urbana-Champaign;Walt Disney Imagineering",
        "aff_unique_dep": ";;;Advanced Development",
        "aff_unique_url": "https://research.disney.com;https://www.caltech.edu;https://illinois.edu;https://www.disney.com",
        "aff_unique_abbr": "Disney Research;Caltech;UIUC;WDI",
        "aff_campus_unique_index": "0;0;0;0;0;1;2;0;0",
        "aff_campus_unique": "Glendale;Pasadena;Urbana",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341109",
        "title": "Reconfigurable Soft Flexure Hinges via Pinched Tubes",
        "track": "main",
        "status": "Poster",
        "abstract": "Tuning the stiffness of soft robots is essential in order to extend usability and control the maneuverability of soft robots. In this paper, we propose a novel mechanism that can reconfigure the stiffness of tubular structures, using pinching to induce highly directional changes in stiffness. When pinched, these tubes can be then utilized as flexure hinges to create virtual joints on demand; the orientation of the hinge axis can additionally be selected via control of the distribution of pinch forces on the surface of the tube. Through proper material and geometry selection, passive shape recovery is observed when pinching forces are removed; a proposed active shape recovery technique can further assist the tube to recover its initial shape in order to re-configure the hinge in a new orientation. The proposed mechanism has been validated in FEA as well as experimentally, looking specifically at the relation between pinching force and curvature change, as well as comparing tube stiffness between pinched and unpinched configurations. The experimental prototype detailed in this paper - and demonstrated in the associated video - is capable of controlling the generation and recovery of flexure hinges at multiple orientations around the radial axis of tubes on demand.",
        "primary_area": "",
        "author": "Yuhao Jiang;Mohammad Sharifzadeh;Daniel M. Aukes;Yuhao Jiang;Mohammad Sharifzadeh;Daniel M. Aukes",
        "authorids": "/37088689350;/37088688054;/37085340777;/37088689350;/37088688054;/37085340777",
        "aff": "School for Engineering of Matter, Transport and Energy, Fulton Schools of Engineering, Arizona State University, Tempe, AZ, USA; The Polytechnic School, Fulton Schools of Engineering, Arizona State University, Mesa, AZ, USA; The Polytechnic School, Fulton Schools of Engineering, Arizona State University, Mesa, AZ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341109/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9557532202699757476&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Arizona State University",
        "aff_unique_dep": "School for Engineering of Matter, Transport and Energy",
        "aff_unique_url": "https://www.asu.edu",
        "aff_unique_abbr": "ASU",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Tempe;Mesa",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341479",
        "title": "Reconstruction of 3D flight trajectories from ad-hoc camera networks",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a method to reconstruct the 3D trajectory of an airborne robotic system only from videos recorded with cameras that are unsynchronized, may feature rolling shutter distortion, and whose viewpoints are unknown. Our approach enables robust and accurate outside-in tracking of dynamically flying targets, with cheap and easy-to-deploy equipment. We show that, in spite of the weakly constrained setting, recent developments in computer vision make it possible to reconstruct trajectories in 3D from unsynchronized, uncalibrated networks of consumer cameras, and validate the proposed method in a realistic field experiment. We make our code available along with the data, including cm-accurate groundtruth from differential GNSS navigation.",
        "primary_area": "",
        "author": "Jingtong Li;Jesse Murray;Dorina Ismaili;Konrad Schindler;Cenek Albl;Jingtong Li;Jesse Murray;Dorina Ismaili;Konrad Schindler;Cenek Albl",
        "authorids": "/37088688825;/37088689089;/37088686566;/37267277500;/37085661473;/37088688825;/37088689089;/37088686566;/37267277500;/37085661473",
        "aff": "Photogrammetry and Remote Sensing, ETH Zurich, Zurich, Switzerland; Photogrammetry and Remote Sensing, ETH Zurich, Zurich, Switzerland; Department of Mathematics, Technical University Munich, Garching bei Munchen, Germany; Photogrammetry and Remote Sensing, ETH Zurich, Zurich, Switzerland; Photogrammetry and Remote Sensing, ETH Zurich, Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341479/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16631156927235658236&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "ETH Zurich;Technical University Munich",
        "aff_unique_dep": "Photogrammetry and Remote Sensing;Department of Mathematics",
        "aff_unique_url": "https://www.ethz.ch;https://www.tum.de",
        "aff_unique_abbr": "ETHZ;TUM",
        "aff_campus_unique_index": "0;0;1;0;0",
        "aff_campus_unique": "Zurich;Garching bei Munchen",
        "aff_country_unique_index": "0;0;1;0;0",
        "aff_country_unique": "Switzerland;Germany"
    },
    {
        "id": "9341576",
        "title": "Reducing the Teleoperator\u2019s Cognitive Burden for Complex Contact Tasks Using Affordance Primitives",
        "track": "main",
        "status": "Poster",
        "abstract": "Using robotic manipulators to remotely perform real-world complex contact tasks is challenging whether tasks are known (due to uncertainty) or unknown a priori (lack of motion waypoints, force profiles, etc.). For known tasks we can integrate and utilize Affordance Templates with a selective compliance jogger to remotely perform high dimensional velocity/force tasks - such as turning valves, opening doors, etc. Affordance Templates (ATs) contain virtual visual representations of task-relevant objects and waypoints for interacting with visualized objects. Operators and/or developers align pre-defined ATs with real-world objects to complete complex tasks, potentially reducing the operator's input dimension to a single initiation command. In this work, we integrate a compliant controller with existing ATs to reduce the operator's burden by 1) reducing the dimension of commanded inputs, 2) internally managing contact forces even for complex tasks, and 3) providing situational awareness in the task frame. Since not all tasks can be modeled for general teleoperation, we also introduce Affordance Primitives which reduce the command dimensionality of complex spatial tasks to as low as 1-dimensional input gestures as demonstrated for this effort. To enable reduction of the command input's dimension, the same compliant jogger used to robustly handle uncertainty with ATs is used with Affordance Primitives to autonomously maintain force constraints associated with complex contact tasks. Both Affordance Templates and Affordance Primitives - when used in tandem with a compliant jogger - provide a safe, intuitive, and efficient teleoperation system for general use including using primitives to easily develop new Affordance Templates from newly completed teleoperation tasks.",
        "primary_area": "",
        "author": "Adam Pettinger;Cassidy Elliott;Pete Fan;Mitch Pryor;Adam Pettinger;Cassidy Elliott;Pete Fan;Mitch Pryor",
        "authorids": "/37087009346;/37088687453;/37088686797;/37282146300;/37087009346;/37088687453;/37088686797;/37282146300",
        "aff": "Walker Department of Mechanical Engineering, The University of Texas at Austin, Austin, Texas; Walker Department of Mechanical Engineering, The University of Texas at Austin, Austin, Texas; Walker Department of Mechanical Engineering, The University of Texas at Austin, Austin, Texas; Walker Department of Mechanical Engineering, The University of Texas at Austin, Austin, Texas",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341576/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14730327033642885535&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "The University of Texas at Austin",
        "aff_unique_dep": "Walker Department of Mechanical Engineering",
        "aff_unique_url": "https://www.utexas.edu",
        "aff_unique_abbr": "UT Austin",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Austin",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341581",
        "title": "Redundancy resolution under hard joint constraints: a generalized approach to rank updates",
        "track": "main",
        "status": "Poster",
        "abstract": "The increasing interest in autonomous robots with a high number of degrees of freedom for industrial applications and service robotics have also increased the demand for efficient control algorithms. The unstructured environment these robots operate in often impose constraints on the joint motion, an important type being the joint limits of the robot itself. These circumstances demand control algorithms to handle multiple tasks as well as constraints efficiently. This paper shows that both kinematic and torque control of redundant robots under hard joint constraints can be formulated in a single framework as a constrained optimization problem. To solve said problem, a generalization of the Fast-SNS algorithm to weighted pseudoinverses is proposed, which fulfills our demand of efficiently and reliably handling joint constraints.",
        "primary_area": "",
        "author": "Anton Ziese;Mario D. Fiore;Jan Peters;Uwe E. Zimmermann;J\u00fcrgen Adamy;Anton Ziese;Mario D. Fiore;Jan Peters;Uwe E. Zimmermann;J\u00fcrgen Adamy",
        "authorids": "/37088688321;/37087471549;/37533077600;/38180258500;/37389754200;/37088688321;/37087471549;/37533077600;/38180258500;/37389754200",
        "aff": "TU Darmstadt, Darmstadt, DE; Corporate Research of KUKA Deutschland GmbH, Augsburg, DE; TU Darmstadt, Darmstadt, DE; Corporate Research of KUKA Deutschland GmbH, Augsburg, DE; TU Darmstadt, Darmstadt, DE",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341581/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1322647049034884557&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;1;0",
        "aff_unique_norm": "Technische Universit\u00e4t Darmstadt;KUKA Deutschland GmbH",
        "aff_unique_dep": ";Corporate Research",
        "aff_unique_url": "https://www.tu-darmstadt.de;https://www.kuka.com",
        "aff_unique_abbr": "TU Darmstadt;KUKA",
        "aff_campus_unique_index": "0;1;0;1;0",
        "aff_campus_unique": "Darmstadt;Augsburg",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9340725",
        "title": "RegionNet: Region-feature-enhanced 3D Scene Understanding Network with Dual Spatial-aware Discriminative Loss",
        "track": "main",
        "status": "Poster",
        "abstract": "Neural networks have recently achieved impressive success in semantic and instance segmentation on 2D images. However, their capabilities have not been fully explored to address semantic instance segmentation on unstructured 3D point cloud data. Digging into the regional feature representation to boost point cloud comprehension, we propose a region-feature-enhanced structure consisting of adaptive regional feature complementary (ARFC) module and affinity-based regional relational reasoning (AR3) module. The ARFC module aims to complement low-level features of sparse regions adaptively. The AR3 module emphasizes on mining the potential reasoning relationships between high-level features based on affinity. Both the ARFC and AR3 modules are plug-and-play. Besides, a novel dual spatial-aware discriminative loss is proposed to improve the discrimination of instance embedding. Our proposal-free point cloud instance segmentation network (RegionNet) equipped with the region-feature-enhanced structure and dual spatial-aware discriminative loss achieves state-of-the-art performance on S3DIS dataset and ScanNet-v2 dataset.",
        "primary_area": "",
        "author": "Guanghui Zhang;Dongchen Zhu;Xiaoqing Ye;Wenjun Shi;Minghong Chen;Jiamao Li;Xiaolin Zhang;Guanghui Zhang;Dongchen Zhu;Xiaoqing Ye;Wenjun Shi;Minghong Chen;Jiamao Li;Xiaolin Zhang",
        "authorids": "/37086823762;/37086420004;/37085686362;/37086421586;/37088686321;/37086083391;/37085830972;/37086823762;/37086420004;/37085686362;/37086421586;/37088686321;/37086083391;/37085830972",
        "aff": "University of Chinese Academy of Sciences, Beijing, China; Bionic Vision System Laboratory, State Key Laboratory of Transducer Technology, Shanghai Institute of Microsystem and Information Technology, Chinese Academy of Sciences, Shanghai, China; Baidu, Shanghai, China; University of Chinese Academy of Sciences, Beijing, China; University of Chinese Academy of Sciences, Beijing, China; University of Chinese Academy of Sciences, Beijing, China; ShanghaiTech University, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340725/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7243523055320214905&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;2;0;0;0;3",
        "aff_unique_norm": "University of Chinese Academy of Sciences;Shanghai Institute of Microsystem and Information Technology;Baidu;ShanghaiTech University",
        "aff_unique_dep": ";Bionic Vision System Laboratory, State Key Laboratory of Transducer Technology;;",
        "aff_unique_url": "http://www.ucas.ac.cn;http://www.sIMIT.ac.cn;https://www.baidu.com;http://www.shanghaitech.edu.cn",
        "aff_unique_abbr": "UCAS;SIMIT;Baidu;ShanghaiTech",
        "aff_campus_unique_index": "0;1;1;0;0;0;1",
        "aff_campus_unique": "Beijing;Shanghai",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9340829",
        "title": "Regulation of 2D Arm Stability Against Unstable, Damping-Defined Environments in Physical Human-Robot Interaction",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents an experimental study to investigate how humans interact with a robotic arm simulating primarily unstable, damping-defined, mechanical environments, and to quantify lower bounds of robotic damping that humans can stably interact with. Human subjects performed posture maintenance tasks while a robotic arm simulated a range of negative damping-defined environments and transiently perturbed the human arm to challenge postural stability. Analysis of 2-dimensional kinematic responses in both the time domain and phase space allowed us to evaluate stability of the coupled human-robot system in both anterior-posterior (AP) and medial-lateral (ML) directions, and to determine the lower bounds of robotic damping for stable physical human-robot interaction (pHRI). All subjects demonstrated higher capacity to stabilize their arm against negative damping-defined environments in the AP direction than the ML direction, evidenced by all 3 stability measures used in this study. Further, the lower bound of robotic damping for stable pHRI was more than 3.5 times lower in the AP direction than the ML direction: -30.0 Ns/m and -8.2 Ns/m in the AP and ML directions, respectively. Sensitivity analysis confirmed that the results in this study were relatively insensitive to varying experimental conditions. Outcomes of this study would allow us to design a less conservative robotic impedance controller that utilizes a wide range of robotic damping, including negative damping, and achieves more transparent and agile operations without compromising coupled stability and safety of the human-robot system, and thus improves the overall performance of pHRI.",
        "primary_area": "",
        "author": "Fatemeh Zahedi;Tanner Bitz;Connor Phillips;Hyunglae Lee;Fatemeh Zahedi;Tanner Bitz;Connor Phillips;Hyunglae Lee",
        "authorids": "/37088505564;/37088505942;/37088691451;/37085768762;/37088505564;/37088505942;/37088691451;/37085768762",
        "aff": "School for Engineering of Matter, Transport, and Energy, Arizona State University, Tempe, AZ, USA; School for Engineering of Matter, Transport, and Energy, Arizona State University, Tempe, AZ, USA; School for Engineering of Matter, Transport, and Energy, Arizona State University, Tempe, AZ, USA; School for Engineering of Matter, Transport, and Energy, Arizona State University, Tempe, AZ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340829/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11465419286508149869&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Arizona State University",
        "aff_unique_dep": "School for Engineering of Matter, Transport, and Energy",
        "aff_unique_url": "https://www.asu.edu",
        "aff_unique_abbr": "ASU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Tempe",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341149",
        "title": "Reinforced Grounded Action Transformation for Sim-to-Real Transfer",
        "track": "main",
        "status": "Poster",
        "abstract": "Robots can learn to do complex tasks in simulation, but often, learned behaviors fail to transfer well to the real world due to simulator imperfections (the \"reality gap\"). Some existing solutions to this sim-to-real problem, such as Grounded Action Transformation (gat), use a small amount of real-world experience to minimize the reality gap by \"grounding\" the simulator. While very effective in certain scenarios, gat is not robust on problems that use complex function approximation techniques to model a policy. In this paper, we introduce Reinforced Grounded Action Transformation (rgat), a new sim-to-real technique that uses Reinforcement Learning (RL) not only to update the target policy in simulation, but also to perform the grounding step itself. This novel formulation allows for end-to-end training during the grounding step, which, compared to gat, produces a better grounded simulator. Moreover, we show experimentally in several MuJoCo domains that our approach leads to successful transfer for policies modeled using neural networks.",
        "primary_area": "",
        "author": "Haresh Karnan;Siddharth Desai;Josiah P. Hanna;Garrett Warnell;Peter Stone;Haresh Karnan;Siddharth Desai;Josiah P. Hanna;Garrett Warnell;Peter Stone",
        "authorids": "/37086310655;/37088687601;/37088467292;/37079072000;/37269574900;/37086310655;/37088687601;/37088467292;/37079072000;/37269574900",
        "aff": "Department of Mechanical Engineering, The University of Texas at Austin; Department of Mechanical Engineering, The University of Texas at Austin; School of Informatics, University of Edinburgh; Army Research Laboratory; Department of Computer Science and Sony AI, The University of Texas at Austin",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341149/",
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13919508578090589946&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;2;0",
        "aff_unique_norm": "The University of Texas at Austin;University of Edinburgh;Army Research Laboratory",
        "aff_unique_dep": "Department of Mechanical Engineering;School of Informatics;",
        "aff_unique_url": "https://www.utexas.edu;https://www.ed.ac.uk;https://www.arl.army.mil",
        "aff_unique_abbr": "UT Austin;Edinburgh;ARL",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Austin;Edinburgh;",
        "aff_country_unique_index": "0;0;1;0;0",
        "aff_country_unique": "United States;United Kingdom"
    },
    {
        "id": "9341629",
        "title": "Reinforcement Learning in Latent Action Sequence Space",
        "track": "main",
        "status": "Poster",
        "abstract": "One problem in real-world applications of reinforcement learning is the high dimensionality of the action search spaces, which comes from the combination of actions over time. To reduce the dimensionality of action sequence search spaces, macro actions have been studied, which are sequences of primitive actions to solve tasks. However, previous studies relied on humans to define macro actions or assumed macro actions to be repetitions of the same primitive actions. We propose encoded action sequence reinforcement learning (EASRL), a reinforcement learning method that learns flexible sequences of actions in a latent space for a high-dimensional action sequence search space. With EASRL, encoder and decoder networks are trained with demonstration data by using variational autoencoders for mapping macro actions into the latent space. Then, we learn a policy network in the latent space, which is a distribution over encoded macro actions given a state. By learning in the latent space, we can reduce the dimensionality of the action sequence search space and handle various patterns of action sequences. We experimentally demonstrate that the proposed method outperforms other reinforcement learning methods on tasks that require an extensive amount of search.",
        "primary_area": "",
        "author": "Heecheol Kim;Masanori Yamada;Kosuke Miyoshi;Tomoharu Iwata;Hiroshi Yamakawa;Heecheol Kim;Masanori Yamada;Kosuke Miyoshi;Tomoharu Iwata;Hiroshi Yamakawa",
        "authorids": "/37088419106;/37892556400;/37088687772;/37851153300;/37345846500;/37088419106;/37892556400;/37088687772;/37851153300;/37345846500",
        "aff": "Laboratory for Intelligent Systems and Informatics, Graduate School of Information Science and Technology, The University of Tokyo; NTT Secure Platform Laboratories; narrative nights inc.; NTT Communication Science Laboratories; Dwango Artificial Intelligence Laboratory",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341629/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13736092743009834513&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;3;4",
        "aff_unique_norm": "The University of Tokyo;NTT Secure Platform Laboratories;Narrative Nights Inc.;NTT Communication Science Laboratories;Dwango Co., Ltd.",
        "aff_unique_dep": "Graduate School of Information Science and Technology;;;;Artificial Intelligence Laboratory",
        "aff_unique_url": "https://www.u-tokyo.ac.jp;https://www.ntt.co.jp;;https://www.ntt-csl.com;https://www.dwango.co.jp",
        "aff_unique_abbr": "UTokyo;NTT SPL;;NTT CSL;Dwango AI Lab",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1;0;0",
        "aff_country_unique": "Japan;United States"
    },
    {
        "id": "9341656",
        "title": "Reinforcement Learning-based Hierarchical Control for Path Following of a Salamander-like Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Path following is a challenging task for legged robots. In this paper, we present a hierarchical control architecture for path following of a quadruped salamander-like robot, in which, the tracking problem is decomposed into two sub-tasks: high-level policy learning based on the framework of reinforcement learning (RL) and low-level traditional controller design. More specifically, the high-level policy is learned in a physics simulator with a low-level controller designed in advance. To improve the tracking accuracy and to eliminate static errors, a soft Actor-Critic algorithm with state integral compensation is proposed. Additionally, to enhance the generalization and transferability, a compact state representation, which only contains the information of the target path and the abstract action similar to front-back and left-right, is proposed. The proposed algorithm is trained offline in the simulation environment and tested on the self-developed real quadruped salamander-like robot for different path following tasks. Simulation and experiments results validate the satisfactory performance of the proposed method.",
        "primary_area": "",
        "author": "Xueyou Zhang;Xian Guo;Yongchun Fang;Wei Zhu;Xueyou Zhang;Xian Guo;Yongchun Fang;Wei Zhu",
        "authorids": "/37086935688;/37085448334;/37293583100;/37086327424;/37086935688;/37085448334;/37293583100;/37086327424",
        "aff": "Institute of Robotics and Automatic Information System, College of Artificial Intelligence, Nankai University, China; Institute of Robotics and Automatic Information System, College of Artificial Intelligence, Nankai University, China; Institute of Robotics and Automatic Information System, College of Artificial Intelligence, Nankai University, China; Institute of Robotics and Automatic Information System, College of Artificial Intelligence, Nankai University, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341656/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5799555938666611000&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Nankai University",
        "aff_unique_dep": "Institute of Robotics and Automatic Information System, College of Artificial Intelligence",
        "aff_unique_url": "http://www.nankai.edu.cn",
        "aff_unique_abbr": "Nankai U",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9340948",
        "title": "Reinforcement co-Learning of Deep and Spiking Neural Networks for Energy-Efficient Mapless Navigation with Neuromorphic Hardware",
        "track": "main",
        "status": "Poster",
        "abstract": "Energy-efficient mapless navigation is crucial for mobile robots as they explore unknown environments with limited on-board resources. Although the recent deep rein-forcement learning (DRL) approaches have been successfully applied to navigation, their high energy consumption limits their use in several robotic applications. Here, we propose a neuromorphic approach that combines the energy-efficiency of spiking neural networks with the optimality of DRL and benchmark it in learning control policies for mapless navigation. Our hybrid framework, spiking deep deterministic policy gradient (SDDPG), consists of a spiking actor network (SAN) and a deep critic network, where the two networks were trained jointly using gradient descent. The co-learning enabled synergistic information exchange between the two networks, allowing them to overcome each other's limitations through a shared representation learning. To evaluate our approach, we deployed the trained SAN on Intel's Loihi neuromorphic processor. When validated on simulated and real-world complex environments, our method on Loihi consumed 75 times less energy per inference as compared to DDPG on Jetson TX2, and also exhibited a higher rate of successful navigation to the goal, which ranged from 1% to 4.2% and depended on the forward-propagation timestep size. These results reinforce our ongoing efforts to design brain-inspired algorithms for controlling autonomous robots with neuromorphic hardware.",
        "primary_area": "",
        "author": "Guangzhi Tang;Neelesh Kumar;Konstantinos P. Michmizos;Guangzhi Tang;Neelesh Kumar;Konstantinos P. Michmizos",
        "authorids": "/37087322548;/37088534941;/37062249500;/37087322548;/37088534941;/37062249500",
        "aff": "Department of Computer Science, Computational Brain Lab, Rutgers University, New Jersey, USA; Department of Computer Science, Computational Brain Lab, Rutgers University, New Jersey, USA; Department of Computer Science, Computational Brain Lab, Rutgers University, New Jersey, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340948/",
        "gs_citation": 98,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5872153777584052984&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Rutgers University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.rutgers.edu",
        "aff_unique_abbr": "Rutgers",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "New Brunswick",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340705",
        "title": "Relational Graph Learning for Crowd Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a relational graph learning approach for robotic crowd navigation using model-based deep reinforcement learning that plans actions by looking into the future. Our approach reasons about the relations between all agents based on their latent features and uses a Graph Convolutional Network to encode higher-order interactions in each agent\u2019s state representation, which is subsequently leveraged for state prediction and value estimation. The ability to predict human motion allows us to perform multi-step lookahead planning, taking into account the temporal evolution of human crowds. We evaluate our approach against a state-of-the-art baseline for crowd navigation and ablations of our model to demonstrate that navigation with our approach is more efficient, results in fewer collisions, and avoids failure cases involving oscillatory and freezing behaviors.",
        "primary_area": "",
        "author": "Changan Chen;Sha Hu;Payam Nikdel;Greg Mori;Manolis Savva;Changan Chen;Sha Hu;Payam Nikdel;Greg Mori;Manolis Savva",
        "authorids": "/37086934032;/37089402786;/37086454305;/37279179700;/37085637170;/37086934032;/37089402786;/37086454305;/37279179700;/37085637170",
        "aff": "Simon Fraser University; Simon Fraser University; Simon Fraser University; Simon Fraser University; Simon Fraser University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340705/",
        "gs_citation": 164,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5078529574614222718&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Simon Fraser University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.sfu.ca",
        "aff_unique_abbr": "SFU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9341707",
        "title": "Relative Pose Estimation and Planar Reconstruction via Superpixel-Driven Multiple Homographies",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a novel method to simultaneously perform relative camera pose estimation and planar reconstruction of a scene from two RGB images. We start by extracting and matching superpixel information from both images and rely on a novel multi-model RANSAC approach to estimate multiple homographies from superpixels and identify matching planes. Ambiguity issues when performing homography decomposition are handled by proposing a voting system to more reliably estimate relative camera pose and plane parameters. A non-linear optimization process is also proposed to perform bundle adjustment that exploits a joint representation of homographies and works both for image pairs and whole sequences of image (vSLAM). As a result, the approach provides a mean to perform a dense 3D plane reconstruction from two RGB images only without relying on RGB-D inputs or strong priors such as Manhattan assumptions, and can be extented to handle sequences of images. Our results compete with keypointbased techniques such as ORB-SLAM while providing a dense representation and are more precise than direct and semi-direct pose estimation techniques used in LSD-SLAM or DPPTAM.",
        "primary_area": "",
        "author": "Xi Wang;Marc Christie;Eric Marchand;Xi Wang;Marc Christie;Eric Marchand",
        "authorids": "/37086529410;/38241597200;/37269970500;/37086529410;/38241597200;/37269970500",
        "aff": "CNRS, Univ Rennes, Inria, Irisa, France; CNRS, Univ Rennes, Inria, Irisa, France; CNRS, Univ Rennes, Inria, Irisa, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341707/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5720315555765061725&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "CNRS",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.cnrs.fr",
        "aff_unique_abbr": "CNRS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9340806",
        "title": "Relevant Region Exploration On General Cost-maps For Sampling-Based Motion Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Asymptotically optimal sampling-based planners require an intelligent exploration strategy to accelerate convergence. After an initial solution is found, a necessary condition for improvement is to generate new samples in the so-called \"Informed Set\". However, Informed Sampling can be ineffective in focusing search if the chosen heuristic fails to provide a good estimate of the solution cost. This work proposes an algorithm to sample the \"Relevant Region\" instead, which is a subset of the Informed Set. The Relevant Region utilizes cost-to-come information from the planner's tree structure, reduces dependence on the heuristic, and further focuses the search. Benchmarking tests in uniform and general cost-space settings demonstrate the efficacy of Relevant Region sampling.",
        "primary_area": "",
        "author": "Sagar Suhas Joshi;Panagiotis Tsiotras;Sagar Suhas Joshi;Panagiotis Tsiotras",
        "authorids": "/37088691385;/37330609800;/37088691385;/37330609800",
        "aff": "Sagar Suhas Joshi; Panagiotis Tsiotras",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340806/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16767485541510632570&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "",
        "aff_unique_norm": "",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "9340753",
        "title": "Reliable chattering-free simulation of friction torque in joints presenting high stiction",
        "track": "main",
        "status": "Poster",
        "abstract": "The simulation of static friction, and especially the effect of stiction, is cumbersome to perform in discrete-time due to its discontinuity at zero velocity and its switching behavior. However, it is essential to achieve reliable simulations of friction to develop compliant torque control algorithms, as they are much disturbed by this phenomenon. This paper takes as a base an elastoplastic model approach for friction, which is free from chattering and drift. It proposes two closed-form solutions that can be used to reliably simulate the effect of stiction consistently with the physics-based Stribeck model. These solutions consider the nonlinearity and velocity dependency, which are main characteristics of lubricated joints. One is directly inspired by the Stribeck nonlinear terms, and the other is a simplified rational approximation. The reliability of this simulation method is shown in simulation, where the consistency and stability are assessed. We also demonstrate the accuracy of these methods by comparing them to experimental data obtained from a robot joint equipped with a high gear reduction harmonic drive.",
        "primary_area": "",
        "author": "Rafael Cisneros;Mehdi Benallegue;Ryo Kikuuwe;Mitsuharu Morisawa;Fumio Kanehiro;Rafael Cisneros;Mehdi Benallegue;Ryo Kikuuwe;Mitsuharu Morisawa;Fumio Kanehiro",
        "authorids": "/38580560800;/37571999700;/37295995700;/37295668600;/37283667500;/38580560800;/37571999700;/37295995700;/37295668600;/37283667500",
        "aff": "CNRS-AIST JRL (Joint Robotics Laboratory), IRL, Tsukuba, Japan; CNRS-AIST JRL (Joint Robotics Laboratory), IRL, Tsukuba, Japan; Machinery Dynamics Lab., Hiroshima Univ., Higashi-Hiroshima, Japan; CNRS-AIST JRL (Joint Robotics Laboratory), IRL, Tsukuba, Japan; CNRS-AIST JRL (Joint Robotics Laboratory), IRL, Tsukuba, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340753/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7528986426730504293&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "CNRS-AIST Joint Robotics Laboratory;Hiroshima University",
        "aff_unique_dep": "Joint Robotics Laboratory;Machinery Dynamics Lab.",
        "aff_unique_url": ";https://www.hiroshima-u.ac.jp",
        "aff_unique_abbr": "CNRS-AIST JRL;Hiroshima U",
        "aff_campus_unique_index": "0;0;1;0;0",
        "aff_campus_unique": "Tsukuba;Higashi-Hiroshima",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9340856",
        "title": "Remove, then Revert: Static Point cloud Map Construction using Multiresolution Range Images",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a novel static point cloud map construction algorithm, called Removert, for use within dynamic urban environments. Leaving only static points and excluding dynamic objects is a critical problem in various robust robot missions in changing outdoors, and the procedure commonly contains comparing a query to the noisy map that has dynamic points. In doing so, however, the estimated discrepancies between a query scan and the noisy map tend to possess errors due to imperfect pose estimation, which degrades the static map quality. To tackle the problem, we propose a multiresolution range image-based false prediction reverting algorithm. We first conservatively retain definite static points and iteratively recover more uncertain static points by enlarging the query-to- map association window size, which implicitly compensates the LiDAR motion or registration errors. We validate our method on the KITTI dataset using SemanticKITTI as ground truth, and show our method qualitatively competes or outperforms the human-labeled data (SemanticKITTI) in ambiguous regions.",
        "primary_area": "",
        "author": "Giseop Kim;Ayoung Kim;Giseop Kim;Ayoung Kim",
        "authorids": "/37086578593;/37403315600;/37086578593;/37403315600",
        "aff": "Department of Civil and Environmental Engineering, KAIST, Daejeon, S. Korea; Department of Civil and Environmental Engineering, KAIST, Daejeon, S. Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340856/",
        "gs_citation": 190,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3753744867377588961&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "KAIST",
        "aff_unique_dep": "Department of Civil and Environmental Engineering",
        "aff_unique_url": "https://www.kaist.ac.kr",
        "aff_unique_abbr": "KAIST",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Daejeon",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9341470",
        "title": "Representation and Experience-Based Learning of Explainable Models for Robot Action Execution",
        "track": "main",
        "status": "Poster",
        "abstract": "For robots acting in human-centered environments, the ability to improve based on experience is essential for reliable and adaptive operation; however, particularly in the context of robot failure analysis, experience-based improvement is practically useful only if robots are also able to reason about and explain the decisions they make during execution. In this paper, we describe and analyse a representation of execution-specific knowledge that combines (i) a relational model in the form of qualitative attributes that describe the conditions under which actions can be executed successfully and (ii) a continuous model in the form of a Gaussian process that can be used for generating parameters for action execution, but also for evaluating the expected execution success given a particular action parameterisation. The proposed representation is based on prior, modelled knowledge about actions and is combined with a learning process that is supervised by a teacher. We analyse the benefits of this representation in the context of two actions - grasping handles and pulling an object on a table -such that the experiments demonstrate that the joint relational-continuous model allows a robot to improve its execution based on experience, while reducing the severity of failures experienced during execution.",
        "primary_area": "",
        "author": "Alex Mitrevski;Paul G. Pl\u00f6ger;Gerhard Lakemeyer;Alex Mitrevski;Paul G. Pl\u00f6ger;Gerhard Lakemeyer",
        "authorids": "/37086062289;/37344552000;/38533030900;/37086062289;/37344552000;/38533030900",
        "aff": "Department of Computer Science, Hochschule Bonn-Rhein-Sieg, Sankt Augustin, Germany; Department of Computer Science, Hochschule Bonn-Rhein-Sieg, Sankt Augustin, Germany; Department of Computer Science, RWTH Aachen, Aachen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341470/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7956823784228736213&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Hochschule Bonn-Rhein-Sieg;RWTH Aachen University",
        "aff_unique_dep": "Department of Computer Science;Department of Computer Science",
        "aff_unique_url": "https://www.h-brs.de;https://www.rwth-aachen.de",
        "aff_unique_abbr": ";RWTH",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Sankt Augustin;Aachen",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9340925",
        "title": "Representing Spatial Object Relations as Parametric Polar Distribution for Scene Manipulation Based on Verbal Commands",
        "track": "main",
        "status": "Poster",
        "abstract": "Understanding spatial relations is a key element for natural human-robot interaction. Especially, a robot must be able to manipulate a given scene according to a human verbal command specifying desired spatial relations between objects. To endow robots with this ability, a suitable representation of spatial relations is necessary, which should be derivable from human demonstrations. We claim that polar coordinates can capture the underlying structure of spatial relations better than Cartesian coordinates and propose a parametric probability distribution defined in polar coordinates to represent spatial relations. We consider static spatial relations such as left of, behind, and near, as well as dynamic ones such as closer to and other side of, and take into account verbal modifiers such as roughly and a lot. We show that adequate distributions can be derived for various combinations of spatial relations and modifiers in a sample-efficient way using Maximum Likelihood Estimation, evaluate the effects of modifiers on the distribution parameters, and demonstrate our representation's usefulness in a pick-and-place task on a real robot.",
        "primary_area": "",
        "author": "Rainer Kartmann;You Zhou;Danqing Liu;Fabian Paus;Tamim Asfour;Rainer Kartmann;You Zhou;Danqing Liu;Fabian Paus;Tamim Asfour",
        "authorids": "/37086429927;/37086046566;/37088686402;/37086267483;/37295529100;/37086429927;/37086046566;/37088686402;/37086267483;/37295529100",
        "aff": "Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340925/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2658046691958734466&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Karlsruhe Institute of Technology",
        "aff_unique_dep": "Institute for Anthropomatics and Robotics",
        "aff_unique_url": "https://www.kit.edu",
        "aff_unique_abbr": "KIT",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Karlsruhe",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9340695",
        "title": "Residual Pose: A Decoupled Approach for Depth-based 3D Human Pose Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose to leverage recent advances in reliable 2D pose estimation with Convolutional Neural Networks (CNN) to estimate the 3D pose of people from depth images in multi-person Human-Robot Interaction (HRI) scenarios. Our method is based on the observation that using the depth information to obtain 3D lifted points from 2D body landmark detections provides a rough estimate of the true 3D human pose, thus requiring only a refinement step. In that line our contributions are threefold. (i) we propose to perform 3D pose estimation from depth images by decoupling 2D pose estimation and 3D pose refinement; (ii) we propose a deep-learning approach that regresses the residual pose between the lifted 3D pose and the true 3D pose; (iii) we show that despite its simplicity, our approach achieves very competitive results both in accuracy and speed on two public datasets and is therefore appealing for multi-person HRI compared to recent state-of-the-art methods.",
        "primary_area": "",
        "author": "Angel Mart\u00ednez-Gonz\u00e1lez;Michael Villamizar;Olivier Can\u00e9vet;Jean-Marc Odobez;Angel Mart\u00ednez-Gonz\u00e1lez;Michael Villamizar;Olivier Can\u00e9vet;Jean-Marc Odobez",
        "authorids": "/37086639130;/37547768200;/37086155606;/37271897800;/37086639130;/37547768200;/37086155606;/37271897800",
        "aff": "\u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), Switzerland; Idiap Research Institute, Switzerland; Idiap Research Institute, Switzerland; \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340695/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13527969583254333546&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "\u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne;Idiap Research Institute",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.epfl.ch;https://www.idiap.ch",
        "aff_unique_abbr": "EPFL;Idiap",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9340871",
        "title": "Resilient Coverage: Exploring the Local-to-Global Trade-off",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a centralized control framework to select suitable robots from a heterogeneous pool and place them at appropriate locations to monitor a region for events of interest. In the event of a robot failure, our framework repositions robots in a user-defined local neighborhood of the failed robot to compensate for the coverage loss. If repositioning robots locally fails to attain a user-specified level of desired coverage, the central controller augments the team with additional robots from the pool. The size of the local neighborhood around the failed robot and the desired coverage over the region are two objectives that can be varied to achieve a user-specified balance. We investigate the trade-off between the coverage compensation achieved through local repositioning and the computation required to plan the new robot locations. We also study the relationship between the size of the local neighborhood and the number of additional robots added to the team for a given user-specified level of desired coverage. Through extensive simulations and an experiment with a team of seven quadrotors we verify the effectiveness of our framework. We show that to reach a high level of coverage in a neighborhood with a large robot population, it is more efficient to enlarge the neighborhood size, instead of adding additional robots and repositioning them.",
        "primary_area": "",
        "author": "Ragesh K. Ramachandran;Lifeng Zhou;James A. Preiss;Gaurav S. Sukhatme;Ragesh K. Ramachandran;Lifeng Zhou;James A. Preiss;Gaurav S. Sukhatme",
        "authorids": "/37087324984;/37086092920;/37086138258;/37278934100;/37087324984;/37086092920;/37086138258;/37278934100",
        "aff": "Department of Computer Science, University of Southern California, Los Angeles, CA, USA; Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA, USA; Department of Computer Science, University of Southern California, Los Angeles, CA, USA; Department of Computer Science, University of Southern California, Los Angeles, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340871/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2548333512244282618&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "University of Southern California;Virginia Tech",
        "aff_unique_dep": "Department of Computer Science;Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.usc.edu;https://www.vt.edu",
        "aff_unique_abbr": "USC;VT",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Los Angeles;Blacksburg",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340746",
        "title": "Resonating Magnetic Manipulation for 3D Path-Following and Blood Clot Removal Using a Rotating Swimmer",
        "track": "main",
        "status": "Poster",
        "abstract": "There are many design trade-offs when building a magnetic manipulator to control millimeter-scale rotating magnetic swimmers for surgical applications.For example, increasing the magnitude of the flux density generated by the magnetic manipulator increases the torque applied to the swimmer, which could enable performing a wider variety of surgical tasks in the future. However, producing stronger magnetic fields has drawbacks, such as increased active power usage.To produce a quickly rotating field, EMs must be quickly charged and discharged. This results in a low power factor (high reactive power used in comparison with the active power). Adding capacitors in series with the electromagnets improves the power factor because the capacitors can provide reactive power. With this method, larger flux densities can be produced without necessitating an increase of the apparent power delivered by the power supplies.This paper highlights the benefits of using capacitors for the magnetic manipulation of rotating swimmers. Rotating swimmers can be used to remove blood clots. The clot removal rate of resonating magnetic manipulators is measured using a realistic blood clot model. This paper also presents a control method for the currents inside the electromagnets that enable 3D navigation without current sensing.",
        "primary_area": "",
        "author": "Julien Leclerc;Yitong Lu;Aaron T. Becker;Mohamad Ghosn;Dipan J. Shah;Julien Leclerc;Yitong Lu;Aaron T. Becker;Mohamad Ghosn;Dipan J. Shah",
        "authorids": "/38246174500;/37088686719;/37588897100;/37085806989;/37605753400;/38246174500;/37088686719;/37588897100;/37085806989;/37605753400",
        "aff": "Department of Electrical Engineering, University of Houston, Houston, TX, USA; Department of Electrical Engineering, University of Houston, Houston, TX, USA; Department of Electrical Engineering, University of Houston, Houston, TX, USA; Houston Methodist DeBakey Heart & Vascular Center, Houston, TX, USA; Houston Methodist DeBakey Heart & Vascular Center, Houston, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340746/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11034497853685227016&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;1",
        "aff_unique_norm": "University of Houston;Houston Methodist DeBakey Heart & Vascular Center",
        "aff_unique_dep": "Department of Electrical Engineering;Heart & Vascular Center",
        "aff_unique_url": "https://www.uh.edu;https://www.houstonmethodist.org/heartvascular",
        "aff_unique_abbr": "UH;HMHVC",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Houston",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341734",
        "title": "Resultant Radius of Curvature of Stylet-and-Tube Steerable Needles Based on the Mechanical Properties of the Soft Tissue, and the Needle",
        "track": "main",
        "status": "Poster",
        "abstract": "Steerable needles have been widely researched in recent years, and they have multiple potential roles in the medical area. The flexibility and capability of avoiding obstacles allow the steerable needles to be applied in the biopsy, drug delivery and other medical applications that require a high degree of freedom and control accuracy. Radius of Curvature (ROC) of the needle while inserting in the soft tissue is an important parameter for evaluation of the efficacy, and steerability of these flexible needles. For our Fracture-directed Stylet-and-Tube Steerable Needles, it is important to find a relationship among the resultant insertion ROC, pre-set wire shape and the Young\u2019s Modulus of soft tissue to characterize this class of steerable needles. In this paper, an approach is provided for obtaining resultant ROC using stylet and tissue\u2019s mechanical properties. A finite element analysis is also conducted to support the reliability of the model. This work sets the foundation for other researchers to predict the insertion ROC based on the mechanical properties of the needle, and the soft tissue that is being inserted.",
        "primary_area": "",
        "author": "Fan Yang;Mahdieh Babaiasl;Yao Chen;Jow-Lian Ding;John P. Swensen;Fan Yang;Mahdieh Babaiasl;Yao Chen;Jow-Lian Ding;John P. Swensen",
        "authorids": "/37086478161;/144069376412113;/37086831010;/37292192000;/37949206100;/37086478161;/144069376412113;/37086831010;/37292192000;/37949206100",
        "aff": "School of Mechanical and Materials Engineering, Washington State University, Pullman, Washington, USA; School of Mechanical and Materials Engineering, Washington State University, Pullman, Washington, USA; School of Mechanical and Materials Engineering, Washington State University, Pullman, Washington, USA; School of Mechanical and Materials Engineering, Washington State University, Pullman, Washington, USA; School of Mechanical and Materials Engineering, Washington State University, Pullman, Washington, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341734/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:FWR55V-XrRIJ:scholar.google.com/&scioq=Resultant+Radius+of+Curvature+of+Stylet-and-Tube+Steerable+Needles+Based+on+the+Mechanical+Properties+of+the+Soft+Tissue,+and+the+Needle&hl=en&as_sdt=0,5",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Washington State University",
        "aff_unique_dep": "School of Mechanical and Materials Engineering",
        "aff_unique_url": "https://wsu.edu",
        "aff_unique_abbr": "WSU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Pullman",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341544",
        "title": "Richer Aggregated Features for Optical Flow Estimation with Edge-aware Refinement",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent CNN-based optical flow approaches have a separated structure of feature extraction and flow estimation. The core task of optical flow is finding the corresponding points while rich representation is just the key part of such matching problems. However, the prior work usually pays more attention to the design of flow decoder than the feature extraction. In this paper, we present a novel optical flow estimation network to enrich the feature representation of each pyramid level, with a hierarchical dilated architecture and a bottom-up aggregation scheme. In addition, inspired by edge guided classical methods, we bring the edge-aware idea into our approach and propose an edge-aware refinement (EAR) subnetwork to handle motion boundaries. Using the same decoding structure as PWC-Net, our network outperforms it by a large margin and leads all its derivatives both on KITTI-2012 and KITTI-2015. Further performance analysis proves the effectiveness of proposed ideas.",
        "primary_area": "",
        "author": "Xianshun Wang;Dongchen Zhu;Jiafei Song;Yanqing Liu;Jiamao Li;Xiaolin Zhang;Xianshun Wang;Dongchen Zhu;Jiafei Song;Yanqing Liu;Jiamao Li;Xiaolin Zhang",
        "authorids": "/37086823920;/37086420004;/37088686096;/37086418759;/37086083391;/37085830972;/37086823920;/37086420004;/37088686096;/37086418759;/37086083391;/37085830972",
        "aff": "University of Chinese Academy of Sciences, Beijing, China; Bionic Vision System Laboratory, State Key Laboratory of Transducer Technology, Shanghai Institute of Microsystem and Information Technology, Chinese Academy of Sciences; ShanghaiTech University, Shanghai, China; Bionic Vision System Laboratory, State Key Laboratory of Transducer Technology, Shanghai Institute of Microsystem and Information Technology, Chinese Academy of Sciences; University of Chinese Academy of Sciences, Beijing, China; ShanghaiTech University, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341544/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12552614719472705334&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;1;0;2",
        "aff_unique_norm": "University of Chinese Academy of Sciences;Shanghai Institute of Microsystem and Information Technology;ShanghaiTech University",
        "aff_unique_dep": ";Bionic Vision System Laboratory, State Key Laboratory of Transducer Technology;",
        "aff_unique_url": "http://www.ucas.ac.cn;http://www.sIMIT.ac.cn;http://www.shanghaitech.edu.cn",
        "aff_unique_abbr": "UCAS;;ShanghaiTech",
        "aff_campus_unique_index": "0;2;0;2",
        "aff_campus_unique": "Beijing;;Shanghai",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9341105",
        "title": "Risk Vector-based Near miss Obstacle Avoidance for Autonomous Surface Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel risk vector-based near miss prediction and obstacle avoidance method. The proposed method uses the sensor readings about the pose of the other obstacles to infer their motion model (velocity and heading) and, accordingly, adapt the risk assessment and take corrective actions if necessary. Relative vector calculations allow the method to perform in real-time. The algorithm has 1.68 times faster computation performance with less change of motion than other methods and it enables a robot to avoid 25 obstacles in a congested area. Fallback behaviors are also proposed in case of faulty sensors or situation changes. Simulation experiments with parameters inferred from experiments in the ocean with our custom-made robotic boat show the flexibility and adaptability of the proposed method to many obstacles present in the environment. Results highlight more efficient trajectories and comparable safety as other state-of-the-art methods, as well as robustness to failures.",
        "primary_area": "",
        "author": "Mingi Jeong;Alberto Quattrini Li;Mingi Jeong;Alberto Quattrini Li",
        "authorids": "/37087244961;/37085808885;/37087244961;/37085808885",
        "aff": "Department of Computer Science, Dartmouth College, Hanover, NH, USA; Department of Computer Science, Dartmouth College, Hanover, NH, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341105/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16962250676788846498&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Dartmouth College",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.dartmouth.edu",
        "aff_unique_abbr": "Dartmouth",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Hanover",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341070",
        "title": "Risk-Averse MPC via Visual-Inertial Input and Recurrent Networks for Online Collision Avoidance",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose an online path planning architecture that extends the model predictive control (MPC) formulation to consider future location uncertainties for safer navigation through cluttered environments. Our algorithm combines an object detection pipeline with a recurrent neural network (RNN) which infers the covariance of state estimates through each step of our MPC's finite time horizon. The RNN model is trained on a dataset that comprises of robot and landmark poses generated from camera images and inertial measurement unit (IMU) readings via a state-of-the-art visualinertial odometry framework. To detect and extract object locations for avoidance, we use a custom-trained convolutional neural network model in conjunction with a feature extractor to retrieve 3D centroid and radii boundaries of nearby obstacles. The robustness of our methods is validated on complex quadruped robot dynamics and can be generally applied to most robotic platforms, demonstrating autonomous behaviors that can plan fast and collision-free paths towards a goal point.",
        "primary_area": "",
        "author": "Alexander Schperberg;Kenny Chen;Stephanie Tsuei;Michael Jewett;Joshua Hooks;Stefano Soatto;Ankur Mehta;Dennis Hong;Alexander Schperberg;Kenny Chen;Stephanie Tsuei;Michael Jewett;Joshua Hooks;Stefano Soatto;Ankur Mehta;Dennis Hong",
        "authorids": "/37088689963;/37088689284;/37085998256;/37088688280;/37086575738;/37282915600;/37086302574;/37575333900;/37088689963;/37088689284;/37085998256;/37088688280;/37086575738;/37282915600;/37086302574;/37575333900",
        "aff": "Department of Mechanical and Aerospace Engineering, Robotics and Mechanisms Laboratory, University of California, Los Angeles, Los Angeles, CA, USA; Department of Electrical and Computer Engineering, Laboratory for Embedded Machines and Ubiquitous Robots, University of California, Los Angeles, Los Angeles, CA, USA; Department of Computer Science, UCLA Vision Lab, University of California, Los Angeles, Los Angeles, CA, USA; Department of Mechanical and Aerospace Engineering, Robotics and Mechanisms Laboratory, University of California, Los Angeles, Los Angeles, CA, USA; Department of Mechanical and Aerospace Engineering, Robotics and Mechanisms Laboratory, University of California, Los Angeles, Los Angeles, CA, USA; Department of Computer Science, UCLA Vision Lab, University of California, Los Angeles, Los Angeles, CA, USA; Department of Electrical and Computer Engineering, Laboratory for Embedded Machines and Ubiquitous Robots, University of California, Los Angeles, Los Angeles, CA, USA; Department of Mechanical and Aerospace Engineering, Robotics and Mechanisms Laboratory, University of California, Los Angeles, Los Angeles, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341070/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9851535712675164479&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;0;0;0",
        "aff_unique_norm": "University of California, Los Angeles",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.ucla.edu",
        "aff_unique_abbr": "UCLA",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341075",
        "title": "Risk-Aware Planning and Assignment for Ground Vehicles using Uncertain Perception from Aerial Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a risk-aware framework for multi-robot, multi-demand assignment and planning in unknown environments. Our motivation is disaster response and search-and-rescue scenarios where ground vehicles must reach demand locations as soon as possible. We consider a setting where the terrain information is available only in the form of an aerial, georeferenced image. Deep learning techniques can be used for semantic segmentation of the aerial image to create a cost map for safe ground robot navigation. Such segmentation may still be noisy. Hence, we present a joint planning and perception framework that accounts for the risk introduced due to noisy perception. Our contributions are two-fold: (i) we show how to use Bayesian deep learning techniques to extract risk at the perception level; and (ii) use a risk-theoretical measure, CVaR, for risk-aware planning and assignment. The pipeline is theoretically established, then empirically analyzed through two datasets. We find that accounting for risk at both levels produces quantifiably safer paths and assignments.",
        "primary_area": "",
        "author": "Vishnu D. Sharma;Maymoonah Toubeh;Lifeng Zhou;Pratap Tokekar;Vishnu D. Sharma;Maymoonah Toubeh;Lifeng Zhou;Pratap Tokekar",
        "authorids": "/37088689166;/37088687119;/37086092920;/37546532700;/37088689166;/37088687119;/37086092920;/37546532700",
        "aff": "Virginia Tech, University of Maryland, College Park, MD, USA; Department of Electrical & Computer Engineering, Virginia Tech, Blacksburg, VA, USA; Department of Electrical & Computer Engineering, Virginia Tech, Blacksburg, VA, USA; Virginia Tech, University of Maryland, College Park, MD, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341075/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14369751378180499936&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Virginia Tech",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.vt.edu",
        "aff_unique_abbr": "VT",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Blacksburg",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341469",
        "title": "Risk-Sensitive Sequential Action Control with Multi-Modal Human Trajectory Forecasting for Safe Crowd-Robot Interaction",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel online framework for safe crowd-robot interaction based on risk-sensitive stochastic optimal control, wherein the risk is modeled by the entropic risk measure. The sampling-based model predictive control relies on mode insertion gradient optimization for this risk measure as well as Trajectron++, a state-of-the-art generative model that produces multimodal probabilistic trajectory forecasts for multiple interacting agents. Our modular approach decouples the crowd-robot interaction into learning-based prediction and model-based control, which is advantageous compared to end-to-end policy learning methods in that it allows the robot's desired behavior to be specified at run time. In particular, we show that the robot exhibits diverse interaction behavior by varying the risk sensitivity parameter. A simulation study and a real-world experiment show that the proposed online framework can accomplish safe and efficient navigation while avoiding collisions with more than 50 humans in the scene.",
        "primary_area": "",
        "author": "Haruki Nishimura;Boris Ivanovic;Adrien Gaidon;Marco Pavone;Mac Schwager;Haruki Nishimura;Boris Ivanovic;Adrien Gaidon;Marco Pavone;Mac Schwager",
        "authorids": "/37086455819;/37086527859;/37945420900;/37307912900;/37424620600;/37086455819;/37086527859;/37945420900;/37307912900;/37424620600",
        "aff": "Department of Aeronautics and Astronautics, Stanford University, Stanford, CA, USA; Department of Aeronautics and Astronautics, Stanford University, Stanford, CA, USA; Toyota Research Institute, Los Altos, CA, USA; Department of Aeronautics and Astronautics, Stanford University, Stanford, CA, USA; Department of Aeronautics and Astronautics, Stanford University, Stanford, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341469/",
        "gs_citation": 49,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8158614140331079921&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "Stanford University;Toyota Research Institute",
        "aff_unique_dep": "Department of Aeronautics and Astronautics;",
        "aff_unique_url": "https://www.stanford.edu;https://www.tri.global",
        "aff_unique_abbr": "Stanford;TRI",
        "aff_campus_unique_index": "0;0;1;0;0",
        "aff_campus_unique": "Stanford;Los Altos",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340810",
        "title": "Risk-constrained Motion Planning for Robot Locomotion: Formulation and Running Robot Demonstration",
        "track": "main",
        "status": "Poster",
        "abstract": "Robots encounter many risks that threaten the success of practical locomotion tasks. Legs break, electrical components overheat, and feet can unexpectedly slip. When all risks cannot be completely avoided, how does a robot decide its best action? We present a method for planning robot motions by reasoning about risk-of-failure probabilities instead of applying cost-penalty functions or inflexible path constraints. This work develops a risk-constrained formulation that can be straightforwardly included in existing motion planning optimizations. The risk constraints scale tractably with many risk sources, and in some cases, only add linear constraints to the optimization problem and are therefore compatible with model-predictive control techniques. We present a toy \"Puck World\" proof-of-concept example and a practical implementation on a planar monopod robot that runs at 3.2 m/s when permitted to take high-risk maneuvers. We believe this risk approach can be used to optimize robot behaviors under numerous conflicting task pressures and model risk-conscious behaviors in animals.",
        "primary_area": "",
        "author": "Jacob Hackett;Wei Gao;Monica Daley;Jonathan Clark;Christian Hubicki;Jacob Hackett;Wei Gao;Monica Daley;Jonathan Clark;Christian Hubicki",
        "authorids": "/37088686594;/37088507050;/37085394138;/37533408500;/37085380316;/37088686594;/37088507050;/37085394138;/37533408500;/37085380316",
        "aff": "Department of Mechanical Engineering, FAMU-FSU College of Engineering, Florida State University, Tallahassee, FL, USA; Department of Mechanical Engineering, FAMU-FSU College of Engineering, Florida State University, Tallahassee, FL, USA; Ecology & Evolutionary Biology Department, University of California Irvine, Irvine, CA, USA; Department of Mechanical Engineering, FAMU-FSU College of Engineering, Florida State University, Tallahassee, FL, USA; Department of Mechanical Engineering, FAMU-FSU College of Engineering, Florida State University, Tallahassee, FL, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340810/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3340807734194553241&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "Florida State University;University of California, Irvine",
        "aff_unique_dep": "Department of Mechanical Engineering;Ecology & Evolutionary Biology Department",
        "aff_unique_url": "https://www.fsu.edu;https://www.uci.edu",
        "aff_unique_abbr": "FSU;UCI",
        "aff_campus_unique_index": "0;0;1;0;0",
        "aff_campus_unique": "Tallahassee;Irvine",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341431",
        "title": "Roadmap Subsampling for Changing Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Precomputed roadmaps can enable effective multi-query motion planning: a roadmap can be built for a robot as if no obstacles were present, and then after edges invalidated by obstacles observed at query time are deleted, path search through the remaining roadmap returns a collision-free plan. However, large roadmaps are memory intensive to store, and can be too slow for practical use. We present an algorithm for compressing a large roadmap so that the collision detection phase fits into a computational budget, while retaining a high probability of finding high-quality paths. Our algorithm adapts work from graph theory and data mining by treating roadmaps as unreliable networks, where the probability of edge failure models the probability of a query-time obstacle causing a collision. We experimentally evaluate the quality of the resulting roadmaps in a suite of four motion planning benchmarks.",
        "primary_area": "",
        "author": "Sean Murray;George D. Konidaris;Daniel J. Sorin;Sean Murray;George D. Konidaris;Daniel J. Sorin",
        "authorids": "/38666448100;/38318614200;/37275338200;/38666448100;/38318614200;/37275338200",
        "aff": "Realtime Robotics; Realtime Robotics; Realtime Robotics",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341431/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11678651232408738388&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Realtime Robotics",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.realtimerobotics.com",
        "aff_unique_abbr": "Realtime Robotics",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340712",
        "title": "Roboat II: A Novel Autonomous Surface Vessel for Urban Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel autonomous surface vessel (ASV), called Roboat II for urban transportation. Roboat II is capable of accurate simultaneous localization and mapping (SLAM), receding horizon tracking control and estimation, and path planning. Roboat II is designed to maximize the internal space for transport, and can carry payloads several times of its own weight. Moreover, it is capable of holonomic motions to facilitate transporting, docking, and inter-connectivity between boats. The proposed SLAM system receives sensor data from a 3D LiDAR, an IMU, and a GPS, and utilizes a factor graph to tackle the multi-sensor fusion problem. To cope with the complex dynamics in the water, Roboat II employs an online nonlinear model predictive controller (NMPC), where we experimentally estimated the dynamical model of the vessel in order to achieve superior performance for tracking control. The states of Roboat II are simultaneously estimated using a nonlinear moving horizon estimation (NMHE) algorithm. Experiments demonstrate that Roboat II is able to successfully perform online mapping and localization, plan its path and robustly track the planned trajectory in the confined river, implying that this autonomous vessel holds the promise on potential applications in transporting humans and goods in many of the waterways nowadays.",
        "primary_area": "",
        "author": "Wei Wang;Tixiao Shan;Pietro Leoni;David Fern\u00e1ndez-Guti\u00e9rrez;Drew Meyers;Carlo Ratti;Daniela Rus;Wei Wang;Tixiao Shan;Pietro Leoni;David Fern\u00e1ndez-Guti\u00e9rrez;Drew Meyers;Carlo Ratti;Daniela Rus",
        "authorids": "/37073346500;/37085681623;/37086455112;/37088686421;/37087090649;/37590016800;/37279652300;/37073346500;/37085681623;/37086455112;/37088686421;/37087090649;/37590016800;/37279652300",
        "aff": "Computer Science and Artificial Intelligence Lab (CSAIL), Massachusetts Institute of Technology, Cambridge, MA, USA; Computer Science and Artificial Intelligence Lab (CSAIL), Massachusetts Institute of Technology, Cambridge, MA, USA; SENSEable City Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA; SENSEable City Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA; SENSEable City Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA; SENSEable City Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA; Computer Science and Artificial Intelligence Lab (CSAIL), Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340712/",
        "gs_citation": 78,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18103794928717783890&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Lab (CSAIL)",
        "aff_unique_url": "https://www.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341787",
        "title": "Robot Calligraphy using Pseudospectral Optimal Control in Conjunction with a Novel Dynamic Brush Model",
        "track": "main",
        "status": "Poster",
        "abstract": "Chinese calligraphy is a unique art form with great artistic value but difficult to master. In this paper, we formulate the calligraphy writing problem as a trajectory optimization problem, and propose an improved virtual brush model for simulating the real writing process. Our approach is inspired by pseudospectral optimal control in that we parameterize the actuator trajectory for each stroke as a Chebyshev polynomial. The proposed dynamic virtual brush model plays a key role in formulating the objective function to be optimized. Our approach shows excellent performance in drawing aesthetically pleasing characters, and does so much more efficiently than previous work, opening up the possibility to achieve real-time closed-loop control.",
        "primary_area": "",
        "author": "Sen Wang;Jiaqi Chen;Xuanliang Deng;Seth Hutchinson;Frank Dellaert;Sen Wang;Jiaqi Chen;Xuanliang Deng;Seth Hutchinson;Frank Dellaert",
        "authorids": "/37090019268;/37088686444;/37088688439;/37282386200;/37282902200;/37090019268;/37088686444;/37088688439;/37282386200;/37282902200",
        "aff": "Georgia Institute of Technology, Atlanta, GA, USA; Georgia Institute of Technology, Atlanta, GA, USA; Georgia Institute of Technology, Atlanta, GA, USA; Georgia Institute of Technology, Atlanta, GA, USA; Georgia Institute of Technology, Atlanta, GA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341787/",
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13607467865269014075&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Georgia Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.gatech.edu",
        "aff_unique_abbr": "Georgia Tech",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Atlanta",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340818",
        "title": "Robot Learning from Demonstration with Tactile Signals for Geometry-Dependent Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "Deploying robot learning frameworks in unconstrained environments requires robustness and tractability. We must not only equip the robot with a sufficient range of sensing capabilities, but also provide training data in a sample-efficient manner. To this end, we identify and address a need specifically in robot learning from demonstration (LfD) literature to account for not only end-effector pose and wrench signals, but also tactile signals for contact. While traditional pose and wrench signals have proven to be sufficient for robots to learn basic position and force-control behaviors, they are inherently too constraining for the learning of general manipulation tasks. In particular, useful manipulation tasks often rely on the geometry of the contact interaction. To explore the value of geometry-based tactile signals, we utilize a LfD framework built upon hidden Markov models and Gaussian mixture regression, adapt it to our robotic system equipped with a soft tactile sensor, and validate its performance with an edge-following task and a manipulation task involving different object geometries.",
        "primary_area": "",
        "author": "Isabella Huang;Ruzena Bajcsy;Isabella Huang;Ruzena Bajcsy",
        "authorids": "/37086538069;/37298488400;/37086538069;/37298488400",
        "aff": "Department of Electrical Engineering and Computer Sciences, University of California, Berkeley, CA, USA; Department of Electrical Engineering and Computer Sciences, University of California, Berkeley, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340818/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14583326923968295940&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "Department of Electrical Engineering and Computer Sciences",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341753",
        "title": "Robot Learning in Mixed Adversarial and Collaborative Settings",
        "track": "main",
        "status": "Poster",
        "abstract": "Previous work has shown that interacting with a human adversary can significantly improve the efficiency of the learning process in robot grasping. However, people are not consistent in applying adversarial forces; instead they may alternate between acting antagonistically with the robot or helping the robot achieve its tasks. We propose a physical framework for robot learning in a mixed adversarial/collaborative setting, where a second agent may act as a collaborator or as an antagonist, unbeknownst to the robot. The framework leverages prior estimates of the reward function to infer whether the actions of the second agent are collaborative or adversarial. Integrating the inference in an adversarial learning algorithm can significantly improve the robustness of learned grasps in a manipulation task.",
        "primary_area": "",
        "author": "Seung Hee Yoon;Stefanos Nikolaidis;Seung Hee Yoon;Stefanos Nikolaidis",
        "authorids": "/37088688855;/37643766400;/37088688855;/37643766400",
        "aff": "Department of Computer Science, The University of Southern California, Los Angeles, CA; Department of Computer Science, The University of Southern California, Los Angeles, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341753/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17139354905462203208&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "The University of Southern California",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.usc.edu",
        "aff_unique_abbr": "USC",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341540",
        "title": "Robot Navigation in Crowded Environments Using Deep Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Mobile robots operating in public environments require the ability to navigate among humans and other obstacles in a socially compliant and safe manner. This work presents a combined imitation learning and deep reinforcement learning approach for motion planning in such crowded and cluttered environments. By separately processing information related to static and dynamic objects, we enable our network to learn motion patterns that are tailored to real-world environments. Our model is also designed such that it can handle usual cases in which robots can be equipped with sensor suites that only offer limited field of view. Our model outperforms current state-of-the-art approaches, which is shown in simulated environments containing human-like agents and static obstacles. Additionally, we demonstrate the real-time performance and applicability of our model by successfully navigating a robotic platform through real-world environments.",
        "primary_area": "",
        "author": "Lucia Liu;Daniel Dugas;Gianluca Cesari;Roland Siegwart;Renaud Dub\u00e9;Lucia Liu;Daniel Dugas;Gianluca Cesari;Roland Siegwart;Renaud Dub\u00e9",
        "authorids": "/37088687033;/37086030360;/37085709740;/37281398300;/37085782572;/37088687033;/37086030360;/37085709740;/37281398300;/37085782572",
        "aff": "Sevensense Robotics AG, Zurich, Switzerland; Autonomous Systems Lab, ETH Zurich, Zurich, Switzerland; Sevensense Robotics AG, Zurich, Switzerland; Autonomous Systems Lab, ETH Zurich, Zurich, Switzerland; Sevensense Robotics AG, Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341540/",
        "gs_citation": 142,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17562561755186332411&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;1;0",
        "aff_unique_norm": "Sevensense Robotics AG;ETH Zurich",
        "aff_unique_dep": ";Autonomous Systems Lab",
        "aff_unique_url": "https://www.sevensense.io;https://www.ethz.ch",
        "aff_unique_abbr": ";ETHZ",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Zurich",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9341196",
        "title": "Robot Sound Interpretation: Combining Sight and Sound in Learning-Based Control",
        "track": "main",
        "status": "Poster",
        "abstract": "We explore the interpretation of sound for robot decision making, inspired by human speech comprehension. While previous methods separate sound processing unit and robot controller, we propose an end-to-end deep neural network which directly interprets sound commands for visual-based decision making. The network is trained using reinforcement learning with auxiliary losses on the sight and sound networks. We demonstrate our approach on two robots, a TurtleBot3 and a Kuka-IIWA arm, which hear a command word, identify the associated target object, and perform precise control to reach the target. For both robots, we show the effectiveness of our network in generalization to sound types and robotic tasks empirically. We successfully transfer the policy learned in simulator to a real-world TurtleBot3.",
        "primary_area": "",
        "author": "Peixin Chang;Shuijing Liu;Haonan Chen;Katherine Driggs-Campbell;Peixin Chang;Shuijing Liu;Haonan Chen;Katherine Driggs-Campbell",
        "authorids": "/37088688639;/37088687174;/37088504797;/37085509519;/37088688639;/37088687174;/37088504797;/37085509519",
        "aff": "Department of Electrical and Computer Engineering, University of Illinois, Urbana-Champaign; Department of Electrical and Computer Engineering, University of Illinois, Urbana-Champaign; Computer Engineering Department, Urbana-Champaign Institute, Zhejiang University-University of Illinois; Department of Electrical and Computer Engineering, University of Illinois, Urbana-Champaign",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341196/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=307503507754836235&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "University of Illinois, Urbana-Champaign;Zhejiang University-University of Illinois",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Computer Engineering Department",
        "aff_unique_url": "https://illinois.edu;https://www.illinois.edu",
        "aff_unique_abbr": "UIUC;UIUC",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Urbana-Champaign",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "9341695",
        "title": "Robot-assisted ultrasound-guided biopsy on MR-detected breast lesions",
        "track": "main",
        "status": "Poster",
        "abstract": "One out of eight women will get breast cancer during their lifetime. A biopsy, a procedure in which a tissue sample is acquired from the lesion, is required to confirm the diagnosis. A biopsy is preferably executed under ultrasound (US) guidance because it is simple, fast, and cheap, gives real-time image feedback and causes little patient discomfort. However, Magnetic Resonance (MR)-detected lesions may be barely or not visible on US and difficult to find due to deformations of the breast. This paper presents a robotic setup and workflow that assists the radiologist in targeting MR-detected breast lesions under US guidance, taking into account deformations and giving the radiologist robotic accuracy. The setup consists of a seven degree-of-freedom robotic serial manipulator equipped with an end-effector carrying a US transducer and a three degree-of-freedom actuated needle guide. During probe positioning, the US probe is positioned on the patient's skin while the system tracks skin contact and tissue deformation. During the intervention phase, the radiologist inserts the needle through the actuated guide. During insertion, the tissue deformation is tracked and the needle path is adjusted accordingly. The workflow is demonstrated on a breast phantom. It is shown that lesions with a radius down to 2.9 mm can be targeted. While MRI is becoming more important in breast cancer detection, the presented robot-assisted approach helps the radiologist to effectively and accurately confirm the diagnosis utilizing the preferred US-guided method.",
        "primary_area": "",
        "author": "M.K. Welleweerd;D. Pantelis;A.G. de Groot;F.J. Siepel;S. Stramigioli;M.K. Welleweerd;D. Pantelis;A.G. de Groot;F.J. Siepel;S. Stramigioli",
        "authorids": "/37088505531;/37088686626;/37088507529;/37085997643;/37282439300;/37088505531;/37088686626;/37088507529;/37085997643;/37282439300",
        "aff": "Robotics and Mechatronics group, University of Twente, The Netherlands; Robotics and Mechatronics group, University of Twente, The Netherlands; Robotics and Mechatronics group, University of Twente, The Netherlands; Robotics and Mechatronics group, University of Twente, The Netherlands; Bio-mechatronics and Energy-Efficient Robotics group, ITMO University, St. Petersburg, The Russian Federation",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341695/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15714444518033086243&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "University of Twente;ITMO University",
        "aff_unique_dep": "Robotics and Mechatronics group;Bio-mechatronics and Energy-Efficient Robotics group",
        "aff_unique_url": "https://www.utwente.nl;https://www.itmo.ru",
        "aff_unique_abbr": ";ITMO",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";St. Petersburg",
        "aff_country_unique_index": "0;0;0;0;1",
        "aff_country_unique": "Netherlands;Russia"
    },
    {
        "id": "9341568",
        "title": "Robot-to-Robot Relative Pose Estimation based on Semidefinite Relaxation Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, the 2D robot-to-robot relative pose (position and orientation) estimation problem based on ego-motion and noisy distance measurements is considered. We address this problem using an optimization-based method, which does not require complicated numerical analysis while yields no inferior relative localization (RL) results compared to existing approaches. In particular, we start from a state-of-the-art method named square distances weighted least square (SD-WLS), and reformulate it as a non-convex quadratically constrained quadratic programming (QCQP) problem. To handle its non-convex nature, a semidefinite programming (SDP) relaxation optimization-based method is proposed, and we prove that the relaxation is tight when measurements are free from noise or just corrupted by small noise. Further, to obtain the optimal solution of the relative pose estimation problem in the sense of maximum likelihood estimation (MLE), a theoretically optimal WLS method is developed to refine the estimate from the SDP optimization. Comprehensive simulations and well-designed experiments are presented for validating the tightness of the SDP relaxation, and the effectiveness of the proposed algorithm is highlighted by comparing it to the existing approaches.",
        "primary_area": "",
        "author": "Ming Li;Guanqi Liang;Haobo Luo;Huihuan Qian;Tin Lun Lam;Ming Li;Guanqi Liang;Haobo Luo;Huihuan Qian;Tin Lun Lam",
        "authorids": "/37089459196;/37088687610;/37088686275;/37549401900;/37571111600;/37089459196;/37088687610;/37088686275;/37549401900;/37571111600",
        "aff": "Shenzhen Institute of Artificial Intelligence and Robotics for Society; Shenzhen Institute of Artificial Intelligence and Robotics for Society; Shenzhen Institute of Artificial Intelligence and Robotics for Society; Shenzhen Institute of Artificial Intelligence and Robotics for Society; Shenzhen Institute of Artificial Intelligence and Robotics for Society",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341568/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11409055254047875955&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Shenzhen Institute of Artificial Intelligence and Robotics for Society",
        "aff_unique_dep": "",
        "aff_unique_url": "http://www.siarfs.org/",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9341186",
        "title": "RobotVQA \u2014 A Scene-Graph- and Deep-Learning-based Visual Question Answering System for Robot Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual robot perception has been challenging to successful robot manipulation in noisy, cluttered and dynamic environments. While some perception systems fail to provide an adequate semantics of the scene, others fail to present appropriate learning models and training data. Another major issue encountered in some robot perception systems is their inability to promptly respond to robot control programs whose realtimeness is crucial.This paper proposes an architecture to robot vision for manipulation tasks that addresses the three issues mentioned above. The architecture encompasses a generator of training datasets and a learnable scene describer, coined as RobotVQA for Robot Visual Question Answering. The architecture leverages the power of deep learning to predict and photo-realistic virtual worlds to train. RobotVQA takes as input a robot scene's RGB or RGBD image, detects all relevant objects in it, then describes in realtime each object in terms of category, color, material, shape, openability, 6D-pose and segmentation mask. Moreover, RobotVQA computes the qualitative spatial relations among those objects. We refer to such a scene description in this paper as scene graph or semantic graph of the scene. In RobotVQA, prediction and training take place in a unified manner. Finally, we demonstrate how RobotVQA is suitable for robot control systems that interpret perception as a question answering process.",
        "primary_area": "",
        "author": "Franklin Kenghagho Kenfack;Feroz Ahmed Siddiky;Ferenc Balint-Benczedi;Michael Beetz;Franklin Kenghagho Kenfack;Feroz Ahmed Siddiky;Ferenc Balint-Benczedi;Michael Beetz",
        "authorids": "/37088686607;/37088689711;/37077499000;/37279125900;/37088686607;/37088689711;/37077499000;/37279125900",
        "aff": "Institute for Artificial Intelligence (IAI), University of Bremen; Institute for Artificial Intelligence (IAI), University of Bremen; Institute for Artificial Intelligence (IAI), University of Bremen; Institute for Artificial Intelligence (IAI), University of Bremen",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341186/",
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12266686136071505218&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Bremen",
        "aff_unique_dep": "Institute for Artificial Intelligence (IAI)",
        "aff_unique_url": "https://www.uni-bremen.de",
        "aff_unique_abbr": "Uni Bremen",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Bremen",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9341704",
        "title": "Robotic Micromanipulation of Biological Cells with Friction Force-Based Rotation Control",
        "track": "main",
        "status": "Poster",
        "abstract": "Cell manipulation is a critical procedure in related biological applications such as embryo biopsy and intracytoplasmic sperm injection (ICSI), where the biological cell is required to be oriented to the desired position. To bridge the gap between the techniques and the clinical applications, a robotic micromanipulation method, which utilizes friction forces to rotate the cell with standard micropipettes, is presented in this paper. Force models for both in-plane and out-of-plane rotations are well established and analyzed for the rotation control. For better controllability, calibration steps are also designed for adjusting the orientation of the micropipette with a more efficient way. A cell orientation recognition algorithm based on the superpixel segmentation and spectral clustering is reported and achieved high validation accuracy (96%) for estimating the orientation of the oocyte. The extracted visual information further facilitates the feedback control of cell rotation. Experimental results show that the overall success rate for the cell rotation control was about 95% with orientation precision of \u00b11\u00b0.",
        "primary_area": "",
        "author": "Shuai Cui;Wei Tech Ang;Shuai Cui;Wei Tech Ang",
        "authorids": "/37088691050;/37299508300;/37088691050;/37299508300",
        "aff": "School of Mechanical and Aerospace Engineering, Nanyang Technological University, Singapore; School of Mechanical and Aerospace Engineering, Nanyang Technological University, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341704/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5960592608513800096&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Nanyang Technological University",
        "aff_unique_dep": "School of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.ntu.edu.sg",
        "aff_unique_abbr": "NTU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Singapore",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "9341191",
        "title": "Robotic Table Tennis with Model-Free Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a model-free algorithm for learning efficient policies capable of returning table tennis balls by controlling robot joints at a rate of 100Hz. We demonstrate that evolutionary search (ES) methods acting on CNN-based policy architectures for non-visual inputs and convolving across time learn compact controllers leading to smooth motions. Furthermore, we show that with appropriately tuned curriculum learning on the task and rewards, policies are capable of developing multi-modal styles, specifically forehand and backhand stroke, whilst achieving 80% return rate on a wide range of ball throws. We observe that multi-modality does not require any architectural priors, such as multi-head architectures or hierarchical policies.",
        "primary_area": "",
        "author": "Wenbo Gao;Laura Graesser;Krzysztof Choromanski;Xingyou Song;Nevena Lazic;Pannag Sanketi;Vikas Sindhwani;Navdeep Jaitly;Wenbo Gao;Laura Graesser;Krzysztof Choromanski;Xingyou Song;Nevena Lazic;Pannag Sanketi;Vikas Sindhwani;Navdeep Jaitly",
        "authorids": "/37088686507;/37088691251;/37086453239;/37088688873;/37088691422;/37846225900;/37282057000;/37673125600;/37088686507;/37088691251;/37086453239;/37088688873;/37088691422;/37846225900;/37282057000;/37673125600",
        "aff": "Columbia University. Work done during Google internship; Robotics at Google; Robotics at Google; Robotics at Google; DeepMind; Robotics at Google; Robotics at Google; Work done at Google",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341191/",
        "gs_citation": 44,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8852720017344208636&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;1;1;2;1;1;1",
        "aff_unique_norm": "Columbia University;Google;DeepMind",
        "aff_unique_dep": ";Robotics;",
        "aff_unique_url": "https://www.columbia.edu;https://www.google.com;https://deepmind.com",
        "aff_unique_abbr": "Columbia;Google Robotics;DeepMind",
        "aff_campus_unique_index": "1;1;1;1;1;1",
        "aff_campus_unique": ";Mountain View",
        "aff_country_unique_index": "0;0;0;0;1;0;0;0",
        "aff_country_unique": "United States;United Kingdom"
    },
    {
        "id": "9340917",
        "title": "Robotic Understanding of Spatial Relationships Using Neural-Logic Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Understanding spatial relations of objects is critical in many robotic applications such as grasping, manipulation, and obstacle avoidance. Humans can simply reason object's spatial relations from a glimpse of a scene based on prior knowledge of spatial constraints. The proposed method enables a robot to comprehend spatial relationships among objects from RGB-D data. This paper proposed a neural-logic learning framework to learn and reason spatial relations from raw data by following logic rules on spatial constraints. The neural-logic network consists of three blocks: grounding block, spatial logic block, and inference block. The grounding block extracts high-level features from the raw sensory data. The spatial logic blocks can predicate fundamental spatial relations by training a neural network with spatial constraints. The inference block can infer complex spatial relations based on the predicated fundamental spatial relations. Simulations and robotic experiments evaluated the performance of the proposed method.",
        "primary_area": "",
        "author": "Fujian Yan;Dali Wang;Hongsheng He;Fujian Yan;Dali Wang;Hongsheng He",
        "authorids": "/37087244707;/37598466400;/37085561124;/37087244707;/37598466400;/37085561124",
        "aff": "Department of Electrical Engineer and Computer Science, Wichita State University, Wichita, KS, USA; Senior R&D Staff and a member of the Artificial Intelligence (AI) team, Oak Ridge National Laboratory (ORNL); Department of Electrical Engineer and Computer Science, Wichita State University, Wichita, KS, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340917/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10908951647337754454&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Wichita State University;Oak Ridge National Laboratory",
        "aff_unique_dep": "Department of Electrical Engineer and Computer Science;Artificial Intelligence (AI) team",
        "aff_unique_url": "https://www.wichita.edu;https://www.ornl.gov",
        "aff_unique_abbr": "WSU;ORNL",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Wichita;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9342536",
        "title": "Robotic Untangling of Herbs and Salads with Parallel Grippers",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic packaging of fresh leafy produce such as herbs and salads generally involves picking out a target mass from a pile or crate of plant material. Typically, for low-complexity parallel grippers, the weight picked can be controlled by varying the opening aperture. However, often individual strands of plant material get entangled with each other, causing more to be picked out than desired. This paper presents a simple spread-and-pick approach that significantly reduces the degree of entanglement in a herb pile when picking. Compared to the traditional approach of picking from an entanglement-free point in the pile, the proposed approach results in a decrease of up to 29.06% of the variance in for separate homogeneous piles of fresh herbs. Moreover, it shows good generalisation with up to 55.53% decrease in picked weight variance for herbs previously unseen by the system.",
        "primary_area": "",
        "author": "Prabhakar Ray;Matthew J. Howard;Prabhakar Ray;Matthew J. Howard",
        "authorids": "/37086170118;/37301483600;/37086170118;/37301483600",
        "aff": "Department of Engineering, Centre for Robotics Research, King\u2019s College London, London, UK; Department of Engineering, Centre for Robotics Research, King\u2019s College London, London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9342536/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5715796493869118885&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "King\u2019s College London",
        "aff_unique_dep": "Department of Engineering, Centre for Robotics Research",
        "aff_unique_url": "https://www.kcl.ac.uk",
        "aff_unique_abbr": "KCL",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9340855",
        "title": "Robots Made From Ice: An Analysis of Manufacturing Techniques",
        "track": "main",
        "status": "Poster",
        "abstract": "Modular robotic systems with self-repair or self-replication capabilities have been presented as a robust, low cost solution to extraterrestrial or Arctic exploration. This paper explores using ice as the sole structure element to build robots. The ice allows for increased flexibility in the system design, enabling the robotic structure to be designed and built post deployment, after tasks and terrain obstacles have been better identified and analyzed. However, ice presents many difficulties in manufacturing. The authors explore a structure driven approach to examine compatible manufacturing processes with an emphasis on conserving process energies. The energy analysis shows the optimal manufacturing technique depends on the volume of the final part relative to the volume of material that must be removed. Based on experiments three general design principles are presented. A mobile robotic platform made from ice is presented as a proof of concept and first demonstration.",
        "primary_area": "",
        "author": "Devin Carroll;Mark Yim;Devin Carroll;Mark Yim",
        "authorids": "/37086283061;/37274063600;/37086283061;/37274063600",
        "aff": "GRASP lab, University of Pennsylvania, Philadelphia, PA; GRASP lab, University of Pennsylvania, Philadelphia, PA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340855/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15124352838234092755&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Pennsylvania",
        "aff_unique_dep": "GRASP lab",
        "aff_unique_url": "https://www.upenn.edu",
        "aff_unique_abbr": "UPenn",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Philadelphia",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341748",
        "title": "Robots Versus Speakers: What Type of Central Smart Home Interface Consumers Prefer?",
        "track": "main",
        "status": "Poster",
        "abstract": "In smart home environments, central interfaces that take commands from users and give orders to each relevant device appropriately are increasingly important. We investigated the type of central interface that consumers are more willing to adopt and whether these interfaces enhance the evaluation of services provided by smart home devices. This study confirms that speaker interfaces are preferred over social robots, speaker interfaces are perceived by users as more persuasive, and the adoption of central interfaces increases the overall service evaluation.",
        "primary_area": "",
        "author": "Sonya S. Kwak;Jun San Kim;Byeong June Moon;Dahyun Kang;JongSuk Choi;Sonya S. Kwak;Jun San Kim;Byeong June Moon;Dahyun Kang;JongSuk Choi",
        "authorids": "/37398989100;/37088688488;/37088528280;/37088529158;/37292544300;/37398989100;/37088688488;/37088528280;/37088529158;/37292544300",
        "aff": "Center for Intelligent and Interactive Robotics, Korea Institute of Science and Technology, Seoul, Korea; KB Research, KB Financial Group Inc., Seoul, Korea; Department of Sociology, Seoul National University, Seoul, Korea; Center for Intelligent and Interactive Robotics, Korea Institute of Science and Technology, Seoul, Korea; Center for Intelligent and Interactive Robotics, Korea Institute of Science and Technology, Seoul, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341748/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1054643719467413448&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;0;0",
        "aff_unique_norm": "Korea Institute of Science and Technology;KB Financial Group Inc.;Seoul National University",
        "aff_unique_dep": "Center for Intelligent and Interactive Robotics;KB Research;Department of Sociology",
        "aff_unique_url": "https://www.kist.re.kr;https://www.kbfg.com;https://www.snu.ac.kr",
        "aff_unique_abbr": "KIST;KBFG;SNU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Seoul;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9341226",
        "title": "Robots can defuse high-intensity conflict situations",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper investigates the specific scenario of high-intensity confrontations between humans and robots, to understand how robots can defuse the conflict. It focuses on the effectiveness of using five different affective expression modalities as main drivers for defusing the conflict. The aim is to discover any strengths or weaknesses in using each modality to mitigate the hostility that people feel towards a poorly performing robot. The defusing of the situation is accomplished by making the robot better at acknowledging the conflict and by letting it express remorse. To facilitate the tests, we used a custom affective robot in a simulated conflict situation with 105 test participants. The results show that all tested expression modalities can successfully be used to defuse the situation and convey an acknowledgment of the confrontation. The ratings were remarkably similar, but the movement modality was different (ANON p<; .05) than the other modalities. The test participants also had similar affective interpretations on how impacted the robot was of the confrontation across all expression modalities. This indicates that defusing a high-intensity interaction may not demand special attention to the expression abilities of the robot, but rather require attention to the abilities of being socially aware of the situation and reacting in accordance with it.",
        "primary_area": "",
        "author": "Morten Roed Frederiksen;Kasper Stoy;Morten Roed Frederiksen;Kasper Stoy",
        "authorids": "/37088689257;/37333021600;/37088689257;/37333021600",
        "aff": "REAL lab at the Computer science department, The IT-University of Copenhagen, Copenhagen S; REAL lab at the Computer science department, The IT-University of Copenhagen, Copenhagen S",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341226/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18247599298095474029&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "The IT-University of Copenhagen",
        "aff_unique_dep": "Computer Science Department",
        "aff_unique_url": "https://itu.dk",
        "aff_unique_abbr": "ITU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Copenhagen",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Denmark"
    },
    {
        "id": "9340701",
        "title": "Robust Autonomous Navigation of a Small-Scale Quadruped Robot in Real-World Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Animal-level agility and robustness in robots cannot be accomplished by solely relying on blind locomotion controllers. A significant portion of a robot\u2019s ability to traverse terrain comes from reacting to the external world through visual sensing. However, embedding the sensors and compute that provide sufficient accuracy at high speeds is challenging, especially if the robot has significant space limitations. In this paper, we propose a system integration of a small-scale quadruped robot, the MIT Mini-Cheetah Vision, that exteroceptively senses the terrain and dynamically explores the world around it at high velocities. Through extensive hardware and software development, we demonstrate a fully untethered robot with all hardware onboard running a locomotion controller that combines state-of-the-art Regularized Predictive Control (RPC) with Whole-Body Impulse Control (WBIC). We devise a hierarchical state estimator that integrates kinematic, IMU, and localization sensor data to provide state estimates specific to path planning and locomotion tasks. Our integrated system has demonstrated robust autonomous waypoint tracking in dynamic real-world environments at speeds of over 1 m/s with high rates of success.",
        "primary_area": "",
        "author": "Thomas Dudzik;Matthew Chignoli;Gerardo Bledt;Bryan Lim;Adam Miller;Donghyun Kim;Sangbae Kim;Thomas Dudzik;Matthew Chignoli;Gerardo Bledt;Bryan Lim;Adam Miller;Donghyun Kim;Sangbae Kim",
        "authorids": "/37088690564;/37088344884;/37086288149;/37088504437;/37088688305;/37085554176;/37537397200;/37088690564;/37088344884;/37086288149;/37088504437;/37088688305;/37085554176;/37537397200",
        "aff": "Department of Electrical Engineering & Computer Science, MIT, Cambridge, MA, USA; Department of Mechanical Engineering, MIT, Cambridge, MA, USA; Department of Mechanical Engineering, MIT, Cambridge, MA, USA; Department of Mechanical Engineering, MIT, Cambridge, MA, USA; Department of Electrical Engineering & Computer Science, MIT, Cambridge, MA, USA; Department of Mechanical Engineering, MIT, Cambridge, MA, USA; Department of Mechanical Engineering, MIT, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340701/",
        "gs_citation": 45,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11099314368443129217&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Department of Electrical Engineering & Computer Science",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341348",
        "title": "Robust Control Synthesis and Verification for Wire-Borne Underactuated Brachiating Robots Using Sum-of-Squares Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "Control of wire-borne underactuated brachiating robots requires a robust feedback control design that can deal with dynamic uncertainties, actuator constraints and unmeasurable states. In this paper, we develop a robust feedback control for brachiating on flexible cables, building on previous work on optimal trajectory generation and time-varying LQR controller design. We propose a novel simplified model for approximation of the flexible cable dynamics, which enables inclusion of parametric model uncertainties in the system. We then use semidefinite programming (SDP) and sum-of-squares (SOS) optimization to synthesize a time-varying feedback control with formal robustness guarantees to account for model uncertainties and unmeasurable states in the system. Through simulation, hardware experiments and comparison with a time-varying LQR controller, it is shown that the proposed robust controller results in relatively large robust backward reachable sets and is able to reliably track a pre-generated optimal trajectory and achieve the desired brachiating motion in the presence of parametric model uncertainties, actuator limits, and unobservable states.",
        "primary_area": "",
        "author": "Siavash Farzan;Ai-Ping Hu;Michael Bick;Jonathan Rogers;Siavash Farzan;Ai-Ping Hu;Michael Bick;Jonathan Rogers",
        "authorids": "/37085533250;/37073227200;/37088686819;/37085897392;/37085533250;/37073227200;/37088686819;/37085897392",
        "aff": "Institute for Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA, USA; Georgia Tech Research Institute, Atlanta, GA, USA; Woodruff School of Mechanical Engineering, Georgia Institute of Technology, Atlanta, GA, USA; Guggenheim School of Aerospace Engineering, Georgia Institute of Technology, Atlanta, GA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341348/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6859820130243872903&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Georgia Institute of Technology;Georgia Tech Research Institute",
        "aff_unique_dep": "Institute for Robotics and Intelligent Machines;",
        "aff_unique_url": "https://www.gatech.edu;https://www.gtri.gatech.edu",
        "aff_unique_abbr": "Georgia Tech;GTRI",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Atlanta",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341489",
        "title": "Robust Dynamic State Estimation for Lateral Control of an Industrial Tractor Towing Multiple Passive Trailers",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a dynamic state estimation framework for lateral control of a heavy tractor-trailers system using only mass-produced low-cost sensors. This issue is challenging since the lateral velocity of the lead tractor is difficult to measure directly. The performance of existing dynamic model-based estimation methods will also be degraded, as different trailers and payloads cause the tractor model parameters to change. We address this issue by incorporating a kinematic estimator into a dynamic model-based estimation scheme. Accurate and reliable tire cornering stiffness and dynamics-informed lateral velocity of the lead tractor can be output in real-time by using our method. The stability and robustness of the proposed method are theoretically proved. The feasibility of our method is verified by full-scale experiments. It is also verified that the estimated model parameters and lateral states do improve the control performance by integrating the estimator into a lateral control system.",
        "primary_area": "",
        "author": "Shunbo Zhou;Hongchao Zhao;Wen Chen;Zhe Liu;Hesheng Wang;Yun-Hui Liu;Shunbo Zhou;Hongchao Zhao;Wen Chen;Zhe Liu;Hesheng Wang;Yun-Hui Liu",
        "authorids": "/37086345412;/37086346685;/37087239966;/38505849700;/37292567100;/37279412600;/37086345412;/37086346685;/37087239966;/38505849700;/37292567100;/37279412600",
        "aff": "Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, HKSAR; Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, HKSAR; Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, HKSAR; Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, HKSAR; Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, HKSAR; Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, HKSAR",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341489/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:fNmdM_ndKQsJ:scholar.google.com/&scioq=Robust+Dynamic+State+Estimation+for+Lateral+Control+of+an+Industrial+Tractor+Towing+Multiple+Passive+Trailers&hl=en&as_sdt=0,33",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "The Chinese University of Hong Kong",
        "aff_unique_dep": "Department of Mechanical and Automation Engineering",
        "aff_unique_url": "https://www.cuhk.edu.hk",
        "aff_unique_abbr": "CUHK",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9341552",
        "title": "Robust Ego and Object 6-DoF Motion Estimation and Tracking",
        "track": "main",
        "status": "Poster",
        "abstract": "The problem of tracking self-motion as well as motion of objects in the scene using information from a camera is known as multi-body visual odometry and is a challenging task. This paper proposes a robust solution to achieve accurate estimation and consistent track-ability for dynamic multi-body visual odometry. A compact and effective framework is proposed leveraging recent advances in semantic instance-level segmentation and accurate optical flow estimation. A novel formulation, jointly optimizing SE(3) motion and optical flow is introduced that improves the quality of the tracked points and the motion estimation accuracy. The proposed approach is evaluated on the virtual KITTI Dataset and tested on the real KITTI Dataset, demonstrating its applicability to autonomous driving applications. For the benefit of the community, we make the source code public\u2020.",
        "primary_area": "",
        "author": "Jun Zhang;Mina Henein;Robert Mahony;Viorela Ila;Jun Zhang;Mina Henein;Robert Mahony;Viorela Ila",
        "authorids": "/37088504580;/37086330243;/37283743600;/37269313000;/37088504580;/37086330243;/37283743600;/37269313000",
        "aff": "Australian National University (ANU), Canberra, Australia; Australian National University (ANU), Canberra, Australia; Australian National University (ANU), Canberra, Australia; Australian National University (ANU), Canberra, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341552/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9408651849741282659&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Australian National University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.anu.edu.au",
        "aff_unique_abbr": "ANU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Canberra",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "9340717",
        "title": "Robust Force Tracking Impedance Control of an Ultrasonic Motor-actuated End-effector in a Soft Environment",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic systems are increasingly required not only to generate precise motions to complete their tasks but also to handle the interactions with the environment or human. Significantly, soft interaction brings great challenges on the force control due to the nonlinear, viscoelastic and inhomogeneous properties of the soft environment. In this paper, a robust impedance control scheme utilizing integral backstepping technology and integral terminal sliding mode control is proposed to achieve force tracking for an ultrasonic motor-actuated end-effector in a soft environment. In particular, the steady-state performance of the target impedance while in contact with soft environment is derived and analyzed with the nonlinear Hunt-Crossley model. Finally, the dynamic force tracking performance of the proposed control scheme is verified via several experiments.",
        "primary_area": "",
        "author": "Wenyu Liang;Zhao Feng;Yan Wu;Junli Gao;Qinyuan Ren;Tong Heng Lee;Wenyu Liang;Zhao Feng;Yan Wu;Junli Gao;Qinyuan Ren;Tong Heng Lee",
        "authorids": "/37598507800;/37085834799;/37085344977;/37088686660;/38264350700;/37277268600;/37598507800;/37085834799;/37085344977;/37088686660;/38264350700;/37277268600",
        "aff": "Agency for Science, Technology and Research (A*STAR), Institute for Infocomm Research (I2R), Singapore; Department of Electrical and Computer Engineering, National University of Singapore (NUS), Singapore; Agency for Science, Technology and Research (A*STAR), Institute for Infocomm Research (I2R), Singapore; School of Automation, Guangdong University of Technology, Guangzhou, China; College of Control Science and Engineering, Zhejiang University, Hangzhou, China; Department of Electrical and Computer Engineering, National University of Singapore (NUS), Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340717/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11666917453996663338&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;2;3;1",
        "aff_unique_norm": "Agency for Science, Technology and Research;National University of Singapore;Guangdong University of Technology;Zhejiang University",
        "aff_unique_dep": "Institute for Infocomm Research;Department of Electrical and Computer Engineering;School of Automation;College of Control Science and Engineering",
        "aff_unique_url": "https://www.a-star.edu.sg;https://www.nus.edu.sg;;http://www.zju.edu.cn",
        "aff_unique_abbr": "A*STAR;NUS;;ZJU",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";Guangzhou;Hangzhou",
        "aff_country_unique_index": "0;0;0;1;1;0",
        "aff_country_unique": "Singapore;China"
    },
    {
        "id": "9341356",
        "title": "Robust Gait Design Insights from Studying a Compass Gait Biped with Foot Slipping",
        "track": "main",
        "status": "Poster",
        "abstract": "Most current bipedal robots were modeled with an assumption that there is no slip between the stance foot and ground. This paper relaxes that assumption and undertakes a comprehensive study of a compass gait biped with foot slipping. It is found that slips are most likely to happen near impact for a broad range of gaits. Among these gaits, ones with a backward swing foot velocity relative to the ground just before touch down generally require less friction to maintain stable walking than ones with a forward relative foot velocity. Moreover, a larger percentage of gaits with the \"swinging backward\" foot can tolerate some slipping without falling than those with a swinging forward foot at touch down. Thus, a gait with the swing-backward foot just before touch down should be more robust in the sense of preventing slipping and falling. It is further shown that only one parameter in gait design determines the swing-backward feature, which can help design robust gaits. Models with varying physical parameters such as mass, leg length, and position of center of mass (CoM), are also studied to validate the generality of the results.",
        "primary_area": "",
        "author": "Tan Chen;Bill Goodwine;Tan Chen;Bill Goodwine",
        "authorids": "/37086128468;/37324652900;/37086128468;/37324652900",
        "aff": "Department of Aerospace & Mechanical Engineering, University of Notre Dame, Notre Dame, IN, USA; Department of Aerospace & Mechanical Engineering, University of Notre Dame, Notre Dame, IN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341356/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11677540803143228172&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Notre Dame",
        "aff_unique_dep": "Department of Aerospace & Mechanical Engineering",
        "aff_unique_url": "https://www.nd.edu",
        "aff_unique_abbr": "Notre Dame",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Notre Dame",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341146",
        "title": "Robust Gait Synthesis Combining Constrained Optimization and Imitation Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Despite plenty of motion planning strategies have been proposed for bipedal locomotion, enhancing the walking robustness in real-world environments is still an open question. This paper focuses on robust body and leg trajectories synthesis through integrating constrained optimization with imitation learning. Specifically, we first propose a Quadratically Constrained Quadratic Programming (QCQP) algorithm to make use of the ankle strategy and stepping strategy. Based on the Linear Inverted Pendulum (LIP) model, body motion can be determined by the modulated Center of Pressure (CoP) position and step parameters (including step location and step duration). After that, we exploit an imitation learning approach Kernelized Movement Primitives (KMP) to plan robot leg motions, which allows for adapting the learned motion patterns to new situations (e.g., passing through various desired points) in a straightforward manner. Several LIP simulations and whole-body dynamic simulations demonstrate that higher walking robustness can be achieved using our framework.",
        "primary_area": "",
        "author": "Jiatao Ding;Xiaohui Xiao;Nikos Tsagarakis;Yanlong Huang;Jiatao Ding;Xiaohui Xiao;Nikos Tsagarakis;Yanlong Huang",
        "authorids": "/37086353143;/37530896000;/37295830800;/37086454561;/37086353143;/37530896000;/37295830800;/37086454561",
        "aff": "Humanoid and Human Centered Mechatronics Research Line, Istituto Italiano di Tecnologia, Genova, Italy; School of Power and Mechanical Engineering, Wuhan University, Wuhan, P. R. China; Humanoid and Human Centered Mechatronics Research Line, Istituto Italiano di Tecnologia, Genova, Italy; School of Computing, University of Leeds, Leeds, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341146/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7109640855531590275&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;2",
        "aff_unique_norm": "Istituto Italiano di Tecnologia;Wuhan University;University of Leeds",
        "aff_unique_dep": "Humanoid and Human Centered Mechatronics Research Line;School of Power and Mechanical Engineering;School of Computing",
        "aff_unique_url": "https://www.iit.it;http://www.whu.edu.cn/;https://www.leeds.ac.uk",
        "aff_unique_abbr": "IIT;WHU;Leeds",
        "aff_campus_unique_index": "0;1;0;2",
        "aff_campus_unique": "Genova;Wuhan;Leeds",
        "aff_country_unique_index": "0;1;0;2",
        "aff_country_unique": "Italy;China;United Kingdom"
    },
    {
        "id": "9341220",
        "title": "Robust Internal Model Control for Motor Systems Based on Sliding Mode Technique and Extended State Observer",
        "track": "main",
        "status": "Poster",
        "abstract": "Electric motors have been widely used as the actuators of robot and automation systems. This paper aims at achieving the high-precision position control of motor drive systems. For this purpose, a robust control scheme is presented by combining the internal model principle, the sliding mode technique and the extended state observer (ESO). The PID-type controller is firstly designed by using the internal model control (IMC) rules. Since the analysis of the IMC system is performed via a sliding surface, a robust sliding mode control (SMC) law is then synthesized to enhance the control ability of the system to uncertainties. However, this robust solution should make a trade-off between the chattering attenuation and the control accuracy. To handle this drawback, a linear ESO is employed to compensate the modeling errors for a higher control accuracy. The stability analysis is provided via a Lyapunov-based method, and the superiority of the proposed approach was validated by comparative experiments on a motor drive platform.",
        "primary_area": "",
        "author": "Ping Li;Kaiqi Guo;Chenyang Sun;Mingming Zhang;Ping Li;Kaiqi Guo;Chenyang Sun;Mingming Zhang",
        "authorids": "/37089610454;/37087031707;/37088686499;/37085459780;/37089610454;/37087031707;/37088686499;/37085459780",
        "aff": "Department of Biomedical Engineering, Southern University of Science and Technology, Shenzhen, Guangdong, China; Department of Biomedical Engineering, Southern University of Science and Technology, Shenzhen, Guangdong, China; Department of Biomedical Engineering, Southern University of Science and Technology, Shenzhen, Guangdong, China; Department of Biomedical Engineering, Southern University of Science and Technology, Shenzhen, Guangdong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341220/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18003513607309220861&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Southern University of Science and Technology",
        "aff_unique_dep": "Department of Biomedical Engineering",
        "aff_unique_url": "https://www.sustech.edu.cn",
        "aff_unique_abbr": "SUSTech",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Shenzhen",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9340826",
        "title": "Robust MUSIC-Based Sound Source Localization in Reverberant and Echoic Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Intuitive human robot interfaces like speech or gesture recognition are essential for gaining acceptance for robots in daily life. However, such interaction requires that the robot detects the human's intention to interact, tracks his position and keeps its sensor systems in an optimal configuration. Audio is a suitable modality for such task as it allows for detecting a speaker in arbitrary positions around the robot. In this paper, we present a novel approach for localization of sound sources by analyzing the frequency spectrum of the received signal and applying a motion model to the estimation process. We use an improved version of the Generalized Singular Value Decomposition (GSVD) based MUltiple SIgnal Classification (MUSIC) algorithm as a direction of arrival (DoA) estimator. Further, we introduce a motion model to enable robust localization in reverberant and echoic environments.We evaluate the system under real conditions in an experimental setup. Our experiments show that our approach outperforms current state-of-the-art algorithm and demonstrate the robustness against the previously mentioned disruptive factors.",
        "primary_area": "",
        "author": "Marco Sewtz;Tim Bodenm\u00fcller;Rudolph Triebel;Marco Sewtz;Tim Bodenm\u00fcller;Rudolph Triebel",
        "authorids": "/37088688892;/37273191300;/37542908700;/37088688892;/37273191300;/37542908700",
        "aff": "Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Germany; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Germany; Dep. of Computer Science, Technical Univ. of Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340826/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17250196816476781522&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "German Aerospace Center;Technical University of Munich",
        "aff_unique_dep": "Institute of Robotics and Mechatronics;Department of Computer Science",
        "aff_unique_url": "https://www.dlr.de;https://www.tum.de",
        "aff_unique_abbr": "DLR;TUM",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Munich",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9340885",
        "title": "Robust Micro-Particle Manipulation in a Microfluidic Channel Network Using Gravity-Induced Pressure Actuators",
        "track": "main",
        "status": "Poster",
        "abstract": "Robust particle manipulation is a challenging but essential technique for single-cell analysis and processing of microfluidic devices. This paper proposes a micro-particle manipulation system with a microfluidic channel network. We built gravity-induced pressure actuators, which can generate high-resolution output pressure with a wide range so that the multiple particles can be delivered from the inlet of the chip. In this paper, we studied how to model the proposed multi-input-single-output system and sources of disturbances, and designed a robust controller using disturbance observer technique. The performance of the proposed system was verified through experiments.",
        "primary_area": "",
        "author": "Donghyeon Lee;Woongyong Lee;Wan Kyun Chung;Keehoon Kim;Donghyeon Lee;Woongyong Lee;Wan Kyun Chung;Keehoon Kim",
        "authorids": "/37677365900;/37085438631;/37280299100;/37066398600;/37677365900;/37085438631;/37280299100;/37066398600",
        "aff": "School of Mechanical Engineering, Robotics Laboratory, Pohang University of Science and Technology (POSTECH), Pohang, Korea; Neuromeka, Seoul, Korea; School of Mechanical Engineering, Robotics Laboratory, Pohang University of Science and Technology (POSTECH), Pohang, Korea; School of Mechanical Engineering, Robotics Laboratory, Pohang University of Science and Technology (POSTECH), Pohang, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340885/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:cDUHQzSe02IJ:scholar.google.com/&scioq=Robust+Micro-Particle+Manipulation+in+a+Microfluidic+Channel+Network+Using+Gravity-Induced+Pressure+Actuators&hl=en&as_sdt=0,33",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Pohang University of Science and Technology;Neuromeka",
        "aff_unique_dep": "School of Mechanical Engineering, Robotics Laboratory;",
        "aff_unique_url": "https://www.postech.ac.kr;",
        "aff_unique_abbr": "POSTECH;",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pohang;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9341052",
        "title": "Robust Monocular Edge Visual Odometry through Coarse-to-Fine Data Association",
        "track": "main",
        "status": "Poster",
        "abstract": "This work describes a monocular visual odometry framework, which exploits the best attributes of edge features for illumination-robust camera tracking, while at the same time ameliorating the performance degradation of edge mapping. In the front-end, an ICP-based edge registration provides robust motion estimation and coarse data association under lighting changes. In the back-end, a novel edge-guided data association pipeline searches for the best photometrically matched points along geometrically possible edges through template matching, so that the matches can be further refined in later bundle adjustment. The core of our proposed data association strategy lies in a point-to-edge geometric uncertainty analysis, which analytically derives (1) a probabilistic search length formula that significantly reduces the search space and (2) a geometric confidence metric for mapping degradation detection based on the predicted depth uncertainty. Moreover, a match confidence based patch size adaption strategy is integrated into our pipeline to reduce matching ambiguity. We present extensive analysis and evaluation of our proposed system on synthetic and real- world benchmark datasets under the influence of illumination changes and large camera motions, where our proposed system outperforms current state-of-art algorithms.",
        "primary_area": "",
        "author": "Xiaolong Wu;Patricio A. Vela;C\u00e9dric Pradalier;Xiaolong Wu;Patricio A. Vela;C\u00e9dric Pradalier",
        "authorids": "/37086493433;/37329553400;/37279005400;/37086493433;/37329553400;/37279005400",
        "aff": "School of Electrical and Computer Engineering, Atlanta, GA, United States; School of Electrical and Computer Engineering, Atlanta, GA, United States; School of Electrical and Computer Engineering, Atlanta, GA, United States",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341052/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3236988475309297336&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Georgia Institute of Technology",
        "aff_unique_dep": "School of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.gatech.edu",
        "aff_unique_abbr": "Georgia Tech",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Atlanta",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341463",
        "title": "Robust Pedestrian Tracking in Crowd Scenarios Using an Adaptive GMM-based Framework",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we address the issue of pedestrian tracking in crowd scenarios. People in close social relationships tend to act as a group which is a great challenge to individually discriminate and track pedestrians on a LiDAR system. In this paper, we integrally model groups of people and track them in a recursive framework based on Gaussian Mixture Model (GMM). The model is optimized by an extended Expectation-Maximization (EM) algorithm which can adaptively vary the number of mixture components over scans. Experimental results both qualitatively and quantitatively indicate the reliability and accuracy of our tracker in populated scenarios.",
        "primary_area": "",
        "author": "Shuyang Zhang;Di Wang;Fulong Ma;Chao Qin;Zhengyong Chen;Ming Liu;Shuyang Zhang;Di Wang;Fulong Ma;Chao Qin;Zhengyong Chen;Ming Liu",
        "authorids": "/37088507304;/37086061043;/37086959093;/37088505064;/37086959820;/37085398677;/37088507304;/37086061043;/37086959093;/37088505064;/37086959820;/37085398677",
        "aff": "Unity-Drive technology Inc, Shenzhen, China; Institute of Artificial Intelligence and Robotics, Xian Jiaotong University, China; Robotics and Multi-Perception Laborotary, Robotics Institute, The Hong Kong University of Science and Technology, Hong Kong SAR, China; Unity-Drive technology Inc, Shenzhen, China; Unity-Drive technology Inc, Shenzhen, China; Robotics and Multi-Perception Laborotary, Robotics Institute, The Hong Kong University of Science and Technology, Hong Kong SAR, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341463/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13339281474675607643&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;0;0;2",
        "aff_unique_norm": "Unity-Drive technology Inc;Xian Jiaotong University;The Hong Kong University of Science and Technology",
        "aff_unique_dep": ";Institute of Artificial Intelligence and Robotics;Robotics and Multi-Perception Laborotary, Robotics Institute",
        "aff_unique_url": ";http://www.xjtu.edu.cn;https://www.ust.hk",
        "aff_unique_abbr": ";XJTU;HKUST",
        "aff_campus_unique_index": "1;2;2",
        "aff_campus_unique": ";Xian;Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9340859",
        "title": "Robust Robotic Pouring using Audition and Haptics",
        "track": "main",
        "status": "Poster",
        "abstract": "Robust and accurate estimation of liquid height lies as an essential part of pouring tasks for service robots. However, vision-based methods often fail in occluded conditions while audio-based methods cannot work well in a noisy environment. We instead propose a multimodal pouring network (MP-Net) that is able to robustly predict liquid height by conditioning on both audition and haptics input. MP-Net is trained on a self-collected multimodal pouring dataset. This dataset contains 300 robot pouring recordings with audio and force/torque measurements for three types of target containers. We also augment the audio data by inserting robot noise. We evaluated MP-Net on our collected dataset and a wide variety of robot experiments. Both network training results and robot experiments demonstrate that MP-Net is robust against noise and changes to the task and environment. Moreover, we further combine the predicted height and force data to estimate the shape of the target container.",
        "primary_area": "",
        "author": "Hongzhuo Liang;Chuangchuang Zhou;Shuang Li;Xiaojian Ma;Norman Hendrich;Timo Gerkmann;Fuchun Sun;Marcus Stoffel;Jianwei Zhang;Hongzhuo Liang;Chuangchuang Zhou;Shuang Li;Xiaojian Ma;Norman Hendrich;Timo Gerkmann;Fuchun Sun;Marcus Stoffel;Jianwei Zhang",
        "authorids": "/37086700920;/37088691335;/37086938152;/37086936937;/37449613700;/37646480900;/37279269000;/37088690265;/37281460600;/37086700920;/37088691335;/37086938152;/37086936937;/37449613700;/37646480900;/37279269000;/37088690265;/37281460600",
        "aff": "Dept. of Informatics, Group TAMS, Universit\u00e4t Hamburg; Institute of General Mechanics, RWTH Aachen University; Dept. of Informatics, Group TAMS, Universit\u00e4t Hamburg; Dept. of Statistics, Group VCLA, University of California, Los Angeles; Dept. of Informatics, Group TAMS, Universit\u00e4t Hamburg; Dept. of Informatics, Signal Processing (SP), Universitat Hamburg; Dept. of Computer Science and Technology, Tsinghua University; Institute of General Mechanics, RWTH Aachen University; Dept. of Informatics, Group TAMS, Universit\u00e4t Hamburg",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340859/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6847136558062518799&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;1;0;2;0;3;4;1;0",
        "aff_unique_norm": "Universit\u00e4t Hamburg;RWTH Aachen University;University of California, Los Angeles;Universitat Hamburg;Tsinghua University",
        "aff_unique_dep": "Dept. of Informatics, Group TAMS;Institute of General Mechanics;Dept. of Statistics;Dept. of Informatics, Signal Processing (SP);Dept. of Computer Science and Technology",
        "aff_unique_url": "https://www.uni-hamburg.de;https://www.rwth-aachen.de;https://www.ucla.edu;https://www.uni-hamburg.de;https://www.tsinghua.edu.cn",
        "aff_unique_abbr": ";RWTH;UCLA;;THU",
        "aff_campus_unique_index": "1;2;1",
        "aff_campus_unique": ";Aachen;Los Angeles",
        "aff_country_unique_index": "0;0;0;1;0;0;2;0;0",
        "aff_country_unique": "Germany;United States;China"
    },
    {
        "id": "9341502",
        "title": "Robust Task and Motion Planning for Long-Horizon Architectural Construction Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Integrating robotic systems in architectural and construction processes is of core interest to increase the efficiency of the building industry. Automated planning for such systems enables design analysis tools and facilitates faster design iteration cycles for designers and engineers. However, generic task-and-motion planning (TAMP) for long-horizon construction processes is beyond the capabilities of current approaches. In this paper, we develop a multi-agent TAMP framework for long horizon problems such as constructing a full-scale building. To this end we extend the Logic-Geometric Programming framework by sampling-based motion planning, a limited horizon approach, and a task-specific structural stability optimization that allow an effective decomposition of the task. We show that our framework is capable of constructing a large pavilion built from several hundred geometrically unique building elements from start to end autonomously.",
        "primary_area": "",
        "author": "Valentin N. Hartmann;Ozgur S. Oguz;Danny Driess;Marc Toussaint;Achim Menges;Valentin N. Hartmann;Ozgur S. Oguz;Danny Driess;Marc Toussaint;Achim Menges",
        "authorids": "/37088690890;/37085638620;/37085994159;/37528418600;/37086610704;/37088690890;/37085638620;/37085994159;/37528418600;/37086610704",
        "aff": "Machine Learning & Robotics Lab, University of Stuttgart, Germany; Max Planck Institute for Intelligent Systems, Germany; Max Planck Institute for Intelligent Systems, Germany; Max Planck Institute for Intelligent Systems, Germany; Institute for Computational Design and Construction, University of Stuttgart, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341502/",
        "gs_citation": 54,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8279962577423583296&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;0",
        "aff_unique_norm": "University of Stuttgart;Max Planck Institute for Intelligent Systems",
        "aff_unique_dep": "Machine Learning & Robotics Lab;",
        "aff_unique_url": "https://www.uni-stuttgart.de;https://www.mpi-is.mpg.de",
        "aff_unique_abbr": ";MPI-IS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9341664",
        "title": "Robust and Efficient Object Change Detection by Combining Global Semantic Information and Local Geometric Verification",
        "track": "main",
        "status": "Poster",
        "abstract": "Identifying new, moved or missing objects is an important capability for robot tasks such as surveillance or maintaining order in homes, offices and industrial settings. However, current approaches do not distinguish between novel objects or simple scene readjustments nor do they sufficiently deal with localization error and sensor noise. To overcome these limitations, we combine the strengths of global and local methods for efficient detection of novel objects in 3D reconstructions of indoor environments. Global structure, determined from 3D semantic information, is exploited to establish object candidates. These are then locally verified by comparing isolated geometry to a reference reconstruction provided by the task. We evaluate our approach on a novel dataset containing different types of rooms with 31 scenes and 260 annotated objects. Experiments show that our proposed approach significantly outperforms baseline methods.",
        "primary_area": "",
        "author": "Edith Langer;Timothy Patten;Markus Vincze;Edith Langer;Timothy Patten;Markus Vincze",
        "authorids": "/37086354313;/37085763735;/37269163100;/37086354313;/37085763735;/37269163100",
        "aff": "Vision4Robotics group, Automation and Control Institute, Vienna, Austria; Vision4Robotics group, Automation and Control Institute, Vienna, Austria; Vision4Robotics group, Automation and Control Institute, Vienna, Austria",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341664/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9406756717842196167&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Automation and Control Institute",
        "aff_unique_dep": "Vision4Robotics group",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Vienna",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Austria"
    },
    {
        "id": "9341600",
        "title": "Robust and efficient post-processing for video object detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Object recognition in video is an important task for plenty of applications, including autonomous driving perception, surveillance tasks, wearable devices or IoT networks. Object recognition using video data is more challenging than using still images due to blur, occlusions or rare object poses. Specific video detectors with high computational cost or standard image detectors together with a fast post-processing algorithm achieve the current state-of-the-art. This work introduces a novel post-processing pipeline that overcomes some of the limitations of previous post-processing methods by introducing a learning-based similarity evaluation between detections across frames. Our method improves the results of stat-of-the-art specific video detectors, specially regarding fast moving objects, and presents low resource requirements. And applied to efficient still image detectors, such as YOLO, provides comparable results to much more computationally intensive detectors.",
        "primary_area": "",
        "author": "Alberto Sabater;Luis Montesano;Ana C. Murillo;Alberto Sabater;Luis Montesano;Ana C. Murillo",
        "authorids": "/37087046559;/37542842700;/37393616700;/37087046559;/37542842700;/37393616700",
        "aff": "DIIS - I3A, Universidad de Zaragoza, Spain; Bitbrain Technologies, Zaragoza, Spain; DIIS - I3A, Universidad de Zaragoza, Spain",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341600/",
        "gs_citation": 74,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4535079896626161866&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Universidad de Zaragoza;Bitbrain Technologies",
        "aff_unique_dep": "DIIS - I3A;",
        "aff_unique_url": "https://www.unizar.es;",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Zaragoza",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Spain"
    },
    {
        "id": "9341131",
        "title": "Robust real-time monitoring of human task advancement for collaborative robotics applications",
        "track": "main",
        "status": "Poster",
        "abstract": "A crucial problem in human-robot collaboration is to achieve seamless coordination among the agents. Robots have to adapt to human behaviour, which is highly uncertain. In fact, humans can perform each task in many ways and with different speeds, occasional errors and short pauses. This paper offers a robust method to monitor the advancement of the current human activity in real-time in order to predict its duration. The algorithm learns online templates of new variants of the task and uses them as references for a Dynamic Time Warping-based algorithm. The proposed strategy has been tested within a realistic assembly task. Results show its ability to give accurate predictions also in case of peculiar variants, such as those associated with errors.",
        "primary_area": "",
        "author": "Riccardo Maderna;Maria Ciliberto;Andrea Maria Zanchettin;Paolo Rocco;Riccardo Maderna;Maria Ciliberto;Andrea Maria Zanchettin;Paolo Rocco",
        "authorids": "/37086455306;/37088688642;/37086389313;/37274178600;/37086455306;/37088688642;/37086389313;/37274178600",
        "aff": "Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milano, Italy; Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milano, Italy; Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milano, Italy; Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milano, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341131/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4208334576871958275&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Politecnico di Milano",
        "aff_unique_dep": "Dipartimento di Elettronica, Informazione e Bioingegneria",
        "aff_unique_url": "https://www.polimi.it",
        "aff_unique_abbr": "Politecnico di Milano",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Milano",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9341507",
        "title": "Robust, Perception Based Control with Quadrotors",
        "track": "main",
        "status": "Poster",
        "abstract": "Traditionally, controllers and state estimators in robotic systems are designed independently. Controllers are often designed assuming perfect state estimation. However, state estimation methods such as Visual Inertial Odometry (VIO) drift over time and can cause the system to misbehave. While state estimation error can be corrected with the aid of GPS or motion capture, these complementary sensors are not always available or reliable. Recent work has shown that this issue can be dealt with by synthesizing robust controllers using a data-driven characterization of the perception error, and can bound the system's response to state estimation error using a robustness constraint. We investigate the application of this robust perception-based approach to a quadrotor model using VIO for state estimation and demonstrate the benefits and drawbacks of using this technique in simulation and hardware. Additionally, to make tuning easier, we introduce a new cost function to use in the control synthesis which allows one to take an existing controller and \"robustify\" it. To the best of our knowledge, this is the first robust perception-based controller implemented in real hardware, as well as one utilizing a data-driven perception model. We believe this as an important step towards safe, robust robots that explicitly account for the inherent dependence between perception and control.",
        "primary_area": "",
        "author": "Laura Jarin-Lipschitz;Rebecca Li;Ty Nguyen;Vijay Kumar;Nikolai Matni;Laura Jarin-Lipschitz;Rebecca Li;Ty Nguyen;Vijay Kumar;Nikolai Matni",
        "authorids": "/37087015656;/37088686634;/37086353035;/37280341400;/37398611500;/37087015656;/37088686634;/37086353035;/37280341400;/37398611500",
        "aff": "GRASP Lab, University of Pennsylvania, PA, USA; GRASP Lab, University of Pennsylvania, PA, USA; GRASP Lab, University of Pennsylvania, PA, USA; GRASP Lab, University of Pennsylvania, PA, USA; GRASP Lab, University of Pennsylvania, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341507/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9555345746040983561&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Pennsylvania",
        "aff_unique_dep": "GRASP Lab",
        "aff_unique_url": "https://www.upenn.edu",
        "aff_unique_abbr": "UPenn",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Philadelphia",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341288",
        "title": "SCALE-Net: Scalable Vehicle Trajectory Prediction Network under Random Number of Interacting Vehicles via Edge-enhanced Graph Convolutional Neural Network",
        "track": "main",
        "status": "Poster",
        "abstract": "Predicting the future trajectory of surrounding vehicles in a randomly varying traffic level is one of the most challenging problems in developing an autonomous vehicle. Since there is no pre-defined number of interacting vehicles participated in, the prediction network has to be scalable with respect to the number of vehicles in order to guarantee consistent performance in terms of both accuracy and computational load. In this paper, the first fully scalable trajectory prediction network, SCALE-Net, is proposed that can ensure both high prediction performance while keeping the computational load low regardless of the number of surrounding vehicles. The SCALE-Net employs the Edge-enhanced Graph Convolutional Neural Network (EGCN) for the inter-vehicular interaction embedding network. Since the proposed EGCN is inherently scalable with respect to the graph node (an agent in this study), the model can be operated independently from the total number of vehicles considered. We evaluated the scalability of the SCALE-Net on the publically available NGSIM datasets by comparing variations on computation time and prediction accuracy per single driving scene with respect to the varying vehicle number. The experimental test shows that both computation time and prediction performance of the SCALE-Net consistently outperform those of previous models regardless of the level of traffic complexities.",
        "primary_area": "",
        "author": "Hyeongseok Jeon;Junwon Choi;Dongsuk Kum;Hyeongseok Jeon;Junwon Choi;Dongsuk Kum",
        "authorids": "/37086488423;/37405961800;/37967151300;/37086488423;/37405961800;/37967151300",
        "aff": "Cho Chun Shik Graduate School of Green Transportation, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, South Korea; Department of Electrical Engineering, Hanyang University, Seoul, South Korea; Cho Chun Shik Graduate School of Green Transportation, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341288/",
        "gs_citation": 94,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16817327916784744347&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology;Hanyang University",
        "aff_unique_dep": "Cho Chun Shik Graduate School of Green Transportation;Department of Electrical Engineering",
        "aff_unique_url": "https://www.kaist.ac.kr;http://www.hanyang.ac.kr",
        "aff_unique_abbr": "KAIST;HYU",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Daejeon;Seoul",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9341548",
        "title": "SCAN: System for Camera Autonomous Navigation in Robotic-Assisted Surgery",
        "track": "main",
        "status": "Poster",
        "abstract": "Robot-Assisted systems for Minimally Invasive Surgery enhance the surgeon capability, however, direct control over both the surgical tools and the endoscope results in an increased workload that leads to longer operation times. This work investigates the introduction of SCAN (System for Camera Autonomous Navigation) to overcome this limitation. An experimental study involving 12 participants was carried out with the da Vinci Research Kit. Each user tested two novel camera control modalities, autonomous and semi-autonomous, as well as the current manual control of the camera, while carrying out a dry-lab task. Among the camera control modalities, the autonomous navigation achieved better objective performances and the highest user confidence. Moreover, the autonomous control (along with the semi-autonomous one) was able to optimize some metrics related to the robotic surgery workflow.",
        "primary_area": "",
        "author": "Tommaso Da Col;Andrea Mariani;Anton Deguet;Arianna Menciassi;Peter Kazanzides;Elena De Momi;Tommaso Da Col;Andrea Mariani;Anton Deguet;Arianna Menciassi;Peter Kazanzides;Elena De Momi",
        "authorids": "/37088688285;/37086361035;/37427184100;/37280284800;/37375173500;/37947344300;/37088688285;/37086361035;/37427184100;/37280284800;/37375173500;/37947344300",
        "aff": "Department of Electronics, Information and Bioengineering, Politecnico di Milano, Italy; BioRobotics Institute, Scuola Superiore Sant\u2019Anna, Pisa, Italy; Department of Computer Science, Johns Hopkins University, Baltimore, Maryland; BioRobotics Institute, Scuola Superiore Sant\u2019Anna, Pisa, Italy; Department of Computer Science, Johns Hopkins University, Baltimore, Maryland; Department of Electronics, Information and Bioengineering, Politecnico di Milano, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341548/",
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3125643612187441696&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;1;2;0",
        "aff_unique_norm": "Politecnico di Milano;Scuola Superiore Sant\u2019Anna;Johns Hopkins University",
        "aff_unique_dep": "Department of Electronics, Information and Bioengineering;BioRobotics Institute;Department of Computer Science",
        "aff_unique_url": "https://www.polimi.it;https://www.sssup.it;https://www.jhu.edu",
        "aff_unique_abbr": "Politecnico di Milano;;JHU",
        "aff_campus_unique_index": "1;2;1;2",
        "aff_campus_unique": ";Pisa;Baltimore",
        "aff_country_unique_index": "0;0;1;0;1;0",
        "aff_country_unique": "Italy;United States"
    },
    {
        "id": "9340766",
        "title": "SGM-MDE: Semi-global optimization for classification-based monocular depth estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Depth estimation plays a crucial role in robotic applications that require environment perception. With the introduction of convolutional neural networks, monocular depth estimation (MDE) methods have become viable alternatives to LiDAR and stereo reconstruction-based solutions. Such methods require less equipment, fewer resources and do not need additional sensor alignment requirements. However, due to the ill-posed formulation of MDE, such algorithms can only rely on learning mechanisms, which makes them less reliable and less robust. In this work we propose a novel method to cope with the lack of geometric constraints inherent to monocular depth computation. Towards this goal, we initially mathematically transform the feature vectors from the last layer inside a MDE CNN such that a 3D stereo-like cost volume is generated. We then adapt the semi-global stereo optimization to the aforementioned volume, global consistency of the map being ensured. Furthermore, we enhance the results by adding a sub-pixel stereo post-processing be means of interpolation functions, a larger range of depth values being obtained. Our method can be applied to any classification-based MDE, experiments showing an increase in accuracy with an additional time cost of only 8 ms on a regular GPU, making the technique usable for real-time applications.",
        "primary_area": "",
        "author": "Vlad-Cristian Miclea;Sergiu Nedevschi;Vlad-Cristian Miclea;Sergiu Nedevschi",
        "authorids": "/37085748669;/37283407700;/37085748669;/37283407700",
        "aff": "Department of Computer Science, Technical University of Cluj-Napoca, Cluj-Napoca, Romania; Department of Computer Science, Technical University of Cluj-Napoca, Cluj-Napoca, Romania",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340766/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10445403443095424021&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Technical University of Cluj-Napoca",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.tucluj.ro",
        "aff_unique_abbr": "TUCN",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Cluj-Napoca",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Romania"
    },
    {
        "id": "9341741",
        "title": "SMA Actuated Low-Weight Bio-Inspired Claws for Grasping and Perching Using Flapping Wing Aerial Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "Taking inspiration from nature, the work presented in this paper aims to develop bio-inspired claws to be used for grasping and perching in flapping-wing aerial systems. These claws can be 3D printed out of two different materials and will be capable of adapt to any shape. Also, they will be soft for avoiding undesired damages on the objects when performing manipulation. These claws will be actuated by shape memory alloys (SMA) springs to get rid of the weight of traditional servos. The design of all the components will be explained in this work. Also, the challenges of being able to control SMA using only a LiPo battery on an aerial vehicle will be exposed. The solutions applied and electronics used will be also described. Lastly, experiments made both in test bench as on flight will be summarized.",
        "primary_area": "",
        "author": "A. E. Gomez-Tamm;V. Perez-Sanchez;B. C. Arrue;A. Ollero;A. E. Gomez-Tamm;V. Perez-Sanchez;B. C. Arrue;A. Ollero",
        "authorids": "/37087322181;/37088504710;/37444998200;/37265412000;/37087322181;/37088504710;/37444998200;/37265412000",
        "aff": "GRVC Robotics Laboratory, University of Seville, Spain; GRVC Robotics Laboratory, University of Seville, Spain; GRVC Robotics Laboratory, University of Seville, Spain; GRVC Robotics Laboratory, University of Seville, Spain",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341741/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14205342558204805815&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Seville",
        "aff_unique_dep": "GRVC Robotics Laboratory",
        "aff_unique_url": "https://www.us.es",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Spain"
    },
    {
        "id": "9340915",
        "title": "SQUIRL: Robust and Efficient Learning from Video Demonstration of Long-Horizon Robotic Manipulation Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent advances in deep reinforcement learning (RL) have demonstrated its potential to learn complex robotic manipulation tasks. However, RL still requires the robot to collect a large amount of real-world experience. To address this problem, recent works have proposed learning from expert demonstrations (LfD), particularly via inverse reinforcement learning (IRL), given its ability to achieve robust performance with only a small number of expert demonstrations. Nevertheless, deploying IRL on real robots is still challenging due to the large number of robot experiences it requires. This paper aims to address this scalability challenge with a robust, sample-efficient, and general meta-IRL algorithm, SQUIRL, that performs a new but related long-horizon task robustly given only a single video demonstration. First, this algorithm bootstraps the learning of a task encoder and a task-conditioned policy using behavioral cloning (BC). It then collects real-robot experiences and bypasses reward learning by directly recovering a Q-function from the combined robot and expert trajectories. Next, this algorithm uses the learned Q-function to re-evaluate all cumulative experiences collected by the robot to improve the policy quickly. In the end, the policy performs more robustly (90%+ success) than BC on new tasks while requiring no experiences at test time. Finally, our real-robot and simulated experiments demonstrate our algorithm's generality across different state spaces, action spaces, and vision-based manipulation tasks, e.g., pick-pour-place and pick-carry-drop.",
        "primary_area": "",
        "author": "Bohan Wu;Feng Xu;Zhanpeng He;Abhi Gupta;Peter K. Allen;Bohan Wu;Feng Xu;Zhanpeng He;Abhi Gupta;Peter K. Allen",
        "authorids": "/37087323203;/37088690247;/37088687305;/37088689015;/37280851400;/37087323203;/37088690247;/37088687305;/37088689015;/37280851400",
        "aff": "Columbia University Robotics Group, New York, NY, USA; Columbia University Robotics Group, New York, NY, USA; Columbia University Robotics Group, New York, NY, USA; Columbia University Robotics Group, New York, NY, USA; Columbia University Robotics Group, New York, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340915/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1167664564399253202&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Columbia University",
        "aff_unique_dep": "Robotics Group",
        "aff_unique_url": "https://www.columbia.edu",
        "aff_unique_abbr": "Columbia",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "New York",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340754",
        "title": "SSP: Single Shot Future Trajectory Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a robust solution to future trajectory forecast, which can be practically applicable to autonomous agents in highly crowded environments. For this, three aspects are particularly addressed in this paper. First, we use composite fields to predict future locations of all road agents in a singleshot, which results in a constant time complexity, regardless of the number of agents in the scene. Second, interactions between agents are modeled as a non-local response, enabling spatial relationships between different locations to be captured temporally as well (i.e., in spatio-temporal interactions). Third, the semantic context of the scene are modeled and take into account the environmental constraints that potentially influence the future motion. To this end, we validate the robustness of the proposed approach using the ETH, UCY, and SDD datasets and highlight its practical functionality compared to the current state-of-the-art methods.",
        "primary_area": "",
        "author": "Isht Dwivedi;Srikanth Malla;Behzad Dariush;Chiho Choi;Isht Dwivedi;Srikanth Malla;Behzad Dariush;Chiho Choi",
        "authorids": "/37086042426;/37086934253;/37444121400;/37086937192;/37086042426;/37086934253;/37444121400;/37086937192",
        "aff": "Honda Research Institute USA, San Jose, CA, USA; Honda Research Institute USA, San Jose, CA, USA; Honda Research Institute USA, San Jose, CA, USA; Honda Research Institute USA, San Jose, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340754/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8082390288949162095&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Honda Research Institute USA",
        "aff_unique_dep": "",
        "aff_unique_url": "https://honda-ri.com",
        "aff_unique_abbr": "HRI USA",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "San Jose",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340991",
        "title": "STORM: Screw Theory Toolbox For Robot Manipulator and Mechanisms",
        "track": "main",
        "status": "Poster",
        "abstract": "Screw theory is a powerful mathematical tool for the kinematic analysis of mechanisms and has become a cornerstone of modern kinematics. Although screw theory has rooted itself as a core concept, there is a lack of generic software tools for visualization of the geometric pattern of the screw elements. This paper presents STORM, an educational and research oriented framework for analysis and visualization of reciprocal screw systems for a class of robot manipulator and mechanisms. This platform has been developed as a way to bridge the gap between theory and practice of application of screw theory in the constraint and motion analysis for robot mechanisms. STORM utilizes an abstracted software architecture that enables the user to study different structures of robot manipulators. The example case studies demonstrate the potential to perform analysis on mechanisms, visualize the screw entities and conveniently add new models and analyses.",
        "primary_area": "",
        "author": "Keerthi Sagar;Vishal Ramadoss;Dimiter Zlatanov;Matteo Zoppi;Keerthi Sagar;Vishal Ramadoss;Dimiter Zlatanov;Matteo Zoppi",
        "authorids": "/37088690010;/37086081885;/37552229000;/37295666600;/37088690010;/37086081885;/37552229000;/37295666600",
        "aff": "Department of Mechanical, Energy, Management and Transportation Engineering, PMAR Robotics Group, University of Genoa, Genoa (GE), Italy; Department of Mechanical, Energy, Management and Transportation Engineering, PMAR Robotics Group, University of Genoa, Genoa (GE), Italy; Department of Mechanical, Energy, Management and Transportation Engineering, PMAR Robotics Group, University of Genoa, Genoa (GE), Italy; Department of Mechanical, Energy, Management and Transportation Engineering, PMAR Robotics Group, University of Genoa, Genoa (GE), Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340991/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=814085649603410060&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Genoa",
        "aff_unique_dep": "Department of Mechanical, Energy, Management and Transportation Engineering",
        "aff_unique_url": "https://www.unige.it",
        "aff_unique_abbr": "UniGe",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Genoa",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9341180",
        "title": "SaD-SLAM: A Visual SLAM Based on Semantic and Depth Information",
        "track": "main",
        "status": "Poster",
        "abstract": "Simultaneous Localization and Mapping (SLAM) is considered significant for intelligent mobile robot autonomous pathfinding. Over the past years, many successful SLAM systems have been developed and works satisfactorily in static environments. However, in some dynamic scenes with moving objects, the camera pose estimation error would be unacceptable, or the systems even lose their locations. In this paper, we present SaD-SLAM, a visual SLAM system that, building on ORB-SLAM2, achieves excellent performance in dynamic environments. With the help of semantic and depth information, we find out feature points that belong to movable objects. And we detect whether those feature points are keeping still at the moment. To make the system perform accurately and robustly in dynamic scenes, we use both feature points extracted from static objects and static feature points derived from movable objects to finetune the camera pose estimation. We evaluate our algorithm in TUM RGB-D datasets. The results demonstrate the absolute trajectory accuracy of SaD-SLAM can be improved significantly compared with the original ORB-SLAM2. We also compare our algorithm with DynaSLAM and DS-SLAM, which are designed to fit dynamic scenes.",
        "primary_area": "",
        "author": "Xun Yuan;Song Chen;Xun Yuan;Song Chen",
        "authorids": "/37088691315;/37086011278;/37088691315;/37086011278",
        "aff": "University of Science and Technology of China, Hefei, China; University of Science and Technology of China, Hefei, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341180/",
        "gs_citation": 59,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4762898748062171200&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Science and Technology of China",
        "aff_unique_dep": "",
        "aff_unique_url": "http://www.ustc.edu.cn",
        "aff_unique_abbr": "USTC",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Hefei",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9341084",
        "title": "Safe Path Planning with Multi-Model Risk Level Sets",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper investigates the safe path planning problem for an autonomous vehicle operating in unstructured, cluttered environments. While some objects may be accurately with canonical perception algorithms, other objects and clutter may be harder to track. We present an approach that combines two methods of risk assessment: for objects with reliable tracking, we use a Gaussian Process (GP) regulated risk map to describe the risk map information; for unknown objects that we fail to accurately track, we compute a Dynamic Risk Density (DRD) from the overall occupancy and velocity field from LiDAR scan snapshots. Several methods are proposed for combining the GP risk map and DRD, and the resultant hybrid risk map is used for the proposed safe path planning algorithm. Experimental results on an autonomous buggy show that the hybrid risk map is able to yield a safe path planner to navigate the autonomous testbed within the cluttered environments.",
        "primary_area": "",
        "author": "Zefan Huang;Wilko Schwarting;Alyssa Pierson;Hongliang Guo;Marcelo Ang;Daniela Rus;Zefan Huang;Wilko Schwarting;Alyssa Pierson;Hongliang Guo;Marcelo Ang;Daniela Rus",
        "authorids": "/37087323099;/37085590089;/37085345711;/37085490043;/37279138700;/37279652300;/37087323099;/37085590089;/37085345711;/37085490043;/37279138700;/37279652300",
        "aff": "Singapore-MIT Alliance for Research and Technology, Singapore; Computer Science and Artificial Intelligence Laboratory, Mas-sachusetts Institute of Technology, Cambridge, MA, USA; Computer Science and Artificial Intelligence Laboratory, Mas-sachusetts Institute of Technology, Cambridge, MA, USA; Singapore-MIT Alliance for Research and Technology, Singapore; National University of Singapore, Singapore; Computer Science and Artificial Intelligence Laboratory, Mas-sachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341084/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11016898163992177460&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;0;2;1",
        "aff_unique_norm": "Singapore-MIT Alliance for Research and Technology;Massachusetts Institute of Technology;National University of Singapore",
        "aff_unique_dep": ";Computer Science and Artificial Intelligence Laboratory;",
        "aff_unique_url": ";https://www.mit.edu;https://www.nus.edu.sg",
        "aff_unique_abbr": "SMART;MIT;NUS",
        "aff_campus_unique_index": "1;1;1",
        "aff_campus_unique": ";Cambridge",
        "aff_country_unique_index": "0;1;1;0;0;1",
        "aff_country_unique": "Singapore;United States"
    },
    {
        "id": "9340886",
        "title": "Safe Planning for Self-Driving Via Adaptive Constrained ILQR",
        "track": "main",
        "status": "Poster",
        "abstract": "Constrained Iterative Linear Quadratic Regulator (CILQR), a variant of ILQR, has been recently proposed for motion planning problems of autonomous vehicles to deal with constraints such as obstacle avoidance and reference tracking. However, the previous work considers either deterministic trajectories or persistent prediction for target dynamical obstacles. The other drawback is lack of generality - it requires manual weight tuning for different scenarios. In this paper, two significant improvements are achieved. Firstly, a two-stage uncertainty-aware prediction is proposed. The short-term prediction with safety guarantee based on reachability analysis is responsible for dealing with extreme maneuvers conducted by target vehicles. The long-term prediction leveraging an adaptive least square filter preserves the long-term optimality of the planned trajectory since using reachability only for long-term prediction is too pessimistic and makes the planner over-conservative. Secondly, to allow a wider coverage over different scenarios and to avoid tedious parameter tuning case by case, this paper designs a scenario-based analytical function taking the states from the ego vehicle and the target vehicle as input, and carrying weights of a cost function as output. It allows the ego vehicle to execute multiple behaviors (such as lane-keeping and overtaking) under a single planner. We demonstrate safety, effectiveness, and real-time performance of the proposed planner in simulations.",
        "primary_area": "",
        "author": "Yanjun Pan;Qin Lin;Het Shah;John M. Dolan;Yanjun Pan;Qin Lin;Het Shah;John M. Dolan",
        "authorids": "/37088689096;/37086031992;/37086805201;/37283756800;/37088689096;/37086031992;/37086805201;/37283756800",
        "aff": "Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; Department of the Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Mechanical Engineering, Indian Institute of Technology Kharagpur, Kharagpur, West Bengal, India; Department of the Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340886/",
        "gs_citation": 40,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8812704972998553610&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Carnegie Mellon University;Indian Institute of Technology Kharagpur",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.cmu.edu;https://www.iitkgp.ac.in",
        "aff_unique_abbr": "CMU;IIT Kharagpur",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Pittsburgh;Kharagpur",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "United States;India"
    },
    {
        "id": "9340922",
        "title": "Safe and Effective Picking Paths in Clutter given Discrete Distributions of Object Poses",
        "track": "main",
        "status": "Poster",
        "abstract": "Picking an item in the presence of other objects can be challenging as it involves occlusions and partial views. Given object models, one approach is to perform object pose estimation and use the most likely candidate pose per object to pick the target without collisions. This approach, however, ignores the uncertainty of the perception process both regarding the target's and the surrounding objects' poses. This work proposes first a perception process for 6D pose estimation, which returns a discrete distribution of object poses in a scene. Then, an open-loop planning pipeline is proposed to return safe and effective solutions for moving a robotic arm to pick, which (a) minimizes the probability of collision with the obstructing objects; and (b) maximizes the probability of reaching the target item. The planning framework models the challenge as a stochastic variant of the Minimum Constraint Removal (MCR) problem. The effectiveness of the methodology is verified given both simulated and real data in different scenarios. The experiments demonstrate the importance of considering the uncertainty of the perception process in terms of safe execution. The results also show that the methodology is more effective than conservative MCR approaches, which avoid all possible object poses regardless of the reported uncertainty.",
        "primary_area": "",
        "author": "Rui Wang;Chaitanya Mitash;Shiyang Lu;Daniel Boehm;Kostas E. Bekris;Rui Wang;Chaitanya Mitash;Shiyang Lu;Daniel Boehm;Kostas E. Bekris",
        "authorids": "/37088013751;/37086289032;/37086579739;/37088690089;/37282424700;/37088013751;/37086289032;/37086579739;/37088690089;/37282424700",
        "aff": "Department of Computer Science, Rutgers University, New Brunswick, NJ, USA; Department of Computer Science, Rutgers University, New Brunswick, NJ, USA; Department of Computer Science, Rutgers University, New Brunswick, NJ, USA; Department of Computer Science, Rutgers University, New Brunswick, NJ, USA; Department of Computer Science, Rutgers University, New Brunswick, NJ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340922/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15083781379494958587&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Rutgers University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.rutgers.edu",
        "aff_unique_abbr": "Rutgers",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "New Brunswick",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341315",
        "title": "Safety Considerations in Deep Control Policies with Safety Barrier Certificates Under Uncertainty",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent advances in Deep Machine Learning have shown promise in solving complex perception and control loops via methods such as reinforcement and imitation learning. However, guaranteeing safety for such learned deep policies has been a challenge due to issues such as partial observability and difficulties in characterizing the behavior of the neural networks. While a lot of emphasis in safe learning has been placed during training, it is non-trivial to guarantee safety at deployment or test time. This paper extends how under mild assumptions, Safety Barrier Certificates can be used to guarantee safety with deep control policies despite uncertainty arising due to perception and other latent variables. Specifically for scenarios where the dynamics are smooth and uncertainty has a finite support, the proposed framework wraps around an existing deep control policy and generates safe actions by dynamically evaluating and modifying the policy from the embedded network. Our framework utilizes control barrier functions to create spaces of control actions that are safe under uncertainty, and when the original actions are found to be in violation of the safety constraint, uses quadratic programming to minimally modify the original actions to ensure they lie in the safe set. Representations of the environment are built through Euclidean signed distance fields that are then used to infer the safety of actions and to guarantee forward invariance. We implement this method in simulation in a drone-racing environment and show that our method results in safer actions compared to a baseline that only relies on imitation learning to generate control actions.",
        "primary_area": "",
        "author": "Tom Hirshberg;Sai Vemprala;Ashish Kapoor;Tom Hirshberg;Sai Vemprala;Ashish Kapoor",
        "authorids": "/37088690080;/37085796013;/37397699500;/37088690080;/37085796013;/37397699500",
        "aff": "CS Department, Technion - Israel Institute of Technology, Haifa, Israel; Microsoft Corporation, Redmond, WA; Microsoft Corporation, Redmond, WA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341315/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6621552545577527974&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Technion - Israel Institute of Technology;Microsoft Corporation",
        "aff_unique_dep": "CS Department;",
        "aff_unique_url": "https://www.technion.ac.il;https://www.microsoft.com",
        "aff_unique_abbr": "Technion;Microsoft",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Haifa;Redmond",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "Israel;United States"
    },
    {
        "id": "9341390",
        "title": "Sample-Efficient Learning for Industrial Assembly using Qgraph-bounded DDPG",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent progress in deep reinforcement learning has enabled agents to autonomously learn complex control strategies from scratch. Model-free approaches like Deep Deterministic Policy Gradients (DDPG) seem promising for applications with intricate dynamics, such as contact-rich manipulation tasks. However, these methods typically require large amounts of training data or meticulous hyperparameter tuning, limiting their usefulness for real-world robotics applications. In this paper, we evaluate and benchmark our recently proposed approach for improving model-free reinforcement learning with DDPG through Qgraph-based bounds in temporal difference learning. We directly apply the algorithm to a challenging real-world industrial insertion task and assess its performance (see https://youtu.be/Z_GcNbCWE-E). Empirical results show that the insertion task can be learned despite significant frictional forces and uncertainty, even in sparse-reward settings. We present an in-depth comparison based on a large number of experiments and demonstrate the advantages and performance of Qgraph-bounded DDPG: the learning process can be significantly sped up, robustified against bad choices of hyperparameters and runs with less memory requirements. Lastly, the presented results extend the current theoretical understanding of the link between data graph structure and soft divergence in DDPG.",
        "primary_area": "",
        "author": "Sabrina Hoppe;Markus Giftthaler;Robert Krug;Marc Toussaint;Sabrina Hoppe;Markus Giftthaler;Robert Krug;Marc Toussaint",
        "authorids": "/37086937814;/37085791761;/37601462700;/37528418600;/37086937814;/37085791761;/37601462700;/37528418600",
        "aff": "University of Stuttgart, Germany; Bosch Center for Artificial Intelligence, Renningen, Germany; Bosch Corporate Research, Renningen, Germany; University of Stuttgart, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341390/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=730135074971844720&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "University of Stuttgart;Bosch Center for Artificial Intelligence;Bosch Corporate Research",
        "aff_unique_dep": ";Artificial Intelligence;",
        "aff_unique_url": "https://www.uni-stuttgart.de;https://www.bosch-ai.com;https://research.bosch.com",
        "aff_unique_abbr": "USTuttgart;BCAI;",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Renningen",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9340839",
        "title": "Sampling-based search for a semi-cooperative target",
        "track": "main",
        "status": "Poster",
        "abstract": "Searching for a lost teammate is an important task for multirobot systems. We present a variant of rapidly-expanding random trees (RRT) for generating search paths based on a probabilistic belief of the target teammate's position. The belief is updated using a hidden Markov model built from knowledge of the target's planned or historic behavior. For any candidate search path, this belief is used to compute a discounted reward which is a weighted sum of the connection probability at each time step. The RRT search algorithm uses randomly sampled locations to generate candidate vertices and adds candidate vertices to a planning tree based on bounds on the discounted reward. Candidate vertices are along the shortest path from an existing vertex to the sampled location, biasing the search based on the topology of the environment. This method produces high quality search paths which are not constrained to a grid and can be computed fast enough to be used in real time. Compared with two other strategies, it found the target significantly faster in the most difficult 60% of situations and was similar in the easier 40% of situations.",
        "primary_area": "",
        "author": "Isaac Vandermeulen;Roderich Gro\u00df;Andreas Kolling;Isaac Vandermeulen;Roderich Gro\u00df;Andreas Kolling",
        "authorids": "/37085373261;/37086937590;/37541684700;/37085373261;/37086937590;/37541684700",
        "aff": "Isaac Vandermeulen is with iRobot, Pasadena, California, USA; Department of Automatic Control and Systems Engineering, The University of Sheffield, Sheffield, UK; Amazon Robotics, North Reading, Massachusetts, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340839/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5682391908500906188&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "iRobot;The University of Sheffield;Amazon Robotics",
        "aff_unique_dep": ";Department of Automatic Control and Systems Engineering;",
        "aff_unique_url": "https://www.irobot.com;https://www.sheffield.ac.uk;https://www.amazonrobotics.com",
        "aff_unique_abbr": "iRobot;Sheffield;Amazon Robotics",
        "aff_campus_unique_index": "0;1;2",
        "aff_campus_unique": "Pasadena;Sheffield;North Reading",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "United States;United Kingdom"
    },
    {
        "id": "9340957",
        "title": "Scalable Collaborative Manipulation with Distributed Trajectory Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a distributed algorithm to enable a group of robots to collaboratively manipulate an object to a desired configuration while avoiding obstacles. Each robot solves a local optimization problem iteratively and communicates with its local neighbors, ultimately converging to the optimal trajectory of the object over a receding horizon. The algorithm scales efficiently to large groups, with a convergence rate constant in the number of robots, and can enforce constraints that are only known to a subset of the robots, such as for collision avoidance using local online sensing. We show that the algorithm converges many orders of magnitude faster, and results in a tracking error two orders of magnitude lower, than competing distributed collaborative manipulation algorithms based on Consensus alternating direction method of multipliers (ADMM).",
        "primary_area": "",
        "author": "Ola Shorinwa;Mac Schwager;Ola Shorinwa;Mac Schwager",
        "authorids": "/37088504638;/37424620600;/37088504638;/37424620600",
        "aff": "",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340957/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11820328325932343976&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4
    },
    {
        "id": "9341303",
        "title": "Scaling Up Multiagent Reinforcement Learning for Robotic Systems: Learn an Adaptive Sparse Communication Graph",
        "track": "main",
        "status": "Poster",
        "abstract": "The complexity of multiagent reinforcement learning (MARL) in multiagent systems increases exponentially with respect to the agent number. This scalability issue prevents MARL from being applied in large-scale multiagent systems. However, one critical feature in MARL that is often neglected is that the interactions between agents are quite sparse. Without exploiting this sparsity structure, existing works aggregate information from all of the agents and thus have a high sample complexity. To address this issue, we propose an adaptive sparse attention mechanism by generalizing a sparsity-inducing activation function. Then a sparse communication graph in MARL is learned by graph neural networks based on this new attention mechanism. Through this sparsity structure, the agents can communicate in an effective as well as efficient way via only selectively attending to agents that matter the most and thus the scale of the MARL problem is reduced with little optimality compromised. Comparative results show that our algorithm can learn an interpretable sparse structure and outperforms previous works by a significant margin on applications involving a large-scale multiagent system.",
        "primary_area": "",
        "author": "Chuangchuang Sun;Macheng Shen;Jonathan P. How;Chuangchuang Sun;Macheng Shen;Jonathan P. How",
        "authorids": "/37085353469;/37086159756;/37276347700;/37085353469;/37086159756;/37276347700",
        "aff": "Laboratory for Information and Decision Systems, Massachusetts Institute of Technology, Cambridge, MA; Laboratory for Information and Decision Systems, Massachusetts Institute of Technology, Cambridge, MA; Laboratory for Information and Decision Systems, Massachusetts Institute of Technology, Cambridge, MA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341303/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12255598641438782929&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Laboratory for Information and Decision Systems",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341309",
        "title": "Scaling laws for parallel motor-gearbox arrangements",
        "track": "main",
        "status": "Poster",
        "abstract": "Research towards (compliant) actuators, especially redundant ones like the Series Parallel Elastic Actuator (SPEA), has led to the development of drive trains, which have demonstrated to increase efficiency, torque-to-mass-ratio, power-to-mass ratio, etc. In the field of robotics such drive trains can be implemented, enabling technological improvements like safe, adaptable and energy-efficient robots. The choice of the used motor and transmission system, as well as the compliant elements composing the drive train, are highly dependent of the application and more specifically on the allowable weight and size. In order to optimally design an actuator adapted to the desired characteristics and the available space, scaling laws governing the specific actuator can simplify and enhance the reliability of the design process. Although scaling laws of electric motors and links are known, none have been investigated for a complete redundant drive train. The present study proposes to fill this gap by providing scaling laws for electric motors in combination with their transmission system. These laws are extended towards parallelization, i.e. replacing one big motor with gearbox by several smaller ones in parallel. The results of this study show that the torque/mass ratio for a motor-gearbox can not be increased by parallelization, but that it can increase the torque/volume ratio. This is however only the case if a good topology is chosen.",
        "primary_area": "",
        "author": "Elias Saerens;Stein Crispel;Pablo L\u00f3pez Garc\u00eda;Vincent Ducastel;Jarl Beckers;Joris De Winter;Rapha\u00ebl Furn\u00e9mont;Bram Vanderborght;Tom Verstraten;Dirk Lefeber;Elias Saerens;Stein Crispel;Pablo L\u00f3pez Garc\u00eda;Vincent Ducastel;Jarl Beckers;Joris De Winter;Rapha\u00ebl Furn\u00e9mont;Bram Vanderborght;Tom Verstraten;Dirk Lefeber",
        "authorids": "/37086301634;/37087051472;/37088685943;/37087045315;/37088691272;/37088689642;/37085427907;/37295389300;/37085436323;/37295410400;/37086301634;/37087051472;/37088685943;/37087045315;/37088691272;/37088689642;/37085427907;/37295389300;/37085436323;/37295410400",
        "aff": "Department of Mechanical Engineering, Robotics & Multibody Mechanics Research Group (R&MM), Vrije Universiteit Brussel (VUB) and Flanders Make, Brussels, Belgium; Department of Mechanical Engineering, Robotics & Multibody Mechanics Research Group (R&MM), Vrije Universiteit Brussel (VUB) and Flanders Make, Brussels, Belgium; Department of Mechanical Engineering, Robotics & Multibody Mechanics Research Group (R&MM), Vrije Universiteit Brussel (VUB) and Flanders Make, Brussels, Belgium; Department of Mechanical Engineering, Robotics & Multibody Mechanics Research Group (R&MM), Vrije Universiteit Brussel (VUB) and Flanders Make, Brussels, Belgium; Department of Mechanical Engineering, Robotics & Multibody Mechanics Research Group (R&MM), Vrije Universiteit Brussel (VUB) and Flanders Make, Brussels, Belgium; Department of Mechanical Engineering, Robotics & Multibody Mechanics Research Group (R&MM), Vrije Universiteit Brussel (VUB) and Flanders Make, Brussels, Belgium; Department of Mechanical Engineering, Robotics & Multibody Mechanics Research Group (R&MM), Vrije Universiteit Brussel (VUB) and Flanders Make, Brussels, Belgium; Department of Mechanical Engineering, Robotics & Multibody Mechanics Research Group (R&MM), Vrije Universiteit Brussel (VUB) and Flanders Make, Brussels, Belgium; Department of Mechanical Engineering, Robotics & Multibody Mechanics Research Group (R&MM), Vrije Universiteit Brussel (VUB) and Flanders Make, Brussels, Belgium; Department of Mechanical Engineering, Robotics & Multibody Mechanics Research Group (R&MM), Vrije Universiteit Brussel (VUB) and Flanders Make, Brussels, Belgium",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341309/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3772153516322124201&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 20,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Vrije Universiteit Brussel",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.vub.be",
        "aff_unique_abbr": "VUB",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Brussels",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "Belgium"
    },
    {
        "id": "9340884",
        "title": "Secure Route Planning Using Dynamic Games with Stopping States",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper studies a motion planning problem over a roadmap in which a vehicle aims to travel from a start to a destination in presence of an attacker who can launch a cyber-attack on the vehicle over any one edge of the roadmap. The vehicle (defender) has the capability to switch on/off a countermeasure that can detect and permanently disable the attack if it occurs concurrently. We first model the problem of traversing an edge as a zero-sum dynamic game with a stopping state, termed as an edge-game played between an attacker and defender. We characterize Nash equilibria of the edge-game and provide closed form expressions for the case of two actions per player. We further provide an analytic and approximate expression on the value of an edge-game and characterize conditions under which it grows sub-linearly with the length of the edge. We study the sensitivity of Nash equilibrium to the (i) cost of using the countermeasure, (ii) cost of motion and (iii) benefit of disabling the attack. The solution of the edge-game is used to formulate and solve the secure route planning problem. We design an efficient heuristic by converting the problem to a shortest path problem using the edge cost as the solution of corresponding edge-games. We illustrate our findings through several insightful simulations.",
        "primary_area": "",
        "author": "Sandeep Banik;Shaunak D. Bopardikar;Sandeep Banik;Shaunak D. Bopardikar",
        "authorids": "/37086851355;/37076274700;/37086851355;/37076274700",
        "aff": "Department of Electrical and Computer Engineering, Michigan State University, East Lansing, MI, USA; Department of Electrical and Computer Engineering, Michigan State University, East Lansing, MI, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340884/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13291588815890468547&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Michigan State University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.msu.edu",
        "aff_unique_abbr": "MSU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "East Lansing",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341517",
        "title": "Seed: A Segmentation-Based Egocentric 3D Point Cloud Descriptor for Loop Closure Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Place recognition is essential for SLAM system since it is critical for loop closure and can help to correct the accumulated drift and result in a globally consistent map. Unlike the visual slam which can use diverse feature detection methods to describe the scene, there are limited works reported to represent a place using single LiDAR scan. In this paper, we propose a segmentation-based egocentric descriptor termed Seed by using a single LiDAR scan to describe the scene. Through the segmentation approach, we first obtain different segmented objects, which can reduce the noise and resolution effect, making it more robust. Then, the topological information of the segmented objects is encoded into the descriptor. Unlike other reported approaches, the proposed method is rotation invariant and insensitive to translation variation. The feasibility of proposed method is evaluated through the KITTI dataset and the results show that the proposed method outperforms the state-of-the-art method in terms of accuracy.",
        "primary_area": "",
        "author": "Yunfeng Fan;Yichang He;U-Xuan Tan;Yunfeng Fan;Yichang He;U-Xuan Tan",
        "authorids": "/37085846226;/37086577031;/37085617165;/37085846226;/37086577031;/37085617165",
        "aff": "Pillar of Engineering Product Development, Singapore University of Technology and Design, Singapore; Pillar of Engineering Product Development, Singapore University of Technology and Design, Singapore; Pillar of Engineering Product Development, Singapore University of Technology and Design, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341517/",
        "gs_citation": 41,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15347770248563274655&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Singapore University of Technology and Design",
        "aff_unique_dep": "Pillar of Engineering Product Development",
        "aff_unique_url": "https://www.sutd.edu.sg",
        "aff_unique_abbr": "SUTD",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "9340918",
        "title": "Segmentation-Based 4D Registration of Plants Point Clouds for Phenotyping",
        "track": "main",
        "status": "Poster",
        "abstract": "Plant phenotyping, i.e., the task of measuring plant traits to describe the anatomy and physiology of plants, is a central task in crop science and plant breeding. Standard methods often require intrusive or time-consuming operations involving a lot of manual labor. Cameras or range sensors, paired with 3D reconstructions methods, can support phenotyping but the task yields several challenges in practice such as plant growth over time. In this paper, we address the problem of finding correspondences between plants recorded at different points in time to track phenotypic traits in an automated fashion. Our approach makes use of semantic segmentation and unsupervised clustering to compute keypoints from plant point clouds. We extract a compact representation of the considered scan that encodes both, topology and semantic information. Through our approach, we are able to tackle the data association problem for 4D point cloud data of plants effectively. We tested our approach on different 3D plus time, i.e., 4D, sequences of plant point clouds of different plant species. The experiments presented in this paper suggest that our 4D matching approach allows for non-rigid registration of the plants that change over time. Moreover, we show that our method allows for tracking different phenotyping traits at an organ level, forming a basis for automated temporal phenotyping.",
        "primary_area": "",
        "author": "Federico Magistri;Nived Chebrolu;Cyrill Stachniss;Federico Magistri;Nived Chebrolu;Cyrill Stachniss",
        "authorids": "/37086805350;/37086411047;/37329668600;/37086805350;/37086411047;/37329668600",
        "aff": "University of Bonn, Germany; University of Bonn, Germany; University of Bonn, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340918/",
        "gs_citation": 58,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16038118815318927953&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Bonn",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.uni-bonn.de",
        "aff_unique_abbr": "UBonn",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9341076",
        "title": "Self-Adapting Recurrent Models for Object Pushing from Learning in Simulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Planar pushing remains a challenging research topic, where building the dynamic model of the interaction is the core issue. Even an accurate analytical dynamic model is inherently unstable because physics parameters such as inertia and friction can only be approximated. Data-driven models usually rely on large amounts of training data, but data collection is time consuming when working with real robots.In this paper, we collect all training data in a physics simulator and build an LSTM-based model to fit the pushing dynamics. Domain Randomization is applied to capture the pushing trajectories of a generalized class of objects. When executed on the real robot, the trained recursive model adapts to the tracked object's real dynamics within a few steps. We propose the algorithm Recurrent Model Predictive Path Integral (RMPPI) as a variation of the original MPPI approach, employing state-dependent recurrent models. As a comparison, we also train a Deep Deterministic Policy Gradient (DDPG) network as a model-free baseline, which is also used as the action generator in the data collection phase. During policy training, Hindsight Experience Replay is used to improve exploration efficiency. Pushing experiments on our UR5 platform demonstrate the model's adaptability and the effectiveness of the proposed framework.",
        "primary_area": "",
        "author": "Lin Cong;Michael Grner;Philipp Ruppel;Hongzhuo Liang;Norman Hendrich;Jianwei Zhang;Lin Cong;Michael Grner;Philipp Ruppel;Hongzhuo Liang;Norman Hendrich;Jianwei Zhang",
        "authorids": "/37088686324;/37088687233;/37086456160;/37086700920;/37449613700;/37281460600;/37088686324;/37088687233;/37086456160;/37086700920;/37449613700;/37281460600",
        "aff": "Department of Informatics, University of Hamburg; Department of Informatics, University of Hamburg; Department of Informatics, University of Hamburg; Department of Informatics, University of Hamburg; Department of Informatics, University of Hamburg; Department of Informatics, University of Hamburg",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341076/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12094565664400477789&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of Hamburg",
        "aff_unique_dep": "Department of Informatics",
        "aff_unique_url": "https://www.uni-hamburg.de",
        "aff_unique_abbr": "UHH",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9340841",
        "title": "Self-Assessment of Grasp Affordance Transfer",
        "track": "main",
        "status": "Poster",
        "abstract": "Reasoning about object grasp affordances allows an autonomous agent to estimate the most suitable grasp to execute a task. While current approaches for estimating grasp affordances are effective, their prediction is driven by hypotheses on visual features rather than an indicator of a proposal's suitability for an affordance task. Consequently, these works cannot guarantee any level of performance when executing a task and, in fact, not even ensure successful task completion. In this work, we present a pipeline for self-assessment of grasp affordance transfer (SAGAT) based on prior experiences. We visually detect a grasp affordance region to extract multiple grasp affordance configuration candidates. Using these candidates, we forward simulate the outcome of executing the affordance task to analyse the relation between task outcome and grasp candidates. The relations are ranked by performance success with a heuristic confidence function and used to build a library of affordance task experiences. The library is later queried to perform one-shot transfer estimation of the best grasp configuration on new objects. Experimental evaluation shows that our method exhibits a significant performance improvement up to 11.7% against current state-of-the-art methods on grasp affordance detection. Experiments on a PR2 robotic platform demonstrate our method's highly reliable deployability to deal with real-world task affordance problems.",
        "primary_area": "",
        "author": "Paola Ard\u00f3n;\u00c8ric Pairet;Yvan Petillot;Ronald P. A. Petrick;Subramanian Ramamoorthy;Katrin S. Lohan;Paola Ard\u00f3n;\u00c8ric Pairet;Yvan Petillot;Ronald P. A. Petrick;Subramanian Ramamoorthy;Katrin S. Lohan",
        "authorids": "/37086803174;/37085611025;/37282015500;/37085392201;/37529920500;/37888866100;/37086803174;/37085611025;/37282015500;/37085392201;/37529920500;/37888866100",
        "aff": "Edinburgh Centre for Robotics, University of Edinburgh and Heriot-Watt University, Edinburgh, UK; Edinburgh Centre for Robotics, University of Edinburgh and Heriot-Watt University, Edinburgh, UK; Edinburgh Centre for Robotics, University of Edinburgh and Heriot-Watt University, Edinburgh, UK; Edinburgh Centre for Robotics, University of Edinburgh and Heriot-Watt University, Edinburgh, UK; Edinburgh Centre for Robotics, University of Edinburgh and Heriot-Watt University, Edinburgh, UK; Edinburgh Centre for Robotics, University of Edinburgh and Heriot-Watt University, Edinburgh, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340841/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5479052978502409742&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 13,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of Edinburgh",
        "aff_unique_dep": "Edinburgh Centre for Robotics",
        "aff_unique_url": "https://www.ed.ac.uk",
        "aff_unique_abbr": "UE",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Edinburgh",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9340820",
        "title": "Self-Supervised Attention Learning for Depth and Ego-motion Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "We address the problem of depth and ego-motion estimation from image sequences. Recent advances in the domain propose to train a deep learning model for both tasks using image reconstruction in a self-supervised manner. We revise the assumptions and the limitations of the current approaches and propose two improvements to boost the performance of the depth and ego-motion estimation. We first use Lie group properties to enforce the geometric consistency between images in the sequence and their reconstructions. We then propose a mechanism to pay attention to image regions where the image reconstruction gets corrupted. We show how to integrate the attention mechanism in the form of attention gates in the pipeline and use attention coefficients as a mask. We evaluate the new architecture on the KITTI datasets and compare it to the previous techniques. We show that our approach improves the state-of-the-art results for ego-motion estimation and achieve comparable results for depth estimation.",
        "primary_area": "",
        "author": "Assem Sadek;Boris Chidlovskii;Assem Sadek;Boris Chidlovskii",
        "authorids": "/37088686419;/37373194900;/37088686419;/37373194900",
        "aff": "Naver Labs Europe, Meylan, France; Naver Labs Europe, Meylan, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340820/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14911145621448614482&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Naver Labs Europe",
        "aff_unique_dep": "",
        "aff_unique_url": "https://labs.naver.com",
        "aff_unique_abbr": "NLE",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Meylan",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9341005",
        "title": "Self-healing Cell Tactile Sensor Fabricated Using Ultraflexible Printed Electrodes",
        "track": "main",
        "status": "Poster",
        "abstract": "We used cells, which are the units that make up a living body, as building blocks to design a biomachine hybrid system and develop a tactile sensor that uses living cells as sensor receptors. We fabricated a novel cell tactile sensor with the electrodes formed using printed electronics technology. This sensor comprises elastic electrodes mounted on a soft material to acquire tactile information; similar to a conventional cell tactile sensor, it acquires signals through mechanical stimulation. Further, self-organization of cells can be induced, and logical processing such as selective responses to stimuli can be performed directly by the physical system, without any coding using programming languages. The proposed novel cell tactile sensor that uses printed electrodes is small enough to mount on robots. Interestingly, we confirmed the self-healing properties of the proposed sensor after cells were injured mechanically.",
        "primary_area": "",
        "author": "Masahiro Shimizu;Toshinori Fujie;Takuya Umedachi;Shunsuke Shigaki;Hiroki Kawashima;Masato Saito;Hirono Ohashi;Koh Hosoda;Masahiro Shimizu;Toshinori Fujie;Takuya Umedachi;Shunsuke Shigaki;Hiroki Kawashima;Masato Saito;Hirono Ohashi;Koh Hosoda",
        "authorids": "/38541662800;/38107893500;/37546535500;/37085895425;/37088553699;/37088689600;/37088236032;/37270101900;/38541662800;/38107893500;/37546535500;/37085895425;/37088553699;/37088689600;/37088236032;/37270101900",
        "aff": "Department of System Innovation, Osaka University, Japan; School of Life Science and Technology, Tokyo Institute of Technology, Japan; Textile Science and Technology, Shinshu University, Japan; Department of System Innovation, Osaka University, Japan; Department of System Innovation, Osaka University, Japan; School of Life Science and Technology, Tokyo Institute of Technology, Japan; Department of System Innovation, Osaka University, Japan; Department of System Innovation, Osaka University, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341005/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17655080185154031733&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;2;0;0;1;0;0",
        "aff_unique_norm": "Osaka University;Tokyo Institute of Technology;Shinshu University",
        "aff_unique_dep": "Department of System Innovation;School of Life Science and Technology;Textile Science and Technology",
        "aff_unique_url": "https://www.osaka-u.ac.jp;https://www.titech.ac.jp;https://www.shinshu-u.ac.jp",
        "aff_unique_abbr": "Osaka U;Titech;Shinshu U",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9341300",
        "title": "Self-reconfiguration planning of adaptive modular robots with triangular structure based on extended binary trees",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a novel description for the configuration space of adaptive modular robots with a triangular structure based on extended binary trees. In general, binary trees can serve as a representation of kinematic trees with a maximum of two immediate descendants per element. Kinematic loops are incorporated in the tree structure by an ingenious extension of the binary tree indices. The introduction of equivalence classes then allows a unique mathematical description of specific configurations of the robot system. Subsequently, we show how the extended binary tree can serve as a systematic tool for reconfiguration planning, allowing to solve the self-reconfiguration problem for modular robots with a triangular structure, which has as yet no general solution. Reconfiguration is performed by populating the binary tree indices of a desired target configuration in an ascending manner, moving modules along the surface of the robot. We demonstrate the planning algorithm on a simple example and conclude by outlining a way to translate the individual reconfiguration steps to specific module movement commands.",
        "primary_area": "",
        "author": "Michael Gerbl;Johannes Gerstmayr;Michael Gerbl;Johannes Gerstmayr",
        "authorids": "/37088687920;/37086574700;/37088687920;/37086574700",
        "aff": "Department of Mechatronics, University of Innsbruck, Innsbruck, Austria; Department of Mechatronics, University of Innsbruck, Innsbruck, Austria",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341300/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2897903265780378327&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Innsbruck",
        "aff_unique_dep": "Department of Mechatronics",
        "aff_unique_url": "https://www.uibk.ac.at",
        "aff_unique_abbr": "UIBK",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Innsbruck",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Austria"
    },
    {
        "id": "9341087",
        "title": "Self-sensing Soft Tactile Actuator for Fingertip Interface",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we report a self-sensing soft tactile actuator based on Dielectric elastomer actuator (DEA) for wearable haptic interface. DEAs are one of electroactive polymer actuators, which are reported to have large area strain and fast response speed. A soft tactile actuator is constructed of a multi-layered DEA membrane layer, a passive membrane layer, and an inner circular pillar. The soft actuator was optimized by varying the geometry, and the force and displacement tests were conducted under a frequency range of 0 to 30 Hz. The selected actuator produces an output force up to 0.9 N, with a displacement of 1.43 mm. To provide accurate physical force feedback to the user, the actuator is integrated with a 1.1 mm thick film-type soft force sensor that enables feedback control. Under the pressure, touch layer contacts with the core, and the light inside the core scatters to the touch layer. A fabricated soft force sensor can measure the force in a range of 0 to 1.25 N under various frequency ranges. Our wearable prototype exhibits high output force of 0.9 N, as well as flexibility, conformity, and light-weight structure (3.2 g).",
        "primary_area": "",
        "author": "Jung-Hwan Youn;Ibrahim Bin Yasir;Ki-Uk Kyung;Jung-Hwan Youn;Ibrahim Bin Yasir;Ki-Uk Kyung",
        "authorids": "/37088689454;/37088689123;/37283149200;/37088689454;/37088689123;/37283149200",
        "aff": "Department of Mechanical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea; Department of Mechanical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea; Department of Mechanical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341087/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10861553789743771193&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.kaist.ac.kr",
        "aff_unique_abbr": "KAIST",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Daejeon",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9340938",
        "title": "Self-supervised Neural Audio-Visual Sound Source Localization via Probabilistic Spatial Modeling",
        "track": "main",
        "status": "Poster",
        "abstract": "Detecting sound source objects within visual observation is important for autonomous robots to comprehend surrounding environments. Since sounding objects have a large variety with different appearances in our living environments, labeling all sounding objects is impossible in practice. This calls for self-supervised learning which does not require manual labeling. Most of conventional self-supervised learning uses monaural audio signals and images and cannot distinguish sound source objects having similar appearances due to poor spatial information in audio signals. To solve this problem, this paper presents a self-supervised training method using 360\u00b0 images and multichannel audio signals. By incorporating with the spatial information in multichannel audio signals, our method trains deep neural networks (DNNs) to distinguish multiple sound source objects. Our system for localizing sound source objects in the image is composed of audio and visual DNNs. The visual DNN is trained to localize sound source candidates within an input image. The audio DNN verifies whether each candidate actually produces sound or not. These DNNs are jointly trained in a self-supervised manner based on a probabilistic spatial audio model. Experimental results with simulated data showed that the DNNs trained by our method localized multiple speakers. We also demonstrate that the visual DNN detected objects including talking visitors and specific exhibits from real data recorded in a science museum.",
        "primary_area": "",
        "author": "Yoshiki Masuyama;Yoshiaki Bando;Kohei Yatabe;Yoko Sasaki;Masaki Onishi;Yasuhiro Oikawa;Yoshiki Masuyama;Yoshiaki Bando;Kohei Yatabe;Yoko Sasaki;Masaki Onishi;Yasuhiro Oikawa",
        "authorids": "/37086454054;/37085462443;/37085481014;/37418160900;/37279716500;/37425682700;/37086454054;/37085462443;/37085481014;/37418160900;/37279716500;/37425682700",
        "aff": "Department of Intermedia Art and Science, Waseda University, Japan; National Institute of Advanced Industrial Science and Technology, Japan; Department of Intermedia Art and Science, Waseda University, Japan; National Institute of Advanced Industrial Science and Technology, Japan; National Institute of Advanced Industrial Science and Technology, Japan; Department of Intermedia Art and Science, Waseda University, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340938/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7708465209724824059&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;1;1;0",
        "aff_unique_norm": "Waseda University;National Institute of Advanced Industrial Science and Technology",
        "aff_unique_dep": "Department of Intermedia Art and Science;",
        "aff_unique_url": "https://www.waseda.jp/top;https://www.aist.go.jp",
        "aff_unique_abbr": "Waseda;AIST",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9341621",
        "title": "Self-supervised Object Tracking with Cycle-consistent Siamese Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Self-supervised learning for visual object tracking possesses valuable advantages compared to supervised learning, such as the non-necessity of laborious human annotations and online training. In this work, we exploit an end-to-end Siamese network in a cycle-consistent self-supervised framework for object tracking. Self-supervision can be performed by taking advantage of the cycle consistency in the forward and backward tracking. To better leverage the end-to-end learning of deep networks, we propose to integrate a Siamese region proposal and mask regression network in our tracking framework so that a fast and more accurate tracker can be learned without the annotation of each frame. The experiments on the VOT dataset for visual object tracking and on the DAVIS dataset for video object segmentation propagation show that our method outperforms prior approaches on both tasks.",
        "primary_area": "",
        "author": "Weihao Yuan;Michael Yu Wang;Qifeng Chen;Weihao Yuan;Michael Yu Wang;Qifeng Chen",
        "authorids": "/37086455209;/37280913900;/37087230927;/37086455209;/37280913900;/37087230927",
        "aff": "Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong SAR, China; Department of Mechanical and Aerospace Engineering and the Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong SAR, China; Department of Computer Science and Engineering and the Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong SAR, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341621/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8297681315771919437&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Hong Kong University of Science and Technology",
        "aff_unique_dep": "Department of Electronic and Computer Engineering",
        "aff_unique_url": "https://www.ust.hk",
        "aff_unique_abbr": "HKUST",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Hong Kong SAR",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9340840",
        "title": "Self-supervised Simultaneous Alignment and Change Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "This study proposes a self-supervised method for detecting scene changes from an image pair. For mobile cameras such as drive recorders, to alleviate the camera viewpoints' difference, image alignment and change detection must be optimized simultaneously because they depend on each other. Moreover, lighting condition makes the scene change detection more difficult because it widely varies in images taken at different times. To solve these challenges, we propose a self-supervised simultaneous alignment and change detection net-work (SACD-Net). The proposed network is robust specifically in differences of camera viewpoints and lighting conditions to simultaneously estimate warping parameters and multi-scale change probability maps while change regions are not taken into account of calculation of the feature consistency and semantic losses. Based on comparative analysis between our self-supervised and the previous supervised models as well as ablation study of the losses of SACD-Net, the results show the effectiveness of the proposed method using a synthetic dataset and our new real dataset.",
        "primary_area": "",
        "author": "Yukuko Furukawa;Kumiko Suzuki;Ryuhei Hamaguchi;Masaki Onishi;Ken Sakurada;Yukuko Furukawa;Kumiko Suzuki;Ryuhei Hamaguchi;Masaki Onishi;Ken Sakurada",
        "authorids": "/37088690206;/37088686548;/37086377082;/37279716500;/37603745700;/37088690206;/37088686548;/37086377082;/37279716500;/37603745700",
        "aff": "National Institute of Advanced Industrial Science and Technology, Tokyo, Japan; National Institute of Advanced Industrial Science and Technology, Tokyo, Japan; National Institute of Advanced Industrial Science and Technology, Tokyo, Japan; National Institute of Advanced Industrial Science and Technology, Tokyo, Japan; National Institute of Advanced Industrial Science and Technology, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340840/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1086786025956529263&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "National Institute of Advanced Industrial Science and Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.aist.go.jp",
        "aff_unique_abbr": "AIST",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9340814",
        "title": "SelfieDroneStick: A Natural Interface for Quadcopter Photography",
        "track": "main",
        "status": "Poster",
        "abstract": "A physical selfie stick extends the user's reach, enabling the acquisition of personal photos that include more of the background scene. Similarly, a quadcopter can capture photos from vantage points unattainable by the user; but teleoperating a quadcopter to good viewpoints is a difficult task. This paper presents a natural interface for quadcopter photography, the SelfieDroneStick that allows the user to guide the quadcopter to the optimal vantage point based on the phone's sensors. Users specify the composition of their desired long-range selfies using their smartphone, and the quadcopter autonomously flies to a sequence of vantage points from where the desired shots can be taken. The robot controller is trained from a combination of real-world images and simulated flight data. This paper describes two key innovations required to deploy deep reinforcement learning models on a real robot: 1) an abstract state representation for transferring learning from simulation to the hardware platform, and 2) reward shaping and staging paradigms for training the controller. Both of these improvements were found to be essential in learning a robot controller from simulation that transfers successfully to the real robot.",
        "primary_area": "",
        "author": "Saif Alabachi;Gita Sukthankar;Rahul Sukthankar;Saif Alabachi;Gita Sukthankar;Rahul Sukthankar",
        "authorids": "/37086938095;/37285072600;/37282878500;/37086938095;/37285072600;/37282878500",
        "aff": "University of Technology, Baghdad, Iraq; Department of Computer Science, University of Central Florida, Orlando, FL; Google",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340814/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14255297522746534233&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "University of Technology;University of Central Florida;Google",
        "aff_unique_dep": ";Department of Computer Science;",
        "aff_unique_url": ";https://www.ucf.edu;https://www.google.com",
        "aff_unique_abbr": ";UCF;Google",
        "aff_campus_unique_index": "0;1;2",
        "aff_campus_unique": "Baghdad;Orlando;Mountain View",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "Iraq;United States"
    },
    {
        "id": "9341060",
        "title": "Semantic Graph Based Place Recognition for 3D Point Clouds",
        "track": "main",
        "status": "Poster",
        "abstract": "Due to the difficulty in generating the effective descriptors which are robust to occlusion and viewpoint changes, place recognition for 3D point cloud remains an open issue. Unlike most of the existing methods that focus on extracting local, global, and statistical features of raw point clouds, our method aims at the semantic level that can be superior in terms of robustness to environmental changes. Inspired by the perspective of humans, who recognize scenes through identifying semantic objects and capturing their relations, this paper presents a novel semantic graph based approach for place recognition. First, we propose a novel semantic graph representation for the point cloud scenes by reserving the semantic and topological information of the raw point cloud. Thus, place recognition is modeled as a graph matching problem. Then we design a fast and effective graph similarity network to compute the similarity. Exhaustive evaluations on the KITTI dataset show that our approach is robust to the occlusion as well as viewpoint changes and outperforms the state-of-the-art methods with a large margin. Our code is available at: https://github.com/kxhit/SG_PR.",
        "primary_area": "",
        "author": "Xin Kong;Xuemeng Yang;Guangyao Zhai;Xiangrui Zhao;Xianfang Zeng;Mengmeng Wang;Yong Liu;Wanlong Li;Feng Wen;Xin Kong;Xuemeng Yang;Guangyao Zhai;Xiangrui Zhao;Xianfang Zeng;Mengmeng Wang;Yong Liu;Wanlong Li;Feng Wen",
        "authorids": "/37087322070;/37088455828;/37087322612;/37087122595;/37088456760;/37086177757;/37066946100;/37088687641;/37088690190;/37087322070;/37088455828;/37087322612;/37087122595;/37088456760;/37086177757;/37066946100;/37088687641;/37088690190",
        "aff": "Institute of Cyber-Systems and Control, Zhe-jiang University, Hangzhou, China; Institute of Cyber-Systems and Control, Zhe-jiang University, Hangzhou, China; Institute of Cyber-Systems and Control, Zhe-jiang University, Hangzhou, China; Institute of Cyber-Systems and Control, Zhe-jiang University, Hangzhou, China; Institute of Cyber-Systems and Control, Zhe-jiang University, Hangzhou, China; Institute of Cyber-Systems and Control, Zhe-jiang University, Hangzhou, China; Institute of Cyber-Systems and Control, Zhe-jiang University, Hangzhou, China; Huawei Noah\u2019s Ark Lab, Beijing, China; Huawei Noah\u2019s Ark Lab, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341060/",
        "gs_citation": 147,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17156978401149623495&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;0;0;0;0;1;1",
        "aff_unique_norm": "Zhe-jiang University;Huawei Noah\u2019s Ark Lab",
        "aff_unique_dep": "Institute of Cyber-Systems and Control;",
        "aff_unique_url": "http://www.zju.edu.cn;https://www.huawei.com/en/ai/noahs-ark-lab",
        "aff_unique_abbr": "ZJU;HNA Lab",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;1;1",
        "aff_campus_unique": "Hangzhou;Beijing",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9340821",
        "title": "Semantic Segmentation of Underwater Imagery: Dataset and Benchmark",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present the first large-scale dataset for semantic Segmentation of Underwater IMagery (SUIM). It contains over 1500 images with pixel annotations for eight object categories: fish (vertebrates), reefs (invertebrates), aquatic plants, wrecks/ruins, human divers, robots, and sea-floor. The images have been rigorously collected during oceanic explorations and human-robot collaborative experiments, and annotated by human participants. We also present a comprehensive benchmark evaluation of several state-of-the-art semantic segmentation approaches based on standard performance metrics. Additionally, we present SUIM-Net, a fully-convolutional deep residual model that balances the trade-off between performance and computational efficiency. It offers competitive performance while ensuring fast end-to-end inference, which is essential for its use in the autonomy pipeline by visually-guided underwater robots. In particular, we demonstrate its usability benefits for visual servoing, saliency prediction, and detailed scene understanding. With a variety of use cases, the proposed model and benchmark dataset open up promising opportunities for future research in underwater robot vision.",
        "primary_area": "",
        "author": "Md Jahidul Islam;Chelsey Edge;Yuyang Xiao;Peigen Luo;Muntaqim Mehtaz;Christopher Morse;Sadman Sakib Enan;Junaed Sattar;Md Jahidul Islam;Chelsey Edge;Yuyang Xiao;Peigen Luo;Muntaqim Mehtaz;Christopher Morse;Sadman Sakib Enan;Junaed Sattar",
        "authorids": "/37085652546;/37086933249;/37088686463;/37088504541;/37088688403;/37086237482;/37088690306;/37546394500;/37085652546;/37086933249;/37088686463;/37088504541;/37088688403;/37086237482;/37088690306;/37546394500",
        "aff": "Department of Computer Science and Engineering (CSE), Interactive Robotics and Vision Laboratory (IRVLab), Minnesota Robotics Institute (MnRI), University of Minnesota, Twin Cities, US; Department of Computer Science and Engineering (CSE), Interactive Robotics and Vision Laboratory (IRVLab), Minnesota Robotics Institute (MnRI), University of Minnesota, Twin Cities, US; Department of Computer Science and Engineering (CSE), Interactive Robotics and Vision Laboratory (IRVLab), Minnesota Robotics Institute (MnRI), University of Minnesota, Twin Cities, US; Department of Computer Science and Engineering (CSE), Interactive Robotics and Vision Laboratory (IRVLab), Minnesota Robotics Institute (MnRI), University of Minnesota, Twin Cities, US; Department of Computer Science and Engineering (CSE), Interactive Robotics and Vision Laboratory (IRVLab), Minnesota Robotics Institute (MnRI), University of Minnesota, Twin Cities, US; Department of Computer Science and Engineering (CSE), Interactive Robotics and Vision Laboratory (IRVLab), Minnesota Robotics Institute (MnRI), University of Minnesota, Twin Cities, US; Department of Computer Science and Engineering (CSE), Interactive Robotics and Vision Laboratory (IRVLab), Minnesota Robotics Institute (MnRI), University of Minnesota, Twin Cities, US; Department of Computer Science and Engineering (CSE), Interactive Robotics and Vision Laboratory (IRVLab), Minnesota Robotics Institute (MnRI), University of Minnesota, Twin Cities, US",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340821/",
        "gs_citation": 271,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10323997495927986937&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;0;0;0",
        "aff_unique_norm": "University of Minnesota",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.minnesota.edu",
        "aff_unique_abbr": "UMN",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Twin Cities",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341441",
        "title": "Semantic Trajectory Planning for Long-Distant Unmanned Aerial Vehicle Navigation in Urban Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "There has been a considerable amount of recent work on high-speed micro-aerial vehicle flight in unknown and unstructured environments. Generally these approaches either use active sensing or fly slowly enough to ensure a safe braking distance with the relatively short sensing range of passive sensors. The former generally requires carrying large and heavy LIDARs and the latter only allows flight far away from the dynamic limits of the vehicle. One of the significant challenges for high-speed flight is the computational demand of trajectory planning at sufficiently high rates and length scales required in outdoor environments. We tackle both problems in this work by leveraging semantic information derived from an RGB camera on-board the vehicle. We first describe how to use semantic information to increase the effective range of perception on certain environment classes. Second, we present a sparse representation of the environment that is sufficiently lightweight for long distance path planning. We show how our approach outperforms more traditional metric planners which seek the shortest path, demonstrate the semantic planner's capabilities in a set of simulated and excessive real-world autonomous quadrotor flights in an urban environment.",
        "primary_area": "",
        "author": "Markus Ryll;John Ware;John Carter;Nick Roy;Markus Ryll;John Ware;John Carter;Nick Roy",
        "authorids": "/38251847500;/37085381741;/37086453883;/37274058700;/38251847500;/37085381741;/37086453883;/37274058700",
        "aff": "Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, USA; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, USA; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, USA; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341441/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9520952093310916089&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341331",
        "title": "Semi-Autonomous Control of Leader-Follower Excavator using Admittance Control for Synchronization and Autonomy with Bifurcation and Stagnation for Human Interface",
        "track": "main",
        "status": "Poster",
        "abstract": "So far, multiple LCD monitors and joysticks have been used for remote operation of excavators while it has low work efficiency. This is because it is difficult for the operator to recognize the state of the excavator and its surrounding environment. We have developed a semi-autonomous control system which consists of autonomy (attractor based dynamical system) and human action (admittance control). On the other hand, excavation tasks require the task selection. In this paper, we propose a nonlinear dynamical system with attractor with stagnation and bifurcation. The stagnation of the attractor is designed as a negative divergence vector field that converges to a point on the trajectory. A stagnation is placed at a bifurcation point of the trajectory, and the operator selects the next task by adding a force to the leader system.",
        "primary_area": "",
        "author": "Kohei Iwano;Masafumi Okada;Kohei Iwano;Masafumi Okada",
        "authorids": "/37088688046;/37280787800;/37088688046;/37280787800",
        "aff": "Department of Mechanical Engineering, Tokyo Institute of Technology, Meguro-ku, Japan; Department of Mechanical Engineering, Tokyo Institute of Technology, Meguro-ku, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341331/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5333536993910546019&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Tokyo Institute of Technology",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.titech.ac.jp",
        "aff_unique_abbr": "Titech",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Meguro-ku",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9341727",
        "title": "SeqSphereVLAD: Sequence Matching Enhanced Orientation-invariant Place Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "Human beings and animals are capable of recognizing places from a previous journey when viewing them under different environmental conditions (e.g., illuminations and weathers). This paper seeks to provide robots with a human-like place recognition ability using a new point cloud feature learning method. This is a challenging problem due to the difficulty of extracting invariant local descriptors from the same place under various orientation differences and dynamic obstacles. In this paper, we propose a novel lightweight 3D place recognition method, SeqSphereVLAD, which is capable of recognizing places from a previous trajectory regardless of the viewpoint and the temporary observation differences. The major contributions of our method lie in two modules: (1) the spherical convolution feature extraction module, which produces orientation-invariant local place descriptors, and (2) the coarse-to-fine sequence matching module, which ensures both accurate loop-closure detection and real-time performance. Despite the apparent simplicity, our proposed approach outperform the state-of-the-arts for place recognition under datasets that combine orientation and context differences. Compared with the arts, our method can achieve above 95% average recall for the best match with only 18% inference time of PointNet-based place recognition methods.",
        "primary_area": "",
        "author": "Peng Yin;Fuying Wang;Anton Egorov;Jiafan Hou;Ji Zhang;Howie Choset;Peng Yin;Fuying Wang;Anton Egorov;Jiafan Hou;Ji Zhang;Howie Choset",
        "authorids": "/37085692390;/37088691499;/37088501427;/37087245956;/38541910000;/37281322200;/37085692390;/37088691499;/37088501427;/37087245956;/38541910000;/37281322200",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; the department of Electronic Engineering, Tsinghua University, Beijing, China; Skolkovo Institute of Science and Technology, Moscow, Russia; the School of Science and Engineering, The Chinese University of Hong Kong, Shenzhen, China; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341727/",
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9780540362455225432&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;3;0;0",
        "aff_unique_norm": "Carnegie Mellon University;Tsinghua University;Skolkovo Institute of Science and Technology;The Chinese University of Hong Kong",
        "aff_unique_dep": "Robotics Institute;Department of Electronic Engineering;;School of Science and Engineering",
        "aff_unique_url": "https://www.cmu.edu;https://www.tsinghua.edu.cn;https://www.skoltech.ru;https://www.cuhk.edu.cn",
        "aff_unique_abbr": "CMU;THU;Skoltech;CUHK",
        "aff_campus_unique_index": "0;1;2;3;0;0",
        "aff_campus_unique": "Pittsburgh;Beijing;Moscow;Shenzhen",
        "aff_country_unique_index": "0;1;2;1;0;0",
        "aff_country_unique": "United States;China;Russia"
    },
    {
        "id": "9341467",
        "title": "Sequential Motion Planning for Bipedal Somersault via Flywheel SLIP and Momentum Transmission with Task Space Control",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a sequential motion planning and control method for generating somersaults on bipedal robots. The somersault (backflip or frontflip) is considered as a coupling between an axile hopping motion and a rotational motion about the center of mass of the robot; these are encoded by a hopping Spring-loaded Inverted Pendulum (SLIP) model and the rotation of a Flywheel, respectively. We thus present the Flywheel SLIP model for generating the desired motion on the ground phase. In the flight phase, we present a momentum transmission method to adjust the orientation of the lower body based on the conservation of the centroidal momentum. The generated motion plans are realized on the full-dimensional robot via momentum-included task space control. Finally, the proposed method is implemented on a modified version of the bipedal robot Cassie in simulation wherein multiple somersault motions are generated.",
        "primary_area": "",
        "author": "Xiaobin Xiong;Aaron D. Ames;Xiaobin Xiong;Aaron D. Ames",
        "authorids": "/37086275102;/37300877900;/37086275102;/37300877900",
        "aff": "Department of Mechanical and Civil Engineering, California Institute of Technology, Pasadena, CA; Department of Mechanical and Civil Engineering, California Institute of Technology, Pasadena, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341467/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12292700577650115893&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "California Institute of Technology",
        "aff_unique_dep": "Department of Mechanical and Civil Engineering",
        "aff_unique_url": "https://www.caltech.edu",
        "aff_unique_abbr": "Caltech",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Pasadena",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341266",
        "title": "Set-Membership Extrinsic Calibration of a 3D LiDAR and a Camera",
        "track": "main",
        "status": "Poster",
        "abstract": "To fuse information from a 3D Light Detection and Ranging (LiDAR) sensor and a camera, the extrinsic transformation between the sensor coordinate systems needs to be known. Therefore, an extrinsic calibration must be performed, which is usually based on features extracted from sensor data. Naturally, sensor errors can affect the feature extraction process, and thus distort the calibration result. Unlike previous works, which do not consider the uncertainties of the sensors, we propose a set-membership approach that takes all sensor errors into account. Since the actual error distribution of off- the-shelf sensors is often unknown, we assume to only know bounds (or intervals) enclosing the sensor errors and accordingly introduce novel error models for both sensors. Next, we introduce interval-based approaches to extract corresponding features from images and point clouds. Due to the unknown but bounded sensor errors, we cannot determine the features exactly, but compute intervals guaranteed to enclose them. Subsequently, these feature intervals enable us to formulate a Constraint Satisfaction Problem (CSP). Finally, the CSP is solved to find a set of solutions that is guaranteed to contain the true solution and simultaneously reflects the accuracy of the calibration. Experiments using simulated and real data validate our approach and show its advantages over existing methods.",
        "primary_area": "",
        "author": "Raphael Voges;Bernardo Wagner;Raphael Voges;Bernardo Wagner",
        "authorids": "/37086577673;/37276784800;/37086577673;/37276784800",
        "aff": "Real Time Systems Group (RTS), Institute of Systems Engineering, Leibniz Universit\u00e4t Hannover, Hannover, Germany; Real Time Systems Group (RTS), Institute of Systems Engineering, Leibniz Universit\u00e4t Hannover, Hannover, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341266/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2703399605816610221&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Leibniz Universit\u00e4t Hannover",
        "aff_unique_dep": "Institute of Systems Engineering",
        "aff_unique_url": "https://www.leibniz-uni-hannover.de",
        "aff_unique_abbr": "LUH",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Hannover",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9341698",
        "title": "Shape reconstruction of CCD camera-based soft tactile sensors",
        "track": "main",
        "status": "Poster",
        "abstract": "CCD camera-based tactile sensors provide high-resolution information about the deformation of soft and elastic interfaces. However, they have poor scalibility as it is difficult to sense a large surface area without increasing the distance between the camera and the interface or using multiple processing chips. For example, using such tactile sensors for a whole robotic arm is not yet possible. In this work, we demonstrate a data driven method that can reconstruct the high-resolution information about deformation of the soft interface while keeping the space requirements and power consumption relatively low. Our modified tactile sensor incorporates two independent sensing techniques, one low- and one high-resolution, and we learn to map to the latter from the former. As a low-resolution sensor, we use liquid-filled channels that transmit the information from the location of the tactile interaction to a rigid display, where the liquid displacements are tracked by a CCD camera. Simultaneously, the same interaction is measured by tracking the markers on the bottom of the sensor using a second CCD camera. After data collection, we train two different machine learning models to reconstruct the time series of the high-resolution sensor. By training a convolutional autoencoder (CAE) and attaching it to the recurrent neural network (RNN), we demonstrate the reconstruction of high-resolution video frames using only the time series of the low-resolution sensor.",
        "primary_area": "",
        "author": "Gabor Soter;Helmut Hauser;Andrew Conn;Jonathan Rossiter;Kohei Nakajima;Gabor Soter;Helmut Hauser;Andrew Conn;Jonathan Rossiter;Kohei Nakajima",
        "authorids": "/37086415851;/38187504200;/38494905000;/37271190700;/38238899500;/37086415851;/38187504200;/38494905000;/37271190700;/38238899500",
        "aff": "Bristol Robotics Laboratory, United Kingdom; Bristol Robotics Laboratory, United Kingdom; Department of Mechanical Engineering, University of Bristol, United Kingdom; Bristol Robotics Laboratory, United Kingdom; Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341698/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7003539578073617492&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;2",
        "aff_unique_norm": "Bristol Robotics Laboratory;University of Bristol;The University of Tokyo",
        "aff_unique_dep": ";Department of Mechanical Engineering;Graduate School of Information Science and Technology",
        "aff_unique_url": ";https://www.bristol.ac.uk;https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": ";Bristol;UTokyo",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Tokyo",
        "aff_country_unique_index": "0;0;0;0;1",
        "aff_country_unique": "United Kingdom;Japan"
    },
    {
        "id": "9340734",
        "title": "SideGuide:A Large-scale Sidewalk Dataset for Guiding Impaired People",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we introduce a new large-scale sidewalk dataset called SideGuide that could potentially help impaired people. Unlike most previous datasets, which are focused on road environments, we paid attention to sidewalks, where understanding the environment could provide the potential for improved walking of humans, especially impaired people. Concretely, we interviewed impaired people and carefully selected target objects from the interviewees' feedback (objects they encounter on sidewalks). We then acquired two different types of data: crowd-sourced data and stereo data. We labeled target objects at instance-level (i.e., bounding box and polygon mask) and generated a ground-truth disparity map for the stereo data. SideGuide consists of 350K images with bounding box annotation, 100K images with a polygon mask, and 180K stereo pairs with the ground-truth disparity. We analyzed our dataset by performing baseline analysis for object detection, instance segmentation, and stereo matching tasks. In addition, we developed a prototype that recognizes the target objects and measures distances, which could potentially assist people with disabilities. The prototype suggests the possibility of practical application of our dataset in real life.",
        "primary_area": "",
        "author": "Kibaek Park;Youngtaek Oh;Soomin Ham;Kyungdon Joo;Hyokyoung Kim;Hyoyoung Kum;In So Kweon;Kibaek Park;Youngtaek Oh;Soomin Ham;Kyungdon Joo;Hyokyoung Kim;Hyoyoung Kum;In So Kweon",
        "authorids": "/37085440126;/37088686495;/37088689980;/37085436130;/37088691177;/37088690809;/37270474800;/37085440126;/37088686495;/37088689980;/37085436130;/37088691177;/37088690809;/37270474800",
        "aff": "School of Electrical Engineering, KAIST, Daejeon, South Korea; School of Electrical Engineering, KAIST, Daejeon, South Korea; School of Electrical Engineering, KAIST, Daejeon, South Korea; Robotics Institute, Carnegie Mellon University, Pittsburgh, USA; TestWorks, Inc, Seoul, South Korea; TestWorks, Inc, Seoul, South Korea; School of Electrical Engineering, KAIST, Daejeon, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340734/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5594496434585273669&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;1;2;2;0",
        "aff_unique_norm": "KAIST;Carnegie Mellon University;TestWorks, Inc",
        "aff_unique_dep": "School of Electrical Engineering;Robotics Institute;",
        "aff_unique_url": "https://www.kaist.ac.kr;https://www.cmu.edu;",
        "aff_unique_abbr": "KAIST;CMU;",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Daejeon;Pittsburgh;",
        "aff_country_unique_index": "0;0;0;1;0;0;0",
        "aff_country_unique": "South Korea;United States"
    },
    {
        "id": "9340945",
        "title": "Silicone-based Capacitive E-skin for Exteroception and Proprioception",
        "track": "main",
        "status": "Poster",
        "abstract": "Thin and imperceptible soft skins that can detect internal deformations as well as external forces, can go a long way to address perception and control challenges in soft robots. However, decoupling proprioceptive and exteroceptive stimuli is a challenging task. In this paper, we present a silicone-based, capacitive E-skin for exteroception and proprioception (SCEEP). This soft and stretchable sensor can perceive stretch as along with touch at 100 different points via its 100 tactels. In this paper, we present a novel algorithm that decouples global strain from local indentations due to external forces. The soft skin is 10.1cm in length and 10cm in width and can be used to accurately measure the global strain of up to 25% with an error of under 3%; while at the same time, can determine the amplitude and position of local indentations. This is a step towards a fully soft electronic skin that can act as a proprioceptive sensor to measure internal states while measuring external forces.",
        "primary_area": "",
        "author": "Abu Bakar Dawood;Hareesh Godaba;Ahmad Ataka;Kaspar Althoefer;Abu Bakar Dawood;Hareesh Godaba;Ahmad Ataka;Kaspar Althoefer",
        "authorids": "/37088686052;/37085735503;/37085781916;/37265264700;/37088686052;/37085735503;/37085781916;/37265264700",
        "aff": "Centre for Advanced Robotics @ Queen Mary, Queen Mary University of London, London, United Kingdom; Centre for Advanced Robotics @ Queen Mary, Queen Mary University of London, London, United Kingdom; Centre for Advanced Robotics @ Queen Mary, Queen Mary University of London, London, United Kingdom; Centre for Advanced Robotics @ Queen Mary, Queen Mary University of London, London, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340945/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17609501750057631665&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Queen Mary University of London",
        "aff_unique_dep": "Centre for Advanced Robotics",
        "aff_unique_url": "https://www.qmul.ac.uk",
        "aff_unique_abbr": "QMUL",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9341644",
        "title": "Sim-to-Real Transfer of Bolting Tasks with Tight Tolerance",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a novel sim-to-real framework to solve bolting tasks with tight tolerance and complex contact geometry which are hard to be modeled. The sim-to-real has desirable features in terms of cost and safety, however, that of the assembly task is rare due to the lack of simulator, which can robustly render multi-contact assembly. We implement the sim-to-real transfer of nut tightening policy which is adaptive to uncertain bolt positions. This can be realized through developing a novel contact model, which is fast and robust to complex assembly geometry, and novel hierarchical controller with reinforcement learning (RL), which can perform the tasks with a narrow and complicated path. The fast and robust contact model is achieved by utilizing configuration space abstraction and passive midpoint integrator (PMI), which render the simulator robust even in a high stiffness contact condition. And we use sampling-based motion planning to construct a path library and design linear quadratic tracking controller as a low-level controller to be compliant and avoid local optima. Additionally, we use the RL agent as a high-level controller to make it possible to adapt to the bolt position uncertainty, thereby realizing sim-to-real. Experiments are performed to verify our proposed sim-to-real framework.",
        "primary_area": "",
        "author": "Dongwon Son;Hyunsoo Yang;Dongjun Lee;Dongwon Son;Hyunsoo Yang;Dongjun Lee",
        "authorids": "/37086455263;/37077410000;/37077171500;/37086455263;/37077410000;/37077171500",
        "aff": "Samsung Research, Seoul, Republic of Korea; Department of Mechanical & Aerospace Engineering and IAMD, Seoul National University, Seoul, Republic of Korea; Department of Mechanical & Aerospace Engineering and IAMD, Seoul National University, Seoul, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341644/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10293943486818486379&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Samsung Research;Seoul National University",
        "aff_unique_dep": ";Department of Mechanical & Aerospace Engineering",
        "aff_unique_url": "https://www.samsung.com/global/research/;https://www.snu.ac.kr",
        "aff_unique_abbr": "Samsung;SNU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9341057",
        "title": "Sim-to-Real with Domain Randomization for Tumbling Robot Control",
        "track": "main",
        "status": "Poster",
        "abstract": "Tumbling locomotion allows for small robots to traverse comparatively rough terrain, however, their motion is complex and difficult to control. Existing tumbling robot control methods involve manual control or the assumption of at terrain. Reinforcement learning allows for the exploration and exploitation of diverse environments. By utilizing reinforcement learning with domain randomization, a robust control policy can be learned in simulation then transferred to the real world. In this paper, we demonstrate autonomous setpoint navigation with a tumbling robot prototype on at and non- at terrain. The flexibility of this system improves the viability of nontraditional robots for navigational tasks.",
        "primary_area": "",
        "author": "Andrew Schwartzwald;Nikolaos Papanikolopoulos;Andrew Schwartzwald;Nikolaos Papanikolopoulos",
        "authorids": "/37089390369;/37278578300;/37089390369;/37278578300",
        "aff": "Department of Computer Science and Engineering, University of Minnesota; Department of Computer Science and Engineering, University of Minnesota",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341057/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7862834045386383254&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Minnesota",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.umn.edu",
        "aff_unique_abbr": "UMN",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341260",
        "title": "Sim2Real Transfer for Reinforcement Learning without Dynamics Randomization",
        "track": "main",
        "status": "Poster",
        "abstract": "We show how to use the Operational Space Control framework (OSC) under joint and Cartesian constraints for reinforcement learning in Cartesian space. Our method is able to learn fast and with adjustable degrees of freedom, while we are able to transfer policies without additional dynamics randomizations on a KUKA LBR iiwa peg-in-hole task. Before learning in simulation starts, we perform a system identification for aligning the simulation environment as far as possible with the dynamics of a real robot. Adding constraints to the OSC controller allows us to learn in a safe way on the real robot or to learn a flexible, goal conditioned policy that can be easily transferred from simulation to the real robot.",
        "primary_area": "",
        "author": "Manuel Kaspar;Juan D. Mu\u00f1oz Osorio;Juergen Bock;Manuel Kaspar;Juan D. Mu\u00f1oz Osorio;Juergen Bock",
        "authorids": "/37086328676;/37088690346;/37088690477;/37086328676;/37088690346;/37088690477",
        "aff": "Manuel Kaspar; Juan D. Mu\u00f1oz Osorio; Juergen Bock",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341260/",
        "gs_citation": 128,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4564175875522383812&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "",
        "aff_unique_norm": "",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "9340999",
        "title": "Simple means Faster: Real-Time Human Motion Forecasting in Monocular First Person Videos on CPU",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a simple, fast, and light-weight RNN based framework for forecasting future locations of humans in first person monocular videos. The primary motivation for this work was to design a network which could accurately predict future trajectories at a very high rate on a CPU. Typical applications of such a system would be a social robot or a visual assistance system \"for all\", as both cannot afford to have high compute power to avoid getting heavier, less power efficient, and costlier. In contrast to many previous methods which rely on multiple type of cues such as camera ego-motion or 2D pose of the human, we show that a carefully designed network model which relies solely on bounding boxes can not only perform better but also predicts trajectories at a very high rate while being quite low in size of approximately 17 MB. Specifically, we demonstrate that having an auto-encoder in the encoding phase of the past information and a regularizing layer in the end boosts the accuracy of predictions with negligible overhead. We experiment with three first person video datasets: CityWalks, FPL and JAAD. Our simple method trained on CityWalks surpasses the prediction accuracy of state-of-the-art method (STED) while being 9.6x faster on a CPU (STED runs on a GPU). We also demonstrate that our model can transfer zero-shot or after just 15% fine-tuning to other similar datasets and perform on par with the state-of-the-art methods on such datasets (FPL and DTP). To the best of our knowledge, we are the first to accurately forecast trajectories at a very high prediction rate of 78 trajectories per second on CPU.",
        "primary_area": "",
        "author": "Junaid Ahmed Ansari;Brojeshwar Bhowmick;Junaid Ahmed Ansari;Brojeshwar Bhowmick",
        "authorids": "/37086452989;/37571664300;/37086452989;/37571664300",
        "aff": "TCS Research and Innovation Labs, Kolkata, India; TCS Research and Innovation Labs, Kolkata, India",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340999/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8292769679484221542&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Tata Consultancy Services",
        "aff_unique_dep": "Research and Innovation Labs",
        "aff_unique_url": "https://www.tcs.com",
        "aff_unique_abbr": "TCS",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Kolkata",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "9341062",
        "title": "Simultaneous 3D Forming and Patterning Method of Realizing Soft IPMC Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Ionic polymer-metal composites (IPMC) actuators are popular because they can be driven at a low voltage, possess excellent responsiveness, and can perform soft motions similar to that of living creatures. Conventional IPMC soft robots are manufactured by cutting and assembling IPMC sheets. However, using this conventional process to stably manufacture three-dimensional (3D)-shaped soft robots is difficult. To mitigate this problem, we propose a new method for fabricating 3D IPMC actuators in which several surface electrodes are separately fabricated from a single ion-exchange membrane. We refer to our proposal as the simultaneous 3D forming and patterning (SFP) method. Unlike the conventional IPMC fabrication process, the SFP method requires only one step to fix the ion-exchange membrane to contact masks. First, we briefly describe IPMC actuators, before introducing the proposed SFP method in detail. Next, we describe our investigations of the patterning resolution for the surface electrode using the proposed method. We fabricated two soft robot prototypes using the proposed method. The first robot is a starfish-type soft robot. Its surface electrode can be patterned in a plane using the proposed method, and independent driving is possible by applying voltage individually to the divided electrodes. The second prototype is a sea anemone-type soft robot, wherein surface electrodes can be patterned on a 3D curved surface to form a 3D shape.",
        "primary_area": "",
        "author": "Keita Kubo;Hiroyuki Nabae;Tetsuya Horiuchi;Kinji Asaka;Gen Endo;Koichi Suzumori;Keita Kubo;Hiroyuki Nabae;Tetsuya Horiuchi;Kinji Asaka;Gen Endo;Koichi Suzumori",
        "authorids": "/37088686541;/37085590608;/37086687680;/37275258500;/37282128000;/37283170500;/37088686541;/37085590608;/37086687680;/37275258500;/37282128000;/37283170500",
        "aff": "School of Engineering, Tokyo Institute of Technology, Tokyo, Japan; School of Engineering, Tokyo Institute of Technology, Tokyo, Japan; National Institute of Advanced Industrial Science and Technology, Osaka, Japan; National Institute of Advanced Industrial Science and Technology, Osaka, Japan; School of Engineering, Tokyo Institute of Technology, Tokyo, Japan; School of Engineering, Tokyo Institute of Technology, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341062/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1228051796950075346&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;1;0;0",
        "aff_unique_norm": "Tokyo Institute of Technology;National Institute of Advanced Industrial Science and Technology",
        "aff_unique_dep": "School of Engineering;",
        "aff_unique_url": "https://www.titech.ac.jp;https://www.aist.go.jp",
        "aff_unique_abbr": "Titech;AIST",
        "aff_campus_unique_index": "0;0;1;1;0;0",
        "aff_campus_unique": "Tokyo;Osaka",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9341184",
        "title": "Simultaneous Estimation of Vehicle Position and Data Delays using Gaussian Process based Moving Horizon Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Automobiles or robots with advanced autonomous systems are equipped with multiple types of sensors to overcome different weather and geographical conditions. These sensors generally have various data delays and sampling rates. Additionally, the communication delays or time synchronization errors between the onboard computers significantly affect the robustness and accuracy of localization for autonomous vehicles. In this paper, the simultaneous estimation of vehicle position and sensor delays using a Gaussian process based moving horizon estimation (GP-MHE) is presented. The GP-MHE can estimate the unknown delays of multiple sensors with the resolution less than that of GP-MHE sampling rate. The localization performance of GP-MHE was confirmed using full-vehicle simulator, then evaluated in a real vehicle experiment on a highway scenario. Experimental result verified the sufficient localization accuracy of sub 0.3m using data that had irregular sampling rate and delay of more than 150ms. The proposed algorithm extends the capability of integrating various data with large unknown delays for vehicles, robots, drones and remote autonomy.",
        "primary_area": "",
        "author": "Daiki Mori;Yoshikazu Hattori;Daiki Mori;Yoshikazu Hattori",
        "authorids": "/37087103980;/37087105029;/37087103980;/37087105029",
        "aff": "Toyota Central R&D Labs. Inc., Nagakute, Japan; Toyota Central R&D Labs. Inc., Nagakute, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341184/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11743903283931439457&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Toyota Central R&D Labs. Inc.",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.toyota-global.com/company/",
        "aff_unique_abbr": "Toyota R&D",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Nagakute",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9340929",
        "title": "Simultaneous Planning for Item Picking and Placing by Deep Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Container loading by a picking robot is an important challenge in the logistics industry. When designing such a robotic system, item picking and placing have been planned individually thus far. However, since the condition of picking an item affects the possible candidates for placing, it is preferable to plan picking and placing simultaneously. In this paper, we propose a deep reinforcement learning (DRL) method for simultaneously planning item picking and placing. A technical challenge in the simultaneous planning is its scalability: even for a practical container size, DRL can be computationally intractable due to large action spaces. To overcome the intractability, we adopt a fully convolutional network for policy approximation and determine the action based only on local information. This enables us to produce a shared policy which can be applied to larger action spaces than the one used for training. We experimentally demonstrate that our method can successfully solve the simultaneous planning problem and achieve a higher occupancy rate than conventional methods.",
        "primary_area": "",
        "author": "Tatsuya Tanaka;Toshimitsu Kaneko;Masahiro Sekine;Voot Tangkaratt;Masashi Sugiyama;Tatsuya Tanaka;Toshimitsu Kaneko;Masahiro Sekine;Voot Tangkaratt;Masashi Sugiyama",
        "authorids": "/37087180404;/38560162700;/37088347346;/37085405521;/37305595700;/37087180404;/38560162700;/37088347346;/37085405521;/37305595700",
        "aff": "Corporate Research & Development Center, Toshiba Corporation, Japan; Corporate Research & Development Center, Toshiba Corporation, Japan; Corporate Research & Development Center, Toshiba Corporation, Japan; Center for Advanced Intelligence Project, RIKEN, Japan; The University of Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340929/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4067747191984663166&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;2",
        "aff_unique_norm": "Toshiba Corporation;RIKEN;The University of Tokyo",
        "aff_unique_dep": "Corporate Research & Development Center;Center for Advanced Intelligence Project;",
        "aff_unique_url": "https://www.toshiba.co.jp;https://www.riken.jp;https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "Toshiba;RIKEN;UTokyo",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9341030",
        "title": "Simultaneous Trajectory Optimization and Force Control with Soft Contact Mechanics",
        "track": "main",
        "status": "Poster",
        "abstract": "Force modulation of robotic manipulators has been extensively studied for several decades but is not yet commonly used in safety-critical applications due to a lack of accurate interaction contact modeling and weak performance guarantees - a large proportion of them concerning the modulation of interaction forces. This study presents a high-level framework for simultaneous trajectory optimization and force control of the interaction between manipulator and soft environments. Sliding friction and normal contact force are taken into account. The dynamics of the soft contact model and the manipulator dynamics are simultaneously incorporated in a trajectory optimizer to generate desired motion and force profiles. A constrained optimization framework based on Differential Dynamic Programming and Alternative Direction Method of Multipliers has been employed to generate optimal control inputs and high-dimensional state trajectories. Experimental validation of the model performance is conducted on a soft substrate with known material properties using a Cartesian space force control mode. Results show a comparison of ground truth and predicted model based contact force states for multiple Cartesian motions and the validity range of the friction model. The proposed high-level planning has the potential to be leveraged for medical tasks involving manipulation of compliant, delicate, and deformable tissues.",
        "primary_area": "",
        "author": "Lasitha Wijayarathne;Qie Sima;Ziyi Zhou;Ye Zhao;Frank L. Hammond;Lasitha Wijayarathne;Qie Sima;Ziyi Zhou;Ye Zhao;Frank L. Hammond",
        "authorids": "/37086800589;/37088690631;/37088485262;/37088450720;/37394264300;/37086800589;/37088690631;/37088485262;/37088450720;/37394264300",
        "aff": "Department of Biomedical Engineering, Woodruff School of Mechanical Engineering and the Coulter, Georgia Institute of Technology; The Laboratory of Intelligent Decision and Autonomous Robots at Woodruff School of Mechanical Engineering, Georgia Institute of Technology; The Laboratory of Intelligent Decision and Autonomous Robots at Woodruff School of Mechanical Engineering, Georgia Institute of Technology; The Laboratory of Intelligent Decision and Autonomous Robots at Woodruff School of Mechanical Engineering, Georgia Institute of Technology; Department of Biomedical Engineering, Woodruff School of Mechanical Engineering and the Coulter, Georgia Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341030/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15428714487434742004&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Georgia Institute of Technology",
        "aff_unique_dep": "Department of Biomedical Engineering",
        "aff_unique_url": "https://www.gatech.edu",
        "aff_unique_abbr": "Georgia Tech",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340727",
        "title": "Simultaneous position-stiffness control of antagonistically driven twisted-coiled polymer actuators using model predictive control",
        "track": "main",
        "status": "Poster",
        "abstract": "Super-coiled polymer (SCP) artificial muscles have many interesting properties that show potentials for making high performance bionic devices. To realize human-like robotic devices from this type of actuator, it is important for the SCP driven mechanisms to achieve human-like performance, such as compliant behaviors through antagonistic mechanisms. This paper presents the simultaneous position-stiffness control of an antagonistic joint driven by hybrid twisted-coiled polymer actuation bundles made from Spandex and nylon fibers, which is a common human compliant behavior. Based on a linear model of the system, which is identified and verified experimentally, a controller based on model predictive control (MPC) is designed. The MPC performance is enhanced by the incorporation of time delay estimation to estimate model variations and external disturbances. The controlled system is verified through simulations and experiments. The results show the controller's ability to control the joint angle with the highest position error of 0.6 degrees while changing joint stiffness, verified with step command and sinusoidal reference with composite frequencies of 0.01Hz to 0.1Hz.",
        "primary_area": "",
        "author": "Tuan Luong;Kihyeon Kim;Sungwon Seo;Jeongmin Jeon;Ja Choon Koo;Hyouk Ryeol Choi;Hyungpil Moon;Tuan Luong;Kihyeon Kim;Sungwon Seo;Jeongmin Jeon;Ja Choon Koo;Hyouk Ryeol Choi;Hyungpil Moon",
        "authorids": "/37086438176;/37086440188;/37086090014;/37085884834;/37288048300;/37086310040;/37274074800;/37086438176;/37086440188;/37086090014;/37085884834;/37288048300;/37086310040;/37274074800",
        "aff": "Faculty of Mechanical Engineering, Sungkyunkwan University, Suwon, South Korea; Faculty of Mechanical Engineering, Sungkyunkwan University, Suwon, South Korea; Faculty of Mechanical Engineering, Sungkyunkwan University, Suwon, South Korea; Faculty of Mechanical Engineering, Sungkyunkwan University, Suwon, South Korea; Faculty of Mechanical Engineering, Sungkyunkwan University, Suwon, South Korea; Faculty of Mechanical Engineering, Sungkyunkwan University, Suwon, South Korea; Faculty of Mechanical Engineering, Sungkyunkwan University, Suwon, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340727/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5789556386413224919&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Sungkyunkwan University",
        "aff_unique_dep": "Faculty of Mechanical Engineering",
        "aff_unique_url": "http://www.skku.edu",
        "aff_unique_abbr": "SKKU",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Suwon",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9341546",
        "title": "Single-Shot Panoptic Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a novel end-to-end single-shot method that segments countable object instances (things) as well as background regions (stuff) into a non-overlapping panoptic segmentation at almost video frame rate. Current state-of-the-art methods are far from reaching video frame rate and mostly rely on merging instance segmentation with semantic background segmentation, making them impractical to use in many applications such as robotics. Our approach relaxes this requirement by using an object detector but is still able to re-solve inter- and intra-class overlaps to achieve a non-overlapping segmentation. On top of a shared encoder-decoder backbone, we utilize multiple branches for semantic segmentation, object detection, and instance center prediction. Finally, our panoptic head combines all outputs into a panoptic segmentation and can even handle conflicting predictions between branches as well as certain false predictions. Our network achieves 32.6% PQ on MS-COCO at 23.5 FPS, opening up panoptic segmentation to a broader field of applications.",
        "primary_area": "",
        "author": "Mark Weber;Jonathon Luiten;Bastian Leibe;Mark Weber;Jonathon Luiten;Bastian Leibe",
        "authorids": "/37088505508;/37086938062;/37298473000;/37088505508;/37086938062;/37298473000",
        "aff": "RWTH Aachen University; RWTH Aachen University; RWTH Aachen University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341546/",
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5572689568908532696&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "RWTH Aachen University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.rwth-aachen.de",
        "aff_unique_abbr": "RWTH",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Aachen",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9340985",
        "title": "Skill-based Programming Framework for Composable Reactive Robot Behaviors",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper introduces a constraint-based skill framework for programming robot applications. Existing skill frameworks allow application developers to reuse skills and compose them sequentially or in parallel. However, they typically assume that the skills are running independently and in a nominal condition. This limitation hinders their applications for more involved and realistic scenarios e.g. when the skills need to run synchronously and in the presence of disturbances. This paper addresses this problem in two steps. First, we revisit how constraint-based skills are modeled. We classify different skill types based on how their progress can be evaluated over time. Our skill model separates the constraints that impose task-consistency and the constraints that make the skills progress i.e. reaching their end conditions. Second, this paper introduces composition patterns that couple skills in parallel such that they are executed in a synchronized manner and reactive to disturbances. The effectiveness of our framework is evaluated on a dual-arm robotics setup that performs an industrial assembly task in the presence of disturbance.",
        "primary_area": "",
        "author": "Yudha Pane;Erwin Aertbeli\u00ebn;Joris De Schutter;Wilm Decr\u00e9;Yudha Pane;Erwin Aertbeli\u00ebn;Joris De Schutter;Wilm Decr\u00e9",
        "authorids": "/38554868000;/37449455800;/37324060800;/37571970600;/38554868000;/37449455800;/37324060800;/37571970600",
        "aff": "Core Lab ROB, Flanders Make; Core Lab ROB, Flanders Make; Core Lab ROB, Flanders Make; Core Lab ROB, Flanders Make",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340985/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3511329189137304709&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Flanders Make",
        "aff_unique_dep": "Core Lab ROB",
        "aff_unique_url": "https://www.flandersmake.be",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Belgium"
    },
    {
        "id": "9341645",
        "title": "Slope Handling for Quadruped Robots Using Deep Reinforcement Learning and Toe Trajectory Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Quadrupedal locomotion skills are challenging to develop. In recent years, deep Reinforcement Learning promises to automate the development of locomotion controllers and map sensory observations to low-level actions. Moreover, the full robot dynamics model can be exploited, but no model-based simplifications are to be made. In this work, a method for developing controllers for the Laelaps II robot is presented and applied to motions on slopes up to 15\u00b0. Combining deep reinforcement learning with trajectory planning at the toe level, reduces complexity and training time. The proposed control scheme is extensively tested in a Gazebo environment similar to the treadmill-robot environment at the Control Systems Lab of NTUA. The learned policies produced promising results.",
        "primary_area": "",
        "author": "Athanasios S. Mastrogeorgiou;Yehia S. Elbahrawy;Andr\u00e9s Kecskem\u00e9thy;Evangelos G. Papadopoulos;Athanasios S. Mastrogeorgiou;Yehia S. Elbahrawy;Andr\u00e9s Kecskem\u00e9thy;Evangelos G. Papadopoulos",
        "authorids": "/37088688942;/37088691135;/37344718900;/37273090500;/37088688942;/37088691135;/37344718900;/37273090500",
        "aff": "Department of Mechanical Engineering, National Technical University of Athens, Athens, Greece; Faculty of Engineering, University of Duisburg-Essen, Duisburg, Germany; Faculty of Engineering, University of Duisburg-Essen, Duisburg, Germany; Department of Mechanical Engineering, National Technical University of Athens, Athens, Greece",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341645/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11968668712635888432&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "National Technical University of Athens;University of Duisburg-Essen",
        "aff_unique_dep": "Department of Mechanical Engineering;Faculty of Engineering",
        "aff_unique_url": "https://www.ntua.gr;https://www.uni-due.de",
        "aff_unique_abbr": "NTUA;",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Athens;Duisburg",
        "aff_country_unique_index": "0;1;1;0",
        "aff_country_unique": "Greece;Germany"
    },
    {
        "id": "9341537",
        "title": "Smart Speaker vs. Social Robot in a Case of Hotel Room",
        "track": "main",
        "status": "Poster",
        "abstract": "Under the circumstances that social robots are increasingly being developed and studied in service encounters at public spaces, are they introduced into residential environments (i.e., private space)? This study hypothesizes that a personal assistant device in residential environments should wear human-like appearance to engage in service as conversation partner. We implemented the interaction design that provides regular services as the current personal assistant and additional service as conversation partner, and then conducted a field experiment where the participants stayed in the hotel rooms with a smart speaker or a social robot. The results support the hypothesis in that of conversation amount and emotional experience by conversation. The results also suggest the possibility of commercial service, namely conversational advertisement through social robots.",
        "primary_area": "",
        "author": "Junya Nakanishi;Jun Baba;Itaru Kuramoto;Kohei Ogawa;Yuichiro Yoshikawa;Hroshi Ishiguro;Junya Nakanishi;Jun Baba;Itaru Kuramoto;Kohei Ogawa;Yuichiro Yoshikawa;Hroshi Ishiguro",
        "authorids": "/37085769525;/37086804031;/37904088300;/37675044800;/37286859300;/37274136400;/37085769525;/37086804031;/37904088300;/37675044800;/37286859300;/37274136400",
        "aff": "Osaka University, Osaka, Japan; Cyber Agent Inc., Tokyo, Japan; University of Fukuchiyama, Kyoto, Japan; Nagoya University, Aichi, Japan; Osaka University, Osaka, Japan; Osaka University, Osaka, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341537/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18272034095812674857&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;3;0;0",
        "aff_unique_norm": "Osaka University;Cyber Agent Inc.;University of Fukuchiyama;Nagoya University",
        "aff_unique_dep": ";;;",
        "aff_unique_url": "https://www.osaka-u.ac.jp;https://www.cyberagent.co.jp;;https://www.nagoya-u.ac.jp",
        "aff_unique_abbr": "Osaka U;;;Nagoya U",
        "aff_campus_unique_index": "0;1;2;0;0",
        "aff_campus_unique": "Osaka;Tokyo;Kyoto;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9341509",
        "title": "Smart-Inspect: Micro Scale Localization and Classification of Smartphone Glass Defects for Industrial Automation",
        "track": "main",
        "status": "Poster",
        "abstract": "The presence of any type of defect on the glass screen of smart devices has a great impact on their quality. We present a robust semi-supervised learning framework for intelligent micro-scaled localization and classification of defects on a 16K pixel image of smartphone glass. Our model features the efficient recognition and labeling of three types of defects: scratches, light leakage due to cracks, and pits. Our method also differentiates between the defects and light reflections due to dust particles and sensor regions, which are classified as non-defect areas. We use a partially labeled dataset to achieve high robustness and excellent classification of defect and non-defect areas as compared to principal components analysis (PCA), multi-resolution and information-fusion-based algorithms. In addition, we incorporated two classifiers at different stages of our inspection framework for labeling and refining the unlabeled defects. We successfully enhanced the inspection depth-limit up to 5 microns. The experimental results show that our method outperforms manual inspection in testing the quality of glass screen samples by identifying defects on samples that have been marked as good by human inspection.",
        "primary_area": "",
        "author": "M Usman Maqbool Bhutta;Shoaib Aslam;Peng Yun;Jianhao Jiao;Ming Liu;M Usman Maqbool Bhutta;Shoaib Aslam;Peng Yun;Jianhao Jiao;Ming Liu",
        "authorids": "/37086552250;/37088691340;/37086640426;/37086552343;/37085398677;/37086552250;/37088691340;/37086640426;/37086552343;/37085398677",
        "aff": "Department of Electronic and Computer Engineering, HKUST, HK; Department of Mechanical and Aerospace Engineering, HKUST, HK; Department of Computer Science and Engineering, HKUST, HK; Department of Electronic and Computer Engineering, HKUST, HK; Department of Computer Science and Engineering, HKUST, HK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341509/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6713018723897038183&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Hong Kong University of Science and Technology",
        "aff_unique_dep": "Department of Electronic and Computer Engineering",
        "aff_unique_url": "https://www.hkust.edu.hk",
        "aff_unique_abbr": "HKUST",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9341279",
        "title": "Snapbot V2: a Reconfigurable Legged Robot with a Camera for Self Configuration Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present the second version of a reconfigurable modular legged robot, Snapbot V2. The mechanical design of Snapbot V2 is enhanced for better dynamic performance and robust connection with modular legs. A motion generator for locomotion is developed to achieve various locomotion skills in one to six-leg configurations. The locomotion is tested on a multi-body dynamic simulation model and implemented on a physical robot as well. A visual detection is implemented with a camera module to recognize the robot\u2019s configuration. By detecting the particular color of the parts at the leg module, the robot can recognize the number and location of the connected legs. Based on the recognized configuration, Snapbot V2 selects the proper locomotion style automatically.",
        "primary_area": "",
        "author": "Kevin G. Gim;Joohyung Kim;Kevin G. Gim;Joohyung Kim",
        "authorids": "/37086454794;/37085576403;/37086454794;/37085576403",
        "aff": "University of Illinois at Urbana-Champign; University of Illinois at Urbana-Champign",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341279/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9483782231068301234&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Illinois at Urbana-Champaign",
        "aff_unique_dep": "",
        "aff_unique_url": "https://illinois.edu",
        "aff_unique_abbr": "UIUC",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Urbana-Champaign",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341291",
        "title": "Socially Assistive Robots at Work: Making Break-Taking Interventions More Pleasant, Enjoyable, and Engaging",
        "track": "main",
        "status": "Poster",
        "abstract": "More than ever, people spend the workday seated in front of a computer, which contributes to health issues caused by excess sedentary behavior. While breaking up long periods of sitting can alleviate these issues, no scalable interventions have had long-term success in motivating activity breaks at work. We believe that socially assistive robotics (SAR), which combines the scalability of e-health interventions with the motivational social ability of a companion or coach, may offer a solution for changing sedentary habits. To begin this work, we designed a SAR system and conducted a within-subjects study with N = 19 participants to compare their experiences taking breaks using the SAR system versus an alarm-like device for one day each in participants' normal workplaces. Results indicate that both systems had similar effects on sedentary behavior, but the SAR system led to greater feelings of pleasure, enjoyment, and engagement. Interviews yielded design recommendations for future systems. We find that SAR systems hold promise for further investigations of aiding healthy habit formation in work settings.",
        "primary_area": "",
        "author": "Brian J. Zhang;Ryan Quick;Ameer Helmi;Naomi T. Fitter;Brian J. Zhang;Ryan Quick;Ameer Helmi;Naomi T. Fitter",
        "authorids": "/37088691065;/37088689150;/37088687638;/37077925800;/37088691065;/37088689150;/37088687638;/37077925800",
        "aff": "Collaborative Robotics and Intelligent Systems (CoRIS) Institute, Oregon State University, Corvallis, OR, USA; Collaborative Robotics and Intelligent Systems (CoRIS) Institute, Oregon State University, Corvallis, OR, USA; Collaborative Robotics and Intelligent Systems (CoRIS) Institute, Oregon State University, Corvallis, OR, USA; Collaborative Robotics and Intelligent Systems (CoRIS) Institute, Oregon State University, Corvallis, OR, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341291/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10129694276476170695&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Oregon State University",
        "aff_unique_dep": "Collaborative Robotics and Intelligent Systems (CoRIS) Institute",
        "aff_unique_url": "https://oregonstate.edu",
        "aff_unique_abbr": "OSU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Corvallis",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341114",
        "title": "Soft Microrobotic Transmissions Enable Rapid Ground-Based Locomotion",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper we present the design, fabrication, testing, and control of a 0.4 g milliscale robot employing a soft polymer flexure transmission for rapid ground movement. The robot was constructed through a combination of two methods: smart-composite-manufacturing (SCM) process to fabricate the actuators and robot chassis, and silicone elastomer molding and casting to fabricate a soft flexure transmission. We actuate the flexure transmission using two customized piezoelectric (PZT) actuators that attach to the transmission inputs. Through high-frequency oscillations, the actuators are capable of exciting vibrational resonance modes of the transmission which result in motion amplification on the transmission output. Directional spines on the transmission output generate traction force with the ground and drive the robot forward. By varying the excitation frequency of the soft transmission we can control locomotion speed, and when the transmission is oscillated at its resonance frequency we achieve high speeds with a peak speed of 439 mm/s (22 body lengths/s). By exciting traveling waves through the soft transmission, we were able to control the steering direction. Overall this paper demonstrates the feasibility of generating resonance behavior in millimeter scale soft robotic structures to achieve high-speed controllable locomotion.",
        "primary_area": "",
        "author": "Wei Zhou;Nick Gravish;Wei Zhou;Nick Gravish",
        "authorids": "/37088687845;/37085401269;/37088687845;/37085401269",
        "aff": "Department of Mechanical & Aerospace Engineering, University of California, San Diego, CA, USA; Department of Mechanical & Aerospace Engineering, University of California, San Diego, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341114/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13585990679429185524&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of California, San Diego",
        "aff_unique_dep": "Department of Mechanical & Aerospace Engineering",
        "aff_unique_url": "https://www.ucsd.edu",
        "aff_unique_abbr": "UCSD",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "San Diego",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341710",
        "title": "Soft Tissue Simulation Environment to Learn Manipulation Tasks in Autonomous Robotic Surgery",
        "track": "main",
        "status": "Poster",
        "abstract": "Reinforcement Learning (RL) methods have demonstrated promising results for the automation of subtasks in surgical robotic systems. Since many trial and error attempts are required to learn the optimal control policy, RL agent training can be performed in simulation and the learned behavior can be then deployed in real environments. In this work, we introduce an open-source simulation environment providing support for position based dynamics soft bodies simulation and state-of-the-art RL methods. We demonstrate the capabilities of the proposed framework by training an RL agent based on Proximal Policy Optimization in fat tissue manipulation for tumor exposure during a nephrectomy procedure. Leveraging on a preliminary optimization of the simulation parameters, we show that our agent is able to learn the task on a virtual replica of the anatomical environment. The learned behavior is robust to changes in the initial end-effector position. Furthermore, we show that the learned policy can be directly deployed on the da Vinci Research Kit, which is able to execute the trajectories generated by the RL agent. The proposed simulation environment represents an essential component for the development of next-generation robotic systems, where the interaction with the deformable anatomical environment is involved.",
        "primary_area": "",
        "author": "Eleonora Tagliabue;Ameya Pore;Diego Dall\u2019Alba;Enrico Magnabosco;Marco Piccinelli;Paolo Fiorini;Eleonora Tagliabue;Ameya Pore;Diego Dall\u2019Alba;Enrico Magnabosco;Marco Piccinelli;Paolo Fiorini",
        "authorids": "/37088649344;/37088506135;/38540860700;/37088689530;/37088688398;/37279139000;/37088649344;/37088506135;/38540860700;/37088689530;/37088688398;/37279139000",
        "aff": "Department of Computer Science, University of Verona, Verona, Italy; Department of Computer Science, University of Verona, Verona, Italy; Department of Computer Science, University of Verona, Verona, Italy; Department of Computer Science, University of Verona, Verona, Italy; Department of Computer Science, University of Verona, Verona, Italy; Department of Computer Science, University of Verona, Verona, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341710/",
        "gs_citation": 65,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=490946332077242491&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of Verona",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.univr.it",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Verona",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9341534",
        "title": "Soft-bubble grippers for robust and perceptive manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Manipulation in cluttered environments like homes requires stable grasps, precise placement and robustness against external contact. Towards addressing these challenges, we present the Soft-bubble gripper system that combines highly compliant gripping surfaces with dense-geometry visuotactile sensing and facilitates multiple kinds of tactile perception. We first present several mechanical design advances on the Soft-bubble sensors including a fabrication technique to deposit custom patterns to the internal surface of the sensor membrane that enables tracking of shear-induced displacement of the grasped object. The depth maps output by the internal imaging sensor are used in an in-hand proximity pose estimation framework - the method better captures distances to corners or edges on the object geometry. We also extend our previous work on tactile classification and integrate the system within a robust manipulation pipeline for cluttered home environments. The capabilities of the proposed system are demonstrated through robust execution of multiple real-world manipulation tasks.",
        "primary_area": "",
        "author": "Naveen Kuppuswamy;Alex Alspach;Avinash Uttamchandani;Sam Creasey;Takuya Ikeda;Russ Tedrake;Naveen Kuppuswamy;Alex Alspach;Avinash Uttamchandani;Sam Creasey;Takuya Ikeda;Russ Tedrake",
        "authorids": "/37297597200;/37992498900;/37088689580;/37088688921;/37090022337;/37283152200;/37297597200;/37992498900;/37088689580;/37088688921;/37090022337;/37283152200",
        "aff": "Toyota Research Institute, Cambridge, MA, USA; Toyota Research Institute, Cambridge, MA, USA; Toyota Research Institute, Cambridge, MA, USA; Toyota Research Institute, Cambridge, MA, USA; Toyota Research Institute, Cambridge, MA, USA; Toyota Research Institute, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341534/",
        "gs_citation": 112,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11568712141082739694&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Toyota Research Institute",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.tri.global",
        "aff_unique_abbr": "TRI",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341328",
        "title": "Software Development Framework for Cooperating Robots with High-level Mission Specification",
        "track": "main",
        "status": "Poster",
        "abstract": "In recent years, there has been a growing interest in multiple robots performing a single task through different types of collaboration. There are two software challenges when deploying collaborative robots: how to specify a cooperative mission and how to program each robot to accomplish its mission. In this paper, we propose a novel software development framework to support distributed robot systems, swarm robots, and their hybrid. We extend the service-oriented and model-based (SeMo) framework [1] to improve the robustness, scalability, and flexibility of robot collaboration. To enable a casual user to specify various types of cooperative missions easily, the high-level mission scripting language is extended with new features such as team hierarchy, group service, one-to-many communication. The script program is refined to the robot codes through two intermediate steps, strategy description and task graph generation, in the proposed framework. The viability of the proposed framework is evidenced by two preliminary experiments using real robots and a robot simulator.",
        "primary_area": "",
        "author": "Hyesun Hong;Woosuk Kang;Soonhoi Ha;Hyesun Hong;Woosuk Kang;Soonhoi Ha",
        "authorids": "/37086155901;/37088688827;/37274314800;/37086155901;/37088688827;/37274314800",
        "aff": "Department of Computer Engineering, Seoul National University, Seoul, South Korea; Department of Computer Engineering, Seoul National University, Seoul, South Korea; Department of Computer Engineering, Seoul National University, Seoul, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341328/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3669391908618067671&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Seoul National University",
        "aff_unique_dep": "Department of Computer Engineering",
        "aff_unique_url": "https://www.snu.ac.kr",
        "aff_unique_abbr": "SNU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9340962",
        "title": "SolarSLAM: Battery-free Loop Closure for Indoor Localisation",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose SolarSLAM, a batteryfree loop closure method for indoor localisation. Inertial Measurement Unit (IMU) based indoor localisation method has been widely used due to its ubiquity in mobile devices, such as mobile phones, smartwatches and wearable bands. However, it suffers from the unavoidable long term drift. To mitigate the localisation error, many loop closure solutions have been proposed using sophisticated sensors, such as cameras, laser, etc. Despite achieving high-precision localisation performance, these sensors consume a huge amount of energy. Different from those solutions, the proposed SolarSLAM takes advantage of an energy harvesting solar cell as a sensor and achieves effective battery-free loop closure method. The proposed method suggests the key-point dynamic time warping for detecting loops and uses robust simultaneous localisation and mapping (SLAM) as the optimiser to remove falsely recognised loop closures. Extensive evaluations in the real environments have been conducted to demonstrate the advantageous photocurrent characteristics for indoor localisation and good localisation accuracy of the proposed method.",
        "primary_area": "",
        "author": "Bo Wei;Weitao Xu;Chengwen Luo;Guillaume Zoppi;Dong Ma;Sen Wang;Bo Wei;Weitao Xu;Chengwen Luo;Guillaume Zoppi;Dong Ma;Sen Wang",
        "authorids": "/37085717047;/37085785383;/37086020980;/37679897600;/37086384896;/37086278300;/37085717047;/37085785383;/37086020980;/37679897600;/37086384896;/37086278300",
        "aff": "Department of Computer and Information Sciences, Northumbria University, Newcastle upon Tyne, United Kingdom; Department of Computer Science, City University of Hong Kong, Hong Kong, China; College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China; Department of Mathematics, Physics and Electrical Engineering, Northumbria University, Newcastle upon Tyne, United Kingdom; Department of Computer Science and Technology, University of Cambridge, Cambridge, United Kingdom; School of Engineering & Physical Sciences, Heriot- Watt University, Edinburgh, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340962/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17911250603411753370&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;0;3;4",
        "aff_unique_norm": "Northumbria University;City University of Hong Kong;Shenzhen University;University of Cambridge;Heriot-Watt University",
        "aff_unique_dep": "Department of Computer and Information Sciences;Department of Computer Science;College of Computer Science and Software Engineering;Department of Computer Science and Technology;School of Engineering & Physical Sciences",
        "aff_unique_url": "https://www.northumbria.ac.uk;https://www.cityu.edu.hk;https://www.szu.edu.cn;https://www.cam.ac.uk;https://www.hw.ac.uk",
        "aff_unique_abbr": "Northumbria;CityU;SZU;Cambridge;HWU",
        "aff_campus_unique_index": "0;1;2;0;3;4",
        "aff_campus_unique": "Newcastle upon Tyne;Hong Kong;Shenzhen;Cambridge;Edinburgh",
        "aff_country_unique_index": "0;1;1;0;0;0",
        "aff_country_unique": "United Kingdom;China"
    },
    {
        "id": "9340827",
        "title": "Solving Cosserat Rod Models via Collocation and the Magnus Expansion",
        "track": "main",
        "status": "Poster",
        "abstract": "Choosing a kinematic model for a continuum robot typically involves making a tradeoff between accuracy and computational complexity. One common modeling approach is to use the Cosserat rod equations, which have been shown to be accurate for many types of continuum robots. This approach, however, still presents significant computational cost, particularly when many Cosserat rods are coupled via kinematic constraints. In this work, we propose a numerical method that combines orthogonal collocation on the local rod curvature and forward integration of the Cosserat rod kinematic equations via the Magnus expansion, allowing the equilibrium shape to be written as a product of matrix exponentials. We provide a bound on the maximum step size to guarantee convergence of the Magnus expansion for the case of Cosserat rods, compare in simulation against other approaches, and demonstrate the tradeoffs between speed and accuracy for the fourth and sixth order Magnus expansions as well as for different numbers of collocation points. Our results show that the proposed method can find accurate solutions to the Cosserat rod equations and can potentially be competitive in computation speed.",
        "primary_area": "",
        "author": "Andrew L. Orekhov;Nabil Simaan;Andrew L. Orekhov;Nabil Simaan",
        "authorids": "/37085540584;/37282380300;/37085540584;/37282380300",
        "aff": "Department of Mechanical Engineering, Vanderbilt University, Nashville, TN, USA; Department of Mechanical Engineering, Vanderbilt University, Nashville, TN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340827/",
        "gs_citation": 43,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17023829220254040231&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Vanderbilt University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.vanderbilt.edu",
        "aff_unique_abbr": "Vanderbilt",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Nashville",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340899",
        "title": "Solving Large-scale Stochastic Orienteering Problems with Aggregation",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper we consider the stochastic cost orienteering problem, i.e., a version of the classic orienteering problem where the cost associated with each edge is a random variable with known distribution. Such a model is relevant when travel costs are variable, e.g., when a robot moves in uncertain terrain conditions. We model this problem using a composite state space tracking both how much progress the robot has made towards the goal and how much time it has left. On top of this state space, we compute a time-aware policy that allows the robot to dynamically adjust its path and avoid missing the temporal deadline. This policy is determined using a Constrained Markov Decision Process that allows tuning the accepted failure probability upfront. This approach suffers from a significant growth in the composite state space, and to mitigate this problem we introduce an aggregation technique where nearby vertices are compounded together, effectively reducing the original routing problem to an instance with a smaller state space. We then analyze this approach over large scale problem instances associated with robotic irrigation on a commercial grade vineyard.",
        "primary_area": "",
        "author": "Thomas C. Thayer;Stefano Carpin;Thomas C. Thayer;Stefano Carpin",
        "authorids": "/37086455994;/37328709200;/37086455994;/37328709200",
        "aff": "Department of Computer Science and Engineering, University of California, Merced, CA, USA; Department of Computer Science and Engineering, University of California, Merced, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340899/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12550785014242202060&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of California, Merced",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.ucmerced.edu",
        "aff_unique_abbr": "UC Merced",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Merced",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341456",
        "title": "SpCoMapGAN: Spatial Concept Formation-based Semantic Mapping with Generative Adversarial Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "In semantic mapping, which connects semantic information to an environment map, it is a challenging task for robots to deal with both local and global information of environments. In addition, it is important to estimate semantic information of unobserved areas from already acquired partial observations in a newly visited environment. On the other hand, previous studies on spatial concept formation enabled a robot to relate multiple words to places from bottom-up observations even when the vocabulary was not provided beforehand. However, the robot could not transfer global information related to the room arrangement between semantic maps from other environments. In this paper, we propose SpCoMapGAN, which generates the semantic map in a newly visited environment by training an inference model using previously estimated semantic maps. SpCoMapGAN uses generative adversarial networks (GANs) to transfer semantic information based on room arrangements to a newly visited environment. Our proposed method assigns semantics to the map of an unknown environment using the prior distribution of the map trained in known environments and the multimodal observations made in the unknown environment. We experimentally show in simulation that SpCoMapGAN can use global information for estimating the semantic map and is superior to previous methods. Finally, we also demonstrate in a real environment that SpCoMapGAN can accurately 1) deal with local information, and 2) acquire the semantic information of real places.",
        "primary_area": "",
        "author": "Yuki Katsumata;Akira Taniguchi;Lotfi El Hafi;Yoshinobu Hagiwara;Tadahiro Taniguchi;Yuki Katsumata;Akira Taniguchi;Lotfi El Hafi;Yoshinobu Hagiwara;Tadahiro Taniguchi",
        "authorids": "/37088689913;/37086202886;/37089392529;/37825579700;/37273806600;/37088689913;/37086202886;/37089392529;/37825579700;/37273806600",
        "aff": "Ritsumeikan University, Kusatsu, Japan; Ritsumeikan University, Kusatsu, Japan; Ritsumeikan University, Kusatsu, Japan; Ritsumeikan University, Kusatsu, Japan; Ritsumeikan University, Kusatsu, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341456/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2221005908402728175&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Ritsumeikan University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.ritsumei.ac.jp",
        "aff_unique_abbr": "Ritsumeikan",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Kusatsu",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9341079",
        "title": "Sparse Discrete Communication Learning for Multi-Agent Cooperation Through Backpropagation",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent approaches to multi-agent reinforcement learning (MARL) with inter-agent communication have often overlooked important considerations of real-world communication networks, such as limits on bandwidth. In this paper, we propose an approach to learning sparse discrete communication through backpropagation in the context of MARL, in which agents are incentivized to communicate as little as possible while still achieving high reward. Building on top of our prior work on differentiable discrete communication learning, we develop a regularization-inspired message-length penalty term, that encourages agents to send shorter messages and avoid unnecessary communications. To this end, we introduce a variable-length message code that provides agents with a general means of modulating message length while keeping the overall learning objective differentiable. We present simulation results on a partially-observable robot navigation task, where we first show how our approach allows learning of sparse communication behavior while still solving the task. We finally demonstrate our approach can even learn an effective sparse communication behavior from demonstrations of an expert (potentially communication-free) policy.",
        "primary_area": "",
        "author": "Benjamin Freed;Rohan James;Guillaume Sartoretti;Howie Choset;Benjamin Freed;Rohan James;Guillaume Sartoretti;Howie Choset",
        "authorids": "/37088199809;/37088686684;/37085791757;/37281322200;/37088199809;/37088686684;/37085791757;/37281322200",
        "aff": "Robotics Institute at Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute at Carnegie Mellon University, Pittsburgh, PA, USA; Department of Mechanical Engineering, National University of Singapore, Singapore; Robotics Institute at Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341079/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1526450044931656892&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Carnegie Mellon University;National University of Singapore",
        "aff_unique_dep": "Robotics Institute;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.cmu.edu;https://www.nus.edu.sg",
        "aff_unique_abbr": "CMU;NUS",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pittsburgh;",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "United States;Singapore"
    },
    {
        "id": "9340765",
        "title": "Spatio-Temporal Ultrasonic Dataset: Learning Driving from Spatial and Temporal Ultrasonic Cues",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent works have proved that combining spatial and temporal visual cues can significantly improve the performance of various vision-based robotic systems. However, for the ultrasonic sensors used in most robotic tasks (e.g. collision avoidance, localization and navigation), there is a lack of benchmark ultrasonic datasets that consist of spatial and temporal data to verify the usability of spatial and temporal ultrasonic cues. In this paper, we are the first to propose a Spatio-Temporal Ultrasonic Dataset (STUD), which aims to develop the ability of ultrasonic sensors by mining spatial and temporal information from multiple ultrasonic measurements. In particular, we first propose a novel Spatio-Temporal (ST) ultrasonic data gathering scheme, in which an innovatory data instance is designed. Besides, part of the data in the STUD is collected in a robot simulator, in which a well-designed corridor map is utilized to increase the data diversity. Then a selection algorithm is proposed to find a proper length of data sequences to obtain the best description of the navigation environments. Finally, we present an end-to-end learning benchmark model that learns driving policies by extracting spatial and temporal ultrasonic cues from the STUD. With the help of our STUD and this benchmark model, more powerful deep neural networks can be trained for addressing the tasks of indoor navigation or motion planning of mobile robots, which is unachievable by using the existing ultrasonic datasets. Comparison experiments verified the effectiveness of spatial and temporal ultrasonic cues for the robot driving policy learning.",
        "primary_area": "",
        "author": "Shuai Wang;Jiahu Qin;Zhanpeng Zhang;Shuai Wang;Jiahu Qin;Zhanpeng Zhang",
        "authorids": "/37086576976;/37398575900;/37088690900;/37086576976;/37398575900;/37088690900",
        "aff": "Department of Automation, University of Science and Technology of China, Hefei, China; Department of Automation, University of Science and Technology of China, Hefei, China; Department of Automation, University of Science and Technology of China, Hefei, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340765/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:MQhZz3wLJUkJ:scholar.google.com/&scioq=Spatio-Temporal+Ultrasonic+Dataset:+Learning+Driving+from+Spatial+and+Temporal+Ultrasonic+Cues&hl=en&as_sdt=0,33",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Science and Technology of China",
        "aff_unique_dep": "Department of Automation",
        "aff_unique_url": "http://www.ustc.edu.cn",
        "aff_unique_abbr": "USTC",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Hefei",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9341333",
        "title": "Spatio-temporal Attention Model for Tactile Texture Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "Recently, tactile sensing has attracted great interest in robotics, especially for facilitating exploration of unstructured environments and effective manipulation. A detailed understanding of the surface textures via tactile sensing is essential for many of these tasks. Previous works on texture recognition using camera based tactile sensors have been limited to treating all regions in one tactile image or all samples in one tactile sequence equally, which includes much irrelevant or redundant information. In this paper, we propose a novel Spatio-Temporal Attention Model (STAM) for tactile texture recognition, which is the very first of its kind to our best knowledge. The proposed STAM pays attention to both spatial focus of each single tactile texture and the temporal correlation of a tactile sequence. In the experiments to discriminate 100 different fabric textures, the spatially and temporally selective attention has resulted in a significant improvement of the recognition accuracy, by up to 18.8%, compared to the non-attention based models. Specifically, after introducing noisy data that is collected before the contact happens, our proposed STAM can learn the salient features efficiently and the accuracy can increase by 15.23% on average compared with the CNN based baseline approach. The improved tactile texture perception can be applied to facilitate robot tasks like grasping and manipulation.",
        "primary_area": "",
        "author": "Guanqun Cao;Yi Zhou;Danushka Bollegala;Shan Luo;Guanqun Cao;Yi Zhou;Danushka Bollegala;Shan Luo",
        "authorids": "/37088686447;/37088690376;/37540532800;/37085478830;/37088686447;/37088690376;/37540532800;/37085478830",
        "aff": "Department of Computer Science, University of Liverpool, Liverpool, U.K; Department of Computer Science, University of Liverpool, Liverpool, U.K; Department of Computer Science, University of Liverpool, Liverpool, U.K; Department of Computer Science, University of Liverpool, Liverpool, U.K",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341333/",
        "gs_citation": 48,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2199119744359435446&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Liverpool",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.liverpool.ac.uk",
        "aff_unique_abbr": "Liv Uni",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Liverpool",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9341265",
        "title": "Spectral-GANs for High-Resolution 3D Point-cloud Generation",
        "track": "main",
        "status": "Poster",
        "abstract": "Point-clouds are a popular choice for robotics and computer vision tasks due to their accurate shape description and direct acquisition from range-scanners. This demands the ability to synthesize and reconstruct high-quality point-clouds. Current deep generative models for 3D data generally work on simplified representations (e.g., voxelized objects) and cannot deal with the inherent redundancy and irregularity in point-clouds. A few recent efforts on 3D point-cloud generation offer limited resolution and their complexity grows with the increase in output resolution. In this paper, we develop a principled approach to synthesize 3D point-clouds using a spectral-domain Generative Adversarial Network (GAN). Our spectral representation is highly structured and allows us to disentangle various frequency bands such that the learning task is simplified for a GAN model. As compared to spatial-domain generative approaches, our formulation allows us to generate high-resolution point-clouds with minimal computational overhead. Furthermore, we propose a fully differentiable block to transform from the spectral to the spatial domain and back, thereby allowing us to integrate knowledge from well-established spatial models. We demonstrate that Spectral-GAN performs well for point-cloud generation task. Additionally, it can learn a highly discriminative representation in an unsupervised fashion and can be used to accurately reconstruct 3D objects. Our codes are available at https://github.com/samgregoost/Spectral-GAN/.",
        "primary_area": "",
        "author": "Sameera Ramasinghe;Salman Khan;Nick Barnes;Stephen Gould;Sameera Ramasinghe;Salman Khan;Nick Barnes;Stephen Gould",
        "authorids": "/37085480970;/37085473843;/37281309800;/37408560000;/37085480970;/37085473843;/37281309800;/37408560000",
        "aff": "CSIRO, Data61, Canberra, AU; College of Engineering and Computer Science (CECS), Australian National University (ANU), Canberra, AU; College of Engineering and Computer Science (CECS), Australian National University (ANU), Canberra, AU; College of Engineering and Computer Science (CECS), Australian National University (ANU), Canberra, AU",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341265/",
        "gs_citation": 42,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8765481962291344156&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "CSIRO;Australian National University",
        "aff_unique_dep": "Data61;College of Engineering and Computer Science",
        "aff_unique_url": "https://www.csiro.au;https://www.anu.edu.au",
        "aff_unique_abbr": "CSIRO;ANU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Canberra",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "9341542",
        "title": "Speed and Memory Efficient Dense RGB-D SLAM in Dynamic Scenes",
        "track": "main",
        "status": "Poster",
        "abstract": "Real-time dense 3D localization and mapping systems are required to enable robotics platforms to interact in and with their environments. Several solutions have used surfel representations to model the world. While they produce impressive results, they require heavy and costly hardware to operate properly. Many of them are also limited to static environments and small inter-frame motions. Whereas most of the state of the art approaches focus on the accuracy of the reconstruction, we assume that many robotics applications do not require a high resolution level in the rebuilt surface and can benefit from a less accurate but less expensive map, so as to gain in run-time and memory efficiency. In this paper we propose a fast RGB-D SLAM articulated around a rough and lightweight 3D representation for dense compact mapping in dynamic indoor environment, targeting mainstream computing platforms. A simple and fast formulation to detect and filter out dynamic elements is also presented. We show the robustness of our system, its low memory requirement and the good performance it enables.",
        "primary_area": "",
        "author": "Bruce Canovas;Mich\u00e8le Rombaut;Amaury N\u00e8gre;Denis Pellerin;Serge Olympieff;Bruce Canovas;Mich\u00e8le Rombaut;Amaury N\u00e8gre;Denis Pellerin;Serge Olympieff",
        "authorids": "/37088689926;/37433195000;/37681775300;/37333319900;/37088688681;/37088689926;/37433195000;/37681775300;/37333319900;/37088688681",
        "aff": "CNRS, Grenoble INP, GIPSA-lab, Univ. Grenoble Alpes, Grenoble, France; CNRS, Grenoble INP, GIPSA-lab, Univ. Grenoble Alpes, Grenoble, France; CNRS, Grenoble INP, GIPSA-lab, Univ. Grenoble Alpes, Grenoble, France; CNRS, Grenoble INP, GIPSA-lab, Univ. Grenoble Alpes, Grenoble, France; CNRS, Grenoble INP, GIPSA-lab, Univ. Grenoble Alpes, Grenoble, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341542/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14524507877226265240&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "CNRS",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.cnrs.fr",
        "aff_unique_abbr": "CNRS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9340721",
        "title": "Spiking Neurons Ensemble for Movement Generation in Dynamically Changing Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Spiking neurons might play a larger role than simply as an efficient signal transmitter. Several studies have demonstrated how movements can be generated using networks of spiking neurons. However, the complexity of spiking neural networks makes their implementation difficult, and the use of spiking neurons in robotics has remained largely impractical. In this paper, we show that the addition of a single layer of spiking neurons can help improve performance on stabilization tasks in dynamically changing environments. In a one-dimensional inverted pendulum stabilization task, the spiking neurons seem to expand the space of usable parameters of the controller. Using a robot arm in 3-D space, the additional layer of spiking neurons suffices to improve performance up to 30% on an inverted pendulum stabilization task. We expect this technique to enhance performance in most stabilization tasks but also tasks that are essentially similar such as reaching tasks and posture control. We also expect the effects of this layer to be greatest when the optimal tuning of control parameters is difficult, such as when the environment is unpredictable and dynamic.",
        "primary_area": "",
        "author": "Kaname Favier;Shogo Yonekura;Yasuo Kuniyoshi;Kaname Favier;Shogo Yonekura;Yasuo Kuniyoshi",
        "authorids": "/37088689039;/37586947200;/37299294900;/37088689039;/37586947200;/37299294900",
        "aff": "Department of Mechano-Informatics, Faculty of Engineering, The University of Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340721/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16830502240161990759&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "The University of Tokyo",
        "aff_unique_dep": "Department of Mechano-Informatics",
        "aff_unique_url": "https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "UTokyo",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Tokyo;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9340797",
        "title": "SplitFlyer: a Modular Quadcoptor that Disassembles into Two Flying Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "We introduce SplitFlyer-a novel quadcopter with an ability to disassemble into two self-contained bicopters through human assistance. As a subunit, the bicopter is a severely underactuated aerial vehicle equipped with only two propellers. Still, each bicopter is capable of independent flight. To achieve this, we provide an analysis of the system dynamics by relaxing the control over the yaw rotation, allowing the bicopter to maintain its large spinning rate in flight. Taking into account the gyroscopic motion, the dynamics are described and a cascaded control strategy is developed. We constructed a transformable prototype to demonstrate consecutive flights in both configurations. The results verify the proposed control strategy and show the potential of the platform for future research in modular aerial swarm robotics.",
        "primary_area": "",
        "author": "Songnan Bai;Shixin Tan;Pakpong Chirarattananon;Songnan Bai;Shixin Tan;Pakpong Chirarattananon",
        "authorids": "/37086482319;/37088690687;/38364343100;/37086482319;/37088690687;/38364343100",
        "aff": "Department of Biomedical Engineering, City University of Hong Kong, China; Department of Biomedical Engineering, City University of Hong Kong, China; Department of Biomedical Engineering, City University of Hong Kong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340797/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7801731762665812994&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "City University of Hong Kong",
        "aff_unique_dep": "Department of Biomedical Engineering",
        "aff_unique_url": "https://www.cityu.edu.hk",
        "aff_unique_abbr": "CityU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9341082",
        "title": "SplitFusion: Simultaneous Tracking and Mapping for Non-Rigid Scenes",
        "track": "main",
        "status": "Poster",
        "abstract": "We present SplitFusion, a novel dense RGB-D SLAM framework that simultaneously performs tracking and dense reconstruction for both rigid and non-rigid components of the scene. SplitFusion first adopts deep learning based semantic instant segmentation technique to split the scene into rigid or non-rigid surfaces. The split surfaces are independently tracked via rigid or non-rigid ICP and reconstructed through incremental depth map fusion. Experimental results show that the proposed approach can provide not only accurate environment maps but also well-reconstructed non-rigid targets, e.g., the moving humans.",
        "primary_area": "",
        "author": "Yang Li;Tianwei Zhang;Yoshihiko Nakamura;Tatsuya Harada;Yang Li;Tianwei Zhang;Yoshihiko Nakamura;Tatsuya Harada",
        "authorids": "/37088446563;/37086443242;/37280754600;/37274148900;/37088446563;/37086443242;/37280754600;/37274148900",
        "aff": "Department of Mechano-Informatics, Graduate School of Information Science and Technology, the University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, the University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, the University of Tokyo, Tokyo, Japan; RIKEN",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341082/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5821168987453821882&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "University of Tokyo;RIKEN",
        "aff_unique_dep": "Department of Mechano-Informatics;",
        "aff_unique_url": "https://www.u-tokyo.ac.jp;https://www.riken.jp",
        "aff_unique_abbr": "UTokyo;RIKEN",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Tokyo;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9341549",
        "title": "SpoxelNet: Spherical Voxel-based Deep Place Recognition for 3D Point Clouds of Crowded Indoor Spaces",
        "track": "main",
        "status": "Poster",
        "abstract": "With its essential role in achieving full autonomy of robot navigation, place recognition has been widely studied with various approaches. Recently, numerous point cloud-based methods with deep learning implementation have been proposed with promising results for their application in outdoor environments. However, their performances are not as promising in indoor spaces because of the high level of occlusion caused by structures and moving objects. In this paper, we propose a point cloud-based place recognition method for crowded indoor spaces. The method consists of voxelizing point clouds in spherical coordinates and defining the occupancy of each voxel in ternary values. We also present SpoxelNet, a neural network architecture that encodes input voxels into global descriptor vectors by extracting the structural features in both fine and coarse scales. It also reinforces its performance in occluded places by concatenating feature vectors from multiple directions. Our method is evaluated in various indoor datasets and outperforms existing methods with a large margin.",
        "primary_area": "",
        "author": "Min Young Chang;Suyong Yeon;Soohyun Ryu;Donghwan Lee;Min Young Chang;Suyong Yeon;Soohyun Ryu;Donghwan Lee",
        "authorids": "/37088686315;/37085644725;/37711035700;/37088886388;/37088686315;/37085644725;/37711035700;/37088886388",
        "aff": "Columbia University; Researchers of NAVER LABS, Seongnam-si, South Korea; Researchers of NAVER LABS, Seongnam-si, South Korea; Researchers of NAVER LABS, Seongnam-si, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341549/",
        "gs_citation": 37,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18379206787825321061&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "Columbia University;NAVER LABS",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.columbia.edu;https://www.naverlabs.com",
        "aff_unique_abbr": "Columbia;NAVER LABS",
        "aff_campus_unique_index": "1;1;1",
        "aff_campus_unique": ";Seongnam-si",
        "aff_country_unique_index": "0;1;1;1",
        "aff_country_unique": "United States;South Korea"
    },
    {
        "id": "9340883",
        "title": "Squash-Box Feasibility Driven Differential Dynamic Programming",
        "track": "main",
        "status": "Poster",
        "abstract": "Recently, Differential Dynamic Programming (DDP) and other similar algorithms have become the solvers of choice when performing non-linear Model Predictive Control (nMPC) with modern robotic devices. The reason is that they have a lower computational cost per iteration when compared with off-the-shelf Non-Linear Programming (NLP) solvers, which enables its online operation. However, they cannot handle constraints, and are known to have poor convergence capabilities. In this paper, we propose a method to solve the optimal control problem with control bounds through a squashing function (i.e., a sigmoid, which is bounded by construction). It has been shown that a naive use of squashing functions damage the convergence rate. To tackle this, we first propose to add a quadratic barrier that avoids the difficulty of the plateau produced by the sigmoid. Second, we add an outer loop that adapts both the sigmoid and the barrier; it makes the optimal control problem with the squashing function converge to the original control-bounded problem. To validate our method, we present simulation results for different types of platforms including a multi-rotor, a biped, a quadruped and a humanoid robot.",
        "primary_area": "",
        "author": "Josep Marti-Saumell;Joan Sol\u00e0;Carlos Mastalli;Angel Santamaria-Navarro;Josep Marti-Saumell;Joan Sol\u00e0;Carlos Mastalli;Angel Santamaria-Navarro",
        "authorids": "/37088506710;/37407733200;/37085537096;/37077359600;/37088506710;/37407733200;/37085537096;/37077359600",
        "aff": "Institut de Rob\u00f3tica i Inform\u00e0tica Industrial, CSIC-UPC, Barcelona, Spain; Institut de Rob\u00f3tica i Inform\u00e0tica Industrial, CSIC-UPC, Barcelona, Spain; Informatics School, University of Edinburgh and the Alan Turing Institute, Edinburgh, UK; NASA-JPL, California Institute of Technology, Pasadena, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340883/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4070151352804023856&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 13,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;2",
        "aff_unique_norm": "Institut de Rob\u00f3tica i Inform\u00e0tica Industrial;University of Edinburgh;California Institute of Technology",
        "aff_unique_dep": ";Informatics School;",
        "aff_unique_url": "http://www.iri.upc.edu/;https://www.ed.ac.uk;https://www.caltech.edu",
        "aff_unique_abbr": "IRI;Edinburgh;Caltech",
        "aff_campus_unique_index": "0;0;1;2",
        "aff_campus_unique": "Barcelona;Edinburgh;Pasadena",
        "aff_country_unique_index": "0;0;1;2",
        "aff_country_unique": "Spain;United Kingdom;United States"
    },
    {
        "id": "9341461",
        "title": "Stable Crawling Policy for Wearable SuperLimbs Attached to a Human with Tuned Impedance",
        "track": "main",
        "status": "Poster",
        "abstract": "A control algorithm that allows a human model to crawl using a pair of supernumerary robotic limbs (SuperLimbs) is presented. The human model and SuperLimbs are coupled by a compliant harness. This work is inspired by the need for wearable robotic systems that can support workers engaged in fatiguing tasks. The walking policy is developed based on Lyapunov analysis. The volume of the region of attraction (ROA) of the system is used to quantify robustness and identify the optimal harness compliance. Simulation experiments are used to verify the performance of the algorithm. The presented formulation allows us to guarantee stable locomotion under nominal conditions and define robustness against modeling error and perturbations. This study is also the first, that the authors are aware of, to address cooperative crawling between a human and a wearable robotic system with state feedback.",
        "primary_area": "",
        "author": "Phillip H. Daniel;Harry H. Asada;Phillip H. Daniel;Harry H. Asada",
        "authorids": "/38667464200;/37279023100;/38667464200;/37279023100",
        "aff": "Department of Mechanical Engineering, Massachusetts Institute of Technology, Cambridge, MA, USA; Department of Mechanical Engineering, Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341461/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14670758714654671305&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341362",
        "title": "Stable In-Grasp Manipulation with a Low-Cost Robot Hand by Using 3-Axis Tactile Sensors with a CNN",
        "track": "main",
        "status": "Poster",
        "abstract": "The use of tactile information is one of the most important factors for achieving stable in-grasp manipulation. Especially with low-cost robotic hands that provide low-precision control, robust in-grasp manipulation is challenging. Abundant tactile information could provide the required feed-back to achieve reliable in-grasp manipulation also in such cases. In this research, soft distributed 3-axis skin sensors (\"uSkin\") and 6-axis F/T (force/torque) sensors were mounted on each fingertip of an Allegro Hand to provide rich tactile information. These sensors yielded 78 measurements for each fingertip (72 measurements from the uSkin and 6 measurements from the 6-axis F/T sensor). However, such high-dimensional tactile information can be difficult to process because of the complex contact states between the grasped object and the fingertips. Therefore, a convolutional neural network (CNN) was employed to process the tactile information. In this paper, we explored the importance of the different sensors for achieving in-grasp manipulation. Successful in-grasp manipulation with untrained daily objects was achieved when both 3-axis uSkin and 6-axis F/T information was provided and when the information was processed using a CNN.",
        "primary_area": "",
        "author": "Satoshi Funabashi;Tomoki Isobe;Shun Ogasa;Tetsuya Ogata;Alexander Schmitz;Tito Pradhono Tomo;Shigeki Sugano;Satoshi Funabashi;Tomoki Isobe;Shun Ogasa;Tetsuya Ogata;Alexander Schmitz;Tito Pradhono Tomo;Shigeki Sugano",
        "authorids": "/37085727304;/37088691309;/37086166387;/37273829100;/37587110100;/37085618711;/37274050800;/37085727304;/37088691309;/37086166387;/37273829100;/37587110100;/37085618711;/37274050800",
        "aff": "Dept. of Modern Mechanical Engineering, Faculty of Science and Engineering, Waseda University, Tokyo, Japan; Dept. of Modern Mechanical Engineering, Faculty of Science and Engineering, Waseda University, Tokyo, Japan; Dept. of Modern Mechanical Engineering, Faculty of Science and Engineering, Waseda University, Tokyo, Japan; Dept. of Intermedia Art and Science, Faculty of Science and Engineering, Waseda University, Tokyo, Japan; Dept. of Modern Mechanical Engineering, Faculty of Science and Engineering, Waseda University, Tokyo, Japan; Dept. of Modern Mechanical Engineering, Faculty of Science and Engineering, Waseda University, Tokyo, Japan; Dept. of Modern Mechanical Engineering, Faculty of Science and Engineering, Waseda University, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341362/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11182520875630844131&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Waseda University",
        "aff_unique_dep": "Dept. of Modern Mechanical Engineering",
        "aff_unique_url": "https://www.waseda.jp/top",
        "aff_unique_abbr": "Waseda",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9341804",
        "title": "Staging energy sources to extend flight time of a multirotor UAV",
        "track": "main",
        "status": "Poster",
        "abstract": "Energy sources such as batteries do not decrease in mass after consumption, unlike combustion-based fuels. We present the concept of staging energy sources, i.e. consuming energy in stages and ejecting used stages, to progressively reduce the mass of aerial vehicles in-flight which reduces power consumption, and consequently increases flight time. A flight time vs. energy storage mass analysis is presented to show the endurance benefit of staging to multirotors. We consider two specific problems in discrete staging - optimal order of staging given a certain number of energy sources, and optimal partitioning of a given energy storage mass budget into a given number of stages. We then derive results for a continuously staged case of an internal combustion engine driving propellers. Notably, we show that a multirotor powered by internal combustion has an upper limit on achievable flight time independent of the available fuel mass. Lastly, we validate the analysis with flight experiments on a custom two-stage battery-powered quadcopter. This quadcopter can eject a battery stage after consumption in-flight using a custom-designed mechanism, and continue hovering using the next stage. The experimental flight times match well with those predicted from the analysis for our vehicle. We achieve a 19% increase in flight time using the batteries in two stages as compared to a single stage.",
        "primary_area": "",
        "author": "Karan P. Jain;Jerry Tang;Koushil Sreenath;Mark W. Mueller;Karan P. Jain;Jerry Tang;Koushil Sreenath;Mark W. Mueller",
        "authorids": "/37086939996;/37088688647;/37563179200;/37086448968;/37086939996;/37088688647;/37563179200;/37086448968",
        "aff": "High Performance Robotics Lab; High Performance Robotics Lab; Dept. of Mechanical Engineering, Hybrid Robotics group, UC Berkeley, CA, USA; High Performance Robotics Lab",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341804/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7893539551754138686&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "High Performance Robotics Lab;University of California, Berkeley",
        "aff_unique_dep": "Robotics;Department of Mechanical Engineering",
        "aff_unique_url": ";https://www.berkeley.edu",
        "aff_unique_abbr": ";UC Berkeley",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Berkeley",
        "aff_country_unique_index": "1",
        "aff_country_unique": ";United States"
    },
    {
        "id": "9340994",
        "title": "Standard Deep Generative Models for Density Estimation in Configuration Spaces: A Study of Benefits, Limits and Challenges",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep Generative Models such as Generative Adversarial Networks (GAN) and Variational Autoencoders (VAE) have found multiple applications in Robotics, with recent works suggesting the potential use of these methods as a generic solution for the estimation of sampling distributions for motion planning in parameterized sets of environments. In this work we provide a first empirical study of challenges, benefits and drawbacks of utilizing vanilla GANs and VAEs for the approximation of probability distributions arising from sampling-based motion planner path solutions. We present an evaluation on a sequence of simulated 2D configuration spaces of increasing complexity and a 4D planar robot arm scenario and find that vanilla GANs and VAEs both outperform classical statistical estimation by an n-dimensional histogram in our chosen scenarios. We furthermore highlight differences in convergence and noisiness between the trained models and propose and study a benchmark sequence of planar C-space environments parameterized by opened or closed doors. In this setting, we find that the chosen geometrical embedding of the parameters of the family of considered C-spaces is a key performance contributor that relies heavily on human intuition about C-space structure at present. We discuss some of the challenges of parameter selection and convergence for applying this approach with an out-of-the box GAN and VAE model.",
        "primary_area": "",
        "author": "Robert Gieselmann;Florian T. Pokorny;Robert Gieselmann;Florian T. Pokorny",
        "authorids": "/37086547525;/37077268000;/37086547525;/37077268000",
        "aff": "RPL, EECS, KTH Royal Institute of Technology, Stockholm, Sweden; RPL, EECS, KTH Royal Institute of Technology, Stockholm, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340994/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12104412989715835627&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "KTH Royal Institute of Technology",
        "aff_unique_dep": "EECS",
        "aff_unique_url": "https://www.kth.se",
        "aff_unique_abbr": "KTH",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Stockholm",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Sweden"
    },
    {
        "id": "9341342",
        "title": "Static Characteristics of Fire Hose Actuators and Design of a Compliant Pneumatic Rotary Drive for Robotics",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we present and explain in detail the design of a new type of pneumatic actuator made of fire hose, the fire hose actuator (FHA), see Fig. 1. We model the force output of this type of actuator and we compare the theoretic results to the data measured on the laboratory test stand.Furthermore, we present the design of a pneumatic rotary drive that is actuated by four of the above-mentioned FHAs. The drive unit features intrinsic compliance and it is capable of high-precision positioning. Due to these characteristics, the design concept of the rotary drive is suitable for the potential use in robotics, especially in human-robot collaboration. In addition, we model the static torque distribution of the rotary drive and we compare the theoretic results to the data measured on the realized laboratory test stand. Moreover, we discuss the most important characteristics of the rotary drive. Hence, we present measurements of the adjustable stiffness and we show that high-precision positioning is possible with the system, reaching in ideal areas every bit of the used 17-bit encoder with a resolution of 0.0027\u00b0. Moreover, the drive unit is capable of continuous rotation while the maximum continuous torque possible is found to be 63.1 Nm.",
        "primary_area": "",
        "author": "Johannes T. Stoll;Kevin Schanz;Michael Derstroff;Andreas Pott;Johannes T. Stoll;Kevin Schanz;Michael Derstroff;Andreas Pott",
        "authorids": "/38547368200;/37086934005;/37088690785;/38539917600;/38547368200;/37086934005;/37088690785;/38539917600",
        "aff": "department \u2018Robot and assistive systems\u2019, Fraunhofer Institute for Manufacturing Engineering and Automation IPA, Stuttgart, Germany; department \u2018Robot and assistive systems\u2019, Fraunhofer Institute for Manufacturing Engineering and Automation IPA, Stuttgart, Germany; department \u2018Robot and assistive systems\u2019, Fraunhofer Institute for Manufacturing Engineering and Automation IPA, Stuttgart, Germany; Institute for Control Engineering of Machine Tools and Manufacturing Units (ISW), University of Stuttgart, Stuttgart, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341342/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8532946567652878808&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Fraunhofer Institute for Manufacturing Engineering and Automation IPA;University of Stuttgart",
        "aff_unique_dep": "Robot and assistive systems;Institute for Control Engineering of Machine Tools and Manufacturing Units (ISW)",
        "aff_unique_url": "https://www.ipa.fraunhofer.de;https://www.uni-stuttgart.de",
        "aff_unique_abbr": "Fraunhofer IPA;Uni Stuttgart",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Stuttgart",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9341078",
        "title": "Steering Magnetic Robots in Two Axes with One Pair of Maxwell Coils",
        "track": "main",
        "status": "Poster",
        "abstract": "This work demonstrates a novel approach to steering a magnetic swimming robot in two dimensions with a single pair of Maxwell coils. By leveraging the curvature of the magnetic field gradient, we achieve motion along two axes. This method allows us to control medical magnetic robots using only existing MRI technology, without requiring additional hardware or posing any additional risk to the patient. We implement a switching time optimization algorithm which generates a schedule of control inputs that direct the swimming robot to a goal location in the workspace. By alternating the direction of the magnetic field gradient produced by the single pair of coils per this schedule, we are able to move the swimmer to desired points in two dimensions. Finally, we demonstrate the feasibility of our approach with an experimental implementation on the millimeter scale and discuss future opportunities to expand this work to the microscale, as well as other control problems and real-world applications.",
        "primary_area": "",
        "author": "Emma Benjaminson;Matthew Travers;Rebecca Taylor;Emma Benjaminson;Matthew Travers;Rebecca Taylor",
        "authorids": "/37088688078;/37545390200;/37088525057;/37088688078;/37545390200;/37088525057",
        "aff": "Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, Pennsylvania; Robotics Institute, Carnegie Mellon University, Pittsburgh, Pennsylvania; Department of Electrical and Computer Engineering, Carnegie Mellon University, Pittsburgh, Pennsylvania",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341078/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11415946003906054839&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340852",
        "title": "Stir to Pour: Efficient Calibration of Liquid Properties for Pouring Actions",
        "track": "main",
        "status": "Poster",
        "abstract": "Humans use simple probing actions to develop intuition about the physical behavior of common objects. Such intuition is particularly useful for adaptive estimation of favorable manipulation strategies of those objects in novel contexts. For example, observing the effect of tilt on a transparent bottle containing an unknown liquid provides clues on how the liquid might be poured. It is desirable to equip general-purpose robotic systems with this capability because it is inevitable that they will encounter novel objects and scenarios. In this paper, we teach a robot to use a simple, specified probing strategy - stirring with a stick- to reduce spillage when pouring unknown liquids. In the probing step, we continuously observe the effects of a real robot stirring a liquid, while simultaneously tuning the parameters to a model (simulator) until the two outputs are in agreement. We obtain optimal simulation parameters, characterizing the unknown liquid, via a Bayesian Optimizer that minimizes the discrepancy between real and simulated outcomes. Then, we optimize the pouring policy conditioning on the optimal simulation parameters determined via stirring. We show that using stirring as a probing strategy result in reduced spillage for three qualitatively different liquids when executed on a UR10 Robot, compared to probing via pouring. Finally, we provide quantitative insights into the reason for stirring being a suitable calibration task for pouring -a step towards automatic discovery of probing strategies.",
        "primary_area": "",
        "author": "Tatiana Lopez-Guevara;Rita Pucci;Nicholas K. Taylor;Michael U. Gutmann;Suhramanian Ramamoorthy;Kartic Suhr;Tatiana Lopez-Guevara;Rita Pucci;Nicholas K. Taylor;Michael U. Gutmann;Suhramanian Ramamoorthy;Kartic Suhr",
        "authorids": "/38494831100;/37088687779;/37267180500;/37088687796;/37529920500;/37088689603;/38494831100;/37088687779;/37267180500;/37088687796;/37529920500;/37088689603",
        "aff": "Heriot-Watt University, Currie, Edinburgh; University of Udine; Heriot-Watt University, Currie, Edinburgh; University of Udine; University of Udine; University of Udine",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340852/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9380052527101065258&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;1;1;1",
        "aff_unique_norm": "Heriot-Watt University;University of Udine",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.hw.ac.uk;https://www.unidue.it",
        "aff_unique_abbr": "HWU;",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Edinburgh;",
        "aff_country_unique_index": "0;1;0;1;1;1",
        "aff_country_unique": "United Kingdom;Italy"
    },
    {
        "id": "9340780",
        "title": "Stochastic Grounded Action Transformation for Robot Learning in Simulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Robot control policies learned in simulation do not often transfer well to the real world. Many existing solutions to this sim-to-real problem, such as the Grounded Action Transformation (GAT) algorithm, seek to correct for- or ground-these differences by matching the simulator to the real world. However, the efficacy of these approaches is limited if they do not explicitly account for stochasticity in the target environment. In this work, we analyze the problems associated with grounding a deterministic simulator in a stochastic real world environment, and we present examples where GAT fails to transfer a good policy due to stochastic transitions in the target domain. In response, we introduce the Stochastic Grounded Action Transformation (SGAT) algorithm, which models this stochasticity when grounding the simulator. We find experimentally-for both simulated and physical target domains-that SGAT can find policies that are robust to stochasticity in the target domain.",
        "primary_area": "",
        "author": "Siddharth Desai;Haresh Karnan;Josiah P. Hanna;Garrett Warnell;and Peter Stone;Siddharth Desai;Haresh Karnan;Josiah P. Hanna;Garrett Warnell;and Peter Stone",
        "authorids": "/37088687601;/37086310655;/37088467292;/37079072000;/37088689673;/37088687601;/37086310655;/37088467292;/37079072000;/37088689673",
        "aff": "Department of Mechanical Engineering, The University of Texas at Austin; Department of Mechanical Engineering, The University of Texas at Austin; Computer Sciences Department, University of Wisconsin, Madison; Computer Sciences Department, University of Wisconsin, Madison; Army Research Laboratory",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340780/",
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3020125285296430098&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;1;2",
        "aff_unique_norm": "The University of Texas at Austin;University of Wisconsin-Madison;Army Research Laboratory",
        "aff_unique_dep": "Department of Mechanical Engineering;Computer Sciences Department;",
        "aff_unique_url": "https://www.utexas.edu;https://www.wisc.edu;https://www.arl.army.mil",
        "aff_unique_abbr": "UT Austin;UW-Madison;ARL",
        "aff_campus_unique_index": "0;0;1;1",
        "aff_campus_unique": "Austin;Madison;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340774",
        "title": "Stochastic Neural Control using Raw Pointcloud Data and Building Information Models",
        "track": "main",
        "status": "Poster",
        "abstract": "Recently, there has been a lot of excitement surrounding the use of reinforcement learning for robot control and navigation. However, many of these algorithms encounter difficulty navigating long or complex trajectories. This paper presents a new mobile robot control system called Stochastic Neural Control (SNC), that uses a stochastic policy gradient algorithm for local control and a modified probabilistic roadmap planner for global motion planning. In SNC, each mobile robot control decision is conditioned on observations from the robot sensors as well as pointcloud data, allowing the robot to safely operate within geometrically complex environments. SNC is tested on a number of challenging navigation tasks and learns advanced policies for navigation, collision-avoidance and fall-prevention. Three variants of the SNC system are evaluated against a conventional motion planning baseline. SNC outperforms the baseline and four other similar RL navigation systems in many of the trials. Finally, we present a strategy for transferring SNC from a simulated environment to a real robot. We empirically show that the SNC system exhibits good policies for mobile robot navigation when controlling a real mobile robot.",
        "primary_area": "",
        "author": "Max Ferguson;Kincho H. Law;Max Ferguson;Kincho H. Law",
        "authorids": "/37086181266;/37343014500;/37086181266;/37343014500",
        "aff": "Department of Civil and Environmental Engineering, Stanford University, Stanford, CA, USA; Faculty of the Department of Civil and Environmental Engineering, Stanford University, Stanford, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340774/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:c0GbBSIf_NAJ:scholar.google.com/&scioq=Stochastic+Neural+Control+using+Raw+Pointcloud+Data+and+Building+Information+Models&hl=en&as_sdt=0,5",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "Department of Civil and Environmental Engineering",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340645",
        "title": "Subsurface Sampling Robot for Time-limited Asteroid Exploration",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel approach to sampling subsurface asteroidal regolith under severe time constraints. Sampling operations that must be completed within a few hours require techniques that can manage subsurface obstructions that may be encountered. The large uncertainties due to our lack of knowledge of regolith properties also make sampling difficult. To aid in managing these challenges, machine learning-based detection methods using tactile feedback can detect the presence of rocks deeper than the length of the probe, ensuring reliable sampling in unobstructed areas. In addition, given the variability of soil hardness and the short time available, a corer shooting mechanism has been developed that uses a special shape-memory alloy to collect regolith in about a minute. Experiments on subsurface obstacle detection and shooting-corer ejection tests were conducted to demonstrate the functionality of this approach.",
        "primary_area": "",
        "author": "Hiroki Kato;Yasutaka Satou;Kent Yoshikawa;Masatsugu Otsuki;Hirotaka Sawada;Takeshi Kuratomi;Nana Hidaka;Hiroki Kato;Yasutaka Satou;Kent Yoshikawa;Masatsugu Otsuki;Hirotaka Sawada;Takeshi Kuratomi;Nana Hidaka",
        "authorids": "/37085383641;/37088470069;/37086107239;/37340705500;/37086079833;/37088691103;/37088686272;/37085383641;/37088470069;/37086107239;/37340705500;/37086079833;/37088691103;/37088686272",
        "aff": "WEL Research Co., Ltd, Tsukuba, Ibaraki, JAPAN; WEL Research Co., Ltd, Sagamihara, Kanagawa; WEL Research Co., Ltd, Sagamihara, Kanagawa; WEL Research Co., Ltd, Sagamihara, Kanagawa; WEL Research Co., Ltd, Sagamihara, Kanagawa; Japan Aerospace Exploration Agency (JAXA), Ichihara, Chiba; Japan Aerospace Exploration Agency (JAXA), Ichihara, Chiba",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340645/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11664443597419859679&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;1;1",
        "aff_unique_norm": "WEL Research Co., Ltd;Japan Aerospace Exploration Agency",
        "aff_unique_dep": ";",
        "aff_unique_url": ";https://www.jaxa.jp",
        "aff_unique_abbr": ";JAXA",
        "aff_campus_unique_index": "0;2;2",
        "aff_campus_unique": "Tsukuba;;Ichihara",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9341111",
        "title": "Supervised Autoencoder Joint Learning on Heterogeneous Tactile Sensory Data: Improving Material Classification Performance",
        "track": "main",
        "status": "Poster",
        "abstract": "The sense of touch is an essential sensing modality for a robot to interact with the environment as it provides rich and multimodal sensory information upon contact. It enriches the perceptual understanding of the environment and closes the loop for action generation. One fundamental area of perception that touch dominates over other sensing modalities, is the understanding of the materials that it interacts with, for example, glass versus plastic. However, unlike the senses of vision and audition which have standardized data format, the format for tactile data is vastly dictated by the sensor manufacturer, which makes it difficult for large-scale learning on data collected from heterogeneous sensors, limiting the usefulness of publicly available tactile datasets. This paper investigates the joint learnability of data collected from two tactile sensors performing a touch sequence on some common materials. We propose a supervised recurrent autoencoder framework to perform joint material classification task to improve the training effectiveness. The framework is implemented and tested on the two sets of tactile data collected in sliding motion on 20 material textures using the iCub RoboSkin tactile sensors and the SynTouch BioTac sensor respectively. Our results show that the learning efficiency and accuracy improve for both datasets through the joint learning as compared to independent dataset training. This suggests the usefulness for large-scale open tactile datasets sharing with different sensors.",
        "primary_area": "",
        "author": "Ruihan Gao;Tasbolat Taunyazov;Zhiping Lin;Yan Wu;Ruihan Gao;Tasbolat Taunyazov;Zhiping Lin;Yan Wu",
        "authorids": "/37086880837;/37085673647;/37277999300;/37085344977;/37086880837;/37085673647;/37277999300;/37085344977",
        "aff": "School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Computing, National University of Singapore, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; Robotics & Autonomous Systems Department, A*STAR Institute for Infocomm Research, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341111/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13924430981866183948&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;2",
        "aff_unique_norm": "Nanyang Technological University;National University of Singapore;A*STAR Institute for Infocomm Research",
        "aff_unique_dep": "School of Electrical and Electronic Engineering;School of Computing;Robotics & Autonomous Systems Department",
        "aff_unique_url": "https://www.ntu.edu.sg;https://www.nus.edu.sg;https://www.a-star.edu.sg",
        "aff_unique_abbr": "NTU;NUS;A*STAR I2R",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Singapore;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "9341383",
        "title": "Supervised Semi-Autonomous Control for Surgical Robot Based on Banoian Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "The recent development of Robot-Assisted Minimally Invasive Surgery (RAMIS) has brought much benefit to ease the performance of complex Minimally Invasive Surgery (MIS) tasks and lead to more clinical outcomes. Compared to direct master-slave manipulation, semi-autonomous control for the surgical robot can enhance the efficiency of the operation, particularly for repetitive tasks. However, operating in a highly dynamic in-vivo environment is complex. Supervisory control functions should be included to ensure flexibility and safety during the autonomous control phase. This paper presents a haptic rendering interface to enable supervised semi-autonomous control for a surgical robot. Bayesian optimization is used to tune user-specific parameters during the surgical training process. User studies were conducted on a customized simulator for validation. Detailed comparisons are made between with and without the supervised semi-autonomous control mode in terms of the number of clutching events, task completion time, master robot end-effector trajectory and average control speed of the slave robot. The effectiveness of the Bayesian optimization is also evaluated, demonstrating that the optimized parameters can significantly improve users' performance. Results indicate that the proposed control method can reduce the operator's workload and enhance operation efficiency.",
        "primary_area": "",
        "author": "Junhong Chen;Dandan Zhang;Adnan Munawar;Ruiqi Zhu;Benny Lo;Gregory S. Fischer;Guang-Zhong Yang;Junhong Chen;Dandan Zhang;Adnan Munawar;Ruiqi Zhu;Benny Lo;Gregory S. Fischer;Guang-Zhong Yang",
        "authorids": "/37087325379;/37086595836;/37086207599;/37088690572;/38183567000;/37398771000;/37276270800;/37087325379;/37086595836;/37086207599;/37088690572;/38183567000;/37398771000;/37276270800",
        "aff": "Hamlyn Centre for Robotic Surgery, Imperial College London, London, United Kingdom; Hamlyn Centre for Robotic Surgery, Imperial College London, London, United Kingdom; Worcester Polytechnic Institute, Worcester, Massachusetts, USA; Hamlyn Centre for Robotic Surgery, Imperial College London, London, United Kingdom; Hamlyn Centre for Robotic Surgery, Imperial College London, London, United Kingdom; Worcester Polytechnic Institute, Worcester, Massachusetts, USA; Institute of Medical Robotics, Shanghai Jiao Tong University, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341383/",
        "gs_citation": 37,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5278660111392607151&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;1;0;0;1;2",
        "aff_unique_norm": "Imperial College London;Worcester Polytechnic Institute;Shanghai Jiao Tong University",
        "aff_unique_dep": "Hamlyn Centre for Robotic Surgery;;Institute of Medical Robotics",
        "aff_unique_url": "https://www.imperial.ac.uk;https://www.wpi.edu;https://www.sjtu.edu.cn",
        "aff_unique_abbr": "Imperial College;WPI;SJTU",
        "aff_campus_unique_index": "0;0;1;0;0;1",
        "aff_campus_unique": "London;Worcester;",
        "aff_country_unique_index": "0;0;1;0;0;1;2",
        "aff_country_unique": "United Kingdom;United States;China"
    },
    {
        "id": "9340713",
        "title": "Supportive Actions for Manipulation in Human-Robot Coworker Teams",
        "track": "main",
        "status": "Poster",
        "abstract": "The increasing presence of robots alongside humans, such as in human-robot teams in manufacturing, gives rise to research questions about the kind of behaviors people prefer in their robot counterparts. We term actions that support interaction by reducing future interference with others as supportive robot actions and investigate their utility in a co-located manipulation scenario. We compare two robot modes in a shared table pick-and-place task: (1) Task-oriented: the robot only takes actions to further its task objective and (2) Supportive: the robot sometimes prefers supportive actions to task-oriented ones when they reduce future goal-conflicts. Our experiments in simulation, using a simplified human model, reveal that supportive actions reduce the interference between agents, especially in more difficult tasks, but also cause the robot to take longer to complete the task. We implemented these modes on a physical robot in a user study where a human and a robot perform object placement on a shared table. Our results show that a supportive robot was perceived more favorably as a coworker and also reduced interference with the human in one of two scenarios. However, it also took longer to complete the task highlighting an interesting trade-off between task-efficiency and human-preference that needs to be considered before designing robot behavior for close-proximity manipulation scenarios.",
        "primary_area": "",
        "author": "Shray Bansal;Rhys Newbury;Wesley Chan;Akansel Cosgun;Aimee Allen;Dana Kuli\u0107;Tom Drummond;Charles Isbell;Shray Bansal;Rhys Newbury;Wesley Chan;Akansel Cosgun;Aimee Allen;Dana Kuli\u0107;Tom Drummond;Charles Isbell",
        "authorids": "/37085390506;/37088528036;/37085498611;/38230493900;/37088689476;/37547876700;/37341144200;/37320500200;/37085390506;/37088528036;/37085498611;/38230493900;/37088689476;/37547876700;/37341144200;/37320500200",
        "aff": "School of Interactive Computing, Georgia Institute of Technology, Atlanta, GA, USA; Department of Electrical and Computer Systems Engineering, Monash University, Clayton, VIC, Australia; Department of Electrical and Computer Systems Engineering, Monash University, Clayton, VIC, Australia; Department of Electrical and Computer Systems Engineering, Monash University, Clayton, VIC, Australia; Department of Electrical and Computer Systems Engineering, Monash University, Clayton, VIC, Australia; Department of Electrical and Computer Systems Engineering, Monash University, Clayton, VIC, Australia; Department of Electrical and Computer Systems Engineering, Monash University, Clayton, VIC, Australia; School of Interactive Computing, Georgia Institute of Technology, Atlanta, GA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340713/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13089804461463601306&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;1;1;1;1;1;0",
        "aff_unique_norm": "Georgia Institute of Technology;Monash University",
        "aff_unique_dep": "School of Interactive Computing;Department of Electrical and Computer Systems Engineering",
        "aff_unique_url": "https://www.gatech.edu;https://www.monash.edu",
        "aff_unique_abbr": "Georgia Tech;Monash",
        "aff_campus_unique_index": "0;1;1;1;1;1;1;0",
        "aff_campus_unique": "Atlanta;Clayton",
        "aff_country_unique_index": "0;1;1;1;1;1;1;0",
        "aff_country_unique": "United States;Australia"
    },
    {
        "id": "9340854",
        "title": "SwarmLab: a Matlab Drone Swarm Simulator",
        "track": "main",
        "status": "Poster",
        "abstract": "Among the available solutions for drone swarm simulations, we identified a lack of simulation frameworks that allow easy algorithms prototyping, tuning, debugging and performance analysis. Moreover, users who want to dive in the research field of drone swarms often need to interface with multiple programming languages. We present SwarmLab, a software entirely written in MATLAB, that aims at the creation of standardized processes and metrics to quantify the performance and robustness of swarm algorithms, and in particular, it focuses on drones. We showcase the functionalities of SwarmLab by comparing two decentralized algorithms from the state of the art for the navigation of aerial swarms in cluttered environments, Olfati-Saber's and Vasarhelyi's. We analyze the variability of the inter-agent distances and agents' speeds during flight. We also study some of the performance metrics presented, i.e. order, inter- and extra-agent safety, union, and connectivity. While Olfati-Saber's approach results in a faster crossing of the obstacle field, Vasarhelyi's approach allows the agents to fly smoother trajectories, without oscillations. We believe that SwarmLab is relevant for both the biological and robotics research communities, and for education, since it allows fast algorithm development, the automatic collection of simulated data, the systematic analysis of swarming behaviors with performance metrics inherited from the state of the art.",
        "primary_area": "",
        "author": "Enrica Soria;Fabrizio Schiano;Dario Floreano;Enrica Soria;Fabrizio Schiano;Dario Floreano",
        "authorids": "/37086807179;/37086123698;/37282168700;/37086807179;/37086123698;/37282168700",
        "aff": "Laboratory of Intelligent Systems (LIS), \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), Lausanne, Switzerland; Laboratory of Intelligent Systems (LIS), \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), Lausanne, Switzerland; Laboratory of Intelligent Systems (LIS), \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), Lausanne, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340854/",
        "gs_citation": 81,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13778464141308774990&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "\u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne",
        "aff_unique_dep": "Laboratory of Intelligent Systems",
        "aff_unique_url": "https://www.epfl.ch",
        "aff_unique_abbr": "EPFL",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Lausanne",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9341006",
        "title": "SwingBot: Learning Physical Features from In-hand Tactile Exploration for Dynamic Swing-up Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Several robot manipulation tasks are extremely sensitive to variations of the physical properties of the manipulated objects. One such task is manipulating objects by using gravity or arm accelerations, increasing the importance of mass, center of mass, and friction information. We present SwingBot, a robot that is able to learn the physical features of an held object through tactile exploration. Two exploration actions (tilting and shaking) provide the tactile information used to create a physical feature embedding space. With this embedding, SwingBot is able to predict the swing angle achieved by a robot performing dynamic swing-up manipulations on a previously unseen object. Using these predictions, it is able to search for the optimal control parameters for a desired swing-up angle. We show that with the learned physical features our end-to-end self-supervised learning pipeline is able to substantially improve the accuracy of swinging up unseen objects. We also show that objects with similar dynamics are closer to each other on the embedding space and that the embedding can be disentangled into values of specific physical properties.",
        "primary_area": "",
        "author": "Chen Wang;Shaoxiong Wang;Branden Romero;Filipe Veiga;Edward Adelson;Chen Wang;Shaoxiong Wang;Branden Romero;Filipe Veiga;Edward Adelson",
        "authorids": "/37087233611;/37086252778;/37088505353;/37085670753;/37349732300;/37087233611;/37086252778;/37088505353;/37085670753;/37349732300",
        "aff": "Department of Computer Science, Shanghai Jiao Tong University; CSAIL, Massachusetts Institute of Technology; CSAIL, Massachusetts Institute of Technology; CSAIL, Massachusetts Institute of Technology; CSAIL, Massachusetts Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341006/",
        "gs_citation": 120,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15713778803323636776&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;1",
        "aff_unique_norm": "Shanghai Jiao Tong University;Massachusetts Institute of Technology",
        "aff_unique_dep": "Department of Computer Science;Computer Science and Artificial Intelligence Laboratory",
        "aff_unique_url": "https://www.sjtu.edu.cn;https://www.csail.mit.edu",
        "aff_unique_abbr": "SJTU;MIT",
        "aff_campus_unique_index": "0;1;1;1;1",
        "aff_campus_unique": "Shanghai;Cambridge",
        "aff_country_unique_index": "0;1;1;1;1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9341585",
        "title": "SynChrono: A Scalable, Physics-Based Simulation Platform For Testing Groups of Autonomous Vehicles and/or Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "This contribution is concerned with the topic of using simulation to understand the behavior of groups of mutually interacting autonomous vehicles (AVs) or robots engaged in traffic/maneuvers that involve coordinated operation. We outline the structure of a multi-agent simulator called SYN-CHRONO and provide results pertaining to its scalability and ability to run real-time scenarios with humans in the loop. SYN-CHRONO is a scalable multi-agent, high-fidelity environment whose purpose is that of testing AV and robot control strategies. Four main components make up the core of the simulation platform: a physics-based dynamics engine that can simulate rigid and compliant systems, fluid-solid interactions, and deformable terrains; a module that provides sensing simulation; an agent-to-agent communication server; dynamic virtual worlds, which host the interacting agents operating in a coordinated scenario. The platform provides a virtual proving ground that can be used to answer questions such as \"what will an AV do when it skids on a patch of ice and moves one way while facing the other way?\"; \"is a new agent-control strategy robust enough to handle unforeseen circumstances?\"; and \"what is the effect of a loss of communication between agents engaged in a coordinated maneuver?\". Full videos based on work in the paper are available at https://tinyurl.com/ChronoIROS2020 and additional descriptions on the particular version of software used is available at https://github.com/uwsbel/publications-data/tree/master/2020/IROS.",
        "primary_area": "",
        "author": "Jay Taves;Asher Elmquist;Aaron Young;Radu Serban;Dan Negrut;Jay Taves;Asher Elmquist;Aaron Young;Radu Serban;Dan Negrut",
        "authorids": "/37088689458;/37086397757;/37088688625;/37829612000;/37086397766;/37088689458;/37086397757;/37088688625;/37829612000;/37086397766",
        "aff": "Department of Mechanical Engineering, University of Wisconsin\u2013Madison, Madison, WI; Department of Mechanical Engineering, University of Wisconsin\u2013Madison, Madison, WI; Department of Mechanical Engineering, University of Wisconsin\u2013Madison, Madison, WI; Department of Mechanical Engineering, University of Wisconsin\u2013Madison, Madison, WI; Department of Mechanical Engineering, University of Wisconsin\u2013Madison, Madison, WI",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341585/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15415884896984802157&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Wisconsin\u2013Madison",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.wisc.edu",
        "aff_unique_abbr": "UW\u2013Madison",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Madison",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341584",
        "title": "Synchronization of Microphones Based on Rank Minimization of Warped Spectrum for Asynchronous Distributed Recording",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper describes a new method for synchronizing microphones based on spectral warping in an asynchronous microphone array. In an audio signal observed by an asynchronous microphone array, two factors are involved: the time lag caused by a mismatch of the sampling rate and offset between microphones, and the modulation caused by differences in spatial transfer function between the sound source and each microphone. A spectrum warping matrix representing a resampling effect in the frequency domain is formulated and an observation model of audio (spectrum) mixture in an asynchronous microphone array is constructed. The proposed synchronization method uses an iterative optimization algorithm based on gradient descent of a new objective function. The function is formulated as a logarithmic determinant of a spectrum correlation matrix that is derived from relaxation of a rank minimization problem. Experimental results showed that the proposed method effectively estimates modulated sampling rate and that the proposed method outperforms an existing synchronization method.",
        "primary_area": "",
        "author": "Katsutoshi Itoyama;Kazuhiro Nakadai;Katsutoshi Itoyama;Kazuhiro Nakadai",
        "authorids": "/37667838300;/37274046900;/37667838300;/37274046900",
        "aff": "Department of Systems and Control Engineering, School of Engineering, Tokyo Institute of Technology, Tokyo, Japan; Honda Research Institute Japan, Co., Ltd., Saitama, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341584/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=362262994736780224&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Tokyo Institute of Technology;Honda Research Institute Japan",
        "aff_unique_dep": "Department of Systems and Control Engineering;",
        "aff_unique_url": "https://www.titech.ac.jp;https://www.honda-ri.jp/english/",
        "aff_unique_abbr": "Titech;HRI-JP",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Tokyo;",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9340740",
        "title": "Synchronous Minimum-Time Cooperative Manipulation using Distributed Model Predictive Control",
        "track": "main",
        "status": "Poster",
        "abstract": "A hierarchical algorithm involving two-layer optimization-based control policies with varying degrees of abstraction is proposed, including upper layer task scheduling and lower layer local path planning. A scenario with two robot arms performing cooperative pick-and-place tasks for moving objects is specifically addressed. The main focus of the paper lies on the bottom layer of the hierarchical control scheme, more precisely on the online generation of the synchronous robot trajectories using distributed minimum-time model predictive control (DMPC) algorithms. To this end, we introduce a decelerating coupling term in the cost functions of the individual distributed optimization algorithms to synchronize the overall robot motion. The performance of the algorithm is illustrated by extensive simulations with high-fidelity robot dynamic models.",
        "primary_area": "",
        "author": "Argtim Tika;Naim Bajcinca;Argtim Tika;Naim Bajcinca",
        "authorids": "/37088688783;/37426387700;/37088688783;/37426387700",
        "aff": "Department of Mechanical and Process Engineering, Technische Universit\u00e4t Kaiserslautern, Germany; Department of Mechanical and Process Engineering, Technische Universit\u00e4t Kaiserslautern, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340740/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9749376201830694939&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Technische Universit\u00e4t Kaiserslautern",
        "aff_unique_dep": "Department of Mechanical and Process Engineering",
        "aff_unique_url": "https://www.uni-kl.de",
        "aff_unique_abbr": "TU Kaiserslautern",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9341190",
        "title": "Synthesis of Control Barrier Functions Using a Supervised Machine Learning Approach",
        "track": "main",
        "status": "Poster",
        "abstract": "Control barrier functions are mathematical constructs used to guarantee safety for robotic systems. When integrated as constraints in a quadratic programming optimization problem, instantaneous control synthesis with real-time performance demands can be achieved for robotics applications. Prevailing use has assumed full knowledge of the safety barrier functions, however there are cases where the safe regions must be estimated online from sensor measurements. In these cases, the corresponding barrier function must be synthesized online. This paper describes a learning framework for estimating control barrier functions from sensor data. Doing so affords system operation in unknown state space regions without compromising safety. Here, a support vector machine classifier provides the barrier function specification as determined by sets of safe and unsafe states obtained from sensor measurements. Theoretical safety guarantees are provided. Experimental ROS-based simulation results for an omnidirectional robot equipped with LiDAR demonstrate safe operation.",
        "primary_area": "",
        "author": "Mohit Srinivasan;Amogh Dabholkar;Samuel Coogan;Patricio A. Vela;Mohit Srinivasan;Amogh Dabholkar;Samuel Coogan;Patricio A. Vela",
        "authorids": "/37086579387;/37088689124;/38232457300;/37329553400;/37086579387;/37088689124;/38232457300;/37329553400",
        "aff": "School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, USA; Department of Electrical and Electronics Engineering, Birla Institute of Technology and Science (BITS), India; School of Civil and Environmental Engineering, Georgia Institute of Technology, Atlanta, USA; School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341190/",
        "gs_citation": 146,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1620680775288494838&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Georgia Institute of Technology;Birla Institute of Technology and Science",
        "aff_unique_dep": "School of Electrical and Computer Engineering;Department of Electrical and Electronics Engineering",
        "aff_unique_url": "https://www.gatech.edu;https://www.bits-pilani.ac.in",
        "aff_unique_abbr": "Georgia Tech;BITS",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Atlanta;",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "United States;India"
    },
    {
        "id": "9340983",
        "title": "TASC: Teammate Algorithm for Shared Cooperation",
        "track": "main",
        "status": "Poster",
        "abstract": "For robots to be perceived as full-fledged team members, they must display intelligent behavior along multiple dimensions. One challenge is that even when the robot and human are on the same team, the interaction may not feel like teamwork to the human. We present a novel algorithm, Teammate Algorithm for Shared Cooperation (TASC). TASC is motivated by the concept of shared cooperative activity (SCA) for human-human teamwork, developed in prior work by Bratman. We focus on enabling the robot to prioritize certain SCA facets in its action selection depending on the task. We evaluated TASC in three experiments using different tasks with human users on Amazon Mechanical Turk. Our results show that TASC enabled participants to predict the robot's goal earlier by one robot move and with greater confidence. The robot also helped reduce participants' energy usage in a simulated block-moving task. Altogether, these results show that considering the SCA facets in the robot's action selection improves teamwork.",
        "primary_area": "",
        "author": "Mai Lee Chang;Taylor Kessler Faulkner;Thomas Benjamin Wei;Elaine Schaertl Short;Gokul Anandaraman;Andrea Lockerd Thomaz;Mai Lee Chang;Taylor Kessler Faulkner;Thomas Benjamin Wei;Elaine Schaertl Short;Gokul Anandaraman;Andrea Lockerd Thomaz",
        "authorids": "/37088529346;/37088505008;/37086944070;/37086578738;/37088689624;/37296354000;/37088529346;/37088505008;/37086944070;/37086578738;/37088689624;/37296354000",
        "aff": "Department of Electrical and Computer Engineering, University of Texas at Austin, Austin, TX, USA; Department of Computer Science, University of Texas at Austin, Austin, TX, USA; Department of Electrical and Computer Engineering, University of Texas at Austin, Austin, TX, USA; Department of Computer Science, Tufts University, Medford, MA, USA; Department of Computer Science, University of Texas at Austin, Austin, TX, USA; Department of Electrical and Computer Engineering, University of Texas at Austin, Austin, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340983/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2449266307685428411&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;0;0",
        "aff_unique_norm": "University of Texas at Austin;Tufts University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Department of Computer Science",
        "aff_unique_url": "https://www.utexas.edu;https://www.tufts.edu",
        "aff_unique_abbr": "UT Austin;Tufts",
        "aff_campus_unique_index": "0;0;0;1;0;0",
        "aff_campus_unique": "Austin;Medford",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341358",
        "title": "TORM: Fast and Accurate Trajectory Optimization of Redundant Manipulator given an End-Effector Path",
        "track": "main",
        "status": "Poster",
        "abstract": "A redundant manipulator has multiple inverse kinematics solutions per end-effector pose. Accordingly, there can be many trajectories for joints that follow a given end-effector path in the Cartesian space. In this paper, we present a trajectory optimization of a redundant manipulator (TORM) to synthesize a trajectory that follows a given end-effector path accurately, while achieving smoothness and collision-free manipulation. Our method holistically incorporates three desired properties into the trajectory optimization process by integrating the Jacobian-based inverse kinematics solving method and an optimization-based motion planning approach. Specifically, we optimize a trajectory using two-stage gradient descent to reduce potential competition between different properties during the update. To avoid falling into local minima, we iteratively explore different candidate trajectories with our local update. We compare our method with state-of-the-art methods in test scenes including external obstacles and two non-obstacle problems. Our method robustly minimizes the pose error in a progressive manner while satisfying various desirable properties.",
        "primary_area": "",
        "author": "Mincheul Kang;Heechan Shin;Donghyuk Kim;Sung-Eui Yoon;Mincheul Kang;Heechan Shin;Donghyuk Kim;Sung-Eui Yoon",
        "authorids": "/37086439291;/37086110200;/37085771730;/37066068100;/37086439291;/37086110200;/37085771730;/37066068100",
        "aff": "School of Computing, KAIST at Daejeon, Korea; School of Computing, KAIST at Daejeon, Korea; School of Computing, KAIST at Daejeon, Korea; Faculty of School of Computing, KAIST at Daejeon, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341358/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=723591486641143377&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "KAIST",
        "aff_unique_dep": "School of Computing",
        "aff_unique_url": "https://www.kaist.ac.kr",
        "aff_unique_abbr": "KAIST",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Daejeon",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9341716",
        "title": "TP-TIO: A Robust Thermal-Inertial Odometry with Deep ThermalPoint",
        "track": "main",
        "status": "Poster",
        "abstract": "To achieve robust motion estimation in visually degraded environments, thermal odometry has been an attraction in the robotics community. However, most thermal odometry methods are purely based on classical feature extractors, which is difficult to establish robust correspondences in successive frames due to sudden photometric changes and large thermal noise. To solve this problem, we propose ThermalPoint, a lightweight feature detection network specifically tailored for producing keypoints on thermal images, providing notable anti-noise improvements compared with other state-of-the-art methods. After that, we combine ThermalPoint with a novel radiometric feature tracking method, which directly makes use of full radiometric data and establishes reliable correspondences between sequential frames. Finally, taking advantage of an optimization-based visual-inertial framework, a deep feature-based thermal-inertial odometry (TP-TIO) framework is proposed and evaluated thoroughly in various visually degraded environments. Experiments show that our method outperforms state-of-the-art visual and laser odometry methods in smoke-filled environments and achieves competitive accuracy in normal environments.",
        "primary_area": "",
        "author": "Shibo Zhao;Peng Wang;Hengrui Zhang;Zheng Fang;Sebastian Scherer;Shibo Zhao;Peng Wang;Hengrui Zhang;Zheng Fang;Sebastian Scherer",
        "authorids": "/37086444189;/37088689449;/37088688128;/37401391100;/37584159000;/37086444189;/37088689449;/37088688128;/37401391100;/37584159000",
        "aff": "Robotics Institute, Carnegie Mellon University, USA; Faculty of Robot Science and Engineering, Northeastern University, China; Robotics Institute, Carnegie Mellon University, USA; Faculty of Robot Science and Engineering, Northeastern University, China; Robotics Institute, Carnegie Mellon University, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341716/",
        "gs_citation": 49,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14445440588795317454&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;1;0",
        "aff_unique_norm": "Carnegie Mellon University;Northeastern University",
        "aff_unique_dep": "Robotics Institute;Faculty of Robot Science and Engineering",
        "aff_unique_url": "https://www.cmu.edu;http://www.neu.edu.cn/",
        "aff_unique_abbr": "CMU;NEU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0;1;0",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "9341464",
        "title": "TT-TSDF: Memory-Efficient TSDF with Low-Rank Tensor Train Decomposition",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper we apply the low-rank Tensor Train decomposition for compression and operations on 3D objects and scenes represented by volumetric distance functions. Our study shows that not only it allows for a very efficient compression of the high-resolution TSDF maps (up to three orders of magnitude of the original memory footprint at resolution of 5123), but also allows to perform TSDF-Fusion directly in the low-rank form. This can potentially enable much more efficient 3D mapping on low-power mobile and consumer robot platforms.",
        "primary_area": "",
        "author": "Alexey I. Boyko;Mikhail P. Matrosov;Ivan V. Oseledets;Dzmitry Tsetserukou;Gonzalo Ferrer;Alexey I. Boyko;Mikhail P. Matrosov;Ivan V. Oseledets;Dzmitry Tsetserukou;Gonzalo Ferrer",
        "authorids": "/37086276980;/37088688797;/37594367100;/37548023000;/38469245200;/37086276980;/37088688797;/37594367100;/37548023000;/38469245200",
        "aff": "CDISE department, Skolkovo Institute of Science and Technology (Skoltech); Space Center department, Skoltech; Institute for Numerical Mathematics of Russian Academy of Sciences; Space Center department, Skoltech; CDISE department, Skolkovo Institute of Science and Technology (Skoltech)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341464/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9146813067924398643&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "Skolkovo Institute of Science and Technology;Russian Academy of Sciences",
        "aff_unique_dep": "CDISE department;Institute for Numerical Mathematics",
        "aff_unique_url": "https://www.skoltech.ru;https://www.ras.ru",
        "aff_unique_abbr": "Skoltech;RAS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Russia"
    },
    {
        "id": "9341477",
        "title": "TTR-Based Reward for Reinforcement Learning with Implicit Model Priors",
        "track": "main",
        "status": "Poster",
        "abstract": "Model-free reinforcement learning (RL) is a powerful approach for learning control policies directly from high-dimensional state and observation. However, it tends to be data-inefficient, which is especially costly in robotic learning tasks. On the other hand, optimal control does not require data if the system model is known, but cannot scale to models with high-dimensional states and observations. To exploit benefits of both model-free RL and optimal control, we propose time-to-reach-based (TTR-based) reward shaping, an optimal control-inspired technique to alleviate data inefficiency while retaining advantages of model-free RL. This is achieved by summarizing key system model information using a TTR function to greatly speed up the RL process, as shown in our simulation results. The TTR function is defined as the minimum time required to move from any state to the goal under assumed system dynamics constraints. Since the TTR function is computationally intractable for systems with high-dimensional states, we compute it for approximate, lower-dimensional system models that still captures key dynamic behaviors. Our approach can be flexibly and easily incorporated into any model-free RL algorithm without altering the original algorithm structure, and is compatible with any other techniques that may facilitate the RL process. We evaluate our approach on two representative robotic learning tasks and three well-known model-free RL algorithms, and show significant improvements in data efficiency and performance.",
        "primary_area": "",
        "author": "Xubo Lyu;Mo Chen;Xubo Lyu;Mo Chen",
        "authorids": "/37088691399;/37085494765;/37088691399;/37085494765",
        "aff": "School of Computing Science, Simon Fraser University, CA; School of Computing Science, Simon Fraser University, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341477/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12926384507379087031&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Simon Fraser University",
        "aff_unique_dep": "School of Computing Science",
        "aff_unique_url": "https://www.sfu.ca",
        "aff_unique_abbr": "SFU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9341130",
        "title": "Tactile Event Based Grasping Algorithm using Memorized Triggers and Mechanoreceptive Sensors",
        "track": "main",
        "status": "Poster",
        "abstract": "Humans perform grasping by breaking down the task into a series of action phases, where the transitions between the action phases are based on the comparison between the predicted tactile events and the actual tactile events. The dependency on tactile sensation in grasping allows humans to grasp objects without the need to locate the object precisely, which is a feature desirable in robot grasping to successfully grasp objects when there are uncertainties in localizing the target object. In this paper, we propose a method of implementing a tactile event based grasping algorithm using memorized predicted tactile events as state transition triggers, inspired by the human grasping. First, a simulated robotic manipulator mounted with pressure and vibration sensors on each finger, analogous to the different mechanoreceptors in humans, performed ideal grasping tasks, from which the tactile signals between consecutive states were extracted. The extracted tactile signals were processed and stored as predicted tactile events. Secondly, a grasping algorithm composed of eight discrete states, Reach, Re-Reach, Load, Lift, Hold, Avoid, Place, and Unload was built. The transition between consecutive states is triggered when the actual tactile events match the predicted tactile events, otherwise, triggering the corrective actions. Our algorithm was implemented on an actual robot, equipped with capacitive and piezoelectric transducers on the fingertips. Lastly, grasping experiments were conducted, where the target objects were deliberately misplaced from their expected positions, to investigate the robustness of the tactile event based grasping algorithm to object localization errors.",
        "primary_area": "",
        "author": "Won Dong Kim;Jung Kim;Won Dong Kim;Jung Kim",
        "authorids": "/37086512793;/37407273800;/37086512793;/37407273800",
        "aff": "Department of Mechanical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea; Department of Mechanical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341130/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4397376155788490151&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.kaist.ac.kr",
        "aff_unique_abbr": "KAIST",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Daejeon",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9341421",
        "title": "TactileSGNet: A Spiking Graph Neural Network for Event-based Tactile Object Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "Tactile perception is crucial for a variety of robot tasks including grasping and in-hand manipulation. New advances in flexible, event-driven, electronic skins may soon endow robots with touch perception capabilities similar to humans. These electronic skins respond asynchronously to changes (e.g., in pressure, temperature), and can be laid out irregularly on the robot\u2019s body or end-effector. However, these unique features may render current deep learning approaches such as convolutional feature extractors unsuitable for tactile learning. In this paper, we propose a novel spiking graph neural network for event-based tactile object recognition. To make use of local connectivity of taxels, we present several methods for organizing the tactile data in a graph structure. Based on the constructed graphs, we develop a spiking graph convolutional network. The event-driven nature of spiking neural network makes it arguably more suitable for processing the event-based data. Experimental results on two tactile datasets show that the proposed method outperforms other state-of-the-art spiking methods, achieving high accuracies of approximately 90% when classifying a variety of different household objects.",
        "primary_area": "",
        "author": "Fuqiang Gu;Weicong Sng;Tasbolat Taunyazov;Harold Soh;Fuqiang Gu;Weicong Sng;Tasbolat Taunyazov;Harold Soh",
        "authorids": "/37086096747;/37088687312;/37085673647;/37684942300;/37086096747;/37088687312;/37085673647;/37684942300",
        "aff": "Dept. of Computer Science, School of Computing, National University of Singapore; Dept. of Computer Science, School of Computing, National University of Singapore; Dept. of Computer Science, School of Computing, National University of Singapore; Dept. of Computer Science, School of Computing, National University of Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341421/",
        "gs_citation": 44,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2404625239865575219&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "National University of Singapore",
        "aff_unique_dep": "Dept. of Computer Science",
        "aff_unique_url": "https://www.nus.edu.sg",
        "aff_unique_abbr": "NUS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "9341520",
        "title": "Target Tracking Control of a Wheel-less Snake Robot Based on a Supervised Multi-layered SNN",
        "track": "main",
        "status": "Poster",
        "abstract": "The snake-like robot without wheels is a bio-inspired robot whose high degree of freedom results in a challenge in autonomous locomotion control. The use of a Spiking Neural Network (SNN) which is a biologically plausible artificial neural network can help to achieve the autonomous locomotion behavior of snake robots in an energy-efficient manner. Approaches that use an SNN without hidden layers have been applied in the single-target tracking task. However, due to the complexity of the 3D gaits on a wheel-less snake robot and the imprecision of the pose control while in motion, they have some fluctuation that adversely affects their performances. In this work, we design two multi-layered SNNs with different topology for a wheel-less snake robot to track a certain moving object. The visual signals obtained from a Dynamic Vision Sensor (DVS) are fed into the SNN to drive the locomotion controller. Furthermore, the Reward-modulated Spike-Timing-Dependent Plasticity (R-STDP) learning rule is utilized to train the SNN end-to-end. Compared to the SNN without hidden layers, the proposed multi-layered SNN with a separated hidden layer shows its advantage in terms of robustness.",
        "primary_area": "",
        "author": "Zhuangyi Jiang;Richard Otto;Zhenshan Bing;Kai Huang;Alois Knoll;Zhuangyi Jiang;Richard Otto;Zhenshan Bing;Kai Huang;Alois Knoll",
        "authorids": "/37086262971;/37088687080;/37085994830;/37534912900;/37276234100;/37086262971;/37088687080;/37085994830;/37534912900;/37276234100",
        "aff": "Department of Informatics, Technical University of Munich, Germany; Department of Informatics, Technical University of Munich, Germany; Department of Informatics, Technical University of Munich, Germany; Peng Cheng Laboratory, China; Department of Informatics, Technical University of Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341520/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4287782686513297906&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Technical University of Munich;Peng Cheng Laboratory",
        "aff_unique_dep": "Department of Informatics;",
        "aff_unique_url": "https://www.tum.de;",
        "aff_unique_abbr": "TUM;",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Munich;",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "Germany;China"
    },
    {
        "id": "9341405",
        "title": "Targetless Calibration of LiDAR-IMU System Based on Continuous-time Batch Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Sensor calibration is the fundamental block for a multi-sensor fusion system. This paper presents an accurate and repeatable LiDAR-IMU calibration method (termed LI-Calib), to calibrate the 6-DOF extrinsic transformation between the 3D LiDAR and the Inertial Measurement Unit (IMU). Regarding the high data capture rate for LiDAR and IMU sensors, LI-Calib adopts a continuous-time trajectory formulation based on B-Spline, which is more suitable for fusing high-rate or asynchronous measurements than discrete-time based approaches. Additionally, LI-Calib decomposes the space into cells and identifies the planar segments for data association, which renders the calibration problem well-constrained in usual scenarios without any artificial targets. We validate the proposed calibration approach on both simulated and real-world experiments. The results demonstrate the high accuracy and good repeatability of the proposed method in common human-made scenarios. To benefit the research community, we open-source our code at https://github.com/APRIL-ZJU/lidar_IMU_calib.",
        "primary_area": "",
        "author": "Jiajun Lv;Jinhong Xu;Kewei Hu;Yong Liu;Xingxing Zuo;Jiajun Lv;Jinhong Xu;Kewei Hu;Yong Liu;Xingxing Zuo",
        "authorids": "/37086604079;/37421833200;/37088690855;/37066946100;/37086314032;/37086604079;/37421833200;/37088690855;/37066946100;/37086314032",
        "aff": "Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China; Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China; Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China; Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China; Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341405/",
        "gs_citation": 94,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13476060962622448190&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Zhejiang University",
        "aff_unique_dep": "Institute of Cyber-Systems and Control",
        "aff_unique_url": "http://www.zju.edu.cn",
        "aff_unique_abbr": "ZJU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Hangzhou",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9341801",
        "title": "TartanAir: A Dataset to Push the Limits of Visual SLAM",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a challenging dataset, the TartanAir, for robot navigation tasks and more. The data is collected in photo-realistic simulation environments with the presence of moving objects, changing light and various weather conditions. By collecting data in simulations, we are able to obtain multi-modal sensor data and precise ground truth labels such as the stereo RGB image, depth image, segmentation, optical flow, camera poses, and LiDAR point cloud. We set up large numbers of environments with various styles and scenes, covering challenging viewpoints and diverse motion patterns that are difficult to achieve by using physical data collection platforms. In order to enable data collection at such a large scale, we develop an automatic pipeline, including mapping, trajectory sampling, data processing, and data verification. We evaluate the impact of various factors on visual SLAM algorithms using our data. The results of state-of-the-art algorithms reveal that the visual SLAM problem is far from solved. Methods that show good performance on established datasets such as KITTI do not perform well in more difficult scenarios. Although we use the simulation, our goal is to push the limits of Visual SLAM algorithms in the real world by providing a challenging benchmark for testing new methods, while also using a large diverse training data for learning-based methods. Our dataset is available at http://theairlab.org/tartanair-dataset.",
        "primary_area": "",
        "author": "Wenshan Wang;Delong Zhu;Xiangwei Wang;Yaoyu Hu;Yuheng Qiu;Chen Wang;Yafei Hu;Ashish Kapoor;Sebastian Scherer;Wenshan Wang;Delong Zhu;Xiangwei Wang;Yaoyu Hu;Yuheng Qiu;Chen Wang;Yafei Hu;Ashish Kapoor;Sebastian Scherer",
        "authorids": "/37087322184;/37086137408;/37086319918;/37086920250;/37088687947;/37089398088;/37088690791;/37397699500;/37584159000;/37087322184;/37086137408;/37086319918;/37086920250;/37088687947;/37089398088;/37088690791;/37397699500;/37584159000",
        "aff": "Robotics Institute of Carnegie Mellon University, Pittsburgh, USA; Department of Electronic Engineering, The Chinese University of Hong Kong, China; control science and engineering of Tongji University, Shanghai, China; Robotics Institute of Carnegie Mellon University, Pittsburgh, USA; Robotics Institute of Carnegie Mellon University, Pittsburgh, USA; Robotics Institute of Carnegie Mellon University, Pittsburgh, USA; Robotics Institute of Carnegie Mellon University, Pittsburgh, USA; Microsoft Research, Seattle, USA; Robotics Institute of Carnegie Mellon University, Pittsburgh, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341801/",
        "gs_citation": 406,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2793640580480689397&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;1;2;0;0;0;0;3;0",
        "aff_unique_norm": "Carnegie Mellon University;The Chinese University of Hong Kong;Tongji University;Microsoft Research",
        "aff_unique_dep": "Robotics Institute;Department of Electronic Engineering;Department of Control Science and Engineering;Research",
        "aff_unique_url": "https://www.cmu.edu;https://www.cuhk.edu.hk;https://www.tongji.edu.cn;https://www.microsoft.com/en-us/research",
        "aff_unique_abbr": "CMU;CUHK;Tongji;MSR",
        "aff_campus_unique_index": "0;1;2;0;0;0;0;3;0",
        "aff_campus_unique": "Pittsburgh;Hong Kong;Shanghai;Seattle",
        "aff_country_unique_index": "0;1;1;0;0;0;0;0;0",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "9341562",
        "title": "Task Planning with Belief Behavior Trees",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose Belief Behavior Trees (BBTs), an extension to Behavior Trees (BTs) that allows to automatically create a policy that controls a robot in partially observable environments. We extend the semantic of BTs to account for the uncertainty that affects both the conditions and action nodes of the BT. The tree gets synthesized following a planning strategy for BTs proposed recently: from a set of goal conditions we iteratively select a goal and find the action, or in general the subtree, that satisfies it. Such action may have preconditions that do not hold. For those preconditions, we find an action or subtree in the same fashion. We extend this approach by including, in the planner, actions that have the purpose to reduce the uncertainty that affects the value of a condition node in the BT (for example, turning on the lights to have better lighting conditions). We demonstrate that BBTs allows task planning with non-deterministic outcomes for actions. We provide experimental validation of our approach in a real robotic scenario and - for sake of reproducibility - in a simulated one.",
        "primary_area": "",
        "author": "Evgenii Safronov;Michele Colledanchise;Lorenzo Natale;Evgenii Safronov;Michele Colledanchise;Lorenzo Natale",
        "authorids": "/37086870741;/37085361393;/37542770000;/37086870741;/37085361393;/37542770000",
        "aff": "Department of Informatics, Bioengineering, Robotics and Systems Engineering, Universit\u00e0 di Genova, Genova, Italy; Istituto Italiano di Tecnologia, Genoa, Italy; Istituto Italiano di Tecnologia, Genoa, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341562/",
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15253686761539631670&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Universit\u00e0 di Genova;Istituto Italiano di Tecnologia",
        "aff_unique_dep": "Department of Informatics, Bioengineering, Robotics and Systems Engineering;",
        "aff_unique_url": "https://www.unige.it;https://www.iit.it",
        "aff_unique_abbr": "UniGe;IIT",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Genova;Genoa",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9341522",
        "title": "Task-Motion Planning for Safe and Efficient Urban Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous vehicles need to plan at the task level to compute a sequence of symbolic actions, such as merging left and turning right, to fulfill people's service requests, where efficiency is the main concern. At the same time, the vehicles must compute continuous trajectories to perform actions at the motion level, where safety is the most important. Task-motion planning in autonomous driving faces the problem of maximizing task-level efficiency while ensuring motion-level safety. To this end, we develop algorithm Task-Motion Planning for Urban Driving (TMPUD) that, for the first time, enables the task and motion planners to communicate about the safety level of driving behaviors. TMPUD has been evaluated using a realistic urban driving simulation platform. Results suggest that TMPUD performs significantly better than competitive baselines from the literature in efficiency, while ensuring the safety of driving behaviors.",
        "primary_area": "",
        "author": "Yan Ding;Xiaohan Zhang;Xingyue Zhan;Shiqi Zhang;Yan Ding;Xiaohan Zhang;Xingyue Zhan;Shiqi Zhang",
        "authorids": "/37086190662;/37088687363;/37088688302;/37086294744;/37086190662;/37088687363;/37088688302;/37086294744",
        "aff": "Department of Computer Science, SUNY Binghamton; Department of Computer Science, SUNY Binghamton; Department of Computer Science, SUNY Binghamton; Department of Computer Science, SUNY Binghamton",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341522/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9293987732377337187&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "State University of New York at Binghamton",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.binghamton.edu",
        "aff_unique_abbr": "SUNY Binghamton",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Binghamton",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341529",
        "title": "Telemanipulation with Chopsticks: Analyzing Human Factors in User Demonstrations",
        "track": "main",
        "status": "Poster",
        "abstract": "Chopsticks constitute a simple yet versatile tool that humans have used for thousands of years to perform a variety of challenging tasks ranging from food manipulation to surgery. Applying such a simple tool in a diverse repertoire of scenarios requires significant adaptability. Towards developing autonomous manipulators with comparable adaptability to humans, we study chopsticks-based manipulation to gain insights into human manipulation strategies. We conduct a within-subjects user study with 25 participants, evaluating three different data-collection methods: normal chopsticks, motion-captured chopsticks, and a novel chopstick telemanipulation interface. We analyze factors governing human performance across a variety of challenging chopstick-based grasping tasks. Although participants rated teleoperation as the least comfortable and most difficult-to-use method, teleoperation enabled users to achieve the highest success rates on three out of five objects considered. Further, we notice that subjects quickly learned and adapted to the teleoperation interface. Finally, while motion-captured chopsticks could provide a better reflection of how humans use chopsticks, the teleoperation interface can produce quality on-hardware demonstrations from which the robot can directly learn.",
        "primary_area": "",
        "author": "Liyiming Ke;Ajinkya Kamat;Jingqiang Wang;Tapomayukh Bhattacharjee;Christoforos Mavrogiannis;Siddhartha S. Srinivasa;Liyiming Ke;Ajinkya Kamat;Jingqiang Wang;Tapomayukh Bhattacharjee;Christoforos Mavrogiannis;Siddhartha S. Srinivasa",
        "authorids": "/37088688640;/37085367109;/37088687393;/37531634500;/37077312800;/37339877600;/37088688640;/37085367109;/37088687393;/37531634500;/37077312800;/37339877600",
        "aff": "Paul G. Allen School of Computer Science and Engineering, University of Washington, Seattle, WA, USA; Paul G. Allen School of Computer Science and Engineering, University of Washington, Seattle, WA, USA; Department of Mechanical Engineering, University of Washington, Seattle, WA, USA; Paul G. Allen School of Computer Science and Engineering, University of Washington, Seattle, WA, USA; Paul G. Allen School of Computer Science and Engineering, University of Washington, Seattle, WA, USA; Paul G. Allen School of Computer Science and Engineering, University of Washington, Seattle, WA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341529/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1314829312957128546&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of Washington",
        "aff_unique_dep": "Paul G. Allen School of Computer Science and Engineering",
        "aff_unique_url": "https://www.washington.edu",
        "aff_unique_abbr": "UW",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Seattle",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341140",
        "title": "Tell me what this is: Few-Shot Incremental Object Learning by a Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "For many applications, robots will need to be incrementally trained to recognize the specific objects needed for an application. This paper presents a practical system for incrementally training a robot to recognize different object categories using only a small set of visual examples provided by a human. The paper uses a recently developed state-of-the-art method for few-shot incremental learning of objects. After learning the object classes incrementally, the robot performs a table cleaning task organizing objects into categories specified by the human. We also demonstrate the system\u2019s ability to learn arrangements of objects and predict missing or incorrectly placed objects. Experimental evaluations demonstrate that our approach achieves nearly the same performance as a system trained with all examples at one time (batch training), which constitutes a theoretical upper bound.",
        "primary_area": "",
        "author": "Ali Ayub;Alan R. Wagner;Ali Ayub;Alan R. Wagner",
        "authorids": "/37090081937;/37267411100;/37090081937;/37267411100",
        "aff": "Department of Electrical Engineering, The Pennsylvania State University, State College, PA, USA; Department of Aerospace Engineering, The Pennsylvania State University, State College, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341140/",
        "gs_citation": 37,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8214565932660154312&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "The Pennsylvania State University",
        "aff_unique_dep": "Department of Electrical Engineering",
        "aff_unique_url": "https://www.psu.edu",
        "aff_unique_abbr": "PSU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "State College",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341125",
        "title": "Template-Based Optimal Robot Design with Application to Passive-Dynamic Underactuated Flapping",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a novel paradigm and algorithm for optimal design of underactuated robot platforms in highly-constrained nonconvex parameter spaces. We apply this algorithm to two variants of the mature RoboBee platform, numerically demonstrating predicted performance improvements of over 10% in some cases by algorithmically reasoning about variable effective-mechanical-advantage (EMA) transmissions, higher aspect ratio (AR) wing designs, and force-power tradeoffs. The algorithm can currently be applied to any underactuated mechanical system with one actuated degree of freedom (DOF), and can be easily extended to arbitrary configuration spaces and dynamics.",
        "primary_area": "",
        "author": "Avik De;Robert J. Wood;Avik De;Robert J. Wood",
        "authorids": "/38071514000;/37326227400;/38071514000;/37326227400",
        "aff": "School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA; School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341125/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:_qh4OlWGZgsJ:scholar.google.com/&scioq=Template-Based+Optimal+Robot+Design+with+Application+to+Passive-Dynamic+Underactuated+Flapping&hl=en&as_sdt=0,33",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Harvard University",
        "aff_unique_dep": "School of Engineering and Applied Sciences",
        "aff_unique_url": "https://www.harvard.edu",
        "aff_unique_abbr": "Harvard",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341696",
        "title": "Tensor Action Spaces for Multi-agent Robot Transfer Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "We explore using reinforcement learning on single and multi-agent systems such that after learning is finished we can apply a policy zero-shot to new environment sizes, as well as different number of agents and entities. Building off previous work, we show how to map back and forth between the state and action space of a standard Markov Decision Process (MDP) and multi-dimensional tensors such that zero-shot transfer in these cases is possible. Like in previous work, we use a special network architecture designed to work well with the tensor representation, known as the Fully Convolutional Q-Network (FCQN). We show simulation results that this tensor state and action space combined with the FCQN architecture can learn faster than traditional representations in our environments. We also show that the performance of a transferred policy is comparable to the performance of policy trained from scratch in the modified environment sizes and with modified number of agents and entities. We also show that the zero- shot transfer performance across team sizes and environment sizes remains comparable to the performance of training from scratch specific policies in the transferred environments. Finally, we demonstrate that our simulation trained policies can be applied to real robots and real sensor data with comparable performance to our simulation results. Using such policies we can run variable sized teams of robots in a variable sized operating environment with no changes to the policy and no additional learning necessary.",
        "primary_area": "",
        "author": "Devin Schwab;Yifeng Zhu;Manuela Veloso;Devin Schwab;Yifeng Zhu;Manuela Veloso",
        "authorids": "/37086937285;/37088690974;/37274032100;/37086937285;/37088690974;/37274032100",
        "aff": "Carnegie Mellon University, Pittsburgh, PA, USA; University of Texas, Austin, Austin, TX, USA; Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341696/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11572829555683517490&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Carnegie Mellon University;University of Texas at Austin",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.cmu.edu;https://www.utexas.edu",
        "aff_unique_abbr": "CMU;UT Austin",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Pittsburgh;Austin",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341655",
        "title": "Terrain-Adaptive Planning and Control of Complex Motions for Walking Excavators",
        "track": "main",
        "status": "Poster",
        "abstract": "This article presents a planning and control pipeline for legged-wheeled (hybrid) machines. It consists of a Trajectory Optimization based planner that computes references for end-effectors and joints. The references are tracked using a whole-body controller based on a hierarchical optimization approach. Our controller is capable of performing terrain adaptive whole-body control. Furthermore, it computes both torque and position/velocity references, depending on the actuator capabilities. We perform experiments on a Menzi Muck M545, a full size 31 Degrees of Freedom (DoF) walking excavator with five limbs: four wheeled legs and an arm. We show motions that require full-body coordination executed in realistic conditions. To the best of our knowledge, this is the first work that shows the execution of whole-body motions on a full size walking excavator, using all DoFs for locomotion.",
        "primary_area": "",
        "author": "Edo Jelavic;Yannick Berdou;Dominic Jud;Simon Kerscher;Marco Hutter;Edo Jelavic;Yannick Berdou;Dominic Jud;Simon Kerscher;Marco Hutter",
        "authorids": "/37086273999;/37088686794;/37085692600;/37086638188;/37545251000;/37086273999;/37088686794;/37085692600;/37086638188;/37545251000",
        "aff": "Robotic Systems Lab, ETH Zurich, Zurich, Switzerland; Robotic Systems Lab, ETH Zurich, Zurich, Switzerland; Robotic Systems Lab, ETH Zurich, Zurich, Switzerland; Robotic Systems Lab, ETH Zurich, Zurich, Switzerland; Robotic Systems Lab, ETH Zurich, Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341655/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10747491277010747633&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Robotic Systems Lab",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Zurich",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9340986",
        "title": "The AmphiSTAR High Speed Amphibious Sprawl Tuned Robot: Design and Experiments",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper details the development, modeling and performance of AmphiSTAR, a novel high-speed amphibious robot. The palm size AmphiSTAR, which belongs to the family of STAR robots, is a \"wheeled\" robot fitted with propellers at its bottom that allow it to crawl on the ground and run (i.e. hover) on water at high speeds. The AmphiSTAR is inspired by two members of the animal kingdom. It possesses a sprawling mechanism inspired by cockroaches, and it is designed to run on water at high speeds like the Basilisk lizard. We start by presenting the mechanical design of the robot and its control system. Then we model AmphiSTAR when crawling, swimming and running on water. We then report experiments on the robot to measure its lift and thrust forces in its on-water running mode and evaluate its energy consumption. The results show that in the on-water running mode, the lift forces are a function of the work volume of the propellers whereas the thrust forces are a linear function of the propellers' rotating speed. Based on these results, the final version of the 3D printed robot was built and experimentally tested in multiple scenarios. The experimental robot can crawl over the ground with performances similar to the original STAR robot and can attain speeds of 3.6 m/s. The robot can run continuously on water surfaces at speeds of 1.5 m/s. It can also swim (i.e. float while advancing by rotating its propellers) at low speeds and transition from swimming to crawling (see video).",
        "primary_area": "",
        "author": "Avi Cohen;David Zarrouk;Avi Cohen;David Zarrouk",
        "authorids": "/37088687272;/37542879300;/37088687272;/37542879300",
        "aff": "Department of Mechanical Engineering, Ben Gurion University of the Negev, Israel; Department of Mechanical Engineering, Ben Gurion University of the Negev, Israel",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340986/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1078941538037910521&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Ben Gurion University of the Negev",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.bgu.ac.il",
        "aff_unique_abbr": "BGU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Israel"
    },
    {
        "id": "9341780",
        "title": "The Application of a Flexible Leader-Follower Control Algorithm to Different Mobile Autonomous Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "In a wide range of applications involving multiple mobile autonomous systems, maneuvering the robots, vehicles or vessels in some sort of formation is a vital component for the overall task performance. Maintaining a specific distance between the platforms or even a relative geometry may greatly enhance sensor performance, provide collision safety, ensure stable vehicle-to-vehicle communication, and is of critical importance when the systems are in some way physically connected. In this paper, we present a flexible leader-follower type formation control algorithm for autonomous robots which is very simple, generic, yet decent in performance. The method applies to any relative geometry between a leader and one or more followers. In addition to testing the algorithm in simulations for a wide range of scenarios, we have performed experiments involving several different autonomous systems, including small Unmanned Aerial Vehicles (UAVs), Autonomous Underwater Vehicles (AUVs) and Unmanned Surface Vehicles (USVs). This includes pairs of USVs physically interconnected by a tow.",
        "primary_area": "",
        "author": "Aleksander S. Simonsen;Else-Line M. Ruud;Aleksander S. Simonsen;Else-Line M. Ruud",
        "authorids": "/37088686861;/37086062227;/37088686861;/37086062227",
        "aff": "Norwegian Defence Research Establishment (FFI), Kjeller, Norway; Norwegian Defence Research Establishment (FFI), Kjeller, Norway",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341780/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1101235319665935934&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Norwegian Defence Research Establishment",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.ffi.no",
        "aff_unique_abbr": "FFI",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Kjeller",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Norway"
    },
    {
        "id": "9341199",
        "title": "The Importance of Prior Knowledge in Precise Multimodal Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "Roads have well defined geometries, topologies, and traffic rules. While this has been widely exploited in motion planning methods to produce maneuvers that obey the law, little work has been devoted to utilize these priors in perception and motion forecasting methods. In this paper we propose to incorporate these structured priors as a loss function. In contrast to imposing hard constraints, this approach allows the model to handle non-compliant maneuvers when those happen in the real world. Safe motion planning is the end goal, and thus a probabilistic characterization of the possible future developments of the scene is key to choose the plan with the lowest expected cost. Towards this goal, we design a framework that leverages REINFORCE to incorporate non-differentiable priors over sample trajectories from a probabilistic model, thus optimizing the whole distribution. We demonstrate the effectiveness of our approach on real-world self-driving datasets containing complex road topologies and multi-agent interactions. Our motion forecasts not only exhibit better precision and map understanding, but most importantly result in safer motion plans taken by our self-driving vehicle. We emphasize that despite the importance of this evaluation, it has been often overlooked by previous perception and motion forecasting works.",
        "primary_area": "",
        "author": "Sergio Casas;Cole Gulino;Simon Suo;Raquel Urtasun;Sergio Casas;Cole Gulino;Simon Suo;Raquel Urtasun",
        "authorids": "/37086821588;/37086453885;/37086567697;/37269502900;/37086821588;/37086453885;/37086567697;/37269502900",
        "aff": "University of Toronto; Uber Advanced Technologies Group; University of Toronto; University of Toronto",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341199/",
        "gs_citation": 54,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3038681377108311865&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "University of Toronto;Uber",
        "aff_unique_dep": ";Advanced Technologies Group",
        "aff_unique_url": "https://www.utoronto.ca;https://www.uber.com",
        "aff_unique_abbr": "U of T;Uber ATG",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "Canada;United States"
    },
    {
        "id": "9341207",
        "title": "The Marathon 2: A Navigation System",
        "track": "main",
        "status": "Poster",
        "abstract": "Developments in mobile robot navigation have enabled robots to operate in warehouses, retail stores, and on sidewalks around pedestrians. Various navigation solutions have been proposed, though few as widely adopted as ROS (Robot Operating System) Navigation. 10 years on, it is still one of the most popular navigation solutions1. Yet, ROS Navigation has failed to keep up with modern trends. We propose the new navigation solution, Navigation2, which builds on the successful legacy of ROS Navigation. Navigation2 uses a behavior tree for navigator task orchestration and employs new methods designed for dynamic environments applicable to a wider variety of modern sensors. It is built on top of ROS2, a secure message passing framework suitable for safety critical applications and program lifecycle management. We present experiments in a campus setting utilizing Navigation2 to operate safely alongside students over a marathon as an extension of the experiment proposed in Eppstein et al. [1]. The Navigation2 system is freely available at https://github.com/ros-planning/navigation2 with a rich community and instructions.",
        "primary_area": "",
        "author": "Steve Macenski;Francisco Mart\u00edn;Ruffin White;Jonatan Gin\u00e9s Clavero;Steve Macenski;Francisco Mart\u00edn;Ruffin White;Jonatan Gin\u00e9s Clavero",
        "authorids": "/37088461104;/37292303000;/37086290046;/37088687838;/37088461104;/37292303000;/37086290046;/37088687838",
        "aff": "R&D Innovations, Samsung Research; Intelligent Robotics Lab, Rey Juan Carlos University; Contextual Robotics Institute, UC San Diego; Intelligent Robotics Lab, Rey Juan Carlos University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341207/",
        "gs_citation": 415,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2053168897160180336&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;1",
        "aff_unique_norm": "Samsung Research;Rey Juan Carlos University;University of California, San Diego",
        "aff_unique_dep": "R&D Innovations;Intelligent Robotics Lab;Contextual Robotics Institute",
        "aff_unique_url": "https://www.samsung.com/global/research/;https://www.urjc.es;https://www.ucsd.edu",
        "aff_unique_abbr": "Samsung;;UCSD",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";San Diego",
        "aff_country_unique_index": "0;1;2;1",
        "aff_country_unique": "South Korea;Spain;United States"
    },
    {
        "id": "9341471",
        "title": "The Masked Mapper: Masked Metric Mapping",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a flexible mapping scheme that uses a masking function (mask) to focus the attention of a pose graph SLAM (Simultaneous Localization and Mapping) system. The masking function takes the robot's observations and returns true if the robot is in an important location. State-of-the-art methods in SLAM generate dense metric lidar maps, creating precise maps at a high computational cost by storing lidar scans for each pose node and continually attempting to close loops. In many cases, trying to always make loop closures is unnecessary for localization and even risky because of perceptual aliasing and false positives. By masking out these less useful positions, our method can create more accurate maps despite performing far fewer scan matches. We evaluate our system with three simple mask functions on a 2.5 km trajectory with significant angular drift. We compare the number of scan matches performed under each mask as well as the accuracy of the loop closures.",
        "primary_area": "",
        "author": "Acshi Haggenmiller;Cameron Kabacinski;Maximilian Krogius;Edwin Olson;Acshi Haggenmiller;Cameron Kabacinski;Maximilian Krogius;Edwin Olson",
        "authorids": "/37086934968;/37088687034;/37086936723;/37413277900;/37086934968;/37088687034;/37086936723;/37413277900",
        "aff": "Robotics Institute, University of Michigan; Computer Science and Engineering Department, University of Michigan; Robotics Institute, University of Michigan; Computer Science and Engineering Department, University of Michigan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341471/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5462307013380842833&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Michigan",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.umich.edu",
        "aff_unique_abbr": "UM",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Ann Arbor",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341430",
        "title": "The Multi-material Actuator for Variable Stiffness (MAVS): Design, Modeling, and Characterization of a Soft Actuator for Lateral Ankle Support",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents the design of the Multi-material Actuator for Variable Stiffness (MAVS), which consists of an inflatable soft fabric actuator fixed between two layers of rigid retainer pieces. The MAVS is designed to be integrated with a soft robotic ankle-foot orthosis (SR-AFO) exosuit to aid in supporting the human ankle in the inversion/eversion directions. This design aims to assist individuals affected with chronic ankle instability (CAI) or other impairments to the ankle joint. The MAVS design is made from compliant fabric materials, layered and constrained by thin rigid retainers to prevent volume increase during actuation. The design was optimized to provide the greatest stiffness and least deflection for a beam positioned as a cantilever with a point load. Geometric programming of materials was used to maximize stiffness when inflated and minimize stiffness when passive. An analytic model of the MAVS was created to evaluate the effects in stiffness observed by varying the ratio in length between the rigid pieces and the soft actuator. A finite element analysis (FEA) was generated to analyze and predict the behavior of the MAVS prior to fabrication. The results from the analytic model and FEA study were compared to experimentally obtained results of the MAVS. The MAVS with the greatest stiffness was observed when the gap between the rigid retainers was smallest and the rigid retainer length was smallest. The MAVS design with the highest stiffness at 100 kPa was determined, which required 26.71 \u00b1 0.06 N to deflect the actuator 20 mm, and a resulting stiffness of 1,335.5 N/m and 9.1% margin of error from the model predictions.",
        "primary_area": "",
        "author": "Carly M. Thalman;Tiffany Hertzell;Marielle Debeurre;Hyunglae Lee;Carly M. Thalman;Tiffany Hertzell;Marielle Debeurre;Hyunglae Lee",
        "authorids": "/37086415339;/37088480468;/37088686094;/37085768762;/37086415339;/37088480468;/37088686094;/37085768762",
        "aff": "Ira A. Fulton Schools of Engineering, Arizona State University, AZ, USA; Ira A. Fulton Schools of Engineering, Arizona State University, AZ, USA; Ira A. Fulton Schools of Engineering, Arizona State University, AZ, USA; Ira A. Fulton Schools of Engineering, Arizona State University, AZ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341430/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10883818985110041828&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Arizona State University",
        "aff_unique_dep": "Ira A. Fulton Schools of Engineering",
        "aff_unique_url": "https:// Fulton.asu.edu",
        "aff_unique_abbr": "ASU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Tempe",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340849",
        "title": "The Newer College Dataset: Handheld LiDAR, Inertial and Vision with Ground Truth",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a large dataset with a variety of mobile mapping sensors collected using a handheld device carried at typical walking speeds for nearly 2.2 km around New College, Oxford as well as a series of supplementary datasets with much more aggressive motion and lighting contrast. The datasets include data from two commercially available devices - a stereoscopic-inertial camera and a multi-beam 3D LiDAR, which also provides inertial measurements. Additionally, we used a tripod-mounted survey grade LiDAR scanner to capture a detailed millimeter-accurate 3D map of the test location (containing ~290 million points). Using the map, we generated a 6 Degrees of Freedom (DoF) ground truth pose for each LiDAR scan (with approximately 3 cm accuracy) to enable better benchmarking of LiDAR and vision localisation, mapping and reconstruction systems. This ground truth is the particular novel contribution of this dataset and we believe that it will enable systematic evaluation which many similar datasets have lacked. The large dataset combines both built environments, open spaces and vegetated areas so as to test localisation and mapping systems such as vision-based navigation, visual and LiDAR SLAM, 3D LiDAR reconstruction and appearance-based place recognition, while the supplementary datasets contain very dynamic motions to introduce more challenges for visual-inertial odometry systems. The datasets are available at:ori.ox.ac.uk/datasets/newer-college-dataset.",
        "primary_area": "",
        "author": "Milad Ramezani;Yiduo Wang;Marco Camurri;David Wisth;Matias Mattamala;Maurice Fallon;Milad Ramezani;Yiduo Wang;Marco Camurri;David Wisth;Matias Mattamala;Maurice Fallon",
        "authorids": "/37088504403;/37088689824;/37085638130;/37087057730;/37088686013;/37540365100;/37088504403;/37088689824;/37085638130;/37087057730;/37088686013;/37540365100",
        "aff": "Oxford Robotics Institute, University of Oxford, UK; Oxford Robotics Institute, University of Oxford, UK; Oxford Robotics Institute, University of Oxford, UK; Oxford Robotics Institute, University of Oxford, UK; Oxford Robotics Institute, University of Oxford, UK; Oxford Robotics Institute, University of Oxford, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340849/",
        "gs_citation": 238,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3914404764437040185&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of Oxford",
        "aff_unique_dep": "Oxford Robotics Institute",
        "aff_unique_url": "https://www.ox.ac.uk",
        "aff_unique_abbr": "Oxford",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Oxford",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9340872",
        "title": "The Omega Turn: A Biologically-Inspired Turning Strategy for Elongated Limbless Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Snake robots have the potential to locomote through tightly packed spaces, but turning effectively within unmodelled and unsensed environments remains challenging. Inspired by a behavior observed in the tiny nematode worm C. elegans, we propose a novel in-place turning gait for elongated limbless robots. To simplify the control of the robots' many internal degrees-of-freedom, we introduce a biologically-inspired template in which two co-planar traveling waves are superposed to produce an in-plane turning motion, the omega turn. The omega turn gait arises from modulating the wavelengths and amplitudes of the two traveling waves. We experimentally test the omega turn on a snake robot, and show that this turning gait outperforms previous turning gaits: it results in a larger angular displacement and a smaller area swept by the body over a gait cycle, allowing the robot to turn in highly confined spaces.",
        "primary_area": "",
        "author": "Tianyu Wang;Baxi Chong;Kelimar Diaz;Julian Whitman;Hang Lu;Matthew Travers;Daniel I. Goldman;Howie Choset;Tianyu Wang;Baxi Chong;Kelimar Diaz;Julian Whitman;Hang Lu;Matthew Travers;Daniel I. Goldman;Howie Choset",
        "authorids": "/37088483378;/37088489862;/37088688405;/37086038296;/37088686494;/37545390200;/38182137200;/37281322200;/37088483378;/37088489862;/37088688405;/37086038296;/37088686494;/37545390200;/38182137200;/37281322200",
        "aff": "Carnegie Mellon University, Pittsburgh, PA, USA; Georgia Institute of Technology, Atlanta, GA, USA; Georgia Institute of Technology, Atlanta, GA, USA; Carnegie Mellon University, Pittsburgh, PA, USA; Georgia Institute of Technology, Atlanta, GA, USA; Carnegie Mellon University, Pittsburgh, PA, USA; Georgia Institute of Technology, Atlanta, GA, USA; Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340872/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16623437332435512499&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;1;0;1;0;1;0",
        "aff_unique_norm": "Carnegie Mellon University;Georgia Institute of Technology",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.cmu.edu;https://www.gatech.edu",
        "aff_unique_abbr": "CMU;Georgia Tech",
        "aff_campus_unique_index": "0;1;1;0;1;0;1;0",
        "aff_campus_unique": "Pittsburgh;Atlanta",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341205",
        "title": "The Pluggable Distributed Resource Allocator (PDRA): a Middleware for Distributed Computing in Mobile Robotic Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "We present the Pluggable Distributed Resource Allocator (PDRA), a middleware for distributed computing in heterogeneous mobile robotic networks. PDRA enables autonomous robotic agents to share computational resources for computationally expensive tasks such as localization and path planning. It sits between an existing single-agent planner/executor and existing computational resources (e.g. ROS packages), intercepts the executor's requests and, if needed, transparently routes them to other robots for execution. PDRA is pluggable: it can be integrated in an existing single-robot autonomy stack with minimal modifications. Task allocation decisions are performed by a mixed-integer programming algorithm, solved in a shared-world fashion, that models CPU resources, latency requirements, and multi-hop, periodic, bandwidth-limited network communications; the algorithm can minimize overall energy usage or maximize the reward for completing optional tasks. Simulation results show that PDRA can reduce energy and CPU usage by over 50% in representative multi-robot scenarios compared to a naive scheduler; runs on embedded platforms; and performs well in delay- and disruption-tolerant networks (DTNs). PDRA is available to the community under an open-source license.",
        "primary_area": "",
        "author": "Federico Rossi;Tiago Stegun Vaquero;Marc Sanchez-Net;Ma\u00edra Saboia da Silva;Joshua Vander Hook;Federico Rossi;Tiago Stegun Vaquero;Marc Sanchez-Net;Ma\u00edra Saboia da Silva;Joshua Vander Hook",
        "authorids": "/37085471827;/37088470100;/37085551077;/37088507228;/38228804700;/37085471827;/37088470100;/37085551077;/37088507228;/38228804700",
        "aff": "Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341205/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10174687626044272356&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "California Institute of Technology",
        "aff_unique_dep": "Jet Propulsion Laboratory",
        "aff_unique_url": "https://www.caltech.edu",
        "aff_unique_abbr": "Caltech",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Pasadena",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341505",
        "title": "The Robot as Scientist: Using Mental Simulation to Test Causal Hypotheses Extracted from Human Activities in Virtual Reality",
        "track": "main",
        "status": "Poster",
        "abstract": "To act effectively in its environment, a cognitive robot needs to understand the causal dependencies of all intermediate actions leading up to its goal. For example, the system has to infer that it is instrumental to open a cupboard door before trying to grasp an object inside the cupboard. In this paper, we introduce a novel learning method for extracting instrumental dependencies by following the scientific approach of observations, generation of causal hypotheses, and testing through experiments. Our method uses a virtual reality dataset containing observations from human activities to generate hypotheses about causal dependencies between actions. It detects pairs of actions with a high temporal co-occurrence and verifies if one action is instrumental in executing the other action through mental simulation in a virtual reality environment which represents the system's mental model. Our system is able to extract all present instrumental action dependencies while significantly reducing the search space for mental simulation, resulting in a 6-fold reduction in computational time.",
        "primary_area": "",
        "author": "Constantin Uhde;Nicolas Berberich;Karinne Ramirez-Amaro;Gordon Cheng;Constantin Uhde;Nicolas Berberich;Karinne Ramirez-Amaro;Gordon Cheng",
        "authorids": "/37086934201;/37088688055;/37079218400;/37276253300;/37086934201;/37088688055;/37079218400;/37276253300",
        "aff": "Institute for Cognitive Systems, Technical University of Munich; Institute for Cognitive Systems, Technical University of Munich; Chalmers University of Technology, Gothenburg; Institute for Cognitive Systems, Technical University of Munich",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341505/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17800023462389541046&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Technical University of Munich;Chalmers University of Technology",
        "aff_unique_dep": "Institute for Cognitive Systems;",
        "aff_unique_url": "https://www.tum.de;https://www.chalmers.se",
        "aff_unique_abbr": "TUM;Chalmers",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Gothenburg",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "Germany;Sweden"
    },
    {
        "id": "9341687",
        "title": "The SPIR: An Autonomous Underwater Robot for Bridge Pile Cleaning and Condition Assessment",
        "track": "main",
        "status": "Poster",
        "abstract": "The SPIR, Submersible Pylon Inspection Robot, is developed to provide an innovative and practical solution to keep workers safe during maintenance of underwater structures in shallow waters, which involves working in dangerous water currents, and high-pressure water-jet cleaning. More advanced than work-class Remotely Operated Vehicles technology, the SPIR is automated and required minimum involvement of humans into the working process, thus effectively lowered the learning curve required to conduct work. To make SPIR operate effectively in poor visibility and highly disturbed environments, the multiple new technologies are developed and implemented into the system, including SBL-SONAR-based navigation, 6-DOF stabilisation, and vision-based 3D mapping. Extensive testing and field trials in various bridges are conducted to verify the robotic system. The results demonstrate the suitability of the SPIR in substituting humans for underwater hazardous tasks such as autonomous cleaning and inspection of bridge and wharf piles.",
        "primary_area": "",
        "author": "Khoa Le;Andrew To;Brenton Leighton;Mahdi Hassan;Dikai Liu;Khoa Le;Andrew To;Brenton Leighton;Mahdi Hassan;Dikai Liu",
        "authorids": "/37087011470;/37547003100;/37086702110;/37085392456;/37290601500;/37087011470;/37547003100;/37086702110;/37085392456;/37290601500",
        "aff": "Centre for Autonomous Systems, University of Technology, Sydney, Australia; Centre for Autonomous Systems, University of Technology, Sydney, Australia; Centre for Autonomous Systems, University of Technology, Sydney, Australia; Centre for Autonomous Systems, University of Technology, Sydney, Australia; Centre for Autonomous Systems, University of Technology, Sydney, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341687/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6350169542760846167&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Technology, Sydney",
        "aff_unique_dep": "Centre for Autonomous Systems",
        "aff_unique_url": "https://www.uts.edu.au",
        "aff_unique_abbr": "UTS",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Sydney",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "9341713",
        "title": "The VCU-RVI Benchmark: Evaluating Visual Inertial Odometry for Indoor Navigation Applications with an RGB-D Camera",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents VCU-RVI, a new visual inertial odometry (VIO) benchmark with a set of diverse data sequences in different indoor scenarios. The benchmark was captured using an Structure Core (SC) sensor, consisting of an RGB-D camera and an IMU. It provides aligned color and depth images with 640\u00d7480 resolution at 30 Hz. The camera's data is synchronized with the IMU's data at 100 Hz. Thirty-nine data sequences covering a total of ~3.7 kilometers trajectory were recorded in various indoor environments by two experimental setups: hand-holding the SC sensor or installing it on a wheeled robot. For the data sequences from the handheld SC, some were recorded in our laboratory under three challenging conditions: fast sensor motion, radical illumination changing, and dynamic objects, and the rest were collected in various indoor spaces outside the laboratory in the East Engineering Building, including corridors, halls, and stairways, during long-distance navigation scenarios. For the data sequences captured using the wheeled robot, half of them were recorded with sufficient IMU excitation in the beginning of the sequence, to meet the need of testing the VIO methods with the requirement of sufficient motion conditions for initialization. We placed three bumpers on the floor of the lab to create an uneven terrain to make the robot motion 6-DOF. The sequences also include data collected from navigational courses with a long trajectory. For trajectory evaluation, a motion capture system is used to generate accurate pose data (at a rate of 120 Hz), which will be used as the ground truth. We conducted experiments to evaluate the state-of-the-art VIO algorithms using our benchmark. These algorithms together with the evaluation tools and the VCU-RVI dataset are made publicly available.",
        "primary_area": "",
        "author": "He Zhang;Lingqiu Jin;Cang Ye;He Zhang;Lingqiu Jin;Cang Ye",
        "authorids": "/37086004148;/37086702509;/37291591400;/37086004148;/37086702509;/37291591400",
        "aff": "Computer Science Department, Virginia Commonwealth University, Richmond, VA, USA; Computer Science Department, Virginia Commonwealth University, Richmond, VA, USA; Computer Science Department, Virginia Commonwealth University, Richmond, VA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341713/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10405514248010019826&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Virginia Commonwealth University",
        "aff_unique_dep": "Computer Science Department",
        "aff_unique_url": "https://www.vcu.edu",
        "aff_unique_abbr": "VCU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Richmond",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341231",
        "title": "The application of navigation technology for the medical assistive devices based on Aruco recognition technology",
        "track": "main",
        "status": "Poster",
        "abstract": "In order to improve the convenience of operation for the medical assistive devices and reduce the use and maintenance cost, the Aruco recognition technology is applied to the navigation and positioning of visual guided electric assistive devices. Firstly, the differential control kinematic model of the electric wheelchair is analyzed. We discuss the feasibility of Aruco recognition technology in the application of medical assistive devices. The camera on wheelchair captures the Aruco marker data and transmits it to controller. The controller calculates the position and posture information of electric wheelchair, which provides reference for the next movement of electric wheelchair. Combining with the kinematic model of electric wheelchair, this method can realize the navigation and positioning of electric wheelchair. Experiments show that the vision guidance of Electric Wheelchair based on Aruco recognition is accurate, stable, low cost, and can be flexibly applied to the auxiliary equipment of medical institutions.",
        "primary_area": "",
        "author": "Weihan Tian;Diansheng Chen;Zihao Yang;Hu Yin;Weihan Tian;Diansheng Chen;Zihao Yang;Hu Yin",
        "authorids": "/37088687404;/37400197000;/37088687306;/37089270784;/37088687404;/37400197000;/37088687306;/37089270784",
        "aff": "School of Mechanical Engineering and Automation, Beihang University, Beijing, China; Beijing Advanced Innovation Center for Biomedical Engineering, Beihang University, Beijing, China; School of Mechanical Engineering and Automation, Beihang University, Beijing, China; School of Mechanical Engineering and Automation, Beihang University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341231/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5201074475115550597&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Beihang University",
        "aff_unique_dep": "School of Mechanical Engineering and Automation",
        "aff_unique_url": "http://www.buaa.edu.cn",
        "aff_unique_abbr": "Beihang",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9341101",
        "title": "The personalization of stiffness for an ankle-foot prosthesis emulator using Human-in-the-loop optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "Evidence suggests that the metabolic cost associated with the locomotive activity of walking is dependent upon ankle stiffness. This stiffness can be a control parameter in an ankle-foot prosthesis. Considering unique physical interaction between each individual with below-knee amputation and robotic ankle-foot prosthesis, individually tuned stiffness in a robotic ankle-foot prosthesis may improve assistance benefits. This personalization can be accomplished through human-in-the-loop (HIL) Bayesian optimization (BO). Here, we conducted a pilot study to identify personalized ankle- foot prosthesis stiffness using the HIL BO to minimize the cost of walking, shown by metabolic cost. We used an improved versatile ankle-foot prosthesis emulator, which enabled to test controllers with a wide range of stiffness conditions. Two participants with simulated amputation reduced their cost of walking under the condition of personalized (optimized) stiffness by 6% and 5%, respectively. This result suggests that personalized stiffness may improve assistance benefit.",
        "primary_area": "",
        "author": "Tin-Chun Wen;Michael Jacobson;Xingyuan Zhou;Hyun-Joon Chung;Myunghee Kim;Tin-Chun Wen;Michael Jacobson;Xingyuan Zhou;Hyun-Joon Chung;Myunghee Kim",
        "authorids": "/37088686788;/37088688010;/37088688038;/37085887133;/37085573281;/37088686788;/37088688010;/37088688038;/37085887133;/37085573281",
        "aff": "Department of Mechanical and Industrial Engineering, University of Illinois at Chicago, Chicago, IL, USA; Mechanical and Industrial Engineering Department, University of Illinois at Chicago, Chicago, IL, USA; Electrical and Computer Engineering Department, University of Illinois at Chicago, Chicago, IL, USA; Korea Institute of Robotics and Technology Convergence, Pohang, Korea; Mechanical and Industrial Engineering Department, University of Illinois at Chicago, Chicago, IL, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341101/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9600466756197915780&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "University of Illinois at Chicago;Korea Institute of Robotics and Technology Convergence",
        "aff_unique_dep": "Department of Mechanical and Industrial Engineering;",
        "aff_unique_url": "https://www.uic.edu;",
        "aff_unique_abbr": "UIC;",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Chicago;Pohang",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "United States;South Korea"
    },
    {
        "id": "9341067",
        "title": "This or That: The Effect of Robot's Deictic Expression on User's Perception",
        "track": "main",
        "status": "Poster",
        "abstract": "The purpose of this study is to investigate a robot's impression perceived by users as well as the accuracy of perception of location information, which the robot provided according to the modality type of the robot. To explore this, we designed two 2 (verbal types: deictic vs. descriptive) x 2 (nose pointing: with nose vs. without nose) x 2 (eye pointing: with eyes vs. without eyes) mixed-participant studies. In the first study, we investigated the impacts of the robot's modality type in the imperative pointing situation. As a result, participants identified the robot's pointing gesture with nose as more effective, social, and positive, than the robot's pointing gesture without nose. Moreover, the descriptive speech robot was evaluated as more positive than the deictic speech robot. In terms of the accuracy of perception of location information, which the robot provided, participants identified the robot-designated chair more accurately when the robot delivered a deictic speech than when the robot delivered a descriptive speech. For the second study, we explored the effects of the robot's modality type in the declarative pointing situation. As a result, the robot's descriptive speech was rated as effective, social, natural, competent, trustworthy, and more positive than deictic speech. In the case of the robot's pointing gestures, pointing gesture with nose was evaluated as more effective, social, natural, competent, trustworthy, and positive than that without nose. In terms of the accuracy of location information perception, participants perceived the location of the object designated by the robot more accurately when the robot used descriptive speech, pointed with nose and without eyes.",
        "primary_area": "",
        "author": "Dahyun Kang;Sonya S. Kwak;Hanbyeol Lee;Eun Ho Kim;JongSuk Choi;Dahyun Kang;Sonya S. Kwak;Hanbyeol Lee;Eun Ho Kim;JongSuk Choi",
        "authorids": "/37088529158;/37398989100;/37088528366;/37088686034;/37292544300;/37088529158;/37398989100;/37088528366;/37088686034;/37292544300",
        "aff": "Center for Intelligent and Interactive Robotics, Korea Institute of Science and Technology, Seoul, Korea; Center for Intelligent and Interactive Robotics, Korea Institute of Science and Technology, Seoul, Korea; Center for Intelligent and Interactive Robotics, Korea Institute of Science and Technology, Seoul, Korea; Human and Culture Convergence Technology R&BD Group, Korea Institute of Industrial Technology, Ansan-si, Korea; Center for Intelligent and Interactive Robotics, Korea Institute of Science and Technology, Seoul, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341067/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5788723419725179951&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Korea Institute of Science and Technology;Korea Institute of Industrial Technology",
        "aff_unique_dep": "Center for Intelligent and Interactive Robotics;Human and Culture Convergence Technology R&BD Group",
        "aff_unique_url": "https://www.kist.re.kr;http://www.kiit.re.kr",
        "aff_unique_abbr": "KIST;KIIT",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Seoul;Ansan-si",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9340714",
        "title": "Three-Dimensional Posture Optimization for Biped Robot Stepping over Large Ditch Based on a Ducted-Fan Propulsion System",
        "track": "main",
        "status": "Poster",
        "abstract": "The recent progress of an ongoing project utilizing a ducted-fan propulsion system to improve a humanoid robot's ability to step over large ditches is reported. A novel method (GAS) based on the genetic algorithm with smoothness constraint can effectively minimize the thrust by optimizing the robot's posture during 3D stepping. The significant advantage of the method is that it can realize the continuity and smoothness of the thrust and pelvis trajectories. The method enables the landing point of the robot's swing foot to be not only in the forward but also in a side direction. The methods were evaluated by simulation and by being applied on a prototype robot, JetHR1. By keeping a quasistatic balance, the robot could step over a ditch with a span of 450 mm (as much as 97% of the length of the robot's leg) in 3D stepping.",
        "primary_area": "",
        "author": "Zhifeng Huang;Zijun Wang;Jiapeng Wei;Jingtao Yu;Yuhao Zhou;Pihao Lao;Xiaoliang Huang;Xuexi Zhang;Yun Zhang;Zhifeng Huang;Zijun Wang;Jiapeng Wei;Jingtao Yu;Yuhao Zhou;Pihao Lao;Xiaoliang Huang;Xuexi Zhang;Yun Zhang",
        "authorids": "/38490431100;/37088689567;/37086321307;/37088690193;/37088690508;/37088686986;/37086489623;/37086458952;/37279968200;/38490431100;/37088689567;/37086321307;/37088690193;/37088690508;/37088686986;/37086489623;/37086458952;/37279968200",
        "aff": "School of Automation, Guangdong University of Technology, Guangzhou, P. R. China; School of Automation, Guangdong University of Technology, Guangzhou, P. R. China; School of Automation, Guangdong University of Technology, Guangzhou, P. R. China; School of Automation, Guangdong University of Technology, Guangzhou, P. R. China; School of Automation, Guangdong University of Technology, Guangzhou, P. R. China; School of Automation, Guangdong University of Technology, Guangzhou, P. R. China; School of Automation, Guangdong University of Technology, Guangzhou, P. R. China; School of Automation, Guangdong University of Technology, Guangzhou, P. R. China; School of Automation, Guangdong University of Technology, Guangzhou, P. R. China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340714/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3905259769672118461&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Guangdong University of Technology",
        "aff_unique_dep": "School of Automation",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Guangzhou",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9341574",
        "title": "Tidying Deep Saliency Prediction Architectures",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning computational models for visual attention (saliency estimation) is an effort to inch machines/robots closer to human visual cognitive abilities. Data-driven efforts have dominated the landscape since the introduction of deep neural network architectures. In deep learning research, the choices in architecture design are often empirical and frequently lead to more complex models than necessary. The complexity, in turn, hinders the application requirements. In this paper, we identify four key components of saliency models, i.e., input features, multi-level integration, readout architecture, and loss functions. We review the existing state of the art models on these four components and propose novel and simpler alternatives. As a result, we propose two novel end-to-end architectures called SimpleNet and MDNSal, which are neater, minimal, more interpretable and achieve state of the art performance on public saliency benchmarks. SimpleNet is an optimized encoder-decoder architecture and brings notable performance gains on the SALICON dataset (the largest saliency benchmark). MDNSal is a parametric model that directly predicts parameters of a GMM distribution and is aimed to bring more interpretability to the prediction maps. The proposed saliency models can be inferred at 25fps, making them suitable for real-time applications. Code and pre-trained models are available at https://github.com/samyak0210/saliency.",
        "primary_area": "",
        "author": "Navyasri Reddy;Samyak Jain;Pradeep Yarlagadda;Vineet Gandhi;Navyasri Reddy;Samyak Jain;Pradeep Yarlagadda;Vineet Gandhi",
        "authorids": "/37088689014;/37088688004;/37088687853;/37075471000;/37088689014;/37088688004;/37088687853;/37075471000",
        "aff": "CVIT, KCIS, International Institute of Information Technology, Hyderabad, India; CVIT, KCIS, International Institute of Information Technology, Hyderabad, India; CVIT, KCIS, International Institute of Information Technology, Hyderabad, India; CVIT, KCIS, International Institute of Information Technology, Hyderabad, India",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341574/",
        "gs_citation": 56,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11768660410171081068&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 13,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "International Institute of Information Technology",
        "aff_unique_dep": "CVIT, KCIS",
        "aff_unique_url": "https://iiit Hyderabad.ac.in",
        "aff_unique_abbr": "IIIT Hyderabad",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Hyderabad",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "9341697",
        "title": "Tightly-coupled Fusion of Global Positional Measurements in Optimization-based Visual-Inertial Odometry",
        "track": "main",
        "status": "Poster",
        "abstract": "Motivated by the goal of achieving robust, drift-free pose estimation in long-term autonomous navigation, in this work we propose a methodology to fuse global positional information with visual and inertial measurements in a tightly-coupled nonlinear-optimization-based estimator. Differently from previous works, which are loosely-coupled, the use of a tightly-coupled approach allows exploiting the correlations amongst all the measurements. A sliding window of the most recent system states is estimated by minimizing a cost function that includes visual re-projection errors, relative inertial errors, and global positional residuals. We use IMU preintegration to formulate the inertial residuals and leverage the outcome of such algorithm to efficiently compute the global position residuals. The experimental results show that the proposed method achieves accurate and globally consistent estimates, with negligible increase of the optimization computational cost. Our method consistently outperforms the loosely-coupled fusion approach. The mean position error is reduced up to 50% with respect to the loosely-coupled approach in outdoor Unmanned Aerial Vehicle (UAV) flights, where the global position information is given by noisy GPS measurements. To the best of our knowledge, this is the first work where global positional measurements are tightly fused in an optimization-based visual-inertial odometry algorithm, leveraging the IMU preintegration method to define the global positional factors.",
        "primary_area": "",
        "author": "Giovanni Cioffi;Davide Scaramuzza;Giovanni Cioffi;Davide Scaramuzza",
        "authorids": "/37088488451;/37397688400;/37088488451;/37397688400",
        "aff": "Dep. of Neuroinformatics, University of Z\u00fcrich and ETH Z\u00fcrich, Switzerland; Dep. of Neuroinformatics, University of Z\u00fcrich and ETH Z\u00fcrich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341697/",
        "gs_citation": 106,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3705516776143036439&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Z\u00fcrich",
        "aff_unique_dep": "Department of Neuroinformatics",
        "aff_unique_url": "https://www.unizh.ch",
        "aff_unique_abbr": "UZH",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9341607",
        "title": "To Ask or Not to Ask: A User Annoyance Aware Preference Elicitation Framework for Social Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper we investigate how social robots can efficiently gather user preferences without exceeding the allowed user annoyance threshold. To do so, we use a Gazebo based simulated office environment with a TIAGo Steel robot. We then formulate the user annoyance aware preference elicitation problem as a combination of tensor completion and knapsack problems. We then test our approach on the aforementioned simulated environment and demonstrate that it can accurately estimate user preferences.",
        "primary_area": "",
        "author": "Balint Gucsi;Danesh S. Tarapore;William Yeoh;Christopher Amato;Long Tran-Thanh;Balint Gucsi;Danesh S. Tarapore;William Yeoh;Christopher Amato;Long Tran-Thanh",
        "authorids": "/37088689034;/37086275308;/38667180200;/37901317700;/38277493200;/37088689034;/37086275308;/38667180200;/37901317700;/38277493200",
        "aff": "University of Southampton, UK; University of Southampton, UK; Washington University in St. Louis, USA; Northeastern University, USA; University of Warwick, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341607/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4911510157405434657&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;2;3",
        "aff_unique_norm": "University of Southampton;Washington University in St. Louis;Northeastern University;University of Warwick",
        "aff_unique_dep": ";;;",
        "aff_unique_url": "https://www.southampton.ac.uk;https://wustl.edu;https://www.northeastern.edu;https://www.warwick.ac.uk",
        "aff_unique_abbr": "Southampton;WUSTL;NEU;Warwick",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";St. Louis",
        "aff_country_unique_index": "0;0;1;1;0",
        "aff_country_unique": "United Kingdom;United States"
    },
    {
        "id": "9341583",
        "title": "Tool Shape Optimization through Backpropagation of Neural Network",
        "track": "main",
        "status": "Poster",
        "abstract": "When executing a certain task, human beings can choose or make an appropriate tool to achieve the task. This research especially addresses the optimization of tool shape for robotic tool-use. We propose a method in which a robot obtains an optimized tool shape, tool trajectory, or both, depending on a given task. The feature of our method is that a transition of the task state when the robot moves a certain tool along a certain trajectory is represented by a deep neural network. We applied this method to object manipulation tasks on a 2D plane, and verified that appropriate tool shapes are generated by using this novel method.",
        "primary_area": "",
        "author": "Kento Kawaharazuka;Toru Ogawa;Cota Nabeshima;Kento Kawaharazuka;Toru Ogawa;Cota Nabeshima",
        "authorids": "/37086101930;/37086937035;/37947185000;/37086101930;/37086937035;/37947185000",
        "aff": "Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo; Preferred Networks, Inc.; Preferred Networks, Inc.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341583/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2646017824797008583&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "The University of Tokyo;Preferred Networks, Inc.",
        "aff_unique_dep": "Department of Mechano-Informatics, Graduate School of Information Science and Technology;",
        "aff_unique_url": "https://www.u-tokyo.ac.jp;https://www.preferred-networks.com",
        "aff_unique_abbr": "UTokyo;PFN",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Tokyo;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9341040",
        "title": "Topology-Aware Self-Organizing Maps for Robotic Information Gathering",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a novel algorithm for constructing a maximally informative path for a robot in an information gathering task. We use a Self-Organizing Map (SOM) framework to discover important topological features in the information function. Using these features, we identify a set of distinct classes of trajectories, each of which has improved convexity compared with the original function. We then leverage a Stochastic Gradient Ascent (SGA) optimization algorithm within each of these classes to optimize promising representative paths. The increased convexity leads to an improved chance of SGA finding the globally optimal path across all homotopy classes. We demonstrate our approach in three different simulated experiments. First, we show that our SOM is able to correctly learn the topological features of a gyre environment with a well-defined topology. Then, in the second set of experiments, we compare the effectiveness of our algorithm in an information gathering task across the gyre world, a set of randomly generated worlds, and a set of worlds drawn from real-world ocean model data. In these experiments our algorithm performs competitively or better than a state-of-the-art Branch and Bound while requiring significantly less computation time. Lastly, the final set of experiments show that our method scales better than the comparison methods across different planning mission sizes in real-world environments.",
        "primary_area": "",
        "author": "Seth McCammon;Dylan Jones;Geoffrey A. Hollinger;Seth McCammon;Dylan Jones;Geoffrey A. Hollinger",
        "authorids": "/37086071053;/37086070292;/37543482700;/37086071053;/37086070292;/37543482700",
        "aff": "Collaborative Robotics and Intelligent Systems (CoRIS) Institute, Oregon State University, Corvallis, OR; Collaborative Robotics and Intelligent Systems (CoRIS) Institute, Oregon State University, Corvallis, OR; Collaborative Robotics and Intelligent Systems (CoRIS) Institute, Oregon State University, Corvallis, OR",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341040/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13672928087784762491&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Oregon State University",
        "aff_unique_dep": "Collaborative Robotics and Intelligent Systems (CoRIS) Institute",
        "aff_unique_url": "https://oregonstate.edu",
        "aff_unique_abbr": "OSU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Corvallis",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341797",
        "title": "Touch the Wind: Simultaneous Airflow, Drag and Interaction Sensing on a Multirotor",
        "track": "main",
        "status": "Poster",
        "abstract": "Disturbance estimation for Micro Aerial Vehicles (MAVs) is crucial for robustness and safety. In this paper, we use novel, bio-inspired airflow sensors to measure the airflow acting on a MAV, and we fuse this information in an Unscented Kalman filter (UKF) to simultaneously estimate the three-dimensional wind vector, the drag force, and other interaction forces (e.g. due to collisions, interaction with a human) acting on the robot. To this end, we present and compare a fully model-based and a deep learning-based strategy. The model-based approach considers the MAV and airflow sensor dynamics and its interaction with the wind, while the deep learning-based strategy uses a Long Short-Term Memory (LSTM) to obtain an estimate of the relative airflow, which is then fused in the proposed filter. We validate our methods in hardware experiments, showing that we can accurately estimate relative airflow of up to 4 m/s, and we can differentiate drag and interaction force.",
        "primary_area": "",
        "author": "Andrea Tagliabue;Aleix Paris;Suhan Kim;Regan Kubicek;Sarah Bergbreiter;Jonathan P. How;Andrea Tagliabue;Aleix Paris;Suhan Kim;Regan Kubicek;Sarah Bergbreiter;Jonathan P. How",
        "authorids": "/37086131568;/37086862338;/37087323805;/37088690293;/37542605000;/37276347700;/37086131568;/37086862338;/37087323805;/37088690293;/37542605000;/37276347700",
        "aff": "Department of Aeronautics and Astronautics, Massachusetts Institute of Technology; Department of Aeronautics and Astronautics, Massachusetts Institute of Technology; Department of Mechanical Engineering, Carnegie Mellon University; Department of Mechanical Engineering, Carnegie Mellon University; Department of Mechanical Engineering, Carnegie Mellon University; Department of Aeronautics and Astronautics, Massachusetts Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341797/",
        "gs_citation": 42,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4604930804899798366&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;1;1;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;Carnegie Mellon University",
        "aff_unique_dep": "Department of Aeronautics and Astronautics;Department of Mechanical Engineering",
        "aff_unique_url": "https://web.mit.edu;https://www.cmu.edu",
        "aff_unique_abbr": "MIT;CMU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Cambridge;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341171",
        "title": "Toward Analytical Modeling and Evaluation of Curvature-Dependent Distributed Friction Force in Tendon-Driven Continuum Manipulators",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present an analytical modeling approach to address the problem of tension loss in a generic variable curvature tendon-driven continuum manipulators (TD-CM) occurring due to the tendon-sheath distributed friction force. Despite the previous approaches in the literature, our presented model and the iterative solution algorithm do not rely on a priori known curvature/shape of the TD-CM and can be implemented on any TD-CM with constant/ variable curvatures with a continuous neutral axis function. The performance of the proposed modeling approach in predicting the distributed tendon tension and tension loss has been evaluated via simulation and experimental studies on a TD-CM with planar bending. Results demonstrate the outstanding and accurate performance of our novel modeling and the proposed solution algorithm.",
        "primary_area": "",
        "author": "Yang Liu;Seong Hyo Ahn;Uksang Yoo;Alexander R. Cohen;Farshid Alambeigi;Yang Liu;Seong Hyo Ahn;Uksang Yoo;Alexander R. Cohen;Farshid Alambeigi",
        "authorids": "/37088690587;/37088688805;/37088939475;/37088687265;/38542997100;/37088690587;/37088688805;/37088939475;/37088687265;/38542997100",
        "aff": "Walker Department of Mechanical Engineering, University of Texas at Austin, Austin, TX, USA; Walker Department of Mechanical Engineering, University of Texas at Austin, Austin, TX, USA; Walker Department of Mechanical Engineering, University of Texas at Austin, Austin, TX, USA; Walker Department of Mechanical Engineering, University of Texas at Austin, Austin, TX, USA; Walker Department of Mechanical Engineering, University of Texas at Austin, Austin, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341171/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3901535424259936226&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Texas at Austin",
        "aff_unique_dep": "Walker Department of Mechanical Engineering",
        "aff_unique_url": "https://www.utexas.edu",
        "aff_unique_abbr": "UT Austin",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Austin",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341360",
        "title": "Toward Enabling a Hundred Drones to Land in a Minute",
        "track": "main",
        "status": "Poster",
        "abstract": "Currently, drone research and development has received significant attention worldwide. Particularly, delivery services employ drones as it is a viable method to improve delivery efficiency by using a several unmanned drones. Research has been conducted to realize complete automation of drone control for such services. However, regarding the takeoff and landing port of the drones, conventional methods have focused on the landing operation of a single drone, and the continuous landing of multiple drones has not been realized. To address this issue, we propose a completely novel port system, \"EAGLES Port,\" that allows several drones to continuously land and takeoff in a short time. Experiments verified that the landing time efficiency of the proposed port is ideally 7.5 times higher than that of conventional vertical landing systems. Moreover, the system can tolerate 270 mm of horizontal positional error, \u00b130\u00b0 of angular error in the drone\u2019s approach (\u00b140\u00b0 with the proposed gate mechanism), and up to 1.9 m/s of drone\u2019s approach speed. This technology significantly contributes to the scalability of drone usage. Therefore, it is critical for the development of a future drone port for the landing of automated drone swarms.",
        "primary_area": "",
        "author": "Daiki Fujikura;Kenjiro Tadakuma;Masahiro Watanabe;Yoshito Okada;Kazunori Ohno;Satoshi Tadokoro;Daiki Fujikura;Kenjiro Tadakuma;Masahiro Watanabe;Yoshito Okada;Kazunori Ohno;Satoshi Tadokoro",
        "authorids": "/37088687774;/38534909200;/37403419100;/37402546000;/37285220400;/37296054300;/37088687774;/38534909200;/37403419100;/37402546000;/37285220400;/37296054300",
        "aff": "Graduate school of Information Sciences, Tohoku University, Japan; Graduate school of Information Sciences, Tohoku University, Japan; Graduate school of Information Sciences, Tohoku University, Japan; Graduate school of Information Sciences, Tohoku University, Japan; Graduate school of Information Sciences, Tohoku University, Japan; Graduate school of Information Sciences, Tohoku University, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341360/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6448534806745356307&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Tohoku University",
        "aff_unique_dep": "Graduate school of Information Sciences",
        "aff_unique_url": "https://www.tohoku.ac.jp",
        "aff_unique_abbr": "Tohoku U",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9340802",
        "title": "Toward Hierarchical Self-Supervised Monocular Absolute Depth Estimation for Autonomous Driving Applications",
        "track": "main",
        "status": "Poster",
        "abstract": "In recent years, self-supervised methods for monocular depth estimation has rapidly become an significant branch of depth estimation task, especially for autonomous driving applications. Despite the high overall precision achieved, current methods still suffer from a) imprecise object-level depth inference and b) uncertain scale factor. The former problem would cause texture copy or provide inaccurate object boundary, and the latter would require current methods to have an additional sensor like LiDAR to provide depth ground-truth or stereo camera as additional training inputs, which makes them difficult to implement. In this work, we propose to address these two problems together by introducing DNet. Our contributions are twofold: a) a novel dense connected prediction (DCP) layer is proposed to provide better object-level depth estimation and b) specifically for autonomous driving scenarios, dense geometrical constrains (DGC) is introduced so that precise scale factor can be recovered without additional cost for autonomous vehicles. Extensive experiments have been conducted and, both DCP layer and DGC module are proved to be effectively solving the aforementioned problems respectively. Thanks to DCP layer, object boundary can now be better distinguished in the depth map and the depth is more continues on object level. It is also demonstrated that the performance of using DGC to perform scale recovery is comparable to that using ground-truth information, when the camera height is given and the ground point takes up more than 1.03% of the pixels. Code is available at https://github.com/TJ-IPLab/DNet.",
        "primary_area": "",
        "author": "Feng Xue;Guirong Zhuo;Ziyuan Huang;Wufei Fu;Zhuoyue Wu;Marcelo H. Ang;Feng Xue;Guirong Zhuo;Ziyuan Huang;Wufei Fu;Zhuoyue Wu;Marcelo H. Ang",
        "authorids": "/37088689504;/38027908900;/37086868757;/37088687840;/37088690962;/37279138700;/37088689504;/38027908900;/37086868757;/37088687840;/37088690962;/37279138700",
        "aff": "School of Automotive Studies, Tongji University, Shanghai, China; School of Automotive Studies, Tongji University, Shanghai, China; Department of Mechanical Engineering, National University of Singapore, Singapore; School of Automotive Studies, Tongji University, Shanghai, China; School of Automotive Studies, Tongji University, Shanghai, China; Department of Mechanical Engineering, National University of Singapore, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340802/",
        "gs_citation": 108,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6679609341349443097&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;0;0;1",
        "aff_unique_norm": "Tongji University;National University of Singapore",
        "aff_unique_dep": "School of Automotive Studies;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.tongji.edu.cn;https://www.nus.edu.sg",
        "aff_unique_abbr": "Tongji;NUS",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Shanghai;",
        "aff_country_unique_index": "0;0;1;0;0;1",
        "aff_country_unique": "China;Singapore"
    },
    {
        "id": "9341425",
        "title": "Towards Autonomous Control of Magnetic Suture Needles",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a magnetic needle steering controller to manipulate mesoscale magnetic suture needles for executing planned suturing motion. This is an initial step towards our research objective: enabling autonomous control of magnetic suture needles for suturing tasks in minimally invasive surgery. To demonstrate the feasibility of accurate motion control, we employ a cardinally-arranged four-coil electromagnetic system setup and control magnetic suture needles in a 2-dimensional environment, i.e., a Petri dish filled with viscous liquid. Different from only using magnetic field gradients to control small magnetic agents under high damping conditions, the dynamics of a magnetic suture needle are investigated and encoded in the controller. Based on mathematical formulations of magnetic force and torque applied on the needle, we develop a kinematically constrained dynamic model that controls the needle to rotate and only translate along its central axis for mimicking the behavior of surgical sutures. A current controller of the electromagnetic system combining with closed-loop control schemes is designed for commanding the magnetic suture needles to achieve desired linear and angular velocities. To evaluate control performance of magnetic suture needles, we conduct experiments including needle rotation control, needle position control by using discretized trajectories, and velocity control by using a time-varying circular trajectory. The experiment results demonstrate our proposed needle steering controller can perform accurate motion control of mesoscale magnetic suture needles.",
        "primary_area": "",
        "author": "Matthew Fan;Xiaolong Liu;Kamakshi Jain;Daniel Lerner;Lamar O. Mair;Irving N. Weinberg;Yancy Diaz-Mercado;Axel Krieger;Matthew Fan;Xiaolong Liu;Kamakshi Jain;Daniel Lerner;Lamar O. Mair;Irving N. Weinberg;Yancy Diaz-Mercado;Axel Krieger",
        "authorids": "/37088686664;/37089394631;/37088406244;/37086698289;/37086156608;/37326900500;/38352376400;/38484449800;/37088686664;/37089394631;/37088406244;/37086698289;/37086156608;/37326900500;/38352376400;/38484449800",
        "aff": "Department of Mechanical Engineering, University of Maryland, College Park, Maryland, USA; Department of Mechanical Engineering, University of Maryland, College Park, Maryland, USA; Department of Mechanical Engineering, University of Maryland, College Park, Maryland, USA; Department of Mechanical Engineering, University of Maryland, College Park, Maryland, USA; Weinberg Medical Physics, Inc, North Bethesda, Maryland, USA; Weinberg Medical Physics, Inc, North Bethesda, Maryland, USA; Department of Mechanical Engineering, University of Maryland, College Park, Maryland, USA; Department of Mechanical Engineering, University of Maryland, College Park, Maryland, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341425/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8300728506024089675&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;1;1;0;0",
        "aff_unique_norm": "University of Maryland, College Park;Weinberg Medical Physics, Inc",
        "aff_unique_dep": "Department of Mechanical Engineering;",
        "aff_unique_url": "https://www/umd.edu;",
        "aff_unique_abbr": "UMD;",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "College Park;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341670",
        "title": "Towards Cooperative Transport of a Suspended Payload via Two Aerial Robots with Inertial Sensing",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper addresses the problem of cooperative transport of a point mass hoisted by two aerial robots. Treating the robots as a leader and a follower, the follower stabilizes the system with respect to the leader using only feedback from its Inertial Measurement Units (IMU). This is accomplished by neglecting the acceleration of the leader, analyzing the system through the generalized coordinates or the cables\u2019 angles, and employing an observation model based on the IMU measurements. A lightweight estimator based on an Extended Kalman Filter (EKF) and a controller are derived to stabilize the robot-payload-robot system. The proposed methods are verified with extensive flight experiments, first with a single robot and then with two robots. The results show that the follower is capable of realizing the desired quasi-static trajectory using only its IMU measurements. The outcomes demonstrate promising progress towards the goal of autonomous cooperative transport of a suspended payload via small flying robots with minimal sensing and computational requirements.",
        "primary_area": "",
        "author": "Heng Xie;Xinyu Cai;Pakpong Chirarattananon;Heng Xie;Xinyu Cai;Pakpong Chirarattananon",
        "authorids": "/37088556769;/37088689871;/38364343100;/37088556769;/37088689871;/38364343100",
        "aff": "Department of Biomedical Engineering, City University of Hong Kong, Hong Kong SAR, China; Department of Biomedical Engineering, City University of Hong Kong, Hong Kong SAR, China; Department of Biomedical Engineering, City University of Hong Kong, Hong Kong SAR, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341670/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9194399330563315462&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "City University of Hong Kong",
        "aff_unique_dep": "Department of Biomedical Engineering",
        "aff_unique_url": "https://www.cityu.edu.hk",
        "aff_unique_abbr": "CityU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Hong Kong SAR",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9341802",
        "title": "Towards Deep Learning Assisted Autonomous UAVs for Manipulation Tasks in GPS-Denied Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we present a pragmatic approach to enable unmanned aerial vehicle (UAVs) to autonomously perform highly complicated tasks of object pick and place. This paper is largely inspired by challenge-2 of MBZIRC 2020 and is primarily focused on the task of assembling large 3D structures in outdoors and GPS-denied environments. Primary contributions of this system are: (i) a novel computationally efficient deep learning based unified multi-task visual perception system for target localization, part segmentation, and tracking, (ii) a novel deep learning based grasp state estimation, (iii) a retracting electromagnetic gripper design, (iv) a remote computing approach which exploits state-of-the-art MIMO based high speed (5000Mb/s) wireless links to allow the UAVs to execute compute intensive tasks on remote high end compute servers, and (v) system integration in which several system components are weaved together in order to develop an optimized software stack. We use DJI Matrice-600 Pro, a hexrotor UAV and interface it with the custom designed gripper. Our framework is deployed on the specified UAV in order to report the performance analysis of the individual modules. Apart from the manipulation system, we also highlight several hidden challenges associated with the UAVs in this context.",
        "primary_area": "",
        "author": "Ashish Kumar;Mohit Vohra;Ravi Prakash;L. Behera;Ashish Kumar;Mohit Vohra;Ravi Prakash;L. Behera",
        "authorids": "/37085729269;/37087236592;/37085729252;/37352203400;/37085729269;/37087236592;/37085729252;/37352203400",
        "aff": "Department of Electrical Engineering, Indian Institute of Technology, Kanpur; Department of Electrical Engineering, Indian Institute of Technology, Kanpur; Department of Electrical Engineering, Indian Institute of Technology, Kanpur; Department of Electrical Engineering, Indian Institute of Technology, Kanpur",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341802/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5040683146174130227&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Indian Institute of Technology Kanpur",
        "aff_unique_dep": "Department of Electrical Engineering",
        "aff_unique_url": "https://www.iitk.ac.in",
        "aff_unique_abbr": "IIT Kanpur",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Kanpur",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "9341054",
        "title": "Towards Dynamic Transparency: Robust Interaction Force Tracking Using Multi-Sensory Control on an Arm Exoskeleton",
        "track": "main",
        "status": "Poster",
        "abstract": "A high-quality free-motion rendering is one of the most vital traits to achieve an immersive human-robot interaction. Rendering free-motion is notably challenging for rehabilitation exoskeletons due to their relatively high weight and powerful actuators required for strength training and support. In the presence of dynamic human movements, accurate feedback linearization of the robot's dynamics is necessary to allow for a linear synthesis of interaction wrench controllers. Hence, we introduce a virtual model controller that uses two 6-DoF force sensors to control the interaction wrenches of a multi-DoF torque-controlled exoskeleton over the joint accelerations and inverse dynamics. Furthermore, we propose a disturbance observer for controlling the joint acceleration to diminish the influence of modeling errors on the inverse dynamics. To provide a high-bandwidth, low-bias estimation of the system's acceleration, we introduce a bias-observer which fuses the information from joint encoders and seven low priced IMUs. We have validated the performance of our proposed control structure on the shoulder and arm exoskeleton ANYexo. The experimental comparison of the controllers shows a reduction of the felt inertia and maximum reflected joint torque by a factor of more than three compared to state of the art. The controllers' robustness w.r.t. a model mismatch is validated. The experiments show that the closed-loop acceleration control improves the tracking, particularly at joints with low inertia. The proposed controllers' performance sets a new benchmark in haptic transparency for comparable devices and should be transferable to other applications.",
        "primary_area": "",
        "author": "Yves Zimmermann;Emek Bar\u0131\u015f K\u00fc\u00e7\u00fcktabak;Farbod Farshidian;Robert Riener;Marco Hutter;Yves Zimmermann;Emek Bar\u0131\u015f K\u00fc\u00e7\u00fcktabak;Farbod Farshidian;Robert Riener;Marco Hutter",
        "authorids": "/37089133835;/37088687440;/37085428006;/37281610400;/37545251000;/37089133835;/37088687440;/37085428006;/37281610400;/37545251000",
        "aff": "Sensory-Motor Systems Lab, ETH Zurich, Switzerland; Systems Lab, ETH Zurich, Switzerland; Systems Lab, ETH Zurich, Switzerland; Spinal Cord Injury Center, University Hospital Balgrist, Zurich, Switzerland; Systems Lab, ETH Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341054/",
        "gs_citation": 46,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10255192436976896434&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "ETH Zurich;University Hospital Balgrist",
        "aff_unique_dep": "Sensory-Motor Systems Lab;Spinal Cord Injury Center",
        "aff_unique_url": "https://www.ethz.ch;https://www.balgrist.ch",
        "aff_unique_abbr": "ETHZ;",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Zurich",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9340804",
        "title": "Towards General Infeasibility Proofs in Motion Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a general approach for constructing proofs of motion planning infeasibility. Effective high-dimensional motion planners, such as sampling-based methods, are limited to probabilistic completeness, so when no plan exists, these planners either do not terminate or can only run until a timeout. We address this completeness challenge by augmenting a sampling-based planner with a method to create an infeasibility proof in conjunction with building the search tree. An infeasibility proof is a closed polytope that separates the start and goal into disconnected components of the free configuration space. We identify possible facets of the polytope via a nonlinear optimization procedure using sampled points in the non-free configuration space. We identify the set of facets forming the separating polytope via a linear constraint satisfaction problem. This proof construction is valid for general (i.e., non-Cartesian) configuration spaces. We demonstrate this approach on the low-dimensional Jaco manipulator and discuss engineering approaches to scale to higher dimensional spaces.",
        "primary_area": "",
        "author": "Sihui Li;Neil T. Dantam;Sihui Li;Neil T. Dantam",
        "authorids": "/37087060752;/37546520000;/37087060752;/37546520000",
        "aff": "Department of Computer Science, Colorado School of Mines, USA; Department of Computer Science, Colorado School of Mines, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340804/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12817227038013500837&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Colorado School of Mines",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.mines.edu",
        "aff_unique_abbr": "CSM",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341172",
        "title": "Towards Gradient-Based Actuation of Magnetic Soft Robots Using a Six-Coil Electromagnetic System",
        "track": "main",
        "status": "Poster",
        "abstract": "Soft materials with embedded magnetic properties can be actuated in a contactless manner for dexterous motion in restricted and unstructured environments. Magnetic soft robots have been demonstrated to be capable of versatile and programmable untethered motion. However, magnetic soft robots reported in literature are typically actuated by utilizing magnetic fields to generate torques that produce deformation. By contrast, this work investigates the utilization of field gradients to produce tethering forces for anchoring soft robots to the working surface, in conjunction with the use of magnetic fields to generate torques for deformation. The methodology applied here uses a six-coil electromagnetic system for field generation. The approach to achieve the magnetic field and gradients desired for soft robot motion is described, along with the restrictions imposed by Maxwell's equations. The design and fabrication of the soft robots is explained together with calculations to assess the capabilities of the actuation system. Proof-of-concept demonstrations of soft robot motion show Hexapede robots with the ability to `walk' untethered on the ceiling of the workspace, working against gravity; and lightweight Worm robots made of thin strips of material are demonstrated to locomote while staying in contact with the ground.",
        "primary_area": "",
        "author": "Venkatasubramanian Kalpathy Venkiteswaran;Sarthak Misra;Venkatasubramanian Kalpathy Venkiteswaran;Sarthak Misra",
        "authorids": "/37086693104;/37536488800;/37086693104;/37536488800",
        "aff": "Department of Biomechanical Engineering, Surgical Robotics Laboratory, University of Twente, Enschede, The Netherlands; Department of Biomedical Engineering, University of Groningen and University Medical Centre Groningen, Groningen, The Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341172/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6552199986124057182&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of Twente;University of Groningen",
        "aff_unique_dep": "Department of Biomechanical Engineering;Department of Biomedical Engineering",
        "aff_unique_url": "https://www.utwente.nl;https://www.rug.nl",
        "aff_unique_abbr": "UT;RUG",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Enschede;Groningen",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Netherlands"
    },
    {
        "id": "9341051",
        "title": "Towards Micro Robot Hydrobatics: Vision-based Guidance, Navigation, and Control for Agile Underwater Vehicles in Confined Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Despite the recent progress, guidance, navigation, and control (GNC) are largely unsolved for agile micro autonomous underwater vehicles (\u03bcAUVs). Hereby, robust and accurate self-localization systems which fit \u03bcAUVs play a key role and their absence constitutes a severe bottleneck in micro underwater robotics research. In this work we present, first, a small-size low-cost high performance vision-based self-localization module which solves this bottleneck even for the requirements of highly agile robot platforms. Second, we present its integration into a powerful GNC-framework which allows the deployment of \u03bcAUVs in fully autonomous mission. Finally, we critically evaluate the performance of the localization system and the GNC-framework in two experimental scenarios.",
        "primary_area": "",
        "author": "Daniel A Duecker;Nathalie Bauschmann;Tim Hansen;Edwin Kreuzer;Robert Seifried;Daniel A Duecker;Nathalie Bauschmann;Tim Hansen;Edwin Kreuzer;Robert Seifried",
        "authorids": "/37086262227;/37088566120;/37088568293;/37622316900;/37085695330;/37086262227;/37088566120;/37088568293;/37622316900;/37085695330",
        "aff": "Hamburg University of Technology, Germany; Hamburg University of Technology, Germany; Hamburg University of Technology, Germany; Hamburg University of Technology, Germany; Hamburg University of Technology, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341051/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4757530556046288079&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Hamburg University of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.tuhh.de/",
        "aff_unique_abbr": "TUHH",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9341598",
        "title": "Towards RL-Based Hydraulic Excavator Automation",
        "track": "main",
        "status": "Poster",
        "abstract": "In this article we present a data-driven approach for automated arm control of a hydraulic excavator. Except for the link lengths of the excavator, our method does not require machine-specific knowledge nor gain tuning. Using data collected during operation of the excavator, we train a general purpose model to effectively represent the highly non-linear dynamics of the hydraulic actuation and joint linkage. Together with the link lengths a simulation is set up to train a neural network control policy for end-effector position tracking using reinforcement learning (RL). The control policy directly outputs the actuator commands that can be applied to the machine without unfounded filtering or modification. The proposed method is implemented and tested on a 12t hydraulic excavator, controlling its 4 main arm joints to track desired positions of the shovel in free-space. The results demonstrate the feasibility of directly applying control policies trained in simulation to the physical excavator for accurate and stable position tracking.",
        "primary_area": "",
        "author": "Pascal Egli;Marco Hutter;Pascal Egli;Marco Hutter",
        "authorids": "/37088688994;/37545251000;/37088688994;/37545251000",
        "aff": "Robotic Systems Lab, ETH Zurich, Switzerland; Robotic Systems Lab, ETH Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341598/",
        "gs_citation": 53,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12173417648221920145&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Robotic Systems Lab",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9341490",
        "title": "Towards Real-Time Non-Gaussian SLAM for Underdetermined Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a method for processing sparse, non-Gaussian multimodal data in a simultaneous localization and mapping (SLAM) framework using factor graphs. Our approach demonstrates the feasibility of using a sum-product inference strategy to recover functional belief marginals from highly non-Gaussian situations, relaxing the prolific unimodal Gaussian assumption. The method is more focused than conventional multi-hypothesis approaches, but still captures dominant modes via multi-modality. The proposed algorithm exists in a trade space that spans the anticipated uncertainty of measurement data, task-specific performance, sensor quality, and computational cost. This work leverages several major algorithm design constructs, including clique recycling, to put an upper bound on the allowable computational expense \u2013 a major challenge in non-parametric methods. To better demonstrate robustness, experimental results show the feasibility of the method on at least two of four major sources of non-Gaussian behavior: i) the first introduces a canonical range-only problem which is always underdetermined although composed exclusively from Gaussian measurements; ii) a real-world AUV dataset, demonstrating how ambiguous acoustic correlator measurements are directly incorporated into a non-Gaussian SLAM solution, while using dead reckon tethering to overcome short term computational requirements.",
        "primary_area": "",
        "author": "Dehann Fourie;Nicholas R. Rypkema;Pedro Vaz Teixeira;Sam Claassens;Erin Fischell;John Leonard;Dehann Fourie;Nicholas R. Rypkema;Pedro Vaz Teixeira;Sam Claassens;Erin Fischell;John Leonard",
        "authorids": "/37670490400;/37086147172;/37089939750;/37086110517;/37085777908;/37329387400;/37670490400;/37086147172;/37089939750;/37086110517;/37085777908;/37329387400",
        "aff": "MIT, Cambridge, MA, USA; Woods Hole Oceanographic Instritution, Woods Hole, MA, USA; Woods Hole Oceanographic Instritution, Woods Hole, MA, USA; University of Chicago, IL, USA; Woods Hole Oceanographic Instritution, Woods Hole, MA, USA; MIT, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341490/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6005604114764826687&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;2;1;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;Woods Hole Oceanographic Institution;University of Chicago",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://web.mit.edu;https://www.whoi.edu;https://www.uchicago.edu",
        "aff_unique_abbr": "MIT;WHOI;UChicago",
        "aff_campus_unique_index": "0;1;1;2;1;0",
        "aff_campus_unique": "Cambridge;Woods Hole;Chicago",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341784",
        "title": "Towards Robust Visual Tracking for Unmanned Aerial Vehicle with Tri-Attentional Correlation Filters",
        "track": "main",
        "status": "Poster",
        "abstract": "Object tracking has been broadly applied in unmanned aerial vehicle (UAV) tasks in recent years. However, existing algorithms still face difficulties such as partial occlusion, clutter background, and other challenging visual factors. Inspired by the cutting-edge attention mechanisms, a novel object tracking framework is proposed to leverage multi-level visual attention. Three primary attention, i.e., contextual attention, dimensional attention, and spatiotemporal attention, are integrated into the training and detection stages of correlation filter-based tracking pipeline. Therefore, the proposed tracker is equipped with robust discriminative power against challenging factors while maintaining high operational efficiency in UAV scenarios. Quantitative and qualitative experiments on two well-known benchmarks with 173 challenging UAV video sequences demonstrate the effectiveness of the proposed framework. The proposed tracking algorithm favorably outperforms 12 state-of-the-art methods, yielding 4.8% relative gain in UAVDT and 8.2% relative gain in UAV123@10fps against the baseline tracker while operating at the speed of ~28 frames per second.",
        "primary_area": "",
        "author": "Yujie He;Changhong Fu;Fuling Lin;Yiming Li;Peng Lu;Yujie He;Changhong Fu;Fuling Lin;Yiming Li;Peng Lu",
        "authorids": "/37088504326;/37086797986;/37088212953;/37087323806;/37087243038;/37088504326;/37086797986;/37088212953;/37087323806;/37087243038",
        "aff": "School of Mechanical Engineering, Tongji University, Shanghai, China; School of Mechanical Engineering, Tongji University, Shanghai, China; School of Mechanical Engineering, Tongji University, Shanghai, China; School of Mechanical Engineering, Tongji University, Shanghai, China; Adaptive Robotic Controls Lab (ArcLab), Hong Kong Polytechnic University (PolyU), Hong Kong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341784/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7816504205164563958&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "Tongji University;Hong Kong Polytechnic University",
        "aff_unique_dep": "School of Mechanical Engineering;Adaptive Robotic Controls Lab (ArcLab)",
        "aff_unique_url": "https://www.tongji.edu.cn;https://www.polyu.edu.hk",
        "aff_unique_abbr": "Tongji;PolyU",
        "aff_campus_unique_index": "0;0;0;0;1",
        "aff_campus_unique": "Shanghai;Hong Kong",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9341773",
        "title": "Towards Transparent Robotic Planning via Contrastive Explanations",
        "track": "main",
        "status": "Poster",
        "abstract": "Providing explanations of chosen robotic actions can help to increase the transparency of robotic planning and improve users' trust. Social sciences suggest that the best explanations are contrastive, explaining not just why one action is taken, but why one action is taken instead of another. We formalize the notion of contrastive explanations for robotic planning policies based on Markov decision processes, drawing on insights from the social sciences. We present methods for the automated generation of contrastive explanations with three key factors: selectiveness, constrictiveness and responsibility. The results of a user study with 100 participants on the Amazon Mechanical Turk platform show that our generated contrastive explanations can help to increase users' understanding and trust of robotic planning policies, while reducing users' cognitive burden.",
        "primary_area": "",
        "author": "Shenghui Chen;Kayla Boggess;Lu Feng;Shenghui Chen;Kayla Boggess;Lu Feng",
        "authorids": "/37088364126;/37088689421;/37085539356;/37088364126;/37088689421;/37085539356",
        "aff": "Department of Computer Science, University of Virginia, Charlottesville, VA, USA; Department of Computer Science, University of Virginia, Charlottesville, VA, USA; Department of Computer Science, University of Virginia, Charlottesville, VA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341773/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3265315852883426747&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Virginia",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.virginia.edu",
        "aff_unique_abbr": "UVA",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Charlottesville",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341625",
        "title": "Towards Understanding and Inferring the Crowd: Guided Second Order Attention Networks and Re-identification for Multi-object Tracking",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-human tracking in the crowded environment is a challenging problem due to occlusions, pose change, viewpoint variation and cluttered background. In this work, we propose a robust feature learning for tracking-by-detection methods based on second-order attention network that can capture higher-order relationships between salient features at the early stages of Convolutional Neural Network (CNN). Guided Second-Order Attention Network (GSAN) that, unlike the existing attention learning methods which are weakly-supervised, uses a supervisory signal based on the quality of the self-learned attention maps. More specifically, GSAN looks into the attended maps of a person having the highest confidence and supervise itself to look into the correct regions in the images of the person. Attention maps learned this way are spatially aligned and thus robust to camera-view changes and body pose variations. We verify the effectiveness of our approach by comparing with the state-of-the-art methods on challenging person re-identification and multi object tracking (MOT) datasets.",
        "primary_area": "",
        "author": "Niraj Bhujel;Li Jun;Yau Wei Yun;Han Wang;Niraj Bhujel;Li Jun;Yau Wei Yun;Han Wang",
        "authorids": "/37087002903;/37086271619;/37086263465;/37292552600;/37087002903;/37086271619;/37086263465;/37292552600",
        "aff": "School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; the Institute for Infocomm Research, A*STAR, Singapore; the Institute for Infocomm Research, A*STAR, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341625/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14214791470211080404&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "Nanyang Technological University;Institute for Infocomm Research",
        "aff_unique_dep": "School of Electrical and Electronic Engineering;",
        "aff_unique_url": "https://www.ntu.edu.sg;https://www.i2r.a-star.edu.sg",
        "aff_unique_abbr": "NTU;I2R",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Singapore;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "9340816",
        "title": "Towards Unsupervised Learning for Instrument Segmentation in Robotic Surgery with Cycle-Consistent Adversarial Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Surgical tool segmentation in endoscopic images is an important problem: it is a crucial step towards full instrument pose estimation and it is used for integration of pre- and intra-operative images into the endoscopic view. While many recent approaches based on convolutional neural networks have shown great results, a key barrier to progress lies in the acquisition of a large number of manually-annotated images which is necessary for an algorithm to generalize and work well in diverse surgical scenarios. Unlike the surgical image data itself, annotations are difficult to acquire and may be of variable quality. On the other hand, synthetic annotations can be automatically generated by using forward kinematic model of the robot and CAD models of tools by projecting them onto an image plane. Unfortunately, this model is very inaccurate and cannot be used for supervised learning of image segmentation models. Since generated annotations will not directly correspond to endoscopic images due to errors, we formulate the problem as an unpaired image-to-image translation where the goal is to learn the mapping between an input endoscopic image and a corresponding annotation using an adversarial model. Our approach allows to train image segmentation models without the need to acquire expensive annotations and can potentially exploit large unlabeled endoscopic image collection outside the annotated distributions of image/annotation data. We test our proposed method on Endovis 2017 challenge dataset and show that it is competitive with supervised segmentation methods.",
        "primary_area": "",
        "author": "Daniil Pakhomov;Wei Shen;Nassir Navab;Daniil Pakhomov;Wei Shen;Nassir Navab",
        "authorids": "/37088687866;/37071253800;/37282965500;/37088687866;/37071253800;/37282965500",
        "aff": "Johns Hopkins University, Baltimore, USA; Johns Hopkins University, Baltimore, USA; Johns Hopkins University, Baltimore, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340816/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3922393291083540869&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Johns Hopkins University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.jhu.edu",
        "aff_unique_abbr": "JHU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Baltimore",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341203",
        "title": "Towards Vision-Based Impedance Control for the Contact Inspection of Unknown Generically-Shaped Surfaces with a Fully-Actuated UAV",
        "track": "main",
        "status": "Poster",
        "abstract": "The integration of computer vision techniques for the accomplishment of autonomous interaction tasks represents a challenging research direction in the context of aerial robotics. In this paper, we consider the problem of contact-based inspection of a textured target of unknown geometry and pose. Exploiting state of the art techniques in computer graphics, tuned and improved for the task at hand, we designed a framework for the projection of a desired trajectory for the robot end-effector on a generically-shaped surface to be inspected. Combining these results with previous work on energy-based interaction control, we are laying the basis of what we call vision-based impedance control paradigm. To demonstrate the feasibility and the effectiveness of our methodology, we present the results of both realistic ROS/Gazebo simulations and preliminary experiments with a fully-actuated hexarotor interacting with heterogeneous curved surfaces whose geometric description is not available a priori, provided that enough visual features on the target are naturally or artificially available to allow the integration of localization and mapping algorithms.",
        "primary_area": "",
        "author": "Ramy Rashad;Davide Bicego;Ran Jiao;Santiago Sanchez-Escalonilla;Stefano Stramigioli;Ramy Rashad;Davide Bicego;Ran Jiao;Santiago Sanchez-Escalonilla;Stefano Stramigioli",
        "authorids": "/37085625955;/37086071930;/37086157769;/37088686178;/37282439300;/37085625955;/37086071930;/37086157769;/37088686178;/37282439300",
        "aff": "Robotics and Mechatronics group, University of Twente, Enschede, The Netherlands; Robotics and Mechatronics group, University of Twente, Enschede, The Netherlands; Robotics and Mechatronics group, University of Twente, Enschede, The Netherlands; Robotics and Mechatronics group, University of Twente, Enschede, The Netherlands; Robotics and Mechatronics group, University of Twente, and ITMO University, Saint Petersburg, Russia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341203/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3982037159103246827&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Twente",
        "aff_unique_dep": "Robotics and Mechatronics group",
        "aff_unique_url": "https://www.utwente.nl",
        "aff_unique_abbr": "UT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Enschede;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Netherlands"
    },
    {
        "id": "9341551",
        "title": "Towards the Development of a Robotic Transcatheter Delivery System for Mitral Valve Implant",
        "track": "main",
        "status": "Poster",
        "abstract": "Mitral regurgitation is one of the most common heart diseases caused by ventricular dysfunction or anatomic abnormality of the mitral valve. The fundamental treatment for mitral regurgitation is to repair/replace the mitral valve through open-heart surgery which is risky and requires more time to recover or through minimally invasive approaches, which have significant challenges and limitations. Through the transcatheter approach, the mitral valve implant is minimally invasively delivered directly to the mitral valve and is clamped onto the leaflet to mitigate or prevent regurgitation. However, this procedure requires delicate manipulation of the catheter in a constrained space and remains a challenging problem. In this work, we present a robotically steerable cathether design for the transcatheter procedure to address mitral regurgitation. The proposed catheter consists of two bending joints, one torsion joint, and implant delivery module at the distal end of the robot. Kinematic models for each joint design are derived and compared with experimental results. Finally, we experimentally demonstrate the feasibility of the proposed catheter to navigate in a phantom heart model. In this demonstration, the bending joint was actuated by 75\u00b0, the torsion joint was actuated by 90\u00b0 and the implant was pushed out by 1.8 mm to deliver the implant.",
        "primary_area": "",
        "author": "Namrata Nayar;Seokhwan Jeong;Jaydev P. Desai;Namrata Nayar;Seokhwan Jeong;Jaydev P. Desai",
        "authorids": "/37088640098;/37087324027;/37282117700;/37088640098;/37087324027;/37282117700",
        "aff": "Wallace H. Coulter Department of Biomedical Engineering, Medical Robotics and Automation (RoboMed) Laboratory, Georgia Center for Medical Robotics (GCMR), Georgia Institute of Technology, Atlanta, GA, USA; Wallace H. Coulter Department of Biomedical Engineering, Medical Robotics and Automation (RoboMed) Laboratory, Georgia Center for Medical Robotics (GCMR), Georgia Institute of Technology, Atlanta, GA, USA; Wallace H. Coulter Department of Biomedical Engineering, Medical Robotics and Automation (RoboMed) Laboratory, Georgia Center for Medical Robotics (GCMR), Georgia Institute of Technology, Atlanta, GA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341551/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17988210605036857819&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Georgia Institute of Technology",
        "aff_unique_dep": "Wallace H. Coulter Department of Biomedical Engineering",
        "aff_unique_url": "https://www.gatech.edu",
        "aff_unique_abbr": "Georgia Tech",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Atlanta",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341601",
        "title": "Tracking Strategy Based on Magnetic Sensors for Microrobot Navigation in the Cochlea",
        "track": "main",
        "status": "Poster",
        "abstract": "One approach to control drug delivery in the cochlea is to use a magnetic microrobot powered by externally applied magnetic fields. However, it is necessary to integrate a localization system to ensure the precise navigation of the microrobot in the cochlear canal. To avoid integrating a clinical imaging modality for the navigation of microrobots in the cochlea, we propose in this work the application of magnetic sensors to localize the magnetic microrobot. In our method, we propose a real-time localization system based only on two sensors to keep a precise localization of the spherical magnetic microrobot. The first sensor measures both the magnetic field of the environment and the magnetic field generated by the microrobot (localization sensor). The second sensor (surrounding sensor) is placed away from the localization sensor, this sensor measures the magnetic field of the environment, which will be subtracted from the signal of the localization sensor to determine the value of the magnetic field of the microrobot. We have proposed a new magnetic sensor calibration method and a robust localization algorithm for precise localization of the microrobot. The experiments demonstrate the effectiveness of the designed system and show the precision of the proposed localization strategy.",
        "primary_area": "",
        "author": "Tarik Kroubi;Karim Belharet;Kamal Bennamane;Tarik Kroubi;Karim Belharet;Kamal Bennamane",
        "authorids": "/37088454063;/37586616100;/37088689529;/37088454063;/37586616100;/37088689529",
        "aff": "Department of Electronics, University of Mouloud Mammeri, Tizi-Ouzou, Algeria; Hautes \u00c9tudes d\u2019Ing\u00e9nieur campus Centre, PRISME, Ch\u00e2teauroux, France; Department of Electronics, University of Mouloud Mammeri, Tizi-Ouzou, Algeria",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341601/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5094086752755412377&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Mouloud Mammeri;Hautes \u00c9tudes d\u2019Ing\u00e9nieur",
        "aff_unique_dep": "Department of Electronics;PRISME",
        "aff_unique_url": ";",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Tizi-Ouzou;Centre",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Algeria;France"
    },
    {
        "id": "9341214",
        "title": "Traffic Control Gesture Recognition for Autonomous Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "A car driver knows how to react on the gestures of the traffic officers. Clearly, this is not the case for the autonomous vehicle, unless it has road traffic control gesture recognition functionalities. In this work, we address the limitation of the existing autonomous driving datasets to provide learning data for traffic control gesture recognition. We introduce a dataset that is based on 3D body skeleton input to perform traffic control gesture classification on every time step. Our dataset consists of 250 sequences from several actors, ranging from 16 to 90 seconds per sequence. To evaluate our dataset, we propose eight sequential processing models based on deep neural networks such as recurrent networks, attention mechanism, temporal convolutional networks and graph convolutional networks. We present an extensive evaluation and analysis of all approaches for our dataset, as well as real-world quantitative evaluation. The code and dataset is publicly available4.",
        "primary_area": "",
        "author": "Julian Wiederer;Arij Bouazizi;Ulrich Kressel;Vasileios Belagiannis;Julian Wiederer;Arij Bouazizi;Ulrich Kressel;Vasileios Belagiannis",
        "authorids": "/37088686349;/37088690381;/37282247500;/37085391038;/37088686349;/37088690381;/37282247500;/37085391038",
        "aff": "Universit\u00e4t Ulm, Ulm, Germany; Universit\u00e4t Ulm, Ulm, Germany; Mercedes-Benz AG, Stuttgart, Germany; Universit\u00e4t Ulm, Ulm, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341214/",
        "gs_citation": 71,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17443687183819157130&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Universit\u00e4t Ulm;Mercedes-Benz AG",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.uni-ulm.de;https://www.mercedes-benz.com",
        "aff_unique_abbr": ";MB AG",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Ulm;Stuttgart",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9341215",
        "title": "Trajectory Tracking of a One-Link Flexible Arm via Iterative Learning Control",
        "track": "main",
        "status": "Poster",
        "abstract": "Trajectory tracking of flexible link robots is a classical control problem. Historically, the link elasticity was considered as something to be removed. Hence, the control performance was guaranteed by adopting high-gain feedback loops and, possibly, a dynamic compensation with the result to stiffen up the dynamic behavior of the robot. Nowadays, robots are pushed more and more towards a safe physical interaction with a less and less structured environment. Hence, the design and control of the robots moved to an on-purpose introduction of highly compliant elements in the robot bodies, the so-called soft robotics, and towards control approaches that aim to provide the tracking performance without a substantial change in the robot dynamic behavior. Following this approach, we present an iterative learning control that relies mainly on a feedforward component, hence preserves the robot dynamics, for trajectory tracking of a one-link flexible arm. We provide a condition, based on the system dynamics and similar to the Strong Inertially Coupled property, that ensures the applicability of the proposed control method. Finally, we report simulation and experimental tests to validate the theoretical results.",
        "primary_area": "",
        "author": "Michele Pierallini;Franco Angelini;Riccardo Mengacci;Alessandro Palleschi;Antonio Bicchi;Manolo Garabini;Michele Pierallini;Franco Angelini;Riccardo Mengacci;Alessandro Palleschi;Antonio Bicchi;Manolo Garabini",
        "authorids": "/37087077798;/37086154079;/37086935756;/37086919526;/37278626700;/37947205100;/37087077798;/37086154079;/37086935756;/37086919526;/37278626700;/37947205100",
        "aff": "Dipartimento di Ingegneria dell\u2019Informazione, Universit\u00e0 di Pisa, Pisa, Italy; Soft Robotics for Human Cooperation and Rehabilitation, Fondazione Istituto Italiano di Tecnologia, Genova, Italy; Dipartimento di Ingegneria dell\u2019Informazione, Universit\u00e0 di Pisa, Pisa, Italy; Dipartimento di Ingegneria dell\u2019Informazione, Universit\u00e0 di Pisa, Pisa, Italy; Soft Robotics for Human Cooperation and Rehabilitation, Fondazione Istituto Italiano di Tecnologia, Genova, Italy; Dipartimento di Ingegneria dell\u2019Informazione, Universit\u00e0 di Pisa, Pisa, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341215/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17154824293420087709&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;0;1;0",
        "aff_unique_norm": "Universit\u00e0 di Pisa;Fondazione Istituto Italiano di Tecnologia",
        "aff_unique_dep": "Dipartimento di Ingegneria dell\u2019Informazione;Soft Robotics for Human Cooperation and Rehabilitation",
        "aff_unique_url": "https://www.unipi.it;https://www.iit.it",
        "aff_unique_abbr": "UniPi;IIT",
        "aff_campus_unique_index": "0;1;0;0;1;0",
        "aff_campus_unique": "Pisa;Genova",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9341108",
        "title": "Transferability in an 8-DoF Parallel Robot with a Configurable Platform",
        "track": "main",
        "status": "Poster",
        "abstract": "Parallel robots with configurable platforms (PRCPs) combine the benefits of parallel robots with additional functionalities such as grasping and cutting. However, some of the theoretical tools used to study classical parallel robots do not apply to parallel robots with configurable platforms. This paper uses screw theory to study the transferable wrenches from the robot's limbs to the configurable platform of an 8-DoF parallel robot. Deriving the transferable wrenches allows one to construct the screw system that is applied to each part of the configurable platform. Based on the analytical expressions of the limb and platform wrenches that have been derived and numerically validated, the mathematical tools that are used to study parallel kinematic structures, such as Grassmann line geometry, can thus be applied to the presented parallel robot with a configurable platform.",
        "primary_area": "",
        "author": "Redwan Dahmouche;Kefei Wen;Cl\u00e9ment Gosselin;Redwan Dahmouche;Kefei Wen;Cl\u00e9ment Gosselin",
        "authorids": "/37546446600;/37086932500;/37293911800;/37546446600;/37086932500;/37293911800",
        "aff": "D\u00e9partement AS2M, Universit\u00e9 Bourgogne Franche-Comt\u00e9, Institut FEMTO-ST, Besan\u00e7on, France; D\u00e9partement de g\u00e9nie m\u00e9canique, Laboratoire de robotique de l'Universit\u00e9 Laval, Universit\u00e9 Laval, Qu\u00e9bec, Canada; D\u00e9partement de g\u00e9nie m\u00e9canique, Laboratoire de robotique de l'Universit\u00e9 Laval, Universit\u00e9 Laval, Qu\u00e9bec, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341108/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5765235419190812251&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Universit\u00e9 Bourgogne Franche-Comt\u00e9;Universit\u00e9 Laval",
        "aff_unique_dep": "D\u00e9partement AS2M;D\u00e9partement de g\u00e9nie m\u00e9canique",
        "aff_unique_url": "https://www.ubfc.fr;https://www.ulaval.ca",
        "aff_unique_abbr": ";UL",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Besan\u00e7on;Qu\u00e9bec",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "France;Canada"
    },
    {
        "id": "9341709",
        "title": "Transferring Experience from Simulation to the Real World for Precise Pick-And-Place Tasks in Highly Cluttered Scenes",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we introduce a novel learning-based approach for grasping known rigid objects in highly cluttered scenes and precisely placing them based on depth images. Our Placement Quality Network (PQ-Net) estimates the object pose and the quality for each automatically generated grasp pose for multiple objects simultaneously at 92 fps in a single forward pass of a neural network. All grasping and placement trials are executed in a physics simulation and the gained experience is transferred to the real world using domain randomization. We demonstrate that our policy successfully transfers to the real world. PQ-Net outperforms other model-free approaches in terms of grasping success rate and automatically scales to new objects of arbitrary symmetry without any human intervention.",
        "primary_area": "",
        "author": "Kilian Kleeberger;Markus V\u00f6lk;Marius Moosmann;Erik Thiessenhusen;Florian Roth;Richard Bormann;Marco F. Huber;Kilian Kleeberger;Markus V\u00f6lk;Marius Moosmann;Erik Thiessenhusen;Florian Roth;Richard Bormann;Marco F. Huber",
        "authorids": "/37087323129;/37088690304;/37088690603;/37088685964;/37089466461;/38541025900;/37392400600;/37087323129;/37088690304;/37088690603;/37088685964;/37089466461;/38541025900;/37392400600",
        "aff": "Department Robot and Assistive Systems, Fraunhofer Institute for Manufacturing Engineering and Automation IPA, Stuttgart, Germany; Department Robot and Assistive Systems, Fraunhofer Institute for Manufacturing Engineering and Automation IPA, Stuttgart, Germany; Department Robot and Assistive Systems, Fraunhofer Institute for Manufacturing Engineering and Automation IPA, Stuttgart, Germany; Department Robot and Assistive Systems, Fraunhofer Institute for Manufacturing Engineering and Automation IPA, Stuttgart, Germany; Department Robot and Assistive Systems, Fraunhofer Institute for Manufacturing Engineering and Automation IPA, Stuttgart, Germany; Department Robot and Assistive Systems, Fraunhofer Institute for Manufacturing Engineering and Automation IPA, Stuttgart, Germany; Institute of Industrial Manufacturing and Management IFF, University of Stuttgart, Stuttgart, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341709/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16390041615141927338&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;1",
        "aff_unique_norm": "Fraunhofer Institute for Manufacturing Engineering and Automation IPA;University of Stuttgart",
        "aff_unique_dep": "Department Robot and Assistive Systems;Institute of Industrial Manufacturing and Management IFF",
        "aff_unique_url": "https://www.ipa.fraunhofer.de;https://www.uni-stuttgart.de",
        "aff_unique_abbr": "Fraunhofer IPA;",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Stuttgart",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9341001",
        "title": "True\u00c6dapt: Learning Smooth Online Trajectory Adaptation with Bounded Jerk, Acceleration and Velocity in Joint Space",
        "track": "main",
        "status": "Poster",
        "abstract": "We present True\u00c6dapt, a model-free method to learn online adaptations of robot trajectories based on their effects on the environment. Given sensory feedback and future waypoints of the original trajectory, a neural network is trained to predict joint accelerations at regular intervals. The adapted trajectory is generated by linear interpolation of the predicted accelerations, leading to continuously differentiable joint velocities and positions. Bounded jerks, accelerations and velocities are guaranteed by calculating the range of valid accelerations at each decision step and clipping the network's output accordingly. A deviation penalty during the training process causes the adapted trajectory to follow the original one. Smooth movements are encouraged by penalizing high accelerations and jerks. We evaluate our approach by training a simulated KUKA iiwa robot to balance a ball on a plate while moving and demonstrate that the balancing policy can be directly transferred to a real robot.",
        "primary_area": "",
        "author": "Jonas C. Kiemel;Robin Weitemeyer;Pascal Mei\u00dfner;Torsten Kr\u00f6ger;Jonas C. Kiemel;Robin Weitemeyer;Pascal Mei\u00dfner;Torsten Kr\u00f6ger",
        "authorids": "/37088504301;/37088691258;/37086908496;/37283223400;/37088504301;/37088691258;/37086908496;/37283223400",
        "aff": "Institute for Anthropomatics and Robotics - Intelligent Process Automation and Robotics (IAR-IPR), Karlsruhe Institute of Technology (KIT); Institute for Anthropomatics and Robotics - Intelligent Process Automation and Robotics (IAR-IPR), Karlsruhe Institute of Technology (KIT); Institute for Anthropomatics and Robotics - Intelligent Process Automation and Robotics (IAR-IPR), Karlsruhe Institute of Technology (KIT); Institute for Anthropomatics and Robotics - Intelligent Process Automation and Robotics (IAR-IPR), Karlsruhe Institute of Technology (KIT)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341001/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8039585814895210135&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Karlsruhe Institute of Technology",
        "aff_unique_dep": "Institute for Anthropomatics and Robotics - Intelligent Process Automation and Robotics (IAR-IPR)",
        "aff_unique_url": "https://www.kit.edu",
        "aff_unique_abbr": "KIT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9341223",
        "title": "Tumbling and Hopping Locomotion Control for a Minor Body Exploration Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents the modeling and analysis of a novel moving mechanism \"tumbling\" for asteroid exploration. The system actuation is provided by an internal motor and torque wheel; elastic spring-mounted spikes are attached to the perimeter of a circular-shaped robot, protruding normal to the surface and distributed uniformly. Compared with the conventional motion mechanisms, this simple layout enhances the capability of the robot to traverse a diverse microgravity environment. Technical challenges involved in conventional moving mechanisms, such as uncertainty of moving direction and inability to traverse uneven asteroid surfaces, can now be solved. A tumbling locomotion approach demonstrates two beneficial characteristics in this environment. First, tumbling locomotion maintains contact between the rover spikes and the ground. This enables the robot to continually apply control adjustments to realize precise and controlled motion. Second, owing to the nature of the mechanical interaction of the spikes and potential uneven surface protrusions, the robot can traverse uneven surfaces. In this paper, we present the dynamics modeling of the robot and analyze the motion of the robot experimentally and via numerical simulations. The results of this study help establish a moving strategy to approach the desired locations on asteroid surfaces.",
        "primary_area": "",
        "author": "Keita Kobashi;Ayumu Bando;Kenji Nagaoka;Kazuya Yoshida;Keita Kobashi;Ayumu Bando;Kenji Nagaoka;Kazuya Yoshida",
        "authorids": "/37088685919;/37088688130;/37410392900;/37329693000;/37088685919;/37088688130;/37410392900;/37329693000",
        "aff": "Department of Aerospace Engineering, Graduate School of Engineering, Tohoku University, Sendai, Japan; Department of Aerospace Engineering, Graduate School of Engineering, Tohoku University, Sendai, Japan; Department of Mechanical and Control Engineering, Graduate School of Engineering, Kyushu Institute of Technology, Kitakyushu, Japan; Department of Aerospace Engineering, Graduate School of Engineering, Tohoku University, Sendai, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341223/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=971823922634795850&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Tohoku University;Kyushu Institute of Technology",
        "aff_unique_dep": "Department of Aerospace Engineering;Department of Mechanical and Control Engineering",
        "aff_unique_url": "https://www.tohoku.ac.jp;https://www.kyutech.ac.jp",
        "aff_unique_abbr": "Tohoku U;Kyutech",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Sendai;Kitakyushu",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9340934",
        "title": "UAV Coverage Path Planning under Varying Power Constraints using Deep Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Coverage path planning (CPP) is the task of designing a trajectory that enables a mobile agent to travel over every point of an area of interest. We propose a new method to control an unmanned aerial vehicle (UAV) carrying a camera on a CPP mission with random start positions and multiple options for landing positions in an environment containing no-fly zones. While numerous approaches have been proposed to solve similar CPP problems, we leverage end-to-end reinforcement learning (RL) to learn a control policy that generalizes over varying power constraints for the UAV. Despite recent improvements in battery technology, the maximum flying range of small UAVs is still a severe constraint, which is exacerbated by variations in the UAV's power consumption that are hard to predict. By using map-like input channels to feed spatial information through convolutional network layers to the agent, we are able to train a double deep Q-network (DDQN) to make control decisions for the UAV, balancing limited power budget and coverage goal. The proposed method can be applied to a wide variety of environments and harmonizes complex goal structures with system constraints.",
        "primary_area": "",
        "author": "Mirco Theile;Harald Bayerlein;Richard Nai;David Gesbert;Marco Caccamo;Mirco Theile;Harald Bayerlein;Richard Nai;David Gesbert;Marco Caccamo",
        "authorids": "/37086532277;/37086439336;/37086595149;/37274459900;/37272874700;/37086532277;/37086439336;/37086595149;/37274459900;/37272874700",
        "aff": "TUM Department of Mechanical Engineering, Technical University of Munich, Germany; Communication Systems Department, EURECOM, Sophia Antipolis, France; TUM Department of Mechanical Engineering, Technical University of Munich, Germany; Communication Systems Department, EURECOM, Sophia Antipolis, France; TUM Department of Mechanical Engineering, Technical University of Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340934/",
        "gs_citation": 129,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3407440745524026278&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;1;0",
        "aff_unique_norm": "Technical University of Munich;EURECOM",
        "aff_unique_dep": "Department of Mechanical Engineering;Communication Systems Department",
        "aff_unique_url": "https://www.tum.de;https://www.eurecom.fr",
        "aff_unique_abbr": "TUM;",
        "aff_campus_unique_index": "0;1;0;1;0",
        "aff_campus_unique": "Munich;Sophia Antipolis",
        "aff_country_unique_index": "0;1;0;1;0",
        "aff_country_unique": "Germany;France"
    },
    {
        "id": "9341790",
        "title": "UAV-AdNet: Unsupervised Anomaly Detection using Deep Neural Networks for Aerial Surveillance",
        "track": "main",
        "status": "Poster",
        "abstract": "Anomaly detection is a key goal of autonomous surveillance systems that should be able to alert unusual observations. In this paper, we propose a holistic anomaly detection system using deep neural networks for surveillance of critical infrastructures (e.g., airports, harbors, warehouses) using an unmanned aerial vehicle (UAV). First, we present a heuristic method for the explicit representation of spatial layouts of objects in bird-view images. Then, we propose a deep neural network architecture for unsupervised anomaly detection (UAV-AdNet), which is trained on environment representations and GPS labels of bird-view images jointly. Unlike studies in the literature, we combine GPS and image data to predict abnormal observations. We evaluate our model against several baselines on our aerial surveillance dataset and show that it performs better in scene reconstruction and several anomaly detection tasks. The codes, trained models, dataset, and video will be available at https://bozcani.github.io/uavadnet.",
        "primary_area": "",
        "author": "Ilker Bozcan;Erdal Kayacan;Ilker Bozcan;Erdal Kayacan",
        "authorids": "/37086455563;/37595300900;/37086455563;/37595300900",
        "aff": "Department of Engineering, Artificial Intelligence in Robotics Laboratory (Air Lab), Aarhus University, Aarhus C, Denmark; Department of Engineering, Artificial Intelligence in Robotics Laboratory (Air Lab), Aarhus University, Aarhus C, Denmark",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341790/",
        "gs_citation": 38,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5117831806684272617&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Aarhus University",
        "aff_unique_dep": "Department of Engineering",
        "aff_unique_url": "https://www.au.dk",
        "aff_unique_abbr": "AU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Aarhus C",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Denmark"
    },
    {
        "id": "9340943",
        "title": "UST: Unifying Spatio-Temporal Context for Trajectory Prediction in Autonomous Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "Trajectory prediction has always been a challenging problem for autonomous driving, since it needs to infer the latent intention from the behaviors and interactions from traffic participants. This problem is intrinsically hard, because each participant may behave differently under different environments and interactions. This key is to effectively model the interlaced influence from both spatial context and temporal context. Existing work usually encodes these two types of context separately, which would lead to inferior modeling of the scenarios. In this paper, we first propose a unified approach to treat time and space dimensions equally for modeling spatio-temporal context. The proposed module is simple and easy to implement within several lines of codes. In contrast to existing methods which heavily rely on recurrent neural network for temporal context and hand-crafted structure for spatial context, our method could automatically partition the spatio-temporal space to adapt to the data. Lastly, we test our proposed framework on two recently proposed trajectory prediction dataset ApolloScape and Argoverse. We show that the proposed method substantially outperforms the previous state-of-the-art methods while maintaining its simplicity. These encouraging results further validate the superiority of our approach.",
        "primary_area": "",
        "author": "Hao He;Hengchen Dai;Naiyan Wang;Hao He;Hengchen Dai;Naiyan Wang",
        "authorids": "/37088687703;/37088689316;/37085671305;/37088687703;/37088689316;/37085671305",
        "aff": "TuSimple, Beijing, China; TuSimple, Beijing, China; TuSimple, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340943/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11697226450040441283&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "TuSimple",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9341042",
        "title": "UWB-based System for UAV Localization in GNSS-Denied Environments: Characterization and Dataset",
        "track": "main",
        "status": "Poster",
        "abstract": "Small unmanned aerial vehicles (UAV) have penetrated multiple domains over the past years. In GNSS-denied or indoor environments, aerial robots require a robust and stable localization system, often with external feedback, in order to fly safely. Motion capture systems are typically utilized indoors when accurate localization is needed. However, these systems are expensive and most require a fixed setup. In this paper, we study and characterize an ultra-wideband (UWB) system for navigation and localization of aerial robots indoors based on Decawave's DWM1001 UWB node. The system is portable, inexpensive and can be battery powered in its totality. We show the viability of this system for autonomous flight of UAVs, and provide open-source methods and data that enable its widespread application even with movable anchor systems. We characterize the accuracy based on the position of the UAV with respect to the anchors, its altitude and speed, and the distribution of the anchors in space. Finally, we analyze the accuracy of the self-calibration of the anchors' positions.",
        "primary_area": "",
        "author": "Jorge Pe\u00f1a Queralta;Carmen Mart\u00ednez Almansa;Fabrizio Schiano;Dario Floreano;Tomi Westerlund;Jorge Pe\u00f1a Queralta;Carmen Mart\u00ednez Almansa;Fabrizio Schiano;Dario Floreano;Tomi Westerlund",
        "authorids": "/37086828421;/37088690697;/37086123698;/37282168700;/37298877900;/37086828421;/37088690697;/37086123698;/37282168700;/37298877900",
        "aff": "Turku Intelligent Embedded and Robotic Systems (TIERS) Lab, University of Turku, Turku, Finland; Turku Intelligent Embedded and Robotic Systems (TIERS) Lab, University of Turku, Turku, Finland; Laboratory of Intelligent Systems (LIS), \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), Lausanne, Switzerland; Laboratory of Intelligent Systems (LIS), \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), Lausanne, Switzerland; Turku Intelligent Embedded and Robotic Systems (TIERS) Lab, University of Turku, Turku, Finland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341042/",
        "gs_citation": 137,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18200115981737058887&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;1;0",
        "aff_unique_norm": "University of Turku;\u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne",
        "aff_unique_dep": "Turku Intelligent Embedded and Robotic Systems (TIERS) Lab;Laboratory of Intelligent Systems",
        "aff_unique_url": "https://www.utu.fi;https://www.epfl.ch",
        "aff_unique_abbr": "UTU;EPFL",
        "aff_campus_unique_index": "0;0;1;1;0",
        "aff_campus_unique": "Turku;Lausanne",
        "aff_country_unique_index": "0;0;1;1;0",
        "aff_country_unique": "Finland;Switzerland"
    },
    {
        "id": "9340756",
        "title": "Ultra Low-Cost Printable Folding Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Current techniques in robot design and fabrication are time consuming and costly. Robot designs are needed that facilitate low-cost fabrication techniques and reduce the design to production timeline. Here we present an axial-rotational coupled metastructure that can serve as the functional core of a low-cost 3D printed walking robot. Using an origami-inspired assembly technique, the axial-rotational coupled metastructure robot can be 3D printed flat and then folded into a final configuration. This print-then-fold approach allows for the facile integration of critical subcomponents during the printing process. The axial-rotational metastructures eliminate the need for joints and linkages by enabling locomotion through a single compliant structure. Finite element models of the axialrotational metastructures were developed and validated against experimental deformation of 3D printed units under tensile loading. As a proof-of-concept, an ultra low-cost 3D-printed metabot was designed and fabricated using the proposed axial-rotational coupled metastructure and its walking performance was characterized. A top speed of 4.30 mm/s was achieved with an alternating stepping gait at a frequency of 0.8 Hz.",
        "primary_area": "",
        "author": "Saul Schaffer;Emily Wang;Nathan Cooper;Bo Li;Zeynep Temel;Ozan Akkus;Victoria A. Webster-Wood;Saul Schaffer;Emily Wang;Nathan Cooper;Bo Li;Zeynep Temel;Ozan Akkus;Victoria A. Webster-Wood",
        "authorids": "/37087133413;/37088690847;/37089544298;/37088691190;/37088689031;/37086195674;/37088689130;/37087133413;/37088690847;/37089544298;/37088691190;/37088689031;/37086195674;/37088689130",
        "aff": "Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA; Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA; Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA; Department of Mechanical and Aerospace Engineering, Case Western Reserve University, Cleveland, OH; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA; Department of Mechanical and Aerospace Engineering, Case Western Reserve University, Cleveland, OH; Department of Biomedical Engineering, by courtesy, Carnegie Mellon University, Pittsburgh, PA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340756/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:5Z35-mRJ7nAJ:scholar.google.com/&scioq=Ultra+Low-Cost+Printable+Folding+Robots&hl=en&as_sdt=0,5",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;1;0;1;0",
        "aff_unique_norm": "Carnegie Mellon University;Case Western Reserve University",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.cmu.edu;https://www.case.edu",
        "aff_unique_abbr": "CMU;CWRU",
        "aff_campus_unique_index": "0;0;0;1;0;1;0",
        "aff_campus_unique": "Pittsburgh;Cleveland",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341439",
        "title": "Ultra-Wideband Aided UAV Positioning Using Incremental Smoothing with Ranges and Multilateration",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a novel smoothing approach for ultra-wideband (UWB) aided unmanned aerial vehicle (UAV) positioning. Existing works based on smoothing or filtering estimate 3D position of UAV by updating a solution for each single 1D low-dimensional UWB range measurement. However, a low-dimensional single range measurement merely acts as a weak constraint in a solution space for UAV position estimation, and thus it can often lead to incorrect estimation in unfavorable conditions. Inspired by the idea that the multilateration outcome can be utilized as a measurement providing a strong constraint, we utilize two types of UWB-based measurements: (i) each single 1D range as a high-rate measurement with a weak constraint, and (ii) multilateration outcome as a low-rate measurement with a strong constraint. We propose an incremental smoothing-based method that seamlessly integrates these two types of UWB-based measurements and inertial measurement into a unified factor graph framework. Through experiments under a variety of scenarios, we demonstrate the effectiveness of the proposed method.",
        "primary_area": "",
        "author": "Jungwon Kang;Kunwoo Park;Zahra Arjmandi;Gunho Sohn;Mozhdeh Shahbazi;Patrick M\u00e9nard;Jungwon Kang;Kunwoo Park;Zahra Arjmandi;Gunho Sohn;Mozhdeh Shahbazi;Patrick M\u00e9nard",
        "authorids": "/37554163000;/37088597293;/37086828645;/38361635000;/37088688718;/37088691057;/37554163000;/37088597293;/37086828645;/38361635000;/37088688718;/37088691057",
        "aff": "Department of Earth and Space Science and Engineering, Lassonde School of Engineering, York University, Toronto, Ontario, Canada; Department of Earth and Space Science and Engineering, Lassonde School of Engineering, York University, Toronto, Ontario, Canada; Department of Earth and Space Science and Engineering, Lassonde School of Engineering, York University, Toronto, Ontario, Canada; Department of Earth and Space Science and Engineering, Lassonde School of Engineering, York University, Toronto, Ontario, Canada; Centre de g\u00e9omatique du Qu\u00e9bec, Saguenay, Qu\u00e9bec, Canada; Centre de g\u00e9omatique du Qu\u00e9bec, Saguenay, Qu\u00e9bec, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341439/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6373449740871094084&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;1",
        "aff_unique_norm": "York University;Centre de g\u00e9omatique du Qu\u00e9bec",
        "aff_unique_dep": "Department of Earth and Space Science and Engineering;",
        "aff_unique_url": "https://www.yorku.ca;",
        "aff_unique_abbr": "York U;",
        "aff_campus_unique_index": "0;0;0;0;1;1",
        "aff_campus_unique": "Toronto;Saguenay",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9340913",
        "title": "Ultrasound-Guided Robotic Navigation with Deep Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper we introduce the first reinforcement learning (RL) based robotic navigation method which utilizes ultrasound (US) images as an input. Our approach combines state-of-the-art RL techniques, specifically deep Q-networks (DQN) with memory buffers and a binary classifier for deciding when to terminate the task.Our method is trained and evaluated on an in-house collected data-set of 34 volunteers and when compared to pure RL and supervised learning (SL) techniques, it performs substantially better, which highlights the suitability of RL navigation for US-guided procedures. When testing our proposed model, we obtained a 82.91% chance of navigating correctly to the sacrum from 165 different starting positions on 5 different unseen simulated environments.",
        "primary_area": "",
        "author": "Hannes Hase;Mohammad Farid Azampour;Maria Tirindelli;Magdalini Paschali;Walter Simson;Emad Fatemizadeh;Nassir Navab;Hannes Hase;Mohammad Farid Azampour;Maria Tirindelli;Magdalini Paschali;Walter Simson;Emad Fatemizadeh;Nassir Navab",
        "authorids": "/37088690360;/37085578239;/37086453713;/37086557562;/37086555204;/37298402800;/37282965500;/37088690360;/37085578239;/37086453713;/37086557562;/37086555204;/37298402800;/37282965500",
        "aff": "Computer Aided Medical Procedures, Technische Universit\u00e4t M\u00fcnchen, Munich, Germany; Sharif University of Technology, Tehran, Iran; Computer Aided Medical Procedures, Technische Universit\u00e4t M\u00fcnchen, Munich, Germany; Computer Aided Medical Procedures, Technische Universit\u00e4t M\u00fcnchen, Munich, Germany; Computer Aided Medical Procedures, Technische Universit\u00e4t M\u00fcnchen, Munich, Germany; Sharif University of Technology, Tehran, Iran; Computer Aided Medical Procedures, John Hopkins University, Baltimore, MD, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340913/",
        "gs_citation": 57,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9402868011217479725&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;0;0;0;1;2",
        "aff_unique_norm": "Technische Universit\u00e4t M\u00fcnchen;Sharif University of Technology;John Hopkins University",
        "aff_unique_dep": "Computer Aided Medical Procedures;;Computer Aided Medical Procedures",
        "aff_unique_url": "https://www.tum.de;https://www.sharif.edu;https://www.jhu.edu",
        "aff_unique_abbr": "TUM;SUT;JHU",
        "aff_campus_unique_index": "0;1;0;0;0;1;2",
        "aff_campus_unique": "Munich;Tehran;Baltimore",
        "aff_country_unique_index": "0;1;0;0;0;1;2",
        "aff_country_unique": "Germany;Iran;United States"
    },
    {
        "id": "9340732",
        "title": "UnRectDepthNet: Self-Supervised Monocular Depth Estimation using a Generic Framework for Handling Common Camera Distortion Models",
        "track": "main",
        "status": "Poster",
        "abstract": "In classical computer vision, rectification is an integral part of multi-view depth estimation. It typically includes epipolar rectification and lens distortion correction. This process simplifies the depth estimation significantly, and thus it has been adopted in CNN approaches. However, rectification has several side effects, including a reduced field of view (FOV), resampling distortion, and sensitivity to calibration errors. The effects are particularly pronounced in case of significant distortion (e.g., wide-angle fisheye cameras). In this paper, we propose a generic scale-aware self-supervised pipeline for estimating depth, euclidean distance, and visual odometry from unrectified monocular videos. We demonstrate a similar level of precision on the unrectified KITTI dataset with barrel distortion comparable to the rectified KITTI dataset. The intuition being that the rectification step can be implicitly absorbed within the CNN model, which learns the distortion model without increasing complexity. Our approach does not suffer from a reduced field of view and avoids computational costs for rectification at inference time. To further illustrate the general applicability of the proposed framework, we apply it to wide-angle fisheye cameras with 190\u00b0 horizontal field of view. The training framework UnRectDepthNet takes in the camera distortion model as an argument and adapts projection and unprojection functions accordingly. The proposed algorithm is evaluated further on the KITTI rectified dataset, and we achieve state-of-the-art results that improve upon our previous work FisheyeDistanceNet [1]. Qualitative results on a distorted test scene video sequence indicate excellent performance1.",
        "primary_area": "",
        "author": "Varun Ravi Kumar;Senthil Yogamani;Markus Bach;Christian Witt;Stefan Milz;Patrick M\u00e4der;Varun Ravi Kumar;Senthil Yogamani;Markus Bach;Christian Witt;Stefan Milz;Patrick M\u00e4der",
        "authorids": "/37086543375;/37086351846;/37088507311;/37089046935;/37086545390;/37089272433;/37086543375;/37086351846;/37088507311;/37089046935;/37086545390;/37089272433",
        "aff": "Technische Universit\u00e4t Ilmenau, Germany; Valeo Vision Systems, Ireland; Valeo DAR Kronach, Germany; Valeo DAR Kronach, Germany; Technische Universit\u00e4t Ilmenau, Germany; Technische Universit\u00e4t Ilmenau, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340732/",
        "gs_citation": 61,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10951171297085563188&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;2;0;0",
        "aff_unique_norm": "Technische Universit\u00e4t Ilmenau;Valeo Vision Systems;Valeo",
        "aff_unique_dep": ";;DAR",
        "aff_unique_url": "https://www.tu-ilmenau.de/;;",
        "aff_unique_abbr": "TU Ilmenau;;",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Kronach",
        "aff_country_unique_index": "0;1;0;0;0;0",
        "aff_country_unique": "Germany;Ireland"
    },
    {
        "id": "9341045",
        "title": "Uncertainty Aware Texture Classification and Mapping Using Soft Tactile Sensors",
        "track": "main",
        "status": "Poster",
        "abstract": "Spatial mapping of surface roughness is a critical enabling technology for automating adaptive sanding operations. We leverage GelSight sensors to convert the problem of surface roughness measurement into a vision classification problem. By combining GelSight sensors with Optitrack positioning systems we attempt to develop an accurate spatial mapping of surface roughness that can compare to human touch, the current state of the art for large scale manufacturing. To perform the classification, we propose the use of Bayesian neural networks in conjunction with uncertainty-aware prediction. We compare the sensor and network with a human baseline for both absolute and relative texture classification. To establish a baseline, we collected performance data from humans on their ability to classify materials into 60, 120, and 180 grit sanded pine boards. Our results showed that the probabilistic network performs at the level of human touch for absolute and relative classifications. Using the Bayesian approach enables establishing a confidence bound on our prediction. We were able to integrate the sensor with Optitrack to provide a spatial map of sanding grit applied to pine boards. From this result, we can conclude that GelSight with Bayesian neural networks can learn accurate representations for sanding, and could be a significant enabling technology for closed loop robotic sanding operations.",
        "primary_area": "",
        "author": "Alexander Amini;Jeffrey I. Lipton;Daniela Rus;Alexander Amini;Jeffrey I. Lipton;Daniela Rus",
        "authorids": "/37086454594;/37086014107;/37279652300;/37086454594;/37086014107;/37279652300",
        "aff": "Computer Science and Artificial Intelligence Lab, MIT, Cambridge, MA, USA; Mechanical Engineering Department, University of Washington, Seattle, WA, USA; Computer Science and Artificial Intelligence Lab, MIT, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341045/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8493798204094463750&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;University of Washington",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Lab;Mechanical Engineering Department",
        "aff_unique_url": "https://web.mit.edu;https://www.washington.edu",
        "aff_unique_abbr": "MIT;UW",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Cambridge;Seattle",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341251",
        "title": "Uncertainty-aware Self-supervised 3D Data Association",
        "track": "main",
        "status": "Poster",
        "abstract": "3D object trackers usually require training on large amounts of annotated data that is expensive and time-consuming to collect. Instead, we propose leveraging vast unlabeled datasets by self-supervised metric learning of 3D object trackers, with a focus on data association. Large scale annotations for unlabeled data are cheaply obtained by automatic object detection and association across frames. We show how these self-supervised annotations can be used in a principled manner to learn point-cloud embeddings that are effective for 3D tracking. We estimate and incorporate uncertainty in self-supervised tracking to learn more robust embeddings, without needing any labeled data. We design embeddings to differentiate objects across frames, and learn them using uncertainty-aware self-supervised training. Finally, we demonstrate their ability to perform accurate data association across frames, towards effective and accurate 3D tracking. Project videos and code are at https://jianrenw.github.io/Self-Supervised-3D-Data-Association/.",
        "primary_area": "",
        "author": "Jianren Wang;Siddharth Ancha;Yi-Ting Chen;David Held;Jianren Wang;Siddharth Ancha;Yi-Ting Chen;David Held",
        "authorids": "/37087079357;/37088691472;/37086488009;/37408101800;/37087079357;/37088691472;/37086488009;/37408101800",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Honda Research Institute, Mountain View, CA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341251/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10956899293547185369&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Carnegie Mellon University;Honda Research Institute",
        "aff_unique_dep": "Robotics Institute;",
        "aff_unique_url": "https://www.cmu.edu;https://honda-ri.com",
        "aff_unique_abbr": "CMU;HRI",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Pittsburgh;Mountain View",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340905",
        "title": "Understanding Contexts Inside Robot and Human Manipulation Tasks through Vision-Language Model and Ontology System in Video Streams",
        "track": "main",
        "status": "Poster",
        "abstract": "Manipulation tasks in daily life, such as pouring water, unfold through human intentions. Being able to process contextual knowledge from these Activities of Daily Living (ADLs) over time can help us understand manipulation intentions, which are essential for an intelligent robot to transition smoothly between various manipulation actions. In this paper, to model the intended concepts of manipulation, we present a vision dataset under a strictly constrained knowledge domain for both robot and human manipulations, where manipulation concepts and relations are stored by an ontology system in a taxonomic manner. Furthermore, we propose a scheme to generate a combination of visual attentions and an evolving knowledge graph filled with commonsense knowledge. Our scheme works with real-world camera streams and fuses an attention-based Vision-Language model with the ontology system. The experimental results demonstrate that the proposed scheme can successfully represent the evolution of an intended object manipulation procedure for both robots and humans. The proposed scheme allows the robot to mimic human-like intentional behaviors by watching real-time videos. We aim to develop this scheme further for real-world robot intelligence in Human-Robot Interaction.",
        "primary_area": "",
        "author": "Chen Jiang;Masood Dehghan;Martin Jagersand;Chen Jiang;Masood Dehghan;Martin Jagersand",
        "authorids": "/37086935025;/37951137300;/37269568300;/37086935025;/37951137300;/37269568300",
        "aff": "Department of Computing Science, University of Alberta, Edmonton, Canada; Department of Computing Science, University of Alberta, Edmonton, Canada; Department of Computing Science, University of Alberta, Edmonton, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340905/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11912722054232291507&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Alberta",
        "aff_unique_dep": "Department of Computing Science",
        "aff_unique_url": "https://www.ualberta.ca",
        "aff_unique_abbr": "UAlberta",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Edmonton",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9341018",
        "title": "Understanding Dynamic Scenes using Graph Convolution Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a novel Multi-Relational Graph Convolutional Network (MRGCN) based framework to model on-road vehicle behaviors from a sequence of temporally ordered frames as grabbed by a moving monocular camera. The input to MRGCN is a multi-relational graph where the graph's nodes represent the active and passive agents/objects in the scene, and the bidirectional edges that connect every pair of nodes are encodings of their Spatio-temporal relations.We show that this proposed explicit encoding and usage of an intermediate spatio-temporal interaction graph to be well suited for our tasks over learning end-end directly on a set of temporally ordered spatial relations. We also propose an attention mechanism for MRGCNs that conditioned on the scene dynamically scores the importance of information from different interaction types.The proposed framework achieves significant performance gain over prior methods on vehicle-behavior classification tasks on four datasets. We also show a seamless transfer of learning to multiple datasets without resorting to fine-tuning. Such behavior prediction methods find immediate relevance in a variety of navigation tasks such as behavior planning, state estimation, and applications relating to the detection of traffic violations over videos.",
        "primary_area": "",
        "author": "Sravan Mylavarapu;Mahtab Sandhu;Priyesh Vijayan;K Madhava Krishna;Balaraman Ravindran;Anoop Namboodiri;Sravan Mylavarapu;Mahtab Sandhu;Priyesh Vijayan;K Madhava Krishna;Balaraman Ravindran;Anoop Namboodiri",
        "authorids": "/37088648900;/37086488844;/37085512772;/38201465600;/37537957400;/37268964700;/37088648900;/37086488844;/37085512772;/38201465600;/37537957400;/37268964700",
        "aff": "Center for Visual Information Technology, KCIS, IIIT Hyderabad; Robotics Research Center, KCIS, IIIT Hyderabad; School of Computer Science, McGill University and Mila; Robotics Research Center, KCIS, IIIT Hyderabad; Dept. of CSE and Robert Bosch Center for Data Science and AI, IIT Madras; Center for Visual Information Technology, KCIS, IIIT Hyderabad",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341018/",
        "gs_citation": 34,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9308762555771087283&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;0;2;0",
        "aff_unique_norm": "International Institute of Information Technology, Hyderabad;McGill University;IIT Madras",
        "aff_unique_dep": "Center for Visual Information Technology;School of Computer Science;Dept. of CSE",
        "aff_unique_url": "https://iiit Hyderabad.ac.in;https://www.mcgill.ca;https://www.iitm.ac.in",
        "aff_unique_abbr": "IIIT Hyderabad;McGill;IITM",
        "aff_campus_unique_index": "0;0;1;0;2;0",
        "aff_campus_unique": "Hyderabad;Montreal;Madras",
        "aff_country_unique_index": "0;0;1;0;0;0",
        "aff_country_unique": "India;Canada"
    },
    {
        "id": "9340919",
        "title": "Underwater Monocular Image Depth Estimation using Single-beam Echosounder",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a methodology for real-time depth estimation of underwater monocular camera images, fusing measurements from a single-beam echosounder. Our system exploits the echosounder's detection cone to match its measurements with the detected feature points from a monocular SLAM system. Such measurements are integrated in a monocular SLAM system to adjust the visible map points and the scale. We also provide a novel calibration process to determine the extrinsic between camera and echosounder to have reliable matching. Our proposed approach is implemented within ORB-SLAM2 and evaluated in a swimming pool and in the ocean to validate image depth estimation improvement. In addition, we demonstrate its applicability for improved underwater color correction. Overall, the proposed sensor fusion system enables inexpensive underwater robots with a monocular camera and echosounder to correct the depth estimation and scale in visual SLAM, leading to interesting future applications, such as underwater exploration and mapping.",
        "primary_area": "",
        "author": "Monika Roznere;Alberto Quattrini Li;Monika Roznere;Alberto Quattrini Li",
        "authorids": "/37087322448;/37085808885;/37087322448;/37085808885",
        "aff": "Department of Computer Science, Dartmouth College, Hanover, NH, USA; Department of Computer Science, Dartmouth College, Hanover, NH, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340919/",
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5974586385626172406&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Dartmouth College",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.dartmouth.edu",
        "aff_unique_abbr": "Dartmouth",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Hanover",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340946",
        "title": "Unified Calibration for Multi-camera Multi-LiDAR Systems using a Single Checkerboard",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a unified calibration method for multi-camera multi-LiDAR systems. Only using a single planar checkerboard, the captured checkerboard frames by each sensor are classified as either global frames if they are observed by at least two sensors, or a local frame if observed by a single camera. Both global and local frames of each camera are used to estimate its intrinsic parameters, whereas the global frames between sensors are for computing their relative poses. In contrast to the previous methods that simply combine the pairwise poses (e.g., camera-to-camera or camera-to-LiDAR) that are separately estimated, we further optimize the sensor poses in the system globally using all observations as the constraints in the optimization problem. We find that the point-to-plane distances are effective as camera-to-LiDAR constraints where the points are 3D positions of the checkerboard corners and the planes are estimated from the LiDAR point-cloud. Also, abundant corner observations in the local frames enable the joint optimization of intrinsic and extrinsic parameters in a unified framework. The proposed calibration method utilizes entire observations in a unified global optimization framework, and it significantly reduces the error caused by a simple composition of the relative sensor poses. We extensively evaluate the proposed algorithm qualitatively and quantitatively using real and synthetic datasets. We plan to make the implementation open to the public with the paper publication.",
        "primary_area": "",
        "author": "Wonmyung Lee;Changhee Won;Jongwoo Lim;Wonmyung Lee;Changhee Won;Jongwoo Lim",
        "authorids": "/37088687532;/37086936082;/37075566700;/37088687532;/37086936082;/37075566700",
        "aff": "Department of Computer Sicence, Hanyang University, Seoul, Korea; MultiplEYE Co., Ltd., Seoul, Korea; MultiplEYE Co., Ltd., Seoul, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340946/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7909870536394554000&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Hanyang University;MultiplEYE Co., Ltd.",
        "aff_unique_dep": "Department of Computer Science;",
        "aff_unique_url": "http://www.hanyang.ac.kr;",
        "aff_unique_abbr": "HYU;",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Seoul;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9341241",
        "title": "Unilateral Constraints for Torque-based Whole-Body Control",
        "track": "main",
        "status": "Poster",
        "abstract": "This work uses quadratic programming to perform torque control on an industrial collaborative robot, while keeping defined constraints. Limits for rotational and translational coordinates are considered at position, velocity and acceleration level. Although the problem of having hardware and safe limitations has been considered before. Solutions usually rely on functions that need a proper tuning. The proposed control scheme is tested to work on a real robot to avoid not only static but also dynamic obstacles without the need of any empirical tuning. The method is tested also under physical human robot interaction (pHRI) showing smooth behaviour of the robot despite of external forces.",
        "primary_area": "",
        "author": "Juan D. Mu\u00f1oz Osorio;Abdelrahman Abdelazim;Felix Allmendinger;Uwe E. Zimmermann;Juan D. Mu\u00f1oz Osorio;Abdelrahman Abdelazim;Felix Allmendinger;Uwe E. Zimmermann",
        "authorids": "/37087470379;/38305375000;/37087472275;/38180258500;/37087470379;/38305375000;/37087472275;/38180258500",
        "aff": "institute of mechatronic systems (IMES), Leibniz University of Hannover, Hannover, Germany; corporate research of KUKA Germany GmbH, Augsburg, Germany; corporate research of KUKA Germany GmbH, Augsburg, Germany; corporate research of KUKA Germany GmbH, Augsburg, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341241/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15496952606170890694&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "Leibniz University of Hannover;KUKA Germany GmbH",
        "aff_unique_dep": "Institute of Mechatronic Systems;corporate research",
        "aff_unique_url": "https://www.imes.uni-hannover.de;https://www.kuka.com",
        "aff_unique_abbr": "IMES;KUKA",
        "aff_campus_unique_index": "0;1;1;1",
        "aff_campus_unique": "Hannover;Augsburg",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9341024",
        "title": "Unsupervised Depth and Confidence Prediction from Monocular Images using Bayesian Inference",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose an unsupervised deep learning framework with Bayesian inference for improving the accuracy of per-pixel depth prediction from monocular RGB images. The proposed framework predicts confidence map along with depth and pose information for a given input image. The depth hypotheses from previous frames are propagated forward and fused with the depth hypothesis of the current frame by using Bayesian inference mechanism. The ground truth information required for training the confidence map prediction is constructed using image reconstruction loss thereby obviating the need for explicit ground truth depth information used in supervised methods. The resulting unsupervised framework is shown to outperform the existing state-of-the-art methods for depth prediction on the publicly available KITTI outdoor dataset. The usefulness of the proposed framework is further established by demonstrating a real-world robotic pick-and-place application where the pose of the robot end-effector is computed using the depth predicted from an eye-in-hand monocular camera. The design choices made for the proposed framework is justified through extensive ablation studies.",
        "primary_area": "",
        "author": "Vishal Bhutani;Madhu Vankadari;Omprakash Jha;Anima Majumder;Swagat Kumar;Samrat Dutta;Vishal Bhutani;Madhu Vankadari;Omprakash Jha;Anima Majumder;Swagat Kumar;Samrat Dutta",
        "authorids": "/37088688259;/37086448149;/37088686122;/38068641200;/37535549500;/37085369267;/37088688259;/37086448149;/37088686122;/38068641200;/37535549500;/37085369267",
        "aff": "TATA Consultancy Services, India; TATA Consultancy Services, India; TATA Consultancy Services, India; TATA Consultancy Services, India; Edge Hill University, UK; TATA Consultancy Services, India",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341024/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3092027414582894619&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;0",
        "aff_unique_norm": "TATA Consultancy Services;Edge Hill University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.tcs.com;https://www.edgehill.ac.uk",
        "aff_unique_abbr": "TCS;EHU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;1;0",
        "aff_country_unique": "India;United Kingdom"
    },
    {
        "id": "9341277",
        "title": "Unsupervised Domain Adaptation for Transferring Plant Classification Systems to New Field Environments, Crops, and Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Crops are an important source of food and other products. In conventional farming, tractors apply large amounts of agrochemicals uniformly across fields for weed control and plant protection. Autonomous farming robots have the potential to provide environment-friendly weed control on a per plant basis. A system that reliably distinguishes crops, weeds, and soil under varying environment conditions is the basis for plant-specific interventions such as spot applications. Such semantic segmentation systems, however, often show a performance decay when applied under new field conditions. In this paper, we therefore propose an effective approach to unsupervised domain adaptation for plant segmentation systems in agriculture and thus to adapt existing systems to new environments, different value crops, and other farm robots. Our system yields a high segmentation performance in the target domain by exploiting labels only from the source domain. It is based on CycleGANs and enforces a semantic consistency domain transfer by constraining the images to be pixel-wise classified in the same way before and after translation. We perform an extensive evaluation, which indicates that we can substantially improve the transfer of our semantic segmentation system to new field environments, different crops, and different sensors or robots.",
        "primary_area": "",
        "author": "Dario Gogoll;Philipp Lottes;Jan Weyler;Nik Petrinic;Cyrill Stachniss;Dario Gogoll;Philipp Lottes;Jan Weyler;Nik Petrinic;Cyrill Stachniss",
        "authorids": "/37088686846;/37085797781;/37088687551;/37088688290;/37329668600;/37088686846;/37085797781;/37088687551;/37088688290;/37329668600",
        "aff": "University of Bonn, Germany; Pheno-Inspect GmbH, Germany; University of Bonn, Germany; University of Oxford, UK; Pheno-Inspect GmbH, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341277/",
        "gs_citation": 40,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8759402954063391341&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;2;1",
        "aff_unique_norm": "University of Bonn;Pheno-Inspect GmbH;University of Oxford",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.uni-bonn.de;;https://www.ox.ac.uk",
        "aff_unique_abbr": "UBonn;;Oxford",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "Germany;United Kingdom"
    },
    {
        "id": "9341224",
        "title": "Unsupervised Learning of Dense Optical Flow, Depth and Egomotion with Event-Based Sensors",
        "track": "main",
        "status": "Poster",
        "abstract": "We present an unsupervised learning pipeline for dense depth, optical flow and egomotion estimation for autonomous driving applications, using the event-based output of the Dynamic Vision Sensor (DVS) as input. The backbone of our pipeline is a bioinspired encoder-decoder neural network architecture - ECN. To train the pipeline, we introduce a covariance normalization technique which resembles the lateral inhibition mechanism found in animal neural systems.Our work is the first monocular pipeline that generates dense depth and optical flow from sparse event data only, and is able to transfer from day to night scenes without any additional training. The network works in self-supervised mode and has just 150k parameters. We evaluate our pipeline on the MVSEC self driving dataset and present results for depth, optical flow and and egomotion estimation. Thanks to the efficient design, we are able to achieve inference rates of 300 FPS on a single Nvidia 1080Ti GPU. Our experiments demonstrate significant improvements upon works that used deep learning on event data, as well as the ability to perform well during both day and night.",
        "primary_area": "",
        "author": "Chengxi Ye;Anton Mitrokhin;Cornelia Ferm\u00fcller;James A. Yorke;Yiannis Aloimonos;Chengxi Ye;Anton Mitrokhin;Cornelia Ferm\u00fcller;James A. Yorke;Yiannis Aloimonos",
        "authorids": "/37086125021;/37086581371;/37269887600;/37088686952;/37282631400;/37086125021;/37086581371;/37269887600;/37088686952;/37282631400",
        "aff": "University of Maryland Institute for Advanced Computer Studies, College Park, MD, USA; University of Maryland Institute for Advanced Computer Studies, College Park, MD, USA; University of Maryland Institute for Advanced Computer Studies, College Park, MD, USA; Institute for Physical Science and Technology, University of Maryland, College Park, MD, USA; University of Maryland Institute for Advanced Computer Studies, College Park, MD, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341224/",
        "gs_citation": 73,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4742626574956806315&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Maryland",
        "aff_unique_dep": "Institute for Advanced Computer Studies",
        "aff_unique_url": "https://www/umd.edu",
        "aff_unique_abbr": "UMD",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "College Park",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341634",
        "title": "Using Diverse Neural Networks for Safer Human Pose Estimation: Towards Making Neural Networks Know When They Don\u2019t Know",
        "track": "main",
        "status": "Poster",
        "abstract": "In recent years, human pose estimation has seen great improvements by the use of neural networks. However, these approaches are unsuitable for safety-critical applications such as human-robot interaction (HRI), as no guarantees are given whether a produced detection is correct or not and false detections with high confidence scores are produced on a regular basis. In this work, we propose a method to identify and eliminate false detections by comparing keypoint detections from different neural networks and assigning a 'Don't know' label in the case of a mismatch. Our approach is driven by the principle of software diversity, a technique recommended by the safety standard IEC 61508-7 [1] for dealing with software implementation faults. We evaluate our general concept on the MPII human pose dataset [2] using available ground truth data to calculate a suitable threshold for our keypoint comparison, reducing the number of false detections by approx. 61%. For the application at runtime, where no ground truth data is available, we introduce a method to calculate the needed threshold directly from keypoint detections. In further experiments, it was possible to reduce the number of false detections by approx. 75%. Eliminating keypoints by comparison also lowers the correct detection rate, which we maintained above 75% in all experiments. As this effect is limited and non-critical regarding safety we believe that the proposed approach can lead the way to a safe use of neural networks for human pose estimation in the future.",
        "primary_area": "",
        "author": "Patrick Schlosser;Christoph Ledermann;Patrick Schlosser;Christoph Ledermann",
        "authorids": "/37088366421;/38468554800;/37088366421;/38468554800",
        "aff": "Intelligent Process Automation and Robotics Lab, Institute of Anthropomatics and Robotics (IAR-IPR), Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany; Intelligent Process Automation and Robotics Lab, Institute of Anthropomatics and Robotics (IAR-IPR), Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341634/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3515112049357846334&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Karlsruhe Institute of Technology",
        "aff_unique_dep": "Institute of Anthropomatics and Robotics",
        "aff_unique_url": "https://www.kit.edu",
        "aff_unique_abbr": "KIT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Karlsruhe",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9341016",
        "title": "Using Machine Learning for Material Detection with Capacitive Proximity Sensors",
        "track": "main",
        "status": "Poster",
        "abstract": "The ability of detecting materials plays an important role in robotic applications. The robot can incorporate the information from contactless material detection and adapt its behavior in how it grasps an object or how it walks on specific surfaces. In this, paper we apply machine learning on impedance spectra from capacitive proximity sensors for material detection. The unique spectra of certain materials only differ slightly and are subject to noise and scaling effects during each measurement. A best-fit classification approach to pre-recorded data is therefore inaccurate. We perform classification on ten different materials and evaluate different classification algorithms ranging from simple k-NN approaches to artificial neural networks, which are able to extract the material specific information from the impedance spectra.",
        "primary_area": "",
        "author": "Yitao Ding;Hannes Kisner;Tianlin Kong;Ulrike Thomas;Yitao Ding;Hannes Kisner;Tianlin Kong;Ulrike Thomas",
        "authorids": "/37086576023;/37086336499;/37088686176;/37281523200;/37086576023;/37086336499;/37088686176;/37281523200",
        "aff": "Lab of Robotics and Human-Machine Interaction, Chemnitz University of Technology, Chemnitz, Germany; Lab of Robotics and Human-Machine Interaction, Chemnitz University of Technology, Chemnitz, Germany; Lab of Robotics and Human-Machine Interaction, Chemnitz University of Technology, Chemnitz, Germany; Lab of Robotics and Human-Machine Interaction, Chemnitz University of Technology, Chemnitz, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341016/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10617686446998800731&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Chemnitz University of Technology",
        "aff_unique_dep": "Lab of Robotics and Human-Machine Interaction",
        "aff_unique_url": "https://www.tu-chemnitz.de",
        "aff_unique_abbr": "TUC",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Chemnitz",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9341280",
        "title": "Utilizing Sacrificial Molding for Embedding Motion Controlling Endostructures in Soft Pneumatic Actuators",
        "track": "main",
        "status": "Poster",
        "abstract": "The field of soft robotics has evolved as a domain for developing light, compliant and safe actuators. However, one of the challenges in the field is the lack of repeatable fabrication techniques as well as customizability that restricts the application of soft robots. We present a fabrication technique using sacrificial molding to fabricate pneumatic channels that are repeatable and less prone to variability. This technique enables the monolithic fabrication of actuators which eliminates conventional failure modes such as delamination. We then use embedded endostructures manufactured using Fused Deposition Modelling (FDM) 3D printers to customize the behavior of bending actuator by altering local mechanical characteristics. Finite element analysis (FEA) was used as a tool to tune the choice of materials and the geometry of the 3D printed layers based on the required application. We analyze the effect of the mechanical properties of the endostructures on actuator behavior and its utility in improving customizability. We analyzed the behavior of actuators with a variety of endostructures using visual markers. As predicted by the FEA and Euler-Bernoulli beam theory, the behavior of the actuators was seen to be influenced by the mechanical properties of the endostucture. Thus, we present a new methodology for tuning the mechanical properties of Soft Pneumatic Actuators (SPAs), which is simple and efficient to predict as well as easy to execute.",
        "primary_area": "",
        "author": "Ajinkya Bhat;Raye Chen-Hua Yeow;Ajinkya Bhat;Raye Chen-Hua Yeow",
        "authorids": "/37088689557;/37085409153;/37088689557;/37085409153",
        "aff": "NUS Graduate School for Integrative Sciences and Engineering, National University of Singapore, Singapore; Department of Biomedical Engineering, National University of Singapore, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341280/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14532368736325290797&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "National University of Singapore",
        "aff_unique_dep": "Graduate School for Integrative Sciences and Engineering",
        "aff_unique_url": "https://www.nus.edu.sg",
        "aff_unique_abbr": "NUS",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Singapore;",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "9341338",
        "title": "Vacuum Driven Auxetic Switching Structure and Its Application on a Gripper and Quadruped",
        "track": "main",
        "status": "Poster",
        "abstract": "The properties and applications of auxetics have been widely explored in the past years. Through proper utilization of auxetic structures, designs with unprecedented mechanical and structural behaviors can be produced. Taking advantage of this, we present the development of novel and low-cost 3D structures inspired by a simple auxetic unit. The core part, which we call the body in this paper, is a 3D realization of 2D rotating squares. This body structure was formed by joining four similar structures through softer material at the vertices. A monolithic structure of this kind is accomplished through a custom-built multi-material 3D printer. The model works in a way that, when torque is applied along the face of the rotational squares, they tend to bend at the vertex of the softer material, and due to the connected-ness of the design, a proper opening and closing motion is achieved. To demonstrate the potential of this part as an important component for robots, two applications are presented: a soft gripper and a crawling robot. Vacuum-driven actuators move both the applications. The proposed gripper combines the benefits of two types of grippers whose fingers are placed parallel and equally spaced to each other, in a single design. This gripper is adaptable to the size of the object and can grasp objects with large and small cross- sections alike. A novel bending actuator, which is made of soft material and bends in curvature when vacuumed, provides the grasping nature of the gripper. Crawling robots, in addition to their versatile nature, provide a better interaction with humans. The designed crawling robot employs negative pressure-driven actuators to highlight linear and turning locomotion.",
        "primary_area": "",
        "author": "Shuai Liu;Sheeraz Athar;Michael Yu Wang;Shuai Liu;Sheeraz Athar;Michael Yu Wang",
        "authorids": "/37088481142;/37088686342;/37280913900;/37088481142;/37088686342;/37280913900",
        "aff": "Department of Mechanical and Aerospace Engineering, The Hong Kong University of Science and Technology; Department of Mechanical and Aerospace Engineering, The Hong Kong University of Science and Technology; Department of Mechanical and Aerospace Engineering, The Hong Kong University of Science and Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341338/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9935355102340491589&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "The Hong Kong University of Science and Technology",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.ust.hk",
        "aff_unique_abbr": "HKUST",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Hong Kong SAR",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9341484",
        "title": "Variable In-Hand Manipulations for Tactile-Driven Robot Hand via CNN-LSTM",
        "track": "main",
        "status": "Poster",
        "abstract": "Performing various in-hand manipulation tasks, without learning each individual task, would enable robots to act more versatile, while reducing the effort for training. However, in general it is difficult to achieve stable in-hand manipulation, because the contact state between the fingertips becomes difficult to model, especially for a robot hand with anthropomorphically shaped fingertips. Rich tactile feedback can aid the robust task execution, but on the other hand it is challenging to process high-dimensional tactile information. In the current paper we use two fingers of the Allegro hand, and each fingertip is anthropomorphically shaped and equipped not only with 6-axis force-torque (F/T) sensors, but also with uSkin tactile sensors, which provide 24 tri-axial measurements per fingertip. A convolutional neural network is used to process the high dimensional uSkin information, and a long short-term memory (LSTM) handles the time-series information. The network is trained to generate two different motions (\"twist\" and \"push\"). The desired motion is provided as a task-parameter to the network, with twist defined as -1 and push as +1. When values between -1 and +1 are used as the task parameter, the network is able to generate untrained motions in-between the two trained motions. Thereby, we can achieve multiple untrained manipulations, and can achieve robustness with high-dimensional tactile feedback.",
        "primary_area": "",
        "author": "Satoshi Funabashi;Shun Ogasa;Tomoki Isobe;Tetsuya Ogata;Alexander Schmitz;Tito Pradhono Tomo;Shigeki Sugano;Satoshi Funabashi;Shun Ogasa;Tomoki Isobe;Tetsuya Ogata;Alexander Schmitz;Tito Pradhono Tomo;Shigeki Sugano",
        "authorids": "/37085727304;/37086166387;/37088691309;/37273829100;/37587110100;/37085618711;/37274050800;/37085727304;/37086166387;/37088691309;/37273829100;/37587110100;/37085618711;/37274050800",
        "aff": "Dept. of Modern Mechanical Engineering, Faculty of Science and Engineering, Waseda University, Tokyo, Japan; Dept. of Modern Mechanical Engineering, Faculty of Science and Engineering, Waseda University, Tokyo, Japan; Dept. of Modern Mechanical Engineering, Faculty of Science and Engineering, Waseda University, Tokyo, Japan; Dept. of Intermedia Art and Science, Faculty of Science and Engineering, Waseda University, Tokyo, Japan; Dept. of Modern Mechanical Engineering, Faculty of Science and Engineering, Waseda University, Tokyo, Japan; Dept. of Modern Mechanical Engineering, Faculty of Science and Engineering, Waseda University, Tokyo, Japan; Dept. of Modern Mechanical Engineering, Faculty of Science and Engineering, Waseda University, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341484/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2184492546418698110&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Waseda University",
        "aff_unique_dep": "Dept. of Modern Mechanical Engineering",
        "aff_unique_url": "https://www.waseda.jp/top",
        "aff_unique_abbr": "Waseda",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9341759",
        "title": "Variable Pitch System for the Underwater Explorer Robot UX-1",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents the results of the experimental tests performed to validate the functionality of a variable pitch system (VPS), designed for pitch attitude control of the novel underwater robotic vehicle explorer UX-1. The VPS is composed of a mass suspended from a central rod mounted across the hull. This mass is rotated around the transverse axis of the vehicle in order to perform a change in the inclination angle for navigation in vertical mine shafts. In this work, the equations of motion are first derived with a quaternion attitude representation, and are then extended to include the dynamics of the VPS. The performance of the VPS is demonstrated in real underwater experimental tests that validate the pitch angle control independently, and coupled with the heave motion control system.",
        "primary_area": "",
        "author": "Ramon A. Suarez Fernandez;Davide Grande;Luca Bascetta;Alfredo Martins;Sergio Dominguez;Claudio Rossi;Ramon A. Suarez Fernandez;Davide Grande;Luca Bascetta;Alfredo Martins;Sergio Dominguez;Claudio Rossi",
        "authorids": "/37086582191;/37086589348;/37640075100;/37553027800;/37567710800;/37573908500;/37086582191;/37086589348;/37640075100;/37553027800;/37567710800;/37573908500",
        "aff": "Center for Automation and Robotics, Universidad Polit\u00e9cnica de Madrid, Madrid, Spain; Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milan, Italy; Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milan, Italy; INESC-TEC, Instituto Superior de Engenharia do Porto, Portugal; Center for Automation and Robotics, Universidad Polit\u00e9cnica de Madrid, Madrid, Spain; Center for Automation and Robotics, Universidad Polit\u00e9cnica de Madrid, Madrid, Spain",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341759/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12230173272316659051&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;2;0;0",
        "aff_unique_norm": "Universidad Polit\u00e9cnica de Madrid;Politecnico di Milano;INESC-TEC",
        "aff_unique_dep": "Center for Automation and Robotics;Dipartimento di Elettronica, Informazione e Bioingegneria;Instituto Superior de Engenharia do Porto",
        "aff_unique_url": "https://www.upm.es;https://www.polimi.it;",
        "aff_unique_abbr": "UPM;Politecnico di Milano;",
        "aff_campus_unique_index": "0;1;1;0;0",
        "aff_campus_unique": "Madrid;Milan;",
        "aff_country_unique_index": "0;1;1;2;0;0",
        "aff_country_unique": "Spain;Italy;Portugal"
    },
    {
        "id": "9340895",
        "title": "Variable Stiffness Control with Strict Frequency Domain Constraints for Physical Human-Robot Interaction",
        "track": "main",
        "status": "Poster",
        "abstract": "Variable impedance control is advantageous for physical human-robot interaction to improve safety, adaptability and many other aspects. This paper presents a gain-scheduled variable stiffness control approach under strict frequency-domain constraints. Firstly, to reduce conservativeness, we characterize and constrain the impedance rendering, actuator saturation, disturbance/noise rejection and passivity requirements into their specific frequency bands. This relaxation makes sense because of the restricted frequency properties of the interactive robots. Secondly, a gain-scheduled method is taken to regulate the controller gains with respect to the desired stiffness. Thirdly, the scheduling function is parameterized via a nonsmooth optimization method. Finally, the proposed approach is validated by simulations, experiments and comparisons with a gain-fixed passivity-based PID method.",
        "primary_area": "",
        "author": "Wulin Zou;Pu Duan;Yawen Chen;Ningbo Yu;Ling Shi;Wulin Zou;Pu Duan;Yawen Chen;Ningbo Yu;Ling Shi",
        "authorids": "/37086069004;/37088688658;/37087051368;/37085356485;/37287511800;/37086069004;/37088688658;/37087051368;/37085356485;/37287511800",
        "aff": "Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong, China; Xeno Dynamics Co., Ltd, Shenzhen, China; Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong, China; Institute of Robotics and Automatic Information Systems, and Tianjin Key Laboratory of Intelligent Robotics, Nankai University, Tianjin, China; Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340895/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5213530294572976093&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;2;0",
        "aff_unique_norm": "Hong Kong University of Science and Technology;Xeno Dynamics Co., Ltd;Nankai University",
        "aff_unique_dep": "Department of Electronic and Computer Engineering;;Institute of Robotics and Automatic Information Systems",
        "aff_unique_url": "https://www.ust.hk;;http://www.nankai.edu.cn",
        "aff_unique_abbr": "HKUST;;NKU",
        "aff_campus_unique_index": "0;0;2;0",
        "aff_campus_unique": "Hong Kong;;Tianjin",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9341404",
        "title": "Variational Filtering with Copula Models for SLAM",
        "track": "main",
        "status": "Poster",
        "abstract": "The ability to infer map variables and estimate pose is crucial to the operation of autonomous mobile robots. In most cases the shared dependency between these variables is modeled through a multivariate Gaussian distribution, but there are many situations where that assumption is unrealistic. Our paper shows how it is possible to relax this assumption and perform simultaneous localization and mapping (SLAM) with a larger class of distributions, whose multivariate dependency is represented with a copula model. We integrate the distribution model with copulas into a Sequential Monte Carlo estimator and show how unknown model parameters can be learned through gradient-based optimization. We demonstrate our approach is effective in settings where Gaussian assumptions are clearly violated, such as environments with uncertain data association and nonlinear transition models.",
        "primary_area": "",
        "author": "John D. Martin;Kevin Doherty;Caralyn Cyr;Brendan Englot;John Leonard;John D. Martin;Kevin Doherty;Caralyn Cyr;Brendan Englot;John Leonard",
        "authorids": "/37088688605;/37085769742;/37086942417;/37601539900;/37329387400;/37088688605;/37085769742;/37086942417;/37601539900;/37329387400",
        "aff": "Stevens Institute of Technology; Massachusetts Institute of Technology; Stevens Institute of Technology; Stevens Institute of Technology; Massachusetts Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341404/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3835135138007550646&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;1",
        "aff_unique_norm": "Stevens Institute of Technology;Massachusetts Institute of Technology",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.stevens.edu;https://web.mit.edu",
        "aff_unique_abbr": "SIT;MIT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341569",
        "title": "Velocity Regulation of 3D Bipedal Walking Robots with Uncertain Dynamics Through Adaptive Neural Network Controller",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a neural-network based adaptive feedback control structure to regulate the velocity of 3D bipedal robots under dynamics uncertainties. Existing Hybrid Zero Dynamics (HZD)-based controllers regulate velocity through the implementation of heuristic regulators that do not consider model and environmental uncertainties, which may significantly affect the tracking performance of the controllers. In this paper, we address the uncertainties in the robot dynamics from the perspective of the reduced dimensional representation of virtual constraints and propose the integration of an adaptive neural network-based controller to regulate the robot velocity in the presence of model parameter uncertainties. The proposed approach yields improved tracking performance under dynamics uncertainties. The shallow adaptive neural network used in this paper does not require training a priori and has the potential to be implemented on the real-time robotic controller. A comparative simulation study of a 3D Cassie robot is presented to illustrate the performance of the proposed approach under various scenarios.",
        "primary_area": "",
        "author": "Guillermo A. Castillo;Bowen Weng;Terrence C. Stewart;Wei Zhang;Ayonga Hereid;Guillermo A. Castillo;Bowen Weng;Terrence C. Stewart;Wei Zhang;Ayonga Hereid",
        "authorids": "/37086936437;/37086936098;/38466979000;/37089656248;/37077055000;/37086936437;/37086936098;/38466979000;/37089656248;/37077055000",
        "aff": "Electrical and Computer Engineering, Ohio State University, Columbus, OH, USA; Electrical and Computer Engineering, Ohio State University, Columbus, OH, USA; National Research Council of Canada, University of Waterloo Collaboration Centre, Waterloo, ON, Canada; SUSTech Institute of Robotics, Southern University of Science and Technology (SUSTech), China; Mechanical and Aerospace Engineering, Ohio State University, Columbus, OH, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341569/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3300299442170021216&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;2;0",
        "aff_unique_norm": "Ohio State University;National Research Council of Canada;Southern University of Science and Technology",
        "aff_unique_dep": "Electrical and Computer Engineering;;Institute of Robotics",
        "aff_unique_url": "https://www.osu.edu;https://www.nrc-cnrc.gc.ca;https://www.sustech.edu.cn",
        "aff_unique_abbr": "OSU;NRC-CNRC;SUSTech",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Columbus;",
        "aff_country_unique_index": "0;0;1;2;0",
        "aff_country_unique": "United States;Canada;China"
    },
    {
        "id": "9341085",
        "title": "Verification of system-wide safety properties of ROS applications",
        "track": "main",
        "status": "Poster",
        "abstract": "Robots are currently deployed in safety-critical domains but proper techniques to assess the functional safety of their software are yet to be adopted. This is particularly critical in ROS, where highly configurable robots are built by composing third-party modules. To promote adoption, we advocate the use of lightweight formal methods, automatic techniques with minimal user input and intuitive feedback. This paper proposes a technique to automatically verify system-wide safety properties of ROS-based applications at static time. It is based in the formalization of ROS architectural models and node behaviour in Electrum, over which system-wide specifications are subsequently model checked. To automate the analysis, it is deployed as a plug-in for HAROS, a framework for the assessment of ROS software quality aimed at the ROS community. The technique is evaluated in a real robot, AgRob V16, with positive results.",
        "primary_area": "",
        "author": "Renato Carvalho;Alcino Cunha;Nuno Macedo;Andr\u00e9 Santos;Renato Carvalho;Alcino Cunha;Nuno Macedo;Andr\u00e9 Santos",
        "authorids": "/37088687511;/37678890600;/37086079618;/37086118726;/37088687511;/37678890600;/37086079618;/37086118726",
        "aff": "Universidade do Minho and INESC TEC, Portugal; Universidade do Minho and INESC TEC, Portugal; Universidade do Minho and INESC TEC, Portugal; Universidade do Minho and INESC TEC, Portugal",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341085/",
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=686338893710537631&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 15,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Universidade do Minho",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.uminho.pt",
        "aff_unique_abbr": "UMinho",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Portugal"
    },
    {
        "id": "9341264",
        "title": "Versatile 3D Multi-Sensor Fusion for Lightweight 2D Localization",
        "track": "main",
        "status": "Poster",
        "abstract": "Aiming for a lightweight and robust localization solution for low-cost, low-power autonomous robot platforms, such as educational or industrial ground vehicles, under challenging conditions (e.g., poor sensor calibration, low lighting and dynamic objects), we propose a two-stage localization system which incorporates both offline prior map building and online multi-modal localization. In particular, we develop an occupancy grid mapping system with probabilistic odometry fusion, accurate scan-to-submap covariance modeling, and accelerated loop-closure detection, which is further aided by 2D line features that exploit the environmental structural constraints. We then develop a versatile EKF-based online localization system which optimally (up to linearization) fuses multi-modal information provided by the pre-built occupancy grid map, IMU, odometry, and 2D LiDAR measurements with low computational requirements. Importantly, spatiotemporal calibration between these sensors are also estimated online to account for poor initial calibration and make the system more \"plug-and-play\", which improves both the accuracy and flexibility of the proposed multi-sensor fusion framework. In our experiments, our mapping system is shown to be more accurate than the state-of-the-art Google Cartographer. Then, extensive Monte-Carlo simulations are performed to verify both accuracy, consistency and efficiency of the proposed map-based localization system with full spatiotemporal calibration. We also validate the complete system (prior map building and online localization) with building-scale real-world datasets.",
        "primary_area": "",
        "author": "Patrick Geneva;Nathaniel Merrill;Yulin Yang;Chuchu Chen;Woosik Lee;Guoquan Huang;Patrick Geneva;Nathaniel Merrill;Yulin Yang;Chuchu Chen;Woosik Lee;Guoquan Huang",
        "authorids": "/37086125563;/37087322112;/37085990232;/37088486425;/37087323297;/37077670600;/37086125563;/37087322112;/37085990232;/37088486425;/37087323297;/37077670600",
        "aff": "Robot Perception and Navigation Group (RPNG), University of Delaware, Newark, DE, USA; Robot Perception and Navigation Group (RPNG), University of Delaware, Newark, DE, USA; Robot Perception and Navigation Group (RPNG), University of Delaware, Newark, DE, USA; Robot Perception and Navigation Group (RPNG), University of Delaware, Newark, DE, USA; Robot Perception and Navigation Group (RPNG), University of Delaware, Newark, DE, USA; Robot Perception and Navigation Group (RPNG), University of Delaware, Newark, DE, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341264/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7214671013534551622&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of Delaware",
        "aff_unique_dep": "Robot Perception and Navigation Group",
        "aff_unique_url": "https://www.udel.edu",
        "aff_unique_abbr": "UD",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Newark",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341659",
        "title": "Video Depth Estimation by Fusing Flow-to-Depth Proposals",
        "track": "main",
        "status": "Poster",
        "abstract": "Depth from a monocular video can enable billions of devices and robots with a single camera to see the world in 3D. In this paper, we present a model for video depth estimation, which consists of a flow-to-depth layer, a camera pose refinement module, and a depth fusion network. Given optical flow and camera poses, our flow-to-depth layer generates depth proposals and their corresponding confidence maps by explicitly solving an epipolar geometry optimization problem. Our flow-to-depth layer is differentiable, and thus we can refine camera poses by maximizing the aggregated confidence in the camera pose refinement module. Our depth fusion network can utilize the target frame, depth proposals, and confidence maps inferred from different neighboring frames to produce the final depth map. Furthermore, the depth fusion network can additionally take the depth proposals generated by other methods to further improve the results. The experiments on three public datasets show that our approach outperforms state-of-the-art depth estimation methods, and has reasonable crossdataset generalization ability: our model trained on KITTI still performs well on the unseen Waymo dataset.",
        "primary_area": "",
        "author": "Jiaxin Xie;Chenyang Lei;Zhuwen Li;Li Erran Li;Qifeng Chen;Jiaxin Xie;Chenyang Lei;Zhuwen Li;Li Erran Li;Qifeng Chen",
        "authorids": "/37088457656;/37087231184;/37085416234;/37085853753;/37087230927;/37088457656;/37087231184;/37085416234;/37085853753;/37087230927",
        "aff": "Department of Computer Science and Engineering, HKUST; Department of Computer Science and Engineering, HKUST; Nuro Inc.; Alexa AI; Department of Computer Science and Engineering and the Department of Electronic and Computer Enginnering, HKUST",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341659/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1266312211504110780&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;2;0",
        "aff_unique_norm": "Hong Kong University of Science and Technology;Nuro Inc.;Alexa Internet",
        "aff_unique_dep": "Department of Computer Science and Engineering;;Alexa AI",
        "aff_unique_url": "https://www.hkust.edu.hk;https://www.nuro.ai;https://www.alexa.com",
        "aff_unique_abbr": "HKUST;Nuro;Alexa",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Hong Kong SAR;",
        "aff_country_unique_index": "0;0;1;1;0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9341344",
        "title": "Virtual Reality for Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper applies the principles of Virtual Reality (VR) to robots, rather than living organisms. A simulator, of either physical states or information states, renders outputs to custom displays that fool the robot's sensors. This enables a robot to experience a combination of real and virtual sensor inputs, combining the efficiency of simulation and the benefits of real world sensor inputs. Thus, the robot can be taken through targeted experiences that are more realistic than pure simulation, yet more feasible and controllable than pure real-world experiences. We define two distinctive methods for applying VR to robots, namely black box and white box; based on these methods we identify potential applications, such as testing and verification procedures that are better than simulation, the study of spoofing attacks and anti-spoofing techniques, and sample generation for machine learning. A general mathematical framework is presented, along with a simple experiment, detailed examples, and discussion of the implications.",
        "primary_area": "",
        "author": "Markku Suomalainen;Alexandra Q. Nilles;Steven M. LaValle;Markku Suomalainen;Alexandra Q. Nilles;Steven M. LaValle",
        "authorids": "/37086198609;/37086265273;/37280522300;/37086198609;/37086265273;/37280522300",
        "aff": "Faculty of Information Technology and Electrical Engineering, Center of Ubiquitous Computing, University of Oulu, Finland; Department of Computer Science, University of Illinois at Urbana-Champaign, Illinois, USA; Faculty of Information Technology and Electrical Engineering, Center of Ubiquitous Computing, University of Oulu, Finland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341344/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2860496947196427492&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 13,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Oulu;University of Illinois at Urbana-Champaign",
        "aff_unique_dep": "Faculty of Information Technology and Electrical Engineering;Department of Computer Science",
        "aff_unique_url": "https://www.oulu.fi;https://illinois.edu",
        "aff_unique_abbr": "UOulu;UIUC",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Urbana-Champaign",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Finland;United States"
    },
    {
        "id": "9341069",
        "title": "Vision Global Localization with Semantic Segmentation and Interest Feature Points",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we present a vision-only global localization architecture for autonomous vehicle applications, and achieves centimeter-level accuracy and high robustness in various scenarios. We first apply pixel-wise segmentation to the front-view mono camera and extract the semantic features, e.g. pole-like objects, lane markings, and curbs, which are robust to illumination, viewing angles and seasonal changes. For the scenes without enough semantic information, we extract interest feature points on static backgrounds, such as ground surface and buildings, assisted by our semantic segmentation. We create the visual global map with semantic feature map layers extracted from LiDAR point-cloud semantic map and the point feature map layer built with a fixed-pose SFM. A lumped Levenberg-Marquardt optimization solver is then applied to minimize the cost from two types of observations. We further evaluate the accuracy and robustness of our method with road tests on Alibaba's autonomous delivery vehicles in multiple scenarios as well as a KAIST urban dataset.",
        "primary_area": "",
        "author": "Kai Li;Xudong Zhang;Kun LI;Shuo Zhang;Kai Li;Xudong Zhang;Kun LI;Shuo Zhang",
        "authorids": "/37088687241;/37088687401;/37088996728;/37088691176;/37088687241;/37088687401;/37088996728;/37088691176",
        "aff": "Alibaba Group, UK Center, Hangzhou, China; Oppo Research Institute, Shanghai, China; Alibaba Group, UK Center, Hangzhou, China; Alibaba Group, UK Center, Hangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341069/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1660552368234803304&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Alibaba Group;Oppo Research Institute",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.alibaba.com;https://www.oppo.com",
        "aff_unique_abbr": "Alibaba;ORI",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Hangzhou;Shanghai",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9341631",
        "title": "Vision Only 3-D Shape Estimation for Autonomous Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a probabilistic framework for detailed 3-D shape estimation and tracking using only vision measurements. Vision detections are processed via a bird's eye view representation, creating accurate detections at far ranges. A probabilistic model of the vision based point cloud measurements is learned and used in the framework. A 3-D shape model is developed by fusing a set of point cloud detections via a recursive Best Linear Unbiased Estimator (BLUE). The point cloud fusion accounts for noisy and inaccurate measurements, as well as minimizing growth of points in the 3-D shape. The use of a tracking algorithm and sensor pose enables 3-D shape estimation of dynamic objects from a moving car. Results are analyzed on experimental data, demonstrating the ability of our approach to produce more accurate and cleaner shape estimates.",
        "primary_area": "",
        "author": "Josephine Monica;Mark Campbell;Josephine Monica;Mark Campbell",
        "authorids": "/37086939060;/37272971700;/37086939060;/37272971700",
        "aff": "School of Mechanical and Aerospace Engineering, Cornell University; School of Mechanical and Aerospace Engineering, Cornell University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341631/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7679013133334180298&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Cornell University",
        "aff_unique_dep": "School of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.cornell.edu",
        "aff_unique_abbr": "Cornell",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341619",
        "title": "Vision and force based autonomous coating with rollers",
        "track": "main",
        "status": "Poster",
        "abstract": "Coating rollers are widely popular in structural painting, in comparison with brushes and sprayers, due to thicker paint layer, better color consistency, and effortless customizability of holder frame and naps. In this paper, we introduce a cost-effective method to employ a general purpose robot (Sawyer, Rethink Robotics) for autonomous coating. To sense the position and the shape of the target object to be coated, the robot is combined with an RGB-Depth camera. The combined system autonomously recognizes the number of faces of the object as well as their position and surface normal. Unlike related work based on two-dimensional RGB-based image processing, all the analyses and algorithms here employ three-dimensional point cloud data (PCD). The object model learned from the PCD is then autonomously analyzed to achieve optimal motion planning to avoid collision between the robot arm and the object. To achieve human-level performance in terms of the quality of coating using the bare minimum ingredients, a combination of our own passive and builtin active impedance control is implemented. The former is realized by installing an ultrasonic sensor at the end-effector of robot working with a customized compliant mass-spring-damper roller to keep a precise distance between the end-effector and surface to be coated, maintaining a fixed force. Altogether, the control approach mimics human painting as evidenced by experimental measurements on the thickness of the coating. Coating on two different polyhedral objects is also demonstrated to test the overall method.",
        "primary_area": "",
        "author": "Yayun Du;Zhaoxing Deng;Zicheng Fang;Yunbo Wang;Taiki Nagata;Karan Bansal;Mohiuddin Quadir;Mohammad Khalid Jawed;Yayun Du;Zhaoxing Deng;Zicheng Fang;Yunbo Wang;Taiki Nagata;Karan Bansal;Mohiuddin Quadir;Mohammad Khalid Jawed",
        "authorids": "/37088689145;/37088690309;/37088687097;/37088689720;/37088688368;/37088689736;/37088690462;/37088686728;/37088689145;/37088690309;/37088687097;/37088689720;/37088688368;/37088689736;/37088690462;/37088686728",
        "aff": "Department of Mechanical & Aerospace Engineering, University of California, Los Angeles, Los Angeles, CA; Department of Mechanical & Aerospace Engineering, University of California, Los Angeles, Los Angeles, CA; Department of Mechanical & Aerospace Engineering, University of California, Los Angeles, Los Angeles, CA; Department of Mechanical & Aerospace Engineering, University of California, Los Angeles, Los Angeles, CA; Department of Mechanical & Aerospace Engineering, University of California, Los Angeles, Los Angeles, CA; Department of Coatings and Polymeric Materials, North Dakota State University, Fargo, ND; Department of Coatings and Polymeric Materials, North Dakota State University, Fargo, ND; Department of Mechanical & Aerospace Engineering, University of California, Los Angeles, Los Angeles, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341619/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6455347057471229219&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;1;1;0",
        "aff_unique_norm": "University of California, Los Angeles;North Dakota State University",
        "aff_unique_dep": "Department of Mechanical & Aerospace Engineering;Department of Coatings and Polymeric Materials",
        "aff_unique_url": "https://www.ucla.edu;https://www.ndsu.edu",
        "aff_unique_abbr": "UCLA;NDSU",
        "aff_campus_unique_index": "0;0;0;0;0;1;1;0",
        "aff_campus_unique": "Los Angeles;Fargo",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340728",
        "title": "Vision-Based Gesture Recognition in Human-Robot Teams Using Synthetic Data",
        "track": "main",
        "status": "Poster",
        "abstract": "Building successful collaboration between humans and robots requires efficient, effective, and natural communication. Here we study a RGB-based deep learning approach for controlling robots through gestures (e.g., \"follow me\"). To address the challenge of collecting high-quality annotated data from human subjects, synthetic data is considered for this domain. We contribute a dataset of gestures that includes real videos with human subjects and synthetic videos from our custom simulator. A solution is presented for gesture recognition based on the state-of-the-art I3D model. Comprehensive testing was conducted to optimize the parameters for this model. Finally, to gather insight on the value of synthetic data, several experiments are described that systematically study the properties of synthetic data (e.g., gesture variations, character variety, generalization to new gestures). We discuss practical implications for the design of effective human-robot collaboration and the usefulness of synthetic data for deep learning.",
        "primary_area": "",
        "author": "Celso M. de Melo;Brandon Rothrock;Prudhvi Gurram;Oytun Ulutan;B.S. Manjunath;Celso M. de Melo;Brandon Rothrock;Prudhvi Gurram;Oytun Ulutan;B.S. Manjunath",
        "authorids": "/37683411800;/37937642500;/37398980300;/37086375781;/37269184100;/37683411800;/37937642500;/37398980300;/37086375781;/37269184100",
        "aff": "CCDC US Army Research Laboratory, Playa Vista, CA, USA; NASA Jet Propulsion Laboratory, Pasadena, CA; CCDC US Army Research Laboratory, Playa Vista, CA, USA; Electrical Engineering Department, UC Santa Barbara, Santa Barbara, CA, USA; Electrical Engineering Department, UC Santa Barbara, Santa Barbara, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340728/",
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2448932502139302276&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;2;2",
        "aff_unique_norm": "US Army Research Laboratory;NASA Jet Propulsion Laboratory;University of California, Santa Barbara",
        "aff_unique_dep": "CCDC;;Electrical Engineering Department",
        "aff_unique_url": "https://www.arl.army.mil;https://www.jpl.nasa.gov;https://www.ucsb.edu",
        "aff_unique_abbr": "ARL;JPL;UCSB",
        "aff_campus_unique_index": "0;1;0;2;2",
        "aff_campus_unique": "Playa Vista;Pasadena;Santa Barbara",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341271",
        "title": "Vision-Based Proprioceptive Sensing: Tip Position Estimation for a Soft Inflatable Bellow Actuator",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a vision-based sensing approach for a soft linear actuator, which is equipped with an internal camera. The proposed vision-based sensing pipeline predicts the three-dimensional tip position of the actuator. To train and evaluate the algorithm, predictions are compared to ground truth data from an external motion capture system. An off-the-shelf distance sensor is integrated in a second actuator of the same type, providing only the vertical component of the tip position and used as a baseline for comparison. The camera-based sensing pipeline runs at 40 Hz in real-time on a standard laptop and is additionally used for closed loop elongation control of the actuator. It is shown that the approach can achieve comparable accuracy to the distance sensor for measuring the linear expansion of the actuator, but additionally provide the full three-dimensional tip position.",
        "primary_area": "",
        "author": "Peter Werner;Matthias Hofer;Carmelo Sferrazza;Raffaello D\u2019Andrea;Peter Werner;Matthias Hofer;Carmelo Sferrazza;Raffaello D\u2019Andrea",
        "authorids": "/37088686131;/37085792603;/37085991609;/38525077800;/37088686131;/37085792603;/37085991609;/38525077800",
        "aff": "Institute for Dynamic Systems and Control, ETH, Z\u00fcrich, Switzerland; Institute for Dynamic Systems and Control, ETH, Z\u00fcrich, Switzerland; Institute for Dynamic Systems and Control, ETH, Z\u00fcrich, Switzerland; Institute for Dynamic Systems and Control, ETH, Z\u00fcrich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341271/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1468389222515896300&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "ETH Z\u00fcrich",
        "aff_unique_dep": "Institute for Dynamic Systems and Control",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETH",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Z\u00fcrich",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9341174",
        "title": "Vision-based Belt Manipulation by Humanoid Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Deformable objects are very common around us in our daily life. Because they have infinitely many degrees of freedom, they present a challenging problem in robotics. Inspired by practical industrial applications, we present in this paper our research on using a humanoid robot to take a long, thin and flexible belt out of a bobbin and pick up the bending part of the belt from the ground. By proposing a novel non-prehensile manipulation strategy \"scraping\" which utilizes the friction between the gripper and the surface of the belt, efficient manipulation can be achieved. In addition, a 3D shape detection algorithm for deformable objects is used during manipulation process. By integrating the novel \"scraping\" motion and the shape detection algorithm into our multi-objective QP-based controller, we show experimentally humanoid robots can complete this complex task.",
        "primary_area": "",
        "author": "Yili Qin;Adrien Escande;Arnaud Tanguy;Eiichi Yoshida;Yili Qin;Adrien Escande;Arnaud Tanguy;Eiichi Yoshida",
        "authorids": "/37086819927;/37542914500;/37086000416;/37286468100;/37086819927;/37542914500;/37086000416;/37286468100",
        "aff": "Department of intelligent and mechanical interaction system, Graduate school of science and technology, University of Tsukuba, Tsukuba, Japan; CNRS-AIST JRL (Joint Robotics Laboratory), IRL, Tsukuba, Japan; CNRS-AIST JRL (Joint Robotics Laboratory), IRL, Tsukuba, Japan; Department of intelligent and mechanical interaction system, Graduate school of science and technology, University of Tsukuba, Tsukuba, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341174/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17411369680953998016&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "University of Tsukuba;CNRS-AIST Joint Robotics Laboratory",
        "aff_unique_dep": "Department of Intelligent and Mechanical Interaction System;Joint Robotics Laboratory",
        "aff_unique_url": "https://www.tsukuba.ac.jp;",
        "aff_unique_abbr": "UT;CNRS-AIST JRL",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Tsukuba",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9341485",
        "title": "Visual Monitoring and Servoing of a Cutting Blade during Telerobotic Satellite Servicing",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a system for visually monitoring and servoing the cutting of a multi-layer insulation (MLI) blanket that covers the envelope of satellites and spacecraft. The main contributions of this paper are: 1) to propose a model for relating visual features describing the engagement depth of the blade to the force exerted on the MLI blanket by the cutting tool, 2) a blade design and algorithm to reliably detect the engagement depth of the blade inside the MLI, and 3) a servoing mechanism to achieve the desired applied force by monitoring the engagement depth. We present results that validate these contributions by comparing forces estimated from visual feedback to measured forces at the blade. We also demonstrate the robustness of the blade design and vision processing under challenging conditions.",
        "primary_area": "",
        "author": "Amama Mahmood;Balazs P. Vagvolgyi;Will Pryor;Louis L. Whitcomb;Peter Kazanzides;Simon Leonard;Amama Mahmood;Balazs P. Vagvolgyi;Will Pryor;Louis L. Whitcomb;Peter Kazanzides;Simon Leonard",
        "authorids": "/37088691019;/37568674700;/37086104864;/37283591700;/37375173500;/37269567400;/37088691019;/37568674700;/37086104864;/37283591700;/37375173500;/37269567400",
        "aff": "Laboratory for Computational Sensing and Robotics (LCSR), Johns Hopkins University, Baltimore, USA; Laboratory for Computational Sensing and Robotics (LCSR), Johns Hopkins University, Baltimore, USA; Laboratory for Computational Sensing and Robotics (LCSR), Johns Hopkins University, Baltimore, USA; Laboratory for Computational Sensing and Robotics (LCSR), Johns Hopkins University, Baltimore, USA; Laboratory for Computational Sensing and Robotics (LCSR), Johns Hopkins University, Baltimore, USA; Laboratory for Computational Sensing and Robotics (LCSR), Johns Hopkins University, Baltimore, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341485/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10272983841481562728&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Johns Hopkins University",
        "aff_unique_dep": "Laboratory for Computational Sensing and Robotics",
        "aff_unique_url": "https://www.jhu.edu",
        "aff_unique_abbr": "JHU",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Baltimore",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341443",
        "title": "Visual Task Progress Estimation with Appearance Invariant Embeddings for Robot Control and Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "One of the challenges of full autonomy is to have robots capable of manipulating its current environment to achieve another environment configuration. This paper is a step towards this challenge, focusing on the visual understanding of the task. Our approach trains a deep neural network to represent images as measurable features that are useful to estimate the progress (or phase) of a task. The training uses numerous variations of images of identical tasks when taken under the same phase index. The goal is to make the network sensitive to differences in task progress but insensitive to the appearance of the images. To this end, our method builds upon Time-Contrastive Networks (TCNs) to train a network using only discrete snapshots taken at different stages of a task. A robot can then solve long-horizon tasks by using the trained network to identify the progress of the current task and by iteratively calling a motion planner until the task is solved. We quantify the granularity achieved by the network in two simulated environments. In the first, to detect the number of objects in a scene and in the second to measure the volume of particles in a cup. Our experiments leverage this granularity to make a mobile robot move a desired number of objects into a storage area and to control the amount of pouring in a cup.",
        "primary_area": "",
        "author": "Guilherme Maeda;Joni V\u00e4\u00e4t\u00e4inen;Hironori Yoshida;Guilherme Maeda;Joni V\u00e4\u00e4t\u00e4inen;Hironori Yoshida",
        "authorids": "/37085364007;/37088688337;/37088689273;/37085364007;/37088688337;/37088689273",
        "aff": "Preferred Networks Inc, Tokyo, Japan; Dept. of Modern Mechanical Engineering, Faculty of Science and Engineering, Waseda University, Tokyo, Japan; Preferred Networks Inc, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341443/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8855366483646776806&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Preferred Networks Inc;Waseda University",
        "aff_unique_dep": ";Dept. of Modern Mechanical Engineering",
        "aff_unique_url": "https://www.preferred-networks.com;https://www.waseda.jp/top",
        "aff_unique_abbr": ";Waseda",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9341161",
        "title": "Visual-Inertial-Wheel Odometry with Online Calibration",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we introduce a novel visual-inertial-wheel odometry (VIWO) system for ground vehicles, which efficiently fuses multi-modal visual, inertial and 2D wheel odometry measurements in a sliding-window filtering fashion. As multi-sensor fusion requires both intrinsic and extrinsic (spatiotemproal) calibration parameters which may vary over time during terrain navigation, we propose to perform VIWO along with online sensor calibration of wheel encoders' intrinsic and extrinsic parameters. To this end, we analytically derive the 2D wheel odometry measurement model from the raw wheel encoders' readings and optimally fuse this 2D relative motion information with 3D visual-inertial measurements. Additionally, an observability analysis is performed for the linearized VIWO system, which identifies five commonly-seen degenerate motions for wheel calibration parameters. The proposed system has been validated extensively in both Monte-Carlo simulations and real-world experiments in large-scale urban driving scenarios.",
        "primary_area": "",
        "author": "Woosik Lee;Kevin Eckenhoff;Yulin Yang;Patrick Geneva;Guoquan Huang;Woosik Lee;Kevin Eckenhoff;Yulin Yang;Patrick Geneva;Guoquan Huang",
        "authorids": "/37087323297;/37086115587;/37085990232;/37086125563;/37077670600;/37087323297;/37086115587;/37085990232;/37086125563;/37077670600",
        "aff": "Robot Perception and Navigation Group (RPNG), University of Delaware, Newark, DE, USA; Robot Perception and Navigation Group (RPNG), University of Delaware, Newark, DE, USA; Robot Perception and Navigation Group (RPNG), University of Delaware, Newark, DE, USA; Robot Perception and Navigation Group (RPNG), University of Delaware, Newark, DE, USA; Robot Perception and Navigation Group (RPNG), University of Delaware, Newark, DE, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341161/",
        "gs_citation": 71,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10718744313568627835&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Delaware",
        "aff_unique_dep": "Robot Perception and Navigation Group",
        "aff_unique_url": "https://www.udel.edu",
        "aff_unique_abbr": "UD",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Newark",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340964",
        "title": "Visualization of Intended Assistance for Acceptance of Shared Control",
        "track": "main",
        "status": "Poster",
        "abstract": "In shared control, advances in autonomous robotics are applied to help empower a human user in operating a robotic system. While these systems have been shown to improve efficiency and operation success, users are not always accepting of the new control paradigm produced by working with an assistive controller. This mismatch between performance and acceptance can prevent users from taking advantage of the benefits of shared control systems for robotic operation. To address this mismatch, we develop multiple types of visualizations for improving both the legibility and perceived predictability of assistive controllers, then conduct a user study to evaluate the impact that these visualizations have on user acceptance of shared control systems. Our results demonstrate that shared control visualizations must be designed carefully to be effective, with users requiring visualizations that improve both legibility and predictability of the assistive controller in order to voluntarily relinquish control.",
        "primary_area": "",
        "author": "Connor Brooks;Daniel Szafir;Connor Brooks;Daniel Szafir",
        "authorids": "/37086576242;/37086231248;/37086576242;/37086231248",
        "aff": "Department of Computer Science, University of Colorado Boulder; Department of Computer Science and ATLAS Institute, University of Colorado Boulder",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340964/",
        "gs_citation": 43,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10082317896595637403&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Colorado Boulder",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.colorado.edu",
        "aff_unique_abbr": "CU Boulder",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Boulder",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341545",
        "title": "Visuomotor Mechanical Search: Learning to Retrieve Target Objects in Clutter",
        "track": "main",
        "status": "Poster",
        "abstract": "When searching for objects in cluttered environments, it is often necessary to perform complex interactions in order to move occluding objects out of the way and fully reveal the object of interest and make it graspable. Due to the complexity of the physics involved and the lack of accurate models of the clutter, planning and controlling precise predefined interactions with accurate outcome is extremely hard, when not impossible. In problems where accurate (forward) models are lacking, Deep Reinforcement Learning (RL) has shown to be a viable solution to map observations (e.g. images) to good interactions in the form of close-loop visuomotor policies. However, Deep RL is sample inefficient and fails when applied directly to the problem of unoccluding objects based on images. In this work we present a novel Deep RL procedure that combines i) teacher-aided exploration, ii) a critic with privileged information, and iii) mid-level representations, resulting in sample efficient and effective learning for the problem of uncovering a target object occluded by a heap of unknown objects. Our experiments show that our approach trains faster and converges to more efficient uncovering solutions than baselines and ablations, and that our uncovering policies lead to an average improvement in the graspability of the target object, facilitating downstream retrieval applications.",
        "primary_area": "",
        "author": "Andrey Kurenkov;Joseph Taglic;Rohun Kulkarni;Marcus Dominguez-Kuhne;Animesh Garg;Roberto Mart\u00edn-Mart\u00edn;Silvio Savarese;Andrey Kurenkov;Joseph Taglic;Rohun Kulkarni;Marcus Dominguez-Kuhne;Animesh Garg;Roberto Mart\u00edn-Mart\u00edn;Silvio Savarese",
        "authorids": "/37085704818;/37088689687;/37088686070;/37088686805;/37086330576;/37085788640;/37298502600;/37085704818;/37088689687;/37088686070;/37088686805;/37086330576;/37085788640;/37298502600",
        "aff": "Stanford University; Stanford University; Stanford University; Caltech; Nvidia; Stanford University; Stanford University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341545/",
        "gs_citation": 51,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=879274534029831498&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;1;2;0;0",
        "aff_unique_norm": "Stanford University;California Institute of Technology;NVIDIA Corporation",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.stanford.edu;https://www.caltech.edu;https://www.nvidia.com",
        "aff_unique_abbr": "Stanford;Caltech;NVIDIA",
        "aff_campus_unique_index": "0;0;0;1;0;0",
        "aff_campus_unique": "Stanford;Pasadena;",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340992",
        "title": "Voxel-Based Representation Learning for Place Recognition Based on 3D Point Clouds",
        "track": "main",
        "status": "Poster",
        "abstract": "Place recognition is a critical component towards addressing the key problem of Simultaneous Localization and Mapping (SLAM). Most existing methods use visual images; whereas, place recognition using 3D point clouds, especially based on the voxel representations, has not been well addressed yet. In this paper, we introduce the novel approach of voxel-based representation learning (VBRL) that uses 3D point clouds to recognize places with long-term environment variations. VBRL splits a 3D point cloud input into voxels and uses multi-modal features extracted from these voxels to perform place recognition. Additionally, VBRL uses structured sparsity-inducing norms to learn representative voxels and feature modalities that are important to match places under long-term changes. Both place recognition, and voxel and feature learning are integrated into a unified regularized optimization formulation. As the sparsity-inducing norms are non-smooth, it is hard to solve the formulated optimization problem. Thus, we design a new iterative optimization algorithm, which has a theoretical convergence guarantee. Experimental results have shown that VBRL performs place recognition well using 3D point cloud data and is capable of learning the importance of voxels and feature modalities.",
        "primary_area": "",
        "author": "Sriram Siva;Zachary Nahman;Hao Zhang;Sriram Siva;Zachary Nahman;Hao Zhang",
        "authorids": "/37086453331;/37088689218;/37085545929;/37086453331;/37088689218;/37085545929",
        "aff": "Human-Centered Robotics Lab at Colorado School of Mines, Golden, CO; Human-Centered Robotics Lab at Colorado School of Mines, Golden, CO; Human-Centered Robotics Lab at Colorado School of Mines, Golden, CO",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340992/",
        "gs_citation": 35,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7878220174990302966&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Colorado School of Mines",
        "aff_unique_dep": "Human-Centered Robotics Lab",
        "aff_unique_url": "https://www.mines.edu",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Golden",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341118",
        "title": "Walking Human Trajectory Models and Their Application to Humanoid Robot Locomotion",
        "track": "main",
        "status": "Poster",
        "abstract": "In order to fluidly perform complex tasks in collaboration with a human being, such as table handling, a humanoid robot has to recognize and adapt to human movements. To achieve such goals, a realistic model of the human locomotion that is computable on a robot is needed. In this paper, we focus on making a humanoid robot follow a human-like locomotion path. We mainly present two models of human walking which lead to compute an average trajectory of the body center of mass from which a twist in the 2D plane can be deduced. Then the velocities generated by both models are used by a walking pattern generator to drive a real TALOS robot [1]. To determine which of these models is the most realistic for a humanoid robot, we measure human walking paths with motion capture and compare them to the computed trajectories.",
        "primary_area": "",
        "author": "I. Maroger;O. Stasse;B. Watier;I. Maroger;O. Stasse;B. Watier",
        "authorids": "/37088691323;/37295476000;/37086480591;/37088691323;/37295476000;/37086480591",
        "aff": "CNRS, UPS, France, LAAS-CNRS, Universit\u00e9 de Toulouse, Toulouse, France; CNRS, UPS, France, LAAS-CNRS, Universit\u00e9 de Toulouse, Toulouse, France; CNRS, UPS, France, LAAS-CNRS, Universit\u00e9 de Toulouse, Toulouse, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341118/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13585249745913205798&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "CNRS",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.cnrs.fr",
        "aff_unique_abbr": "CNRS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9340926",
        "title": "Walking on TacTip toes: A tactile sensing foot for walking robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Little research into tactile feet has been done for walking robots despite the benefits such feedback could give when walking on uneven terrain. This paper describes the development of a simple, robust and inexpensive tactile foot for legged robots based on a high-resolution biomimetic TacTip tactile sensor. Several design improvements were made to facilitate tactile sensing while walking, including the use of phosphorescent markers to remove the need for internal LED lighting. The usefulness of the foot is verified on a quadrupedal robot performing a beam walking task and it is found the sensor prevents the robot falling off the beam. Further, this capability also enables the robot to walk along the edge of a curved table. This tactile foot design can be easily modified for use with any legged robot, including much larger walking robots, enabling stable walking in challenging terrain.",
        "primary_area": "",
        "author": "Elizabeth A. Stone;Nathan F. Lepora;David A.W. Barton;Elizabeth A. Stone;Nathan F. Lepora;David A.W. Barton",
        "authorids": "/37088687837;/37399610200;/37086455530;/37088687837;/37399610200;/37086455530",
        "aff": "EPSRC Centre for Doctoral Training in Future Autonomous and Robotic Systems (FARSCOPE) at the Bristol Robotics Laboratory; Dept. of Engineering Maths and Bristol Robotics Laboratory, University of Bristol, UK; Dept. of Engineering Maths, University of Bristol, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340926/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14488464304712547212&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Bristol Robotics Laboratory;University of Bristol",
        "aff_unique_dep": "EPSRC Centre for Doctoral Training in Future Autonomous and Robotic Systems (FARSCOPE);Dept. of Engineering Maths and Bristol Robotics Laboratory",
        "aff_unique_url": "https://www.brl.ac.uk;https://www.bristol.ac.uk",
        "aff_unique_abbr": "BRL;UoB",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Bristol;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9341414",
        "title": "Waste Not, Want Not: Lessons in Rapid Quadrupedal Gait Termination from Thousands of Suboptimal Solutions",
        "track": "main",
        "status": "Poster",
        "abstract": "Elaborate trajectory optimization models with many degrees of freedom can be a useful locomotion-planning tool, as they provide rich solutions that take advantage of the robot's specific morphology. They are, however, prone to falling into local minima. Depending on the seed that initializes the solver, the trajectories themselves and the extent to which they minimize the cost function can vary widely, making it impossible to judge the quality of any solution without generating many more. In this paper, we argue that this perceived drawback can actually be a powerful advantage in exploratory studies, since the resulting set of diverse motions can reveal which features tend to be associated with good performance, and therefore aid in the formulation of strategies for executing challenging maneuvers. We selected rapid gait termination from a high-speed gallop as our case study - a dangerous and scarcely-researched movement. By analyzing a set of over 3000 monopedal and quadrupedal trajectories, we were able to extract conclusions about how braking and sliding should be performed to reduce the stopping distance, and identify a hindlimb action that creates large braking forces.",
        "primary_area": "",
        "author": "Stacey Shield;Amir Patel;Stacey Shield;Amir Patel",
        "authorids": "/37085618790;/38029333400;/37085618790;/38029333400",
        "aff": "Stacey Shield; Amir Patel",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341414/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6163245925418049056&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "",
        "aff_unique_norm": "",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "9340877",
        "title": "Water Based Magnification of Capacitive Proximity Sensors: Water Containers as Passive Human Detectors",
        "track": "main",
        "status": "Poster",
        "abstract": "Sensors that detect human presence received an increasing attention due to the recent advances in smart homes, collaborative fabrication cells, and human robot interaction. These sensors can be used in collaborative robot cells and mobile robots, in order to increase the robot awareness about the presence of humans, in order to increase safety during their operation. Among proximity detection systems, capacitive sensors are interesting, since they are low cost and simple human proximity detectors, however their detection range is limited. In this article, we show that the proximity detection range of a capacitive sensor can be enhanced, when the sensor is placed near a water container. In addition, the signal can pass trough several adjacent water containers, even if they are separated by a few centimeters. This phenomenon has an important implication in establishing low cost sensor networks. For instance, a limited number of active capacitive sensor nodes can be linked with several simple passive nodes, i.e. water containers, to detect human or animal proximity in a large area such as a farm, a factory or home. Analysis on the change of the maximum proximity range with sensor dimension, container size and liquid filler was performed in order to study this effect. Examples of application are also demonstrated.",
        "primary_area": "",
        "author": "Rui Pedro Rocha;Anibal T. de Almeida;Mahmoud Tavakoli;Rui Pedro Rocha;Anibal T. de Almeida;Mahmoud Tavakoli",
        "authorids": "/37408311600;/37276441900;/37642159700;/37408311600;/37276441900;/37642159700",
        "aff": "Institute of Systems and Robotics, University of Coimbra, Portugal; Institute of Systems and Robotics, University of Coimbra, Portugal; Institute of Systems and Robotics, University of Coimbra, Portugal",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340877/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:EFnW1hFDRYwJ:scholar.google.com/&scioq=Water+Based+Magnification+of+Capacitive+Proximity+Sensors:+Water+Containers+as+Passive+Human+Detectors&hl=en&as_sdt=0,5",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Coimbra",
        "aff_unique_dep": "Institute of Systems and Robotics",
        "aff_unique_url": "https://www.uc.pt",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Portugal"
    },
    {
        "id": "9340788",
        "title": "Weakly-Supervised Learning for Multimodal Human Activity Recognition in Human-Robot Collaboration Scenarios",
        "track": "main",
        "status": "Poster",
        "abstract": "The ability to synchronize expectations among human-robot teams and understand discrepancies between expectations and reality is essential for human-robot collaboration scenarios. To ensure this, human activities and intentions must be interpreted quickly and reliably by the robot using various modalities. In this paper we propose a multimodal recognition system designed to detect physical interactions as well as nonverbal gestures. Existing approaches feature high post-transfer recognition rates which, however, can only be achieved based on well-prepared and large datasets. Unfortunately, the acquisition and preparation of domain-specific samples especially in industrial context is time consuming and expensive. To reduce this effort we introduce a weakly-supervised classification approach. Therefore, we learn a latent representation of the human activities with a variational autoencoder network. Additional modalities and unlabeled samples are incorporated by a scalable product-of-expert sampling approach. The applicability in industrial context is evaluated by two domain-specific collaborative robot datasets. Our results demonstrate, that we can keep the number of labeled samples constant while increasing the network performance by providing additional unprocessed information.",
        "primary_area": "",
        "author": "Clemens Pohlt;Thomas Schlegl;Sven Wachsmuth;Clemens Pohlt;Thomas Schlegl;Sven Wachsmuth",
        "authorids": "/37085684388;/37444051300;/37329499300;/37085684388;/37444051300;/37329499300",
        "aff": "Regensburg Robotics Research Unit, OTH Regensburg, Regensburg, Germany; Regensburg Robotics Research Unit, OTH Regensburg, Regensburg, Germany; CITEC, Bielefeld University, Bielefeld, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340788/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17811203144838872094&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "OTH Regensburg;Bielefeld University",
        "aff_unique_dep": "Regensburg Robotics Research Unit;CITEC",
        "aff_unique_url": "https://www.oth-regensburg.de;https://www.uni-bielefeld.de",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Regensburg;Bielefeld",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9341095",
        "title": "Wet Adhesion of Micro-patterned Interfaces for Stable Grasping of Deformable Objects",
        "track": "main",
        "status": "Poster",
        "abstract": "Stable grip of wet, deformable objects is a challenging task for robotic grasping and manipulation, especially for food products' handling. The wet, slippery interfaces between the object and robotic fingers may require larger gripping force, resulting in higher risk of damaging the grasped object. This research aims to evaluate the role of micro-patterned soft pad on enhancement of wet adhesion in grasping a food sample in wet environment. We showcased this scenario with a tofu block 19.6\u00d719.6\u00d715mm3 that is soft, and deformable object, gripped by a soft robotic gripper with two fingers. Each fingertip's surface, which directly makes contact with the tofu, was deposited soft pads in two cases: normal pads (flat surface) and a micropatterned pads. The micropatterned pad comprises of 14400 square cells, each cell has four 85 \u03bcm edges, surrounded by a channel network with 44 \u03bcm in depth. We conducted estimation of grasped force generated by pads in two cases, then verified by actual setup in griping the tofu block. Both estimated and experimental results reveal that the micropatterned pad decreased necessary load acting on the tofu's surface 2.2 times lower than that of the normal one, while maintaining the stability of the grasped tofu. The showcase in this paper supported the potential of micro patterns on soft fingertip in grasping deformable objects in wet environments without complicated control strategy, promising wider applications for robot in service section or food industry.",
        "primary_area": "",
        "author": "Pho Van Nguyen;Quan Khanh Luu;Yuzuru Takamura;Van Anh Ho;Pho Van Nguyen;Quan Khanh Luu;Yuzuru Takamura;Van Anh Ho",
        "authorids": "/37086414145;/37088687613;/37312464300;/37529964700;/37086414145;/37088687613;/37312464300;/37529964700",
        "aff": "School of Materials Science, Japan Advanced Institute of Science and Technology (JAIST), Nomi, Japan; School of Materials Science, Japan Advanced Institute of Science and Technology (JAIST), Nomi, Japan; School of Materials Science, Japan Advanced Institute of Science and Technology (JAIST), Nomi, Japan; School of Materials Science, Japan Advanced Institute of Science and Technology (JAIST), Nomi, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341095/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2596739734675055259&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Japan Advanced Institute of Science and Technology",
        "aff_unique_dep": "School of Materials Science",
        "aff_unique_url": "https://www.jaist.ac.jp",
        "aff_unique_abbr": "JAIST",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Nomi",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9340879",
        "title": "What the HoloLens Maps Is Your Workspace: Fast Mapping and Set-up of Robot Cells via Head Mounted Displays and Augmented Reality",
        "track": "main",
        "status": "Poster",
        "abstract": "Classical methods of modelling and mapping robot work cells are time consuming, expensive and involve expert knowledge. We present a novel approach to mapping and cell setup using modern Head Mounted Displays (HMDs) that possess self-localisation and mapping capabilities. We leveraged these capabilities to create a point cloud of the environment and build an OctoMap - a voxel occupancy grid representation of the robot's workspace for path planning. Through the use of Augmented Reality (AR) interactions, the user can edit the created Octomap and add safety zones. We perform comprehensive tests of the HoloLens' depth sensing capabilities and the quality of the resultant point cloud. A high-end laser scanner is used to provide the ground truth for the evaluation of the point cloud quality. The amount of false-positive and false-negative voxels in the OctoMap are also tested.",
        "primary_area": "",
        "author": "David Puljiz;Franziska Krebs;Fabian Bosing;Bjorn Hein;David Puljiz;Franziska Krebs;Fabian Bosing;Bjorn Hein",
        "authorids": "/37086575797;/37088688715;/37088688110;/37604448500;/37086575797;/37088688715;/37088688110;/37604448500",
        "aff": "Intelligent Process Automation and Robotics Lab (IPR), Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany; High Performance Humanoid Technologies Lab (H2T), Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany; Intelligent Process Automation and Robotics Lab (IPR), Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany; Karlsruhe University of Applied Sciences, Karlsruhe, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340879/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2311271157504748638&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Karlsruhe Institute of Technology;Karlsruhe University of Applied Sciences",
        "aff_unique_dep": "Institute for Anthropomatics and Robotics;",
        "aff_unique_url": "https://www.kit.edu;https://www.hs-karlsruhe.de",
        "aff_unique_abbr": "KIT;HsKA",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Karlsruhe",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9341412",
        "title": "What to Do When You Can\u2019t Do It All: Temporal Logic Planning with Soft Temporal Logic Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we consider a temporal logic planning problem in which the objective is to find an infinite trajectory that satisfies an optimal selection from a set of soft specifications expressed in linear temporal logic (LTL) while nevertheless satisfying a hard specification expressed in LTL. Our previous work considered a similar problem in which linear dynamic logic for finite traces (LDLf), rather than LTL, was used to express the soft constraints. In that work, LDLf was used to impose constraints on finite prefixes of the infinite trajectory. By using LTL, one is able not only to impose constraints on the finite prefixes of the trajectory, but also to set `soft' goals across the entirety of the infinite trajectory. Our algorithm first constructs a product automaton, on which the planning problem is reduced to computing a lasso with minimum cost. Among all such lassos, it is desirable to compute a shortest one. Though we prove that computing such a shortest lasso is computationally hard, we also introduce an efficient greedy approach to synthesize short lassos nonetheless. We present two case studies describing an implementation of this approach, and report results of our experiment comparing our greedy algorithm with an optimal baseline.",
        "primary_area": "",
        "author": "Hazhar Rahmani;Jason M. O\u2019Kane;Hazhar Rahmani;Jason M. O\u2019Kane",
        "authorids": "/37086453006;/37279835400;/37086453006;/37279835400",
        "aff": "Department of Computer Science and Engineering, University of South Carolina; Department of Computer Science and Engineering, University of South Carolina",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341412/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8546872677892395114&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 14,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of South Carolina",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.sc.edu",
        "aff_unique_abbr": "USC",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341739",
        "title": "When We First Met: Visual-Inertial Person Localization for Co-Robot Rendezvous",
        "track": "main",
        "status": "Poster",
        "abstract": "We aim to enable robots to visually localize a target person through the aid of an additional sensing modality - the target person's 3D inertial measurements. The need for such technology may arise when a robot is to meet a person in a crowd for the first time or when an autonomous vehicle must rendezvous with a rider amongst a crowd without knowing the appearance of the person in advance. A person's inertial information can be measured with a wearable device such as a smart-phone and can be shared selectively with an autonomous system during the rendezvous. We propose a method to learn a visual-inertial feature space in which the motion of a person in video can be easily matched to the motion measured by a wearable inertial measurement unit (IMU). The transformation of the two modalities into the joint feature space is learned through the use of a triplet loss which forces inertial motion features and video motion features generated by the same person to lie close in the joint feature space. To validate our approach, we compose a dataset of over 3,000 video segments of moving people along with wearable IMU data. We show that our method is able to localize a target person with 80.7% accuracy averaged over testing data with various number of candidates using only 5 seconds of IMU data and video.",
        "primary_area": "",
        "author": "Xi Sun;Xinshuo Weng;Kris Kitani;Xi Sun;Xinshuo Weng;Kris Kitani",
        "authorids": "/37088690788;/37086376142;/37294510900;/37088690788;/37086376142;/37294510900",
        "aff": "Robotics Institute, Carnegie Mellon University; Robotics Institute, Carnegie Mellon University; Robotics Institute, Carnegie Mellon University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341739/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2906709761328978253&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341072",
        "title": "Who Make Drivers Stop? Towards Driver-centric Risk Assessment: Risk Object Identification via Causal Inference",
        "track": "main",
        "status": "Poster",
        "abstract": "A significant amount of people die in road accidents due to driver errors. To reduce fatalities, developing intelligent driving systems assisting drivers to identify potential risks is in an urgent need. Risky situations are generally defined based on collision prediction in the existing works. However, collision is only a source of potential risks, and a more generic definition is required. In this work, we propose a novel driver-centric definition of risk, i.e., objects influencing drivers' behavior are risky. A new task called risk object identification is introduced. We formulate the task as the cause-effect problem and present a novel two-stage risk object identification framework based on causal inference with the proposed object-level manipulable driving model. We demonstrate favorable performance on risk object identification compared with strong baselines on the Honda Research Institute Driving Dataset (HDD). Our framework achieves a substantial average performance boost over a strong baseline by 7.5%.",
        "primary_area": "",
        "author": "Chengxi Li;Stanley H. Chan;Yi-Ting Chen;Chengxi Li;Stanley H. Chan;Yi-Ting Chen",
        "authorids": "/37088506006;/37600910000;/37086488009;/37088506006;/37600910000;/37086488009",
        "aff": "Department of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, USA; Department of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, USA; Honda Research Institute USA, San Jose, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341072/",
        "gs_citation": 63,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17579847376061178133&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Purdue University;Honda Research Institute USA",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;",
        "aff_unique_url": "https://www.purdue.edu;https://honda-ri.com",
        "aff_unique_abbr": "Purdue;HRI USA",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "West Lafayette;San Jose",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341009",
        "title": "Whole-Game Motion Capturing of Team Sports: System Architecture and Integrated Calibration",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper discusses the application of video motion capturing technology (VMocap) to a competitive team sports game. The setting introduces a specific set of constraints: large scale markerless motion capturing, big recording volume, transmitting and processing gigabytes of data, operation without interfering with players or distracting spectators and staff, etc... In this paper, we present how we tackled and successfully solved all of these constraints. That enabled us to analyze the sportsmen without any intrusions, while giving their peak performance, hence opening a new field for Mocap application. International volleyball game was recorded in full length with the described system. During the course of the event, we compressed 54TB of raw image data real-time, capturing 6 hours of high framerate video per camera, without disturbing any of the game operations. Using the data, we were able to reconstruct the motion, muscle activity and behavior of the athletes present on the court.",
        "primary_area": "",
        "author": "Yosuke Ikegami;Milutin Nikoli\u0107;Ayaka Yamada;Lei Zhang;Natsu Ooke;Yoshihiko Nakamura;Yosuke Ikegami;Milutin Nikoli\u0107;Ayaka Yamada;Lei Zhang;Natsu Ooke;Yoshihiko Nakamura",
        "authorids": "/38251779000;/37721482100;/37087031398;/37292620600;/37088691182;/37280754600;/38251779000;/37721482100;/37087031398;/37292620600;/37088691182;/37280754600",
        "aff": "Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Faculty of Technical Sciences, University of Novi Sad, Novi Sad, Serbia; Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; School of Electrical and Information Engineering, Beijing University of Civil Engineering and Architecture, Beijing, China; Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341009/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11349439092394155168&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;2;0;0",
        "aff_unique_norm": "The University of Tokyo;University of Novi Sad;Beijing University of Civil Engineering and Architecture",
        "aff_unique_dep": "Graduate School of Information Science and Technology;Faculty of Technical Sciences;School of Electrical and Information Engineering",
        "aff_unique_url": "https://www.u-tokyo.ac.jp;https://www.uns.ac.rs;http://www.bucea.edu.cn",
        "aff_unique_abbr": "UTokyo;;",
        "aff_campus_unique_index": "0;1;0;2;0;0",
        "aff_campus_unique": "Tokyo;Novi Sad;Beijing",
        "aff_country_unique_index": "0;1;0;2;0;0",
        "aff_country_unique": "Japan;Serbia;China"
    },
    {
        "id": "9340812",
        "title": "Wind and the City: Utilizing UAV-Based In-Situ Measurements for Estimating Urban Wind Fields",
        "track": "main",
        "status": "Poster",
        "abstract": "A high-quality estimate of wind fields can potentially improve the safety and performance of Unmanned Aerial Vehicles (UAVs) operating in dense urban areas. Computational Fluid Dynamics (CFD) simulations can help provide a wind field estimate, but their accuracy depends on the knowledge of the distribution of the inlet boundary conditions. This paper provides a real-time methodology using a Particle Filter (PF) that utilizes wind measurements from a UAV to solve the inverse problem of predicting the inlet conditions as the UAV traverses the flow field. A Gaussian Process Regression (GPR) approach is used as a surrogate function to maintain the real-time nature of the proposed methodology. Real-world experiments with a UAV at an urban test-site prove the efficacy of the proposed method. The flight test shows that the 95% confidence interval for the difference between the mean estimated inlet conditions and mean ground truth measurements closely bound zero, with the difference in mean angles being between -3.7\u00b0 and 1.3\u00b0 and the difference in mean magnitudes being between -0.2 m/s and 0.0 m/s.Video : https://youtu.be/U4XdYgSJRZM.",
        "primary_area": "",
        "author": "Jay Patrikar;Brady G. Moon;Sebastian Scherer;Jay Patrikar;Brady G. Moon;Sebastian Scherer",
        "authorids": "/37086449345;/37086448648;/37584159000;/37086449345;/37086448648;/37584159000",
        "aff": "School of Computer Science, Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; School of Computer Science, Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; School of Computer Science, Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340812/",
        "gs_citation": 35,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10845774611147178099&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "School of Computer Science, Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341275",
        "title": "Wiping 3D-objects using Deep Learning Model based on Image/Force/Joint Information",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a deep learning model for a robot to wipe 3D-objects. Wiping of 3D-objects requires recognizing the shapes of objects and planning the motor angle adjustments for tracing the objects. Unlike previous research, our learning model does not require pre-designed computational models of target objects. The robot is able to wipe the objects to be placed by using image, force, and arm joint information. We evaluate the generalization ability of the model by confirming that the robot handles untrained cube and bowl shaped-objects. We also find that it is necessary to use both image and force information to recognize the shape of and wipe 3D objects consistently by comparing changes in the input sensor data to the model. To our knowledge, this is the first work enabling a robot to use learning sensorimotor information alone to trace various unknown 3D-shape.",
        "primary_area": "",
        "author": "Namiko Saito;Danyang Wang;Tetsuya Ogata;Hiroki Mori;Shigeki Sugano;Namiko Saito;Danyang Wang;Tetsuya Ogata;Hiroki Mori;Shigeki Sugano",
        "authorids": "/37086597961;/37088690391;/37273829100;/37086432927;/37274050800;/37086597961;/37088690391;/37273829100;/37086432927;/37274050800",
        "aff": "Department of Modern Mechanical Engineering, Waseda University, Tokyo, Japan; Department of Modern Mechanical Engineering, Waseda University, Tokyo, Japan; National Institute of Advanced Science and Technology, Tokyo, Japan; Future Robotics Organization, Waseda University, Tokyo, Japan; Department of Modern Mechanical Engineering, Waseda University, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341275/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10375827736164275236&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "Waseda University;National Institute of Advanced Science and Technology",
        "aff_unique_dep": "Department of Modern Mechanical Engineering;",
        "aff_unique_url": "https://www.waseda.jp/top;",
        "aff_unique_abbr": "Waseda;",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9340787",
        "title": "Wireless Electronic Skin with Integrated Pressure and Optical Proximity Sensing",
        "track": "main",
        "status": "Poster",
        "abstract": "Electronic skins and tactile sensors can provide the sense of touch to robotic manipulators. These sensing modalities complement existing long range optical sensors and can provide detailed information before and after contact. However, integration with existing systems can be challenging due to size constraints, the interface geometry, and restrictions of external wiring used to interface with the sensor. Here, we introduce a low-profile, wireless electronic skin for direct integration with existing robotic manipulators. The flexible electronic skin combines pressure, optical proximity sensing, and a micro-LIDAR device in a small, low profile package. Each of the sensors are characterized individually and the system is demonstrated on Robonaut 2, an anthropomorphic robot designed to work in environments designed for humans. We demonstrate the sensor can be used for contact sensing, mapping of local unknown environments, and to provide medical monitoring during an emergency in a remote area.",
        "primary_area": "",
        "author": "Eric J. Markvicka;Jonathan M. Rogers;Carmel Majidi;Eric J. Markvicka;Jonathan M. Rogers;Carmel Majidi",
        "authorids": "/37086368257;/37088687087;/37589572800;/37086368257;/37088687087;/37589572800",
        "aff": "Department of Mechanical and Materials Engineering, Smart Materials and Robotics Laboratory, University of Nebraska\u2013Lincoln, Lincoln, NE; NASA Johnson Space Center, Houston, TX; Soft Machines Lab, Robotics Institute, Carnegie Mellon University, Pittsburgh, PA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340787/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13753504943628637962&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "University of Nebraska\u2013Lincoln;NASA Johnson Space Center;Carnegie Mellon University",
        "aff_unique_dep": "Department of Mechanical and Materials Engineering;;Robotics Institute",
        "aff_unique_url": "https://www.unl.edu;https://www.nasa.gov centers johnson;https://www.cmu.edu",
        "aff_unique_abbr": "UNL;JSC;CMU",
        "aff_campus_unique_index": "0;1;2",
        "aff_campus_unique": "Lincoln;Houston;Pittsburgh",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341762",
        "title": "With Whom to Communicate: Learning Efficient Communication for Multi-Robot Collision Avoidance",
        "track": "main",
        "status": "Poster",
        "abstract": "Decentralized multi-robot systems typically perform coordinated motion planning by constantly broadcasting their intentions as a means to cope with the lack of a central system coordinating the efforts of all robots. Especially in complex dynamic environments, the coordination boost allowed by communication is critical to avoid collisions between cooperating robots. However, the risk of collision between a pair of robots fluctuates through their motion and communication is not always needed. Additionally, constant communication makes much of the still valuable information shared in previous time steps redundant. This paper presents an efficient communication method that solves the problem of \"when\" and with \"whom\" to communicate in multi-robot collision avoidance scenarios. In this approach, every robot learns to reason about other robots' states and considers the risk of future collisions before asking for the trajectory plans of other robots. We evaluate and verify the proposed communication strategy in simulation with four quadrotors and compare it with three baseline strategies: non-communicating, broadcasting and a distance-based method broadcasting information with quadrotors within a predefined distance.",
        "primary_area": "",
        "author": "\u00c1lvaro Serra-G\u00f3mez;Bruno Brito;Hai Zhu;Jen Jen Chung;Javier Alonso-Mora;\u00c1lvaro Serra-G\u00f3mez;Bruno Brito;Hai Zhu;Jen Jen Chung;Javier Alonso-Mora",
        "authorids": "/37088691504;/37086963867;/37086618561;/37085668354;/38271697300;/37088691504;/37086963867;/37086618561;/37085668354;/38271697300",
        "aff": "Department of Cognitive Robotics, Delft University of Technology; Department of Cognitive Robotics, Delft University of Technology; Department of Cognitive Robotics, Delft University of Technology; Autonomous Systems Lab, ETH Zurich; Department of Cognitive Robotics, Delft University of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341762/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7554620992408840550&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 14,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Delft University of Technology;ETH Zurich",
        "aff_unique_dep": "Department of Cognitive Robotics;Autonomous Systems Lab",
        "aff_unique_url": "https://www.tudelft.nl;https://www.ethz.ch",
        "aff_unique_abbr": "TUDelft;ETHZ",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "Netherlands;Switzerland"
    },
    {
        "id": "9340984",
        "title": "X-Ray: Mechanical Search for an Occluded Object by Minimizing Support of Learned Occupancy Distributions",
        "track": "main",
        "status": "Poster",
        "abstract": "For applications in e-commerce, warehouses, healthcare, and home service, robots are often required to search through heaps of objects to grasp a specific target object. For mechanical search, we introduce X-Ray, an algorithm based on learned occupancy distributions. We train a neural network using a synthetic dataset of RGBD heap images labeled for a set of standard bounding box targets with varying aspect ratios. X-Ray minimizes support of the learned distribution as part of a mechanical search policy in both simulated and real environments. We benchmark these policies against two baseline policies on 1,000 heaps of 15 objects in simulation where the target object is partially or fully occluded. Results suggest that X-Ray is significantly more efficient, as it succeeds in extracting the target object 82% of the time, 15% more often than the best-performing baseline. Experiments on an ABB YuMi robot with 20 heaps of 25 household objects suggest that the learned policy transfers easily to a physical system, where it outperforms baseline policies by 15% in success rate with 17% fewer actions. Datasets, videos, and experiments are available at https://sites.google.com/berkeley.edu/x-ray.",
        "primary_area": "",
        "author": "Michael Danielczuk;Anelia Angelova;Vincent Vanhoucke;Ken Goldberg;Michael Danielczuk;Anelia Angelova;Vincent Vanhoucke;Ken Goldberg",
        "authorids": "/37086541913;/37295407600;/37426058000;/37273026700;/37086541913;/37295407600;/37426058000;/37273026700",
        "aff": "The Autolab at University of California, Berkeley; Robotics at Google; Robotics at Google; The Autolab at University of California, Berkeley",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340984/",
        "gs_citation": 46,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8116698799003132670&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "University of California, Berkeley;Google",
        "aff_unique_dep": "The Autolab;Robotics",
        "aff_unique_url": "https://www.berkeley.edu;https://www.google.com",
        "aff_unique_abbr": "UC Berkeley;Google Robotics",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Berkeley;Mountain View",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341426",
        "title": "Z-Net: an Anisotropic 3D DCNN for Medical CT Volume Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "Accurate volume segmentation from the Computed Tomography (CT) scan is a common prerequisite for pre-operative planning, intra-operative guidance and quantitative assessment of therapeutic outcomes in robot-assisted Minimally Invasive Surgery (MIS). 3D Deep Convolutional Neural Network (DCNN) is a viable solution for this task, but is memory intensive. Small isotropic patches are cropped from the original and large CT volume to mitigate this issue in practice, but it may cause discontinuities between the adjacent patches and severe class-imbalances within individual sub-volumes. This paper presents a new 3D DCNN framework, namely Z-Net, to tackle the discontinuity and class-imbalance issue by preserving a full field-of-view of the objects in the XY planes using anisotropic spatial separable convolutions. The proposed Z-Net can be seamlessly integrated into existing 3D DCNNs with isotropic convolutions such as 3D U-Net and V-Net, with improved volume segmentation Intersection over Union (IoU) - up to 12.6%. Detailed validation of Z-Net is provided for CT aortic, liver and lung segmentation, demonstrating the effectiveness and practical value of Z-Net for intra-operative 3D navigation in robot-assisted MIS.",
        "primary_area": "",
        "author": "Peichao Li;Xiao-Yun Zhou;Zhao-Yang Wang;Guang-Zhong Yang;Peichao Li;Xiao-Yun Zhou;Zhao-Yang Wang;Guang-Zhong Yang",
        "authorids": "/37088405582;/37085804767;/37088406942;/37276270800;/37088405582;/37085804767;/37088406942;/37276270800",
        "aff": "Imperial College London, The Hamlyn Centre for Robotic Surgery, UK; Imperial College London, The Hamlyn Centre for Robotic Surgery, UK; Imperial College London, The Hamlyn Centre for Robotic Surgery, UK; Institute of Medical Robotics, Shanghai Jiao Tong University, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341426/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3563113316268266399&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Imperial College London;Shanghai Jiao Tong University",
        "aff_unique_dep": "The Hamlyn Centre for Robotic Surgery;Institute of Medical Robotics",
        "aff_unique_url": "https://www.imperial.ac.uk;https://www.sjtu.edu.cn",
        "aff_unique_abbr": "ICL;SJTU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "United Kingdom;China"
    },
    {
        "id": "9341102",
        "title": "Zero-tuning Grinding Process Methodology of Cyber-Physical Robot System",
        "track": "main",
        "status": "Poster",
        "abstract": "Industrial robots play potential and important roles on labor-intensive and high-risk jobs. For example, typical industrial robots have been used in grinding process. However, the automatic grinding process by robots is a complex process because it still relies on skillful engineers to adaptively adjust several key parameters. Moreover, it might take a lot of time and effort to yield better grinding quality. Hence, this paper proposed a new framework of cyber-physical robot system with automatic zero-tuning optimization of the process parameters to achieve the desired quality. To overcome the unexpected difference between reality and simulation, proper system calibration can help in precise positioning in real environment, and the cloud database is constructed to record the relative data during the grinding process simultaneously. The proposed zero-tuning methodology combines both neural network (NN) model and genetic algorithm (GA) to generate the best combination of corresponding parameters to meet the desired quality. Experimental results showed that the average error of the output result was 8.93%. To compare the CNC machine, our solution shows more prominent role and potential in plumbing industry.",
        "primary_area": "",
        "author": "Hsuan-Yu Yang;Chih-Hsuan Shih;Yuan-Chieh Lo;Feng-Li Lian;Hsuan-Yu Yang;Chih-Hsuan Shih;Yuan-Chieh Lo;Feng-Li Lian",
        "authorids": "/37088455075;/37086924827;/37088455350;/37300823500;/37088455075;/37086924827;/37088455350;/37300823500",
        "aff": "Mechanical and Mechatronics System Research Laboratories, Industrial Technology Research Institute, Hsinchu, Taiwan; Mechanical and Mechatronics System Research Laboratories, Industrial Technology Research Institute, Hsinchu, Taiwan; Mechanical and Mechatronics System Research Laboratories, Industrial Technology Research Institute, Hsinchu, Taiwan; Mechanical and Mechatronics System Research Laboratories, Industrial Technology Research Institute, Hsinchu, Taiwan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341102/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9951059432658923763&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Industrial Technology Research Institute",
        "aff_unique_dep": "Mechanical and Mechatronics System Research Laboratories",
        "aff_unique_url": "https://www.itri.org.tw",
        "aff_unique_abbr": "ITRI",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Taiwan",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9340723",
        "title": "daVinciNet: Joint Prediction of Motion and Surgical State in Robot-Assisted Surgery",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a technique to concurrently and jointly predict the future trajectories of surgical instruments and the future state(s) of surgical subtasks in robot-assisted surgeries (RAS) using multiple input sources. Such predictions are a necessary first step towards shared control and supervised autonomy of surgical subtasks. Minute-long surgical subtasks, such as suturing or ultrasound scanning, often have distinguishable tool kinematics and visual features, and can be described as a series of fine-grained states with transition schematics. We propose daVinciNet - an end-to-end dual-task model for robot motion and surgical state predictions. daVinciNet performs concurrent end-effector trajectory and surgical state predictions using features extracted from multiple data streams, including robot kinematics, endoscopic vision, and system events. We evaluate our proposed model on an extended Robotic Intra-Operative Ultrasound (RIOUS+) imaging dataset collected on a da Vinci\u00ae Xi surgical system and the JHU-ISI Gesture and Skill Assessment Working Set (JIGSAWS). Our model achieves up to 93.85% short-term (0.5s) and 82.11% long-term (2s) state prediction accuracy, as well as 1.07mm short-term and 5.62mm long-term trajectory prediction error.",
        "primary_area": "",
        "author": "Yidan Qin;Seyedshams Feyzabadi;Max Allan;Joel W. Burdick;Mahdi Azizian;Yidan Qin;Seyedshams Feyzabadi;Max Allan;Joel W. Burdick;Mahdi Azizian",
        "authorids": "/37088507580;/37073463100;/37086200641;/37265975700;/37088506571;/37088507580;/37073463100;/37086200641;/37265975700;/37088506571",
        "aff": "Department of Mechanical and Civil Engineering, California Institute of Technology, Pasadena, CA, USA; Intuitive Surgical Inc., Sunnyvale, CA, USA; Intuitive Surgical Inc., Sunnyvale, CA, USA; Department of Mechanical and Civil Engineering, California Institute of Technology, Pasadena, CA, USA; Intuitive Surgical Inc., Sunnyvale, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340723/",
        "gs_citation": 37,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16857584293706241381&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;0;1",
        "aff_unique_norm": "California Institute of Technology;Intuitive Surgical Inc.",
        "aff_unique_dep": "Department of Mechanical and Civil Engineering;",
        "aff_unique_url": "https://www.caltech.edu;https://www.intuitivesurgical.com",
        "aff_unique_abbr": "Caltech;Intuitive Surgical",
        "aff_campus_unique_index": "0;1;1;0;1",
        "aff_campus_unique": "Pasadena;Sunnyvale",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9340956",
        "title": "robo-gym \u2013 An Open Source Toolkit for Distributed Deep Reinforcement Learning on Real and Simulated Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Applying Deep Reinforcement Learning (DRL) to complex tasks in the field of robotics has proven to be very successful in the recent years. However, most of the publications focus either on applying it to a task in simulation or to a task in a real world setup. Although there are great examples of combining the two worlds with the help of transfer learning, it often requires a lot of additional work and fine-tuning to make the setup work effectively. In order to increase the use of DRL with real robots and reduce the gap between simulation and real world robotics, we propose an open source toolkit: robo-gym1. We demonstrate a unified setup for simulation and real environments which enables a seamless transfer from training in simulation to application on the robot. We showcase the capabilities and the effectiveness of the framework with two real world applications featuring industrial robots: a mobile robot and a robot arm. The distributed capabilities of the framework enable several advantages like using distributed algorithms, separating the workload of simulation and training on different physical machines as well as enabling the future opportunity to train in simulation and real world at the same time. Finally, we offer an overview and comparison of robo-gym with other frequently used state-of-the-art DRL frameworks.",
        "primary_area": "",
        "author": "Matteo Lucchi;Friedemann Zindler;Stephan M\u00fchlbacher-Karrer;Horst Pichler;Matteo Lucchi;Friedemann Zindler;Stephan M\u00fchlbacher-Karrer;Horst Pichler",
        "authorids": "/37089124257;/37088688286;/38353427100;/37086935320;/37089124257;/37088688286;/38353427100;/37086935320",
        "aff": "Joanneum Research \u2013 Robotics, Klagenfurt am W\u00f6rthersee, Austria; Joanneum Research \u2013 Robotics, Klagenfurt am W\u00f6rthersee, Austria; Joanneum Research \u2013 Robotics, Klagenfurt am W\u00f6rthersee, Austria; Joanneum Research \u2013 Robotics, Klagenfurt am W\u00f6rthersee, Austria",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9340956/",
        "gs_citation": 47,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6716175836692423982&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Joanneum Research",
        "aff_unique_dep": "Robotics",
        "aff_unique_url": "https://www.joanneum.at",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Klagenfurt am W\u00f6rthersee",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Austria"
    },
    {
        "id": "9341314",
        "title": "se(3)-TrackNet: Data-driven 6D Pose Tracking by Calibrating Image Residuals in Synthetic Domains",
        "track": "main",
        "status": "Poster",
        "abstract": "Tracking the 6D pose of objects in video sequences is important for robot manipulation. This task, however, introduces multiple challenges: (i) robot manipulation involves significant occlusions; (ii) data and annotations are troublesome and difficult to collect for 6D poses, which complicates machine learning solutions, and (iii) incremental error drift often accumulates in long term tracking to necessitate re-initialization of the object's pose. This work proposes a data-driven optimization approach for long-term, 6D pose tracking. It aims to identify the optimal relative pose given the current RGB-D observation and a synthetic image conditioned on the previous best estimate and the object's model. The key contribution in this context is a novel neural network architecture, which appropriately disentangles the feature encoding to help reduce domain shift, and an effective 3D orientation representation via Lie Algebra. Consequently, even when the network is trained only with synthetic data can work effectively over real images. Comprehensive experiments over benchmarks - existing ones as well as a new dataset with significant occlusions related to object manipulation - show that the proposed approach achieves consistently robust estimates and outperforms alternatives, even though they have been trained with real images. The approach is also the most computationally efficient among the alternatives and achieves a tracking frequency of 90.9Hz.",
        "primary_area": "",
        "author": "Bowen Wen;Chaitanya Mitash;Baozhang Ren;Kostas E. Bekris;Bowen Wen;Chaitanya Mitash;Baozhang Ren;Kostas E. Bekris",
        "authorids": "/37088488448;/37086289032;/37088686114;/37282424700;/37088488448;/37086289032;/37088686114;/37282424700",
        "aff": "Computer Science Department of Rutgers, University in Piscataway, New Jersey, USA; Computer Science Department of Rutgers, University in Piscataway, New Jersey, USA; Computer Science Department of Rutgers, University in Piscataway, New Jersey, USA; Computer Science Department of Rutgers, University in Piscataway, New Jersey, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341314/",
        "gs_citation": 142,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17625390908019628846&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Rutgers University",
        "aff_unique_dep": "Computer Science Department",
        "aff_unique_url": "https://www.rutgers.edu",
        "aff_unique_abbr": "Rutgers",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Piscataway",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9341798",
        "title": "\u03c0-Map: A Decision-Based Sensor Fusion with Global Optimization for Indoor Mapping",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose \u03c0-map, a tightly coupled fusion mechanism that dynamically consumes LiDAR and sonar data to generate reliable and scalable indoor maps for autonomous robot navigation. The key novelty of \u03c0-map over previous attempts is the utilization of a fusion mechanism that works in three stages: the first LiDAR scan matching stage efficiently generates initial key localization poses; the second optimization stage is used to eliminate errors accumulated from the previous stage and guarantees that accurate large-scale maps can be generated; then the final revisit scan fusion stage effectively fuses the LiDAR map and the sonar map to generate a highly accurate representation of the indoor environment. We evaluate \u03c0-map on both large and small environments and verify its superiority over existing fusion methods.",
        "primary_area": "",
        "author": "Zhiliu Yang;Bo Yu;Wei Hu;Jie Tang;Shaoshan Liu;Chen Liu;Zhiliu Yang;Bo Yu;Wei Hu;Jie Tang;Shaoshan Liu;Chen Liu",
        "authorids": "/37086430886;/37086262236;/37088549429;/37085384969;/37406041000;/37599996300;/37086430886;/37086262236;/37088549429;/37085384969;/37406041000;/37599996300",
        "aff": "Department of Electrical and Computer Engineering, Clarkson University, Potsdam, NY, USA; PerceptIn, Fremont, CA, USA; PerceptIn, Fremont, CA, USA; School of Computer Science and Engineering, South China University of Technology, Guangzhou, China; PerceptIn, Fremont, CA, USA; Department of Electrical and Computer Engineering, Clarkson University, Potsdam, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341798/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12300481701363489232&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;2;1;0",
        "aff_unique_norm": "Clarkson University;PerceptIn;South China University of Technology",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;;School of Computer Science and Engineering",
        "aff_unique_url": "https://www.clarkson.edu;;https://www.scut.edu.cn",
        "aff_unique_abbr": "Clarkson;;SCUT",
        "aff_campus_unique_index": "0;1;1;2;1;0",
        "aff_campus_unique": "Potsdam;Fremont;Guangzhou",
        "aff_country_unique_index": "0;0;0;1;0;0",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "9341154",
        "title": "\u21121-Adaptive MPPI Architecture for Robust and Agile Control of Multirotors",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a multirotor control architecture, where Model Predictive Path Integral Control (MPPI) and \u21121 adaptive control are combined to achieve both fast model predictive trajectory planning and robust trajectory tracking. MPPI provides a framework to solve nonlinear MPC with complex cost functions in real-time. However, it often lacks robustness, especially when the simulated dynamics are different from the true dynamics. We show that the \u21121 adaptive controller robustifies the architecture, allowing the overall system to behave similar to the nominal system simulated with MPPI. The architecture is validated in a simulated multirotor racing environment.",
        "primary_area": "",
        "author": "Jintasit Pravitra;Kasey A. Ackerman;Chengyu Cao;Naira Hovakimyan;Evangelos A. Theodorou;Jintasit Pravitra;Kasey A. Ackerman;Chengyu Cao;Naira Hovakimyan;Evangelos A. Theodorou",
        "authorids": "/37085791898;/37085541358;/37287632200;/37299175600;/37546007800;/37085791898;/37085541358;/37287632200;/37299175600;/37546007800",
        "aff": "School of Aerospace Engineering, Georgia Institute of Technology, Atlanta, GA, USA; Mechanical Science and Engineering Department, University of Illinois at Urbana-Champaign, Urbana, IL; Department of Mechanical Engineering, University of Connecticut, Storrs, CT; Mechanical Science and Engineering Department, University of Illinois at Urbana-Champaign, Urbana, IL; School of Aerospace Engineering, Georgia Institute of Technology, Atlanta, GA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9341154/",
        "gs_citation": 88,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1299349559677375267&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;1;0",
        "aff_unique_norm": "Georgia Institute of Technology;University of Illinois at Urbana-Champaign;University of Connecticut",
        "aff_unique_dep": "School of Aerospace Engineering;Mechanical Science and Engineering Department;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.gatech.edu;https://illinois.edu;https://www.uconn.edu",
        "aff_unique_abbr": "Georgia Tech;UIUC;UConn",
        "aff_campus_unique_index": "0;1;2;1;0",
        "aff_campus_unique": "Atlanta;Urbana;Storrs",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    }
]